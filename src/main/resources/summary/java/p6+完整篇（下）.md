# 九、Netty篇

### 1.1. 内核空间、用户空间？

1. 现在操作系统都是采用虚拟存储器，那么对 32 位操作系统而言，它的寻址空间（虚拟存储空间）为 4G（2的32次方）。
2. 操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限，所以，为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。
3. 针对 linux 操作系统而言，将最高的 1G 字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF），供内核使用，称为内核空间。
4. 而将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。

### 1.2. 进程切换？

为了控制进程的执行，内核必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：

1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新 PCB 信息。
3. 把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其 PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

=> **总而言之就是很耗资源**。

### 1.3. 进程的阻塞？

1. 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由进程自动执行阻塞原语（Block），使自己由运行状态变为阻塞状态。
2. 所以，进程的阻塞，是进程自身的一种**主动行为**，也因此只有处于运行态的进程（已获得 CPU 的进程），才可能将其转为阻塞状态。
3. 当进程进入阻塞状态后，会让出 CPU 资源，不占用 CPU。

### 1.4. 同步、异步、阻塞、非阻塞？

- **同步、异步**：同步和异步，是针对应用程序和内核的**交互**而言的：
  1. 同步，是指用户进程触发 I/O 操作，并等待或者轮询地去查看 I/O 操作是否就绪。
  2. 异步，则是指用户进程触发 I/O 操作以后，便开始做自己的事情，当 I/O 操作已经完成时，会得到操作系统派发的 I/O 操作完成的通知。
- **阻塞、非阻塞**：阻塞和非阻塞，是针对于进程在访问数据时，根据 I/O 操作的就绪状态而采取的不同方式，说白了就是读取或者写入时说调用**函数的不同实现方式**：
  1. 阻塞方式下，读取或者写入函数，应用程序需要一直等待，直到函数执行完成。
  2. 非阻塞方式下，读取或者写入函数，会立即返回一个状态值，相当于是一个尝试性的执行动作。

=> 综上所述，同步、异步是相对于应用和内核的交互方式而言的，同步需要主动去询问，而异步的时候内核在 I/O 事件发生时通知应用程序，而阻塞、非阻塞仅仅是系统在调用系统调用时，函数的实现方式不同而已。

### 1.5. 文件描述符 fd？

1. 文件描述符，File descriptor，是计算机科学中的一个术语，是一个用于表述指向**文件引用**的抽象化概念。
2. 文件描述符，在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开**文件的记录表**：当程序打开一个现有文件，或者创建一个新文件时，内核向进程返回一个文件描述符。
3. 在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展，但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

### 1.6. 缓存 I/O？

1. 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。
2. 在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据，缓存在文件系统的页缓存（page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区中，拷贝到应用程序的地址空间。
3. **缓存 I/O 的缺点**：数据在传输过程中，需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

### 1.7. Linux I/O 模式？

对于一次 I/O 访问（以 read 为例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，所以，当一个 read 操作发生时，它会经历两个阶段：

1. 等待数据准备 (Waiting for the data to be ready)
2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux 系统产生了下面五种网络模式的方案：
- 阻塞 I/O（blocking I/O）
- 非阻塞 I/O（nonblocking I/O）
- I/O 多路复用（ I/O multiplexing）
- 信号驱动 I/O（ signal driven I/O）
- 异步 I/O（asynchronous I/O）

注：signal driven IO 在实际中并不常用~

#### 1）阻塞 I/O（blocking I/O）

在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：

![1646817239297](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817239297.png)

1. 当用户进程调用了 `recvfrom` 这个系统调用，kernel 就开始了 I/O 的第一个阶段：准备数据（对于网络 I/O 来说，很多时候数据在一开始还没有到达，比如，还没有收到一个完整的 UDP 包，这个时候，kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。
2. 而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 状态，重新运行起来。
3. 所以，blocking I/O 的特点是，在 I/O 执行的两个阶段都会被 block 住。

#### 2）非阻塞 I/O（nonblocking I/O）

linux 下，可以通过设置 socket 使其变为 non-blocking，当对一个 non-blocking socket 执行读操作时，流程是这个样子：

![1646817424161](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817424161.png)

1. 当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。
2. 从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果，但用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。
3. 一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回。
4. 所以，nonblocking I/O 的特点是，用户进程需要不断的主动询问 kernel 数据好了没有。

#### 3）I/O 多路复用（ I/O multiplexing）

I/O multiplexing 就是我们说的 `select`、`poll` 和 `epoll`，有些地方也称这种 I/O 方式为事件驱动型 I/O event driven IO。

1. `select` / `epoll` 的好处就在于，单个 process 就可以同时处理**多个**网络连接的 I/O，其基本原理是，`select`、`poll` 、`epoll` 这些 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。
2. 当用户进程调用了 `select`，那么整个进程会被block，同时，kernel会“监视”所有 `select` 负责的socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。
3. 所以，I/O 多路复用的特点是，通过一种机制，让一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select` 函数就可以返回了。

![1646817566451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817566451.png)

- 这个图和 blocking IO 的图其实并没有太大的不同，事实上，还更差一些，因为这里需要使用两个 system call  (`select` 和 `recvfrom`)，而blocking IO只调用了一个 system call (`recvfrom`)。
- 但是，用 `select` 的优势在于它可以同时处理多个 connection，所以，如果处理的连接数不是很高的话，使用 `select` / `epoll` 的web server不一定比使用 multi-threading + blocking IO 的 web server 性能更好，可能延迟还更大，即其优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。
- 在 IO multiplexing Model 当前模型中，实际中，对于每一个 socket，一般都设置成为 non-blocking，但是，如上图所示，整个用户的 process 其实是一直被 block 的，只不过 process 过程是被 `select` 这个函数 block，而不是被 socket I/O 给 block 住。

=> 所以，基于多路复用模型实现的代码，处理网络 I/O 过程，可以看作是同步非阻塞的。

#### 4）信号驱动 I/O（ signal driven I/O）

1. 在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞。
2. 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中，调用 I/O 操作函数处理数据。

![1646818238023](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646818238023.png)

- **优点**：线程并没有在等待数据时被阻塞，可以提高资源的利用率。
- **缺点**：信号 I/O 在大量 I/O 操作时，可能会因为信号队列溢出，导致没法通知。
- **适用场景**：
  1. 信号驱动 I/O 尽管对于处理 UDP 套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。
  2. 但是，对于 TCP 而言，信号驱动的 I/O 方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源，与前几种方式相比优势尽失。

#### 5）异步 I/O（asynchronous I/O）

inux 下的 asynchronous I/O 其实用得很少，先看一下它的流程：

![1646818029954](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646818029954.png)

1. 用户进程发起 read 操作之后，立刻就可以开始去做其它的事。
2. 而另一方面，从 kernel 的角度，当它受到一个 asynchronous read 之后，首先它会立刻返回，不会对用户进程产生任何 block。
3. 然后，kernel 会等待数据准备完成后，再将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal，告诉它 read 操作完成了。

### 1.8. select、poll、epoll？

1. `select`、`poll`、`epoll` 都是 I/O 多路复用的机制。
2. I/O多路复用，就是通过一种机制，让一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
3. 但 `select`、`poll`、`epoll` 本质上都是同步 I/O，因为它们都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，操作系统会负责把数据从内核拷贝到用户空间。

#### 1）select

```c++
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

1. `select` 函数监视的文件描述符分 3 类，分别是 `writefds`、`readfds`、和 `exceptfds`。
2. 调用后，`select` 函数会阻塞，直到有描述副就绪（比如有数据 可读、可写、或者有 except），或者超时（`timeout` 指定等待时间，如果立即返回设为 null 即可），则函数返回。
3. 当 `select` 函数返回后，可以通过遍历 `fdset` ，来找到就绪的描述符。

- **优点**：`select` 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
- **缺点**：`select` 的一个缺点在于，单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义，甚至重新编译内核的方式来提升这一限制，但是这样也会造成效率的降低。

#### 2）poll

```c++
int poll (struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

- **特点**：
  1. 不同与 `select` 使用三个位图来表示三个 `fdset` 的方式，`poll` 只使用一个 `pollfd` 的指针来实现。
  2. `pollfd` 结构包含了要监视的 event，和 发生的 event，不再使用 `select` “参数-值” 的传递方式。
  3. 同时，`pollfd` 并没有最大数量限制，但数量过大后性能也还是会下降。 
  4. 和 `select` 函数一样，`poll` 返回后，需要轮询 `pollfd` 来获取就绪的描述符。

- **缺点**：
  1. 从上面看，`select` 和 `poll` 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。
  2. 事实上，同时连接的大量客户端，在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

#### 3）epoll

`epoll` 是在 Linux 2.6 内核中提出的，是之前的 `select` 和`poll` 的增强版本。

1. 相对于 `select` 和 `poll` 来说，`epoll` 更加灵活，没有描述符限制。
2. `epoll` 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件，存放到内核的一个事件表中，这样在用户空间和内核空间只需一次的 copy。

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

##### API  - int epoll_create(int size)

1. 创建一个 `epoll` 句柄，size 用来告诉内核这个监听的数目一共有多大，这个参数不同于 `select()` 中的第一个参数，给出最大监听的 fd+1 的值，参数 size 并不是限制了 `epoll` 所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。
2. 当创建好 `epoll` 句柄后，它就会占用一个 fd 值，在 linux 下如果查看 `/proc/进程id/fd/`，是能够看到这个fd 的，所以在使用完 `epoll` 后，必须调用 `close()` 关闭，否则可能导致 fd 被耗尽。

##### API - int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)

此函数是对指定描述符 fd 执行 op 操作：

1. **epfd**：是 `epoll_create()` 的返回值。
2. **op**：表示op操作，用三个宏来表示：
   - 1）`EPOLL_CTL_ADD` ：添加对 fd 的监听事件。
   - 2）`EPOLL_CTL_DEL`：删除对 fd 的监听事件。
   - 3）`EPOLL_CTL_MOD`：修改对 fd 的监听事件。
3. **fd**：是需要监听的文件描述符 fd。
4. **epoll_event**：是告诉内核需要监听什么事，`struct epoll_event` 结构如下：

```c++
// struct epoll_event结构
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
```

##### API - int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout)

等待 `epfd` 上的 I/O 事件，最多返回 `maxevents` 个事件。

1. 参数 `events` 用来从内核得到事件的集合。
2. 参数 `maxevents` 用来告诉内核这个 `events` 有多大，这个 `maxevents` 的值不能大于创建 `epoll_create()` 时的size。
3. 参数 `timeout` 是超时时间，毫秒，0 会立即返回，-1 表示不确定，也有说法说是永久阻塞。
4. **返回值**：该函数返回需要处理的事件数目，如返回0表示已超时。

###### epoll 工作模式

`epoll` 对文件描述符的操作有两种模式：

- **LT 模式**：level trigger，水平触发模式，默认模式。

  1. 当 `epoll_wait` 检测到描述符事件发生，并将此事件通知应用程序，应用程序可以不用立即处理该事件。
  2. 在下次调用 `epoll_wait` 时，操作系统会再次响应应用程序并通知此事件

- **ET模式**：edge trigger，边缘触发模式。

  1. 当 `epoll_wait` 检测到描述符事件发生，并将此事件通知应用程序，应用程序必须立即处理该事件。
  2. 如果一直不对这个 `fd` 做 I/O 操作，内核不会发送更多的通知 (only once)，在下次调用 `epoll_wait` 时，操作系统不会再次响应应用程序通知此事件。

  => **优点**：ET 模式在很大程度上，减少了 `epoll` 事件被重复触发的次数，因此效率要比 LT 模式高。

  => **局限**：`epoll` 工作在 ET 模式时，必须使用 no-block socket 非阻塞套接口，以避免由于一个文件句柄的阻塞读、或者阻塞写操作，把处理多个文件描述符的任务饿死。

##### 4）epoll 总结

- **原理**：
  1. 在 `select` / `poll` 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描。
  2. 而 `epoll` 事先通过 `epoll_ctl()` 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 `callback` 的回调机制，迅速激活这个文件描述符，当进程调用 `epoll_wait()` 时便得到通知。
  3. 这样，`epoll` 去掉了遍历文件描述符，而是通过监听回调的的机制，这也正是 `epoll` 的魅力所在。
- **优点**：
  1. **监视的描述符数量不受限制**：`epoll` 所支持的 fd 上限，是最大可以打开文件的数目，这个数字一般远大于 2048。比如，在 1GB 内存的机器上大约为10 万左右，具体数目可以 `cat /proc/sys/fs/file-max` 察看，一般来说这个数目和系统内存关系很大。
     - `select` 的最大缺点就是，进程打开的 fd 是有数量限制的，这对于连接数量比较大的服务器来说，根本不能满足。虽然也可以选择多进程的解决方案(Apache就是这样实现的)，不过虽然 linux 上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。
  2. **I/O 效率不会随着监视 fd 的数量的增长而下降**：`epoll` 不同于 `select` 和 `poll` 轮询的方式，而是通过每个 fd 定义的回调函数来实现的，只有就绪的 fd 才会执行回调函数。

=> 如果没有大量的 idle -connection 或者 dead-connection，`epoll` 的效率并不会比 `select` / `poll` 高很多，但是当遇到大量的 idle- connection，就会发现 `epoll` 的效率大大高于 `select` / `poll`。

### 1.9. Java 复制？

#### 1）直接赋值

直接赋值， 比如在 Java 中，`A a1 = a2`，实际上复制的是引用，也就是说 `a1` 和 `a2` 指向的是同一个对象，因此，当 `a1` 变化时，`a2` 里面的成员变量也会跟着变化。

#### 2）浅复制

浅复制，指创建一个新对象时，把对象的非静态字段复制到新对象上，如果字段是值类型，则会对该字段执行复制，如果字段是引用类型，则只会复制引用不复制引用的对象，因此，原始对象及其复制后的副本，它们的引用类型属性引用属于同一个对象。

=> 通过复制引用的方式，来完成对象引用类型属性值的复制，叫做浅复制。

- **实现方式**：实现 `Cloneable` 接口，然后调用 `Object#clone()`。

  ```java
  @Test
  public void testBook() {
      Chapter chapter1 = new Chapter("第一章", 2500, 15);
      Chapter chapter2 = new Chapter("第二章", 2600, 16);
      Book book = new Book(1l, "三国演义", "罗贯中", Lists.newArrayList(chapter1, chapter2));
      
      Book cloneBook = (Book) book.clone();
      
      // false
      System.out.println(book == cloneBook);  
      // true
      System.out.println(book.getChapterList() == cloneBook.getChapterList()); 
   
      //给book对象的chapterList加一个元素，可以看到cloneBook的chapter也变化了
      book.getChapterList().add(new Chapter("第三章", 2500, 15));
      System.out.println(cloneBook.getChapterList().size()); //3
  }
  ```

#### 3）深复制

深拷贝，指不仅复制对象本身，还复制其引用类型属性所指向的对象。

- **实现方式**： 实现 `Serializable` 接口，把对象写到一个流里，再从流里读出来，可以重建对象。

  ```java
  @Test
  public void testDeepClone() throws Exception{
      Chapter chapter1 = new Chapter("第一章", 2500, 15);
      Chapter chapter2 = new Chapter("第二章", 2600, 16);
      Book book = new Book(1l, "三国演义", "罗贯中", Lists.newArrayList(chapter1, chapter2));
      
      //将对象转换为字节流写入流中
      ByteArrayOutputStream baos = new ByteArrayOutputStream();
      ObjectOutputStream oos = new ObjectOutputStream(baos);
      oos.writeObject(book);
   
      //从流里读出来
      ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
      ObjectInputStream ois = new ObjectInputStream(bais);
      Book cloneBook = (Book) ois.readObject();
      
      //关闭流
      baos.close();
      oos.close();
      bais.close();
      ois.close();
   
      /**
       * 此处如果没有实现Serializable接口，就会报错java.io.NotSerializableException
       * Library持有任何对象的类型都要实现Serializable接口，否则会报错
       */
      // false
      System.out.println(book == cloneBook);
      // false
      System.out.println(book.getChapterList() == cloneBook.getChapterList());
  }
  ```

### 2.0. Java 序列化？

- **序列化**：

  - 指将 Java 对象转化为字节序列的过程，即将对象的状态转化成字节流，然后可以通过这些值再生成相同状态的对象。
  - 对象序列化，是对象**持久化**的一种实现方法，是将对象的属性和方法转化为一种序列化的形式，用于存储和传输。

- **反序列化**：指将字节序列转化为 Java 对象的过程，即将对象字节序列重建对象的过程。

- **优点**：

  - 实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上，通常是放在文件里，比如 Redis 的RDB。
  - 利用序列化实现远程通信，即在网络上传送对象的字节序列，比如 Google 的 ProtoBuf。

- **反序列失败场景**：

  - 如果 `serialVersionUID` 不一致，会导致反序列化失败。
  - **`serialVersionUID` 作用**：
    1. 如果用户没有自己声明一个 `serialVersionUID`，接口会默认生成一个 `serialVersionUID`。
    2. 但是，强烈建议用户自定义一个 `serialVersionUID`，因为默认的 `serialVersinUID` 对于 class 的细节非常敏感，反序列化时可能会导致 `InvalidClassException` 异常。
    3. 比如说先进行序列化，然后在反序列化之前修改了类，那么就会报错，因为修改了类，对应的`serialversionUID` 也变化了，而序列化和反序列化就是通过对比其 `serialversionUID` 来进行的，一旦 `serialversionUID` 不匹配，反序列化就无法成功。

  ```java
  private static final Long serialVersionUID = 1573531233370L;
  ```

- **transient  关键字**：可以阻止所修饰的变量被序列化到文件中。 
  1. 在变量前加上 `transient`  关键字，可以阻止该变量被序列化到文件中，在被反序列
     化后，`transient` 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 
  2. 服务器端给客户端发送序列化对象数据，对象中有一些数据是敏感的，比如密码字符串
     等，希望对该密码字段在序列化时，进行加密，而客户端如果拥有解密的密钥，只有在
     客户端进行反序列化时，才可以对密码进行读取，这样可以一定程度保证序列化对象的
     数据安全。

### 2.1. 什么是 Java I/O？

- Java#I/O，是以流为基础进行数据输入输出的，所有数据被串行化出写入输出流，所谓串行化，就是数据按顺序进行输入输，简单来说就是 Java 通过 IO 流的方式和外部设备进行交互。

- 在 Java 类库中，IO 部分的内容是很庞大的，因为它涉及的领域很广泛：标准输入输出、文件的操作、网络数据传输流、字符串流、对象流等等。
- 比如程序从服务器上下载图片，就是通过流的方式，从网络上以流的方式加载到程序中，最后保存到硬盘中。

### 2.2. Java I/O 流分类？

![1646819558347](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646819558347.png)

#### 1）按照实际IO操作来分

1. **输入流**：从文件读入到内存，只能进行读操作。
2. **输出流**：从内存读出到文件，只能进行写操作。

=> **注意**：输出流可以帮助我们创建文件，而输入流不会。

#### 2）按照读写的单位大小来分

1. **字节流**：以字节为单位，每次次读入或读出是 8 位数据（一个字节占 8 bit），可以读任何类型数据，比如图片、文件、音乐视频等，在 Java 代码中，接收数据只能为 `byte[]` 。
2. **字符流**：以字符为单位，每次次读入或读出是 16 位数据（char 占两个字节），其只能读取字符类型数据，在 Java 代码中，接收数据为一般为 `char[]`。

#### 3）按照读写时是否直接与硬盘、内存等节点连接来分

1. **节点流**：直接与数据源相连，可读入或读出。
2. **处理流**：也叫**包装流**，是对一个对于已存在的流连接进行包装，通过所封装流的功能调用，以实现数据读写，比如添加个 Buffered 缓冲区的 `BufferedInputStream`。

=> **注意**：为什么要有处理流？主要作用是在读入或写出时，对数据进行缓存，以减少 I/O 次数，以便下次更好更快地读写文件，所以有了处理流。

### 2.3. Java I/O 常用实现类？

![1646820304336](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646820304336.png)

#### 1）FileReader | 字符节点输入流

```java
public class FileReaderTest {

    public static void main(String[] args) {
        FileReaderTest fileReaderTest = new FileReaderTest();
        fileReaderTest.printStr(Constant.FILE_READ_PATH);
    }

    public void printStr(String path) {
        // 读取文件
        FileReader fileReader = null;
        try {
            fileReader = new FileReader(path);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 读取文件内容
        int res = -1;
        List<Character> characterList = new ArrayList<>();
        while (true) {
            try {
                res = fileReader.read();
                if(res == -1) {
                    break;
                }
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }

            characterList.add((char) res);
        }

        // 打印文件内容
        StringBuilder sb = new StringBuilder();
        for (Character character : characterList) {
            if(character != '\r' && character != '\n') {
                sb.append(character);
            }
            if(character == '\n') {
                // HelloWorld!
                // Nice!
                // 哈喽!
                System.err.println(sb.toString());
                sb = new StringBuilder();
            }
        }

        // 关闭流
        try {
            fileReader.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

#### 2）BufferedReader | 字符处理输入流

```java
public class BufferedReaderTest {

    public static void main(String[] args) {
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_READ_PATH);
    }

    public void printStr(String path) {
        // 读取文件
        FileReader fileReader = null;
        try {
            fileReader = new FileReader(path);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedReader bufferedReader = new BufferedReader(fileReader);

        // 读取文件内容
        String str = null;
        List<String> stringList = new ArrayList<>();
        while (true) {
            try {
                str = bufferedReader.readLine();
                if(str == null) {
                    break;
                }
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }

            stringList.add(str);
        }

        // 打印文件内容
        // [HelloWorld!, Nice!, 哈喽!]
        System.err.println(stringList);

        // 关闭流
        try {
            bufferedReader.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                fileReader.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
```

#### 3）FileWriter | 字符节点输出流

```java
public class FileWriterTest {

    public static void main(String[] args) {
        // 读取文件
        FileWriter fileWriter = null;

        try {
            // 文件不存在时则创建, true代表追加式写入
            fileWriter = new FileWriter(Constant.FILE_WRITE_PATH, true);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        }

        // 写入内容到文件
        try {
            fileWriter.write("哈喽Write!\r\n");
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 关闭流
        try {
            fileWriter.close();
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 读取并打印文件内容: [哈喽Write!, 哈喽Write!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}
```

#### 4）BufferedWriter | 字符处理输出流

```java
public class BufferedWriterTest {

    public static void main(String[] args) {
        // 读取文件
        FileWriter fileWriter = null;

        try {
            // 文件不存在时则创建, true代表追加式写入
            fileWriter = new FileWriter(Constant.FILE_WRITE_PATH, true);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedWriter bufferedWriter = new BufferedWriter(fileWriter);

        // 写入内容到文件
        try {
            bufferedWriter.write("哈喽BufferdWrite!\r\n");
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 关闭流
        try {
            bufferedWriter.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                fileWriter.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        // 读取并打印文件内容: [哈喽BufferdWrite!, 哈喽BufferdWrite!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}
```

#### 5）FileInputStream、FileOutputStream | 字节节点输入输出流

```java
public class FileInputOutTest {

    public static void main(String[] args) {
        // 读取文件
        FileInputStream fileInputStream = null;
        FileOutputStream fileOutputStream = null;
        try {
            fileInputStream = new FileInputStream(Constant.FILE_READ_PATH);

            // 文件不存在时则创建, true代表追加式写入
            fileOutputStream = new FileOutputStream(Constant.FILE_WRITE_PATH, true);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        try {
            // 读取可用空间
            byte[] bytes = new byte[fileInputStream.available()];

            // 读取流内容到bytes数组中
            fileInputStream.read(bytes);

            // 输出bytes数组到另一个文件中
            fileOutputStream.write(bytes);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        } finally {
            try {
                fileOutputStream.close();
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    fileInputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }

        // 打印并读取输入后的文件结果: [哈喽BufferdWrite!, 哈喽BufferdWrite!, HelloWorld!, Nice!, 哈喽!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}
```

#### 6）BufferedInputStream、BufferedOutputStream | 字节处理输入输出流

```java
public class FileBufferdInputOutTest {

    public static void main(String[] args) {
        // 读取文件
        FileInputStream fileInputStream = null;
        FileOutputStream fileOutputStream = null;
        try {
            fileInputStream = new FileInputStream(Constant.FILE_READ_PATH);

            // 文件不存在时则创建, true代表追加式写入
            fileOutputStream = new FileOutputStream(Constant.FILE_WRITE_PATH, true);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream);
        BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(fileOutputStream);

        while (true) {
            try {
                int read = bufferedInputStream.read();
                if(read == -1) {
                    break;
                }

                bufferedOutputStream.write(read);
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }
        }

        try {
            bufferedOutputStream.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                bufferedInputStream.close();
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    fileOutputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                } finally {
                    try {
                        fileInputStream.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            }
        }

        // 打印并读取输入后的文件结果: [哈喽BufferdWrite!, 哈喽BufferdWrite!, HelloWorld!, Nice!, 哈喽!, HelloWorld!, Nice!, 哈喽!, HelloWorld!, Nice!, 哈喽!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}
```

### 2.4. TCP Socket API？

![1646914477436](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646914477436.png)

#### 1）服务端 - API

1. new Socket（..）：构造 Socket 对象，在 Java 中，为 `new ServerSocket() `。
2. bind（..）：绑定端口。
3. listen（）：监听端口，在 Java 中，该方法已经与 `bind（..）` 方法融为一体了。
4. accept（）：TCP 三次握手成功，则唤醒当前阻塞的线程，在 Java 中，返回一个 `Socket` 对象。
5. read（） / write（）：在 Java 中，是通过使用 `Socket` 的输入输出流来实现读取和写出。
6. close（）：关闭套接字文件描述符。

#### 2）客户端 - API

1. new Socket（..）：构造 Socket 对象，在 Java 中，为 `new Socket() ` 。
2. connect（）：连接目标服务端口，在 Java 中，该方法已经与`new Socket() ` 方法融为一体了。
3. read（） / write（）：在 Java 中，是通过使用 `Socket` 的输入输出流来实现读取和写出。
4. close（）：关闭套接字文件描述符。



### 2.5. Java BIO、NIO、AIO？

#### 1）BIO

BIO，**同步阻塞 I/O**：

1. 服务器实现一个连接一个线程，即客户端有连接请求时，服务器端就需要启动一个线程进行处理，没处理完之前，此线程不能做其他操作。
2. 如果是单线程的情况下，传输的文件很大，可以通过线程池机制改善。

=> 因此，BIO 适用于连接数目比较小、且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，是 JDK 1.4 以前的唯一选择，同时程序也直观简单、易于理解。

##### BIO Server

```java
public class BioServerTest {

    private static final AtomicInteger COUNT = new AtomicInteger(0);

    public static void start(int port) throws IOException {
        // socket
        ServerSocket server = new ServerSocket();
        // bind & listen
        server.bind(new InetSocketAddress(port));
        System.err.println("bind & listen!");

        while (true) {
            // accept
            final Socket socket = server.accept();// block!
            int count = COUNT.incrementAndGet();
            System.err.println("accept! ip=" + socket.getRemoteSocketAddress() + ", count=" + count);

            // or user thread pool
            new Thread(() -> {
                try {
                    BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                    PrintWriter out = new PrintWriter(socket.getOutputStream(), true);
                    String line = in.readLine();

                    while (line != null) {
                        System.err.println("read: " + line);
                        out.println(line);
                        out.flush();
                        line = in.readLine();
                    }
                    socket.close();
                } catch (IOException e) {
                    e.printStackTrace();
                    try {
                        socket.close();
                    } catch (IOException ee) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

    }

    public static void main(String[] args) throws IOException {
        start(8084);
    }
}
```

##### BIO Client

```java
public class BioClientTest implements Cloneable {

    public static final String[] commands = new String[]{
            "hi\n",
            "i am client\n",
            "helloworld\n",
            "java and netty\n"
    };

    public static void main(String[] args) throws IOException {
        BioClientTest bioClientTest = new BioClientTest();
        try {
            Object clone = bioClientTest.clone();
        } catch (CloneNotSupportedException e) {
            e.printStackTrace();
        }

        int concurrent = 100;
        Runnable task = () -> {
            try {
                Socket socket = new Socket("127.0.0.1", 8084);
                DataOutputStream out = new DataOutputStream(socket.getOutputStream());
                for (String str : commands) {
                    out.write(str.getBytes());
                }
                out.flush();

                Thread.sleep(100);
                BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                while (br.ready()) {
                    Thread.sleep(100);
                    System.out.println(br.readLine());
                }

                socket.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        };

        ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 2, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(1024));
        for (int i = 0; i < concurrent; i++) {
            executor.execute(task);
        }
        executor.shutdown();
    }
}
```

#### 2）NIO

NIO，**同步非阻塞 I/O**：

1. 服务器实现一个连接一个线程，即客户端发送的连接请求都会注册到多路复用器上。
2. 多路复用器轮询到连接有 I/O 请求时，才会启动一个线程进行处理。

=> 因此，NIO 方式适用于连接数目多、且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，在 JDK 1.4 之后开始支持。

##### NIO Server

Selector 可以处理 4 个事件：

1. **OP_READ = 1**：读取事件。
2. **OP_WRITE = 4**：写出事件。
3. **OP_CONNECT = 8**：通道已连接事件。
4. **OP_ACCEPT = 16**：服务端套接字已准备就绪事件。

```java
public class NioServerTest {

    public static void start(int port) throws IOException {
        // non blocking
        ServerSocketChannel serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);

        // bind & listen
        InetSocketAddress address = new InetSocketAddress(port);
        serverChannel.bind(address);
        System.err.println("bind & listen");

        Selector selector = Selector.open();
        serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        System.err.println("注册事件: OP_ACCEPT");

        while (true) {
            // epoll: blocking
            selector.select();

            // OP_ACCEPT | OP_READ
            Set<SelectionKey> readyKeys = selector.selectedKeys();
            Iterator<SelectionKey> it = readyKeys.iterator();
            while (it.hasNext()) {
                SelectionKey key = it.next();

                // OP_ACCEPT: 三次握手成功, 注册读事件
                if (key.isAcceptable()) {
                    ServerSocketChannel server = (ServerSocketChannel) key.channel();
                    SocketChannel socket = server.accept();
                    System.err.println("Accept !");

                    socket.configureBlocking(false);
                    socket.register(selector, SelectionKey.OP_READ);
                    System.err.println("注册事件: OP_READ");
                } else if (key.isReadable()) {
                    SocketChannel socket = (SocketChannel) key.channel();
                    final ByteBuffer buffer = ByteBuffer.allocate(64);
                    final int bytesRead = socket.read(buffer);
                    if (bytesRead > 0) {
                        System.err.println("read: " + new String(buffer.array()).trim());
                        buffer.flip();
                        int ret = socket.write(buffer);
                        // 尝试写, 没写完则要注册写事件
//                         if (ret <=0) {
//                        	 //register op_write
//                         }
                        buffer.clear();
                    } else if (bytesRead < 0) {
                        key.cancel();
                        socket.close();
                        System.err.println("Client close");
                    }
                }

                // 从readyKeys中移除, 免得下次重新执行
                it.remove();
            }
        }
    }


    public static void main(String[] args) throws InterruptedException, IOException {
        start(8084);
    }
}	
```

#### 3）AIO

AIO，**异步非阻塞 I/O**：

1. 服务器实现模式为一个有效请求一个线程。
2. 客户端的 I/O 请求都是由操作系统先完成了，再通过回调，通知客户端应用去启动线程进行处理。

=> AIO 方式适用于连接数目多、且连接比较长（重操作）的架构，比如相册服务器，可以充分调用操作系统参与并发操作，编程比较复杂，在 JDK 1.7 之后开始支持。

- AIO 属于 NIO 包中的类实现，其实 I/O 主要分为 BIO和 NIO，AIO 只是附加品，主要是为了解决 I/O 不能异步实现的问题。
- 在以前很少有 Linux 系统支持 AIO，Windows 的 IOCP 就是此 AIO 模型，但是现在的服务器一般都是支持AIO 操作。

#### 4）总结

1. BIO 是阻塞的，NIO 是非阻塞的。
2. BIO 是面向流的，只能单向读写，NIO 是面向缓冲的, 可以双向读写。
   - 使用 BIO 做 Socket 连接时，由于单向读写，当没有数据时，会挂起当前线程，阻塞等待，为防止影响其它连接,需要为每个连接新建线程处理，然而系统资源是有限的，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗，因此需要使用 NIO 进行 BIO 多路复用，使用一个线程来监听所有 Socket连接，使用本线程或者其他线程处理连接。
3. AIO 以非阻塞的异步方式发起 I/O 操作，当 I/O 操作进行后，自己可以去做其他操作，由操作系统内核空间提醒 I/O 操作已完成。

### 2.6. Java IO 设计模式？

在高性能 I/O 设计中，有两个比较著名的模式，Reactor 和 Proactor 模式，其中 Reactor 模式用于同步 I/O，而 Proactor 运用于异步 I/O 操作。

#### Reactor 模式

Reactor 模式，应用于同步 I/O 场景，以 read 操作为例，Reactor 中的具体步骤为：

1. 应用程序注册 `读就绪` 事件和相关联的事件处理器。
2. 事件分离器等待事件的发生。
3. 当发生 `读就绪` 事件时，事件分离器调用第一步注册的事件处理器
4. 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理。

![1646831826891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831826891.png)

##### 1）单 Reactor 单线程模式

###### Reactor NIO 原型实现

1. 在 NIO Server 的基础上，抽取了一个 `ChannelHandler`，用于处理连接和读取事件。
2. 以及分离了连接和读取事件所实现的位置，分别丢给 `Accept ChannelHandler` 和 `Read ChannelHandler`  来处理，以实现业务解耦。
3. 这就是 Reactor 的思路原型，其中还有很多地方可以继续抽象优化的~

```java
public class BaseReactorServer {

    interface ChannelHandler {
        void onRead(SocketChannel channel) throws Exception;
        void onAccept();
    }

    public static void start(int port) throws Exception {
        // non blocking
        final ServerSocketChannel serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);

        //bind & listen
        InetSocketAddress address = new InetSocketAddress(port);
        serverChannel.bind(address);

        final Selector selector = Selector.open();
        SelectionKey selectionKey = serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        System.err.println("注册事件: OP_ACCEPT");

        // Acceptor: 绑定OP_ACCEPT
        selectionKey.attach(new ChannelHandler() {
            public void onRead(SocketChannel channel) {

            }

            // ChannelHandler: 绑定OP_READ
            public void onAccept() {
                try {
                    SocketChannel socket = serverChannel.accept();
                    System.out.println("Accept !");
                    socket.configureBlocking(false);
                    SelectionKey sk = socket.register(selector, SelectionKey.OP_READ);

                    // 绑定
                    sk.attach(new ChannelHandler() {
                        public void onRead(SocketChannel socket) throws IOException {
                            final ByteBuffer buffer = ByteBuffer.allocate(256);
                            final int bytesRead = socket.read(buffer);

                            // Worker
                            if (bytesRead > 0) {
                                // 读
                                String readRes = new String(buffer.array()).trim();
                                System.err.println("read: " + readRes);

                                // 模拟业务执行过久
                                doBusiness(500, readRes);

                                // 写
                                buffer.flip();
                                socket.write(buffer);
                                buffer.clear();
                            } else if (bytesRead < 0) {
                                socket.close();
                                System.out.println("Client close");
                            }
                        }

                        public void onAccept() {

                        }

                        // 模拟业务执行过久
                        private void doBusiness(long time, String readRes) {
                            System.err.println("测试业务处理: time=" + time);
                            try {
                                Thread.sleep(time);
                            } catch (InterruptedException e) {
                                e.printStackTrace();
                            }
                        }
                    });
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        });

        while (true) {
            selector.select();
            Set<SelectionKey> readyKeys = selector.selectedKeys();
            Iterator<SelectionKey> it = readyKeys.iterator();
            while (it.hasNext()) {
                SelectionKey key = it.next();
                ChannelHandler handler = (ChannelHandler) key.attachment();
                System.err.println(String.format("handler: %s", handler));

                // OP_ACCEPT
                if (key.isAcceptable()) {
                    handler.onAccept();
                }
                // OP_READ
                else if (key.isReadable()) {
                    handler.onRead((SocketChannel) key.channel());
                }

                // 从readyKeys中移除, 免得下次重新执行
                it.remove();
            }
        }

    }

    public static void main(String[] args) throws Exception {
        start(8084);
    }
}
```

###### Reactor 架构图实现

Reactor 又称之为响应器模式，常用于 NIO 网络通信框架，其单线程服务架构图如下，不同于传统 I/O 的串行调度方式，NIO 把整个服务请求分为五个阶段：

1. **read**：接收到请求，读取数据。
2. **decode**：解码数据。
3. **compute**：业务逻辑处理。
4. **encode**：编码返回数据。
5. **send**：返回数据。

![1646831937063](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831937063.png)

1. `selector.select()` 是前面 NIO#API （多路复用模型），可以实现一个阻塞对象监听多路的连接请求。
2. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后通过 `dispatch()` 进行分发。
3. 如果是建立连接请求事件，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理连接完成后的后续业务处理。
4. 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应。
5. `Handler` 会完成 `read()` -> `doBusiness()` 业务处理 -> `send()` 一个完整的业务流程。

- **优点**：服务器使用一个线程，通过多路复用搞定所有 I/O 操作（包括连接、读、写等），编码简单，清晰明了，但如果客户端连接数量较多，将无法支撑。
- **缺点**：
  1. **性能问题**：只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上业务时，整个进程无法处理其它连接事件，容易导致性能瓶颈。
  2. **可靠性问题**：线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

```java
/**
 * 1、单Reactor单线程
 */
public class AaReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public AaReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.selector, this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("Waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            AaReactorServer aaReactorServer = new AaReactorServer(8084);
            aaReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public Acceptor(Selector selector, ServerSocketChannel serverSocketChannel) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // ChannelHandler: 绑定OP_READ
            SelectionKey selectionKey = socketChannel.register(this.selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 唤醒一个阻塞的selector
            this.selector.wakeup();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    int state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = 0;
    }

    @Override
    public void run() {
        try {
            // 读取
            if(this.state == 0) {
                read();
            }
            // 返回
            else {
                send();
            }
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    private synchronized void read() throws IOException {
        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = this.socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            // 执行业务处理
            doBusiness(str);
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 读取 -> 返回
            this.state = 1;
            this.selectionKey.interestOps(SelectionKey.OP_WRITE);

            // 唤醒一个阻塞的selector
            selectionKey.selector().wakeup();
        }
    }

    private void doBusiness(String str) {
        System.err.println("执行业务处理...");
    }

    private void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private void send() throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        this.state = 0;
        this.selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}
```

##### 2）单 Reactor 多线程模式

![1646889343446](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889343446.png)

1. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后，通过 `dispatch()` 进行分发。
2. 如果是建立连接请求，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理完成连接后的各种事件。
3. 如果不是连接请求，则由 `Reactor` 对象分发调用连接对应的 `Handler` 来处理。
4. 此时，`Handler` 只负责读取和响应事件，不做具体的业务处理，通过 `read()` 读取数据后，会分发给后面的 `Worker` 线程池的某个线程进行处理业务。
5. `Worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `Handler`。
6. `Handler` 收到线程池处理完的结果后，通过 `send()` 将结果返回给 Client。

- **优点**：可以充分利用多核 CPU 的处理能力。
- **缺点**：
  1. 多线程在需要数据共享时，可能实现比较复杂。
  2. Reactor 单线程处理完所有的监听、连接、读、写事件，在高并发场景下，容易出现性能瓶颈。

```java
/**
 * 1、单Reactor多线程
 */
public class AbReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public AbReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.selector, this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("Waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            AbReactorServer abReactorServer = new AbReactorServer(8084);
            abReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public Acceptor(Selector selector, ServerSocketChannel serverSocketChannel) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // ChannelHandler: 绑定OP_READ
            SelectionKey selectionKey = socketChannel.register(this.selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 唤醒一个阻塞的selector
            this.selector.wakeup();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private static final int DEFAULT_THREAD_COUNT = 4;
    private static final int MAX_THREAD_COUNT = 8;
    private static final ThreadPoolExecutor POOL = new ThreadPoolExecutor(
            DEFAULT_THREAD_COUNT,
            MAX_THREAD_COUNT,
            10,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1024)
    );

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    private HandlerState state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = new ReadState();
    }

    @Override
    public void run() {
        try {
            state.handle(this, this.selectionKey, this.socketChannel, POOL);
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    public void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void setState(HandlerState state) {
        this.state = state;
    }
}

/**
 * 4、状态
 */
public interface HandlerState {

    /**
     * 状态处理事件
     *
     * @param handler
     * @param selectionKey
     * @param socketChannel
     * @param pool
     */
    void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException;
}

/**
 * 5、读取状态
 */
public class ReadState implements HandlerState {

    private SelectionKey selectionKey;

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        this.selectionKey = selectionKey;

        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            handler.closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 开始处理业务
            handler.setState(new WorkState(str, handler, selectionKey, socketChannel, pool));
        }
    }
}

/**
 * 6、工作状态
 */
public class WorkState implements HandlerState {

    private String readResult;
    private SelectionKey selectionKey;

    public WorkState(String readResult, ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) {
        this.readResult = readResult;
        this.selectionKey = selectionKey;

        try {
            this.handle(handler, selectionKey, socketChannel, pool);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        pool.execute(new WorkerThread(handler, this.readResult));
    }

    private synchronized void change2WriteState(ChannelHandler handler, String str) {
        // 读取 -> 返回
        handler.setState(new WriteState());
        this.selectionKey.interestOps(SelectionKey.OP_WRITE);

        // 唤醒一个阻塞的selector
        this.selectionKey.selector().wakeup();
    }

    class WorkerThread implements Runnable {

        private ChannelHandler handler;
        private String str;

        public WorkerThread(ChannelHandler handler, String str) {
            this.handler = handler;
            this.str = str;
        }

        @Override
        public void run() {
            // 执行业务处理
            doBusiness(str);
            change2WriteState(this.handler, this.str);
        }

        private void doBusiness(String str) {
            System.err.println("执行业务处理...");
        }
    }
}

/**
 * 7、返回状态
 */
public class WriteState implements HandlerState {

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        handler.setState(new ReadState());
        selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}
```

##### 3）主从 Reactor 多线程模式

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

```java
/**
 * 1、主从Reactor
 */
public class BbReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public BbReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT, 主selector用于处理连接
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("MainReactor waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            BbReactorServer bbReactorServer = new BbReactorServer(8084);
            bbReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private static final int CORES = Runtime.getRuntime().availableProcessors();
    private final ServerSocketChannel serverSocketChannel;
    private final Selector[] selectors = new Selector[CORES];
    private int selIndex = 0;
    private SubReactor[] subReactors = new SubReactor[CORES];
    private Thread[] threads = new Thread[CORES];

    public Acceptor(ServerSocketChannel serverSocketChannel) throws IOException {
        this.serverSocketChannel = serverSocketChannel;

        // 创建多个selector, 以及多个SubReactor线程
        for (int i = 0; i < CORES; i++) {
            this.selectors[i] = Selector.open();
            this.subReactors[i] = new SubReactor(this.selectors[i], serverSocketChannel, i);
            this.threads[i] = new Thread(this.subReactors[i]);
            this.threads[i].start();
        }
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = this.serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // 暂停SubReactor线程, 停止轮训
            SubReactor subReactor = this.subReactors[this.selIndex];
            Selector selector = this.selectors[this.selIndex];
            Thread thread = this.threads[this.selIndex];
            subReactor.setRestart(true);

            // 唤醒一个阻塞的selector
            selector.wakeup();

            // ChannelHandler: 绑定OP_READ, 从selector用于处理读取、返回
            SelectionKey selectionKey = socketChannel.register(selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 重启SubReactor线程, 只有为false才会继续轮训
            subReactor.setRestart(false);
            LockSupport.unpark(thread);

            // 轮训重置selIndex
            if(++this.selIndex == this.selectors.length) {
                this.selIndex = 0;
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、子Reactor
 */
public class SubReactor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;
    private volatile boolean restart = false;
    private int num;

    public SubReactor(Selector selector, ServerSocketChannel serverSocketChannel, int num) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
        this.num = num;
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            if(this.restart) {
                LockSupport.park();
            }

            System.out.println("SubReactor"+ this.num + " waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    // 重启SubReactor线程, 只有为false才会继续轮训
    public void setRestart(boolean restart) {
        this.restart = restart;
    }
}

/**
 * 4、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private static final int DEFAULT_THREAD_COUNT = 4;
    private static final int MAX_THREAD_COUNT = 8;
    private static final ThreadPoolExecutor POOL = new ThreadPoolExecutor(
            DEFAULT_THREAD_COUNT,
            MAX_THREAD_COUNT,
            10,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1024)
    );

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    private HandlerState state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = new ReadState();
    }

    @Override
    public void run() {
        try {
            state.handle(this, this.selectionKey, this.socketChannel, POOL);
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    public void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void setState(HandlerState state) {
        this.state = state;
    }
}

/**
 * 5、状态
 */
public interface HandlerState {

    /**
     * 状态处理事件
     *
     * @param handler
     * @param selectionKey
     * @param socketChannel
     * @param pool
     */
    void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException;
}

/**
 * 6、读取状态
 */
public class ReadState implements HandlerState {

    private SelectionKey selectionKey;

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        this.selectionKey = selectionKey;

        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            handler.closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 开始处理业务
            handler.setState(new WorkState(str, handler, selectionKey, socketChannel, pool));
        }
    }
}

/**
 * 7、工作状态
 */
public class WorkState implements HandlerState {

    private String readResult;
    private SelectionKey selectionKey;

    public WorkState(String readResult, ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) {
        this.readResult = readResult;
        this.selectionKey = selectionKey;

        try {
            this.handle(handler, selectionKey, socketChannel, pool);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        pool.execute(new WorkerThread(handler, this.readResult));
    }

    private synchronized void change2WriteState(ChannelHandler handler, String str) {
        // 读取 -> 返回
        handler.setState(new WriteState());
        this.selectionKey.interestOps(SelectionKey.OP_WRITE);

        // 唤醒一个阻塞的selector
        this.selectionKey.selector().wakeup();
    }

    // 工作线程用于处理业务逻辑
    class WorkerThread implements Runnable {

        private ChannelHandler handler;
        private String str;

        public WorkerThread(ChannelHandler handler, String str) {
            this.handler = handler;
            this.str = str;
        }

        @Override
        public void run() {
            // 执行业务处理
            doBusiness(str);
            change2WriteState(this.handler, this.str);
        }

        private void doBusiness(String str) {
            System.err.println("执行业务处理...");
        }
    }
}

/**
 * 8、返回状态
 */
public class WriteState implements HandlerState {

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        handler.setState(new ReadState());
        selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}
```

##### Reactor 模式总结

| Reactor 线程模型    | 比喻                                           |
| ------------------- | ---------------------------------------------- |
| 单 Reactor 单线程   | 前台接待员和服务员都是同一个人，全程为顾客服务 |
| 单 Reactor 多线程   | 1 个前台接待员，多个服务员，接待员只负责接待   |
| 主从 Reactor 多线程 | 多个前台接待员，多个服务生                     |

**Reactor 优点**：

1. 响应快，不必被单个同步时间所阻塞，虽然 Reactor 本身依然是同步的。
2. 可以最大程度地避免复杂了多线程及同步问题，并且避免了多线程 / 进程切换的开销。
3. 扩展性好，可以方便的通过增加 Reactor 实例个数，来充分利用 CPU 资源。
4. 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

#### Proactor 模式

Proactor 模式 read 操作过程为：

1. 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注 `读取就绪` 事件，而是关注 `读完成` 事件，这是区别于 Reactor 的关键。
2. 事件分离器等待 `读完成` 事件。
3. 在事件分离器等待 `读完成` 时，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中，这也是区别于 Reactor的一点，Proactor 中，应用程序**需传递缓存区**。
4. 事件分离器捕获到 `读完成` 事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
5. 而 Proactor 中的 write 操作和 read 操作类似，即感兴趣的事件是 `写完成` 事件。

![1646831843451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831843451.png)

=> 从上面可以看出，Reactor 和 Proactor 模式的主要区别就是，真正的读取和写入操作是由谁来完成的，Reactor 中需要应用程序自己读取或者写入数据，而 Proactor 模式中，应用程序不需要进行实际的读写过程，只需要从缓存区读取或者写入即可，操作系统会写入缓存区或者从缓存区读取并写入到真正的 I/O 设备中。

### 2.7. 什么是 Netty？

- **概念**：Netty 是一个 基于 JAVA NIO 实现的高性能、异步事件驱动的 NIO 框架。
- **原理**：它提供了对TCP、UDP 和文件传输的支持，作为一个异步实现的 NIO 框架，Netty 的所有 I/O 操作都是异步非阻塞的，通过 `Future-Listener` 机制，用户可以方便地主动获取，或者通过通知机制获得 I/O 操作结果。 
- **高性能原理**：
  1. **I/O 多路复用**：见 I/O 多路复用模型。
  2. **Reactor 线程模型**：见主从 Reactor 模型。
  3. **零拷贝机制**：
     1. Netty 接收和发送的 ByteBuffer，底层采用`DirectBuffers` 使用堆外内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。
     2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行Socket读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
     3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
        方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
        Buffer。 
     4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
        避免了传统通过循环 `write()`方式导致的内存拷贝问题。
  4. **高性能的序列化框架**：Netty 默认提供了对 Google Protobuf 的支持，通过扩展 Netty 的编解码接口，用户可以自定义实现其它的高性能序列化框架，比如 Thrift 的压缩二进制编解码框架等。 

### 2.8. Netty 快速入门？

Netty 实现通信的步骤：（客户端与服务端基本一致）

1. 先创建 2 个 NIO 线程组，一个专门用于网络事件的处理（接受客户端的连接），另一个则进行网络通信读写。
2. 然后，创建一个 `ServerBootStrap` 对象，配置 Netty 的一些列参数，比如接受传出数据的缓存大小等等。
3. 接着，创建一个实际处理数据的 `ChannelInitializer` 类，进行初始化的准备工作，比如设置接受传出数据的字符集、格式、实际处理数据的 `ChannelHandler` 等。
4. 最后，绑定接口，执行同步阻塞方法，等待服务端启动即可。

#### 1、NettyServer

```java
/**
 * 1、NettyServer
 */
public class NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 指定连接超时时间
                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000)
                // 2.4. TCP不允许延迟, 通信不延迟
                .option(ChannelOption.TCP_NODELAY, true)
                // 2.5. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.6. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.6.1. 设置接收缓冲区自动扩容, 已弃用
//                .option(ChannelOption.RCVBUF_ALLOCATOR, AdaptiveRecvByteBufAllocator.DEFAULT)
                // 2.6.2. 设置发送缓冲区使用对象池, 重用缓冲区
//                .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT)
                // 2.7. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.7.1. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}
```

#### 2、NettyServerHandler

```java
/**
 * 2、NettyServerHandler
 */
public class NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 获取TCP包缓冲区数据
        ByteBuf byteBuf = (ByteBuf) msg;

        // 2. 根据缓冲数据大小构造字节数组
        byte[] bytes = new byte[byteBuf.readableBytes()];

        // 3. 读取到缓冲区数据到字节数组中
        byteBuf.readBytes(bytes);

        // 4. 使用UTF-8编码解码字节数组成字符串
        String body = new String(bytes, "utf-8");
        System.err.println("Netty server: " + body);

        // 5. 构造响应体给客户端 => 测试与客户端的交互
        String response = "Netty server ack: " + body;
        ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}
```

#### 3、NettyClient

```java
/**
 * 3、NettyClient
 */
public class NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 指定连接超时时间
                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000)
                // 2.4. TCP不允许延迟, 通信不延迟
                .option(ChannelOption.TCP_NODELAY, true)
                // 2.5. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.6. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.7. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.7.1. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("Hello netty!".getBytes()));

        // 5. 睡眠10秒钟后再发送一条数据到服务端
        Thread.sleep(10000);
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("Hello netty again!".getBytes()));

        // 6. 同步阻塞5s, 再关闭监听并释放资源
        cf.channel().closeFuture().await(5, TimeUnit.SECONDS);
        
        // 7. 释放资源
        workGroup.shutdownGracefully();
    }
}

```

#### 4、ClientHandler

```java
/**
 * 4、ClientHandler
 */
public class NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 获取TCP包缓冲区数据
            ByteBuf byteBuf = (ByteBuf) msg;

            // 2. 根据缓冲数据大小构造字节数组
            byte[] bytes = new byte[byteBuf.readableBytes()];

            // 3. 读取到缓冲区数据到字节数组中
            byteBuf.readBytes(bytes);

            // 4. 使用UTF-8编码解码字节数组成字符串
            String body = new String(bytes, "utf-8");

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client receive ack: " + body);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}
```

### 2.9. RPC、HTTP、MQ、Netty？

| 技术  | 应用场景                                          |
| ----- | ------------------------------------------------- |
| RPC   | 系统间即时访问、同步服务调用                      |
| HTTP  | 外部接口 API 提供、非高并发场景、非大数据报文传输 |
| MQ    | 微服务之间解耦、流量削峰                          |
| Netty | 底层基础通信、数据传输、数据同步                  |

### 3.0 Netty 核心组件？

#### 1）Channel

Channel，通道，连接是单向的，**通道双向的**，是Java NIO 的一个基本构造，可以看作是传入或传出数据的载体，它可以被打开或关闭，连接或者断开连接。以下是常用的 Channel 有 `EmbeddedChannel` 、`LocalServerChannel` 、`NioDatagramChannel` 、`NioSctpChannel` 、`NioSocketChannel`。

#### 2）Future 

1. Netty 中所有的 I/O 操作都是异步的，一个操作可能不会立即返回，可以在之后的某个时间点确定其结果的方法。
2. 和 `Handler` 回调 是相互补充的机制，提供了另一种在操作完成时通知应用程序的方式，可以看作是一个异步操作结果的占位符，将在未来的某个时刻完成，并提供对其结果的访问。
3. Netty 提供了 `ChannelFuture`，用于在执行异步操作的时候使用，每个 Netty 的 I/O 操作都会返回一个`ChannelFuture`。
4. `ChannelFuture` 能够注册一个或者多个 `ChannelFutureListener` 实例，监听器的回调方法`operationComplete()` 将会在对应的操作完成时被调用。

#### 3）ChannelHandler

1. Netty 的主要组件是 ChannelHandler，它负责所有处理出入站数据的逻辑处理。
2. Netty 使用不同的事件，来通知操作状态的改变，每个事件都可以被分发给 ChannelHandler 类中某个用户自定义实现的方法中。
3. Netty 还提供了大量预定义的、可以开箱即用的 ChannelHandler 实现，包括用于各种协议的ChannelHandler。

#### 4）ChannelPipeline

1. ChannelPipeline 提供了 ChannelHandler 链的容器，并定义了用于在该链上传播入站和出站事件流的 API，在应用程序的初始化、或者引导阶段被安装。
2. 这可以使事件流经 ChannelPipeline 时，让 ChannelHandler 进行相关工作，然后将数据传递给链中的下一个 ChannelHandler。

![1646917753469](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646917753469.png)

#### 5）EventLoop

1. EventLoop 定义了 Netty 的核心抽象，用来处理连接的生命周期中所发生的事件，在内部，将会为每个Channel 分配一个 EventLoop 。
2. EventLoop 本身只由一个线程驱动，其处理了一个 Channel 的所有 I/O 事件，并且在该 EventLoop 的整个生命周期内都不会改变。
3. EventLoop 的管理是通过 EventLoopGroup 来实现的。

![1646918023384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918023384.png)

#### 6）BootStarp、ServerBootstrap 

1. BootStarp 和 ServerBootstrap 被称为引导类，指对应用程序进行配置，并使他运行起来的过程。

2. BootStrap 是客户端的引导类，Bootstrap 在调用 `bind()`（连接UDP）和 `connect()`（连接TCP）方法时，会新创建一个 Channel，仅创建一个单独的、没有父 Channel 的 Channel 来实现所有的网络交换，只需要一个 EventLoopGroup。

   ![1646918238983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918238983.png)

3. ServerBootstrap 是服务端的引导类，ServerBootstarp 在调用 `bind()` 方法时，会创建一个 ServerChannel 来接受来自客户端的连接，并且该 ServerChannel 管理了多个子 Channel，用于同客户端之间的通信，通常需要两个 EventLoopGroup，一个用来接收客户端连接，一个用来处理 I/O 事件。

   ![1646918257373](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918257373.png)

#### 7）ByteBuffer

1. Netty 接收和发送的 ByteBuffer，底层采用`DirectBuffers` 使用堆外内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。
2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行Socket读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
   方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
   Buffer。 
4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
   避免了传统通过循环 `write()`方式导致的内存拷贝问题。
5.  

### 3.1. Netty 拆包粘包问题？

#### TCP 拆包粘包机制

1. 由于 TCP 是基于流的协议，本身没有界限，没有任何分界线，它不会理解上层数据包的含义。
2. 所以，一个上层的数据包可能会被拆成多个包，分批发送，这就是**拆包问题**。
3. 同理，多个上层小的数据包也能会被合成一个大包，一起发送，这就是**粘包问题**。

#### 问题产生原因

1. 应用程序写入的字节大小，大于套接字发送缓冲区的大小。
2. 进行 MSS 大小的 TCP 分段、以太网帧的 payload 大于 MTU 进行 IP 分片等。

#### 业务主流解决方案

1. **消息定长**：比如，每个报文大小固定为 200 个字节，如果不够，则用空格补位。
2. **在包尾添加特殊字符进行分割**：比如加回车符等。
3. **消息分为消息头 Header 和消息体 Body**：在消息头中包含表示消息总长度的字段，然后根据长度去读取消息体，再进行业务处理。
   - 用得最多，比如自定义协议栈。

##### 1）Netty 消息定长解决方案 | FixedLengthFrameDecoder

###### 1、NettyServer

```java
/**
 * 测试Netty: 服务端, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.4. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.5. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.5.1. 测试消息定长, 空格补位解决TCP拆包/粘包问题 => 定长5个字符
                        ch.pipeline().addLast(new FixedLengthFrameDecoder(5));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.5.3. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg1NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}
```

###### 2、NettyServerHandler

```java
/**
 * 测试Netty: 服务端业务处理器, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 使用了Netty String解码器后, 可以直接转换成String类型
        String body = (String) msg;
        System.err.println("Netty server: " + body);

        // 2. 构造响应体给客户端 => 测试与客户端的交互
        ctx.writeAndFlush(Unpooled.copiedBuffer(body.getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}
```

###### 3、NettyClient

```java
/**
 * 测试Netty: 客户端, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试消息定长, 空格补位解决TCP拆包/粘包问题 => 定长5个字符
                        ch.pipeline().addLast(new FixedLengthFrameDecoder(5));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.3.2. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg1NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端 => 5个a, 5个b
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("aaaaabbbbb".getBytes()));

        // 5. 睡眠10秒钟后再发送一条数据到服务端、
        System.err.println("睡10s...");
        Thread.sleep(10000);
//        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ccccccc   ".getBytes()));// => 7个c + 3个空格 => 后面2个c和3个空格可以发送
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ccccccc".getBytes()));// => 7个c + 没有空格补位 => 后面2个c不可以发送

        // 5.1. 再睡眠10秒钟后再发送一条数据到服务端
        System.err.println("再睡10s...");
        Thread.sleep(10000);
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ddd".getBytes()));// => 3个d, 凑够5个字符 => 之前残留的2个c在缓冲区中, 凑了3个d凑够5个字符后, 可以一起发送出去

        // 6. 阻塞的方式等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 7. 释放资源
        workGroup.shutdownGracefully();
    }
}
```

###### 4、ClientHandler

```java
/**
 * 测试Netty: 客户端业务处理器, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 使用了Netty String解码器后, 可以直接转换成String类型
            String response = (String) msg;

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client: " + response);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}
```

##### 2）Netty 特殊字符解决方案 | DelimiterBasedFrameDecoder

###### 1、NettyServer

```java
/**
 * 测试Netty: 服务端, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.4. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.5. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试特殊字符方式解决TCP拆包/粘包问题, 以"$_"结尾作为分割符(只要收到$_,就认为到这里就是一个数据包), 最大帧长1024bit
                        ByteBuf delimiterBuf = Unpooled.copiedBuffer("$_".getBytes());
                        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiterBuf));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.5.3. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg2NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}
```

###### 2、NettyServerHandler

```java
/**
 * 测试Netty: 服务端业务处理器, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 使用了Netty String解码器后, 可以直接转换成String类型
        String body = (String) msg;
        System.err.println("Netty server: " + body);

        // 2. 构造响应体给客户端 => 测试与客户端的交互
        ctx.writeAndFlush(Unpooled.copiedBuffer(("服务器响应: " + body + "$_").getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}
```

###### 3、NettyClient

```java
/**
 * 测试Netty: 客户端, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试特殊字符方式解决TCP拆包/粘包问题, 以"$_"结尾作为分割符(只要收到$_,就认为到这里就是一个数据包), 最大帧长1024bit
                        ByteBuf delimiterBuf = Unpooled.copiedBuffer("$_".getBytes());
                        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiterBuf));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.3.2. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg2NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端 => 循环发送100次带特殊字符的消息
        for (int i = 0; i < 100; i++) {
            channelFuture.channel().writeAndFlush(Unpooled.wrappedBuffer(("消息" + i + "$_").getBytes()));
        }

        // 5. 阻塞的方式等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 6. 释放资源
        workGroup.shutdownGracefully();
    }
}
```

###### 4、ClientHandler

```java
/**
 * 测试Netty: 客户端业务处理器, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 使用了Netty String解码器后, 可以直接转换成String类型
            String response = (String) msg;

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client: " + response);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}
```

##### 3）Netty 报文帧解决方案 | LengthFieldBasedFrameDecoder

###### 1、NettyServer

```java
public class Server {
    
	private static void start(int port) throws InterruptedException {
		EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup);
            b.channel(NioServerSocketChannel.class);
            b.childHandler(new ChannelInitializer() {
				@Override
				protected void initChannel(Channel ch) throws Exception {
					 ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024,0,2,0,2));
					 ch.pipeline().addLast(new DefaultEventExecutorGroup(16), new IProtocalHandler());
					 ch.pipeline().addLast(new StringEncoder(CharsetUtil.UTF_8));
				}            	
            });
            
            ChannelFuture f = b.bind(port).sync();
            f.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
	}
	
    public static void main( String[] args ) throws InterruptedException{
    	 start(8084);
    }
}
```

###### 2、NettyServerHandler

```java
public class IProtocalHandler extends ChannelInboundHandlerAdapter {
	@Override
	public void channelRead(ChannelHandlerContext ctx, final Object msg) throws Exception {
		int sleep = 500 * new Random().nextInt(5);
		System.out.println("sleep:" + sleep);
		Thread.sleep(sleep);
		
		final ByteBuf buf = (ByteBuf) msg;
		String outputStr = buf.toString(CharsetUtil.UTF_8);
		System.out.println(outputStr);
		
		ctx.channel().writeAndFlush(outputStr+"\n");
	}
}
```

# 十、Spring篇

### 1.1. 说说你对 Spring 的理解？

1. Spring 是一个开源框架，可以为了简化企业级 Java 开发过程，使得开发变得更加优雅和简洁。
2. Spring 是一个 **IoC** 控制反转和 **AOP** 面向切面编程的**容器框架**，包含并管理了对象的生命周期。

### 1.2. 说说 Spring 的优势有哪些？

1. Spring 通过 DI、AOP 和消除样板式代码，来简化企业级 Java 开发，同时由于低侵入式的设计，对业务代码的污染极低，以及其扩展性、开放性极高，使得并不强制应用完全依赖于 Spring，开发者可以自由选用 Spring 框架的部分或全部。
2. 其中， Spring 的 IoC 容器，降低了对象替换的复杂性，提高了组件之间的解耦。
3. Spring 的 AOP 则支持允许将一些通用任务如安全、事务、日志等进行集中式处理，从而提供了更好的复用。
4. Spring 的 ORM 和 DAO，则提供了与第三方持久层框架的的良好整合，并简化了底层的数据库访问。
5. 除 Spring 框架之外，还存在一个构建在核心框架之上的庞大生态圈，它将 Spring 扩展到不同的领域，比如 Web 服务、REST、移动开发、 NoSQL 以及 CloudFundry 这些。

### 1.3. Spring 是如何简化企业级 Java 开发的？

1. 基于 POJO 的轻量级和最小侵入性编程。
2. 通过依赖注入和面向接口，实现松耦合。
3. 基于切面和惯例，进行声明式编程。
4. 通过切面和模板，减少样板式代码。

### 1.4. 说说你对 IoC 的理解？

1. **IoC**，Inversion of Control，**控制反转**，是⼀种设计思想，指将原本在程序中⼿动创建对象的控制权，交由专门的容器来进行管理，比如 Spring，而 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 
2. **IoC 容器**，是 Spring ⽤来实现 IoC 的载体， 实际上就是个 Map（key，value）键值对，其中存放的是各种对象，将对象之间的相互依赖关系**交给 IoC 容器来管理**，并由 IoC 容器**完成对象的注⼊**。
   - **DI**：Dependancy Injection，依赖注入，站在容器的角度，将对象创建依赖的其他对象，注入到该对象中。
3. 也就是，**IoC 容器**像⼀个⼯⼚，当需要创建⼀个对象时，只需要配置好配置⽂件或者注解即可，不⽤考虑对象是如何被创建出来的，这样可以很⼤程度上简化应⽤的开发，把应⽤从复杂的依赖关系中解放出来。 

### 1.5. Spring IOC 容器的实现原理？

1. 先准备一个基本的容器对象，包含一些 map 结构的集合，用来方便后续过程中存储具体的对象。
2. 进行配置文件的读取工作，或者注解的解析工作，将需要创建的 bean 对象，都封装成 BeanDefinition 对象存储在容器中。
3. 容器将封装好了的 BeanDefinition 对象，通过反射的方式进行实例化，完成对象的实例化工作。
4. 进行对象属性的依赖注入工作，完成整个对象的创建，成为一个 bean 对象，存储在容器的 map 结构中。
5. 通过容器来获取对象，进行对象的获取和逻辑处理工作。
6. 提供销毁操作，当对象不用，或者容器关闭时，将无用的对象进行销毁。

### 1.6. Spring Bean 的生命周期？

#### 从生命周期长短来看

- **单例对象**： singleton，此时，对象的生命周期和容器相同。
- **多例对象**： prototype，此时，对象的生命周期有 3 个阶段：
  1. **出生**：使用对象时，Spring 才进行创建。
  2. **存活**：对象只要是在使用，那么就一直活着。
  3. **死亡**：当对象长时间不用，且没有其它对象引用时，会由 Java 垃圾回收机制回收。

#### 从构造过程的步骤来看

  ![1645326910721](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645326910721.png)

1. **Bean 对象实例化**：通过反射的方式进行对象的创建，此时的创建只是在堆空间中申请内存空间，属性都是默认值。
2. **注入对象属性**：给对象中的属性进行依赖注入的工作。
3. **执行 Aware**：
   1. 如果这个 Bean 实现了 `BeanNameAware` 接口，那么就会调用它实现的 `setBeanName(String)` 方法，由 Spring 容器来传入 `beanName` 的值。
   2. 如果这个 Bean 实现了 `BeanClassLoaderAware` 接口，那么就会调用它实现 的`setBeanClassLoader(ClassLoader)`，由 Spring 容器来传入 `ClassLoader` 对象。
   3. 如果这个 Bean 实现了 `BeanFactoryAware` 接口，那么就会调用它实现 的`setBeanFactory(BeanFactory)`，由 Spring 容器来传入 `BeanFactory` 对象。
4. **BeanPostProcessor 前置处理**：如果这个 Bean 实现了 `BeanPostProcessor` 接口，那么就会调用它实现的 `postProcessBeforeInitialization()` 方法，对生成的 Bean 对象进行前置处理工作，比如经常用作对 Bean 内容的更改，由于这个是在 Bean 初始化结束时调用的方法，所以可以被应用于缓存技术。
5. **InitializatingBean、init-method 检查和执行**：
   1. 如果这个 Bean 实现了 InitializatingBean 接口，那么就会调用它实现的 `afterPropertiesSet()`，在属性设置后的进行一些处理工作。
   2. 如果这个 Bean 自定义并配置了 `init-method` 方法，那么就会调用其初始化方法。
6. **BeanPostProcessor 后置处理**：如果这个 Bean 实现了 `BeanPostProcessor` 接口，那么就会调用 `postProcessAfterInitialization()`，对生成的 Bean 对象进行后置处理工作，比如打印日志等。
7. **注册回调方法**：如果对象实现了 `DestructionXXX` 相关的接口，那么就会调用它实现的回调接口，方便以后对象的销毁操作。
8. **Bean 使用**：通过 Spring 容器，来获取 Bean 对象并进行使用。
9. **执行销毁方法**：当Bean不再需要时，会进入清理阶段：
   1. 如果这个 Bean 实现了 `DisposableBean` 接口，自定义并配置了 `destroy-method` 方法，那么就会调用它实现的 `destroy()` 方法，进行对象的销毁工作。

### 1.7. Spring Bean 的作用域？

| 类型           | 作用域                                                       |
| -------------- | ------------------------------------------------------------ |
| **singleton**  | **单例对象，默认值的作用域**                                 |
| **prototype**  | **每次获取都会创建⼀个新的 Bean 实例**                       |
| request        | 每⼀次 HTTP 请求都会产⽣⼀个新的 Bean 实例，该 Bean 仅在当前 HTTP request 内有效 |
| session        | 仅用于 HTTP Session，同一个 Session 共享一个 Bean 实例，不同 Session 使用不同的实例 |
| global-session | 仅用于HTTP Session， 将对象存入到 web 项目集群的 session 域中，所有 Session 共享一个Bean 实例，但若不存在集群，则 global session 相当于 session |

- 默认作用域是 **singleton**，多个线程访问同一个 bean 时，会存在**线程不安全**问题，其**保障线程安全方法**有：
  1. 在 Bean 对象中，尽量避免不去定义可变的成员变量：有时不太现实。
  2. 在类中定义⼀个 `ThreadLocal` 成员变量，将需要的可变成员变量，保存在该 `ThreadLocal` 中：
     - 这样每个线程中都有一个自己的 ThreadLocalMap 对象，则可以把自己线程的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。
     - 将一个**共用的 ThreadLocal 静态实例作为 key**，将不同对象的引用，保存到不同线程的ThreadLocalMap 中，然后在线程执行的各处，通过这个静态`ThreadLocal#get()` 方法取得自己线程保存的那个对象，避免了将这个对象作为**参数传递**的麻烦。

### 1.8. BeanFactory 和 ApplicationContext 有什么区别？

- **相同点**：
  1. **IoC 容器**：两者都是 Spring 的 IoC 容器，都可以用 XML 来配置属性，都支持属性的自动注入。
  2. **接口**：两者都是接口，其中 ApplicationContext 继承于 ListableBeanFactory，ListableBeanFactory 又继承于 BeanFactory，都提供了一种 `getBean(name)`的方式，来获取 Bean 对象。
- **不同点**：
  1. **Bean 提早实例化**：调用 BeanFactory#getBean()  时会对 Bean 进行实例化，而 Application#getBean() 被调用时，并不会再对 Bean 进行实例化，而是早就在容器启动时实例化完毕。
  2. **自动注入方便**：如果使用BeanFactory 来实现自动注入，则需要注册 AutoWiredBeanPostProcessor，而如果使用 ApplicationContext，则可以直接使用 XML 进行 Bean 配置。
  3. **支持事件发布**：BeanFactory不支持事件发布，而 ApplicationContext 能够把事件发布到注册了监听器的Bean 中。
  4. **支持国际化**：BeanFactory不支持国际化，即 i18n，而 ApplicationContext 提供了对它的支持。
- **总结**：
  1. 简而言之，BeanFactory 提供基本的 IoC 和 DI 的功能，而 ApplicationContext 则还提供了高级的功能。
  2. 所以，BeanFactory 只在测试和非生产环境使用，ApplicationContext 则提供更强大的功能来应对生产环境，应该优于 BeanFactory。

### 1.9. Bean Factory 与 Factory Bean 有什么区别？

- **相同点**：都是用来创建 Bean对象的。
- **不同点**：使用 BeanFactory 创建对象时，必须要遵循**严格的生命周期流程**，这太复杂了，如果想要简单地自定义某个对象的创建，同时创建完成的对象还想交给 Spring 来管理的话，那么就可以实现 FactoryBean 接口，其中包含以下三个方法：
  1. **boolean isSingleton()**：是否为单例对象。
  2. **Class<?> getObjectType()**：返回对象的类型。
  3. **Object getObject()**：自定义对象的创建过程，比如 new、反射、动态代理，例子有 FeignClient 的动态代理实现。

### 2.0. BeanFactoryPostProcessor 与 BeanPostProcessor 有什么区别？

- **相同点**：都是接口，都是 Spring 的扩展点。
- **不同点**：BeanFactoryPostProcessor 指的是 Bean 工厂后置处理器，在 Bean 工厂准备完毕后，用于改写 BeanDefinition 的，而 BeanPostProcessor 指的是 Bean 初始化前/后置处理器，是在 Bean 初始化前和初始化后进行调用处理的，分别对应 `postProcessBeforeInitialization` 和 `postProcessAfterInitialization`。

### 2.1. Spring 启动流程原理？

![1645341206075](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645341206075.png)

```java
public abstract class AbstractApplicationContext extends DefaultResourceLoader
implements ConfigurableApplicationContext {
	@Override
    public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) {
        // 1：刷新前的预处理，包括一些scanner缓存清空、标志位active激活、时间戳记录等 
        prepareRefresh();
        // 2: 获取DefaultListableBeanFactory
        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
        // 3: 做一些BeanFactory的准备工作，包括设置classLoader、注册environment、systemProperties、systemEnvironment单例等
        prepareBeanFactory(beanFactory);
        try {
                // 4: 允许一些上下文子类在BeanFactory完成准备工作后，做一些后置的处理工作
                postProcessBeanFactory(beanFactory);
                // 5: 实例化并顺序执行BeanFactoryProcessor，以在实例化Bean之前，添加更多的BeanDefinition，其中核心的是ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry去扫描解析所有@Configuration下的@PropertySource、@ComponentScan、@Import、@ImportResource、@Bean，并加载成为BeanDefinitions
                invokeBeanFactoryPostProcessors(beanFactory);
                // 6: 实例化并注册所有的BeanPostProcessor，但没有执行，要在Bean初始化前/后再执行
                registerBeanPostProcessors(beanFactory);
                // 7: 实例化并注册MessageSource组件，用于做国际化功能、消息绑定、消息解析等
                initMessageSource();
                // 8: 实例化并注册事件多播器，用于观察者模式
                initApplicationEventMulticaster();
                // 9: 允许一些上下文子类，在容器刷新时自定义逻辑 
                onRefresh();
                // 10: 注册ApplicationListener
                registerListeners();
                // 11： 实例化所有剩下非懒加载的单例Bean，并完成它们的初始化和依赖注入，通过遍历所有beanNames，然后挨个判断走FactoryBean的流程，还是走BeanFactory的流程，其中主要步骤总结起来分为3步，分别是NewInstance实例化、Populate属性赋值、Initialization初始化
                finishBeanFactoryInitialization(beanFactory);
                // 12: 完成上下文的刷新，主要是调用LifecycleProcessor#onRefresh()方法
                finishRefresh();
            }
        ...
	}
}
```

### 2.2. Spring 是如何解决循环依赖的？

- **概念**：循环依赖，其实就是 Bean 的循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成依赖闭环，比如 A 依赖于B，B又依赖于A。

- **Spring中循环依赖场景有**: 

  1. prototype 原型 bean 的循环依赖。
  2. 构造器注入的循环依赖（构造器注入）。
  3. Field 属性注入的循环依赖（set注入）。

  => 其中，**构造器的循环依赖**问题无法解决，在解决属性循环依赖，也可以使用**懒加载**，而 Spring 采用的是**提前暴露对象**的方式来解决的。

- **懒加载 @Lazy 解决循环依赖问题**：

  1. Spring 启动时，会把所有的 bean 信息，包括 XML 和注解解析转化成 Spring 能够识别的 BeanDefinition 存到 HashMap 里，供后面初始化时使用。
  2. 然后对每个 BeanDefinition 进行处理，普通 Bean 初始化是在容器启动初始化阶段执行的，而被 `lazy-init=true` 修饰的 bean，则是在从容器里第一次进行 `context.getBean()` 时才会被触发，而此时其依赖的普通 Bean 早就被初始化完毕了，所以可以解决正常情况下的属性注入的循环依赖问题。 

- **三级缓存解决循环依赖问题**：

  ![1645350673009](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645350673009.png)

  Class A 依赖（这里是 @Autowire） Class B，Class B 又依赖（这里是 @Autowire） Class A，造成循环依赖，Spring 的解决方式是**三级缓存**：

  1. Class A 首先被实例化（一个空壳），实例化后立马放入三级缓存中。
  2. 然后在 populateBean填充 Class A 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class B name 调用 doGetBean 方法，获取 Class B 的实例。
  3. 然后在 Class B 也被实例化（一个空壳），实例化后也立马放入三级缓存中。
  4. 然后在 populateBean 填充 Class B 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class A name 调用 doGetBean 方法，获取 Class A 的实例。
  5. 由于此时 A 已经在三级缓存中，所以取出 A 的 ObjectFactory 表达式并执行，获取到 Class A 实例的引用。
     - 其中要注意的是，这个表达式调用的 `getEarlyBeanReference(beanName, mbd, bean)` 方法，可以获取 AOP 代理的空壳引用，即该方法要么返回的是原对象，要么返回的是代理对象，如果返回的是代理对象，那么该代理对象 B'/A' 不会持有另外一个 A/B 的引用，而是**持有 B/A 原对象的引用**，再由原对象去持有 A/B 的引用，而 A/B 则持有代理对象的引用 B'/A'。
  6. 获取到 Class A 实例的引用，设置到二级缓存中，删除 A 三级缓存，并返回给 Class B 注入。
  7. 此时 Class B 已经解决了循环依赖 A 的问题，最后设置单例 Class B 到一级缓存中，删除 B 二三级缓存。
  8. 由于此时 B 已经在一级缓存中，所以取出 B 实例引用，返回给 Class A 注入。
  9. 此时 Class A 也解决了循环依赖 B 的问题，最后设置单例 Class A 到一级缓存中，删除 A 二三级缓存。

  => 最后，Class A、Class B 分别完成注入，也就是解决了循环依赖的问题。

### 2.3. 说说你对 AOP 的理解？

1. **AOP**，Aspect-Oriented Programming，**⾯向切⾯编程**，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑，或者责任封装起来（比如事务管理、⽇志管理、权限控制等），以便于减少系统的重复代码，降低模块间的耦合度，有利于未来的可拓展性和可维护性。

2. AOP 有如下 7 个核心的**概念**：

   1. **切面**：Aspect，指对哪些方法进行拦截处理的**横切关注点**，可能会横切多个对象，比如 Spring 的事务管理， 在 Spring AOP 中，切面可以在普通类中以 `@Aspect` 注解来实现。
   2. **连接点**：Join point，指在程序执行过程中某个特定的点，比如某个方法调用的时间点，或者处理异常的时间点，在 Spring AOP 中，一个连接点代表一个**方法的执行**。
   3. **通知**：Advice，在切面的某个特定的连接点上**执行的动作**，通知有多种类型，包括 `around`， `before`， 和 `after` 等等。
   4. **切点**：Pointcut，**匹配连接点的断言**，通知会在满足这个切点的连接点上运行，比如 AOP 去执行某个特定名称的方法。
   5. **目标对象**：Target object，被一个或者多个切面所通知的对象，也被称作**被通知的业务对象**。
   6. **织入**：Weaving，把切面连接到目标对象上，并创建一个代理对象的过程。
   7. **AOP 代理**：AOP proxy，AOP 框架创建的对象，用来实现切面契约，包括通知方法执行等功能，在Spring 中，AOP代理可以是 JDK 动态代理，或者是 CGLIB 动态代理。

3. 比如日志管理的公共代码，可以抽象出一个**切面**，然后注入到**目标对象**中（具体的业务对象），通过**动态代理**，将对目标对象进行代理，在进行调用时，代理对象会根据通知类型，在对应的时间点，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

4. **原理**：Spring AOP 是基于**动态代理**实现的，是 IoC 的一个扩展功能，是在 IoC 整个流程中新增的一个 BeanPostProcessor `AbstractAutoProxyCreator` 扩展点而已。

   1. `AbstractAutoProxyCreator` 实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
   2. 如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
   3. ⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 asm框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。

5. **实现**：选讲，只是用于记忆而已。

   - **1、POM 依赖**：

     ```xml
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-aop</artifactId>
     </dependency>
     ```

   - **2、开启 AOP**：

     ```java
     // proxyTargetClass默认为false, 表示默认使用JDK 动态代理, 碰到接口或者设置为true, 则使用CGLIB动态代理
     @EnableAspectJAutoProxy(proxyTargetClass = true)
     @SpringBootApplication
     public class SpringbootDemoApplication {
         public static void main(String[] args) {
             SpringApplication.run(SpringbootDemoApplication.class, args);
         }
     }
     ```

   - **3、配置切面、切点、通知**：

     ```java
     @Aspect
     @Component
     public class AspectJConfig {
         @Pointcut("execution(* com.jsonyao.cs.controller.*.*(..))")
         private void pointcut() {
     
         }
     
         @Around("pointcut()")
         public Object around(ProceedingJoinPoint point) throws Throwable {
             long start = System.currentTimeMillis();
             Object res = point.proceed();
             long end = System.currentTimeMillis();
             System.err.println("执行结果: " + res + ", 消耗时间: " + (end - start));
             return res;
         }
     }
     ```

   - **4、测试切面**：

     ```java
     package com.jsonyao.cs.controller;
     
     @RestController
     @RequestMapping("/boot")
     public class UserController {
         @Autowired
         private UserSerivce userService;
     	
         // 打印了日志：执行结果: User{id=0, username='AOP', password='AOP'}, 消耗时间: 8
         @RequestMapping("/getUser/{id}")
         public String GetUser(@PathVariable Long id){
             return userService.findById(id).toString();
         }
     }
     ```

### 2.4. Spring 事务传播属性？

- **概念**：

| 属性                     | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| REQUIRED（默认属性）     | 如果存在一个事务，则支持**当前事务**，如果没有事务，则开启一个**新的事务** |
| MANDATORY                | 支持**当前事务**，如果当前没有事务，就**抛出异常**           |
| NEVER                    | 以**非事务**方式执行，如果当前存在事务，则**抛出异常**       |
| NOT_SUPPORTED            | 以**非事务**方式执行操作，如果当前存在事务，就把当前事务**挂起** |
| REQUIRES_NEW（相互独立） | **新建事务**，如果当前存在事务，把当前**事务挂起**，内外两个事务相互独立，互不影响，当外层事务失败时，并不会回滚内层事务所做的动作，而内层事务操作失败时，也不会引起外层事务的回滚 |
| SUPPORTS                 | 支持**当前事务**，如果当前没有事务，就以**非事务**方式执行   |
| NESTED（局部回滚）       | 支持**当前事务**，新增 Savepoint 点，与当前事务**同步提交或回滚**。嵌套事务一个非常重要的概念，就是内层事务依赖于外层事务，当外层事务失败时，会回滚内层事务所做的动作，而内层事务操作失败时，并不会引起外层事务的回滚 |

- **实现**：@Transactional

  ```java
  @EnableTransactionManagement 
  @Transactional
  ```

- **原理**：

  ![1645359975955](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645359975955.png)

  Spring 的事务是由 AOP 来实现的，首先按照 AOP 的整套流程来执行具体的操作逻辑，使用 `InfrastructureAdvisorAutoProxyCreator` （AbstractAutoProxyCreator 的子类）来生成具体的代理对象，然后通过一个 `TransactionInterceptor` 来实现，在调用 `JdkDynamicAopProxy#invoke(proxy, method, args)` 方法时，则代理到 `TransactionInterceptor`  实现的具体逻辑中。

  1. 先做准备工作，解析各个方法上事务相关的属性，根据具体的属性来判断是否开始新事务。
  2. 当需要开启事务时，则获取数据库连接，关闭自动提交功能，开启事务。
  3. 执行具体的业务逻辑。
  4. 在执行过程中发生异常，那么会通过 `completeTransactionAfterThrowing` 来完成事务的回滚操作，回滚的具体逻辑是通过 `doRollBack` 方法来实现的，实现的时候也是要先获取链接对象，再通过连接对象来回滚。
  5. 如果执行过程中，没有任何意外情况的发生，那么通过 `commitTransactionAfterReturning` 来完成事务的提交操作，提交的具体逻辑是通过 `doCommit` 方法来实现的，实现的时候也要获取链接，通过链接对象来提交。
  6. 当事务执行完毕之后，需要通过 `cleanupTransactionInfo` 来清除相关的事务信息。 

- **注意事项**：

  1. 事务函数中不要处理**耗时任务**，会导致长期占有数据库连接。
  2. 事务函数中不要处理**无关业务**，防止产生异常导致事务回滚。
  3. Spring 事务控制什么时候会**失效**？
     1. Bean 对象没有被 Spring 容器所管理。
     2. 调用方法的访问修饰符不是 public。
     3. 数据源没有配置事务管理器。
     4. 数据库不支持事务。
     5. 异常被捕获，所以没有回滚。

### 2.5. Spring 中的设计模式？

- **单例模式** : Bean 默认都是单例的。
- **⼯⼚模式** : 使用 BeanFactory、ApplicationContext 来创建 Bean 对象。
- **模板方法模式**：BeanFactoryPostProcessor#postProcessBeanFactory，AbstractApplicationContext#onRefresh。
- **代理模式** ：AOP。
- **观察者模式**：事件驱动模型。
- **责任链模式**：MVC Filter。
- **适配器模式**：MVC 适配器适配 Controller 。

### 2.6. 谈谈你对 SpringBoot 的理解？

- **背景**：SpringBoot 所解决了的问题。
  1. 搭建后端框架时需要涉及很多 **XML 配置文件**，增加了搭建难度和时间成本。
  2. 将项目编译成 war 包，部署到 Tomcat 中，项目**部署依赖 Tomcat**，这样非常不方便。
  3. **应用监控**需要做的比较简单，通过一个没有任何逻辑的接口，来判断应用的存活状态。
- **概念**：
  1. 使用 Spring Boot 通过简单的步骤，就可以创建一个 Spring 应用。
  2. Spring Boot 为 Spring 整合第三方框架提供了**开箱即用**的功能。
  3. Spring Boot 的核心思想是**约定大于配置**。
- **优点**：
  1. **自动装配**：Spring Boot 会根据某些规则对所有配置的 Bean 进行初始化，减少了很多重复性的工作。
     - 比如使用 MongoDB 时，只需加入 MongoDB 的 Starter 包，然后配置  的连接信息，就可以直接使用 MongoTemplate 自动装配来操作数据库了。简化了 Maven Jar 包的依赖，降低了烦琐配置的出错几率。
  2. **内嵌容器：**Spring Boot 应用程序可以不用部署到外部容器中，比如 Tomcat，应用程序可以直接通过 Maven 命令编译成可执行的 jar 包，通过 java-jar 命令启动即可，非常方便。
  3. **应用监控：**Spring Boot 中自带监控功能 Actuator，可以实现对程序内部运行情况进行监控，比如 Bean 加载情况、环境变量、日志信息、线程信息等，也可以自定义跟业务相关的监控，通过Actuator 的端点信息进行暴露。

### 2.7. SpringBoot 自动装配原理？

- **Starter 是什么**：
  1. starter 就是一个 jar 包，写一个 @Configuration 的配置类，把这些 Bean 的定义都包含在其中，然后在 Starter 包下的 `META-INF/spring.factories` 中写入该配置类，那么 SpringBoot 程序在启动时，就会按照约定来加载该配置类。
  2. 开发人员只需要将相应的 Starter 包依赖进应用中，然后进行相关的属性配置，就可以进行代码开发，而不需要再单独对 Bean 进行配置。
- **自定义 Starter**：
  1. 创建 Starter 项目，定义 Starter 需要的 Properties 配置类，比如数据库连接信息等。
  2. 然后编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean。
  3. 编写 `META-INF/spring.factories` 文件，以让 SpringBoot 在启动时加载自动配置类。
  4. 然后在项目中，引入自定义 Starter 的 Maven 依赖，增加对应的配置值后，即可直接使用。
- **原理**：
  1. 当启动 SpringBoot 应用时，会先创建 SpringApplication 的对象，在对象的构造方法中，会进行某些参数的初始化工作，最主要的是判断当前应用的类型（比如 Servlet） 以及 SPI 加载整个应用的 `spring.factories` 文件中的初始化器和监听器 Class 类。
  2. SpringApplication 对象创建完成之后，开始执行 `run()` 方法，来完成整个启动，启动过程中最主要的有两个方法，第一个叫做 `prepareContext()`，第二个叫做 `refreshContext()`，在这两个步骤中完整了自动装配的核心功能，而其他方法的处理逻辑包含了上下文对象的创建、Banner 的打印、异常报告期的准备等各个准备工作，方便后续来进行调用。
  3. 在 `prepareContext()` 方法中，主要完成了对上下文对象的初始化工作，包括属性值的设置，比如环境对象，在整个过程中，有一个非常重要的方法 `load()`，`load()` 主要完成一件事，那就是将**启动类**作为BeanDefinition 注册到 Registry 中，方便后续在进行 BeanFactoryPostProcessor 调用执行时，找到对应的主类来完成 `@SpringBootApplication` 和 `@EnableAutoConfiguration` 等注解的解析工作。
  4. 在 `refreshContext()` 方法中，会进行整个容器的刷新过程，会调用 Spring 中的启动流程，即`AbstractApplicationContext#refresh()`，有 13 个关键方法，来完成整个  Spring 应用的启动，其中会调用 `invokeBeanFactoryPostProcessor()` 方法，主要是对`ConfigurationClassPostProcessor` 的处理，会先调用实现 `BeanDefinitionRegistryPostProcessor` 接口的 `postProcessBeanDefinitionRegistry()` 方法，然后再调用自己实现的 `postProcessBeanFactory()` 方法，处理各种包括 @PropertySource、@ComponentScan、@Import、@ImportResource、@Bean 等注解。
  5. 其中，在解析 @Import 注解时，会有一个 `getImports()` 的方法，会从**启动类**开始递归解析注解，把所有包含 @Import 注解都收集到，然后在 `processImport()` 方法中，对 Import 导入的类进行分类，这里主要起识别作用的是 `ImportSelect` 的实现类  `AutoConfigurationImportSelect`，来调用 `selectImports()` 方法使用 SPI 方式，来获取并加载 `spring.factories` 中的 `EnableAutoConfiguration` 自动装配配置类的 Class。
  6. 接着，调用子类上下文 `ServletWebServerApplicationContext#onRefresh` 方法，来拉起嵌入式 Tomcat 服务器。
  7. 最后，还有一步关键步骤是 `finishBeanFactoryInitialization()` 方法，主要是实例化所有剩下非懒加载的单例 Bean，并完成它们的初始化和依赖注入，通过遍历所有 beanNames，然后挨个判断走FactoryBean 的流程，还是走 BeanFactory 的流程，其中主要步骤总结起来分为 3 步，分别是NewInstance 实例化、Populate 属性赋值 和 Initialization 初始化，从而完成自动配置配置 Bean 的自动注入。

### 2.8. Spring MVC 原理？

- **自动装配原理**：

  - ../spring-boot-**autoconfigure**-2.2.2.RELEASE.jar!/META-INF/**spring.factories**：

    ```properties
    # Auto Configure
    org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
    ...,
    org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\
    ...
    ```

  - **DispatcherServletAutoConfiguration**：Springboot 中 的Spring MVC，主要是依靠DispatcherServletAutoConfiguration 中的两个内部类进行初始化，两者配合，最终完成初始化工作：

    ```java
    @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)
    @Configuration(proxyBeanMethods = false)
    @ConditionalOnWebApplication(type = Type.SERVLET)
    @ConditionalOnClass(DispatcherServlet.class)
    @AutoConfigureAfter(ServletWebServerFactoryAutoConfiguration.class)
    public class DispatcherServletAutoConfiguration {
        
        // 1、DispatcherServletConfiguration，负责生成dispatcherServlet
    	@Configuration(proxyBeanMethods = false)
    	@Conditional(DefaultDispatcherServletCondition.class)
    	@ConditionalOnClass(ServletRegistration.class)
    	@EnableConfigurationProperties({ HttpProperties.class, WebMvcProperties.class })
        protected static class DispatcherServletConfiguration {
            @Bean(name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)
            public DispatcherServlet dispatcherServlet(HttpProperties httpProperties, WebMvcProperties webMvcProperties) {
                ...
            }
            ...
        }
        
        // 2、DispatcherServletRegistrationConfiguration，负责将dispatcherServlet注册到系统里面的servlet中，使其生效
        @Configuration(proxyBeanMethods = false)
    	@Conditional(DispatcherServletRegistrationCondition.class)
    	@ConditionalOnClass(ServletRegistration.class)
    	@EnableConfigurationProperties(WebMvcProperties.class)
    	@Import(DispatcherServletConfiguration.class)
        protected static class DispatcherServletRegistrationConfiguration {
            ...
        }
    }
    ```

- **请求访问原理**：

![1645420150788](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645420150788.png)

总：当客户端发起请求时，被中心控制器拦截到请求，根据请求参数生成代理请求，找到对应的实际控制器，调用控制器去处理请求，创建数据模型，访问数据库填充好模型后，再把模型视图返回给适配器到中心控制器，然后由中心控制器去调用视图解析器，根据逻辑的视图获取实际的视图，再使用模型去渲染该视图后，最后再把视图返回给客户端，从而完成一次请求的处理。

分：

1. DispatcherServlet，表示中心控制器，在客户端发出请求后，经过 Web 容器（比如 Tomcat）后，会打到 DispatcherServlet 上，并由其来处理请求。
2. HandlerMapping，表示处理器映射，DispatcherServlet 收到请求后，会调用 HandlerMapping，HandlerMapping 会根据请求 url 去查找对应的 Handler，即一个 Handler Method 对象，指的是 url 对应 Controller 中的对应方法。
3. HandlerExecutionChain，表示处理器执行链，Handler 解析完 url  后，会返回一个处理器执行链给DispatcherServlet。
4. HandlerAdapter，表示处理器适配器，DispatcherServlet 会按照规则去匹配对应的 HandlerAdapter。
5. 再由对应的 Handler Method 去处理请求，其中就包括调用去执行我们编写的业务逻辑。
6. Controller 代理对象，则会去创建数据模型，访问数据库填充好模型后，再把 ModelAndView 返回给 HandlerAdapter。
   - 对于我们平常使用的 @ResponseBoday 的方法，返回的 ModelAndView 为空，也就是不会返回视图给客户端，而是经过 `RequestResponseBodyMethodProcessor`，把 JSON 串写入到 Response 的 Body 中。
7. HandlerAdapter 收到后，再将 ModelAndView  传递给 DispatcherServlet。
8. DispatcherServlet 收到后，则调用视图解析器 ViewResolver，来解析 ModelAndView。
9. ViewResolver 会解析逻辑视图名，根据逻辑的 View 找到实例的 View，并返回给 DispatcherServlet。
10. DispatcherServlet 收到后，则根据 ViewResolver 解析出的 View，调用对应的实际视图，结合 Model 进行渲染。
11. 最后，DispatcherServlet 再将渲染后的 View 作为结果，响应给客户端。

- **MVC 9 大组件**：
  1. **HandlerMapping**：处理器映射，RequestMappingHandlerMapping 可以根据 request#url，找到 **Handler Method** 对象，这指的是 url 对应 Controller 中的对应方法。
  2. **HandlerAdapter**：调用 Handler Method 的适配器，主要处理方法参数、相关注解、数据绑定、消息转换、返回值、调用视图解析器等工作。
  3. HandlerExceptionResolver：异常解析器，对异常进行处理。
  4. **ViewResolver**：视图解析器，用来将 String 类型的视图名和 Locale 解析为 View 类型的逻辑视图。
  5. RequestToViewNameTranslator：请求视图名获取器，有的 Handler Method 处理完后没有设置返回类型，比如是 void 返回值的方法，就需要从 request 中获取 viewName。
  6. LocaleResolver：多语言解析器，从 request 中解析出请求中的本地语言 Locale，Locale表示一个区域，比如 zh-cn，针对不同的区域的用户，显示不同的结果，即 i18n（SpringMVC 中有具体的拦截器`LocaleChangeInterceptor`）。
  7. ThemeResolver：主题解析器，主题解析，这种类似于我们手机更换主题，不同的 UI，css 等。
  8. MultipartResolver：多部件文件解析器，处理上传请求，把普通的request封装成MultipartHttpServletRequest。
  9. FlashMapManager：FlashMap 管理器，用于管理 FlashMap，FlashMap 可以用于在 redirect 重定向中传递参数。

### 2.9. Spring、Spring MVC、Spring Boot 的区别是什么？

1. Spring，是一个一站式的轻量级 Java 开发框架，核心是控制反转（IOC）和面向切面（AOP），针对于开发的
   WEB 层(Spring Mvc)、业务层(IoC)、持久层(JdbcTemplate)等都提供了多种配置解决方案。
2. Spring MVC，是 Spring 基础之上的一个 MVC 框架，主要处理 WEB 开发的路径映射和视图渲染，属于 Spring 框架中 WEB 层开发的一部分。
3. SpringBoot，由于 Spring 配置非常复杂，各种 XML、JavaConfig、Servlet 处理起来比较繁琐，为了简化开发者的使用，从而创造性地推出了 SpringBoot 脚手架，相对于 Spring MVC 框架来说，更专注于开发微服务后台接口，不开发前端视图，同时遵循默认优于配置，简化了插件配置流程，不需要配置 XML，大大简化了配置流程。

### 3.0. Spring 常用注解？

| 注解           | 包位置           | 作用                                                         | 用法举例                                                     |
| -------------- | ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| @Autowired     | spring-beans     | 属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入 | @Autowired + 属性、@Autowired + setxxx()、@Autowired + 构造方法、@Autowired + 方法参数，原理见 AutowiredAnnotationBeanPostProcessor |
| @Resource      | javax.annotation | 属性注入，先按属性名字去找，再按属性类型去找，如果指定名字则直接按名字去找 | @Resource、@Resource(name = "beanName")                      |
| @Value         | spring-beans     | 注入普通字符串、占位符替换、SpringEL                         | @Value（"abc"）、@Value（"${str}"）、@Value（"#{beanName}"） |
| @Lazy          | spring-context   | 懒加载式注入代理 Bean、解决构造函数循环依赖问题              | @Lazy + 类、@Lazy + 属性、@Lazy + 方法、@Lazy + 方法参数、@Lazy + 构造方法 |
| @Lookup        | spring-beans     | 找到对应的 Bean 作为返回值返回                               | @Lookup("beanName") + 方法                                   |
| @Bean          | spring-context   | Bean 注入                                                    | @Configuration + @Bean 配置 Bean、@Component + @Bean 普通 Bean |
| @Component     | spring-context   | Bean 注入                                                    | @Component + 类，延伸出 @Configuration、@Service、@Controller、@Repository |
| @Primary       | spring-context   | 标识某个 Bean 为主 Bean，优先注入                            | @Bean + @Primary、@Component + @Primary                      |
| @Configuration | spring-context   | 标识为配置 Bean                                              | @Configuration + @Bean，配置 Bean 不仅会被注入，还会被解析   |
| @ComponentScan | spring-context   | @Component Bean 扫描                                         | @Component("beanPkg") + includeFilters、excludeFilters、META-INF/spring-components 索引 |
| @Conditional   | spring-context   | 条件式注入                                                   | @Conditional + 类、@Conditional + 方法、实现 Condition#matches 接口方法，返回 true 则代表匹配 |
| @Import        | spring-context   | 批量导入 Bean 类从而注入 Bean                                | @Import（BeanClass） + ImportSelector#selectImports、或者 DeferredImportSelector#selectImports、或者 ImportBeanDefinitionRegistrar#registerBeanDefinitions |

### 3.1. Spring 注入一个 Bean 的方式？

1. **@Component（@Configuration、@Service、@Controller、@Repository）**：通过注入某个类成为 Bean。
2. **@Bean**：通过解析某个方法成为 Bean。
3. **@Import**：导入类或者 BeanDefinition 成为 Bean。
4. **@ImportResource**：导入一个 Spring.xml 文件，通过解析文件注册 Bean。
5. **BeanDefinitionRegistryPostProcessor**：通过 BeanDefinition 注册 Bean。
6. **FactoryBean、SmartFactoryBean**：将自己 New 的一个对象注册为 Bean。
7. **ApplicationContext#registerBean**：通过 ApplicationContext 实现 Supplier 接口，来提供一个对象成为 Bean。
8. **ApplicationContext#register**：通过 ApplicationContext 某个类注册成为 Bean。
9. **ApplicationContext#registerBeanDefinition**：通过 BeanDefinition 注册 Bean。

### 3.2. Spring 依赖注入方式？

1. **@Autowired**：属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入。
2. **@Resource**：属性注入，先按属性名字去找，再按属性类型去找，如果指定名字则直接按名字去找。
3. **@Value**：注入普通字符串、占位符替换、SpringEL。
4. **自定义注解**：实现 BeanPostProcessor#postProcessBeforeInitialization 方法，解析 Bean 上的自定义注解，完成属性注入。

### 3.3. ApplicationContext 获取方式？

1. **@Autowired**：属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入。
2. **实现自省接口**：实现 ApplicationContextAware#setApplicationContext 方法。

### 3.4. Spring AOP 使用方式？

1. **ProxyFactory**：代理对象工厂，封装了 JDK 和 CGLIB 动态代理方法，比如：

   ![1647155729524](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155729524.png)

2. **ProxyFactoryBean**：利用 FactoryBean 机制，将代理对象作为一个 Bean，比如：

   ![1647155822496](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155822496.png)

3. **BeanNameAutoProxyCreator**：指定某个 beanName，让 Spring 对其匹配的 Bean，进行批量 AOP，比如：

   ![1647155851621](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155851621.png)

4. **DefaultAdvisorAutoProxyCreator**：指定某个 Advisor，让 Spring 对其匹配的 Bean，进行批量 AOP。

   ![1647155943409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155943409.png)

5. **@EnableAspectJAutoProxy**：开启支持 AspectJ。

### 3.5. Spring MVC 常用注解？

| 注解            | 包位置     | 作用                                           | 用法举例                                                     |
| --------------- | ---------- | ---------------------------------------------- | ------------------------------------------------------------ |
| @RequestMapping | spring-web | 映射Web请求                                    | @RequestMapping（"path"）+ 类、@RequestMapping（"path"）+ 方法 |
| @RequestBody    | spring-web | 读取请求体中的参数                             | @RequestBody + 方法参数                                      |
| @PathVariable   | spring-web | 读取请求路径中的参数                           | @PathVariable + 方法参数                                     |
| @ResponseBody   | spring-web | 把 json 返回值放在 response 内，而不是一个页面 | @ResponseBody + 类 = @RestController、@ResponseBody + 方法   |

### 3.6. Spring Boot 常用注解？

| 注解                   | 包位置                    | 作用                                                         | 用法举例                    |
| ---------------------- | ------------------------- | ------------------------------------------------------------ | --------------------------- |
| @SpringBootApplication | spring-boot-autoconfigure | @SpringBootConfiguration 表示为配置 Bean + @EnableAutoConfiguration 开启自动装配 `META-INF/spring.factories` + @ComponentScan 扫描注解 | @SpringBootApplication + 类 |

# 十一、MyBatis篇

### 1.1. MyBatis 是什么？

1. Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程，程序员直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高。
2. MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO 映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。

### 1.2. MyBatis 优缺点？

- **优点**：
  1. 基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在 XML 里，解除 sql 与程序代码的耦合，便于统一管理，且提供 XML 标签，支持编写动态 SQL 语句，并可重用。
  2. 与 JDBC 相比，减少了 50% 以上的代码量，消除了 JDBC 大量冗余的代码，不需要手动开关连接。
  3. 很好的与各种数据库兼容（因为 MyBatis 使用 JDBC 来连接数据库，所以只要 JDBC 支持的数据库，MyBatis 都支持）。
  4. 提供映射标签，支持对象与数据库的 ORM 字段关系映射，提供对象关系映射标签，支持对象关系组件维护。
  5. 能够与 Spring 很好的集成。
- **缺点**：
  1. SQL 语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写 SQL 语句的功底有一定要求。
  2. SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

### 1.3. Mybatis 和 Hibernate 的区别？ 

- **1）概念上**：
  1. Hibernate，是一个开放源代码的对象关系映射框架，它对 JDBC 进行了非常轻量级的对象封装，建立对象与数据库表的映射，是一个全自动的、完全面向对象的持久层框架。
  2. Mybatis，是一个开源对象关系映射框架，原名 Ibatis，2010年由谷歌接管以后更名，是一个半自动化的持久层框架。
- **2）开发速度上**：
  1. Hibernate 开发中，sql 语句已经被封装，直接可以使用，加快系统开发。
  2. Mybatis 属于半自动化，sql需要手工完成，稍微繁琐。
  3. 但是，凡事都不是绝对的，如果对于庞大复杂的系统项目来说，复杂语句较多，hibernate 就不是好方案。
- **3）sql 性能上**：
  1. Hibernate 自动生成sql，有些语句较为繁琐，会多消耗一些性能。
  2. Mybatis 手动编写sql，可以避免不需要的查询，提高系统性能。
- **4）对象管理比对**：
  1. Hibernate，是完整的对象-关系映射的框架，开发工程中，无需过多关注底层实现，只要去管理对象即可。
  2. Mybatis 需要自行管理映射关系，所以，称之为半自动 ORM 映射工具。
     - **ORM**：Object Relational Mapping，对象关系映射，是一种为了解决关系型数据库数据与简单 Java对象（POJO）的映射关系的技术，简单来说就是，ORM 通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系型数据库中。

#### 1、jdbc

```java
@Slf4j
public class UserExecutor {

    public static final String URL = "jdbc:mysql://localhost:3306/muse";
    public static final String USER = "root";
    public static final String PASSWORD = "root";

    public static void main(String[] args) throws Exception {
        //1.加载驱动程序
        Class.forName("com.mysql.jdbc.Driver");
        //2. 获得数据库连接
        Connection conn = DriverManager.getConnection(URL, USER, PASSWORD);
        ResultSet rs = null;
        PreparedStatement ps = null;
        try {
            //3.操作数据库，实现增删改查
            ps = conn.prepareStatement("SELECT name, age FROM tb_user where id = ?");
            ps.setInt(1, 2);
            rs = ps.executeQuery();
            //如果有数据，rs.next()返回true
            while (rs.next()) {
                System.out.println("姓名：" + rs.getString("name") + "，年龄：" + rs.getInt("age"));
            }
        } catch (SQLException e) {
            log.error("error", e);
        } finally {
            close(rs, ps, conn);
        }
    }

    private static void close(ResultSet rs, Statement stmt, Connection connection) {
        try {
            if (rs !=null && !rs.isClosed()) {
                rs.close();
            }
        } catch (SQLException e) {
            log.error("rs.close() error!", e);
        }

        try {
            if (stmt != null && stmt.isClosed()) {
                stmt.close();
            }
        } catch (SQLException e) {
            log.error("stmt.close() error!", e);
        }

        try {
            if (connection != null && connection.isClosed()) {
                connection.close();
            }
        } catch (SQLException e) {
            log.error("connection.close() error!", e);
        }

    }
}
```

#### 2、Hibernate

```java
public class UserExecutor {

    //保存用户的案例
    public static void main(String[] args) {
        Configuration configuration = new Configuration().configure("hibernate.cfg.xml");
        SessionFactory sessionFactory = configuration.buildSessionFactory();
        Session session = null;
        try {
            session = sessionFactory.openSession();
            User user = session.get(User.class, 2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        } finally {
            if (session != null) {
                //7. 释放资源
                session.close();
                sessionFactory.close();
            }
        }
    }
}
```

#### 3、Mybatis

```java
public class MessageExecuter {
    public static void main(String[] args) {
        sqlSession = SqlSessionFactoryUtil.openSqlSession();
        MessageMapper messageMapper = sqlSession.getMapper(MessageMapper.class);
        Message message = messageMapper.getMessageById(2L);
        System.out.println("getMessageById--->" + message);
    }
}
```

### 1.4. MyBatis 核心组件？

1. **SqlSessionFactoryBuilder**：构造器，根据配置信息或代码，来生成 SqlSessionFactory。
2. **SqlSessionFactory**：工厂，用来生成SqlSession。
3. **SqlSession**：会话，可以用来发送 SQL，去执行并返回结果，也可以获取 Mapper 的接口。
4. **SQL Mapper**：它由一个 Java 接口和 XML 文件/注解构成，需要给出对应的 SQL 和映射规则，负责发送 SQL 去执行，并返回结果。

### 1.5. MyBatis 使用？

#### 1、使用步骤

1. **第一步**：配置mybatis-config.xml：

   ```xml
   <configuration>
       <!-- 属性 -->
       <properties resource="sqlmap/mybatis/mysql/jdbc.properties"/>
       
       <!-- 配置 -->
       <settings>
           <!-- PARTIAL是默认值，只会自动映射，没有定义嵌套结果集映射的结果集 -->
           <setting name="autoMappingBehavior" value="PARTIAL"/>
   		<!-- 打印查询语句 -->
           <setting name="logImpl" value="STDOUT_LOGGING"/>
           <!-- 配置驼峰转下划线 数据库中的下划线，转换Java Bean中的驼峰-->
           <setting name="mapUnderscoreToCamelCase" value="true"/>
       </settings>
   
       <!-- 类型别名 -->
       <typeAliases>
           <package name="vo"/>
           <!-- <typeAlias type="vo.User" alias="user"/> -->
       </typeAliases>
   
       <!-- 类型处理器
       <typeHandlers/> -->
   
       <!-- 对象工厂
       <objectFactory type="" />   -->
   
       <!-- 对象包装工厂
       <objectWrapperFactory type="" />    -->
   
       <!-- 对象工厂
       <reflectorFactory type="" />    -->
   
       <!-- 插件
       <plugins>
           <plugin interceptor=""></plugin>
       </plugins> -->
   
       <!-- 配置数据库环境 -->
       <environments default="dev">
           <environment id="dev">
               <transactionManager type="JDBC"/> <!-- 事务管理器 -->
               <dataSource type="POOLED">
                   <property name="driver" value="${driver}"/>
                   <property name="url" value="${url}"/>
                   <property name="username" value="${username}"/>
                   <property name="password" value="${password}"/>
               </dataSource>
           </environment>
       </environments>
   
       <!-- 数据库厂商标识 -->
       <databaseIdProvider type="DB_VENDOR"/>
   
       <!-- 映射器 -->
       <mappers>
           <mapper resource="sqlmap/mybatis/mysql/UserMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/UserContactMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/MessageMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/MessageDetailMapper.xml"/>
       </mappers>
   </configuration>
   ```

2. **第二步**：配置 MessageMapper.xml：

   ```xml
   java id, msgid, status, content, deleted, createtime, update_time...
   ```

3. **第三步**：构建 Message 实体类和 MessageMapper 接口：

   ```java
   public interface MessageMapper { 
       Message getMessageById(Long id); 
       int insert(User user); 
       int delById(Long id);
   }
   ```

#### 2、select | 查询

##### 1）基础类型查询

```java
Message message = messageMapper.getMessageById(2L);

public interface MessageMapper {
    Message getMessageById(Long id); 
}
```

```xml
<select id="getMessageById" parameterType="long" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} 
</select>
```

##### 2）Map 类型查询

```java
Map<String, String> paramsMap = new HashMap<>(); 
paramsMap.put("id", "2");
paramsMap.put("msgId", "1001"); 
Message message = messageMapper.getMessageByMap(paramsMap);

public interface MessageMapper {
    Message getMessageByMap(Map<String, String> params); 
}
```

```xml
<select id="getMessageByMap" parameterType="map" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} and msg_id = #{msgId} 
</select>
```

##### 3）注解方式传递参数

```java
message = messageMapper.getMessageByAnnotation(2L, "1001");

public interface MessageMapper { 
    Message getMessageByAnnotation(@Param("id") Long id, @Param("msgId") String msgId); 
}
```

```xml
<select id="getMessageByAnnotation" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} and msg_id = #{msgId} 
</select>
```

##### 4）Java Bean 方式传递参数

```java
Message param = new Message(); 
param.setId(1L); 
param.setMsgId("1000"); 
message = messageMapper.getMessageByMessage(param);

public interface MessageMapper {
    Message getMessageByMessage(Message message);
}
```

```xml
<select id="getMessageByMessage" parameterType="vo.Message" resultMap="messageResult"> 
     select 
     	<include refid="allColumns"/> 
     from tb_message 
     where id = #{id} 
     and msg_id = #{msgId} 
</select>
```

> 总结：
>
> - 使用 Map 传递参数：
>   => 会导致业务可读性的丧失，后续维护困难，实际工作中应该尽量避免使用这种方式
> - 使用 @Param 注解：
>   => 如果参数 <= 5时，是最佳的传参方式，比 JavaBean 更直观，但是如果参数多，那么会造成接口参数膨胀，可读性和维护性差。
> - 使用 Java Bean 方式：
>   => 当参数个数 > 5时，建议采用这种方式。

#### 3、insert | 插入

##### 1）普通插入 | 主键不回填

```xml
<insert id="insert" parameterType="message" keyProperty="id"> 
    insert into tb_message(<include refid="updateAllColumns"/>) 
    values (#{msgId}, #{status}, #{content}, #{deleted}, #{createTime}) 
</insert>
```

##### 2）主键回填 | useGeneratedKeys="true"

```xml
<insert id="insertAndGetIdBack" parameterType="message" keyProperty="id" useGeneratedKeys="true"> 
    insert into tb_message(<include refid="updateAllColumns"/>) 
    values (#{msgId}, #{status}, #{content}, #{deleted}, #{createTime}) 
</insert>
```

#### 4、update | 更新

```java
messageMapper.updateContentById(1L, "bbbb");
sqlSession.commit();

int updateContentById(@Param("id") Long id, @Param("content") String content);
```

```xml
<update id="updateContentById" parameterType="message"> 
    update tb_message 
    set content=#{content} 
    where id=#{id} 
</update>
```

#### 5、delete | 删除

```java
messageMapper.delById(28L); 
sqlSession.commit();

int delById(@Param("id") Long id);
```

```xml
<delete id="delById" parameterType="long"> 
    delete from tb_message where id = #{id} 
</delete>
```

#### 6、${} 与 #{} | 防止sql注入

1. 简单的说就是，`#{}` 是经过预编译的，属于占位符的作用，参数赋值时只会替换掉占位符，由于 SQL 格式在编译时已经确认，所以无论参数怎么传，都是安全的。
2. 而 `${}` 是未经过预编译的，仅仅是取变量的值，属于字符串 append 添加，可能会追加新的 SQL，是非安全的，存在 SQL 注入的风险。
3. 因此，在编写 mybatis 的映射语句时，尽量采用 `#{}`  的格式。

##### 1）#{} 方式

```xml
<select id="getMessageByMsgId" resultMap="messageResult">
    select 
    	<include refid="allColumns"/> 
    from tb_message where msg_id = #{msgId} 
</select>
```

```java
// 结果输出与结论：所以，#{}采用的是，预编译的方式，去构建查询语句
Preparing: select id, msg_id, status, content, deleted, create_time, update_time from tb_message where msg_id = ? 
==> Parameters: 1001(String)
```

##### 2）${} 方式

```xml
<select id="getMessageByMsgId" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where msg_id = ${msgId} 
</select>
```

```java
// 结果输出与结论：所以，${}方式采用的是，值传递的方式，去构建查询语句，存在SQL注入的风险
Preparing: 
select id, msg_id, status, content, deleted, create_time, update_time from tb_message where msg_id = 1001
```

#### 7、结果集处理

##### 1）使用 Map 存储结果集

```java
Map map = messageMapper.getMessageMapById(2L);
```

```xml
<select id="getMessageMapById" resultType="map"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} 
</select>
```

##### 2）使用 POJO 存储结果集

```java
Message message = messageMapper.getMessageById(2L);
```

```xml
<resultMap id="messageResult" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
</resultMap>

<select id="getMessageById" resultMap="messageResult">
    select
    <include refid="allColumns"/>
    from tb_message where id = #{id}
</select>
```

#### 8、级联查询

##### 1）一对一 | association

```java
Message message = messageMapper.getMessageAndMessageDetailById(2L);

Message getMessageAndMessageDetailById(@Param("id") Long id);
```

```xml
<resultMap id="messageAndDetailResult" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
    <association column="msg_id" property="messageDetail" select="mapper.MessageDetailMapper.getMessageByMsgId"/>
</resultMap>

<select id="getMessageByMsgId" resultMap="msgDetailResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message_detail where msg_id = #{msgId} 
</select>
```

##### 2）一对一 | 多参数关联

```java
Message message = messageMapper.getMessageAndMessageDetailById1(2L);

Message getMessageAndMessageDetailById1(@Param("id") Long id);
MessageDetail getMessageByMsgIdAndCreateTime(@Param("msgId") String msgId, @Param("content") String content);
```

```xml
<resultMap id="messageAndDetailResult1" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
    <association column="{msgId=msg_id, content=content}" property="messageDetail"
                 select="mapper.MessageDetailMapper.getMessageByMsgIdAndCreateTime"/>
</resultMap>

<select id="getMessageAndMessageDetailById1" parameterType="long" resultMap="messageAndDetailResult1">
    select
    <include refid="allColumns"/>
    from tb_message where id = #{id}
</select>
```

##### 3）一对多 | collection

```java
User getUserAndContactById(@Param("id") Long id);
```

```xml
<resultMap id="userContactResultMap" type="vo.User">
    <id column="id" property="id"/>
    <result column="name" property="name"/>
    <result column="age" property="age"/>
    <collection column="id" property="userContacts" select="mapper.UserContactMapper.getUserContactByUserId"/>
</resultMap>

<select id="getUserAndContactById" parameterType="long" resultMap="userContactResultMap">
    select id, name, age from tb_user where id = #{id}
</select>
```

#### 9、缓存

##### 1）一级缓存

MyBatis 默认开启一级缓存，即：同一个 SqlSession 对象，调用同一个 Mapper 的方法时，如果没有声明需要刷新，并且缓存没超时的情况下，一般只执行一次 SQL，其他的查询 SqlSession 都只会取出当前缓存的数据。如下所示：

```java
public class CacheExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = SqlSessionFactoryUtil.openSqlSession();
        UserMapper userMapper = sqlSession.getMapper(UserMapper.class);

        User user1 = userMapper.getUserById(1L);
        System.out.println("----真实查询-----user1 = " + user1);

        //当使用二级缓存的时候，只有调用了commit方法后才会生效。
        sqlSession.commit();

        User user2 = userMapper.getUserById(1L);
        System.out.println("----缓存查询-----user2 = " + user2);

        /**
         * 开启了新的sqlSession，则无法利用一级缓存。因为一级缓存是sqlSession之间隔离的。
         */
        sqlSession = SqlSessionFactoryUtil.openSqlSession();
        userMapper = sqlSession.getMapper(UserMapper.class);
        User user3 = userMapper.getUserById(1L);
        System.out.println("----真实查询-----user3 = " + user3);
    }
}
```

输出如下：

```java
Created connection 1071097621. Returned connection 1071097621 to pool. Cache Hit Ratio [mapper.UserMapper]: 0.0 Opening JDBC
Connection Checked out connection 1071097621 from pool. Setting autocommit to false on JDBC Connection
[com.mysql.cj.jdbc.ConnectionImpl@3fd7a715] 
==> Preparing: select id, name, age from tbuser where id = ? ==> Parameters: 1(Long) 
<== Columns: id, name, age 
<== Row: 1, muse1, 22 
<== Total: 1 ----真实查询-----user1 = User{id=1, name='muse1', age=22, userContacts=null}
Cache Hit Ratio [mapper.UserMapper]: 0.0 ----缓存查询-----user2 = User{id=1, name='muse1', age=22, userContacts=null} 
Cache Hit Ratio
[mapper.UserMapper]: 0.0 Opening JDBC Connection Created connection 280265505. Setting autocommit to false on JDBC Connection
[com.mysql.cj.jdbc.ConnectionImpl@10b48321] 
==> Preparing: select id, name, age from tbuser where id = ? ==> Parameters: 1(Long) <== Columns: id, name, age 
<== Row: 1, muse1, 22 
<== Total: 1 ----真实查询-----user3 = User{id=1, name='muse1', age=22, userContacts=null}
Process finished with exit code 0
```

##### 2）二级缓存

在 UserMapper.xml 中添加标签，当使用二级缓存的时候，只有调用了 `sqlSession.commit();` 方法后才会生效，且 POJO 必须实现 Serializable 接口。使用方式：

```xml
<mapper namespace="mapper.UserMapper">
	<!-- UserMapper开启二级缓存 -->
	<cache/>
</mapper>
```

##### 3）自定义缓存

可以通过实现 `org.apache.ibatis.cache.Cache` 接口，使用 Redis，Memcache 等缓存机制，来实现自定义缓存。使用方式：

```xml
<mapper namespace="mapper.UserMapper">
	<!-- UserMapper开启二级缓存 -->
	<cache type="com.muse.RedisCache"/>
</mapper>
```

#### 10、动态 SQL

##### 1）if

最常用的判断语句：

```java
public interface UserMapper { 
    User getUserByUser(User user);
}
```

```xml
<select id="getUserByUser" parameterType="vo.User" resultMap="userResultMap"> 
    select id, name, age 
    from tb_user
    where 1=1 
    <if test="id != null"> 
        and id = #{id} 
    </if> 
    <if test="name != null and name != ''">
        and name = #{name}
    </if> 
    <if test="age != null"> 
        and age = #{age} 
    </if> 
</select>
```

##### 2）choose、when、otherwise

相当于 if-if else-else：

```java
User userParam = new User();
userParam.setName("muse1"); 
// userParam.setId(1L); 
userParam.setAge(22);
User user = userMapper.getUserByUser2(userParam);
System.out.println("user = " + user);

public interface UserMapper { 
    User getUserByUser2(User user); 
}
```

```xml
<select id="getUserByUser2" parameterType="vo.User" resultMap="userResultMap">
    select id, name, age
    from tb_user
    where 1=1
    <choose>
        <when test="id != null">
            and id = #{id}
        </when>
        <when test="name != null and name != ''">
            and name = #{name}
        </when>
        <otherwise>
            and age is not null
        </otherwise>
    </choose>
</select>
```

##### 3）where

可以通过标签，来避免去写 where 1=1。如下所示：

```java
User userParam = new User(); 
userParam.setId(1L);
List<User> user = userMapper.getUserByUser3(userParam); System.out.println("user = " + user);

// 指定ID的输出结果：
==> Preparing: select id, name, age from tb_user WHERE id = ? 
==> Parameters: 1(Long) 
<== Columns: id, name, age <== Row: 1, muse1, 22
<== Total: 1 user = [User{id=1, name='muse1', age=22, userContacts=null}]
```

```java
User userParam = new User(); 
// userParam.setId(1L);
List<User> user = userMapper.getUserByUser3(userParam);
System.out.println("user = " + user);

// 不指定ID的输出结果：
==> Preparing: select id, name, age from tb_user
==> Parameters: 
<== Columns: id, name, age 
<== Row: 1, muse1, 22 <== Row: 2, muse2, 24 
<== Total: 2 user = [User{id=1, name='muse1', age=22, userContacts=null}, User{id=2, name='muse2', age=24, userContacts=null}]
```

```xml
<select id="getUserByUser3" parameterType="vo.User" resultMap="userResultMap">
    select
    id, name, age from tb_user
    <where>
        <if test="id != null">
            and id = #{id}
        </if>
    </where>
</select>
```

##### 4）trim

有时候，要去掉一些特殊的 SQL 语法，比如 and、or。则可以使用 trim 标签。

```xml
<select id="getUserByUser4" parameterType="vo.User" resultMap="userResultMap">
    select id, name, age 
    from tb_user 
    <trim prefix="where" prefixOverrides="and">
        and id = #{id} 
    </trim> 
</select>
```

【解释】

- prefix，表示输出前缀语句 where。
- prefixOverrides，表示 where 后面的语句的前缀（第一个）and，要清除掉。

##### 5）set

set 标签会默认把最后一个逗号去掉：

```xml
<update id="updateUserByUser" parameterType="vo.User"> 
    update tb_user
    <set> 
        <if test="name != null and name != ''"> name = #{name}, </if>
        <if test="age != null"> age = #{age}, </if>
    </set> 
    where id = #{id} 
</update>
```

也可以采用 trim 的方式：

```xml
<update id="updateUserByUser" parameterType="vo.User"> 
    update tb_user 
    <trim prefix="set" suffixOverrides=","> 
        <if test="name != null and name != ''"> name = #{name}, </if> 
        <if test="age != null"> age = #{age}, </if> 
    </trim>
    where id = #{id}
</update>
```

##### 6）foreach

foreach 语句，用于循环遍历传入的集合数据：

```java
public interface UserMapper {
    List<User> getUserByIds(@Param("idList") List<Long> idList);
}
```

```xml
<select id="getUserByIds" resultMap="userResultMap">
    select id, name, age 
    from tb_user where id in 
    <foreach collection="idList" index="index" item="id" open="(" separator="," close=")"> 
        #{id} 
    </foreach> 
</select>
```

【解释】

- collection：传递进来的参数名称，可以是数组、List、Set等集合。
- index：当前元素在集合的下标位置。
- item：循环中当前的元素。
- open和close：使用什么符号包装集合元素。
- separator：每个元素的间隔符号。

##### 7）test

test 属性用于条件判断的语句中。

```xml
<select id="getUserByUser3" parameterType="vo.User" resultMap="userResultMap"> 
    select id, name, age 
    from tb_user 
    <where> 
        <if test="id != null"> and id = #{id} </if> 
    </where> 
</select>
```

##### 8）bind

bind 用于优化重复的 SQL 字段模板：

```java
List<User> users = userMapper.getUserByName("muse");

List<User> getUserByName(@Param("name") String name);

// 输出结果：
==> Preparing: select id, name, age from tb_user where name like ? ==> Parameters: %muse%(String) 
<== Columns: id, name, age 
<== Row: 1, muse, 22 
<== Row: 2, muse2, 24 
<== Total: 2
```

```xml
<select id="getUserByName" parameterType="string" resultMap="userResultMap"> 
    <bind name="namePattern" value="'%' + name + '%'"/> 
    select id, name, age from tb_user 
    where name like #{namePattern} 
    <!-- 等于name like concat('%', #{name}, '%') --> 
</select>
```

### 1.6. Java 动态代理？

#### 1、反射

```java
public class Reflaction { 
    public static void main(String[] args) throws Throwable { 
        Class clazz = User.class; 
        User user = (User) clazz.newInstance();
        Method method = clazz.getMethod("setName", String.class); 
        method.invoke(user, "张三");
        System.out.println(user.getName()); // 输出：张三 
    }
}
```

#### 2、JDK 动态代理

JDK 动态代理，需要提供接口，而 MyBatis 的 Mapper 就是一个接口，它采用的就是 JDK 动态代理。如下所示：

```java
public interface MessageService { 
    void sendMessage(); 
}

public class MessageServiceImpl implements MessageService {
    public void sendMessage() {
        System.out.println("MessageServiceImpl.sendMessage"); 
    } 
}
```

```java
public class JdkProxy<T> implements InvocationHandler {

    T target;

    public T getProxy(T target) {
        this.target = target;

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理拦截开始！");
        Object result =  method.invoke(target, args);
        System.out.println("JDK动态代理拦截结束！");
        return result;
    }
}
```

```java
public class Executer {
    public static void main(String[] args) {
        JdkProxy<MessageService> jdkProxy = new JdkProxy();
        MessageService messageService = jdkProxy.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

#### 3、CGLIB 动态代理

CGLIB，不需要提供接口，即可实现动态代理，当然，它也可以代理有接口的服务类。如下所示：

```java
public class PlayService {
    public void play() {
        System.out.println("PlayService.play");
    }
}
```

```java
public class CglibProxy<T> implements MethodInterceptor {

    T target;

    public T getProxy(T target) {
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return (T) enhancer.create();
    }

    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理拦截开始!");
        Object result = methodProxy.invokeSuper(o, objects);
        System.out.println("CGLIB动态代理拦截结束!");
        return result;
    }
}
```

```java
public class Executer {
    public static void main(String[] args) {
        CglibProxy<PlayService> cglibProxy = new CglibProxy();
        
        // 代理无接口服务类
        PlayService playService = cglibProxy.getProxy(new PlayService());
        playService.play();

//        CglibProxy<MessageService> cglibProxy1 = new CglibProxy();
//        // 代理有接口服务类
//        MessageService messageService = cglibProxy1.getProxy(new MessageServiceImpl());
//        messageService.sendMessage();
    }
}
```

### 1.7. MyBatis 整体架构？

![1647161327867](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647161327867.png)

MyBatis 的整体架构分为三层：

1. **API接口层**：
   - 提供给外部使用的接口 API，开发人员通过这些本地 API 来操纵数据库。
   - 接口层一接收到调用请求，就会调用数据处理层来完成具体的数据处理。
2. **数据处理层**：
   - 负责具体的 SQL 查找、SQL 解析、SQL 执行和执行结果映射处理等。
   - 其主要的目的是，根据调用的请求完成一次数据库操作。
3. **基础支撑层**：
   - 负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理。
   - 这些都是共用的东西，将他们抽取出来作为最基础的组件，为上层的数据处理层提供最基础的支撑。

### 1.8. MyBatis SqlSession 执行流程？

#### 1、获取 Mapper 的动态代理

1. 自定义的 Mapper 接口想要发挥功能，必须有具体的实现类，在 MyBatis 中是通过为 Mapper 每个接口提供一个动态代理。
2. 动态代理类来实现的整个过程主要有四个类：MapperRegistry、MapperProxyFactory、MapperProxy、MapperMethod。
   - **MapperRegistry**：是 Mapper 接口及其对应的代理对象工厂的注册中心。
   - **MapperProxyFactory**：是 MapperProxy 的工厂类，主要方法就是包装了 Java 动态代理 `Proxy.newProxyInstance()` 方法。
   - **MapperProxy**：是一个动态代理类，实现了 `InvocationHandler` 接口，对于代理对象的调用都会被代理到 `InvocationHandler#invoke()` 方法上。
   - **MapperMethod**：包含了具体增删改查方法的实现逻辑。

```java
public class UserExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = null;
        try {
            sqlSession = SqlSessionFactoryUtil.openSqlSession();
            // 1、获取 Mapper 的动态代理
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            User user = userMapper.getUserById(2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        }
    }
}

public class DefaultSqlSession implements SqlSession {
    @Override
    public <T> T getMapper(Class<T> type) {
        // 2、获取 Mapper 的动态代理
        return configuration.<T>getMapper(type, this);
    }
}

public class Configuration {
    public <T> T getMapper(Class<T> type, SqlSession sqlSession) {
        // 3、获取 Mapper 的动态代理
        return mapperRegistry.getMapper(type, sqlSession);
    }
}

public class MapperRegistry {
    /**
      * 4、加载mybatis-config.xml配置的<mapper>配置，根据指定type，查找对应的MapperProxyFactory对象
      **/
    // eg1: 获得UserMapper的mapperProxyFactory
    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);
    
    /**
      * 5、如果没配置<mapper>，则找不到对应的MapperProxyFactory，抛出BindingException异常
      */
    if (mapperProxyFactory == null) {
        throw new BindingException("Type " + type + " is not known to the MapperRegistry.");
    }
    
    try {
        /** 6、使用该工厂类生成MapperProxy的代理对象 */
        return mapperProxyFactory.newInstance(sqlSession);
    } catch (Exception e) {
        throw new BindingException("Error getting mapper instance. Cause: " + e, e);
    }
}

public class MapperProxyFactory<T> {

    public T newInstance(SqlSession sqlSession) {
        /**
         * 7、创建MapperProxy对象，每次调用都会创建新的MapperProxy对象，MapperProxy implements InvocationHandler
         */
        final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);
        return newInstance(mapperProxy);
    }
    
   protected T newInstance(MapperProxy<T> mapperProxy) {
        // 8、通过动态代理，创建mapperInterface的代理类对象
        return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] {mapperInterface}, mapperProxy);
    }
}
```

#### 2、获得 MapperMethod 对象

```java
public class UserExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = null;
        try {
            sqlSession = SqlSessionFactoryUtil.openSqlSession();
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            // 1、发起方法调用，调用代理对象增强后的方法
            User user = userMapper.getUserById(2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        }
    }
}

public class MapperProxy<T> implements InvocationHandler, Serializable {
    // eg1: UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
    //      User user = userMapper.getUserById(2L); args = {2L}
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        try {
            /** 2、如果被代理的方法是Object类的方法，如toString()、clone()，则不进行代理 */
            // eg1: method.getDeclaringClass()==interface mapper.UserMapper  由于被代理的方法是UserMapper的getUserById方法，而不是Object的方法，所以返回false
            if (Object.class.equals(method.getDeclaringClass())) {
                return method.invoke(this, args);
            }

            /** 3、如果是接口中的default方法，则调用default方法 */
            else if (isDefaultMethod(method)) { // eg1: 不是default方法，返回false
                return invokeDefaultMethod(proxy, method, args);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.unwrapThrowable(t);
        }
        
        // eg1: method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
        /** 4、初始化一个MapperMethod并放入缓存中 或者 从缓存中取出之前的MapperMethod */
        final MapperMethod mapperMethod = cachedMapperMethod(method);

        // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
        /** 99、调用MapperMethod.execute()方法执行SQL语句 */
        return mapperMethod.execute(sqlSession, args);
    }
    
    // eg1: public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
    private MapperMethod cachedMapperMethod(Method method) {
        /**
         * 5、在缓存中查找MapperMethod，若没有，则创建MapperMethod对象，并添加到methodCache集合中缓存
         */
        // eg1: 因为methodCache为空，所以mapperMethod等于null
        MapperMethod mapperMethod = methodCache.get(method);
        if (mapperMethod == null) {
            // eg1: 6、构建mapperMethod对象，并维护到缓存methodCache中
            mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration());
            // eg1: method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
            methodCache.put(method, mapperMethod);
        }
        return mapperMethod;
    }
}

public class MapperMethod {
    // eg1: 7、mapperInterface = interface mapper.UserMapper
    //      method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
    public MapperMethod(Class<?> mapperInterface, Method method, Configuration config) {
        this.command = new SqlCommand(config, mapperInterface, method);
        this.method = new MethodSignature(config, mapperInterface, method);
    }
}
```

#### 3、根据 SQL 指令跳转执行语句

```java
public class MapperProxy<T> implements InvocationHandler, Serializable {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
      	...
        // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
        /** 1、调用MapperMethod.execute()方法执行SQL语句 */
        return mapperMethod.execute(sqlSession, args);
    }
}

public class MapperMethod {
    /**
     * 2、MapperMethod采用命令模式运行，根据上下文跳转，它可能跳转到许多方法中。实际上它最后就是通过SqlSession对象去运行对象的SQL。
     */
    // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
    public Object execute(SqlSession sqlSession, Object[] args) {
        Object result;
        // eg1: command.getType() = SELECT
        switch (command.getType()) {
            case INSERT: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.insert(command.getName(), param));
                break;
            }
            case UPDATE: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.update(command.getName(), param));
                break;
            }
            case DELETE: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.delete(command.getName(), param));
                break;
            }
            case SELECT:
                // eg1: method.returnsVoid() = false  method.hasResultHandler() = false
                if (method.returnsVoid() && method.hasResultHandler()) {
                    executeWithResultHandler(sqlSession, args);
                    result = null;
                } else if (method.returnsMany()) { // eg1: method.returnsMany() = false
                    result = executeForMany(sqlSession, args);
                } else if (method.returnsMap()) { // eg1: method.returnsMap() = false
                    result = executeForMap(sqlSession, args);
                } else if (method.returnsCursor()) { // eg1: method.returnsCursor() = false
                    result = executeForCursor(sqlSession, args);
                } else {
                    // eg1: args = {2L}
                    /** 3、将参数转换为sql语句需要的入参 */
                    Object param = method.convertArgsToSqlCommandParam(args);

                    // eg1: sqlSession=DefaultSqlSession  command.getName()="mapper.UserMapper.getUserById" param={"id":2L, "param1":2L}
                    /** 4、执行sql查询操作 */
                    result = sqlSession.selectOne(command.getName(), param);
                }
                break;
            case FLUSH:
                result = sqlSession.flushStatements();
                break;
            default:
                ...
        }
        return result;
    }
}
```

#### 4、查询前的缓存处理

```java
public class MapperMethod {
    public Object execute(SqlSession sqlSession, Object[] args) {
        ...
        // 1、执行sql查询操作
        result = sqlSession.selectOne(command.getName(), param);
        ...
    }
}

public class DefaultSqlSession implements SqlSession {
    // 2、eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <T> T selectOne(String statement, Object parameter) {
        List<T> list = this.selectList(statement, parameter);
        if (list.size() == 1) {
            return list.get(0);
        } else if (list.size() > 1) {
            throw new TooManyResultsException(
                    "Expected one result (or null) to be returned by selectOne(), but found: " + list.size());
        } else {
            return null;
        }
    }
    
    // 3、eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <E> List<E> selectList(String statement, Object parameter) {
        return this.selectList(statement, parameter, RowBounds.DEFAULT);
    }
    
    // eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {
        try {
            // 4、eg1: statement="mapper.UserMapper.getUserById"
            MappedStatement ms = configuration.getMappedStatement(statement);
            // 5、eg1: executor=CachingExecutor
            //      wrapCollection(parameter)=parameter={"id": 2L, "param1", 2L}
            //      rowBounds=RowBounds.DEFAULT=new RowBounds()
            //      Executor.NO_RESULT_HANDLER=null
            return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
        } catch (Exception e) {
            throw ExceptionFactory.wrapException("Error querying database.  Cause: " + e, e);
        } finally {
            ErrorContext.instance().reset();
        }
    }
}

public class CachingExecutor implements Executor {
    // 6、eg1: parameterObject={"id":2L, "param1":2L}
    //      rowBounds=new RowBounds()
    //      resultHandler=null
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
        // eg1: parameterObject = {"id":2L, "param1":2L}
        /** 7、获得boundSql对象，承载着sql和对应的参数*/
        BoundSql boundSql = ms.getBoundSql(parameterObject);

        // eg1: parameterObject = {"id":2L, "param1":2L}  rowBounds = new RowBounds()
        /** 8、生成缓存key */
        CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql);

        // eg1: parameterObject = {"id":2L, "param1":2L}  rowBounds = new RowBounds() resultHandler = null
        /** 9、执行查询语句 */
        return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
    
    // 10、eg1: parameterObject = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds,
                             ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        Cache cache = ms.getCache();
        // eg1: cache = null
        /** 11、如果在UserMapper.xml配置了<cache/>开启了二级缓存，则cache不为null*/
        if (cache != null) {
            /**
             * 如果flushCacheRequired=true并且缓存中有数据，则先清空缓存
             *
             * <select id="save" parameterType="XXXXXEO" statementType="CALLABLE" flushCache="true" useCache="false">
             *     ……
             * </select>
             * */
            flushCacheIfRequired(ms);

            /** 12、如果useCache=true并且resultHandler=null*/
            if (ms.isUseCache() && resultHandler == null) {
                ensureNoOutParams(ms, parameterObject, boundSql);
                @SuppressWarnings("unchecked")
                List<E> list = (List<E>) tcm.getObject(cache, key);
                if (list == null) {
                    /** 13、执行查询语句 */
                    list = delegate.<E>query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
                    /** 14、以cacheKey为主键，将结果维护到缓存中 */
                    tcm.putObject(cache, key, list); // issue #578 and #116
                }
                return list;
            }
        }
        // 15、如果没有开启二级缓存，则走这里
        // eg1: delegate = SimpleExecutor(BaseExecutor) parameterObject = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
        return delegate.<E>query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
}

public abstract class BaseExecutor implements Executor {
    // 16、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @SuppressWarnings("unchecked")
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                             CacheKey key, BoundSql boundSql) throws SQLException {
        ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId());
        // 17、eg1: closed = false
        if (closed) {
            throw new ExecutorException("Executor was closed.");
        }

        // eg1: queryStack = 0  ms.isFlushCacheRequired() = false
        /** 18、如果配置了flushCacheRequired=true并且queryStack=0（没有正在执行的查询操作），则会执行清空缓存操作*/
        if (queryStack == 0 && ms.isFlushCacheRequired()) {
            clearLocalCache();
        }

        List<E> list;
        try {
            /** 19、记录正在执行查询操作的任务数*/
            queryStack++; // eg1: queryStack=1

            // eg1: resultHandler=null localCache.getObject(key)=null
            /** 20、localCache维护一级缓存，试图从一级缓存中获取结果数据，如果有数据，则返回结果；如果没有数据，再执行queryFromDatabase */
            list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;
            // eg1: list = null
            if (list != null) {
                /** 21、如果是执行存储过程 */
                handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
            } else {
                // eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
                list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
            }
        } finally {
            queryStack--;
        }
        if (queryStack == 0) {
            /** 22、延迟加载处理 */
            for (DeferredLoad deferredLoad : deferredLoads) {
                deferredLoad.load();
            }
            // issue #601
            deferredLoads.clear();

            // eg1: configuration.getLocalCacheScope()=SESSION
            /** 23、如果设置了<setting name="localCacheScope" value="STATEMENT"/>，则会每次执行完清空缓存。即：使得一级缓存失效 */
            if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
                // issue #482
                clearLocalCache();
            }
        }
        return list;
    }
    
    @Override
    public void clearLocalCache() {
        if (!closed) {
            localCache.clear();
            localOutputParameterCache.clear();
        }
    }
}
```

#### 5、执行 DB 查询操作

Mapper执行的过程是通过 Executor、StatementHandler、ParameterHandler 和 ResultHandler 来完成数据库操作和结果返回的：

1. **Executor**：
   - 1）代表执行器，由它来调度 StatementHandler、ParameterHandler、ResultHandler 等来执行对应的SQL。
   - 2）执行器 Executor 是一个真正执行执行 Java 和数据库交互的类，一共有 3 种执行器，可以在MyBatis 的配置文件中，设置 defaultExecutorType 属性来进行选择：
     1. **SIMPLE**：org.apache.ibatis.executor.SimpleExecutor，简易执行器，默认执行器。
     2. **REUSE**：org.apache.ibatis.executor.ReuseExecutor，是一种执行器重用预处理语句。
     3. **BATCH**：org.apache.ibatis.executor.BatchExecutor，执行器重用语句和批量更新，它是针对批量专用批量专用的执行器。
2. **StatementHandler**：
   - 1）作用是使用数据库的 Statement（PreparedStatement）执行操作，起到承上启下的作用，专门处理数据库会话的，创建 StatementHandler 的过程在 Configuration 中。
   - 2）MyBatis 是使用来委派模式，把具体的 StatementHandler 类型隐藏起来，通过 `RoutingStatementHandler` 来统一管理，一共用三种具体的StatementHandler类型：
     SimpleHandler、PreparedStatementHandler 和 CallableStatementHandler。
   - 3）在 Executor 的具体执行逻辑中，主要关注 `StatementHandler#prepared` 和 `StatementHandler#parameterize` 两个方法。
3. **ParameterHandler**：
   - 1）用于SQL对参数的处理。
   - 2）MyBatis 是通过 ParameterHandler 对预编译的语句进行参数设置的。
   - 3）MyBatis 为 ParameterHandler 提供了一个实现类 DefaultParameterHandler，具体执行过程是：
     1. 从 parameterObject 对象中取参数。
     2. 然后使用 typeHandler 进行参数处理。
     3. 而 typeHandler 也是在 MyBatis 初始化时，注册在 Configuration 里面的，需要时可以直接拿来用。
4. **ResultHandler**：
   - 1）进行最后数据集（ResultSet）的封装返回处理。
   - 2）MyBatis 为我们提供了一个 DefaultResultSetHandler 类，在默认情况下，都是通过这个类进行处理的。
   - 3）这个类 JAVASSIST 或者 CGLIB 作为延迟加载，然后通过 typeHandler 和 ObjectFactory 进行组装结果再返回。

=> 以 SimpleExecutor 来看一下 Executor 的**具体执行逻辑**：

1. 根据 Configuration 来构建 StatementHandler。
2. 然后使用 `prepareStatement` 方法，对 SQL 编译并对参数进行初始化。
3. 在 `prepareStatement` 方法中，调用了 `StatementHandler#prepared` 进行了预编译和基础设置。
4. 然后通过 `StatementHandler#parameterize` 来设置参数并执行。
5. 包装好的 Statement 通过 StatementHandler 来执行，并把结果传递给 resultHandler。

```java
public abstract class BaseExecutor implements Executor {
    @SuppressWarnings("unchecked")
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                             CacheKey key, BoundSql boundSql) throws SQLException {
        ...
        // 1、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
        ...
    }
    
    // 2、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    private <E> List<E> queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds,
                                          ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        List<E> list;
        // 3、eg1: key = -445449180:-48278933:mapper.UserMapper.getUserById:0:2147483647:select id, name, age from tb_user where id = ?:2:dev
        localCache.putObject(key, EXECUTION_PLACEHOLDER);
        try {
            // 4、eg1: SimpleExecutor.doQuery parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
            list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
        } finally {
            localCache.removeObject(key);
        }
        /** 99、将查询结果放到一级缓存中，如果同一session中有相同查询操作，则可以直接从缓存中获取结果*/
        localCache.putObject(key, list);

        // eg1: ms.getStatementType() = PREPARED
        if (ms.getStatementType() == StatementType.CALLABLE) {
            localOutputParameterCache.putObject(key, parameter);
        }
        return list;
    }
}

public class SimpleExecutor extends BaseExecutor {
    // 5、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @Override
    public <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                               BoundSql boundSql) throws SQLException {
        Statement stmt = null;
        try {
            Configuration configuration = ms.getConfiguration();
            /** 6、根据Configuration来构建StatementHandler */
            StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds,
                    resultHandler, boundSql);

            // eg1: handler=RoutingStatementHandler
            /** 7、然后使用prepareStatement方法，对SQL进行预编译并设置入参 */
            stmt = prepareStatement(handler, ms.getStatementLog());

            // eg1: handler=RoutingStatementHandler parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
            /** 21、开始执行真正的查询操作。将包装好的Statement通过StatementHandler来执行，并把结果传递给resultHandler */
            return handler.<E>query(stmt, resultHandler);
        } finally {
            closeStatement(stmt);
        }
    }
    
    /**
     * 使用prepareStatement方法，对SQL编译并设置入参
     *
     * @param handler
     * @param statementLog
     * @return
     * @throws SQLException
     */
    // 8、eg1: handler=RoutingStatementHandler
    private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {
        Statement stmt;

        /** 9、获得Connection实例 */
        Connection connection = getConnection(statementLog);

        // eg1: handler=RoutingStatementHandler
        /** 10、第一步：调用了StatementHandler的prepared进行了【sql的预编译】 */
        stmt = handler.prepare(connection, transaction.getTimeout());

        /** 14、第二步：通过PreparedStatementHandler的parameterize来给【sql设置入参】 */
        handler.parameterize(stmt);

        // 20、eg1: 返回org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
        return stmt;
    }
}

public class RoutingStatementHandler implements StatementHandler {
    // 11、eg1: delegate=PreparedStatementHandler
    @Override
    public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException {
        return delegate.prepare(connection, transactionTimeout);
    }
    
    // 22、eg1: delegate = PreparedStatementHandler  resultHandler = null
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        return delegate.<E>query(statement, resultHandler);
    }
    
    // 15、第二步：通过PreparedStatementHandler的parameterize来给【sql设置入参】
    @Override
    public void parameterize(Statement statement) throws SQLException {
        delegate.parameterize(statement);
    }
}

public abstract class BaseStatementHandler implements StatementHandler {
    // eg1: delegate=PreparedStatementHandler
    /**
     * 12、执行预编译语句
     */
    @Override
    public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException {
        ErrorContext.instance().sql(boundSql.getSql());
        Statement statement = null;
        try {
            // eg1: 13、调用PreparedStatementHandler的instantiateStatement
            statement = instantiateStatement(connection);
            setStatementTimeout(statement, transactionTimeout);
            setFetchSize(statement);
            return statement;
        } catch (SQLException e) {
            closeStatement(statement);
            throw e;
        } catch (Exception e) {
            closeStatement(statement);
            throw new ExecutorException("Error preparing statement.  Cause: " + e, e);
        }
    }
}

public class PreparedStatementHandler extends BaseStatementHandler {
    // 16、eg1: org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
    @Override
    public void parameterize(Statement statement) throws SQLException {
        parameterHandler.setParameters((PreparedStatement) statement);
    }
    
    // 23、eg1: delegate = PreparedStatementHandler  resultHandler = null
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        /** 24、最终还是使用JDBC去进行数据操作 */
        PreparedStatement ps = (PreparedStatement) statement;

        /** 25、执行查询操作 */
        ps.execute();

        // eg1: 封装结果集 resultSetHandler=DefaultResultSetHandler
        /** 26、将结果集进行封装 */
        return resultSetHandler.handleResultSets(ps);
    }
}

public class DefaultParameterHandler implements ParameterHandler {
    // eg1: org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
    /**
     * 17、针对预处理语句，设置入参
     */
    @Override
    public void setParameters(PreparedStatement ps) {
        ErrorContext.instance().activity("setting parameters").object(mappedStatement.getParameterMap().getId());

        // 18、eg1: parameterMappings[0] = ParameterMapping{property='id', mode=IN, javaType=class java.lang.Long, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}
        List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();
        if (parameterMappings != null) {
            ...
            // eg1: typeHandler=BaseTypeHandler
            /** 19、针对预处理语句，设置入参 */
            typeHandler.setParameter(ps, i + 1, value, jdbcType);
            ...
        }
    }
}
```

#### 6、针对 ResultSet 结果集转换为 POJO

```java
public class PreparedStatementHandler extends BaseStatementHandler {
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        ...
        // eg1: 封装结果集 resultSetHandler=DefaultResultSetHandler
        /** 1、将结果集进行封装 */
        return resultSetHandler.handleResultSets(ps);
    }
}

public class DefaultResultSetHandler implements ResultSetHandler {
    
    // 4、eg1: 执行到这里
    private ResultSetWrapper getFirstResultSet(Statement stmt) throws SQLException {
        // eg1: rs != null
        /** 5、通过JDBC获得结果集ResultSet */
        ResultSet rs = stmt.getResultSet();
        while (rs == null) {
            if (stmt.getMoreResults()) {
                rs = stmt.getResultSet();
            } else {
                /**
                 * 6、getUpdateCount()==-1,既不是结果集,又不是更新计数了.说明没的返回了。
                 * 如果getUpdateCount()>=0,则说明当前指针是更新计数(0的时候有可能是DDL指令)。
                 * 无论是返回结果集或是更新计数,那么则可能还继续有其它返回。
                 * 只有在当前指指针getResultSet()==null && getUpdateCount()==-1才说明没有再多的返回。
                 */
                if (stmt.getUpdateCount() == -1) {
                    // no more results. Must be no resultset
                    break;
                }
            }
        }
        // eg1: rs不为空，则将结果集封装到ResultSetWrapper中
        /** 7、将结果集ResultSet封装到ResultSetWrapper实例中 */
        return rs != null ? new ResultSetWrapper(rs, configuration) : null;
    }
    
    /**
     * 2、处理数据库操作的结果集
     */
    // eg1: 执行到这里
    @Override
    public List<Object> handleResultSets(Statement stmt) throws SQLException {
        ErrorContext.instance().activity("handling results").object(mappedStatement.getId());

        final List<Object> multipleResults = new ArrayList<>();
        int resultSetCount = 0;

        /** 3、首先：获得执行后的结果集，并封装到ResultSetWrapper */
        ResultSetWrapper rsw = getFirstResultSet(stmt);

        /** 8、其次：如果rsw != null && resultMapCount < 1，则抛异常ExecutorException */
        List<ResultMap> resultMaps = mappedStatement.getResultMaps();
        int resultMapCount = resultMaps.size(); // eg1: resultMapCount = 1
        validateResultMapsCount(rsw, resultMapCount);

        // eg1: rsw不为空 resultMapCount=1 resultSetCount=0
        /** 9、第三步：处理结果集 */
        while (rsw != null && resultMapCount > resultSetCount) {
            // eg1: ResultMap resultMap=resultMaps.get(0);
            ResultMap resultMap = resultMaps.get(resultSetCount);

            /** 10、处理结果集, 存储在multipleResults中 */
            handleResultSet(rsw, resultMap, multipleResults, null);

            // 33、eg1: rsw=null
            rsw = getNextResultSet(stmt);

            cleanUpAfterHandlingResultSet();
            resultSetCount++; // eg1: 自增后resultSetCount=1
        }

        String[] resultSets = mappedStatement.getResultSets();
        // eg1: 34、resultSets = null
        if (resultSets != null) {
            while (rsw != null && resultSetCount < resultSets.length) {
                ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
                if (parentMapping != null) {
                    String nestedResultMapId = parentMapping.getNestedResultMapId();
                    ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
                    handleResultSet(rsw, resultMap, null, parentMapping);
                }
                rsw = getNextResultSet(stmt);
                cleanUpAfterHandlingResultSet();
                resultSetCount++;
            }
        }

        // eg1: multipleResults.get(0).get(0) = User{id=2, name='muse2', age=24, userContacts=null}
        /** 99、返回结果 */
        return collapseSingleResultList(multipleResults);
    }
    
    // eg1: parentMapping = null
    /**
     * 11、处理结果集
     */
    private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List<Object> multipleResults,
                                 ResultMapping parentMapping) throws SQLException {
        try {
            // eg1: parentMapping = null
            if (parentMapping != null) {
                handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
            } else {
                // eg1: resultHandler = null
                if (resultHandler == null) {
                    // eg1: objectFactory = DefaultObjectFactory defaultResultHandler里面包含了一个空集合的ArrayList实例
                    /** 12、初始化ResultHandler实例，用于解析查询结果并存储于该实例对象中 */
                    DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
                    /** 13、解析行数据 */
                    handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
                    multipleResults.add(defaultResultHandler.getResultList());
                } else {
                    handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
                }
            }
        } finally {
            // eg1：
            /** 关闭ResultSet */
            closeResultSet(rsw.getResultSet());
        }
    }
    
    // 14、eg1: parentMapping = null
    public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler<?> resultHandler,
                                RowBounds rowBounds, ResultMapping parentMapping) throws SQLException {
        // eg1: resultMap.hasNestedResultMaps()=false
        /** 15、是否是聚合Nested类型的结果集 */
        if (resultMap.hasNestedResultMaps()) {
            ensureNoRowBounds();
            checkResultHandler();
            handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        } else {
            // 16、eg1: parentMapping = null
            handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        }
    }
    
    // 17、eg1: parentMapping = null
    private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap,
                                                   ResultHandler<?> resultHandler, RowBounds rowBounds,
                                                   ResultMapping parentMapping) throws SQLException {
        DefaultResultContext<Object> resultContext = new DefaultResultContext<>();

        // eg1: skipRows里面没做什么事情
        /** 18、将指针移动到rowBounds.getOffset()指定的行号，即：略过（skip）offset之前的行 */
        skipRows(rsw.getResultSet(), rowBounds);

        // eg1: shouldProcessMoreRows(resultContext, rowBounds) = true    rsw.getResultSet().next() = true
        while (shouldProcessMoreRows(resultContext, rowBounds) && rsw.getResultSet().next()) {
            /** 23、解析结果集中的鉴别器<discriminate/> */
            ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null);

            /** 24、将数据库操作结果保存到POJO并返回 */
            Object rowValue = getRowValue(rsw, discriminatedResultMap);

            // eg1: rowValue=User{id=2, name='muse2', age=24, userContacts=null}  parentMapping = null
            /** 32、存储POJO对象到DefaultResultHandler中 */
            storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet());
        }
    }
    
    // eg1:
    /**
     * 19、将指针移动到rowBounds.getOffset()指定的行号，即：略过（skip）offset之前的行
     *
     * @param rs
     * @param rowBounds
     * @throws SQLException
     */
    private void skipRows(ResultSet rs, RowBounds rowBounds) throws SQLException {
        // 20、eg1: rs.getType() = 1003 = ResultSet.TYPE_FORWARD_ONLY
        /**
         * ResultSet.TYPE_FORWARD_ONLY          结果集的游标只能向下滚动
         * ResultSet.TYPE_SCROLL_INSENSITIVE    结果集的游标可以上下移动，当数据库变化时，当前结果集不变。
         * ResultSet.TYPE_SCROLL_SENSITIVE      返回可滚动的结果集，当数据库变化时，当前结果集同步改变
         */
        if (rs.getType() != ResultSet.TYPE_FORWARD_ONLY) {
            /** rowBounds.getOffset()不为0 */
            if (rowBounds.getOffset() != RowBounds.NO_ROW_OFFSET) {
                /** 21、将指针移动到此ResultSet对象的给定行编号rowBounds.getOffset()。 */
                rs.absolute(rowBounds.getOffset());
            }
        } else {
            // eg1: rowBounds.getOffset() = 0
            for (int i = 0; i < rowBounds.getOffset(); i++) {
                /** 22、将指针移动到此ResultSet对象的给定行编号rowBounds.getOffset()。 */
                rs.next();
            }
        }
    }
    
    /**
     * 25、将数据库操作结果保存到POJO并返回
     */
    private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException {
        final ResultLoaderMap lazyLoader = new ResultLoaderMap();
        /** 26、创建空的结果对象 */
        Object rowValue = createResultObject(rsw, resultMap, lazyLoader, null);

        // eg1: rowValue=User{id=null, name='null', age=null, userContacts=null}   hasTypeHandlerForResultObject(rsw, resultMap.getType())=false
        if (rowValue != null && !hasTypeHandlerForResultObject(rsw, resultMap.getType())) {
            /** 27、创建rowValue的metaObject */
            final MetaObject metaObject = configuration.newMetaObject(rowValue);

            // eg1: foundValues = useConstructorMappings = false
            boolean foundValues = this.useConstructorMappings;

            // eg1: shouldApplyAutomaticMappings(resultMap, false) = true
            /** 28、是否应用自动映射 */
            if (shouldApplyAutomaticMappings(resultMap, false)) {
                // eg1: applyAutomaticMappings(rsw, resultMap, metaObject, null)=true
                /**
                 * 29、将查询出来的值赋值给metaObject中的POJO对象
                 */
                foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues; // eg1: foundValues=true
            }

            // eg1: foundValues=true
            foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues;

            // eg1: lazyLoader.size()=0   foundValues=true
            foundValues = lazyLoader.size() > 0 || foundValues;

            // 31、eg1: foundValues=true  configuration.isReturnInstanceForEmptyRow()=false
            /** configuration.isReturnInstanceForEmptyRow() 当返回行的所有列都是空时，MyBatis默认返回null。当开启这个设置时，MyBatis会返回一个空实例。*/
            rowValue = (foundValues || configuration.isReturnInstanceForEmptyRow()) ? rowValue : null;
        }
        return rowValue; // eg1: rowValue=User{id=2, name='muse2', age=24, userContacts=null}
    }
    
    // eg1: columnPrefix=null
    private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject,
                                           String columnPrefix) throws SQLException {
        /** 30、创建自动映射 */
        List<UnMappedColumnAutoMapping> autoMapping = createAutomaticMappings(rsw, resultMap, metaObject, columnPrefix);
        boolean foundValues = false;

        // eg1: autoMapping={UnMappedColumnAutoMapping("id", "id", LongTypeHandler@2397, false),
        //                   UnMappedColumnAutoMapping("name", "name", StringTypeHandler@2418, false),
        //                   UnMappedColumnAutoMapping("age", "age", IntegerTypeHandler@2433, false)}
        if (autoMapping.size() > 0) {
            for (UnMappedColumnAutoMapping mapping : autoMapping) {
                // eg1: mapping.column="id"      mapping.typeHandler=LongTypeHandler       value=2L
                // eg1: mapping.column="name"    mapping.typeHandler=StringTypeHandler     value="muse2"
                // eg1: mapping.column="age"     mapping.typeHandler=IntegerTypeHandler    value=24
                final Object value = mapping.typeHandler.getResult(rsw.getResultSet(), mapping.column);
                if (value != null) {
                    // eg1: foundValues = true
                    // eg1: foundValues = true
                    // eg1: foundValues = true
                    foundValues = true;
                }
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                if (value != null || (configuration.isCallSettersOnNulls() && !mapping.primitive)) {
                    // eg1: mapping.property="id"  value=2L
                    // eg1: mapping.property="name"  value="muse2"
                    // eg1: mapping.property="age"  value=24
                    metaObject.setValue(mapping.property, value);
                }
            }
        }
        return foundValues; // eg1: 返回true
    }
}
```

### 1.9. Mybatis 是如何进行分页的？分页插件的原理是什么？

1. Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的**内存分页**，而非物理分页，可以在 sql 内直接书写带有物理分页的参数，来完成物理分页功能，也可以使用分页插件来完成物理分页。
2. 分页插件的基本原理是，使用 Mybatis 提供的插件接口，实现自定义插件，在插件的拦截方法内，拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。
3. 比如，`select * from student`，拦截 sql 后重写为 `select t.* from (select * from student) t limit 0, 10`，从而完成插件分页的功能。

### 2.0. Mybatis 插件运行原理，以及如何编写一个插件？

1. Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这4种接口的插件。
2. Mybatis 使用 JDK 动态代理，为需要拦截的接口生成代理对象，以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 `InvocationHandler#invoke()` 方法，拦截那些指定需要拦截的方法。
3. 具体做法为，实现 `Mybatis#Interceptor#intercept()` 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法，最后在配置文件中，配置所编写的插件即可。

# **十二、分布式篇**

### 1.1. 分布式系统？

1. 分布式系统，是一个硬件或者软件分布在不同的计算机上，彼此之间仅仅通过消息传递，进行通信和协调的系统。
2. 提到分布式架构，就一定绕不开 `一致性` 问题，而 `一致性` 又包含了 `数据一致性` 和 `事务一致性` 两种情况，其解决方案在后面都有给出。

### 1.2. CAP 定理？

1. **CAP 定理**，又叫布鲁尔定理，指的是，在一个分布式系统中，最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）三项中的两项。
   - CAP 的适用场景是副本性数据，业务间的不一致性（比如订单和库存的不一致）不在 CAP 的讨论范畴。
2. **C：一致性（Consistency）**，数据在多个副本中保持一致，可以理解成两个用户访问两个系统 A 和 B，当 A系统数据有变化时，及时同步给 B 系统，让两个用户看到的数据是一致的。
   - 强调的是，对某个读操作，必须保证能够返回最新的写操作结果，要求的是**数据强一致性**，要和弱一致性、最终一致性、缓存一致性、业务一致性区分开来。
   - **保证方案**：分布式一致性算法。
3. **A：可用性（Availability）**，系统对外提供服务必须一直处于可用状态，在任何故障下，客户端都能在合理时间内，获得服务端非错误的响应。
   - 强调的是，对某次请求，必须保证在合理的时间内，返回合理的响应（不是错误和超时的响应），要求的是**返回及时**。
   - **保证方案**：接口高性能相关，比如缓存、限流、降级、熔断。
4. **P：分区容错性（Partition tolerance）**，在分布式系统中，遇到任何网络分区故障，系统仍然能对外提供服务。其中，网络分区是指，由于某些原因，子节点之间的网络出现故障，导致不同的节点分布在不同的子网络中，有可能子网络中只有一个节点，这就是网络分区。
   - 强调的是，当出现网络分区后，系统能够继续履行职责，要求的是**分布式和数据同步**。
   - **保证方案**：集群、日志复制、主从复制。

证明，为什么只能满足其中两个，而不能 3 个都满足：

![1647171096774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647171096774.png)

- 假设，系统 A 和系统 B 是可以通过网络，进行同步数据的。
- 此时，用户 1 和用户 2 分别要访问系统 A 和系统 B，理想情况下，用户 1 访问系统 A 对数据进行修改，将 data1 改成了 data2，同时用户 2 访问系统 B，拿到的数据应该是 data2。
- 但是，由于网络总是不可靠的，涉及网络调用，就需要一一进行分析：
  1. 当网络发生故障时，系统 A 和系统 B 没法进行数据同步，也就是不能满足 P，同时两个系统依然可以访
     问，那么此时其实相当于是单机系统，就不是分布式系统了，因此，对于分布式系统，P 是必须满足的。
  2. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让用户 2 通过系统 B 正确地拿到 data2，那么此时就满足了 C，由于 P 的存在，可能会导致一致性同步的时间无限延长，在同步期间，任何人不能访问系统 B，从而导致系统 B 不可用，以保证数据一致性，此时满足的是 CP。
  3. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让系统 B 能继续提供服务，那么此时，由于 P 的存在，一致性同步可能需要更多的时间，所以只能牺牲掉一致性，接受系统 A 没有将 data2 同步给系统B，此时满足的就是 AP。
- 因此，分布式系统只能同时满足 CAP 定理中其中 2 个，比如注册中心 Eureka 满足的是 AP，并不能保证 C，Zookeeper 保证了 CP，但不满足 A，而在生产中，A 和 C 的选择，没有正确的答案，应该要取决于自己的业务，比如 12306 系统满足 CP，是因为买票必须满足数据的一致性，不然一个座位多卖了，对铁路运输都是不可以接受的。

### 1.3. Base 理论？

由于 CAP 中一致性 C 和可用性 A 无法兼得，eBay 的架构师，提出了 BASE 理论，它是通过牺牲数据的强一致性，来获得可用性，属于对 CAP 中 AP 方案的一个补充，BASE 理论并没有要求数据的强一致性，而是允许数据在一定的时间段内是不一致的，但在最终某个状态会达到一致。

它具有如下 3 种特征：

1. **基本可用**：Basically Available，分布式系统在出现不可预知故障时，允许损失部分可用性，保证核心功能的可用性。
2. **软状态**：Soft state，软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该
   中间状态的存在，不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间，进行数据同步的过程存在延时。
3. **最终一致性**：Eventually consistent，最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是，需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

在生产环境中，很多公司，会采用 BASE 理论来实现数据的一致，因为产品的可用性相比强一致性来说，更加重要。

1. 比如在电商平台中，当用户对一个订单发起支付时，往往会调用第三方支付平台，比如支付宝支付或者微信支付。
2. 调用第三方成功后，第三方并不能及时通知我方系统，在第三方没有通知我方系统的这段时间内，我们给用户的订单状态显示支付中，等到第三方回调之后，我们再将状态改成已支付。
3. 虽然订单状态在短期内存在不一致，但是用户却获得了更好的产品体验。

### 1.4. 分布式数据一致性？

#### 1、数据不一致性产生原因

复制，是导致数据一致性问题的唯一原因。

如果只用一台数据库实例，来处理所有的写入和读取请求，就一定不存在数据一致性的问题。但在中大型项目中，却经常需要将一份数据，存储在超过一台数据库中（即复制），原因有三：

1. **高可用**：即使一部分数据库出现故障，系统也能正常工作。
2. **降低延迟**：使数据与用户在地理上接近。
3. **可扩展性、提高读取吞吐量**：可以扩展处理读请求的机器数量。

这里假设数据集非常小，每台机器的空间都足够保存整个数据集，否则将会引入一个新的话题 `数据分区`。

#### 2、强一致性与弱一致性 | 强弱角度

其实只有两类数据一致性，**强一致性与弱一致性**。

1. **强一致性**：也叫做线性一致性，除此以外，所有其他的一致性都是弱一致性的特殊情况。
2. **弱一致性**：所谓强一致性，即复制是同步的，弱一致性，即复制是异步的。

用户更新网站头像，在某个时间点，用户向主库发送更新请求，不久之后主库就收到了请求。在某个时刻，主库又会将数据变更转发给自己的从库。最后，主库通知用户更新成功。

1. **强一致性举例**：如果在返回“更新成功”并使新头像对其他用户可见之前，主库需要等待从库的确认，确保从库已经收到写入操作，那么复制是同步的，即**强一致性**。
2. **弱一致性举例**：如果主库写入成功后，不等待从库的响应，直接返回“更新成功”，则复制是异步的，即弱一致性。

**优点**：强一致性，可以保证从库有与主库一致的数据。如果主库突然宕机，仍可以保证数据完整。

**缺点**：但如果从库宕机或网络阻塞，主库就无法完成写入操作。

**结论**：

1. 在实践中，通常使一个从库是同步的，而其他的则是异步的。如果这个同步的从库出现问题，则使另一个异步从库同步。
2. 这可以确保永远有两个节点拥有完整数据：主库和同步从库。 这种配置称为**半同步。**

#### 3、最终一致性 | 强弱角度

除了强一致性以外，所有其他的一致性都是弱一致性的特殊情况，最终一致性就是其中一种特例。

- **最终一致性举例**：当用户从异步从库读取时，如果此异步从库落后，他可能会看到过时的信息。

这种不一致只是一个暂时的状态，如果等待一段时间，从库最终会赶上并与主库保持一致吗，这就是最终一致性。

- **最终**：这两个字用得很微妙，反映了从写入主库到同步至从库之间的延迟，可能仅仅是几分之一秒，也可能是几个小时，时延是不确定的。

#### 4、读写一致性 | 读写角度

读写一致性，也称为读己之写一致性。它可以保证，如果用户刷新页面，总会看到自己刚提交的任何更新，虽然不能保证其他用户的写入，他们的更新可能稍等才会看到，但它保证用户自己提交的数据能马上被自己看到。

- **读写不一致性举例**：手机刷虎扑的时候经常遇到，回复某人的帖子然后想马上查看，但我刚提交的回复可能尚未到达从库，看起来好像是刚提交的数据丢失了，很不爽。

如何实现读写一致性？最简单的方案，对于某些特定的内容，都**从主库读**。

- **举例**：知乎个人主页信息只能由用户本人编辑，而不能由其他人编辑。因此，永远从主库读取用户自己的个人主页，从从库读取其他用户的个人主页。

还有一种更好的方法是：

1. 客户端可以在本地记住**最近一次写入的时间戳**，发起请求时带着此时间戳。
2. 从库提供任何查询服务前，需确保该时间戳前的变更都已经同步到了本从库中。
3. 如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来。

#### 5、单调一致性 | 多次读角度

单调读，比强一致性更弱，比最终一致性更强，意味着如果一个用户进行多次读取时，绝对不会遇到时光倒流，即如果先前读取到较新的数据，后续读取不会得到更旧的数据。

- **多次读不一致性举例**：用户在从某从库查询到了一条记录，再次刷新后发现此记录不见了，就像遇到了**时光倒流**。如果用户从不同从库进行多次读取，就可能发生这种情况。

实现单调读取的一种方式是：

1. 确保每个用户总是从**同一个节点**进行读取（不同的用户可以从不同的节点读取）。
2. 比如，可以基于用户 ID 哈希值来选择节点，而不是随机选择节点。

#### 6、因果一致性 | 数据分区角度

数据分区（分片）后，每个节点并不包含全部数据。不同的节点独立运行，不存在全局写入顺序。

1. 如果用户A提交一个问题，用户B提交了回答。
2. 问题写入了节点A，回答写入了节点B。
3. 由于同步延迟，发起查询的用户可能会先看到回答，再看到问题。

为了防止这种异常，需要保证**因果一致性**， 即如果一系列写入按某个逻辑顺序发生，那么任何人读取这些写入时，会看见它们以正确的逻辑顺序出现。

- **解决方案举例**：由应用来保证，将问题和对应的回答写入**相同的分区**。

### 1.5. 分布式一致性算法？

#### 1、背景

1. 分布式系统，对分区容错性的一般解决方案是 `state machine replication` 状态机复制。
2. 分布式一致性算法，本质上就是一种 `state machine replication` 状体机复制的共识算法。
3. 分布式系统，有多个节点就会存在节点间通信的问题，存在着两种节点通讯模型：共享内存（Shared memory）和消息传递（Messages passing）传递模型。
4. 以下谈到的分布式一致性算法，都是基于**消息传递**通讯模型实现的，从而保证在分布式系统中，进程间基于消息传递就某个值达成一致。

#### 2、一致性模型

1. 现阶段工业，有 2 种一致性模型：弱一致性和强一致性。
2. 弱一致性中最主要的是最终一致性，对于**最终一致性**最好的体现是 DNS（Domain Name System） 和 Gossip （Cassandra、Redis 的通信协议）。
3. **强一致性**主要有：同步模型（主从同步）和多数派机制模型（Paxos、Raft、Zab）。

#### 3、同步模型

**基本思想**：

1. Master 接受写请求。
2. Master 复制日志至 Slave。
3. Master 等待，直到所有从库返回后，才响应客户端。

**存在的问题**：任意一个从节点返回失败，都会导致 Master 阻塞，导致整个集群不可用，虽然保证了一致性，但可用性大大降低。

#### 4、多数派模型

**基本思想**：

1. 每次写，都保证写入大于 N / 2 个节点。
2. 每次读，都保证从大于 N / 2 个节点中读。

**相关算法**：

![1647235115496](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235115496.png)

Paxos 算法，是莱斯利 · 兰伯特(Leslie Lamport) 于 1990 年提出的一种基于消息传递的一致性算法，其发展分类有：Basic Paxos、Multi Paxos 和 Fast Paxos，其中工业界用得最多的是 Raft 和 ZAB。

##### 1）Basic Paxos

**算法角色**：

- **Client**： 系统外部角色，请求发起者，像民众。
- **Proposer**： 接受 Client 请求，向集群提出提议（propose），并在冲突发生时，起到冲突调解的作用，像提议员，替民众提出议案。
- **Acceptor**：提议投票和接受者，只有在形成法定人数（Quorum，一般即为 majority 多数派）时，提议才会最终被接受，像国会议员。
- **Learner**：提议接受者，负责 backup 备份工作，对集群一致性没什么影响，像记录员。

![1647235532293](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235532293.png)

**算法阶段**，有 2 个阶段，每个阶段有 2 个分支阶段：

1. **Prepare**：提出一个提案，编号为N，只有 N 大于此 Propser 之前提出的提案编号（全局递增的一种编号）， 请求才会被 Accpetor 的 Quorum 多数派接受。
2. **Promise**：接受发过来的请求，前提是该请求编号 N 大于之前任何提案的编号。
3. **Accept**：如果 Propser  确认达到了多数派，则会发出 Accept 请求，该请求包含提案编号 N 和提案内容。
4. **Accpeted**：如果 Acccetor 集群在此期间，没有收到任何编号还大于 N 的提案，则接受刚刚的提案，否则忽略。

**算法问题**：

1. **活锁问题**：在议案还没有被接受时，如果再出现新议案编号，那么就会不断出现 Prepare + Promise 讨论新提案，而不是 Accept 接受一个提案。
   - **解决方案**：提供一个 random timeout，其他的提案需要等待一段随机时间，才被讨论。
2. **效率较低**：提交提案、接收提案进行了 2 轮的 RPC 操作，效率较低。
3. **实现难度大，且不容易理解**。

![1647235817187](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235817187.png)

##### 2）Multi Paxos

**目的**：为了减少角色，简化步骤。

**解决方案**：

1. 由于 Basic Paxos 存在活锁问题，其根因是多个 Proposer 导致的，所以，Multi Paxos 提出了一个新的概念 -> Leader，Leader 是唯一的 Proposer，所有请求都需经过此 Leader。
2. 由于 Basic Paxos 存在两轮 RPC 导致的效率低下问题，所以，Multi Paxos 则通过 Leader 角色 + 在消息中增加一个随机的 Term 任期，使得两轮 RPC 的情况，只在竞选 Leader （选举）时才出现，其余情况（复制）只需要进行一轮 RPC。

![1647236688258](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647236688258.png)

##### 3）Raft

Raft，可以认为是比 Multi Paxos 更简单的一致性算法。

其**算法角色**有：

1. **Leader**：主节点，整个集群只有一个 Leader，所有的写请求都通过 Leader 发送给 Follower。
   - **Term**：在每一个 Leader 的任期期间，都有唯一表示该任期的一个 Term。
2. **Follower**：从节点（跟随角色）。
3. **Candidate**：在 Leader 消息发送失败或宕机，整集群没有 Leader 时，Follower 接收 Leader 的心跳包超时，则它们以 Candidate 身份，开始竞选 Leader。Candidate 只是个中间状态，不会长期存在。

Raft 将分布式问题划分成 3 个小问题：

1. **Leader Election**：主节点选举，集群启动、或者 Leader 心跳包消息无法发送给 Follower 时，触发选主操作。

   集群启动：

   ![1647238020422](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238020422.png)

2. **Log Replication**：日志复制。

   1. 客户端请求 Leader 写入数据.
   2. Leader 将数据分发到 Follower 中，然后数据被写入 Follower 的内存.
   3. Follower 向 Leader 发送确认消息，Leader 首先提交自己的数据，响应客户端，然后向 Follower 发送提交数据请求。
   4. Follower 收到提交请求后，提交数据。

   ![1647238328150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238328150.png)

3. **Safety**：安全恢复。

   - **1）Leader 宕机感知**：

     1. 通过 timeout，来保证 Follower 能正确感知 Leader 宕机或消息丢失的事件，并触发 Follower 竞选Leader。

        ![1647238709444](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238709444.png)

     2. Leader 需要给 Follower 发送心跳包（heartbeats），数据也是携带在心跳包中，发送给 Follower 的。

        ![1647238617190](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238617190.png)

   - **2）选主平票情况**：Leader Election 平票时，两个 Candidates 会产生一个随机的 timewait，继续发送下一个竞选消息。

     ![1647238893242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238893242.png)

   - **3）脑裂（大小集群）情况**：

     1. 小集群由于没有得到多数派的回复，写操作失败。
     2. 大集群会发生重新选主的过程，且新 Leader 拥有自己新的 Term(任期)，写操作成功。
     3. 当小集群回到大集群时，由于小集群的 Term 小于新集群的 Term，则会同步大集群的信息。

     ![1647238545305](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238545305.png)

##### 4）ZAB

ZAB，全称是 Zookeeper atomic broadcast protocol，是 ZK 内部用到的一致性协议，基本与 Raft 相同：

1. Zab 将任期 Term 换成了epoch。
2. 用于保证日志连续性的心跳检测，方向 ZAB 改由 Follower 发送至 Leader。

**算法角色**：

1. **Leader**：负责投票的发起和决议、更新系统状态。
2. **Follower**：接受客户端请求、响应客户端结果、参与投票。
3. **Observer**：可以接受客户端请求，将其转发给 Leader，但是不参与投票过程，只同步 Leader 状态，目的是为了扩展系统，提高读取速度。

ZAB 有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。

- **1）恢复模式（选主）**：
  1. 当服务启动或者在领导者崩溃后，ZAB 就进入了恢复模式。
  2. 当领导者被选举出来，且大多数 Follower 完成了和Leader 的状态同步以后，恢复模式就结束了。
  3. 状态同步保证了 Leader 和 Follower 具有相同的系统状态。
  4. ZK 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的，系统默认的选举算法为 fast paxos。
- **2）广播模式（同步）**：
  1. 选完 leader 以后，ZK 就进入状态同步过程。
  2. leader 等待 server 连接。
  3. Follower 连接 leader，将最大的 ZXID（全局递增的事务 ID）发送给leader。
  4. Leader 根据 Follower 的 ZXID 确定同步点。
  5. 完成同步后，通知 Follower 已经成为 uptodate 状态。
  6. Follower 收到 uptodate 消息后，又可以重新接受 client 的请求，继续进行服务了。

### 1.6. 分布式事务一致性？

#### 1）XA 方案 - 2PC 协议 | 数据库实现 | 非 100% 一致

**XA 方案**：

1. XA，是由 X/Open 组织提出的分布式事务规范，由一个事务管理器（TM）和多个资源管理器（RM）组成。
2. 当一个事务跨越多个节点时，为了保持事务 ACID 的特性，需要引入协调者（TM），来统一掌控所有参与者节点（RM）的操作结果，并最终指示这些节点是否要把操作结果进行真正的提交或者回滚。

**两阶段提交**，Two phaseCommit，是指在计算机网络以及数据库领域中，为了使基于分布式系统架构下的所有节点，在进行事务提交时，保持一致性而设计的一种算法，整体思路可以概括为：

1. 参与者将操作成败通知协调者。
2. 再由协调者根据所有参与者的反馈情报，决定各参与者是否要提交操作还是回滚操作。

所谓的两个阶段是指：**准备阶段和提交阶段**。

1. **准备阶段**：

   1. 事务协调者（TM）给每个参与者（RM）发送Prepare消息。
   2. 每个参与者（RM），要么直接返回失败，比如权限验证失败等，要么在执行本地事务，各自写本地的 redo log 和 undo log，但不提交事务。

   ![1647248864385](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647248864385.png)

2. **提交阶段**：

   1. 如果协调者（TM），收到了参与者（RM）的失败通知或者超时，则直接给每个参与者（RM）发送回滚（Rollback）通知；否则，发送提交（Commit）通知。
   2. 参与者（RM），根据协调者（TM）的指令，执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源，注意的是，2 PC 协议是必须在最后阶段，才会释放锁资源。

   ![1647250694317](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250694317.png)

**缺点**：

1. **同步阻塞问题**：执行过程中，所有参与节点（RM）都是事务阻塞的，当参与者（RM）占有公共资源时，其他第三方节点访问公共资源，将不得不处于阻塞状态。
2. **存在单点故障风险**：一旦协调者（TM）发生故障，参与者（RM）将会一直阻塞下去，尤其在第二阶段，协调者发生故障，那么所有的参与者（RM）还都处于锁定事务资源的状态中，而无法继续完成事务操作。
   - **解决方案**：如果是协调者（TM）挂了，可以重新选举一个协调者（TM），但是无法解决因为协调者（TM）宕机，导致的参与者（RM）处于阻塞状态的问题。
3. **数据不一致**：
   1. 在两阶段提交的二阶段中，当协调者（TM）向参与者（RM）发送 commit 请求后，如果发生局部的网络异常，或者在发送 commit 请求过程中，协调者（TM）发生故障，则会导致只有一部分参与者（RM）接受到了 commit 请求。
   2. 而在这部分参与者（RM）接到 commit 请求之后，就会执行 commit 操作。
   3. 但是，其他部分未接到 commit 请求的参与者（RM），则无法执行事务提交。
   4. 于是，整个分布式系统便出现了数据不一致性的情况。

#### 2）XA 方案 - 3PC 协议 | 数据库实现 | 非 100% 一致

![1647250732842](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250732842.png)

**3PC 算法流程**：

1. **`can commit` 阶段**：准备阶段，3PC 的 `can commit` 阶段其实和 2PC 的准备阶段很像。协调者（TM）向参与者（RM）发送 commit 请求，如果参与者（RM）可以提交就返回 Yes 响应，否则返回 No 响应。
2. **`pre commit` 阶段**：预提交阶段，协调者（TM），根据参与者（RM）的反应情况，来决定是否可以进行事务的 `preCommit` 操作：
   1. **参与者（RM）情况判断**：如果协调者（TM）从所有的参与者（RM），获得的反馈都是 Yes 响应，那么就会执行事务的预执行。
   2. **发送预提交请求**：协调者（TM）向参与者（RM），发送 `pre commit` 请求，并进入 prepared 阶段。
   3. **事务预提交**：参与者（RM）接收到 `pre commit` 请求后，会执行事务操作，并将 undo log 和 redo log记录到本地的事务日志中。
   4. **响应反馈**：如果参与者（RM）成功执行了事务操作，则返回 ACK 响应给协调者（TM），同时开始等待其最终的指令。
   5. **事务中断**：但是，如果有任何一个参与者（RM），向协调者（TM）发送了 No 响应，或者协调者（TM）等待超时，没有接到参与者（RM）的响应，那么就执行事务的中断：
      - **1）发送中断请求**：协调者（TM）发送中断 abort 请求给所有参与者（RM）。
      - **2）事务中断**：参与者（RM），收到来自协调者（TM）的 abort 请求后，或超时没收到协调者（TM）的任何请求，则执行事务中断，**什么都不用做**。
3. **`do commit` 阶段**：提交阶段，此阶段进行真正的事务提交，也需要分为以下 2 种情况：
   1. **发送提交请求**：协调者（TM），收到参与者（RM）返回的 ACK 响应，则会从预提交状态进入到提交状态，并向所有参与者（RM）发送 `do commit` 请求。
   2. **事务提交**：参与者（RM），接收到 `do commit` 请求后，执行正式的事务提交，并在完成事务提交后，释放所有事务资源。
   3. **响应反馈**：参与者（RM）事务提交完之后，向协调者（TM）再次返回 ACK 响应。
   4. **完成事务**：协调者（TM），再次接收到所有参与者（RM）的 ACK 响应之后，代表本次分布式事务完成。
   5. **中断事务**：但是，如果协调者（TM），没有接收到任意一个参与者（RM）返回的 ACK 响应，可能是响应的不是 ACK，也可能发生了超时，那么就会执行中断事务：
      - **1）发送中断请求**：协调者（TM），向所有参与者（RM）发送 `abort` 请求。
      - **2）事务回滚**：参与者（RM），接收到 `abort` 请求后，利用其在 `pre commit` 阶段记录的 undo log 来执行本地事务的回滚操作，并在完成回滚之后，释放所有的事务资源；但如果超时没收到协调者（TM）的任何请求，则参与者（RM）会进行**事务提交**（因为都到了这一阶段了，大概率是可以提交的）。
      - **3）反馈结果**：参与者（RM），完成事务回滚之后，向协调者（TM）发送 ACK 响应。
      - **4）中断事务**：协调者（TM），接收到参与者（RM）反馈的 ACK 响应之后，执行最终的事务中断。

**2PC 和 3PC 的区别**：

1. **3PC 能够及时释放资源**：3PC 比 2PC，多了一个 `can commit` 阶段，减少了不必要的资源浪费。
   - 因为 2PC 在第一阶段会占用资源，而 3PC 在 `can commit` 阶段不占用资源，只是校验一下 sql，如果不能执行，则直接返回，减少了资源占用。
2. **3PC 引入了参与者（RM）超时机制**：在协调者（TM）和参与者（RM），都引入超时机制。
   - **2PC**：只有协调者（TM）有超时机制，超时后，发送会发送回滚指令。
   - **3PC**：协调者（TM）和参与者（RM）都有超时机制：
     1. **协调者（TM）超时**：`can commit`、`pre commit` 阶段，如果收不到参与者（RM）的反馈，则协调者（TM）会向参与者（RM）发送中断指令，参与者（RM）进行事务中断，什么都不用做。
     2. **参与者（RM）超时**：`pre commit` 阶段，参与者（RM）进行回滚；`do commit` 阶段，参与者（RM）进行事务提交（因为都到了这一阶段了，大概率是可以提交的）。

**总结**：

1. 3PC 相对于 2PC 做了一定的改进，引入了参与者（RM）超时机制，并且增加了 `pre commit` 预提交阶段，使得故障恢复之后，协调者（TM）的决策复杂度降低，但整体的交互过程更长了，性能会有所下降，并且同样还会存在数据不一致的问题。
2. 所以，2PC 和 3PC 都**不能保证数据 100% 一致**，因此，一般都需要有**定时扫描补偿机制**来兜底。
3. 3PC 只是纯理论上的东西，相比于 2PC 只是做了一些优化，但是效果甚微，所以只做了解即可。

#### 3）AT 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

![1647251563240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647251563240.png)

AT 模式，基于支持本地 ACID 事务的关系型数据库实现：

1. **一阶段 `prepare` 行为**：在本地事务中，一并提交业务数据更新，和相应回滚日志记录。
2. **二阶段 `commit` 行为**：马上成功结束，自动异步批量清理回滚日志。
3. **二阶段 `rollback` 行为**：通过回滚日志，自动解析生成补偿 SQL，完成数据回滚。

**缺点**：

1. 解析回滚日志，生成 SQL 损耗性能。
2. 默认事务隔离级别是读未提交，无法解决脏读。如果设定读已提交（`SELECT FOR UPDATE` 申请全局锁），则性能会直线下降。

#### 4）TCC 方案 | Seata 实现 | 默认读未提交，读已提交性能低下 

TCC，Try-Confirm-Cancel，是一种 Seata 的分布式事务解决方案，它将一个事务拆分成 3 个步骤：

1. **T**：try，业务检查阶段，主要进行业务校验，以及检查或者资源预留，也可以进行一些业务处理。
2. **C**：confirm，业务确认阶段，主要是对 `try` 阶段校验过的业务，或者预留的资源进行确认。
3. **C**：cancel，业务回滚阶段，主要进行与上面相反的业务操作，释放 `try` 阶段预留的资源或者业务。

![1647254230571](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647254230571.png)

**TCC  方案 VS AT 方案**：

1. TCC 方案，相当于 AT 方案的人工版，属于事务补偿型。
2. AT 方案的回滚，是自动解析回滚日志，解析出反向 SQL。
3. 而 TCC 方案则是完全把 `perpare`、`rollback` 和 `commit` 三个方法全都交给开发者来实现。

**TCC 空回滚是解决什么问题的？**

1. 在没有调用 `try` 方法的情况下，调用了二阶段的 `cancel` 方法。
2. 比如，当 `try` 请求由于网络延迟或故障等原因，没有执行，且结果返回了异常时， `cancel` 不能正常执行，只能进行空回滚，因为 `try` 并没有对数据进行修改，如果 `cancel` 正常执行，对数据进行反向修改，那就会导致数据的不一致。
3. **解决思路**：
   1. 关键是要识别出这个空回滚，也就是需要知道 `try` 阶段到底是否执行，如果  `try`  执行了，那就正常回滚，如果  `try`  没有执行，那就空回滚。
   2. 可以让协调者（TM）在发起全局事务时，生成全局事务记录以及分支事务记录， `try` 阶段插入一条记录，表示 `try` 阶段执行了，`cancel` 阶段再读取该记录，如果该记录存在，则正常回滚，如果该记录不存在，则进行空回滚。

**如何解决 TCC 幂等问题？**

1. 为了保证 TCC 二阶段提交，重试机制不会引发数据的不一致，就要求 TCC 的二阶段 `confirm` 和 `cancel` 方法保证幂等性。
2. 这样才不会重复使用或者释放资源，但如果幂等性控制没有做好，很可能会导致数据不一致等严重问题。
3. **解决思路**：
   1. 在上述所说的分支事务记录中，增加执行状态，每次执行前都查询该状态是否已执行，执行过了就不再执行。
   2. 也可以用分布式锁解决。

**如何解决 TCC 中悬挂问题？**

1. 悬挂，就是对于一个分布式事务，其二阶段 `cancel` 方法比 一阶段的 `try` 方法先执行。
2. **出现原因**是，在调用分支事务 `try` 时，由于网络发生拥堵，造成了超时，协调者（TM）就会通知参与者（RM）回滚该分布式事务，可能回滚完成后，`try` 请求才到达参与者（RM）被真正执行。
3. **造成的后果**是，由于一个 `try` 方法预留的业务资源，只有该分布式事务才能使用，此分布式事务最后才执行的 `try`，导致业务资源预留后，无法被继续处理。
4. **解决思路**是：
   1. 如果二阶段执行完成，那一阶段就不能再继续执行。
   2. 在执行一阶段事务时，判断在该全局事务下，分支事务记录表中，是否已经有二阶段的事务记录，如果有，则不再执行 `try` 。

**缺点**：

1. 默认事务隔离级别读未提交，还是会出现脏读问题。
2. 所要编写的代码量，可能会恶心死人。

#### 5）Saga 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

Saga，长事务解决方案，事务一旦 start，各个参与者（RM）按照顺序，一个一个执行自己的逻辑，当其中有一个参与者（RM）执行失败，那么之前已经执行的参与者（RM）都需要**反向逆序**进行回滚。

![1647255581291](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647255581291.png)

**优点**：

1. 一阶段提交本地事务，无锁，高性能。
2. 事件驱动架构，参与者（RM）可异步执行，高吞吐。
3. 补偿服务易于实现。

**缺点**：默认事务隔离级别读未提交，还是会出现脏读问题，不保证隔离性。

**适用场景**：

1. **业务流程长、业务流程多时**。
2. **调用第三方业务**：参与者（RM）包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口时。

#### 6）本地消息表 | MQ 实现 | 最终一致性

本地消息表，其实就是利用了**各系统本地的事务**来实现分布式事务。

1. 本地消息表，顾名思义就是，会有一张存放本地消息的表，一般都是放在数据库中。
2. 然后，在执行业务时，将业务的执行和将消息放入消息表中的操作，包在同一个事务中，以保证消息放入本地表后，业务肯定能够执行成功。
3. 然后，再去调用下一个操作，如果下一个操作调用成功了，那么消息表的消息状态直接改成已成功。
4. 如果调用失败了，那也没事，会有后台任务定时去读取本地消息表，筛选出还未成功的消息，再调用对应的服务，服务更新成功了再变更对应消息的状态。
5. 其中，有可能消息对应的操作不成功，所以，还需要进行重试（要保证服务接口幂等），在超过最大次数时，还需要记录下来，报警，进行人工处理。

可以看到，本地消息表，其实实现的是最终一致性，容忍了数据暂时不一致的情况。

#### 7）可靠消息最终一致性方案 | MQ 实现 | 最终一致性	

可靠消息最终一致性方案，指的是：当事务发起方（消息发送者）执行完本地事务后，发出一条消息，保证事务参与方（消息的消费者）一定能够接受消息，并可以成功处理他自己的事务。

1. **可靠消息**：发起方一定得把消息传递到消费者。
2. **最终一致性**：最终，发起方的业务处理，和消费方的业务处理都得完成，达到数据的最终一致性。

![1647242994399](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647242994399.png)

**解决方案**：比如，阿里 RocketMQ 的消息事务（**双端都要进行确认，重试要保证幂等性**）

1. A（比如订单）系统，先发送一个 `prepared` 消息到 Broker。
2. 如果 `prepared` 消息发送失败，则取消操作，不再执行。
3. 如果 `prepared`  消息发送成功后，则执行 A 的本地事务，执行成功，则发送确认消息到 Broker，执行失败，则发送回滚消息到 Broker，其中，Broker 会**定时轮询**所有 `prepared` 消息回调的接口，以确认事务的执行状态。
4. 如果 Broker 收到了确认消息，则 B （比如仓储） 系统会接收到该事务消息，然后执行 B 的本地事务。
5. 如果 B 事务执行失败，则会不断重试，直到成功，或者达到一定次数后，发送报警，人工介入，来手工回滚或者补偿。

![1647256631363](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647256631363.png)

#### 8）最大努力通知方案 | MQ 实现 | 最终一致性

**概念**：

1. 其实，本地消息表，也可以算作最大努力通知，事务消息也可以算最大努力通知。
2. 本地消息表来说，会有后台任务定时去查看未完成的消息，然后去调用对应的服务，当一个消息多次调用都失败时，可以记录下来，然后人工介入，也可以直接舍弃掉，算最大努力通知。
3. 事务消息也是一样，当 half message 被 commit 了之后，确实就是普通消息了，如果订阅者一直不消费，或者消费不了，则会一直重试，最后进入死信队列，也算是最大努力通知。
4. 所以，最大努力通知，其实就是一种**柔性事务**的思想，我已经尽力我最大的努力，想达成事务的最终一致了。

**执行流程**：

1. 系统 A 本地事务执行完后，发送消息到 MQ。
2. 然后有个专门消费 MQ 的**最大努力通知服务**，去调用系统 B 的接口。
3. 要是系统 B 执行失败了，就会定时尝试重新调用系统 B 的接口，**反复 N 次** 。
4. 最后还是不行的话，就**放弃**。

**注意要点**：

1. **消息重复通知机制**：由于消费可能没有接收到通知，所以需要有一定的机制，对消息进行重复通知。
2. **消息校对机制**：如果尽最大努力，也没有通知到消费方，或者消费方消费消息后要再次消费，就可由消费方，主动向生产方，查询消息信息来满足需求。

**适用场景**：适用于对时间不敏感的业务，比如短信通知。

#### 9）分布式事务总结

1. 可以看出 2PC 和 3PC 是一种**强一致性事务**，不过还是有数据不一致、事务阻塞等风险，且只能用在数据库层面。
2. 而 TCC 则是一种**补偿性事务**的思想，适用范围更广，由于在业务层面实现，所以对业务的侵入性较大，每个分布式事务，都需要实现对应的三个方法。
3. 本地消息表、事务消息和最大努力通知，都属于**最终一致性事务**，所以，适用于一些对时间不敏感的业务。

**比如**：

1. 如果是一个严格资金绝对不能错的场景，可以用 **TCC 方案**。
2. 如果是一个一般的分布式事务场景，比如积分数据，可以用**事务消息**方案。
3. 如果分布式场景允许不一致，可以使用**本地消息表、最大努力通知**等最终一致性方案。

### 1.7. 分布式消息队列？

见《消息队列篇》。

### 1.8. 分布式缓存？

见《Redis篇》。

#### 1、数据库、缓存双写一致性？

##### 1、总

1. 首先，从理论上来讲，给缓存设置**过期时间**，所有写操作以数据库的为准，对缓存操作只尽最大努力更新的话，如果数据库写成功，缓存更新失败，只要缓存到达了过期时间，那么后面的读请求自然会从数据库中，读取到新值，然后回填到缓存，是可以实现**最终一致性**的。
2. 而如果要给出依赖过期时间的方案的话，可以从更新/删除缓存的角度去思考，它们的大前提是，先读缓存，如果缓存没有，才从数据库读取：
   1. 先更新缓存，再更新数据库。（不可取，数据丢失）
   2. 先更新数据库，再更新缓存。（不可取，后者脏数据覆盖）
   3. 先删除缓存，再更新数据库。（不可取，延迟双删、异步双删依然不能保证一致性）
   4. 先更新数据库，再删除缓存。（可取，Cannal + MQ 实现业务解耦、以及最终一致性）

##### 2、分

###### 1）先更新缓存，再更新数据库 | 数据丢失

1. 这个方案会出现，同一个缓存被频繁写入，但还没来得及更新到数据库，造成数据丢失的问题。
2. 故，放弃。

###### 2）先更新数据库，再更新缓存 | 后者脏数据覆盖

1. 这个方案，也是有问题的，如果有请求 A 和请求 B 并发进行更新操作，那么就会出现：
   - （1）线程 A 更新了数据库。
   - （2）线程 B 更新了数据库。
   - （3）线程 B 更新了缓存。
   - （4）线程 A 更新了缓存。
2. 理论上，请求 A 更新缓存，应该比请求 B 更新缓存早才对，但是由于网络等原因，B 却比 A 更早更新了缓存，导致 A 最后才把脏数据刷到缓存中，造成数据不一致。
3. 故，放弃。

显然，删除缓存才是更好的选择。

###### 3）先删除缓存，再更新数据库 | 延迟双删、异步双删依然不能保证一致性

1. 这个方案，也还是有问题的，如果在请求 A 更新时，请求 B 并发查，会出现：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询，发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值填入缓存。
   - （4）请求 A 将新值写入数据库。
2. 上述情况就会导致不一致的情形出现，如果不给缓存设置过期时间，则该数据永远都是脏数据。
3. 此时，解决方案可以采用**延时双删**策略：
   - （1）先淘汰缓存。
   - （2）再写数据库（这两步和原来一样） 。
   - （3）关键来了，再**休眠** n 秒，然后淘汰缓存，这么做，可以把 n 秒内，所产生的缓存脏数据，再次删除掉。
4. 但是，这个 n 秒怎么确定，可以在写数据后，休眠的时间在读数据业务逻辑的耗时基础上，加几百 ms 即可，这么做的目的，就是确保读请求结束后，写请求可以删除读请求造成的缓存脏数据。
5. 然而，如果 MySQL 读写分离架构下，还是会出现不一致的情况：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 A 将数据写入数据库了。
   - （3）请求 B 查询缓存，发现缓存没有值，然后去从库查询，但是此时，还没有完成主从同步，因此，查询到的还是旧值。
   - （4）请求 B 将旧值写入缓存。
   - （5）数据库完成主从同步，从库变为新值 。
6. 上述情况也产生了数据不一致的现象，解决方法还是使用**延时双删**策略，只不过，休眠时间 n，需要在主从同步的延时时间基础上，加几百 ms，而不是读耗时加几百 ms。
7. 但是，采用这种同步淘汰策略，由于设计到阻塞休眠 n s，接口吞吐量将会降低很多，此时可以把第二次休眠后删除的步骤，改为**异步**的操作，即起一个线程做异步删除。这样，写请求就不用沉睡一段时间后才返回响应。
8. 如果采用**异步双删**，虽然保证了吞吐量，但第二次可能会**删除失败**，比如：
   - 为了方便，假设是单库。
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值写入缓存。
   - （4）请求 A 将新值写入数据库。
   - （5）请求 A 试图去删除，但由于某种原因失败了，导致缓存中一直存在 B 放入的旧值。
9. 这种情况下，如果第二次删除缓存失败，还是会出现后面缓存和数据库不一致的现象。
10. 所以，更新数据库前的缓存删除，起不到任何作用，一致性是由第二次缓存删除来保证的。
11. 故，放弃更新前缓存删除方案。

###### 4）先更新数据库，再删除缓存

1. 这种情况，也还是会存在并发问题：
   - （1）缓存刚好失效。
   - （2）请求 A 查询数据库，得一个旧值。
   - （3）请求 B 将新值写入数据库。
   - （4）请求 B 删除缓存。
   - （5）请求 A 将查到的旧值写入缓存。 
2. 上述情况，确实还是有脏数据，解决方案有：
   1. **过期时间**：给缓存设有效时间是一种方案。
   2. **异步删除**：采用上面的异步删除策略，保证读请求完成以后，再进行删除操作也可以，但同样，也存在缓存删除失败导致数据不一致的情况，此时可以提供一个**重试删除**机制即可解决。

##### 3、总

1. 因此，要保证数据库、缓存双写一致性的关键在于，**先更新数据库 + 再删除缓存 + 异步重试删除**，实现方案如下：

2. **方案一**：

   - （1）更新数据库后，再删除缓存。
   - （2）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （3）然后消费消息，获取到要删除的 key。
   - （5）接着根据 key 继续重试删除操作，直到成功。

   **缺点**：对业务线代码，造成了大量的侵入。

   ![1647257594150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257594150.png)

3. **方案二**： 启动一个订阅程序，去订阅数据库的 **binlog**，获得需要操作的数据，然后另起一个程序，获得这个订阅程序传来的数据，进行删除缓存操作。

   - （1）更新数据库数据。
   - （2）数据库则会把更新操作的信息，写入 binlog 日志当中。
   - （3）binlog 日志被订阅程序订阅到，则提取出所需要的数据以及 key。
     - 这个订阅 binlog 程序，在 MySQL 有现成的中间件（阿里# Canal），至于 Oracle 目前好像还没有现成的中间件。
   - （4）调用另一段非业务代码，获得 key。
   - （5）根据这个 key，尝试执行缓存删除操作。
   - （6）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （7）然后消费消息，获取到要删除的 key。
   - （8）接着根据 key 继续重试删除操作，直到成功。

   ![1647257612877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257612877.png)

=> 以上，就是我对数据库、缓存双写一致性的一些实现方案的理解，请问有什么细节需要补充的吗？

### 1.9. 分布式锁？

#### 1、总

分布式锁指的是，在不同的系统或者同一个系统的不同主机之间，共享访问某个资源时，用来互斥地防止彼此干扰保证一致性的锁实现，其实现方式有：

- **基于数据库实现**：通过乐观锁，或者唯一索引实现。
- **基于分布式缓存实现**： 典型的有，通过 Redis 实现。
- **基于分布式一致性算法实现**：典型的有，通过 ZK 实现。

#### 2、分

##### 1）基于数据库实现 | 负担大

- **基于乐观锁实现**：原理是，根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。
- **基于唯一索引实现**：原理是，在表上建立唯一索引，当想要获得锁时，向表中插入一条记录，释放锁时则删除这条记录。
  - **缺点**：
    1. **锁没有失效时间**，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
    2. **不可重入**，同一线程在没有释放锁之前无法再获取到锁。

##### 2）基于分布式缓存实现 | 锁失效

- **基于 Redis 单机实现**：使用 `SET NX EX` 指令加锁，保证**原子性**地给锁设置**过期时间，防止死锁**，使用 LUA 脚本 `redis.call` 指令，保证 key 值判断与删除键指令原子性执行，且防止由于 STW 时间过长，锁被其他进程误删。

  - **缺点**：会出现由于**时钟漂移** 或者 任务执行时间过长，导致的锁被提前释放的问题。

- **基于 Redisson 实现**：它是一个 Redis 的客户端，其分布式锁的实现原理是，让获得锁的线程开启一个定时守护线程，每隔 expireTime / 3 的时间就去检查一下，该线程持有的锁是否还存在，如果存在，则对锁的过期时间重新设置为 expireTime，完成守护线程对**锁的续约**，防止锁由于过期提前释放。

  - **缺点**：这些只是在 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 是**异步复制**的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下，发生了故障转移，那么其他客户端上的线程依然可以获取到锁，丧失了锁的安全性。

- **基于 RedLock 算法实现**：红锁算法的原理是，

  1. 先获取当前时间 `t1`，然后按顺序依次尝试从 n 个 Redis 实例，使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁的失效时间 `expire`，还应该设置超时时间 `timeout`，且这个超时时间 **<** 锁的失效时间 `expire` ，这样可以避免 Redis 已经挂掉的情况下，客户端不用一直等待响应结果，而是尽快地去尝试另外一个 Redis 实例来获取锁。
  2. 客户端通过使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从过半数（N/2+1 个）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` **<** 锁失效时间 `expire` 时，锁才算获取成功，如果获取到了锁，那么 key 的真正有效时间 `real_expire` 等于锁失效时间 `expire` **减去**锁花费的总时间 `T`。
  3. 如果获取锁失败，客户端则应该在所有的 Redis 实例上使用 **Lua 脚本进行解锁**，原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端到服务器的通信是正常的，但反方向却是有问题的，虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功，因此，释放锁时，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起解锁请求。

  - **缺点**：
    1. **性能过重**：使用 RedLock 需要维护那么多的 Redis 实例，提升了系统的维护成本。
    2. **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生回调，则会导致它持有的锁提前过期释放，还是不能保证锁的安全性，这个是基于时间来实现自动释放的分布式锁，都无法解决的问题。

##### 3）基于分布式一致性算法实现 | 强一致

基于 ZK 实现：可以利用**顺序临时节点**的特性，结点在创建时，会自动在结点名后加一个数字后缀，以保证有序，同时，如果客户端连接失效，则还会立即删除结点，再利用 **watcher 监视器**的特性，注册某个结点的监视器，当节点状态发生改变时，watcher 被触发时，ZK 会向客户端发送一条通知。其分布式锁的实现原理是，

1. 创建一个锁目录 lock，希望获得锁的线程 A 在 lock 目录下，将创建**顺序临时结点**。
2. A 先获取锁目录下所有的子结点，判断是否存在序号比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则线程 A 获得锁。
3. 当另外一个线程 B 获取锁时，判断到 B 自己不是最小的结点，存在有更小的线程 A 结点，则设置  watcher 监听器，只监听比自己**次小**的结点 A。
4. 当线程 A 处理完业务后，会删除结点 A，释放掉分布式锁，然后线程 B 监听到节点状态变更事件后，判断自己已经是最小的结点了，则成功获得锁。

#### 3、总

以上，就是我对分布式锁一些实现方案的理解，总结一下就是，

- **基于数据库实现**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：但这样会增加数据库的负担。
- **基于分布式缓存实现**：
  - **优点**：属于 AP 模型，性能高，实现起来较为方便，在允许偶发性的锁失效情况发生，不影响系统正常使用时，可以采用分布式缓存来实现锁。
  - **缺点**：通过过期时间实现的锁超时机制不是十分可靠，当业务必须要数据的**强一致性**，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下，就不能使用分布式缓存来实现锁了，此时可以使用 CP 模型来实现，比如 Zookeeper。
- **基于分布式一致性算法实现**：
  - **优点**：不依靠过期时间来释放锁，可靠性高，当系统要求高可靠性时，可以采用分布式一致性算法来实现锁。
  - **缺点**：性能比不上分布式缓存实现的锁，因为 ZK 需要频繁的创建和删除结点。

### 2.0. 分布式全局 ID？

#### 1、总

1. 在分库分表环境中，由于表中数据同时存在不同数据库中，平时使用的自增主键 ID 将无用武之地，因为某个分区数据库自生成的 ID 无法保证全局唯一。
2. 因此，需要单独设计全局主键，来避免跨库主键重复的问题，我了解到的方案有：UUID、MyISAM ID 表、高可用 ID 服务器、Snowflake 分布式自增 ID 算法、以及美团的 Leaf 分布式 ID 生成系统。

#### 2、分

##### 1）UUID

UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8­4­4­4­12 的 36 个字符，比如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：方案最简单，且本地生成，性能高，没有网络耗时。
- **缺点**：
  1. 由于 UUID 非常长，会占用大量的存储空间。
  2. UUID 作为主键，建立索引和基于索引进行查询时，都会存在性能问题，在 InnoDB 下，UUID 的无序性会引起数据位置频繁变动，导致页分裂。

##### 2）MyISAM ID 表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();
```

- **概念**：
  1. `stub` 字段（存根）设置为**唯一索引**，同一 `stub` 值在 `sequence` 表中只有一条记录，支持同时给多张表生成全局 ID。
  2. 使用 MyISAM 存储引擎而不是 InnoDB，可以获取更高的性能，因为 MyISAM 使用的是表级锁，对表的读写是串行的，不用担心在并发时两次读取同一个 ID 值的问题。
  3. 使用 `REPLACE INTO + SELECT` 来获取自增 ID，保证两操作在同一事务内，它会先删除旧数据，再生成新数据，从而实现主键自增。
- **优点**：实现简单。
- **缺点**：
  1. 存在单点问题，且强依赖 DB，当 DB 异常时，会导致整个分布式系统都不可用。
  2. 虽然可以配置主从来增加可用性，但当主库挂了，主从切换时，数据一致性难以得到保证。
  3. 因此，整个系统的性能瓶颈，被限制在单台 MySQL 的读写性能上。

##### 3）高可用 ID 服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：Flickr（弗里克，雅虎的一个图片分享网站）团队使用的一种主键生成策略，与上面的 `sequence` 表方案类似，但可以更好地解决了单点故障和性能瓶颈的问题。

- **思想**：

  1. 建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 `sequence` 表用于记录当前全局 ID。
  2. 表中 ID 增长的**步长相同，等于库的数量，起始值依次错开**，这样能将 ID 的生成散列到各个数据库上，比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...）等等。

- **优点**：生成 ID 的压力，能够均匀分布在多台机器上，同时提高了系统的容错能力，当第一台出现了错误，可以自动切换到第二台机器，来获取 ID。

- **缺点**：

  1. 系统添加机器水平扩展时，需要停止原本正在运行的 ID 服务器，以**修改步长**。
  2. 每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。

- **优化方案 **：**批量获取 ID**。

  - 使用批量获取的方式，可以降低数据库的写压力，每次获取**一段**区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    - 1）比如，还是使用 2 台 DB 保证可用性，数据库中只存储当前的最大 ID。
    - 2）ID 生成服务，每次批量获取 6 个ID，可以先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从**号段缓存**中依次派发 0~5 的 ID。
    - 3）当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的ID。
    - 4）这样，数据库的压力降低为原来的 1/6。
  - **缺点**：ID 生成服务需要维护最大 ID 值，再下次生成 ID 时，需要告诉 DB M1、DB M2 各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

##### 4）Snowflake 分布式自增 ID 算法

Twitter 的 snowflake 算法，解决了分布式系统生成全局 ID 的需求，可以生成 64 位的 long 类型的数值。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

- **概念**：1 + 41 + 10 + 12  = 64位。
  1. 首先是，第 1 位不使用。
  2. 接下来是， 41 位的毫秒级时间戳，最大可以表示 **69年** 的时间。
  3. 然后是，5 位的 `datacenterId`，5位的 `workerId`，这 10 位长度，最多支持部署**1024 个节点**。
  4. 最后是，12 位是毫秒内的计数值，最大支持每个节点、每毫秒产生**4096 个 ID 序列**。
- **优点**：
  1. 毫秒数在高位，生成的 ID 整体上按时间趋势是**递增**的，还可以根据自身业务灵活分配 bit 位。
  2. 不依赖第三方系统，稳定、效率高，理论上 QPS 约为 409.6 w/s（2^12 * 1000 ms），且整个分布式系统中不会产生 ID 碰撞。
- **缺点**：强依赖于机器时钟，如果时钟回拨，则可能导致生成的 ID 重复。

##### 5）美团点评分布式ID生成系统 - Leaf

Leaf，服务美团点评公司内部产品，包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在 4 C 8 G 的机器上，QPS 能压测到近 5 w/s，TP 999 1ms，能够满足大部分的业务需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

###### 1、Leaf - segment ID 服务器方案

- **思想**：
  1. 获取 ID 时，向 proxy server 代理服务器批量获取 ID，每次获取一个 segment 号段（由 `step` 决定大小）的值。
  2. 用完之后，再去获取新的号段，可以大大减轻数据库的压力。
- **实现**：
  1. `biz_tag` 用来区分业务，`max_id` 表示该 `biz_tag` 目前所被分配的 ID 号段的最大值，`step` 表示每次分配的号段长度。
  2. 比如，`test_tag` 在第 1 台 Leaf 机器上是 1~1000 的号段，当这个号段用完时，会去加载另一个长度为step=1000 的号段，而如果另外机器的号段都没有更新的话，此时第 1 台机器会重新加载 3001~4000 的号段，同时，数据库对应的 `biz_tag` 这条数据的 `max_id` 会从 3000 被更新成 4000。
  3. 这样，各业务不同的发号需求用 `biz_tag` 字段来区分，每个 `biz-tag` 的 ID 相互隔离，互不影响，如果以后有性能要求，需要对数据库进行扩容时，则不用复杂的扩容操作，只需要对 `biz_tag` 分库分表即可。
  4. 而且，对比原来获取 ID 每次都需要写数据库，现在只需要把 `step` 设置得足够大，比如 1000，那么只有当 1000 个号被消耗完了之后，才会去重新读写一次数据库，此时读写数据库的频率从1  减小到了 **1 / step** 。
- **优点**：
  1. Leaf 服务可以很方便的进行**线性扩展**，性能完全能够支撑大多数业务场景。
  2. 生成的 ID 是**趋势递增**的 8 byte 的数字，满足上述数据库存储的主键要求。
  3. 容灾性高，Leaf 服务内部有**号段缓存**，即使 DB 宕机，短时间内，Leaf 仍能正常对外提供服务。
  4. 可以自定义 `max_id` 的大小，非常方便业务从原有的 ID 方式上**迁移**过来。
- **缺点**：
  1. **TP 999 数据波动大**：当号段使用完之后，还是会 hang 在更新数据库的 I/O 上，TP 999 数据会出现偶尔的尖刺。
  2. **高可用得不到保障**：DB 宕机会造成整个系统不可用。
  3. **生成的 ID 不够随机**：会泄露发号数量的信息，不太安全。

###### 2、双 buffer 优化方案

目的是，优化第 1 个缺点，当号段使用完、线程取号时阻塞的问题。

![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **背景**：
  1. Leaf 取号段的时机，是在号段消耗完时进行的，意味着号段临界点的 ID 下发时间，取决于下一次从 DB 取回号段的时间，并且在这期间，进来的请求也会因为 DB 号段没有取回来，导致线程阻塞。
  2. 假如 Leaf 服务取 DB 时，网络发生抖动，或者 DB 发生慢查询，就会导致整个系统的响应时间变慢。
- **思想**：
  1. 为了让 DB 取号段的过程能够做到无阻塞，不会在 DB 取号段时阻塞请求线程，可以让发号段消费到某个点时，就**异步**的把下一个号段加载到内存中，而不需要等到号段用尽时，才去更新号段。
- **实现**：
  1. 采用双 buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。
  2. 当前号段已下发 10% 时，如果下一个号段未更新，则**异步**另启一个更新线程去更新下一个号段。
  3. 当前号段全部下发完后，如果下个号段准备好了，则切换到下个号段为当前 segment 接着下发，循环往复。

###### 3、高可用容灾方案

目的是，解决第 2 个缺点，DB 宕机会造成整个系统不可用的问题。

![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

**DB 高可用方案**：

1. 采用 1 主 2 从的方式，同时分机房部署，Master 和 Slave 之间采用半同步复制的方式，进行数据同步，同时使用公司的 DBProxy（原 Atlas）数据库中间件，做主从切换。
2. 当然，这种方案在一些情况会退化成**异步模式**，甚至在非常极端情况下仍然会造成**数据不一致**的情况，但是出现的概率非常小。
3. 如果系统确实要保证 100% 的数据强一致，可以选择使用**类Paxos算法**，实现强一致 MySQL 的方案，但这样运维成本和精力都会相应的增加，应该需要根据实际情况进行选型。

**应用高可用方案**：

1. Leaf 服务分 IDC 部署，内部的服务化框架是 `MTthrift RPC`。
2. 服务调用时，根据负载均衡算法，优先调用同机房的 Leaf 服务。
3. 如果该 IDC 内，Leaf 服务不可用，则会选择其他机房的 Leaf 服务。
4. 同时，服务治理平台 `OCTO` ，还提供了针对服务的过载保护、一键截流、动态流量分配等服务保护措施。

###### 4、Leaf-snowflake 方案

目的是，优化第 3 个缺点，生成的 ID不够随机，会泄露发号数量信息，不太安全的问题。

![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

Leaf-snowflake 方案，完全沿用了 snowflake 方案的 bit 位设计，即是 `1+41+10+12` 的方式组装 ID 号。

1. 对于 `workerID` 的分配，当服务集群数量较小时，完全可以手动配置。
2. 但当 Leaf 服务规模较大时，动手配置成本太高，此时可以使用 ZK 持久顺序节点的特性，自动对 snowflake 节点配置 `wokerID`。

**对接 ZK 的步骤**：

1. 启动 Leaf-snowflake 服务时，会去连接 ZK，在 `leaf_forever` 父节点下，检查自己是否已经注册过，是否有该节点的持久化顺序子节点。
2. 如果有注册过，则直接取回自己的 `workerID`，启动服务。
3. 如果没有注册过，则在该节点下，创建一个持久化顺序节点，创建成功后，取回顺序号当做自己的 `workerID` 号，启动服务。
4. 除了每次会去 ZK 拿数据以外，也会在本机文件系统上，缓存一个 `workerID` 文件，当 ZK 出现问题且恰好 Leaf-snowflake 服务机器也需要重启时，还能保证服务正常启动，做到了对 ZK 的**弱依赖**，一定程度上提高了 SLA 。

![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

**解决 snowflake 时钟回退问题**：

由于 snowflake 强依赖机器时间，如果其发生了回拨，则可能会生成重复的 ID，解决方案为：

1. 首先，服务启动时，先检查自己是否写过 `ZK#leaf_forever` 节点。
   - 1）如果写过，则用自身系统时间与 `leaf_forever/#{self}` 节点记录时间做比较，且小于 `leaf_forever/​#{self}` 的时间，则认为当前机器时间发生了回拨，服务启动失败并报警。
   - 2）如果没写过，则证明是新服务节点，此时需要创建持久顺序节点 `leaf_forever/#{self}` ，并写入自身系统的时间。
2. 接下来，综合对比其余 Leaf 节点的系统时间，来判断自身系统时间是否准确，具体做法是：
   - 1）取 `leaf_temporary` 下的所有临时节点（**所有运行中的** Leaf-snowflake节点）的服务 IP+端口。
3. 然后，通过 RPC 请求，得到它们各自的系统时间，计算 `at = sum(time) / nodeSize`。
4. 如果计算结果 `at < 阈值`，认为当前系统时间准确，可以正常启动服务，同时写临时节点 `leaf_temporary/#{self}` ，每隔一段时间（3s），上报自身系统时间，并写入到 `leaf_forever/#{self}` 中，以维持租约。
5. 否则，则认为本机系统时间发生大步长的偏移，启动失败并报警。

#### 3、总

以上，就是我对分布式全局 ID 的一些实现方案的理解，请问有什么细节需要补充的吗？

### 2.1. 分布式幂等性？

#### 1、总

1. 幂等，idempotence，是一个数学与计算机学的概念，常见于抽象代数中。
2. 在编程中，一个幂等操作的特点是，**该操作被任意多次执行，其所产生的影响，都与一次执行的影响相同**。
3. 所以，幂等性的方法是指，可以使用相同参数，重复执行，并还能获得相同结果的方法，这些方法不会影响系统的状态，也不用担心重复执行后，是否会对系统造成多余的改变。
4. 比如，`getUsername()` 和 `setTrue()` 方法就是一个幂等性方法。
5. 因此，我的理解是，幂等就是一个操作，无论执行多少次，返回的结果或者产生的效果都是一样的。

#### 2、分

1. 那么，保证幂等性有哪些方案呢？
2. **查询操作**：查询一次和查询多次，在数据不变的情况下，结果都是一样的。select 是天然的幂等操作。
3. **删除操作**：删除一次和删除多次，都是把数据删除，产生的效果都是一样的，但是返回的结果可能不一样，因为删除的数据不存在时，会返回 0，存在时，则返回 1。
4. **唯一索引**：可以防止新增脏数据，比如，给资金账户表中的用户 ID 加唯一索引，使得并发时，一个用户新增一个资金账户记录，只会让一个新增成功，后新增的则报错，从而保证了只插入一条记录。
   - **注意**：为了幂等性友好反馈，一定要先查询一下，判断是否处理过该笔业务，如果不查询，直接插入业务的话，由于该业务实际已经处理过了，从而导致大量报错的发生。
5. **token 机制**：防止页面重复提交，比如，由于重复点击、或者网络重发等情况，会页面表单被重复提交，解决办法是 token + 分布式锁保证幂等性。

#### 3、总

以上，就是我对分布式幂等性的一些理解，请问有什么细节需要补充的吗？

### 2.2. 分布式会话？

#### 1、为什么 cookie 无法防止 CSRF 攻击，而 token 却可以？

1. CSRF，Cross Site Request Forgery，跨站请求伪造，简单来说，就是用你的身份，去发送一些对你不友好的请求。
   - 1）比如，小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，于是小壮就好奇地点开了这个链接，结果发现自己的账户少了10000元。
   - 2）这是这么回事呢？原来黑客在链接中，藏了一个请求 `<a src=http://www.mybank.com/Transfer?bankId=11&money=10000>科学理财，年盈利率过万</> `，这个请求直接利用小壮的身份，给银行发送了一个转账请求，也就是通过小壮的 cookie 向银行发出请求。
2. 使用 session 认证时，一般使用 cookie 来存储 sessionid，在登陆后，后端生成这个 sessionid，放在 cookie 中，返回给客户端，而服务端通过 Redis 或者其他存储工具，记录保存着这个 sessionid。
3. 客户端登录以后，每次请求都会带上这个 sessionId，服务端就可以用这个 sessionId，来标识哪些请求来源于你个人。
4. 但是，如果别人通过 cookie，拿到了你的 sessionId 后，就可以代替你的身份访问系统了，在登录后的客户端中，攻击者可以通过让用户误点攻击链接，从而利用每次请求都会带上这个 sessionId 的特性，以达到攻击效果。
5. 而如果使用 token 的话，就不会存在这个问题，因为登录成功获得 token 后，一般存放在 local storage 中，然后是前端通过某些方式，在每个发到后端的请求中，都加上这个 token。
6. 而如果点击了个非法链接，由于是非法链接，不是脚本，没有查询 local storage#token 的能力，此时发送给服务端的请求也，是不会携带 token 的，也就是这个请求是非法的，这样，就不会出现 CSRF 漏洞的问题了。

#### 2、什么是 token? 什么是 JWT ? 如何基于 token 进行身份验证？

![1647336741900](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647336741900.png)

1. 由于 session 需要先保存一份在服务器端，使得服务存在状态，这给后端服务带来一定的麻烦，比如，需要保证有 session 信息的服务器的可用性、在扩容时还要为其做额外的考虑、由于依赖于 cookie，所以不适合移动端等等。
2. JWT ，JSON Web Token，可以让服务器端不用保存 session 信息，只需在登录后返回给客户端，由客户端进行保存，以后每次请求都带上这个 token，服务端解析 token 即可拿到 session 信息，从而使后端服务的扩展性得到提升，所以，**token 就相当于一个通行令牌**。
3. JWT，本质上就一段签名后的 JSON 数据，接收者可以根据签名，验证它的真实性，它由 3 部分构成：
   - **1）Header**：token 头，描述 JWT 的元数据，主要定义了，生成签名的算法，以及 token 的类型。
   - **2）Payload**：token 体，主要用来存放实际传递的数据。
   - **3）Signature**：token 签名，服务器通过 Payload、Header 和一个 secret 密钥，使用 Header 指定的签名算法来生成 token 令牌，默认是 `HMAC SHA256`，登录生成后，则把 token 令牌返回给客户端。
4. 客户端收到 token 后，可以保存在 cookie，或者 local storage 里面，在以后发出的所有请求，都携带这个令牌，以标识请求来源，然后服务端检查 JWT，并从中获取用户相关信息，从而替代掉 sessionId。
   - 1）如果放在 cookie 里，让请求发送时自动带上，则不能跨域问题，因为非子域下的 token 将会失效。
   - 2）所以，最好的做法是，放在 `HTTP Header#Authorization` 字段中。

#### 3、token 使用的最佳实践？

1. **设置合理的过期时间**。
2. **注销的 token，如果后端保存过，则需要及时清除**。
3. **监控 token 的使用频率**：防止数据被别人爬取，通过监控使用频率，从请求痕迹中，分析出是否为爬虫程序访问。 
4. **核心功能、敏感操作可以使用动态验证码**：比如提现功能，就要求在提现时，再次进行验证码校验，以防止非本人操作。
5. **识别网络环境、浏览器等信息**：比如，网络环境跟之前使用的不一样时，则需要 APP 重新登录。
6. **secret 加密密钥支持动态修改**：
   - 1）如果 token 的 secret  加密密钥泄露了，意味着别人可以伪造这些 token，这需要能够立刻修改密钥，以更改 token 生成和校验机制。
   - 2）此时，可以将 secret 密钥存储在配置中心，以支持动态修改刷新。
   - 3）但需要注意的是，建议在流量低峰时，再去做 secret 加密密钥的更换操作，否则会导致 token 全部失效，使得所有在线的请求，都需要重新申请 token，导致并发量突增。

#### 4、session 共享方案？

1. **集中式 session 服务器**：还是使用 sessionid 和 cookie 的机制，统一由一个集中式服务器进行 session 管理，缺点是，sessionid  存储在客户端本地有风险，且要保证集中式 session 服务器的高可用。
2. **session 同步**：对各服务器进行 session 数据同步，虽然可以保证每个服务器上都有全部的 session 信息，但当服务器数量过多时，同步会带来很大延迟，甚至同步失败，故放弃。
3. **负载均衡 IP 绑定**：通过负载均衡，比如 nginx 对客户端 IP 与某个服务实例进行绑定，让同一个 IP 只能在指定的同一个机器访问，缺点是对应服务实例宕机后，session 将会丢失，且失去了对请求进行负载均衡的意义。
4. **Redis 共享存储**：把 session 存放到 Redis 中，缺点是需要多访问一次 Redis，但真正实现了 session 共享，不仅可以跨服务器 session 共享，还可以跨平台 session 共享，比如网页端和 APP 端；同时，还支持水平扩展、无状态化后端服务，即使服务重启了，存在 Redis 中的 session 也至于丢失。

#### 5、认证与授权的区别？

1. 认证，Authentication，身份验证，是验证你的身份凭据，比如用户名、用户ID 和密码是否合法，通过这个凭据，系统可以得以知道你就是你，是**身份维度**。
2. 授权，Authorization，发生在认证之后，主要是掌控用户访问系统的权限，有些特定资源只能具有特定权限的人才能访问，比如 admin，是**权限维度**。
3. 认证和授权，一般在系统中都被结合使用，目的是为了保护系统安全。

#### 6、单点登录 SSO？

SSO，Single Sign On，单点登录，是一种会话共享的技术，指用户只需要在某一个网站登录后，那么他所产生的同一次会话，就共享给了其他网站，也就是说，实现了单点登录后，间接地也登录了其他网站。

- **会话**，session，代表的是客户端与服务器的一次交互过程，这个过程可以是连续的，也可以是断断续续的。

根据浏览器的跨域与 cookie 特性，二级域名可同享一级域名的 cookie， 其他不同域名间不共享 cookie，实现基于会话共享的单点登录，可以分为 2 种不同方案：相同一级域名的单点登录和不同一级域名的单点登录。

##### 1、相同一级域名的单点登录 | cookie + Redis

二级域名共享一级域名的 cookie，即 `www.abc.test.com` 和 `www.def.test.com` ，两者共享 `www.test.com` 域名下的 cookie。

**具体流程为**：

1. 首先，前端方面，登录后，后端可以把标志当前会话的 userId，设置到 `www.test.com` 域名下的 cookie 中。
2. 然后，后端方面，则把 userId 作为 key，把会话信息放到 Redis 中，实现分布式会话。

这样，用户在 `www.abc.test.com` 登录后，userId 放入了 `www.test.com`  的 cookie 中，会话信息放到了 Redis 中，只要会话没结束（浏览器没关闭），则在用户下次访问 `www.def.test.com` 时，后端照样能够拿到 cookie 中的 userId，从而去 Redis 查到有会话信息，则认为本次请求有效，无需重新登录，从而实现单点登录。

##### 2、不同一级域名的单点登录 | cookie + CAS + Redis

（图片仅供参考，与下面流程不符）

![1647352168308](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647352168308.png)

不同一级域名间的 cookie 无法共享，即 `www.abc.com` 和 `www.def.com`，两者间的 cookie 无法共享。

这样，就需要引入一个中心节点，用于专门承接单点登录工作，以实现以上两个域名间的 cookie 共享，这个中心节点就是 CAS。

- **CAS**，Center Authentication Service，中央认证服务，是一个单点登录的解决方案，用于不同一级域名之间的单点登录。

**具体流程为**：

![img](file:///D:/MyData/yaocs2/Desktop/%E5%A4%87%E6%B3%A8/5%20SSO/SSO_%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95_%E6%97%B6%E5%BA%8F%E5%9B%BE_20220315.png)

假设 CAS 服务端域名为 `www.cas.com`，其他一级域名都是它的客户端，这里有两个，分别为 `www.abc.com` 和 `www.def.com` 。

1. 一个用户在某个时间，访问了 `www.mtv.com` 服务 A。
2. 此时，A 需要校验请求，由于 A 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
3. CAS 收到请求后，发现请求并没有会话标记，代表没有登录，则重定向用户到登录页面，需要用户进行登录。
4. 用户在登录成功后（账号密码校验通过），则 CAS 为用户创建会话，生成全局门票和临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 A。
5. A 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
6. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 A 登录成功。
7. 接着，用户跑去访问 `www.music.com` 服务 B。
8. 此时，B 需要校验请求，由于 B 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
9. CAS 收到请求后，发现请求有会话标记，然后去查 Redis 是否存在全局门票，如果存在，则说明会话已共享，认为用户已登录，然后生成临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 B。
10. B 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
11. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 B 登录成功。
12. 至此，一次不同一级域名间的单点登录流程完毕。

其原理在于，利用了两网站间接共享了 CAS 同一个域名的 cookie，使用其中的 userId 作为当前会话的标记，以让后端能够拿着这个标记，去 Redis 中判断是否已生成分布式会话，从而免去第二次的重复登录，实现单点登录。

**全局门票 VS 临时门票**：

1. **全局门票是分布式会话**，是判断当前会话是否已经登录的核心所在。
2. **临时门票是安全性保证**，用于跟 CAS 换取会话信息。
   - **1）假设不用临时门票**，而是直接把全局门票返回给客户端，这样就会导致，如果该全局门票被他人知道了，那么即使用户的当前会话关闭了，劫持者依然能够通过全局门票进行登录操作，就保证不了单点登录是同一次会话。
   - **2）而如果用的是临时门票**，就可以保证本次登录只在当前会话有效，会话结束后，cookie 中的 userId 过期，再次请求 CAS 的话，就需要重新登录和设置了，并且，就算临时门票被劫持了，只需在临时门票兑换会话信息的操作中，增加额外的校验（比如网站来源，或者校验 cookie 中有没有 userId），返回校验不通过，就可以避免掉上面这种劫持风险了。

### 2.3. 分布式限流？

#### 1、分布式限流维度？

1. **时间**：限流基于某段时间范围，或者某个时间点，也就是常说的时间窗口，比如每分钟、每秒钟的时间窗口做限定。
2. **资源**：基于可用资源的限制，比如设定最大访问次数，或者最高可用连接数。

=> 故，

1. **限流就是在某个时间窗口内，对资源访问做限制**，比如设定每秒最多放行 100 个访问请求。
2. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
3. 比如针对了某个 IP 的限流，限制其每秒最多 10 个访问，那么不管这个 IP 的请求，落在了分布式中的哪台机器上，只要是访问了集群中的服务节点，那么都会受到限流规则的制约。

#### 2、分布式限流规则？

在真正的场景里，往往不止设置一种限流规则，而是会设置多个限流规则共同作用，主要以下 4 种规则：

1. **QPS 和连接数控制**：Nginx、Gateway / Zuul、Redis + Lua、Sentinel、Guava#RateLimiter 等。
2. **传输速率**：Nginx 限制下载速度。
3. **黑白名单**：布隆过滤器。

![1647393890625](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393890625.png)

#### 3、分布式限流实现方案？

1. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
2. 所以，需要将限流信息，保存在一个中心化的组件上，这样它就可以获取到集群中所有机器的访问状态，从而实现分布式限流。

目前比较主流的**实现方案**有：

1. **网关层限流**：把限流规则应用在所有流量的入口处。
2. **中间件限流**：把限流规则存储在分布式环境中的某个中间件里，比如 Redis 缓存中，每个组件都可以从这里，获取到当前时刻的流量统计信息，从而决定是拒绝服务，还是放行流量。

#### 4、分布式限流算法 - 计数器算法？

![1647393051245](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393051245.png)

**概念**：

计数器算法，是指在指定的时间周期内，累加访问次数，如果达到设定的阈值，则触发限流策略，在下一个时间周期进行访问时，再将访问次数清零。

**实现**：此算法无论在单机，还是分布式环境下实现都非常简单，使用 `redis#incr` 原子自增性，再结合 key
的过期时间，可以轻松实现。

**缺点**：

1. 这个算法有一个临界问题，比如在上图中，在 0:00 到 1:00 内，只在 0:50 有 60 个请求，而在 1:00 到 2:00 之间，只在 1:10 有 60 个请求。
2. 虽然在 2 个一分钟的时间内，都没有超过 100 个请求，但是在 0:50 到 1:10 这 20 秒内，却有 120 个请求。
3. 虽然在每个周期内，都没超过阈值，但是在这 20 秒内，却已经远远超过了我们原来设置的 1 分钟内 100 个请求的阈值。

#### 5、分布式限流算法 - 滑动时间窗口算法？

![1647393095141](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393095141.png)

**概念**：

1. 为了解决计数器算法的临界值问题，于是就发明了滑动时间窗口算法，而在 TCP 网络通信协议中，就采用滑动时间窗口算法来解决网络拥堵问题的。
2. 滑动时间窗口，是将计数器算法中的实际周期，切分成多个小的时间窗口，分别在每个小的时间窗口中，记录访问次数，然后根据时间将窗口往前滑动，并删除过期的小时间窗口，最终只需要统计滑动窗口范围内的小时间窗口的总的请求数即可，本质上也是一种计数器算法。

**优点**：

1. 在上图中，假设我们设置一分钟的请求阈值是 100，则将一分钟拆分成 4 个小时间窗口，这样，每个小的时间窗口只能处理 25 个请求，用虚线方框表示滑动时间窗口，当前窗口的大小是 2，也就是在窗口内最多能处理50 个请求。
2. 随着时间的推移，滑动窗口也随着时间往前移动，比如上图开始时，窗口是 0:00 到 0:30 的这个范围，过了15 秒后，窗口右移到 0:15 到 0:45 的这个范围，窗口中的请求重新清零，很大地减少了计数器算法临界值问题出现的概率。
3. 在滑动时间窗口算法中，我们的小窗口划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。

**缺点**：滑动时间窗口算法，本质上还是计数器算法，所以极端情况下，还是会出现临界值问题，使用令牌桶算法则可以很好地解决这个问题。

#### 6、分布式限流算法 - 漏桶算法？

![1647394890225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394890225.png)

**概念**：

1. 漏桶算法的原理，就像它的名字一样，维持一个漏斗，拥有恒定的流出速度，不管水流流入的速度有多快，漏斗出水的速度始终保持不变。
2. 类似于消息中间件，不管消息的生产者请求量有多大，消息的处理能力取决于消费者。
3. `漏桶的容量 = 漏桶的流出速度 * 可接受的等待时长`，在这个容量范围内的请求，可以排队等待系统的处理，超过这个容量的请求，才会被抛弃。

**限流规则**：

在漏桶限流算法中，存在下面几种情况：

1. 当请求速度大于漏桶的流出速度时，也就是请求量大于当前服务所能处理的最大极限值时，会触发限流策略。
2. 当请求速度小于或等于漏桶的流出速度时，也就是服务的处理能力大于或等于请求量时，则正常执行。s

**缺点**：当系统在短时间内，有突发的大流量时，漏桶算法处理不了。

**优点**：桶末端流量匀速流出，能够保证系统平稳运行，不用应对突发流量。

#### 7、分布式限流算法 - 令牌桶算法？

![1647394814391](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394814391.png)

**概念**：

1. 令牌桶算法，是增加一个大小固定的容器，也就是令牌桶，系统以**恒定的速率**向令牌桶中放入令牌，当令牌桶满时，再向令牌桶生成令牌时，令牌会被抛弃。
2. 如果有客户端来请求，先需要从令牌桶中拿一个令牌，拿到令牌，才有资格访问系统，这时令牌桶中少一个令牌。

**匀速要生成令牌原因**

1. **提高令牌利用率**：
   - 1）如果前 1 秒，一把梭哈了 10 个，但桶里都有 9 个了，此时只利用了 1 个令牌，其余 9 个令牌都会被丢弃。
   - 2）而如果匀速生成的话，就可以先 10 个令牌一个一个的发放，这样令牌也不至于被梭哈式的丢弃掉，提高了令牌的利用率。
2. **避免服务雪崩**：
   - 1）计数器算法和滑动时间窗口算法，在极端情况下，都会存在一个**临界值的问题**，即虽然某个统计窗口内没超过系统阈值，但前后区间总和却远远超过了系统阈值，从而有可能造成服务响应超时，甚至发生服务雪崩。
   - 2）采用匀速令牌生成，则可以避免某个区间前后之和大于系统阈值，因为**这个和 = 桶容量大小 + 令牌生成速度 * 区间跨度**，可见，令牌生成速度如果是匀速的话，那么这个和就会被限定在一个很小的值，从而可以很好的解决，上述那种人造区间洪峰流量的攻击，避免服务雪崩。

**限流规则**：

在令牌桶算法中，存在以下几种情况：

1. **请求速度大于令牌的生成速度**：那么令牌桶中的令牌会被取完，后续再进来的请求，由于拿不到令牌，会被限
   流。
2. **请求速度等于令牌的生成速度**：那么此时系统处于平稳状态。
3. **请求速度小于令牌的生成速度**：那么此时系统的访问量远远低于系统的并发能力，请求可以被正常处理。

**优点**：令牌桶算法，由于有一个桶的存在，可以处理短时间大流量的场景，这是令牌桶算法和漏桶算法的区别。

**缺点**： 由于可能会存在突发的大量，对系统设计时，需要保留一定的余力去面对。

### 2.5. 分布式文件存储？

#### 1、什么是分布式文件系统？

![1647397927726](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647397927726.png)

1. 随着文件数据的越来越多，通过 tomcat 或者 nginx 虚拟化的静态资源文件，在单一的一个服务器内已经存不下了，如果用多个节点存存储又不利于管理和维护，所以，需要一个系统来管理多台计算机节点上的文件数据，这个系统就是分布式文件系统。
2. 分布式文件系统，是一个允许文件，通过网络在多台节点上分享的文件系统，多台计算机节点，共同组成一个整体，为用户提供更大的文件存储空间。

#### 2、分布式文件系统的优点？

1. **海量文件数据存储**。
2. **文件数据高可用（冗余备份）**。
3. **读写性能好和支持负载均衡**。

#### 3、什么是 Fast DFS？

1. Fast DFS，是一个开源的轻量级的分布式文件系统，用于对文件进行管理，包括：文件存储、文件同步、文件上传、文件下载等。
2. 解决了大容量存储和负载均衡的问题，特别适合以文件为载体的在线服务，比如相册网站、视频网站等。

#### 4、Fast DFS 核心组件？

1. **tracker**：追踪者服务器，主要用于协调调度，起负载均衡的作用，记录 storage 的相关状态信息。
2. **storage**：存储服务器，用于保存文件，以及文件的元数据信息。
3. **group**：组，同组节点提供冗余备份，不同组用于扩容。
4. **mata data**：文件的元数据信息，比如长宽信息、图片后缀，视频帧数等信息。

#### 5、Fast DFS 文件上传流程？

1. Fast DFS 启动后，storage 会定期向 tracker 发送心跳续约。
2. 此时，一个客户端发起一个文件上传请求给 Fast DFS。
3. Fast DFS#tracker 收到请求后，则首先检查目前是否还有可用的 storage。
4. 检查到有，则返回可用的 storage 地址给客户端。
5. 客户端到后，则携带文件数据，到目标 storage 地址上传文件。
6. storage 服务接收文件，把文件写入磁盘中。
7. storage 文件写入磁盘成功后，则组装返回**文件对象信息**给客户端，包括文件相对路径、组名、文件名、文件 ID 等。
8. 客户端收到文件对象信息后，则做关于文件的一些业务处理，比如保存好文件存储的 ID 和路径等。

![1647398273896](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647398273896.png)

#### 6、Fast DFS 文件下载流程？

1. Fast DFS 启动后，storage 会定期向 tracker 发送心跳续约。
2. 此时，一个客户端发起一个文件下载请求给 Fast DFS。
3. Fast DFS#tracker 收到请求后，则首先根据**文件对象信息**（比如文件存储 ID），查找对应的 storage 地址。
4. 查找到，则返回对应的 storage 地址给客户端。
5. 客户端收到后，则到目标 storage 地址，文件进行下载。
6. storage 服务根据客户端给到的文件存储地址，查找所要下载的文件。
7. storage 找到文件后，则输出文件字节流给客户端。
8. 客户端收到文件流数据后，则可以进行文件下载或者展示。

![1647398629900](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647398629900.png)

#### 7、Fast DFS vs HDFS？

- **HDFS**：Hadoop 的默认存储方式，主要解决并行计算中大数据存储的问题，采用分块存储技术，适用于**大文件存储**。
- **Fast DFS**：主要是为文件上传和下载提供在线服务，支持负载均衡和动态扩容，适用于**中小文件存储**，比如用户头像、小视频等。

### 2.6. 分布式搜索？

#### 1、什么是分布式搜索？

分布式搜索，可以将更大范围分布的异构数据联合起来，形成一个逻辑整体，为用户提供强大的**全文检索**能力。

![1647400157225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647400157225.png)

#### 2、Lucene、Solr、ElasticSearch？

- **Lucene**：是一个基于 Java 的类库，集成了许多 API 方法，相当于一个 Jar 包，只能给 Java 使用，实现集群十分复杂。
- **Solr**：Apche 的开源项目，也是用的 Java 开发，基于 Lucene 的开源搜索引擎，本质上是对 Lucene 进行的一层封装，可以实现集群，可靠性，容错性高。
- **ElasticSearch**：也叫 ES，基于 Lucene 开发，提供很多 RestFul 风格的接口，可供其他语言使用，可扩展性更高，支持 PB 级别的近实时搜索。

#### 3、倒排索引 vs 正排索引？

- **正排索引**：文档 => 关键词，但在检索关键词时很费力，要一个文档一个文档，挨个遍历查找。
- **倒排索引**：关键词 => 文档，可以根据关键词，立马找到其出现过的所有文档。

#### 4、ES 核心概念？

1. **Near Realtime**：NRT，近实时，两个意思：
   - 1）从写入数据到数据可以被搜索到有一个小延迟（大概1秒）。
   - 2）基于es执行搜索和分析可以达到秒级。
2. **Cluster**：
   - 1）集群，包含多个节点，通过配置集群名称，来划分每个节点所属集群。
   - 2）对于中小型应用来说，刚开始一个集群只有一个节点很正常。
3. **Node**：节点，集群中的一个节点，节点也有一个名称，默认随机分配。
4. **index**：
   - 1）索引，包含一堆有相似结构的文档数据，比如客户索引、商品分类索引、订单索引。
   - 2）索引有一个名称，一个 index 包含很多 document，一个 index 就代表了一类类似的或者相同的document 。
   - 3）在 ES 5.x 版本以前，可以在一个索引中定义多个类型，6.x 之后一个索引只能创建一个类型，在 7~8.x 版本中，已经被彻底移除了。
5. **type**：类型，每个索引里都可以有一个或多个 type，type 是 index 中的一个逻辑数据分类，一个 type 下的document，都有相同的 field。
6. **document**：文档，是 ES 中的最小数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示，每个 index 下的 type 中，都可以去存储多个 document。
7. **field**：属性，一个 document 里面有多个 field，每个 field 就是一个数据字段。
8. **shard**：
   - 1）分区，单台机器无法存储大量数据，ES 就把一个索引中的数据，切分为多个 shard，分布在多台服务器上存储。
   - 2）有了 shard 就可以横向扩展，以存储更多数据，让搜索和分析等操作，分布到多台服务器上去执行，提升吞吐量和性能。
9. **replica**：
   - 1）副本，任何一个服务器随时都可能故障或宕机，导致 shard 可能就会丢失，因此，ES 为每个 shard 创建多个 replica 副本。
   - 2）replica 可以在 shard 故障时，提供备用服务，保证数据不丢失。

| ES       | 类比于 MySQL 中的     |
| -------- | --------------------- |
| index    | 库                    |
| type     | 表                    |
| document | 行                    |
| field    | 列                    |
| mappings | 表结构                |
|          |                       |
| **ES**   | **类比于 Kafka 中的** |
| Node     | Broker                |
| shard    | Partition             |
| replica  | Partition#Replica     |

#### 5、ES 读写原理？

**写原理**：

1. 把索引拆分成多个 shard 分区，每个 shard 存储部分数据。
2. 其中，一个 shard 可以有多个备份，也就是说，每个 shard 都会有一个 primary shard 主分区，负责写入数据，还有几个 replica shard 副本分区。
3. primary shard 主分区写入数据之后，会将数据同步到其他几个 replica shard 副本上去。
4. 通过这个分区 + 副本机制，可以保证每个 shard 都有多个备份，如果某个机器宕机了，则还会有别的副本在别的机器上，从而实现高可用。
5. 如果某台 primary shard 主分区宕机，那么会由 master 节点，让那个宕机节点上的 primary shard 主分区的身份，转移到其他机器上的 replica shard 副本分区中。
6. 当宕机的那台机器修复完，并重启之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据，让集群恢复正常。
7. 而如果 master 节点宕机了，那么则会重新选举一个节点为 master 节点。

**读原理**：

1. 客户端发送一个搜索请求，协调节点会把请求发送给所有的 shard。
2. 然后这些 shard 会去自己里面查，找到可能会匹配到的 doc，返回给协调节点。
3. 协调节点再去 doc 里面去做匹配，找到最符合查询需要的那些 document。
4. 最后再给客户端返回。

#### 6、ES API 使用？

以下操作都是基于《elasticsearch-6.4.3》进行记录的~

##### 一、集群操作

###### 1）查询集群健康信息

```json
GET     /_cluster/health
```

##### 二、索引操作

###### 1）查看索引

```json
GET     _cat/indices?v
```

###### 2）创建索引

```json
PUT     /index_test

{
    "settings": {
        "index": {
            "number_of_shards": "2",
            "number_of_replicas": "0"
        }
    }
}
```

###### 3）删除索引

```json
DELETE      /index_test
```

###### 4）创建索引同时创建 mappings

```
PUT     /index_str

{
    "mappings": {
        "properties": {
            "realname": {
            	"type": "text",
            	"index": true
            },
            "username": {
            	"type": "keyword",
            	"index": false
            }
        }
    }
}
```

###### 5）为已存在的索引新增 mappings

1. 注意，某个 mappings 的属性一旦被建立，就不能再修改了，但还可以追加额外的属性。
2. **主要数据类型**有：
   - 1）**字符串型**：text、keyword。
   - 2）**整型**：long、Integer、short、byte。
   - 3）**浮点型**： double、short。
   - 4）**布尔型**：boolean。
   - 5）**日期型**：date。
   - 6）**对象型**：object（{ } 格式）。
   - 7）**数组型**：[ ] 格式，但里面的类型要一致。
3. **text vs keyword**：
   - **text**：会对内容进行分词，可以用于商品名称、商品详情、商品介绍。
   - **keyword**：不会对内容进行分词，需要精确匹配，可以用于订单状态、qq 号、微信号、手机号等。

```json
POST        /index_str/_mapping

{
    "properties": {
        "id": {
        	"type": "long"
        },
        "age": {
        	"type": "integer"
        },
        "nickname": {
            "type": "keyword"
        },
        "money1": {
            "type": "float"
        },
        "money2": {
            "type": "double"
        },
        "sex": {
            "type": "byte"
        },
        "score": {
            "type": "short"
        },
        "is_teenager": {
            "type": "boolean"
        },
        "birthday": {
            "type": "date"
        },
        "relationship": {
            "type": "object"
        }
    }
}
```

##### 三、文档操作

这些查询方式，称为 QueryString 查询方式。

###### 1）添加文档数据

注意，如果索引没有手动建立 mappings，那么插入文档时，则会根据文档类型自动设置属性类型，这就是 ES 的动态映射。

```json
POST /{索引名}/_doc/{索引ID}

{
    "id": 1001,
    "name": "imooc-1",
    "desc": "imooc is very good, 慕课网非常牛！",
    "create_date": "2019-12-24"
}
```

###### 2）删除文档

注意，文档删除不是立即删除，删除后文档还是会保存在磁盘上，当索引积累得越来越多时，ES 才会把那些曾经标识为删除的清理掉，此时才会真正的从磁盘上移出去。

```json
DELETE /my_doc/_doc/1

```

###### 3）局部更新文档

每次修改后，隐藏的 `version` 字段都会被更改。

```json
POST /my_doc/_doc/1/_update

{
    "doc": {
        "name": "慕课"
    }
}

```

###### 4）全量更新文档

每次修改后，隐藏的 `version` 字段都会 +1。

```json
PUT /my_doc/_doc/1

{
     "id": 1001,
    "name": "imooc-1",
    "desc": "imooc is very good, 慕课网非常牛！",
    "create_date": "2019-12-24"
}
```

###### 5）查询文档

```json
GET /index_demo/_doc/1
GET /index_demo/_doc/_search
```

**查询得到的结果**：

1. **_index**：文档数据所属索引。
2. **_type**：文档数据属于哪个类型。
3. **_id**：文档数据的唯一标识，类似于数据库中某张表的主键，可以自动生成或者手工指定。
4. **_score**：查询相关度，表示与用户查询条件的契合程度，分数越高，用户搜索体验越好。
5. **_version**：版本号。
6. **_source**：真实的文档数据，json 格式表示。

```json
{
    "_index": "my_doc",
    "_type": "_doc",
    "_id": "2",
    "_score": 1.0,
    "_version": 9,
    "_source": {
        "id": 1002,
        "name": "imooc-2",
        "desc": "imooc is fashion",
        "create_date": "2019-12-25"
    }
}
```

###### 6）定制文档查询结果

```json
GET /index_demo/_doc/1?_source=id,name
GET /index_demo/_doc/_search?_source=id,name

```

###### 7）查询文档是否存在

```json
HEAD /index_demo/_doc/1

```

##### 四、分词检索

###### 1）内置分词检索

**ES 内置分词器**：

1. **standard**：默认分词，单词会被拆分，大小会转换为小写。
2. **simple**：按照非字母分词，大小转为小写。
3. **whitespace**：按照空格分词，忽略大小写。
4. **stop**：去掉无意义的单词，比如 the / a / an / is 等等。
5. **keyword**：不做分词，把整个文本作为一个单独的关键词。

```json
POST /my_doc/_analyze

{
    "analyzer": "standard",
    "field": "name",
    "text": "text文本"
}

```

###### 2）IK 分词检索

```json
POST /_analyze

{
    "analyzer": "ik_max_word",
    "text": "上下班车流量很大"
}

```

##### 五、DSL 操作

DSL，Domain Specific Language，领域特定语言，是 ES 基于 JSON 格式的数据查询语言，相比于 Query String 方式，DSL 查询更加灵活，有利于复杂查询。

###### 1）查询所有文档

```json
POST     /shop/_doc/_search

{
    "query": {
        "match_all": {}
    },
    "_source": ["id", "nickname", "age"]
}

```

###### 2）term vs match

1. match 会对 `慕课网` 先进行分词，然后再查询。
2. 而 term 则不会，直接把 `慕课网` 作为一个 整的词汇去搜索。

```json
POST     /shop/_doc/_search

{
    "query": {
        "term": {
            "desc": "慕课网"
        }
    }
}

对比

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    }
}

```

###### 3）连续分词匹配查询

1. match 分词后，只要有匹配就返回。
2. match_phrase：分词结果必须在字段中包含，顺序还要与 query 中的相同才返回，而且必须是连续的。

```json
POST     /shop/_doc/_search

{
    "query": {
        "match_phrase": {
            "desc": {
            	"query": "大学 毕业 研究生",
            	"slop": 2
            }
        }
    }
}

```

###### 4）逻辑匹配查询

and / or 

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    }
}

+

{
    "query": {
        "match": {
            "desc": {
                "query": "xbox游戏机",
                "operator": "or"
            }
        }
    }
}

=> 相当于 select * from shop where desc='xbox' or|and desc='游戏机'

```

###### 5）匹配度查询

minimum_should_match，最低匹配精度，至少有 n% * query 中分词个数的文档才会被匹配。

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": {
                "query": "女友生日送我好玩的xbox游戏机",
                "minimum_should_match": "60%"
            }
        }
    }
}

```

###### 6）主键查询

```json
POST     /shop/_doc/_search

{
    "query": {
        "ids": {
            "type": "_doc",
            "values": ["1001", "1010", "1008"]
        }
    }
}


```

###### 7）多条件匹配

multi_match，多个字段同时满足条件，才会被匹配。

```json
POST     /shop/_doc/_search

{
    "query": {
        "multi_match": {
                "query": "皮特帕克慕课网",
                "fields": ["desc", "nickname"]

        }
    }
}

```

###### 8）权重查询 

权重，为某个字段设置权重，权重越高，文档相关性得分就越高，比如商品名称的权重，一般都比商品简介的权重要高。

```json
POST     /shop/_doc/_search

{
    "query": {
        "multi_match": {
            "query": "皮特帕克慕课网",
            -- nickname^10，表示搜索权重提升10倍相关性，搜索时以nickname为主，desc为辅
            "fields": ["desc", "nickname^10"]
        }
    }
}

```

###### 9）布尔查询

1. **must**：查询必须匹配搜索条件，类似于 and。
2. **should**：查询需匹配满足 1 个以上条件，类似于 or。
3. **must_not**：一个搜索条件都不能匹配。

```json
{
    "query": {
        "bool": {
            "must": [
                {
                	"match": {
                		"desc": "慕"
                	}	
                },
                {
                	"match": {
                		"nickname": "慕"
                	}	
                }
            ],
            "should": [
                {
                	"match": {
                		"sex": "0"
                	}	
                }
            ],
            "must_not": [
                {
                	"term": {
                		"birthday": "1992-12-24"
                	}	
                }
            ]
        }
    }
}

```

###### 10）过滤器

1. 过滤器，可以对搜索出来的结果进行数据过滤，可以和全文检索一起结合使用。
2. 过滤器类型：
   - **gte**：大于等于。
   - **lte**：小于等于。
   - **gt**：大于。
   - **lt**：小于。

```json
POST     /shop/_doc/_search

{
	"query": {
		"match": {
			"desc": "慕课网游戏"
		}	
    },
    "post_filter": {
		"range": {
			"money": {
				"gt": 60,
				"lt": 1000
			}
		}
	}	
}

```

###### 11）排序

类似于 sql 中的排序，asc 表示顺序，desc 表示逆序。

```json
POST     /shop/_doc/_search
{
	"query": {
		"match": {
			"desc": "慕课网游戏"
		}
    },
    "post_filter": {
    	"range": {
    		"money": {
    			"gt": 55.8,
    			"lte": 155.8
    		}
    	}
    },
    "sort": [
        {
            "age": "desc"
        },
        {
            "money": "desc"
        }
    ]
}

```

###### 12）高亮标签

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    },
    "highlight": {
        "pre_tags": ["<tag>"],
        "post_tags": ["</tag>"],
        "fields": {
            "desc": {}
        }
    }
}

```

###### 13）前缀匹配查询

```json
POST     /shop/_doc/_search

{
    "query": {
        "prefix": {
            "desc": "imo"
        }
    }
}

```

###### 14）错误纠偏查询

```json
POST     /shop/_doc/_search

{
  "query": {
    "fuzzy": {
      "desc": "imoov.coom"
    }
  }
}

```

###### 15）占位符查询

- **?**：占 1 个字符。
- *****：占 1 个或者多个字符。

```json
POST     /shop/_doc/_search

{
  "query": {
    "wildcard": {
      "desc": "*oo?"
    }
  }
}

```

###### 16）分页查询

```json
POST     /shop/_doc/_search

{
	"query": {
		"match_all": {}
	},
	"_source": [
		"id",
		"nickname",
		"age"
	],
	"from": 5,
	"size": 5
}

```

###### 17）滚动分页查询 | 解决深度分页问题

scroll=1m，相当于一个 session 会话时间，设置搜索保持的上下文为 1 分钟。

```json
-- 滚动分页第一次查询，开启滚动分页
POST    /shop/_search?scroll=1m
{
    "query": { 
    	"match_all": {
    	}
    },  
    "sort" : ["_doc"], 
    "size":  5
}

-- 滚动分页第二次查询
POST    /_search/scroll
{
    "scroll_id": "DnF1ZXJ5VGhlbkZldGNoBQAAAAABrDnhFnFiRFN6VFZEVDRLNXNCTFJKeHZkTkEAAAAAAaw55BZxYkRTelRWRFQ0SzVzQkxSSnh2ZE5BAAAAAAGsOeMWcWJEU3pUVkRUNEs1c0JMUkp4dmROQQAAAAABrDniFnFiRFN6VFZEVDRLNXNCTFJKeHZkTkEAAAAAAaw55RZxYkRTelRWRFQ0SzVzQkxSSnh2ZE5B",
    "scroll": "1m"
}

```

##### 六、批量操作

###### 1）批量获取文档

```json
GET http://10.18.12.149:9200/shop/_doc/_mget
{
    "ids": [
        "1001",
        "1003",
        "10015"
    ]
}

```

###### 2）批量插入文档及 mappings

```json
POST http://10.18.12.149:9200/_bulk

{"create": {"_index": "shop2", "_type": "_doc", "_id": "2004"}}
{"id": "2004", "nickname": "name-2004"}
{"create": {"_index": "shop2", "_type": "_doc", "_id": "2005"}}
{"id": "2002", "nickname": "name-2005"}
{"create": {"_index": "shop2", "_type": "_doc", "_id": "2003"}}
{"id": "2003", "nickname": "name-2003"}
```

###### 3）批量插入文档到已有索引中

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"create": {"_id": "2007"}}
{"id": "2004", "nickname": "name-2004"}
{"create": {"_id": "2008"}}
{"id": "2002", "nickname": "name-2005"}
{"create": {"_id": "2009"}}
{"id": "2003", "nickname": "name-2003"}
```

###### 4）批量更新或保存文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"index": {"_id": "2004"}}
{"id": "2004", "nickname": "index-2004"}
{"index": {"_id": "2007"}}
{"id": "2007", "nickname": "name-2007"}
{"index": {"_id": "2008"}}
{"id": "2008", "nickname": "name-2008"}
```

###### 5）批量更新文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"update": {"_id": "2004"}}
{"doc": {"id": "3304"}}
{"update": {"_id": "2007"}}
{"doc": {"nickname": "name-update"}}
```

###### 6）批量删除文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"delete": {"_id": "2001"}}
{"delete": {"_id": "2003"}}
{"create": {"_id": "8008"}}
{"id": "8008", "nickname": "name-8088"}
{"update": {"_id": "2002"}}
{"doc": {"id": "2222"}}
```



