# 二、JVM篇 

### 1.1. JDK、JRE、JVM的区别？

![1625884268478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625884268478.png)

从图中可以看出，**JDK包含了JRE，而JRE又包含了JVM**。

- **JDK**，Java Development Kit，是Java的软件开发工具包（SDK），包含JRE和Java工具。
- **JRE**，Java Runtime Environment，是Java的运行时环境，大部分都是C和C++语言编写的，可以在其上运行、测试应用程序的Java平台，包括JVM和Java核心类库。
- **JVM**，Java Virtual Machine，Java虚拟机，是一种用于计算设备的规范，是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的，屏蔽了与具体平台相关的信息，使得Java语言编译程序只需要在Java虚拟机上运行的字节码，就可以不加修改地在多种平台上运行。

### 1.2.  JVM整体架构？

![1625963806257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625963806257.png)

- JVM包含**2个子系统和2个组件**：2个子系统分别为Class Loader（类加载子系统）、Execution Engine（执行引擎）；2个组件分为别Runtime data area（运行时数据区）、Native Interface（本地接口）。
  - **Class loader（类加载子系统）**：根据给定的全限定名类名（如java.lang.Object）来装载class文件到Runtime data area中的Method Area（方法区）。
  - **Runtime data area（运行时数据区域）**：这就是我们常说的JVM的内存。
  - **Execution engine（执行引擎）**：执行class文件中的指令。
  - **Native Interface（本地接口）**：与native libraries交互，是其它编程语言交互的接口。
- 架构整体流程：

1. 通过编译器把 Java 代码转换成字节码，**类加载器（ClassLoader）**再把字节码加载到内存中，将其放在**运行时数据区（Runtime data area）**的方法区内。
2. 而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器**执行引擎（Execution Engine）**，将字节码翻译成底层系统指令，再交由 CPU 去执行。
3. 而这个过程中需要调用其他语言的**本地接口（Native Interface）**来实现整个程序的功能。

### 1.3. 详细介绍类加载机制？

![1625975271139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625975271139.png)

程序主动使用某个类时，如果这个类还未被加载到内存中，则JVM会通过**加载、链接、初始化**3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时也把这个3个步骤统称为**类加载或类初始化**。

1. **加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。

   - 加载过程需要**类加载器**参与。类加载器，可以从不同来源加载类的二进制数据，比如：本地Class文件、Jar包Class文件、网络Class文件等等。
   - Java类加载器由JVM提供，是所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。
   - 除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。
   - Java的类加载是动态的，不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类完全加载到JVM中。至于其他类，则**在需要的时候才加载**（为了节省内存开销）。
     - **隐式加载**：程序在运行过程中，当碰到通过new 方式生成对象时，将会隐式调用类装载器，加载对应的类到JVM中。
     - **显式加载**：通过class.forname（）反射方法，显式加载需要的类。
2. **链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：

   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
     - 文件验证：是否以0xCAFEBABE开头、版本号是否合理等。
     - 元数据验证：是否有父类、是否继承了final类、非抽象类是否实现了所有抽象方法等。
     - 字节码验证：运行检查、栈数据类型和操作码的操作参数是否吻合（不能大于栈空间）、跳转指令是否指向合理的位置。
     - 符号引用验证：常量池中描述的类是否存在、访问的方法或字段是否存在且有足够的权限。
     - 可使用**-Xverify:none**关闭验证：比如提高IDEA的启动速度。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。

   - 实际上，JVM不一定完全按照类加载机制顺序执行，比如解析操作有可能会发生在初始化操作之后。
3. **初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。

   - 执行< clinit >方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。
     - 初始化的顺序和源文件中的顺序一致。
     - 子类的< clinit >被调用前，会先调用父类的< clinit >。
     - JVM会保证clinit方法的线程安全性。
   - 即执行顺序为：JVMTest5静态块 -> super静态块 -> Sub静态块 -> Super构造块 -> Super构造方法 -> Sub构造块 -> Sub构造方法。
     - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
     - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
     - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

```java
// JVMTest5不用被实例化，所以不会调用JVMTest5的构造块和构造方法
public class JVMTest5 {
    static {
        System.out.println("JVMTest5静态块");
    }

    {
        System.out.println("JVMTest5构造块");
    }

    public JVMTest5() {
        System.out.println("JVMTest5构造方法");
    }

    public static void main(String[] args) {
        new Sub();
    }
}

class Super {
    static {
        System.out.println("Super静态块");
    }

    public Super() {
        System.out.println("Super构造方法");
    }

    {
        System.out.println("Super构造块");
    }
}

class Sub extends Super {
    static {
        System.out.println("Sub静态块");
    }

    public Sub() {
        System.out.println("Sub构造方法");
    }

    {
        System.out.println("Sub构造块");
    }
}
```

### 1.4. 什么是类加载器？类加载器有哪些？

![1625986988156](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625986988156.png)

**类加载器**，是能够实现通过类的全限定名，获取该类的二进制字节流的**代码块**。JVM提供了3种类加载器，启动类加载器、扩展类加载器、系统类加载器（也叫应用类加载器），以及用户自定义的类加载器（其父类为应用类加载器）。

- **启动类加载器**：Bootstrap ClassLoader，该类加载使用C++实现，其引用为null，无法被java程序直接引用。用于加载Java核心类库，即负责把**/lib**目录下或者**-Xbootclasspath**参数指定路径下的Jar包加载到内存中。
  - 注意，JVM是按照文件名识别加载Jar包，如rt.jar，如果文件名不被虚拟机识别，即使把Jar包丢到lib目录下也是没有作用的。
  - 处于安全考虑，启动类加载器只能加载包名为java、javax、sun等开头的类。

- **扩展类加载器**：ExtClassLoader，由Java实现，父类加载器为启动类加载器（持有为null的parent引用，并不是真正的继承关系）。用于加载 Java 的扩展库，即负责把**/lib/ext**目录下或者**-Djava.ext.dir**参数指定路径下的类库加载到内存中。
  - 开发者可以直接使用标准的扩展类加载器。
- **系统类加载器**：AppClassLoader，也叫应用类加载器，由Java实现，父类加载器为ExtClassLoader（持有ExtClassLoader的parent引用，并不是真正的继承关系）。用于加载一般的Java 应用类，即负责把**java -classpath**或者**-D java.class.path**指定路径下的类库加载到内存中。
  - 一般情况下，系统类加载器是程序中默认的类加载器。
  - 开发者可以直接使用应用类加载器，可以通过**ClassLoader.getSystemClassLoader（）**来获取。
- **用户自定义的类加载器**：用户可以通过继承 java.lang.ClassLoader类的方式，来自定义自己的加载器。
  - 应用场景：
    - 加密编译后的class字节码 ->  自定义ClassLoader -> 加载该class时解密字节码。
    - 自定义ClassLoader，加载时从非标准来源加载字节码：比如数据库、网络上。

### 1.5. 什么是双亲委派机制？

#### 概念

加载器之间存在着"父子关系"（区别于Java里的继承），子加载器保存着父加载器的引用。

1. 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回。
2. 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到，则解析或者返回。
3. 如果找不到，才会交还子加载器加载目标类，查找逻辑交由子加载器实现。

#### 实现原理

- **java.lang.ClassLoader**：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法。
- **loadClass（String，boolean）**：类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找。
- **findClass（String）**：加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用**defineClass（String，Resource）**方法生成Class对象。
- **resolveClass（Class<?>）**： 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值。
- **defineClass（String，Resource）**：在Java堆区生成Class对象。

```java
// java.lang.ClassLoader#loadClass：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法
public abstract class ClassLoader {
    
    // 类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            // 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回
            Class<?> c = findLoadedClass(name);// native方法
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    // 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到则解析或者返回
                    if (parent != null) {
                        c = parent.loadClass(name, false);
                    } 
                    // 交由启动类加载器加载
                    else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }

            // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
            if (resolve) {
                resolveClass(c);
            }

            // 返回class
            return c;
        }
    }
    protected final Class<?> findLoadedClass(String name) {
        if (!checkName(name))
            return null;
        return findLoadedClass0(name);
    }
    private native final Class<?> findLoadedClass0(String name);
    
    // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
    private native void resolveClass0(Class<?> c);

    // 加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用defineClass(String，Resource)方法生成Class对象
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
}
```

#### 双亲委派模型好处

- 此机制保证了Java核心类库被优先加载，避免了用户编写的类动态替换Java核心类的错误，使得Java程序能够稳定运⾏。
- 同时也避免了类的重复加载，使用双亲委派模型，JVM能够根据**类的完整类名+ClassLoader实例对象**来区分不同的类。如果不使⽤双亲委派模型，⽽是每个类加载器⾃⼰加载的话，会出现⼀些问题。⽐如编写⼀个称为 java.lang.Object 类的话，在程序运⾏的时候，系统会有多个不同的Object 类，此时会出现Object类的选择问题。

#### 双亲委派模型局限

1. SPI接口，Service Provider Interface，允许第三方为其提供实现，如JDBC、JNDI等 。
2. SPI接口属于Java核心类库，由启动类加载器加载（rt.jar），而SPI的第三方代码则是作为Java应用所依赖的Jar中（Classpath下）。
3. 其中SPI接口中的代码经常需要加载具体的第三方实现类，并调用其相关方法，此时由于双亲委派模型的存在，启动类加载器无法直接加载SPI实现类，也无法反向委托给系统类加载器加载，从而让JDK SPI机制产生了问题。

#### 打破双亲委派模型

如果不想打破双亲委派模型，则只需要重写findClass方法即可；如果想打破双亲委派模型，则需要重写整个loadClass方法。

##### 线程上下文类加载器

- **背景**：由于双亲委派模型存在SPI局限，需要一种特殊的类加载器来加载第三方类库，此时线程上下文加载器是个很好的选择。
- **线程上线文类加载器**：是从JDK 1.2开始引入的，可以通过java.lang.Thread#getContextClassLoader（）和setContextClassLoader（ClassLoader）方法来获取和设置线程的上下文类加载器。如果没有手动设置，则线程将会继承父线程的上下文类加载器，默认为系统类加载器，即在线程中运行的代码可以通过此类来加载Classpath下的类和资源。
- **打破双亲委派**：从图中可以看到，启动类加载器委派线程上下文加载器，把jdbc.jar中的实现类加载到内存中以便SPI相关类使用，因此打破了双亲委派模型，使得Java类加载更加灵活。

![1625996283343](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625996283343.png)

- **实现原理**：
  - contextClassLoader是在ClassLoader.SystemClassLoaderAction#run（）方法进行了赋值，其中构造了**java.system.class.loader**加载器实例（实际上为AppClassLoader？），并持有当前加载器的parent作为其父加载器。
  - 接着，ClassLoader.SystemClassLoaderAction#run（）方法通过Thread#setContextClassLoader（ClassLoader）设置到当前线程的实例变量中，从而使得当前Thread实例持有contextClassLoader的引用。
  - 最后，java.sql.DriverManager在调用sevice.loader（Driver.class）时，jdbc.jar中在META-INF/sevice/java.sql.Driver配置的**com.mysql.cj.jdbc.Driver**，就会在java.util.ServiceLoader#load（Class）方法调用Thread.currentThread().getContextClassLoader()时进行类加载，从而达到SPI的目的。
  - 可以看出虽然java.util.ServiceLoader是rt.jat包的核心类库，由启动类加载器加载，但通过Thread.currentThread().getContextClassLoader()确实加载到了第三方包下的com.mysql.cj.jdbc.Driver，因此线程上下文类加载器可以打破双亲委派模型。

```java
// java.sql.DriverManager，启动类加载器加载
public class DriverManager {
 	static {
        loadInitialDrivers();
        println("JDBC DriverManager initialized");
    }
    
    private static void loadInitialDrivers() {
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                // SPI加载
                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
                Iterator<Driver> driversIterator = loadedDrivers.iterator();
            }
            ...
        }
    }      
}    


// java.util.ServiceLoader，启动类加载器加载
public final class ServiceLoader<S>implements Iterable<S> {  
    // SPI加载: 获取当前线程上下文类加载器进行SPI加载，从而打破了双亲委派模型
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    ...
}
```

##### Tomcat类加载机制

- **背景**：
  - a. 一个web容器可能要部署两个或者多个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，因此要保证每一个应用程序的类库都是**独立、相互隔离**的。
  - b. 同一个web容器中的**相同类库的相同版本**可以共享，否则会有**重复的类被加载进JVM**。
  - c. **web容器也有自己的类库**，不能和应用程序的类库混淆，基于安全考虑，需要相互隔离。
  - d. Jsp文件也是要编译成class文件的，web容器需要支持在**Jsp**文件修改后，可以实现**HostSwap（热替换）**的功能。

![1626065847576](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626065847576.png)

- **类加载器逻辑关系**：

  Common、Catalina、Shared类加载器（本质上是URLClassLoader）分别加载/common/、/server/、/shared/路径下的Class，但在Tomcat6后已经统一合并到了/lib目录下了。

  - **CommonClassLoader**：Tomcat最基本的类加载器，加载对应路径中的Class，可**以被Tomcat容器本身以及各个webapp访问**。
  - **CatalinaClassLoader**：Tomcat容器私有的类加载器，加载对应路径中的class，**对于webapp不可见**。
  - **SharedClassLoader**：各个webapp共享的类加载器，加载对应路径中的class，**对于所有webapp可见，但对于Tomcat容器不可见**。
  - **WebappClassLoader**：各个webapp私有的类加载器，每一个webapp对应一个WebAppClassLoader实例，加载路径中的class，**只对当前webapp可见**。
  - **JasperClassLoader**：
    - 每一个Jsp文件对应一个JasperClassLoader实例，**加载范围仅仅是这个Jsp文件所编译出来的那一个Class文件**。
    - JasperClassLoad出现的目的就是为了被丢弃，当Web容器检测到Jsp文件被修改时，会替换掉目前的JasperClassLoader实例，并通过重新建立一个新的JasperClassLoader实例来实现JSP文件的HostSwap（热替换）功能。

![1626066067882](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626066067882.png)

![1626090586657](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090586657.png)

- **类加载流程**：WebappClassLoaderBase#loadClass(String, boolean)流程：

1. 先查找Tomcat缓存，如果找得到，则返回Tomcat缓存中的Class对象。
2. 如果Tomcat缓存中找不到，则查找JVM缓存，如果找得到，则返回JVM缓存中的Class对象。
3. 如果JVM缓存中也找不到，则用扩展类加载器来加载（**重点！这里并没有首先使用系统类加载器，而是直接使用了扩展类加载器来加载，也就是打破了系统类加载器的双亲委派机制**），根据双亲委派机制，扩展类加载器会委派启动类加载器来加载Class，从而保证了JRE核心类库不会被重复加载。
4. 如果指定了delegateLoad（需要先委托父类加载），则**先调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保持顺序加载机制），如果找不到**才调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），找到则返回，找不到则抛出ClassNotFoundException异常。
5. 如果没有指定delegateLoad（需要先委托父类加载），则**先调用调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），如果找不到**才调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保底机制），找到则返回，找不到则抛出ClassNotFoundException异常。

![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

- **总结**：可以看到，Tomcat#WebappClassLoaderBase的类加载机制是**打破了双亲委派模型**的：
  - **ext -> bootstarp模型**：保证了JRE核心类库不会被重复加载，满足了背景b加载JVM共同类库的需求。
  - **ext -> webapp模型**：实现了每个web应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离，满足了背景a的需求。
  - **webapp -> share -> common模型**：实现了所有web应用之间、web与Tomcat之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了背景b加载其他共同类库的需求。
  - **（不确定）catalina -> 父类加载器模型**：实现了只加载Tomcat容器自身的类库，对于webapp是看不到的（可在config/catalina.properties的server.loader中配置jar和class的路径），满足了背景c的需求。
  - **（不确定）Jsp -> webapp -> 父类加载器模型**：通过在jsp修改后卸载再生成新的Jsp类加载器，重新加载新生成的Jsp class，从而实现Jsp的HostSwap（热替换），满足了背景d的需求。

### 1.6. JVM运行时数据区？

![1626181528728](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181528728.png)

JVM在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。

这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着JVM进程的启动而存在（**线程共享**），有些区域则是依赖线程的启动和结束而建立和销毁（**非线程共享**）。

JVM所管理的内存被划分为如下几个区域：

- **程序计数器**：Program Counter Register，非线程共享，JVM当前线程所执行的**字节码的行号指示器**，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。
- **虚拟机栈**：Java Virtual Machine Stacks，非线程共享，每个方法在执行的同时都会在Java 虚拟机栈中创建一个栈帧（Stack Frame），用于存储**局部变量表、操作数栈、动态链接和方法返回地址**；
- **本地方法栈**：Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。

### 1.7. 详细介绍程序计数器？

- **概念**：程序计数器，Program Counter Register，非线程共享，JVM当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。

- **出现的原因**：由于JVM多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，需要**记住原线程的下一条指令的位置**，所以每条线程都要有一个独立存储、互不影响的程序计数器，称之为“**线程私有**”的内存。

- **例子**：

  1. 比如线程A在看直播。
  2. 突然，线程B来了一个视频电话，就会抢夺线程A的时间片，就会打断了线程A，线程A就会挂起。
  3. 然后，视频电话结束，如果没有线程计数器，此时线程A就不知道要干什么了；如果有线程计数器，此时线程A就可以想起来要去看直播了。

  => 线程是最小的执行单位，不具备“记忆”功能，只负责去干，这就需要**由程序计数器来为线程提供保护和恢复现场**的功能。

### 1.8. 详细介绍虚拟机栈？

![1626137840755](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626137840755.png)

Java虚拟机栈**是线程私有的（非线程共享）**，每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致。单位是**栈帧**，在每个方法执行的时候，都会创建一个栈帧，在被调用直至执行完毕的过程，对应一个栈帧在虚拟机栈中**从入栈到出栈**的过程。

每个栈帧都存放着**局部变量表、操作数栈、动态链接和方法返回地址**。

> 在JVM规范中，对此区域规定了两种异常状况：在固定情况下，如果线程请求的栈深度大于虚拟机所允许的最大栈深度，则会抛出**StackOverflowError**异常；在可动态扩展情况下，如果虚拟机栈无法申请到足够的内存，或者在创建新线程的时候没有足够的内存去创建对应的虚拟机栈，则会抛出**OutOfMemoryError**异常。

在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

- **局部变量表**：

  - 是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。
  - 存放了编译期可知的各种**基本数据类型**（boolean、byte、char、short、int、float、long、double，对包装类型在栈中保存地址、在堆中保存值）、**对象引用**（Reference类型，可能是一个指向对象起始地址的引用指针，也可能是一个代表对象的句柄或者其他与对象相关的位置）和**returnAddress类型**（指向下一条字节码指令的地址）。
  - 局部变量表所需的内存空间在编译期间完成分配，方法在运行之前，该局部变量表所需要的内存空间是固定的，运行期间不会发生改变。

- **操作数栈**：

  - 用于保存计算过程中的**中间结果**，同时作为计算过程中变量临时的存储空间。
  - 操作数栈在方法的执行过程中，根据字节码指令往操作数栈中写入数据或提取数据，即入栈和出栈操作。
  - 比如add（）方法执行过程中，其操作数栈与局部变量表的交互顺序为：15入栈（操作数栈写入数据） -> 15出栈（操作数栈提取数据到局部变量表） -> 1入栈（操作数栈写入数据） -> 1出栈（操作数栈提取数据到局部变量表） -> 15入栈（加载局部变量表变量15） -> 1入栈（加载局部变量表变量1） -> iadd（执行相加15 + 1指令） -> 16出栈（操作数栈提取结果到局部变量表）-> return（如果返回值为void，则当前栈帧出栈即可，如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中）。

  ```java
  public class Test {
      public void add() {
          int a = 15;
          int b = 1;
          int c = a + b;
      }
  }
  ```

- **动态链接**：

  - 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接（Dynamic Linking）。
  - Class 文件的常量池中存在大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数，这些符号引用一部分会在类加载阶段或**第一次使用时转化为直接引用，这种转化成为静态解析**。另一部分将在**每一次运行期间转化为直接引用，这部分称为动态连接**。

- **方法返回地址**：returnAddress类型（**指向下一条字节码指令的地址**）:

  - 当一个方法开始执行后，只有两种方式可以退出这个方法。一种是执行引擎遇到**任意一个方法返回的字节码指令**，这时候可能会有返回值传递给上层方法的调用者，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为**正常完成出口**。
  - 另一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是 Java 虚拟机内部产生的异常，还是代码中使用 athrow 字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种称为**异常完成出口**。一个方法使用异常完成出口的方式退出，是不会给上层调用者产生任何返回值的。
  - 无论采用何种退出方式，在方法退出后都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来恢复它的上层方法的执行状态。一般来说，方法正常退出时，**调用者的PC计数器的值可以作为返回地址**，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。
  - 方法退出的过程实际上就等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上次方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，**调整PC计数器的值以指向方法调用指令后面的一条指令等**。

- 附加信息：虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如与调试相关的信息，这部分信息完全取决于具体的虚拟机实现。实际开发中，一般会把动态连接、方法返回地址与其他附加信息全部归为一类，成为栈帧信息。

### 1.9. 详细介绍本地方法栈？

- 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- Native方法是看不到的，必须要去oracle官网去下载才可以看的到，而且native关键字修饰的大部分源码都是C和C++的代码。
- 在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，因此同样会抛StackOverflowError异常，以及OutOfMemoryError异常。
  - 在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

### 2.0. 详细介绍堆？

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
  - 非栈上分配情况下，**创建的对象会存储在堆内存中，在栈上存储该对象的引用**（栈空间只包含方法基础数据类型的局部变量以及引用堆对象的引用变量）。
  - ClassA a = new ClassA（）；此时a叫实例，不能说a对象，**实例在栈上，对象在堆中**，操作实例实际上是通过实例指针间接操作对象，多个实例可以指向同一个对象。
  - 栈中的数据和堆中的数据销毁并不是同步的，方法一旦结束，**栈中的局部变量会立即销毁**；堆中的对象不一定会销毁，因为可能有其他变量也指向了该对象，直到没有变量指向该对象，才有可能会被垃圾回收。
  - 类的成员变量在对象中，每个对象都有自己成员变量的存储空间；而**类的方法只有一套**，存储在方法区中，被该类的所有对象共享，对象在使用方法的时候才会将方法压入栈中，而**方法在不使用时并不会占用内存**。
- 对象在堆中分配好以后，会在栈中保存一个4字节的实例（指向对象堆内存地址），用来定位对应的对象在堆中的位置，便于找到该对象。但在开启逃逸分析后，某些未逃逸的对象也可以通过标量替换的方式在**栈上分配**。
- 堆是垃圾回收（GC）的主要场所，从内存回收角度来看，可以分为**新生代和老年代，默认内存大小比值为1：2**，对于新生代又可以分为**Eden区（伊甸园）、Survivor区（存活区），默认内存大小比值默认为8：2**，而Survivor区又分为**Surviver0（From Survivor）和Survivor1（To Survivor），默认内存大小比值默认为1：1**。
- **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **优点 - 加速对象分配**：
    - 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM底层采用CAS + 失败重试的方式来做同步处理，如果多线程竞争非常激烈，那么此时在堆中分配对象性能是非常差的。因此，JVM设计了TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **缺点 - 大对象无法分配**：TLAB空间比较小，所以大对象无法在TLAB分配，这时只能直接分配到线程共享的堆里面。
- 堆可以处于物理上不连续的内存空间中，可通过 -Xmx（最大堆内存）和 -Xms（初始堆内存） 来扩展空间大小。如果堆中没有内存可以完成对象分配，且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

### 2.1. 详细介绍方法区？

![1626181213768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181213768.png)

- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - **永久代**：是Hotspot虚拟机特有的概念（在别的JVM没有），是方法区的一种实现，主要存放类信息、常量等方法区内容。
    - 在JDK1.6 中，方法区中包含的数据，除了JIT编译生成的代码是存放在native memory的CodeCache区域，其他都存放在永久代。
    - 移除永久代的工作从JDK1.7就开始了，在JDK1.7中，存储在永久代的部分数据就已经转移到了Java Heap或者是Native Heap。但永久代仍存在于JDK1.7中，并没完全移除，比如**符号引用**（Symbols）转移到了native heap，**字面量**（interned strings，见字符串常量池）转移到了java heap，**类的静态变量**（class statics）转移到了java heap。
    - 在Java 8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存：元空间（Metaspace）中，此时‑XX：MaxPermSize 参数失去了意义，取而代之的是-XX：MaxMetaspaceSize。
  - **元空间**：JDK8后用于替代永久代，存储类的元数据信息，存放在本地内存中。
    - **元空间与永久代最大的区别**：元空间并不是在JVM虚拟机中 ，而是使用了本地内存，默认情况下，元空间的大小仅受本地内存限制，解决了永久代容易溢出的问题。
  - **元空间替代永久代的原因**：
    - 字符串存在永久代中，容易出现性能问题和内存溢出。
    - 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则会导致空间的浪费。
    -  JRockit虚拟机方法区没有永久代的实现，Oracle需要将HotSpot与JRockit合二为一 ，剔除永久代。
    - （？）永久代会为GC带来不必要的复杂度，并且回收效率偏低。
- 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。
  - **常量池 - 静态常量池**：也叫class文件常量池，即class文件中的常量池，占用class文件绝大部分空间。主要存放：
    - **字面量**：相当于Java语言层面常量的概念，如文本字符串、final修饰的变量。
    - **符号引用**：属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
  - **常量池 - 运行时常量池**：当class文件加载到内存后，JVM会将静态常量池中的内容存放到运行时常量池中，这就是常说的“常量池”，主要存放：
    - 编译期间产生的字面量、符号引用。
    - 注意，运行时常量池具有动态性，也就是并非只有通过class文件常量池才能进入，运行期间也可能将新的常量放入池中，比如调用String#intern（）方法。
  - **常量池 - 字符串常量池**：可以理解为运行时常量池中分出来的一部分，当类加载到内存时，**字符串**会存到字符串常量池里面，即在编译阶段把所有字符串放到一个常量池中。
    - String#intern（）方法，native方法，返回规范的字符串，equals判断常量池是否有存在的字符串，如果没有则会将实参字符串加入常量池。
    - 程序运行时，除非手动向常量池中添加常量，比如调用String#intern（）方法，否则JVM不会自动添加常量到常量池。
    - 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量则会加入常量池；如果是变量，由于地址不能确定，所以在不调用String#intern（）时是并不会加入常量池的。
    - JDK5以后，除了有字符串常量池，实际上还有数值型常量池，也就是Java中大部分基本类型的包装类都实现了常量池技术，比如Byte、Short、Integer、Long、Character、Boolean，而两种浮点数类型的包装类Float、Double并没有实现常量池技术。其中，只有Integer常量池缓存区间（-128~127），可通过-XX:AutoBoxCacheMax参数进行设置。
  - **常量池的好处**：
    - 常量池是为了避免频繁的创建和销毁对象而影响系统性能，实现了对象的共享。
    - 常量池可以节省内存空间：常量池中所有相同的字符串常量被合并，只占用一个空间。
    - 常量池可以节省运行时间：在比较字符串时，==比equals（）快，所以对于两个引用变量，只用==判断引用是否相等，就可以判断实际值是否相等了。
- 垃圾回收在方法区出现得比较少，这个区域回收的目的主要是针对**常量池的回收和类的卸载**。
- 方法区也是可以由内存不连续的内存区域组成，也是可扩展的，当方法区无法满足内存分配需求时，则会抛出OutOfMemoryError异常。

### 2.2. 堆和虚拟机栈的区别？

|              | 堆                                                           | 虚拟机栈                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 物理地址     | 堆的物理地址是不连续的，因此分配对象的速度较慢               | 虚拟机栈使用的是栈数据结构，物理地址是连续的，因此分配对象的速度较快 |
| 内存大小     | 由于堆是不连续的，所以分配到的内存是在运行期才确定的，因此大小不固定，一般堆大小远远大于虚拟机栈 | 虚拟机栈是连续的，所以分配到的内存大小在编译期就已经确定好了，因此大小是固定的 |
| 存放内容     | 堆存放的是对象的实例和数组，所以更关注的是数据的存储         | 虚拟机栈存放的是局部变量、操作数栈、动态链接和方法返回地址，所以更关注的是程序方法的执行 |
| 程序的可见性 | 堆是线程共享的                                               | 栈是线程私有的，只对于线程是可见                             |
| 生命周期     | 堆的生命周期与JVM的生命周期相等                              | 虚拟机栈的生命周期与所在线程的生命周期相等                   |

### 2.3. 详细介绍直接内存？

- **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，但这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。

- 直接内存（堆外内存）的使用，**避免了在I/O操作时Java堆和Native堆中来回复制数据**，从而提高性能。

  - 在JVM层面，每当程序需要执行一个I/O操作时，都需要将数据先从**Java Heap**复制到**C Heap**中，才能够触发系统调用完成操作。
  - 其中，C Heap内存站在JVM角度来看，属于堆外内存，但是站在操作系统的角度来看，其实都属于进程的Heap，**操作系统并不知道JVM的存在**，所以认为都是普通的用户程序。因此，JVM在I/O时永远比使用Native方法多一次数据复制。
  - **为什么必须有这一次的数据复制呢**？
    - 这是因为JVM只是一个用户程序，本身并没有直接访问硬件的能力，所有的I/O操作都需要借助于系统调用来实现。在Linux系统中，与I/O相关的read（）和write（）系统调用，都需要传入一个指向在程序中分配的一片内存区域的起始地址指针，然后操作系统才会将数据填入到这片区域或者从这片区域中读出数据。
    - 如果直接使用JVM堆中对应byte[]类型的地址的话，则会有两个无法解决的问题：一是，**Java中的对象实际的内存布局跟C不一样**，不同的JVM可能有不同的实现，byte[]的首地址可能只是个对象头，并不是真实的数据；二是，**垃圾收集器的存在使得JVM会经常移动对象的位置**，这样同一个对象的真实内存地址随时都有可能发生变化，而虽然JVM知道对象地址变了，但是操作系统并不知道。
  - 因此，在适当的位置直接使用直接内存，可以避免数据从JVM Heap到C Heap的拷贝。

- **API上**：可以使用**Unsafe**类或者**ByteBuffer**类分配直接内存：

  - **Unsafe**：Unsafe.allocateMemory（size）：
    - Unsafe可用来直接访问系统内存资源并自主管理，在提升Java运行效率、增强Java语言底层操作能力方面起了很大的作用。
    - 可以认为，**Unsafe类是Java中留下的后门**，提供了一些底层的操作，比如直接访问内存、线程调度等。
    - Unsafe不属于Java标准，官方并不建议使用Unsafe，并且从JDK 9开始去Unsafe，然而目前业界有很多好用的类库大量用了Unsafe类，比如JUC atomic包下的类、Netty、Hadoop、Kafka等，所以了解一下还是有好处的。
    - 不同JDK版本中，Unsafe类有区别：在JDK 8中归属于sun.misc包下；在JDK 11中归属于sun.misc包下与jdk.internal.misc下（这个功能更强大）。

  ```java
  public class DirectMemoryTest1 {
      private static final int MB_1 = 1024 * 1024;
  
      public static void main(String[] args) throws IllegalAccessException, NoSuchFieldException {
          //通过反射获取Unsafe类并通过其分配直接内存
          Field unsafeField = Unsafe.class.getDeclaredFields()[0];
          unsafeField.setAccessible(true);
          Unsafe unsafe = (Unsafe) unsafeField.get(null);
  
          // 分配1M内存，并返回这块内存的起始地址
          long address = unsafe.allocateMemory(MB_1);
  
          // 向内存地址中设置对象
          unsafe.putByte(address, (byte) 1);
  
          // 从内存中获取对象
          byte aByte = unsafe.getByte(address);
          System.out.println(aByte);
  
          // 释放内存
          unsafe.freeMemory(address);
      }
  }
  ```

  - **ByteBuffer**：ByteBuffer.allocateDirect（size）：

  ```java
  public class DirectMemoryTest2 {
      private static final int ONE_MB = 1024 * 1024;
  
      public static void main(String[] args) {
          // 底层使用unsafe分配内存，unsafe.freeMemory(address)释放内存
          ByteBuffer buffer = ByteBuffer.allocateDirect(ONE_MB);
          
          // 相对写，向position的位置写入一个byte，并将postion+1，为下次读写作准备
          buffer.put("abcde".getBytes());
          buffer.put("fghij".getBytes());
  
          // 转换为读取模式
          buffer.flip();
  
          // 相对读，从position位置读取一个byte，并将position+1，为下次读写作准备
          // 读取第1个字节(a)
          System.out.println((char) buffer.get());
  
          // 读取第2个字节
          System.out.println((char) buffer.get());
  
          // 绝对读，读取byteBuffer底层的bytes中下标为index的byte，不改变position
          // 读取第3个字节
          System.out.println((char) buffer.get(2));
      }
  }
  ```

- **JVM参数上**：可以使用-XX：MaxDirectMemorySize控制，默认是0，表示不控制。

- **优点**：
  - **减少了垃圾回收的工作**：因为直接内存是由操作系统直接管理的内存，分配到直接内存的对象不受JVM管理，也就不用JVM对其进行垃圾回收了。
  - **I/O效率高**：由于I/O操作中，使用直接内存可以减少一次Java Heap与C Heap之间的内存拷贝，从而提高了性能。
- **缺点**：

  - **直接内存难以控制**：直接内存不受JVM管理，需要用户自己来释放内存，当发生内存溢出时排查问题可能会变得非常困难。
- **适用场景**：
  - **需要存储的数据大且生命周期长**。
  - **频繁的I/O操作**，比如并发网络通信。

### 2.4. JVM执行引擎？

- JVM核心的组件就是**执行引擎**，负责执行虚拟机的字节码，一般会先编译成机器码后执行。
- “虚拟机”是一个相对于“物理机”的概念，虚拟机的字节码是不能直接在物理机上运行的，需要执行引擎编译成机器码后才可在物理机上执行。

### 2.5. 编译器优化机制？

#### 字节码运行模式

- **解释执行**：由解释器一行一行翻译字节码执行。
  - 优势在于没有编译的等待时间，可以节省内存（不存放到CodeCache），但由于要一行一行去翻译性，所以能差一些。
- **编译执行**：把字节码编译成字节码，直接执行机器码。
  - 运行效率会高很多，一般比解释执行快一个数量级，但带来了额外的内存（CodeCache）和CPU的开销。
- 相关命令：

| JVM参数              | 显示值                             | 说明                                                  |
| -------------------- | ---------------------------------- | ----------------------------------------------------- |
| java -version        | mixed mode，表示混合模式           | 查看字节码运行模式                                    |
| java -Xint -version  | interpreted mode，表示解释执行模式 | 指定解释执行模式                                      |
| java -Xcomp -version | compiled mode，表示编译执行模式    | 指定JVM优先以编译模式运行，不能编译的再以解释模式运行 |
| java -Xmixed         | mixed mode，表示混合模式           | 指定以混合模式运行（默认）                            |

#### JIT即时编译器

- **背景**：

  - JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。
  - 为了提高热点代码的执行效率，JVM会使用**即时编译器**，把这些热点代码编译成与本地平台相关的机器码，并进行**各层次的优化**。

- **概念**：Just In Time Compiler，JIT即时编译器，简称JIT编译器，在运行时JVM将会把热点代码编译成与本地平台相关的机器码，并进行各种层次的优化（比如锁粗化等），从而提高热点代码的执行效率。

  - **Hotspot - C1即时编译器**：也被称为Client  Compiler，是一个简单快速的编译器，主要关注局部性的优化，适用于执行时间较短或者对启动性能有要求的程序。比如GUI应用对界面启动速度就有一定的要求，此时适合用C1 编译器。
  - **Hotspot - C2 即时编译器**：也被称为Server Compiler，是为长期运行的服务器端应用程序做性能调优的编译器，适用于执行时间长或者对峰值性能有要求的程序。
  - **javac是前端编译**（也叫前期编译），负责把java代码编译成class字节码；而**JIT是后端编译**，负责把字节码编译成本地平台相关的机器码。

- **分层编译优化**：

  - level 0：解释执行。
  - level 1：简单的C1编译，使用C1编译器进行一些简单的优化，不开启Profiling（JVM的性能监控）。
  - level 2：受限的C1编译，仅执行**带方法调用次数**以及**循环回边执行次数**Pofiling的C1编译。
  - level 3：完全的C1编译，会执行带有所有Profiling的C1代码。
  - level 4：C2编译，使用C2编译器进行优化，该级别会启用一些编译耗时较长的优化，在一些情况下，会根据性能监控信息进行一些非常激进的性能优化。

  => 级别越高，应用启动越慢，优化的 开销越高，峰值性能也越高。

| JVM参数                                          | 默认值 | 说明                    |
| ------------------------------------------------ | ------ | ----------------------- |
| -XX：-TieredCompilation                          | ？     | 只开启C2（禁用123层）   |
| -XX：+TieredCompilation -XX：TieredStopAtLevel=1 | -      | 只开启C1（只开启0~1层） |

#### CodeCache

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。

#### 热点代码

- **概念**：JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。

- **探测方法**：

  - **基于采样的热点探测**：周期性检查各个线程的栈顶，经常出现在栈顶的则为热点方法。
  - **基于计数器的热点探测**：Hotspot使用的方法，思路是为每个方法或者代码块建立一个**计数器**，统计其执行的次数，如果超过某个阈值，则认为它是热点代码。

- **Hotspot内置计数器**：

  - **方法调用计数器**：Invocation Counter，用于统计方法被调用的次数（不是绝对次数，而是在一个相对的执行频率，即一段时间内方法被调用的次数），在不开启分层编译的情况下，默认C1阈值为1500次，C2为10000次。

  | JVM参数                  | 默认值 | 说明                                                     |
  | ------------------------ | ------ | -------------------------------------------------------- |
  | -XX：CompileThreshold=？ | ？     | 指定方法调用计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626357990780](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626357990780.png)

  - **回边计数器**：
    - 回边，Back Edge，指定的是在字节码中遇到控制流向后跳转的指令。
    - 回边计数器，Back Edge Counter，用于统计一个方法中循环体代码执行的次数，在不开启分层编译的情况下，默认C1为13995次，C2为10700次。
    - 建立回边计数器的目的是为了触发OSR，OnStackReplacement编译，是一种在运行时替换正在运行函数或者方法的栈帧的技术，是一种用于提升benchmark跑分非常有效的技术。

    | JVM参数                         | 默认值 | 说明                                                 |
    | ------------------------------- | ------ | ---------------------------------------------------- |
    | -XX：OnStackReplacePercentage=? | ?      | 指定回边计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626358121407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626358121407.png)

#### 方法内联

- **概念**：把目标方法的代码复制到发起调用的方法之中，即方法内联，避免发生真实的方法调用，从而减少方法调用时压栈和出栈的操作，以减少内存消耗和操作的时间，提高系统性能。

  - 方法内联，本质上是空间换时间的方式，也就是即时编译器在编译期间把方法调用连接起来，从而减少入栈和出栈的开销。

- **内联条件**：

  - **方法体足够小**：

    - 热点方法，方法体小于325字节会尝试内联，可用-XX：FreqInlineSize命令修改阈值大小。

    - 非热点方法，方法体小于35字节会尝试内联，可用-XX：MaxInlineSize命令修改阈值大小。

  - **被调用的方法运行时的实现可以被唯一确定**：

    - static方法、private方法以及final方法，JIT可以唯一确定具体的实现代码，此时会尝试内联。
    - 而public的实例方法，指向的实现可能是自身、父类或者子类的代码，仅当JIT能够唯一确定其唯一实现时，才有可能完成内联。

- **内联带来的问题**：

  - 由于经过内联后的代码会变多，其增加的代码量取决于方法的调用次数和方法本身的大小，在一些极端情况下，内联可能会引起CodeCahce溢出，可能会导致JVM退化成解释执行模式。
    - CodeCahce：是热点代码的一个缓存区，即时编译器编译后的代码以及本地方法代码都会存放在这个区间内，空间大小比较有限（JDK 8中只有240M内存），比较容易出现CodeCahce溢出。

| JVM参数                             | 默认值 | 说明                                                         |
| ----------------------------------- | ------ | ------------------------------------------------------------ |
| -XX：+Printlnlining                 | -      | 打印内联详情，该参数需和-XX：+UnlockDiagnosticVMOption配合使用 |
| -XX：+UnlockDiagnosticVMOption      | -      | 打印JVM诊断相关的信息                                        |
| -XX：MaxlnlineSize=？               | 35     | 如果非热点方法的字节码超过该值（单位字节），则无法内联       |
| -XX：FreqlnlineSize=？              | 325    | 如果热点方法的字节码超过该值（单位字节），则无法内联         |
| -XX：lnlineSmallCode=？             | 1000   | 如果目标编译后生成的机器码大小大于该值（单位字节），则无法内联 |
| -XX：MaxlnlineLevel=？              | 9      | 内联方法的最大调用帧数（嵌套调用的最大内联深度）             |
| -XX：MaxTrivialSize=？              | 6      | 如果方法的字节码少于该值（单位字节），则直接内联             |
| -XX：MinlnlingThreshold=？          | 250    | 如果目标方法的调用次数低于该值，则不去内联                   |
| -XX：LiveNodeCountlnliningCutoff=？ | 40000  | 编译过程中最大活动节点（IR节点）的上限，仅对C2编译器有效     |
| -XX：lnliningFrequencyCount=？      | 100    | 如果方法的调用点（call site）的执行次数超过该值，则触发内联  |
| -XX：MaxRecursivelnlining Level=？  | 1      | 如果递归调用大于该值，则不去内联                             |
| -XX：+lnlineSynchronizedMethods     | 开启   | 是否允许同步方法的内联                                       |

#### 逃逸分析

- **概念**：分析变量能否逃出它的作用域。

- **4种逃逸场景**：

  - **全局变量赋值逃逸**：局部变量作用域放大到全局变量。

  ```java
  public static SomeClass someClass;
  
  // 全局变量赋值逃逸
  public void globalVariablePointerEscape() {
      someClass = new SomeClass();
  }
  ```

  - **方法返回值逃逸**：变量作用域随着方法返回而放大。

  ```java
  // someMethod(){
  //   SomeClass someClass = methodPointerEscape();// 方法返回值逃逸
  // }
  public SomeClass methodPointerEscape() {
      return new SomeClass();
  }
  ```

  - **实例引用逃逸**：变量作用域随着方法参数逃逸到其他作用域。

  ```java
  // 实例引用传递逃逸
  public void instancePassPointerEscape() {
      this.methodPointerEscape().printClassName(this);
  }
  ```

  - **线程逃逸**：类变量或者可以被其他线程中访问的实例变量，即共享变量，可以随着线程共享发生的逃逸。

- **逃逸状态标记**：JVM针对每个逃逸场景进行分析，分析后会给对象做一个逃逸状态标记。

  - **全局逃逸标记**：一个对象可能从**方法**或者**线程**中逃逸，即其他方法或者其他线程也可以访问这个对象。
    - 对象被作为方法的返回值。
    - 对象作为静态字段或者成员变量。
    - 如果某个类重写了析构函数finalize（）方法，则整个类的对象都会被标记为全局逃逸状态，并且一定会放到堆内存里面。
  - **参数逃逸状态**：一个对象被作为参数传递给一个方法，但在接收参数的方法之外无法访问该对象，且该对象对其他线程也是不可见的。
  - **无逃逸状态**：一个对象不会发生逃逸。

| JVM参数                    | 默认值       | 说明             |
| -------------------------- | ------------ | ---------------- |
| -XX：+DoEscapeAnalysis     | JDK8默认开启 | 是否开启逃逸分析 |
| -XX：+EliminateAllocations | JDK8默认开启 | 开启标量替换     |
| -XX：+EliminateLocks       | JDK8默认开启 | 是否开启锁消除   |

#### 逃逸分析优化 - 标量替换

标量替换指的是，在通过逃逸分析确定对象不会被外部访问，且对象可以进一步被分解后（聚合量），JVM不会创建该对象，而是创建其成员变量（标量）去代替。

- **标量**：不能被进一步分配的量，比如基础数据类型和对象的地址引用。
- **聚合量**：可以进一步分解的量，可以由标量聚合而成，比如字符串、自己定义变量。

```java
public void someTest() {
    // someTest没有逃逸时, 且可以进一步分解, 则可以进行标量替换
    SomeTest someTest = new SomeTest();
    someTest.age = 1;
    someTest.id = 1;

    // 开启标量替换之后, 上述代码会被优化成: 并不会创建SomeTest对象
    int age = 1;
    int id = 1;
}
```

#### 逃逸分析优化 - 栈上分配

栈上分配指的是，在通过逃逸分析确定对象不会被外部访问后，并且对象足够的小，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。

#### 逃逸分析优化 - 锁消除

等到并发章节再写。

### 2.6. 详细介绍创建一个对象的步骤？

**步骤：类加载检查、类加载（加载、链接、初始化）、分配内存、初始化零值、设置对象头、执行init方法**

1. **类加载检查** ：当JVM遇到new指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。

2. **类加载 - 加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。

3. **类加载 - 链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：

   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。

4. **类加载 - 初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。

   - 执行clinit 方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。

5. **分配内存**：在确定对象需要创建后，接下来JVM将为对象分配内存，分配⽅式有 **“指针碰撞”** 和 **“空闲列表”** 两种，在分配内存的过程中，需要注意使用的是哪一种垃圾收集算法，因为垃圾收集算法的不同会导致内存块是否规整，从而影响到分配内存的方式是使用指针碰撞还是使用空闲列表。

   - 在进行内存分配的时候，如果使用的是指针碰撞方法，还需要注意并发情况下，内存的分配是否是线程安全的。一般使用**加同步块**的方式和**线程私有分配缓存区**这两种方式解决线程安全的问题。

6. **初始化零值**：对象内存分配完成后，JVM需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的**实例字段**在Java代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。

7. **设置对象头**： 初始化零值完成之后，JVM要对对象进⾏必要的设置，比如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息将存放在对象头中。另外，根据JVM当前运⾏状态的不同，比如是否启⽤偏向锁等，对象头会有不同的设置⽅式。

   - **对象头主要包括两部分**：用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）以及类型指针（即对象指向该类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例）。

   ![1626822381182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626822381182.png)

8. **执⾏init⽅法**： 从JVM的视⻆来看，⼀个新的对象已经产⽣了，但从Java程序的视⻆来看， init⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏new指令之后会接着执⾏init⽅法，这样⼀个真正可⽤的对象才算产⽣出来。

   - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
   - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
   - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

### 2.7. 对象内存分配过程？

![1626823040622](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626823040622.png)

1. 对象首先尝试栈上分配，如果栈上分配成功，则直接在栈上分配对象。
   - **栈上分配**指的是，在通过**逃逸分析**确定对象不会被外部访问后，并且**对象足够的小**，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。
2. 如果不能在栈上分配，且**对象也足够的小**，则尝试TLAB分配，如果TLAB分配成功，则直接在TLAB分配对象。
   - **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配**小对象**，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
3. 如果也不能在TLAB分配（大部分对象），则对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
4. 然而，**新建的对象不一定直接分配到Eden区**：如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
5. 同时还要注意的是，**由于JVM有动态年龄判定机制，对象不一定要达到年龄才能进入老年代**：
   - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

### 2.8. Java垃圾回收机制？

- **背景**：
  - 在Java中，程序员是**不需要显式去释放一个对象的内存**的，而是由虚拟机自行执行。
  - 在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。
- **使用场景原则**：
  - **内存要求**：内存不够，则需要想办法提高对象的回收率，以多回收一些对象，从而腾出更多的内存。
  - **CPU要求**：CPU不够，则需要降低垃圾回收频率，让CPU多去执行业务，而不是垃圾回收。
- **垃圾回收的区域**：虚拟机栈、本地方法栈和程序计数器是线程独享的，是随着线程的创建而创建的，随着线程的销毁而销毁的， 是不需要考虑垃圾回收的；而堆和方法区是线程共享的，需要关注垃圾回收。
  - **堆**：是垃圾回收的主要区域，用于回收创建的对象。
  - **方法区**：用于回收废弃的常量以及不需要的类。
- **回收时机**：由对象存活算法决定。

### 2.9. 对象存活算法？

#### 引用计数法

通过对象的引用计数器，来判断该对象是否被引用，比如有对象引用就+1，其引用失效就-1，当为0时，则代表该对象没有被引用。

- **优缺点**：实现简单，判断效率高；但无法解决对象循环引用的问题，**目前Java并不使用该算法**。

![1626436324696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436324696.png)

#### 可达性分析

以**根对象（GC Roots）**作为起点向下搜索，走过的路径被称为**引用链**（Reference Chain），如果某个对象到根对象之间没有引用链相连，则认为该对象是不可达的，是可以被回收的。**Java使用的是该存活算法**。

- **根对象**包括：
  - 虚拟机栈（栈帧中的局部变量表）中Reference对象所引用的对象。
  - 方法区中类的静态属性（static）Reference对象所引用的对象。
  - 方法区中常量（final）Reference对象所引用的对象。
  - 本地方法栈中JNI（即Native方法）Reference对象所引用的对象。

![1626436445717](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436445717.png)

- **可达性分析完整流程**：注意，一个对象即使不可达，也不一定会被回收，还要继续判断有无必要执行析构函数**finalize（）**方法，如果方法里面重新建立了与根对象之间的引用链，则不会去回收，否则还是会被回收。
  - **两次标记过程**：
    - 第一次标记不在“关系网”中的对象。
    - 第二次先判断该对象有没有实现finalize（）方法，如果没有实现，则直接判断该对象可回收；如果实现了，则会先放在一个队列中，并由JVM建立的一个低优先级的线程去执行它，随后会进行第二次的小规模标记，而在这次被标记的对象就会真正地被回收了。
  - **使用建议**：
    - 避免使用finalize（）方法，操作不当可能会导致问题。
    - finalize（）方法优先级低，什么时候会被调用也无法确定，因为什么时候发生GC是不确定的。
    - 建议使用try...catch...finally来代替finalzie（）方法。

![1626437028531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437028531.png)

### 3.0. JVM垃圾回收算法

分为**基础垃圾回收算法**（标记清除算法、标记整理算法和复制算法）和**综合垃圾回收算法**（分代搜集算法和增量算法）。

#### 基础 - 标记清除算法

- **优缺点**：实现简单；但存在内存碎片，影响对象的内存分配速度，在极端情况下需要遍历整个内存链表。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 再清理掉要回收的对象。

![1626437545225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437545225.png)

#### 基础 - 标记整理算法

也叫标记压缩算法。

- **优缺点**：无内存碎片；但由于整理需要计算和时间整理对象到一端，存在CPU和时间的开销。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 然后把所有存活对象压缩到内存的一端。
3. 再清理掉边界外的所有空间。

![1626437785184](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437785184.png)

#### 基础 - 复制算法

- **优缺点**：性能好（无需标记所有对象，只需找出存活的并移动即可），无内存碎片；但内存利用率低，最多才达到50%。
- **算法流程**：

1. 把内存分为两块，每次只使用其中一块。
2. 通过可达性分析，将存活的对象复制到另一块未使用的内存中，然后清除掉正在使用的那块内存中的所有对象。
3. 最后交换两块内存块的角色，等待下次回收重复执行上述操作。

![1626437874675](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437874675.png)

#### 综合 - 分代收集算法

- **概念**：

  - 各种商业虚拟机堆内存的垃圾收集基本上都采用了分代收集算法。
  - 根据对象的存活周期，把内存分为多个区域，**不同区域使用不同的回收算法**来回收对象，以提升整体性能。
  - 堆是垃圾回收的主要区域，其内存可以划分为以下区域：

  ![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **垃圾回收类型**：

  - **新生代回收**：Minor GC或者Young GC
  - **老年代回收**：Major GC，执行Major GC往往伴随一次Minor GC，所以**Major GC  ≈ Full GC**。
  - **清理整个堆**：Full GC = Major GC + Minor GC。

- **对象内存分配过程**：

  - **典型模型**：
    - **回收新生代使用复制算法**，因此新生代需要有两块内存（Eden区和Survivor区，8：2），Survivor区也有两块内存（From Survivor和To Survivor，1：1）。
      1. 对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。
      2. 而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。
      3. 对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
    - **回收老年代使用标记清除或者标记整理算法**，老年代：新生代，默认内存大小比值为2：1。
  - **新建的对象不一定直接分配到Eden区**：
    - 如果对象大于-XX：PretenureSizeThreshold（默认为0，表示所有对象都优先在Eden区分配），则会直接分配到老年代。
    - 如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
  - **对象不一定要达到年龄才能进入老年代**：
    - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

- **触发垃圾回收的条件**：

  - **新生代Minor GC**：Eden区空间不足时。
  - **老年代/Full GC**：
    - **老年代空间不足**：没有足够空间，或者内存碎片过多导致没有足够的连续空间去分配对象。
    - **元空间不足**：方法区的元空间不足也会触发Full GC。
    - **显示调用System.gc（）**：该方法的作用是建议垃圾回收器执行垃圾回收，会触发Full GC，可以使用-XX：+DisableExplicitGC参数忽略System.gc（）的调用。

- **分代收集算法的好处**：

  - **更有效的清除不再需要的对象**：对于生命周期比较短的对象，在新生代就会被回收掉了。
  - **提升了垃圾回收的效率**：如果不做分代处理，每次回收需要扫描整个堆的对象，而分代回收则需要扫描新生代或者老年代就可以了。

- **分代收集算法的调优原则**：

  - **合理设置Survivor区的大小，避免内存浪费**：因为Survivor区的内存利用率不高，如果设置得过大，则会导致内存浪费严重。
  - **让GC尽量发生在Minor GC级别，尽量减少Full GC的发生**。

| JVM参数                        | 默认值 | 说明                                                         |
| ------------------------------ | ------ | ------------------------------------------------------------ |
| -XX：+NewRatio=？              | 2      | 老年代：新生代的内存大小比值                                 |
| -XX：SurvivorRatio=？          | 8      | Eden区：Survivor区的内存大小比值                             |
| -XX：PretenureSizeThreshold=？ | 0      | 分配到老年代的对象大小阈值，为0表示不做限制，所有对象都优先在Eden区分配 |
| -Xms                           | -      | 最小堆内存                                                   |
| -Xmx                           | -      | 最大堆内存                                                   |
| -Xmn                           | -      | 新生代大小                                                   |
| -XX：+DisableExplicitGC        | 开启   | 忽略掉System.gc（）的调用                                    |
| -XX：NewSize=？                | -      | 新生代初始内存大小                                           |
| -XX：MaxNewSize=？             | -      | 新生代最大内存                                               |

#### 综合 - 增量算法

每次只收集一小片区域内存的垃圾，从而减少系统的停顿时间，见G1收集器的实现。

### 3.1. JVM垃圾收集器？

#### 相关概念

- **垃圾回收算法**：为实现垃圾回收提供理论支持。
- **垃圾收集器**：利用垃圾回收算法，实现垃圾回收的实践落地。
- **Stop The World**：**简写为STW，也叫全局停顿**，处于该状态时，Java代码将停止运行，而native代码可以继续运行，但无法与JVM进行交互。
  - **原因**：多半由于垃圾回收导致，也有可能由Dump线程、Dump堆、死锁检查等操作导致。
  - **危害**：服务会停止，没有响应；STW时间过长，可能会导致主从发生切换，影响生产环境。
- **并行收集**：指多个垃圾收集线程同时并行工作，但在收集过程中，用户线程处于等待状态。
- **并发收集**：指用户线程与垃圾收集线程同时工作。
- **应用吞吐量**：指的是CPU用于运行业务代码的时间，与CPU总消耗时间的比值。
  - **计算公式**：应用吞吐量 = 运行业务代码时间 / （运行用户代码时间 + 垃圾收集时间）* 100%，垃圾收集时间越长，应用吞吐量越小。

 ![1626495749202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626495749202.png)

#### 新生代 - Serial收集器

- **背景**：最基本的、发展历史最悠久的收集器。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **单线程、简单、相对高效**：由于是单线程实现的，不存在与其他线程的交互开销，可以专心做垃圾回收。
  - **收集过程全程Stop The World**。
- **适用场景**：
  - **用于客户端程序**：如果应用以java -client -jar方式启动时，默认使用的就是Serial收集器。
  - **用于单核机器上**：常见于一些嵌入式低性能的机器上运行。
- **执行过程**：
  - **Safepoint**：当发生GC时，用户线程必须全部停下来，才可以进行垃圾回收，这个状态可以认为JVM 是安全的（safe），整个堆的状态是稳定的。如果在GC前，有线程迟迟进入不了safepoint状态，那么整个 JVM都在等待这个线程，从而造成了GC整体时间变长。

![1626496514434](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626496514434.png)

#### 新生代 - ParNew收集器

- **背景**：Serial收集器的多线程版本，除了使用多线程不同以外，其他都和Serial收集器一样，包括JVM参数、Stop The World别的表现和垃圾收集算法。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **多线程、收集过程全程Stop The World**。
  - 可使用**-XX：ParallelGCThreads**设置垃圾收集的线程数，一般设置为CPU核心数就可以了。
- **适用场景**：主要用来和CMS收集器配合使用。
- **执行过程**：

![1626505507768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505507768.png)

#### 新生代 - Parallel  Scavenge收集器

- **背景**：也叫吞吐量优先收集器，也是并行的多线程收集器（多线程的方式与ParNew收集器类似）。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **可以达到一个可控制的吞吐量**：
    - -XX：MaxGCPauseMillis，设置阈值后，JVM将**尽力控制**最大的垃圾收集停顿时间为该阈值。
    - -XX：GCTimeRatio，设置吞吐量的大小，取值0~100，设置后JVM将花费不超过1 + / （1+n）的时间用于垃圾收集。
  - **自适应GC策略**：可用-XX：+UseAdptiveSizePolicy启用，启用后无需手动设置-Xmn、-XX：SurvivorRatio等参数，虚拟机会根据系统的运行状况收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。因此Parallel  Scavenge收集器存在着一定的智能性。
- **适用场景**：比较注重吞吐量的场景。
- **执行过程**：

![1626505950316](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505950316.png)

#### 老年代 - Serial Old收集器

- **背景**：也叫串行老年代收集器，可以认为是Serial收集器的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：除了算法采用标记整理算法与Serial收集器不同之外，其他都是一样的。
- **适用场景**：
  - 可以和Serial、ParNew、Parallel Scavenge三个新生代收集器配合使用。
  - CMS收集器在出现故障时，会使用Serial Old收集器作为备用。
- **执行过程**：

![1626506526709](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506526709.png)

#### 老年代 - Parallel Old收集器

- **背景**：可以认为是Parallel Scavenge的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：只能和Parallel Scavenge新生代收集器使用。
- **适用场景**：关注吞吐量的场景。
- **执行过程**：

![1626506871826](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506871826.png)

#### 老年代 - CMS收集器

- **背景**：CMS，Concurrent Mark Sweep，并发标记清除，是一个并发收集器，可以与用户线程同时工作。
- **垃圾回收算法**：标记清除算法。Serial Old与Parallel Scavenge采用的是标记整理算法。
- **特点**：
  - **优点**：
    - **Stop The World时间比较短，大多过程都是并发执行的**：只有1. 初始标记和5. 重新标记阶段存在Stop The World，其他阶段都是并发执行的）。
  - **缺点**：
    - **CPU资源比较敏感，并发执行的阶段会导致应用吞吐量的降低**：由于垃圾收集线程也需要占用一定的CPU资源，与业务线程一起去争抢CPU时间片，导致影响业务线程的执行效率，降低应用吞吐量。
    - **无法处理浮动垃圾**：由于并发清除阶段用户线程仍在并发执行，其可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而CMS无法在本次GC清理掉这些浮动垃圾，需要留到下次GC才能清理掉。
    - **不能等到老年代几乎满了才开始收集**：因为用户线程并发执行，必须为老年代预留足够的内存给用户线程使用。如果CMS执行期间预留的内存不能满足用户程序的需要，则会出现一次Concurrent Mode  Failure异常，这将会导致JVM**改用备用的Serial Old收集器**去收集老年代的垃圾，从而导致Stop The World时间加长。
      - 可使用CMSInitiatingOccupancyFraction，设置老年代占比达到多少后（默认68%），就会触发CMS垃圾收集。
    - **存在内存碎片（最令人诟病的地方）**：标记清除算法会导致内存碎片的产生。
      - 可使用UseCMSCompactAtFullCollection，在完成Full GC后是否要进行内存碎片的整理（默认打开）。
      - 也可使用CMSFullGCsBeforeCompaction，在进行几次Full GC后就进行一次内存碎片的整理（默认为0）。
  - **其他**：对于CMS收集器，Major GC和Full GC并不约等于，因为CMS是作用在老年代的垃圾回收，这里讲的Major GC并不是之前讲的Full GC。
- **适用场景**：
  - **希望系统停顿时间短，响应速度快的场景**：比如各种服务端应用场景。
- **执行过程**：

1. **初始标记**： 
   - initial  mark，标记根对象（GC Roots）能直接关联到的对象，因此能够标记到的对象会比较少。
   - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
2. **并发标记**：
   - concurrent mark，找出所有根对象（GC Roots）能够关联到的对象。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
3. **并发预清理**：
   - concurrent-preclean，**不一定会执行的阶段**，可用-XX：-CMSPrecleaningEnabled，关闭并发预清理阶段，默认是打开的。
   - 重新标记那些在并发标记阶段，引用被更新了的对象（比如新晋升到老年代的对象），从而减少后面重新标记阶段的工作量。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
4. **并发可中止的预清理阶段**：
   - concurrent-abortable-preclean，**不一定会执行的阶段**，使用该阶段的前提条件是：当Eden区使用量大于CMSScheduleRemarkEdenSizeThreshold的阈值（默认2M）时，才会执行该阶段。
   - 与并发预清理阶段所工作的事情是一样的。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 该阶段的主要作用是：允许用户能够控制预清理阶段的结束时机。
     - 比如，扫描多长时间：可用CMSMaxAbortablePrecleanTime进行设置，默认为5秒。
     - 再如，当Eden区使用占比达到多大阈值就结束本阶段：可用CMSScheduleRemarkEdenPenetration进行设置，默认为50%。
5. **重新标记**：
   - remark，修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
     - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
     - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
   - 存在Stop The World，一般来说（经验之谈），重新标记所花费的时间会比初始标记阶段的要长一些，但会比并发标记阶段的段一些。
6. **并发清理**：
   - concurrent sweep，或者叫**并发清除**，会基于标记结果，清除掉要前面标记出来需要清除的垃圾（会存在内存碎片）。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 为什么是并发清除，而不是并发整理？
     - 由于本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     - 试想一下如果既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，保证业务程序没有问题，这实现起来会变得非常困难，还容易出错。
     - 而采用并发清除就变得容易了许多，因此这里是并发清除而不是并发整理。
7. **并发重置**：
   - concurrent reset，清理本次CMS GC的上下文信息，为下一次GC做准备。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

#### 新生代&老年代 - G1收集器

- **背景**：Garbge First，是一款面向服务器端应用的垃圾收集器，既可以用在新生代，又可以用在老年代，即整个堆内存，会优先处理那些垃圾多的Region（First是价值优先的意思）。

- **垃圾回收算法**：复制算法。

- **革命性变化**：

  - **堆内存布局上的变化**：G1将整个堆划分成了若干个大小相等的区域，每个区域叫一个Region。
    - Region的大小可通过-XX：G1HeapRegionSize来指定，取值范围为1M~32M，必须为2的N次幂。
    - 在G1收集器里，同一代的对象可能是不连续的：一共分为4类Region，分别为Eden Region（伊甸园）、Survivor Region（存活区）、Old Region（老年代）、 Humongous Region（用于存储大对象，即超过Region大小一半的对象，而特大对象会分配到连续的Humongous Region里面）。

  ![1626511732234](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626511732234.png)

  - **设计思想上的变化**：**化整为零，分而治之**，本质上是应用了**增量算法**的思想。
    - 将堆内存按照Region分成多个块。
    - 然后会去跟踪每个Region里面的垃圾堆积的价值大小（即回收一个Region能够获取到多大的剩余空间）。
    - 最后构建一个优先列表，根据允许的收集时间，**优先回收价值高的Region**（回收后能够得到大的空间），以获得更高的垃圾收集效率。

- **特点**：

  - 可以作用在整个堆，既可以作用在新生代，又可以作用在老年代。
  - 垃圾回收时的停顿时间是可控的。
    - 可用MaxGCPauseMillis=？去控制。
  - 回收Region使用的是复制算法，无内存碎片的问题。

- **适用场景**：

  - 占用内存较大的应用（比如6G以上）。
  - 用于替换CMS垃圾收集器。
    - 对于JDK 8，G1和CMS的性能差异并不大，都可以使用。（经验之谈）如果内存<=6G，建议使用CMS；如果内存>6G，可以考虑使用G1。
    - 对于> JDK 8，则使用G1，因为CMS从JDK 9就已经被废弃了。

- **垃圾收集机制**：

  - **Young GC**：过程上与之前的Minor GC差不多（**复制算法**），只不过回收的单位是Region。

    - 所有Eden Region都满了时，会触发Young GC。
    - 所有Eden Region里面存活的对象，都会转移到Survivor Region里面去。
    - 而原先在Survivor Region中存活的对象，则会转移到新的Survivor Region中，或者晋升到Old Region中。
    - 其中，回收后空闲的Region会被放入空闲的列表中，等待下次被使用。

  - **Mixed GC**：最能体现G1的设计思想，与CMS有类似之处，但也有许多差异，比如使用的是复制算法。

    - 老年代大小占整个堆的百分比达到一定阈值时，则会触发Mixed GC。
      - 可用-XX：InitiatingHeapOccupancyPercent指定，默认为45%。
    - Mixed GC会回收所有Young Region，同时回收**部分**Old Region，回收那些根据收集时间与回收价值而选择的Old Region。
    - **执行过程**：除2. 并发标记是并发执行，其他阶段都是需要Stop The World的，但由于每次只回收部分Region，所以**Stop The World的时间是可控的**。

    1. **初始标记**：
       - Initial Marking，与CMS的初始标记类似，都是标记根对象（GC Roots）能直接关联到的对象。
       - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
    2. **并发标记**：
       - Concurrent Marking，与CMS的并发标记类似，用于找出所有根对象（GC Roots）能够关联到的对象。
       - 垃圾收集线程和用户线程并发执行，没有Stop The World。
    3. **最终标记**：
       - Final Marking，与CMS的重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
         - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
         - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
       - 存在Stop The World。
    4. **筛选回收**：
       - Live Data Counting and Evaluation，会对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间（MaxGCPauseMillis）来制定回收计划，并选择一些Region进行回收。
       - **回收过程：复制算法，无内存碎片**。
         - 选择一系列Region构成一个回收集。
         - 接着把决定要回收的Region中的存活对象复制空的 Region中。
         - 最后删除掉需要回收的Region。
       - 存在Stop The World。

  ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

  - **Full  GC**：
    - 当G1在复制对象时发现内存不够，或者无法分配足够内存（比如特大对象没有足够的连续Humongous Region可分配）时，则会触发Full GC。
    - 一旦触发Full GC，在Full GC模式下使用的是Serial Old模式的垃圾回收，将会出现长时间的Stop The World。

- **G1调优原则**：

  - 尽量减少Full GC的发生，尽量只停留在Young GC或者Mixed GC的模式上进行垃圾回收。
  - **减少Full GC的思路**？
    - **增加预留的内存**：可用过加大-XX：G1ReserveRercent来实现，默认为堆的10%。
    - **更早地回收垃圾，可降低老年代大小占整个堆的百分比的阈值，提早触发Mixed GC**：可通过减少-XX：InitiatingHeapOccupancyPercent来实现，默认为45%。
    - **增加并发阶段使用的线程数**：可增大-XX：ConcGCThreads，这样就可以有更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

#### 其他垃圾收集器

Shenandoah、ZGC、Epsilon，JDK 14处于实验状态，不建议在生产环境中使用。

#### 如何选择垃圾收集器？

不能纸上谈兵，要根据实际情况选择。

- 应用系统所关注的最主要的矛盾点？
  - 响应快、吞吐量高：Parallel Scaveng。
  - Web应用，低延迟：CMS或者G1。
  - 桌面端应用，启动慢：Serial & -Xverify：none参数。
-  应用系统的基础设施？
  - 单核：Serial。
  - Windows + JDK11：应用不了ZGC，需要升级到JDK14才支持。
- 应用系统的JDK的版本？
  - JDK6用不了G1。
  - Oracle JDK用不了Shenandoah。

#### 垃圾收集器相关JVM参数

详细见《JVM参数选型-高级选型-常用高级垃圾收集选项》一栏。

### 3.2. JVM性能调优工具？

详细见《JVM调优工具集锦》：基于JDK 11编写。

#### JDK内置 - 监控类工具

##### jps

Java Virtual Machine Process Status Tool，实验性工具，用于查看所有Java进程，比ps -ef  | grep java方便。

```java
eg：
jps -q：只查看进程号。
jps -m：查看传递给main方法的参数。
jps -l：查看启动类的全限定名。
jps -v：查看JVM启动时的参数。
```

##### jstat

JVM Statistics Monitoring Tool，实验性工具，⽤于监控JVM的各种运⾏状态息，包括**内存状态**和**垃圾回收**。

```java
命令格式：jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]
  -<option> ：指定参数，取值可⽤jstat -options查看
  -t        ：⽤来展示每次采样花费的时间
  <lines>   ：每抽样⼏次就列⼀个标题，默认0，显示数据第⼀⾏的列标题
  <interval>：抽样的周期，格式使⽤:<n>["ms"|"s"]，n是数字，ms/s是时间单位，默认是ms
  <count>   ：采样多少次停⽌，默认是一直打印

option参数解释：
-class    :：显示类加载器的统计信息
-gcutil    ：垃圾回收统计概述
-gc        ：垃圾回收堆的行为统计
-gcnew     ：新生代行为统计
-gcold     ：年老代和永生代行为统计
-gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计
```

#### JDK内置 - 故障排查类工具

##### jinfo

Java Configuration Info，实验性参数，主要⽤来查看以及调整JVM参数。

```java
命令格式：jinfo <option> <pid>

1）查看能力:
jinfo 11666：查看11666进程的Java System Properties、VM Flags、VM Arguments
jinfo -sysprops 11666          ：只查看11666进程的Java System Properties
jinfo -flags 11666             ：只查看11666进程的VM Flags
jinfo -flag 11666 Xmx          ：只查看11666进程的Xmx参数（最大堆内存大小）
jinfo -flag 11666 Xms          ：只查看11666进程的Xms参数（初始堆内存大小）
jinfo -flag 11666 Xmn          ：只查看11666进程的Xmn参数（新生代内存大小）
jinfo -flag 11666 MetaspaceSize：只查看11666进程的MetaspaceSize参数（元空间内存大小）

2）动态修改能力：不用重启JVM就可以生效，但能力比较有限
java -XX:+PrintFlagsInitial | grep manageable：只有显示出来的结果才能被动态修改。
开关类（打开/关闭）：jinfo -flag +HeapDumpAfterFullGC 11666
赋值类（更新为60） ：jinfo -flag MinHeapFreeRatio=60 11666
```

##### jmap

Java Memory Map，实验性工具，⽤来展示对象内存映射或者堆内存详细信息。

- **生成堆dump的8种方式**：
  - **jmap**：jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆Dump文件为mydump.hprof。
  - **jcmd**：jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）。
  - **jhsdb jmap**：jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件。
  - **Visual VM**：Monitor界面的Heap Dump按钮Dump堆，相当于jmap dump命令。
  - **OOM异常自动后生成**：使用-XX：+HeapDumpOnOutOf  MemeoryError，使JVM在OOM异常出现后自动生成堆Dump文件。
  - **Ctrl + （Pause）Break生成**：使用-XX：+HeapDumpOnCtrBreak，开启后可使用Ctrl + （Pause）Break，让虚拟机生成堆Dump文件。
  - **kill -3命令**：在Linux操作系统下，发送kill -3 pid命令生成堆Dump文件。
  - **借助SpringBoot Actuator生成**：对于SpringBoot应⽤，可以使⽤SpringBoot Actuator提供的/actuator/heapdump来实现堆Dump的生成。

```java
命令格式：jmap [option] <pid>

option参数解释：
-heap             ：打印java heap摘要
-clstats          ：打印Java堆的类加载器统计信息
-finalizerinfo    ：打印等待finalization的对象的信息
-histo[:live]     ：打印Java堆的直⽅图。如果指定了live⼦选项，则仅统计活动对象
-dump:dump_options：生成java堆的dump文件。其中，dump_options的取值为：
              live：指定时，仅Dump活动对象；如果未指定，则转储堆中的所有对象
          format=b：以hprof格式Dump堆
     file=filename：将堆Dump到filename

eg:
jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆dump文件为mydump.hprof
```

##### jstack

Stack Trace for Java，实验性工具，⽤于打印当前虚拟机的线程快照（线程快照也叫Thread Dump或者javacore⽂件，包含展示每个线程正在做什么、执行到了哪里等信息），常用于定位线程出现长时间卡顿的原因，比如死锁、死循环等。

- **生成线程dump的4种方式**：
  - **jstack**：jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息。
  - **jcmd**：jcmd 11666 Thread.print -l：打印11666进程所有线程以及线程持有锁的额外信息。
  - **jhsdb jstack**：jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息。
  - **VisualVM**：Threads界面的Thread Dump按钮Dump线程，相当于jstack。

```java
命令格式：jstack [-l][-e] <pid>
  
option参数解释：
-l：显示有关线程持有的锁的额外信息
-e：展示有关线程的额外信息（⽐如分配了多少内存、定义了多少个类等等）

eg：
jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息
```

##### jhat

JVM Heap Analysis Tool，实验性工具，⽤来分析jmap⽣成的堆Dump，能力比较弱，有非常多的替代品（比如VisualVM、Eclipse Memory Analyzer），且在JDK 11已被废弃（可在JDK 8中使用），对于学习不太重要了。

```java
命令格式：jhat [options] heap-dump-file

option参数解释：
-stack false | true   ：开启或关闭跟踪对象分配调⽤栈，默认true
-refs false | true    ：开启或关闭对对象引⽤的跟踪，默认true
-port port-number     ：指定jhat HTTP Server的端⼝，默认7000
-exclude exclude-file ：指定⼀个⽂件，该⽂件列出了应从可达对象查询中排除的数据成员
-baseline exclude-file：指定基线堆Dump⽂件。两个堆Dunmp中，对于⽐较两个不同的堆转储很有⽤
-debug intSets        ：指定该⼯具的debug级别。设置为0，则不会有debug输出。数值越⾼，⽇志越详细
-version              ：显示版本
```

##### jcmd

JVM Command，⽤于将诊断命令请求发送到正在运⾏的Java虚拟机，从JDK 7开始提供。

```java
命令格式：jcmd <pid | main class> <command ...|PerfCounter.print|-f file>

命令参数解释：
pid              ：接收诊断命令请求的进程ID
main class      :：接收诊断命令请求的main类的所有进程
command          ：command必须是⼀个有效的jcmd命令
PerfCounter.print：打印指定Java进程上可⽤的性能计数器
-f filename      ：从指定⽂件中读取命令并执⾏
-l               ：查看所有的JVM进程。jcmd不使⽤参数与jcmd -l效果相同

eg：
jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）
jcmd 11666 GC.run						 ：调⽤一次java.lang.System.gc()
jcmd 11666 Thread.print -l		         ：打印11666进程所有线程以及线程持有锁的额外信息
```

##### jhsdb

Java Hotspot Debugger，Hotspot进程调试器，可⽤于从崩溃的JVM附加到Java进程或核⼼转储，从JDK 9开始引入，JDK 9前使用sa-jdi.jar（jhsdb的原型）也是可以的。

```java
1）jhsdb clhsdb --pid 11666：进入11666进程的jhsdb的交互界面
eg：（交互界面下）
	flags          ：展示所有以-XX开头的JVM参数的值
	g1regiondetails：查看G1每个Region的起始指针、结束指针、是哪一个分代的信息

2）jhsdb hsdb --pid 11666：进入11666进程的图形化界面

3）jhsdb jinfo --flags --pid 11666：打印11666进程的VM标志

4）jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件

5）jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息

6）jhsdb jsnap --all -pid 11666：打印11666进程所有性能计数器的信息=jcmd的PerfCounter.print
```

#### JDK内置 - 可视化工具

##### jhsdb

jhsdb hsdb --pid 11666：进入11666进程的图形化界面，其菜单功能包括：

- Inspect Thread：这个线程的诊断信息，包含对象头和指向对象元数据的指针（Java类型的名字、继承关系、实现接⼝关系，字段信息、⽅法信息、运⾏时常量池的指针、内嵌的虚⽅法表（vtable）以及接⼝⽅法表（itable）等）。
- Stack Memory：这个线程栈的内存数据信息。
  - 第⼀列：内存地址（虚拟地址，⾮物理内存地址）。
  - 第⼆列：该地址上存储的数据，以字宽为单位。
  - 第三列是：对数据的注释，竖线表示范围，横线或斜线连接范围与注释⽂字。
- Show Java stack trace：这个线程的线程栈信息。
- Show Thread Information：这个线程的其他信息。
- Find Crashes：可找出这个线程崩溃的原因。
- Windows Console：可输⼊诊断命令，也就是jhsdb clhsdb命令交互页面。

![1626576342750](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576342750.png)

##### jconsole

- Java Monitoring and Management Console，是⼀款基于JMX（Java Manage-ment Extensions）的可视化监控、管理⼯具，主要是通过JMX的MBean（Managed Bean）对系统进⾏信息收集和参数动态调整。
  - JMX是⼀种开放性的技术，它既可以⽤在虚拟机本身的管理上，也可以⽤于运⾏在虚拟机之上的软件中。⽬前很多软件都⽀持基于JMX进⾏管理与监控。

- 执行jconsole命令打开界面，然后输入线程号即可。

![1626576867182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576867182.png)

##### VisualVM

- 也叫JVisualVM，是⼀个All-in-One Java Troubleshooting Tool，即多合一的故障排查工具，从JDK 6开始提供，是⽬前最强⼤的监控及故障处理程序之⼀。
- JDK 8输入jvisualvm启动即可，JDK 9输入独自安装，其界面菜单功能包括：
  - Overview：展示应⽤的概要信息，相当于可视化的jps、jinfo。
  - Monitor：展示一些监控信息，包括CPU、内存、类、线程等曲线图，Perform GC按钮通知JVM执⾏垃圾回收，Heap Dump按钮Dump堆，相当于jmap dump命令。
  - Threads：展示查看线程状态，以及Thread Dump按钮Dump线程，相当于jstack。
  - Sampler：抽样器，可⽤于实时性能分析，支持CPU抽样以及内存抽样。
  - Profiler：性能分析，提供了程序运⾏期⽅法级的处理器执⾏时间分析及内存分析。
    - 执⾏该性能分析，会对程序运⾏性能有⽐较⼤的影响，⼀般不建议在⽣产环境使⽤这项功能，建议使用JMC来代替。
    - 开启类共享（⼀种共享类，从⽽提升加载速度、节省内存的技术）可能会导致执⾏Profiler的应⽤崩
      溃，建议在执⾏Profiler的应⽤上添加-Xshare:off，关闭掉类共享。
  - 分析堆dump文件：File -> Load -> 选择hprof -> 打开 -> 分析。
  - 其他插件：VisualVM还支持安装插件来扩展功能，比如Visual CC来实时分析垃圾回收的情况。

![1626577315983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626577315983.png)

##### JDK Mission Control

- 也叫Java Mission Control，简称JMC，是一款监控、定义线上问题以及性能调优的神器。
  - 它是⼀款商业授权⼯具（例如在JDK 8中），需要商业授权才能在⽣产环境中使⽤，现已开源，在JDK 11（哪怕是OpenJDK）中，任何⼈都可以使⽤JFR + JMC（需遵循 UPL协议 ）。
- JMC的两大功能：
  - 作为JMX控制台，监控虚拟机MBean提供的数据。
  - 可持续收集数据的JFR，并可作为JFR的可视化分析⼯具。
    - JFR：Java Flight Recorder，是⼀种⽤于收集有关运⾏中的Java应⽤的诊断信息和性能数据的⼯具。它⼏乎没有性能开销，因此，即使在负载很⼤的⽣产环境中也可以使⽤。
    - 主要用于性能分析、性能分析、⽀持与调试的场景。
- MBean服务器菜单功能介绍：
  - 概览：各种概要信息。
  - MBean浏览器：展示应⽤被JMX管理的Bean。
  - 触发器：配置触发规则，当规则满⾜时，就触发某个操作（在操作⼀栏配置）。
  - 系统：查看系统相关信息。
  - 内存：查看内存相关信息。
  - 线程：查看线程相关信息。
  - 诊断命令：可视化使⽤诊断命令，相当于可视化的jcmd。
- 飞行记录性菜单功能介绍：
  - 如果应用JDK版本 < JDK11，则启动项目时需要添加-XX:+UnlockCommercialFeatures -XX:+FlightRecorder。
  - ⾃动分析结果：JMC⾃动给出的优化提议。
  - Java应⽤程序：展示应⽤的各种执⾏情况。
  - JVM内部：展示JVM层⾯的执⾏情况。
  - 环境：展示操作系统层⾯的执⾏情况。
  - 事件：展示录制期间发⽣的事件。
- JMC优点：
  - JFR在⽣产环境中对吞吐量的影响⼀般不会⾼于1%。
  - JFR监控过程是可动态的，⽆需重启。
  - JFR监控过程对应⽤完全透明，⽆需修改应⽤的代码，也⽆需安装额外的插件或代理。
  - JFR提供的数据质量⾮常⾼，对监控、排查的参考价值更⼤。
- JMC缺点：
  - JFR并不完全向后兼容。⽐如，在JDK 11⾥⾯⽣成的JFR⽂件，⽤早期的JMC（例如JMC 5.5）⽆法打开。
  - JMC 7.0.1⽆法分析堆dump⽂件（hprof格式），但 官⽅Wiki 宣称⽀持分析堆dump⽂件。

![1626578206459](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626578206459.png)

#### 第三方工具

##### Memory Analyzer Tool

- Memory Analyzer Tool，简称MAT，可以作为独⽴软件，也可作为Eclipse插件存在，是⼀个快
  速且功能丰富的Java堆内存分析器，可帮助您查找内存泄漏并减少内存消耗。

- MAT主要功能：

  - 找出内存泄漏的原因。
  - 找出重复引⽤的类和jar。
  - 分析集合的使⽤。
  - 分析类加载器。

- 相关概念：

  - **浅堆**：一个对象E自身所消耗的内存，根据堆转储格式，对象⼤⼩可能会被调整（例如，对⻬为8bit），从⽽更好地模拟VM的实际消耗量。⼀般来说，对象的浅堆是对象在堆中的⼤⼩，⽽同⼀对象的保留⼤⼩是在垃圾回收对象时将释放的堆内存量。
  - **X的保留集**：Retained set，当E被垃圾回收时，由GC删除的对象集E和G。同理，如果E没有被回收，那么该集合中的对象E和G都会“保留下来”。
  - **X的保留堆**：Retained heap，指的是对象E的保留集E和G的内存⼤⼩，即由于它的存活导致多⼤的内存没有被回收。
  - **前导对象集的保留集**：前导对象E不可达时，被释放的那些对象E和G，所以这里前导对象集E的保留集为E和G。

  ![1626581295844](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626581295844.png)

  - **支配树**：MAT提供了对象图的⽀配树，通过将对象参考图转换为⽀配树，可以轻松地识别最⼤的保留内存块以及对象之间的依赖关系。⽀配树是在对象图的基础上建⽴的，在⽀配树中，每个节点都是其⼦节点的直接⽀配者。因此，基于⽀配树可以轻松看出对象之间的依赖关系。其具有以下属性：
    - 对象从属于X的⼦树（例如对象被X⽀配）就是X的Retained set。
      - **X⽀配Y**：如果对象图中从起始（或Root）节点到Y的每条路径都必须经过X，那么就说对象X⽀配对象Y。
      - **直接⽀配者**：某个对象路径最短的⽀配者。
      - **间接支配者**：一个对象X支配了该对象Y，但又不是Y的直接支配者，则称X为Y的间接支配者。
    - 如果X是Y的直接⽀配节点，那么⽀配X的节点也可以⽀配Y。
    - ⽀配树中的边并不直接对应于对象图中的对象引⽤。

  ![1626582280791](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582280791.png)

- MAT菜单功能介绍：

  - inspector：透视图，⽤于展示⼀个对象的详细信息，例如内存地址、加载器名称、包名、对象名称、对象所属的类的⽗类、对象所属的类的加载器对象、该对象的堆内存⼤⼩和保留⼤⼩，gc root信息。下半部分展示类的静态属性和值、对象的实例属性和值、对象所属的类的继承结构。
  - Heap Dump History：列出最近分析过的⽂件。
  - 功能选择栏：从左到右依次是：概览、类直⽅图、⽀配树、OQL查询、线程视图、报告相关、详细功能。其中概览就是上图的这个⻚⾯，其他则提供了⼀些更细致的分析能⼒。总的来说，功能上和VisualVM⼤同⼩异，但分析得更加细致。
  - 饼图：展示retained size对象占⽤⽐例。
  - Actions：常⽤的内存分析动作。
    - Histogram：列出内存中的对象，对象的个数及其⼤⼩。点击后⽣成的报表：
      - Class Name ： 类名称，java类名。
      - Objects ： 类的对象的数量，这个对象被创建了多少个。
      - Shallow Heap ：⼀个对象内存的消耗⼤⼩，不包含对其他对象的引⽤。
      - Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和。
    - Dominator Tree：列出最⼤的那些对象，以及他们为什么存活。
    - Top Consumers：打印最昂贵的对象，以内和包分组。
    - Duplicate Classes：检测被多个classloader加载的类。
  - Reports：报表功能，包括：
    - Leak Suspects：⾃动分析内存泄漏的原因，并能直接定位到Class，找到可能导致内存泄露的代码⾏数。
    - Top Components：列出占⽤超过1%的组件的报告信息。
  - Step by Step：
    - Top Components：分析从属于指定包或者class loader的对象。

![1626582745483](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582745483.png)

##### JITWatch

- JITWatch是JIT编译器的⽇志分析器与可视化⼯具，可⽤来检查内联决策、热点⽅法、字节码以及汇编的各种细节，经常和HSDIS配合使⽤，实际中用的也不是特别多。
  - HSDIS是⼀个HotSpot虚拟机即时编译代码的反汇编插件，它包含在HotSpot虚拟机的源码当中，在OpenJDK的⽹站也可以找到单独的源码下载，但并没有提供编译后的程序。
- 安装HSDIS后，启动应用，添加以下参数，用于收集反汇编日志，执行完后将会⽣成⼀个  /Users/itmuch.com/logfile.log ⽂件，⾥⾯包括了各种类编辑以及汇编信息。
  - UnlockDiagnosticVMOptions：开启诊断信息。
  - PrintAssembly：输出反汇编内容。
  - Xcomp：以编译模式启动，这样，⽆执⾏⾜够次数来预热即可触发即时编译。
  - LogCompilation：打印编译相关信息。
  - LogFile：指定⽇志⽂件。
  - TraceClassLoading：是否跟踪类的加载。

```java
java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp -XX:+LogCompilation -XX:LogFile=/Users/itmuch.com
/logfile.log -XX:+TraceClassLoading -jar xxx.jar
```

- 最后使用JITWatch可视化阅读⽇志，使用以下命令启动JITWatch，选择反汇编日志，点击start即可可视化地分析了。

```java
mvn clean compile exec:java
```

![1626583188575](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626583188575.png)

### 3.3. JVM参数选项？

笔记时间：2021-07-18。

#### 标准选项

- 用于**执行常见操作**（比如检查JRE版本、设置类路径、启动详细输出等），各种厂牌的虚拟机都会支持。

- **格式不统一**，以java -help的结果为准。

- **常见的标准选项有**：

| JVM参数                          | 作用                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| -class-path \| -classpath \|- cp | 指定JVM类搜索路径，多个路径之间以分号隔开。如果指定了-classpath，则JVM就忽略系统变量CLASSPATH中指定的路径。如果-classpath和CLASSPATH都没有指定，则JVM会从当前路径寻找class |
| -server                          | 以server模式启动JVM，与client模式恰好相反。适合生产环境，适用于服务器。64位的JVM自动以server模式启动 |
| -client                          | 以client模式启动JVM，这种方式启动速度快，但运行时性能和内存管理效率不高，适合客户端程序或者开发调试。64位的JVM不支持client模式 |
| -Dproperty=value                 | 设置系统属性值。其中， property是属性名称，value是属性值，如果value有空格，则需要使用双引号，比如-Dfoo=“foo bar” |
| -javaagent：jarpath[=options]    | 加载指定的Java编程语言代理                                   |
| -verbose：class                  | 显示类加载相关的信息，当报找不到类或者类冲突时，可用此参数来诊断 |
| -verbose：gc                     | 显示垃圾收集事件的相关信息                                   |
| -verbose：jni                    | 显示本机方法和其他Java本机接口（JNI）的相关信息              |
| -version                         | 展示JDK版本                                                  |

#### 附加选项

- JDK 11文档中称为**额外参数**，JDK 8文档中称为**非标准参数**，是**Hotspot虚拟机的通用选项**，其他厂牌的JVM不一定会支持，并且未来可能会发生变化。

- 附加选项都以**-X开头**，具体以java -x的结果为准。

- **常见的附加选项有**：

| JVM参数                  | 默认值                                                       | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| -Xcomp                   | 默认情况下，client模式下会解释执行10000次（< JDK 11），server模式下会解释执行10000次，并收集信息，此后才可能编译运行。 | 在第一次调用时强制编译方法。指定该选项将禁用解释方法调用。此外，还可使用-XX：CompileThreshold选项更改在编译之前解释执行方法的调用次数 |
| -Xint                    | -                                                            | 以解释模式运行                                               |
| -Xmixed                  | -                                                            | 热点方法以编译模式运行，其他方法以解释模式运行               |
| -Xloggc：option          | -                                                            | 将GC事件的相关信息记录到文件中                               |
| -Xnoclassgc              | -                                                            | 禁用类的垃圾收集。使用该参数可节省一些GC时间，缩短应用程序运行期间的停顿。但一旦使用该参数，那么应用程序中的类对象就会始终被视为活动对象，从而导致这块内存被永久占用。如果使用不当，将会导致内存溢出 |
| -Xshare：mode            | auto：尽可能使用CDS，是32位的Hotspot JVM的默认值；on：开启CDS。如果CDS无法被开启，将会打印错误信息；off：不适用CDS | 设置类数据共享模式（class data sharing，即CDS）。注意，此选项只应用于测试目的，并且可能由于操作系统使用地址空间布局随机化而导致间歇性故障，不应在生产环境中使用 |
| -XshowSettings：category | all：默认值，展示所有设置；locale：展示语言环境相关的设置；properties：展示系统属性相关的设置；vm：展示JVM的设置；system：展示Linux主机系统或者容器的配置 | 展示设置                                                     |
| -Xmn                     | -                                                            | 设置年轻代的初始值以及最大值，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节，例如-Xmn256m。此外，还可用-XX：NewSize设置年轻代初始大小，-XX：MaxNewSize设置年轻代最大大小 |
| -Xms                     | -                                                            | 设置堆内存的初始大小，以字节为单位。此值必须是1024的倍数且大于1MB。如果未设置此选项，则将堆内存初始大小设置为老年代和年轻代分配的大小之和。设置格式同-Xmn，例如-Xms6144K |
| -Xmx                     | -                                                            | 设置堆内存的最大大小，以字节为单位。此值必须是1024的倍数且大于2MB。等效于-XX：MaxHeapSize |
| -Xss                     | 默认值取决于平台，64位Linux：1024KB；64位 MacOS：1024KB；64位Oracle Solaris：1024KB；Windows：默认值取决于虚拟内存 | 设置线程栈大小，以字节为单位                                 |

#### 高级选项

- 高级选项是**为开发人员提供的选项**，用于调整Java **HotSpot虚拟机**操作的特定区域（这些区域通常具有特定的系统要求，并且可能需要对系统配置参数的特权访问），其他厂牌的JVM不一定会支持，并且未来可能会发生变化。
- 高级选项都以**-XX开头**，可以使用以下方法查看所支持的选项：

```java
1）解锁参数并打印：java -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsInitial

2）jhsdb clhsdb --pid 11666，进入交互页面后使用flags查看
```

- **使用格式**：
  - **boolean类型**：格式为-XX：（+/-），+表示将选项设置为true，-表示将选项设置为false。
  - **非boolean类型**：格式为-XX：选项=值。

- **常见的高级选项有**：

##### 常用高级运行时选项

用于控制HotSpot VM的运行时的各种行为。

| JVM参数                               | 默认值或者取值方式 | 作用                                                         |
| ------------------------------------- | ------------------ | ------------------------------------------------------------ |
| -XX：ActiveProcessorCount=n           | -                  | JVM使用多少个CPU核心，去计算用于执行垃圾收集或者ForkJoinPool线程池的大小 |
| -XX：InitiatingHeapOccupancyPercent=n | 45                 | 老年代大小到达该阈值，会触发G1 Mixed GC                      |
| -XX：LargePageSizeInBytes=n           | -                  | 设置用于Java堆的大页面尺寸，以字节为单位，其数值必须是2的幂次，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxDirectMemorySize=n            | -                  | 设置java.nio包的直接缓存区分配的最大总大小，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxGCPauseMillis=n               | 200ms              | 期望的最大停顿时间                                           |
| -XX：OnError=string                   | -                  | 发生错误的时候做某事，string是一个或者多个命令，多个命令使用分号分隔，如果字符串包含空格，则必须将其用引号引起来。比如“gcore %p；dbx - %p”，表示当发生错误时，使用gcore命令创建核心dump文件 |
| -XX：OnOutOfMemoryError=string        | -                  | 当发生OOM异常时做模式，配置格式同-XX：OnError                |
| -XX：ParallelGCThreads=n              | -                  | 设置GC并行阶段的线程数                                       |
| -XX：+PrintCommandLineFlags           | 关闭               | 打印命令行标记                                               |
| -XX：ThreadStackSize=size             | -                  | 设置线程栈的大小，和-Xss等价                                 |
| -XX：-UseBiasedLocking                | -                  | 禁用偏向锁                                                   |
| -XX：-UseCompressedOops               | 启用               | 禁用压缩指针。此选项仅适用于64位JVM，当Java堆大小小于32GB时，将使用压缩指针。启用此选项后，对象引用将表示为32位偏移量，而非64位指针，这通常会在运行Java堆大小小于32GB的应用程序时提高性能。当Java堆大小大于32GB时，可使用-XX：ObjectAlignmentInBytes选项 |
| -XX：GCLogFileSize=n                  | 512KB              | 处理大型日志文件                                             |
| -XX：+UseLargePages                   | 关闭               | 启用大页面内存的使用                                         |
| -XX： VMOptionsFile=filename          | -                  | 允许用户在文件中指定VM选项。比如java -XX：VMOptionsFile=/var/my_vm_options_HelloWorld |
|                                       |                    |                                                              |
| 元空间参数                            |                    |                                                              |
| -XX：MetaspaceSize                    | 20.8MB             | 元空间的初始值，元空间占用达到该值就会触发垃圾回收，进行类的卸载，同时收集器会自动调整该值。如果能够释放空间，则会自动降低该值（减少空间浪费）；如果释放空间很少，则在不超过-XX：MaxMetaspaceSize的情况下，适当提高该值（保证有足够空间） |
| -XX：MaxMetaspaceSize                 | 受限于本地内存大小 | 元空间大小的最大值                                           |
| -XX：MinMetaspaceFreeRatio            | 40%                | 垃圾收集后，计算当前元空间的空闲百分比，如果小于该值，则增加元空间的大小（保证有足够空间） |
| -XX：MaxMetaspaceFreeRatio            | 70%                | 垃圾收集后，计算当前元空间的空闲百分比，如果大于该值，则减少元空间的大小（减少空间浪费） |
| -XX：MinMetaspaceExpansion            | 332.8KB            | 元空间增长时的最小幅度                                       |
| -XX：MaxMetaspaceExpansion            | 5.2MB              | 元空间增长时的最大幅度                                       |
|                                       |                    |                                                              |
| 直接内存参数                          |                    |                                                              |
| -XX：MaxDirectMemorySize              | -                  | 设置最大直接内存大小，对Unsafe不起作用，但对ByteBuffer有效   |
|                                       |                    |                                                              |
| TLAB参数（不建议修改）                |                    |                                                              |
| -XX：+UseTLAB                         | 开启               | 是否启用线程私有分配缓存区（Thread-Local Allocation Buffer） |
| -XX：MinTLABSize                      | 2048B              | 最小TLAB大小，单位字节                                       |
| -XX：+ResizeTLAB                      | 是                 | 是否动态调整TLAB的大小                                       |
| -XX：TLABRefillWasteFraction          | 64                 | 由于TLAB空间比较小，因此很容易装满。比如TLAB 100KB，已使用80KB，当需要再分配一个30KB的对象时，就无法分配到这个TLAB了。这时虚拟机会有两种选择，第一，废弃当前TLAB，这样就会浪费20KB的空间；第二，保留当前的TLAB并将这30KB的对象直接分配在堆上，这样将来有小于20KB的对象时，仍可以使用这块空间。实际上，JVM内部维护了一个叫做refill_waste的值，当请求对象大于refill_waste时，会在堆中分配；若小于该值，则会废弃当前TLAB，新建TLAB分配对象。可以用TLABRefillWasteFraction来调整该阈值，表示TLAB中允许产生这种浪费的比例，默认为64，即允许使用1/64的TLAB空间作为refill_waste。默认情况下，TLAB和refill_waste都会在运行时不断地调整，使系统的运行状态达到最优。如果想要禁用自动调整TLAB的大小，可以使用-XX：-ResizeTLAB禁用ResizeTLAB，并使用-XX：TLABSize手工指定一个TLAB的大小 |
| -XX：+TLABStats                       | 是                 | 是否提供详细的TLAB的统计信息                                 |
| -XX：TLABSize                         | 0                  | 设置TLAB的初始大小，如果设置为0，JVM会自动设置TLAB的初始大小 |
| -XX：TLABWasteTargetPercent           | 1                  | 允许TLAB占用Eden空间的百分比                                 |

##### 常用高级JIT编译器选项

用于控制HotSpot VM如果执行的JIT编译。

| JVM参数                                       | 默认值                                                   | 作用                                                         |
| --------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| -XX：+BackgroundCompilation                   | 开启                                                     | 启用JIT后台编译                                              |
| -XX：CompileCommand=command，method[，option] | -                                                        | 在指定方法上执行指定command。command可选项为：break：在调试JVM时设置一个断点，以便在指定方法编译开始时停止； compileonly：排除所有未指定的所有方法；dontinline：防止内联指定方法；exclude：排除指定的方法；help：打印-XX： CompileCommand选项的帮助信息；inline：尝试内联指定的方法；log：排除指定方法以外的所有方法的编译日志记录（用-XX：+Log Compilation打印编译日志），默认情况下将对所有编译方法执行日志记录；option：将JIT编译选项传递给指定的方法，以代替最后一个参数（option）。编译选项设置在方法名称之后，且可指定多个编译选项，以逗号或者空格分隔；print：在编译指定的方法后打印生成的汇编代码；quiet：不打印编译命令，默认情况下，将显示使用-XX：CompileCommand选项指定的命令 |
| -XX：+DoEscapeAnalysis                        | 开启                                                     | 启用逃逸分析                                                 |
| -XX：+Inline                                  | 开启                                                     | 启用方法内敛                                                 |
| -XX：InlineSmallCode=n                        | 1000B                                                    | 指定内联的以编译的方法的最大代码大小，以字节为单位           |
| -XX：+LogCompliation                          | 关闭                                                     | 将编译活动记录到当前工作目录的hotspot.log文件中，也可用+XX：LogFile选项来指定其他日志文件路径和名称。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：MaxInlineSize=n                          | -                                                        | 设置要内联的方法的最大字节码大小，以字节为单位               |
| -XX：+PrintAssembly                           | 关闭                                                     | 打印字节码和本地方法的汇编代码，需要HSDIS的支持。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：+PrintCompaction                         | 关闭                                                     | 打印哪些方法被内联。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
|                                               |                                                          |                                                              |
| CodeCache参数                                 |                                                          |                                                              |
| -XX：ReservedCodeCacheSize=n                  | 不同版本不同，JDK 8 + 64位以及JDK 11 + 64位都是240MB     | 设置 JIT编译的代码的最大代码缓存大小，以字节为单位，最大不超过2GB，否则会产生错误。该配置不应小于-XX： InitialCodeCacheSize的值，以java -XX：PrintFlagsFianl \| grep ReservedCodeCacheSize的结果为准 |
| -XX：InitialCodeCacheSize=n                   | 不同的操作系统，以及不同的编译器的值也会不同，一般为48MB | 设置代码缓存区的初始大小，以java -XX：PrintFlagsFianl \| grep InitialCodeCacheSize的结果为准 |
| -XX：-PrintCodeCache                          | 关闭                                                     | 在JVM停止时打印代码缓存的使用情况                            |
| -XX：-PrintCodeCacheOnCompilation             | 关闭                                                     | 每当方法被编译后，就打印一下代码缓存区的使用情况             |
| -XX：+UseCodeCacheFlushing                    | 打开                                                     | 代码缓存区即将耗尽时，尝试回收一些早期编译但又很久没有被调用的方法 |
| -XX：-SegementedCodeCache                     | 关闭，表示使用整体的代码缓存区                           | 是否使用分段的代码缓存区                                     |

##### 常用高级可服务性选项

用于控制系统信息收集与调试支持。

| JVM参数                                  | 默认值                                | 作用                                                         |
| ---------------------------------------- | ------------------------------------- | ------------------------------------------------------------ |
| -XX：HeapDumpPath=path                   | -                                     | 指定堆Dump的文件路径，经常和-XX：+HeapDumpOnOutOf MemoryError选项配合使用 |
| -XX：LogFile=path                        | 在当前工作目录中创建，名为hotspot.log | 指定日志文件的路径，经常和-XX：+LogCompilation配合使用       |
| -XX：+Unlock ExperimentalVMOptions       | 关闭                                  | 用于解锁JVM实验性参数                                        |
| -XX：+UnlockDiagnosticVMOptions          | 关闭                                  | 用于解锁JVM诊断性参数                                        |
|                                          |                                       |                                                              |
| JDK 8日志参数                            |                                       |                                                              |
| -XX：+PrintFlagsInitial                  | 关闭                                  | 打印支持的高级选项，并展示默认值                             |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |
| -XX：+PrintGCCause                       | 打开                                  | 是否在GC日志中打印造成GC的原因                               |
| -XX：+PrintGCID                          | 关闭                                  | 打印垃圾GC的唯一标识                                         |
| -XX：+PrintGCDateStamps                  | 关闭                                  | 以日期的格式输出GC的时间戳，如2013-05-04T21：53：59.234+0800 |
| -XX：+PrintGCTimeStamps                  | 关闭                                  | 以基准时间的格式，打印GC时间戳                               |
| -XX：+PrintHeapAtGC                      | 关闭                                  | 在GC前后打印堆信息                                           |
| -XX：+PrintHeapAtGCExtended              | 关闭                                  | 在开启PrintHeapAtGC的前提下，额外打印更多堆的相关信息        |
| -XX：+PrintGCApplicationStoppedTime      | 关闭                                  | 打印垃圾回收期间程序暂定的时间                               |
| -XX：+PrintGCApplicationConcurrentTime   | 关闭                                  | 打印每次垃圾回收前，程序未中断的执行时间，可与PrintGCApplicationStoppedTime配合使用 |
| -XX：+PrintClassHistogramAfterFullGC     | 关闭                                  | Full GC之后打印堆的直方图                                    |
| -XX：+PrintClassHistogramBeforeFullGC    | 关闭                                  | Full GC之前打印堆的直方图                                    |
| -XX：+PrintReferenceGC                   | 关闭                                  | 打印处理引用对象的时间消耗，需开启PrintGCDetails才有效       |
| -XX：+PrintTLAB                          | 关闭                                  | 查看TLAB空间的使用情况                                       |
| -XX：-UseGCLogFileRotation               | 关闭                                  | 轮换文件，日志文件达到一定大小后，就创建一个新的日志文件。需指定-Xloggc：时才有效 |
| -XX：GCLogFileSize                       | 8KB                                   | 设置单个日志文件的大小，需开启UseGCLogFileRotation才有效     |
| -XX：NumberOfGCLogFiles                  | 0，表示保留所有日志                   | 日志轮换时，保留几个日志文件                                 |
| -Xloggc：path                            | -                                     | 指定GC日志文件路径                                           |
| -XX：+PrintAdaptiveSizePolicy            | 关闭                                  | 某些GC收集器有自适应策略，自适应调整策略会动态调整Eden、Survivor、老年代的大小。使用该标记，可打印自适应调节策略的相关信息 |
| -XX：+PrintTenuringDistribution          | 关闭                                  | 查看每次Minor GC后新的存活周期的阈值                         |
| -XX：G1PrintRegionLivenessInfo           | -                                     | 标记阶段结束后打印所有Region的存活情况，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+G1PrintHeapRegions                 | -                                     | 打印堆的区域上的分配和释放的信息，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+PrintStringDeduplicationStatistics | -                                     | JDK 8u20开始，使用G1垃圾收集器，可支持-XX：+UseStringDeduplication开启字符串去重。可用-XX：+PrintStringDeduplicationStatistics打印字符串去重的统计信息 |
|                                          |                                       |                                                              |
| JDK 11统一日志管理（只剩下两个）         |                                       |                                                              |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |

##### 常用高级垃圾收集选项

用于控制HotSpot VM如何执行垃圾收集

| 收集器                | 参数以及默认值                             | 备注                                                         |
| --------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| Serial                | -XX：+UseSerialGC                          | 虚拟机在Client模式下的默认值，开启后，使用Serial + Serial Old的组合 |
| ParNew                | -XX：+UseParNewGC                          | 开启后，使用ParNew + Serial Old的组合                        |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
| Parallel Scavenge     | -XX：+UseParallelGC                        | 虚拟机在Server模式下的默认值，开启后，使用Parallel Scavenge + Serial Old的组合 |
|                       | -XX：MaxGCPauseMillis=n                    | 收集器尽可能保证单次内存回收停顿的时间不超过这个值，但是并不保证不超过该值，只是尽可能 |
|                       | -XX：GCTimeRatio=n                         | 设置吞吐量的大小，取值范围为0~100，假设GCTimeRatio的值为n，那么系统将花费不超过1 / （1 + n）的时间用于垃圾收集 |
|                       | -XX：+UseAdaptiveSizePolicy                | 开启后，无需人工指定新生代的大小（-Xmn）、Eden和Survivor的比例（-XX：SurvivorRatio）以及晋升老年代对象的年龄（-XX：PretenureSizeThreshold）等参数，收集器会根据当前系统的运行情况自动调整 |
| Serial Old            | 无                                         | Serial Old是Serial的老年代版本，主要用于Client模式下的老年代收集，同时也是CMS在发生Concurrent Mode Failure时的后备方案 |
| Parallel Old          | -XX：+UseParallelOldGC                     | 开启后，使用Parallel Scavenge + Parallel Old的组合。Parallel Old是Parallel Scavenge的老年代版本，在注重吞吐量和CPU资源敏感的场合，可以优先考虑这个组合 |
| CMS                   | -XX：+UseConcMarkSweepGC                   | 开启后，使用ParNew + CMS的组合，Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后备收集器使用 |
|                       | -XX：CMSInitiatingOccupancyFraction=68     | CMS收集器在老年代空间被使用多少后触发垃圾收集，默认68%       |
|                       | -XX：+UseCMSCompactAtFullCollection        | 在完成垃圾收集后是否要进行一次内存碎片整理，默认开启         |
|                       | -XX：CMSFullGCsBeforeCompaction=0          | 在进行若干次Full GC后就进行一次内存碎片整理，默认为0         |
|                       | -XX：+UseCMSInitiatingOccupancyOnly        | 允许使用占用值作为启动CMS收集器的唯一标准，一般和CMSFullGCsBeforeCompaction配合使用。如果开启，那么当CMSFullGCsBeforeCompaction达到阈值就开始GC，如果关闭，那么JVM仅在第一次使用CMSFullGCsBeforeCompaction的值，后续则自动调整，默认关闭 |
|                       | -XX：+CMSParallelRemarkEnabled             | 重新标记阶段会并行执行，使用此参数可降低标记停顿，默认打开（仅适用于CMS + ParNew的GC） |
|                       | -XX：+CMSScavengeBeforeRemark              | 开启或关闭在CMS重新标记阶段之前的清除Young GC的尝试。新生代里一部分对象会作为GC Roots，让CMS在重新标记之前，做一次Young GC，而YGC能够回收掉新生代里大多数对象，这样就可以减少GC Roots的开销。因此，打开此开关，可在一定程度上降低CMS重新标记阶段的扫描时间，当然，开启此开关后，Young GC也会消耗一些时间。PS：开启此开关并不保证在标记阶段前一定会进行清除操作，生产环境建议开启，默认关闭 |
| CMS-Precleaning       | -XX：+CMSPrecleaningEnabled                | 是否启用并发预清理，默认开启                                 |
| CMS-AbortablePreclean | -XX：CMSScheduleRemarkEdenSizeThreshold=2M | 如果Eden区的内存使用超过该值，才可能进入并发可中止的预清理阶段 |
| CMS-AbortablePreclean | -XX：+CMSMaxAbortablePrecleanTime=5000     | 并发可终止的预清理阶段持续的最大时间                         |
| CMS                   | -XX：+CMSClassUnloadingEnabled             | 使用CMS时，是否启用类卸载，默认开启                          |
|                       | -XX：+ExplicitGCInvokesConcurrent          | 显示调用System.gc（）会触发Full GC，会有Stop The World，开启此参数后，可让System.gc（）触发的垃圾回收变成一次普通的CMS GC |
| G1                    | -XX：+UseG1GC                              | 使用G1收集器                                                 |
|                       | -XX：G1HeapRegionSize=n                    | 设置每个 Region的大小，该值必须为2的幂次，范围为1M到32M，如果不指定G1会根据堆的大小自动决定 |
|                       | -XX：MaxGCPauseMillis=200                  | 设置最大停顿时间，默认值为200毫秒                            |
|                       | -XX：G1NewSizePercent=5                    | 设置年轻代占整个堆的最小百分比，默认值为5，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1MaxNewSizePercent=60                | 设置年轻代占整个堆的最大百分比，默认值为60，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
|                       | -XX：ConcGCThreads=n                       | 设置垃圾收集器并发阶段使用的线程数量，设置n大约为ParallelGCThreads的1/4 |
|                       | -XX：InitiatingHeapOccupancyPercent=45     | 老年代大小达到该阈值，则会触发Mixed GC，默认值为45           |
|                       | -XX：G1MixedGCLiveThresholdPercent=85      | Region中的对象，活跃度低于该阈值，才可能被包含在Mixed GC收集周期中，默认值为85，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1HeapWastePercent=5                  | 设置浪费的堆内存百分比，当可回收百分比小于浪费百分比时，JVM就不会启动Mixed GC，从而避免昂贵的GC开销。此参数相当于用来设置允许垃圾对象占用内存的最大百分比。 |
|                       | -XX：G1MixedGCCountTarget=8                | 设置在标记周期完成之后，最多执行多少个Mixed GC，默认值为8，启动多个Mixed GC可以缩短老年代的收集时间 |
|                       | -XX：G1OldCSetRegionThresholdPercent=10    | 设置在一次Mixed GC中被收集的老年代的比例上限，默认值为Java堆的10%，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1ReservePercent=10                   | 设置预留空闲内存百分比，虚拟机会保证Java堆有这么多空间可用，从而防止对象晋升时无空间可用而失败，默认值为Java堆的10% |
|                       | -XX：G1PrintHeapRegions                    | 输出Region被分配和回收的信息，默认为false                    |
|                       | -XX：G1PrintRegionLivenessInfo             | 在清理阶段的并发标记环节，输出堆中的所有Regions的活跃度信息，默认为fasle |
| Shenandoah            | -XX：+UseShenandoahGC                      | 使用Shenandoah收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| ZGC                   | -XX：+UseZGC                               | 使用ZGC收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| Epsilon               | -XX：+UseEpsilonGC                         | 使用Epsilon收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |

### 3.4. JVM线上故障排查？

#### 如何打印JVM日志？

- JDK 8垃圾收集日志打印参数：

打印GC明细、日期、系统相对时间戳、GC的原因、GC日志存储的位置。

```java
-Xms50m -Xmx50m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -Xloggc:/Users/itmuch.com/gclog.log
```

- JDK 11垃圾收集日志打印参数：

打印GC详情、GC日志存储的位置，使用-Xlog进行统一日志管理。

```java
-Xms50m -Xmx50m -Xlog:gc*=trace:file=/Users/itmuch.com/xloggc.log
```

- JDK 8运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志。

```java
-XX:+TraceClassLoading -XX:+TraceBiasedLocking
```

- JDK 11运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志，使用-Xlog进行统一日志管理。

```java
-Xlog:class+load=debug,biasedlocking=debug:file=/Users/itmuch.com/trace.log
```

#### 如果分析GC日志？

- **自动分析GC日志工具**：

  - **GCEasy（在线）**：<https://www.gceasy.io/>。

  ![1626740104774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740104774.png)

  - **GC Viewer（老牌）**：<https://github.com/chewiebug/GCViewer>。

  ![1626740032908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740032908.png)

  - **GCPlot（很久没维护了）**：<https://github.com/GCPlot/gcplot>。

- **手工分析，格式如下**：

##### Serial GC日志

除CMS、G1 GC日志与Serial GC（Serial + Serial Old）日志不太一样外，其他的格式都是类似的。

###### JDK 8 Serial GC日志

```java
# Serial GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseSerialGC -Xmx50m -Xloggc:./gc_analysis.log

# JDK相关信息
Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)

# 内存相关信息
Memory: 4k page, physical 8266332k(2973848k free), swap 16532664k(9866032k free)

# 展示当前应用使用的JVM参数
CommandLine flags:
    -XX:-BytecodeVerificationLocal
    -XX:-BytecodeVerificationRemote
    -XX:InitialHeapSize=52428800
    -XX:+ManagementServer
    -XX:MaxHeapSize=52428800
    -XX:+PrintGC
    -XX:+PrintGCDateStamps
    -XX:+PrintGCDetails
    -XX:+PrintGCTimeStamps
    -XX:TieredStopAtLevel=1
    -XX:+UseCompressedClassPointers
    -XX:+UseCompressedOops
    -XX:-UseLargePagesIndividualAllocation
    -XX:+UseSerialGC

# 年轻代GC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:08.848+0800:
# 相对时间戳(PrintGCTimeStamps):
    3.708:
# 造成GC的原因(PrintGCCause):...:
    [GC (Allocation Failure) 2021-04-15T20:36:08.849+0800: 3.709:
# 展示DefaultNew的回收前后的内存以及年轻代总内存大小(Serial DefNew)
    [DefNew: 13696K->1663K(15360K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0099516 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13696K->2410K(49536K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0111863 secs]
# 用户、系统、实际耗时
    [Times: user=0.00 sys=0.00, real=0.01 secs]

# FullGC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:20.608+0800:
# 相对时间戳(PrintGCTimeStamps):
    15.466:
# 造成GC的原因(PrintGCCause):...:
    [Full GC (Metadata GC Threshold) 2021-04-15T20:36:20.608+0800: 15.466:
# 老年代回收之前和回收之后的内存大小以及老年代总内存大小
    [Tenured: 5749K->6890K(34176K),
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0256217 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13665K->6890K(49536K),
# 元空间回收之前和回收之后的内存大小以及元空间总内存大小
    [Metaspace: 20533K->20533K(1067008K)],
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0257088 secs]
# 用户、系统、实际耗时
    [Times: user=0.01 sys=0.00, real=0.02 secs]
```

###### JDK 11 Serial GC日志

```java
# JDK11 Serial GC收集器日志分析:

[0.104s][info][gc] Using Serial
# 内存概览: 堆内存地址、堆内存总大小、、压缩指针模式
[0.105s][info][gc,heap,coops] Heap address: 0x00000000fe200000, size: 30 MB, Compressed Oops mode: 32-bit
# 年轻代GC, 第1次回收为GC(0)
[1.846s][info][gc,start     ] GC(0) Pause Young (Allocation Failure)
# 年轻代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) DefNew: 8192K->1024K(9216K)
# 老年代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) Tenured: 0K->4482K(20480K)
# 元空间回收前后的内存以及总内存大小
[1.862s][info][gc,metaspace ] GC(0) Metaspace: 6131K->6131K(1056768K)
# 整个堆回收前后的内存以及总内存大小
[1.862s][info][gc           ] GC(0) Pause Young (Allocation Failure) 8M->5M(29M) 16.267ms
# 用户、系统、实际耗时
[1.862s][info][gc,cpu       ] GC(0) User=0.00s Sys=0.00s Real=0.02s
[4.813s][info][gc,start     ] GC(1) Pause Young (Allocation Failure)
[4.824s][info][gc,heap      ] GC(1) DefNew: 9216K->1024K(9216K)
[4.824s][info][gc,heap      ] GC(1) Tenured: 4482K->6236K(20480K)
[4.824s][info][gc,metaspace ] GC(1) Metaspace: 11473K->11473K(1060864K)
[4.824s][info][gc           ] GC(1) Pause Young (Allocation Failure) 13M->7M(29M) 11.722ms
```

##### CMS GC日志

使用ParNew + CMS的组合，Serial Old作为后备。

```java
# CMS GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -Xmx50m -Xloggc:./GC_CMS.log
# 结论: => 日志格式大体上与GC_Serial.log一致, 但增加了一些CMS的步骤描述

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3336640k free), swap 16532664k(9654484k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:MaxNewSize=17477632 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC 
2021-04-15T21:04:10.842+0800: 2.650: [GC (Allocation Failure) 2021-04-15T21:04:10.842+0800: 2.650: [ParNew: 13696K->1664K(15360K), 0.0128738 secs] 13696K->2445K(49536K), 0.0131776 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]

# 1、初始标记
2021-04-15T21:04:22.827+0800: 14.635: [GC (CMS Initial Mark) [1 CMS-initial-mark: 7035K(34176K)] 8820K(49536K), 0.0007531 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:22.827+0800: 14.636: [CMS-concurrent-mark-start]
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-mark: 0.019/0.019 secs] [Times: user=0.06 sys=0.03, real=0.02 secs]
# 3、并发预清理 -> (4、并发可中止清理)
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-preclean-start]
2021-04-15T21:04:22.848+0800: 14.656: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 5、重新标记
2021-04-15T21:04:22.848+0800: 14.656: [GC (CMS Final Remark) [YG occupancy: 2776 K (15360 K)]2021-04-15T21:04:22.848+0800: 14.656: [Rescan (parallel) , 0.0009519 secs]2021-04-15T21:04:22.849+0800: 14.657: [weak refs processing, 0.0000363 secs]2021-04-15T21:04:22.849+0800: 14.657: [class unloading, 0.0032038 secs]2021-04-15T21:04:22.853+0800: 14.660: [scrub symbol table, 0.0038571 secs]2021-04-15T21:04:22.856+0800: 14.664: [scrub string table, 0.0003238 secs][1 CMS-remark: 7035K(34176K)] 9811K(49536K), 0.0087240 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]
# 6、并发清除
2021-04-15T21:04:22.857+0800: 14.665: [CMS-concurrent-sweep-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-sweep: 0.003/0.003 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 7、并发重置
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]

# 1、初始标记
2021-04-15T21:04:27.076+0800: 18.884: [GC (CMS Initial Mark) [1 CMS-initial-mark: 21029K(34176K)] 22587K(49536K), 0.0011465 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:27.077+0800: 18.885: [CMS-concurrent-mark-start]
2021-04-15T21:04:27.113+0800: 18.921: [CMS-concurrent-mark: 0.036/0.036 secs] [Times: user=0.08 sys=0.01, real=0.04 secs]
# 3、并发预清理
2021-04-15T21:04:27.114+0800: 18.922: [CMS-concurrent-preclean-start]
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、并发可中止清理
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-abortable-preclean-start]
2021-04-15T21:04:27.282+0800: 19.090: [GC (Allocation Failure) 2021-04-15T21:04:27.282+0800: 19.090: [ParNew: 14979K->1443K(15360K), 0.0043541 secs] 36009K->22692K(49536K), 0.0044774 secs] [Times: user=0.06 sys=0.00, real=0.00 secs] 
2021-04-15T21:04:27.418+0800: 19.226: [CMS-concurrent-abortable-preclean: 0.050/0.303 secs] [Times: user=0.47 sys=0.00, real=0.30 secs]
# 5、重新标记
2021-04-15T21:04:27.418+0800: 19.226: [GC (CMS Final Remark) [YG occupancy: 8840 K (15360 K)]2021-04-15T21:04:27.418+0800: 19.226: [Rescan (parallel) , 0.0028890 secs]2021-04-15T21:04:27.421+0800: 19.229: [weak refs processing, 0.0000623 secs]2021-04-15T21:04:27.421+0800: 19.229: [class unloading, 0.0035473 secs]2021-04-15T21:04:27.425+0800: 19.233: [scrub symbol table, 0.0088034 secs]2021-04-15T21:04:27.434+0800: 19.242: [scrub string table, 0.0005316 secs][1 CMS-remark: 21248K(34176K)] 30088K(49536K), 0.0162688 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]
# 6、并发清除
2021-04-15T21:04:27.435+0800: 19.243: [CMS-concurrent-sweep-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-sweep: 0.012/0.012 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
# 7、并发重置
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
```

##### G1 GC日志

与Serial GC、CMS GC格式差异非常大。

```java
# G1 GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseG1GC -Xmx50m -Xloggc:./GC_G1.log

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3458332k free), swap 16532664k(9495268k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:-UseLargePagesIndividualAllocation

# 年轻代G1 GC: 下面的缩进表示日志的子任务
2021-04-15T21:12:09.426+0800: 2.494: [GC pause (G1 Evacuation Pause) (young), 0.0052693 secs]
   # 并发任务解释
   [Parallel Time: 4.1 ms, GC Workers: 4]
      # GC统计
      [GC Worker Start (ms): Min: 2493.6, Avg: 2493.6, Max: 2493.6, Diff: 0.0]
      # GC扫描对象统计
      [Ext Root Scanning (ms): Min: 0.0, Avg: 0.7, Max: 1.1, Diff: 1.1, Sum: 2.7]
      # Update Remembered Sets(指保存到堆中的区域跟踪引用 -> 保存到Update Buffers更新缓存中)
      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Update Buffers数量统计
         [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0]
      # Remembered Sets扫描统计
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Code Root扫描统计
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.3]
      # 拷贝存活对象统计
      [Object Copy (ms): Min: 0.0, Avg: 2.2, Max: 3.1, Diff: 3.1, Sum: 8.6]
      # 中断统计
      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 0.6]
         # 尝试中断统计
         [Termination Attempts: Min: 1, Avg: 1.3, Max: 2, Diff: 1, Sum: 5]
      # GC线程其他工作统计
      [GC Worker Other (ms): Min: 0.0, Avg: 1.0, Max: 4.0, Diff: 3.9, Sum: 4.1]
      # GC线程总工作统计
      [GC Worker Total (ms): Min: 4.0, Avg: 4.1, Max: 4.1, Diff: 0.1, Sum: 16.3]
      # GC线程结束时间
      [GC Worker End (ms): Min: 2497.6, Avg: 2497.7, Max: 2497.7, Diff: 0.1]
   # 串行任务, 修复Code Root耗时统计
   [Code Root Fixup: 0.1 ms]
   # 串行任务, 清除Code Root耗时统计
   [Code Root Purge: 0.0 ms]
   # 清除Card Table中的Dirty Card耗时统计
   [Clear CT: 0.0 ms]
   # 其他任务
   [Other: 1.0 ms]
      # Collection Set选择区域耗时统计
      [Choose CSet: 0.0 ms]
      # 对象引用处理耗时统计
      [Ref Proc: 0.8 ms]
      # 引用队列ReferenceQueue耗时统计
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.0 ms]
      # 处理超大对象耗时统计
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      # 释放Collection Set耗时统计
      [Free CSet: 0.0 ms]
      # 各区域内存变化统计
   [Eden: 14.0M(14.0M)->0.0B(18.0M) Survivors: 0.0B->2048.0K Heap: 14.0M(50.0M)->2555.5K(50.0M)]
 # 用户、系统、实际耗时
 [Times: user=0.00 sys=0.00, real=0.01 secs]

# 最重要, 体现了G1 GC的过程
# 并发回收日志: 1、初始标记(stop the world)
2021-04-15T21:12:11.327+0800: 4.394: [GC pause (Metadata GC Threshold) (young) (initial-mark), 0.0047654 secs]
   [Parallel Time: 4.3 ms, GC Workers: 4]
      [GC Worker Start (ms): Min: 4394.3, Avg: 4394.3, Max: 4394.3, Diff: 0.0]
      [Ext Root Scanning (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.2, Sum: 4.1]
      [Update RS (ms): Min: 0.6, Avg: 0.7, Max: 0.8, Diff: 0.2, Sum: 2.7]
         [Processed Buffers: Min: 2, Avg: 3.8, Max: 7, Diff: 5, Sum: 15]
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]
      [Object Copy (ms): Min: 2.4, Avg: 2.5, Max: 2.5, Diff: 0.1, Sum: 9.9]
      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4]
      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [GC Worker Total (ms): Min: 4.2, Avg: 4.2, Max: 4.2, Diff: 0.0, Sum: 16.8]
      [GC Worker End (ms): Min: 4398.5, Avg: 4398.5, Max: 4398.5, Diff: 0.0]
   [Code Root Fixup: 0.0 ms]
   [Code Root Purge: 0.0 ms]
   [Clear CT: 0.1 ms]
   [Other: 0.4 ms]
      [Choose CSet: 0.0 ms]
      [Ref Proc: 0.2 ms]
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.1 ms]
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      [Free CSet: 0.0 ms]
   [Eden: 5120.0K(26.0M)->0.0B(26.0M) Survivors: 4096.0K->4096.0K Heap: 14.9M(50.0M)->11.3M(50.0M)]
 [Times: user=0.06 sys=0.00, real=0.01 secs]
# 开始扫描初始标记阶段Survivor区的Root Region
2021-04-15T21:12:11.332+0800: 4.399: [GC concurrent-root-region-scan-start]
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-root-region-scan-end, 0.0055232 secs]
# 2、并发标记
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-mark-start]
2021-04-15T21:12:11.352+0800: 4.419: [GC concurrent-mark-end, 0.0143048 secs]
# 3、最终标记(stop the world)
2021-04-15T21:12:11.355+0800: 4.422: [GC remark 2021-04-15T21:12:11.355+0800: 4.422: [Finalize Marking, 0.0001519 secs] 2021-04-15T21:12:11.355+0800: 4.422: [GC ref-proc, 0.0006391 secs] 2021-04-15T21:12:11.356+0800: 4.423: [Unloading, 0.0037653 secs], 0.0048311 secs]
 [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、筛选回收(stop the world)
2021-04-15T21:12:11.360+0800: 4.427: [GC cleanup 12M->12M(50M), 0.0005645 secs]
 [Times: user=0.00 sys=0.02, real=0.00 secs] 
```

#### 如何定位CPU过高的地方？

- **定位问题代码的方法**：
  - 可以使用JMC MBean服务器实时查看：但需要应用开启JMX连接。
  - **也可以使用top + jstack配合查看**：

1. top查看当前CPU占用率最高的进程，拿到占用率最高的进程号36032：

   ```java
   top
   ```

2. top -Hp查看该进程线程的运行信息，拿到占用率最高的线程号36044：

   ```java
   top -Hp 36032
   ```

3. printf得到该线程号36044的16进制数8ccc，用于搜索dump文件：

   ```java
   printf %x 36044
   ```

4. jstack dump出进程36032所有的线程栈，得到文件1.txt：

   ```java
   jstack 36032 > 1.txt
   ```

5. cat搜索线程栈文件1.txt，找到16进制为8ccc（即线程号为36044），并往后再搜索30行的内容：

   ```java
   cat 1.txt | grep -A 30 8ccc
   ```

6. 定位该线程中的出问题代码，并分析原因：原来是有个for循环，导致CPU过高。

```java
@Override
public void run() {
    while (true) {
        double a = Math.random() * Math.random();
        System.out.println(a);
    }
}
```

- **CPU过高的场景与解决方案**？
  - **无限while循环**：
    - 尽量避免无限循环。
    - 也可以让循环执行得慢点，比如sleep（）或者yeild（）。
  - **频繁GC**：
    - 尽量降低GC频率。
  - **频繁创建新的对象**：
    - 合理使用单例，避免频繁创建对象。
  - **频繁的线程上下文切换**：
    - 降低切换的频率，不过需要结合业务进行业务改造，而改造的难度取决于业务的复杂度。
  - 序列化和反序列化：
    - 原因：大多都是由于使用了不合理的类库导致的，比如XStream反序列化大对象，改用ObjectInputStream来解决问题。
    - 解决方案：使用合理的API来实现，选择好用的序列化与反序列化的类库。
  - 正则表达式：
    - 原因：由于正则表达式使用NFA自动机的引擎，在进行字符串匹配时会发生回溯，一旦发生回溯可能会导致CPU过高的问题。
    - 解决方案：改写正则表达式，降低回溯的发生。

#### 如何解决内存溢出问题？

##### 堆内存溢出

- **相关概念**：**堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。

- **定位问题代码的方法**：

1. 指定OOM溢出后转储堆Dump：

   真实环境下，堆内存溢出很可能会导致进程直接挂掉，根本不会打印堆栈日志，所以需要JVM发生异常时自动转储出堆Dump文件，以便出现问题后能够进行分析。

   ```java
   --XX:+HeapDumpOnOutOfMemoryError
   ```

2. 在项目根目录，找到堆Dump文件，使用MAT打开堆Dump文件：

   ![1626605721295](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605721295.png)

3. 点击Leak Suspects，分析内存泄露：

   ![1626605971298](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605971298.png)

4. 查看问题对象Object[]的details，分析with incoming references，即问题对象被引用的情况：

   此外，如果Leak Suspects有堆栈信息，也可以从堆栈信息中分析问题所在。

   ![1626606234660](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626606234660.png)

5. 原来是因为无限循环插入了一堆随机String对象：

   ```java
   public class HeapOOMTest {
       private List<String> oomList = new ArrayList<>();
   
       public static void main(String[] args) {
           HeapOOMTest oomTest = new HeapOOMTest();
           while (true) {
               oomTest.oomList.add(UUID.randomUUID().toString());
           }
       }
   }
   ```

- **堆内存溢出的场景**？
  - **内存泄露**：
    - 可以借助MAT或者VisualVM，去查看泄露对象到对象的引用链，分析这个泄露的对象是通过哪个路径跟哪个对象关联，从而导致没有被回收掉。最后找到内存泄露对象的创建位置，优化相关的代码。
  - **存在生命周期或者数据结构不合理的对象**：
    - 更换不合理对象的生命周期或者数据结构。
  - **机器的堆内存大小设置得过小**：
    - 根据实际情况适当增大-Xms、-Xmn的值。

##### 栈内存溢出

- **相关概念**：在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。
- **定位的方法**：栈溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
- **栈内存溢出的场景**？
  - **递归调用深度过大**：
    - 原因：每递归调用一次，就会创建一个栈帧压入栈中，在栈容量有限的情况下，当容纳不了足够多的栈帧时，则会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **方法内创建过多的局部变量**：
    - 原因：局部变量存放在局部变量表中，当栈中容纳不了这么多变量时也会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **创建了过多的线程**：
    - 原因：栈是线程独享的，每个线程会创建自己的栈，当创建新线程的时候没有足够的内存去创建对应的栈，则会抛出**OutOfMemoryError**异常。
    - 解决方法：优化问题代码。
- **如何保证创建足够多的线程**？
  - **减少-Xss配置**：由于栈是线程独享的，每个线程会创建自己的栈，对于相同的内存总量，减少每个栈的大小，就可以创建更多的栈，在OOM之前就可以创建更多的线程了。
  - **增大栈能分配的内存**：尽量减少除了栈以外的内存占用，增大栈内存占用。其中公式为：
    - 栈内存 = 机器总内存 - 操作系统内存 - 堆内存 - 方法区内存 - 程序计数器内存 - 直接内存。 
  - **尽量杀死其他应用程序**：这样可以为目标应用腾出更多的内存。
  - **增大操作系统对线程数量的限制**：
    - sysctl -w kernel.threads-max：增大Linux系统支持的最大线程数（表示物理内存决定的理论系统进程数上限，一般会很大）。
    - sysctl -w kernel.pid_max：增大Linux系统限制某用户下最多可以运行多少进程或线程数。
    - sysctl -w vm.max_map_count：增大限制一个进程可以拥有的VMA(虚拟内存区域)的数量。
      - 虚拟内存区域是一个连续的虚拟地址空间区域。在进程的生命周期中，每当程序尝试在内存中映射文件，链接到共享内存段，或者分配堆空间的时候，这些区域将被创建。
    - ulimit -u：增大用户最多可启动的进程数目。

##### 方法区溢出

- **相关概念**：

  - Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。

- **定位的方法**：方法区溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。

- **方法区内存溢出分类**：

  不同的JDK版本，方法区存放的结构不同，所以相同的代码导致的内存溢出抛出的异常信息也可能不同。

  - **永久代溢出 & 堆内存溢出**：
    - 对于小于JDK 7的版本，采用的是**永久代**存储符号引用、字符串以及类的静态变量，所以小于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 7把符号引用（native heap）、字符串常量池以及类的静态变量移动到了**堆**中，所以大于等于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**堆的大小**。
  - **永久代溢出 & 元空间溢出**：
    - 对于小于JDK 8的版本，采用的是**永久代**存储类信息，所以小于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 8中使用了**元空间**替代永久代，采用运行时常量池存储已加载的类的元数据信息，所以大于等于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**元空间**的大小，而元空间是放在**本地内存**上的，只要**机器内存**足够大，理论上是很难发生溢出的。

- **方法区内存溢出的场景**？

  - **常量池对象太大**：
    - **原因**：比如字符串过多。
    - **解决方案**：根据JDK版本，为（字符串）常量池预留足够的空间。
      - < JDK 7：增大PermSize、MaxPermSize。
      - 》= JDK7：增大-Xms、-Xmx。
  - **加载的类过多**：
    - **原因**：
      - **动态代理的操作库生成了大量的动态类**：比如CXF、XSource、CGLIB等动态代理的框架，因为增强的类越多，就需要更多的空间来存储类的定义信息。
      - **JSP过多**：因为JSP是在第一次被访问的时候，才会被编译成Java类，在极端场景下，访问过多的JSP页面，可能会打满方法区导致内存溢出。
      - 脚本语言动态类加载：比如Grovy脚本出现的动态类加载导致的元空间溢出的问题。
    - **解决方案**：
      - < JDK 8：增大PermSize、MaxPermSize。
      - 》= JDK 8：可以留空元空间相关的配置（本地内存实现，不配置时JVM会动态去分配），或者设置合理的元空间大小。

##### 直接内存溢出

- **相关概念**：
  - **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，但这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。
- **定位的方法**：直接溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
  - java.lang.OutOfMemoryError：Unsafe导致直接内存溢出报错没有小尾巴。
  - java.lang.OutOfMemoryError: Direct buffer memory：ByteBuffer直接内存溢出报错是有小尾巴的。
  - **（经验之谈）如果堆Dump文件看不出问题或者太小，可考虑是直接内存溢出的问题**。
- **直接内存溢出的场景**？
  - **内存泄露多导致的内存溢出**：
    - **原因**：分配对象到直接内存后，不使用时不释放内存，然后继续分配对象，时间久了就会出现溢出问题。
    - **解决方案**：设置最大直接内存大小-XX：MaxDirectMemorySize，**对Unsafe不起作用**，但对ByteBuffer有效（会先设置long maxMemory = VM.maxDirectMemory（））。

##### 代码缓存区溢出

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。
- **定位的方法**：
  - 使用jconsole连接进程观察CodeCache。
  - 日志打印出VM warning：CodeCache is full. Compiler has been disabled信息。
  - 项目平常性能OK，但突然出现性能下降，业务又没有问题时，可排查是否由代码缓存区溢出所导致。
- **代码缓存区溢出的场景**：
  - **单体项目过于庞大但CodeCache又设置得过小**。
    - **解决方案**：
      - 可以对照jconsole设置合理的-XX：ReservedCodeCacheSize（代码缓存区的最大大小）。
      - 而对于微服务等代码量不多的小应用来说，240MB默认的CodeCache一般都是够用的了。

#### 项目越跑越慢如何定位与解决？

可能的场景有：

- **Stop The World时间过长、GC频繁**：
  - **定位方法**：检查GC日志。
  - 解决方案？：增加-XX：ParallelGCThreads并行收集的线程数、根据实际情况更换垃圾收集器。

- **项目依赖的资源导致变慢**：
  - **定位方法**：检查数据库、网络等资源是否被其他程序占用了很多。
  - 解决方案？：释放调用问题的资源。

- **CodeCache满了**：会导致JIT从编译执行退化成了解释执行。

  - **定位方法**：使用jconsole检查CodeCache大小。

- **线程争抢过于激烈**：会导致目标线程抢不到CPU片。
  - **定位方法**：使用VisualVM检查目标进程中的线程运行情况、分析ThreadDump（比如可以使用FastThread、PerfMa进行可视化分析）。
    - 结果发现：在循环中创建了一堆线程池，且使用完了又没关闭掉，导致线程池争抢激烈，消耗CPU资源严重。
    - 解决方案：使用完线程池后，在finally代码块把线程池关闭掉；同时根据业务规则命名线程（new ThreadFactoryBuilder().setNameFormat("my-thread-pool-%d")），方便以后定位问题。

- 服务器问题（了解就好）：操作系统问题、其他进程争抢资源。

  如果一个实例发生了问题，根据情况选择，要不要着急去重启。如果出现的CPU、内存飙高或者日志里出现了OOM异常**第一步是隔离**，第二步是**保留现场**，第三步才是**问题排查**。

  - **隔离**：就是把你机器从请求列表里摘除，比如把nginx相关的权重设成零。

  - **保留现场**：

    1. **系统当前网络连接**：使用 ss 命令而不是netstat的原因是：netstat 在网络连接非常多的情况下，执行非常缓慢。后续的处理，可通过查看各种网络连接状态的梳理，排查 TIME_WAIT或者CLOSE_WAIT，或者其他连接过高的问题，非常有用。

       ```shell
       ss -antp > $DUMP_DIR/ss.dump 2>&1
       ```

    2. **网络状态统计**：

       ```shell
       # 它能够按照各个协议进行统计输出，对把握当时整个网络状态，有非常大的作用。
       netstat -s > $DUMP_DIR/netstat-s.dump 2>&1
       
       # 在一些速度非常高的模块上，比如 Redis、Kafka，就经常发生跑满网卡的情况。表现形式就是网络通信非常缓慢。
       sar -n DEV 1 2 > $DUMP_DIR/sar-traffic.dump 2>&1
       ```

    3. **进程资源**：通过查看进程，能看到打开了哪些文件，可以以进程的维度来查看整个资源的使用情况，包括每条网络连接、每个打开的文件句柄。同时，也可以很容易的看到连接到了哪些服务器、使用了哪些资源。这个命令在资源非常多的情况下，输出稍慢，请耐心等待。

       ```shell
       lsof -p $PID > $DUMP_DIR/lsof-$PID.dump
       ```

    4. **CPU 资源**：主要用于输出当前系统的 CPU 和负载，便于事后排查。

       ```shell
       mpstat > $DUMP_DIR/mpstat.dump 2>&1
       vmstat 1 3 > $DUMP_DIR/vmstat.dump 2>&1
       sar -p ALL  > $DUMP_DIR/sar-cpu.dump  2>&1
       uptime > $DUMP_DIR/uptime.dump 2>&1
       ```

    5. **I/O 资源**：一般，以计算为主的服务节点，I/O 资源会比较正常，但有时也会发生问题，比如**日志输出过多，或者磁盘问题**等。此命令可以输出每块磁盘的基本性能信息，用来排查 I/O 问题。在第 8 课时介绍的 GC 日志分磁盘问题，就可以使用这个命令去发现。

       ```shell
       iostat -x > $DUMP_DIR/iostat.dump 2>&1
       ```

    6. **内存问题**：free 命令能够大体展现操作系统的内存概况，这是故障排查中一个非常重要的点，比如 SWAP 影响了 GC，SLAB 区挤占了 JVM 的内存。

       ```shell
       free -h > $DUMP_DIR/free.dump 2>&1
       ```

    7. **其他全局**：dmesg 是许多静悄悄死掉的服务留下的最后一点线索。当然，ps 作为执行频率最高的一个命令，由于内核的配置参数，会对系统和 JVM 产生影响，所以我们也输出了一份。

       ```shell
       ps -ef > $DUMP_DIR/ps.dump 2>&1
       dmesg > $DUMP_DIR/dmesg.dump 2>&1
       sysctl -a > $DUMP_DIR/sysctl.dump 2>&1
       ```

    8. **进程快照**：此命令将输出 Java 的基本进程信息，包括**环境变量和参数配置**，可以查看是否因为一些错误的配置造成了 JVM 问题。

       ```shell
       ${JDK_BIN}jinfo $PID > $DUMP_DIR/jinfo.dump 2>&1
       ```

    9. **dump堆信息**：jstat 将输出当前的 gc 信息。一般，基本能大体看出一个端倪，如果不能，可将借助 jmap 来进行分析。

       ```shell
       ${JDK_BIN}jstat -gcutil $PID > $DUMP_DIR/jstat-gcutil.dump 2>&1
       ${JDK_BIN}jstat -gccapacity $PID > $DUMP_DIR/jstat-gccapacity.dump 2>&1
       ```

    10. **堆信息**：jmap 将会得到当前 Java 进程的 dump 信息。如上所示，其实最有用的就是第 4 个命令，但是前面三个能够让你初步对系统概况进行大体判断。因为，第 4 个命令产生的文件，一般都非常的大。而且，需要下载下来，导入 MAT 这样的工具进行深入分析，才能获取结果。这是分析内存泄漏一个必经的过程。

        ```shell
        ${JDK_BIN}jmap $PID > $DUMP_DIR/jmap.dump 2>&1
        ${JDK_BIN}jmap -heap $PID > $DUMP_DIR/jmap-heap.dump 2>&1
        ${JDK_BIN}jmap -histo $PID > $DUMP_DIR/jmap-histo.dump 2>&1
        ${JDK_BIN}jmap -dump:format=b,file=$DUMP_DIR/heap.bin $PID > /dev/null  2>&1
        ```

    11. **JVM 执行栈**：

        ```shell
        # jstack 将会获取当时的执行栈。一般会多次取值，我们这里取一次即可。这些信息非常有用，能够还原 Java 进程中的线程情况。
        ${JDK_BIN}jstack $PID > $DUMP_DIR/jstack.dump 2>&1
        
        # 为了能够得到更加精细的信息，我们使用 top 命令，来获取进程中所有线程的 CPU 信息，这样，就可以看到资源到底耗费在什么地方了。
        top -Hp $PID -b -n 1 -c >  $DUMP_DIR/top-$PID.dump 2>&1
        ```

    12. **高级替补**：

        ```shell
        # 有时候，jstack 并不能够运行，有很多原因，比如 Java 进程几乎不响应了等之类的情况。我们会尝试向进程发送 kill -3 信号，这个信号将会打印 jstack 的 trace 信息到日志文件中，是 jstack 的一个替补方案。
        kill -3 $PID
        
        # 对于 jmap 无法执行的问题，也有替补，那就是 GDB 组件中的 gcore，将会生成一个 core 文件。我们可以使用如下的命令去生成 dump：
        gcore -o $DUMP_DIR/core $PID
        ${JDK_BIN}jhsdb jmap --exe ${JDK}java  --core $DUMP_DIR/core --binaryheap
        ```

    13. **内存泄漏的现象**：稍微提一下 jmap 命令，它在 9 版本里被干掉了，取而代之的是 jhsdb，你可以像下面的命令一样使用。一般内存溢出，表现形式就是 Old 区的占用持续上升，即使经过了多轮 GC 也没有明显改善。比如ThreadLocal里面的GC Roots，内存泄漏的根本就是，这些对象并没有切断和 GC Roots 的关系，可通过一些工具，能够看到它们的联系。

        ```shell
        jhsdb jmap  --heap --pid  37340
        jhsdb jmap  --pid  37288
        jhsdb jmap  --histo --pid  37340
        jhsdb jmap  --binaryheap --pid  37340
        ```





# 三、多线程篇 

### 线程调度

#### **1、线程状态**

​		线程是cpu任务调度的最小执行单位，每个线程拥有自己独立的程序计数器、虚拟机栈、本地方法栈

**线程状态：创建、就绪、运行、阻塞、死亡**

<img src="https://s0.lgstatic.com/i/image3/M01/77/29/Cgq2xl5xxGKAKBpeAAEw9Ifr07Y662.png" alt="img" style="zoom: 40%;" />



#### **2、线程状态切换**

| 方法      | 作用                                                   | 区别             |
| --------- | ------------------------------------------------------ | ---------------- |
| start     | 启动线程，由虚拟机自动调度执行run()方法                | 线程处于就绪状态 |
| run       | 线程逻辑代码块处理，JVM调度执行                        | 线程处于运行状态 |
| sleep     | 让当前正在执行的线程休眠（暂停执行）                   | 不释放锁         |
| wait      | 使得当前线程等待                                       | 释放同步锁       |
| notify    | 唤醒在此对象监视器上等待的单个线程                     | 唤醒单个线程     |
| notifyAll | 唤醒在此对象监视器上等待的所有线程                     | 唤醒多个线程     |
| yiled     | 停止当前线程，让同等优先权的线程运行                   | 用Thread类调用   |
| join      | 使当前线程停下来等待，直至另一个调用join方法的线程终止 | 用线程对象调用   |

<img src="https://s0.lgstatic.com/i/image/M00/80/24/Ciqc1F_Qfy2ACkrLAAD2DLkc2qw212.png" alt="img" style="zoom:67%;" />

#### **3、阻塞唤醒过程** 

**阻塞：**

​		这三个方法的调用都会使当前线程阻塞。该线程将会被放置到对该Object的请求等待队列中，然后让出当前对Object所拥有的所有的同步请求。线程会一直暂停所有线程调度，直到下面其中一种情况发生：

　　　　① 其他线程调用了该Object的notify方法，而该线程刚好是那个被唤醒的线程；

　　　　② 其他线程调用了该Object的notifyAll方法；

**唤醒：**

​		线程将会从等待队列中移除，重新成为可调度线程。它会与其他线程以常规的方式竞争对象同步请求。**一旦它重新获得对象的同步请求，所有之前的请求状态都会恢复，也就是线程调用wait的地方的状态。线程将会在之前调用wait的地方继续运行下去。**

**为什么要出现在同步代码块中：**

​		由于`wait()属于Object方法，调用之后会强制释放当前对象锁，所以在wait()` 调用时必须拿到当前对象的监视器monitor对象。因此，wait()方法在同步方法/代码块中调用。



#### **4、wait和sleep区别**

- wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。

- wait 方法会主动释放 monitor 锁，在同步代码中执行 sleep 方法时，并不会释放 monitor 锁。

- wait 方法意味着永久等待，直到被中断或被唤醒才能恢复，不会主动恢复，sleep 方法中会定义一个时间，时间到期后会主动恢复。

- wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。

  

#### 5、创建线程方式

**实现 Runnable 接口**（优先使用）

```java
public class RunnableThread implements Runnable {
    @Override
    public void run() {System.out.println('用实现Runnable接口实现线程');}
}
```

**实现Callable接口**（有返回值可抛出异常）

```java
class CallableTask implements Callable<Integer> {
    @Override
    public Integer call() throws Exception { return new Random().nextInt();}
}
```

**继承Thread类**（java不支持多继承）

```java
public class ExtendsThread extends Thread {
    @Override
    public void run() {System.out.println('用Thread类实现线程');}
}
```

**使用线程池**（底层都是实现run方法）

```java
static class DefaultThreadFactory implements ThreadFactory {
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup();
        namePrefix = "pool-" + poolNumber.getAndIncrement() +"-thread-";
    }
    public Thread newThread(Runnable r) {
        Thread t = new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0);
        if (t.isDaemon()) t.setDaemon(false);  //是否守护线程
        if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); //线程优先级
        return t;
    }
}
```





### 线程池

优点：通过复用已创建的线程，**降低资源损耗**、线程可以直接处理队列中的任务**加快响应速度**、同时便于**统一监控和管理**。

#### **1、线程池构造函数** 

```java
/**
* 线程池构造函数7大参数
*/
public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,
    TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,
    RejectedExecutionHandler handler) {}
```

**参数介绍：**

| 参数                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| corePoolSize             | 核心线程池大小                                               |
| maximumPoolSize          | 最大线程池大小                                               |
| keepAliveTime            | 线程池中超过 corePoolSize 数目的空闲线程最大存活时间；       |
| TimeUnit                 | keepAliveTime 时间单位                                       |
| workQueue                | 阻塞任务队列                                                 |
| threadFactory            | 新建线程工厂                                                 |
| RejectedExecutionHandler | 拒绝策略。当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 |

#### **2、线程处理任务过程：**

<img src="https://s0.lgstatic.com/i/image3/M01/78/50/Cgq2xl5zjxGAXOA-AABF0Dv8GMI518.png" alt="img" style="zoom: 67%;" />

1. 当线程池小于corePoolSize，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。
2. 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。
3. 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。
4. 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。
5. 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。

#### **3、线程拒绝策略**

​		线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。

JDK 内置的拒绝策略如下：

​		**AbortPolicy：**直接抛出异常，阻止系统正常运行。可以根据业务逻辑选择重试或者放弃提交等策略。

​		**CallerRunsPolicy ：**只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。

​				不会造成任务丢失，同时减缓提交任务的速度，给执行任务缓冲时间。

​		**DiscardOldestPolicy ：**丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。

​		**DiscardPolicy ：**该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。

#### **4、Execuors类实现线程池**

<img src="https://s0.lgstatic.com/i/image3/M01/63/5A/CgpOIF4z1EiAFjNQAAAtVe5xjgQ999.png" alt="img" style="zoom: 50%;" />

- **newSingleThreadExecutor()：**只有一个线程的线程池，任务是顺序执行，适用于一个一个任务执行的场景
- **newCachedThreadPool()：**线程池里有很多线程需要同时执行，60s内复用，适用执行很多短期异步的小程序或者负载较轻的服务
- **newFixedThreadPool()：**拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，适用执行长期的任务。
- **newScheduledThreadPool()：**用来调度即将执行的任务的线程池
- **newWorkStealingPool()**：底层采用forkjoin的Deque，采用独立的任务队列可以减少竞争同时加快任务处理
- 
- <img src="https://s0.lgstatic.com/i/image2/M01/AF/80/CgoB5l3kzomAckv5AAAxf6FCPco696.png" alt="img" style="zoom:50%;" />

**因为以上方式都存在弊端：**

​		FixedThreadPool 和 SingleThreadExecutor ： 允许请求的**队列⻓度**为 Integer.MAX_VALUE，会导致OOM。
​		CachedThreadPool 和 ScheduledThreadPool ： 允许创建的**线程数量**为 Integer.MAX_VALUE，会导致OOM。

手动创建的线程池底层使用的是ArrayBlockingQueue可以防止OOM。



#### **5、线程池大小设置**

- CPU 密集型（n+1）

​	CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。

​	CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。

- IO 密集型（2*n）

​	由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 

​	也可以使用公式：CPU 核心数 *（1+平均等待时间/平均工作时间）。



### 线程安全

#### **1、乐观锁，CAS思想**

**java乐观锁机制：**

​		乐观锁体现的是悲观锁的反面。它是一种积极的思想，它总是认为数据是不会被修改的，所以是不会对数据上锁的。但是乐观锁在更新的时候会去判断数据是否被更新过。乐观锁的实现方案一般有两种（版本号机制和CAS）。乐观锁适用于**读多写少的场景，这样可以提高系统的并发量**。在Java中 **java.util.concurrent.atomic**下的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

　　乐观锁，大多是基于数据版本  (Version)记录机制实现。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来 实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提 交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据 版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。

**CAS思想：**

​		CAS就是compare and swap（**比较交换**），是一种很出名的无锁的算法，就是可以不使用锁机制实现线程间的同步。使用CAS线程是不会被阻塞的，所以又称为非阻塞同步。CAS算法涉及到三个操作：

​		需要读写内存值V；进行比较的值A；准备写入的值B

​		当且仅当V的值等于A的值等于V的值的时候，才用B的值去更新V的值，否则不会执行任何操作（比较和替换是一个原子操作-A和V比较，V和B替换），一般情况下是一个**自旋操作**，即**不断重试**

**缺点：**

​		[ABA问题-知乎](https://www.zhihu.com/question/23281499/answer/854522984)

​		高并发的情况下，很容易发生并发冲突，如果CAS一直失败，那么就会一直重试，浪费CPU资源

**原子性：**

​		功能限制CAS是能保证单个变量的操作是原子性的，在Java中要配合使用volatile关键字来保证线程的安全；当涉及到多个变量的时候CAS无能为力；除此之外CAS实现需要硬件层面的支持，在Java的普通用户中无法直接使用，只能**借助atomic包下的原子类**实现，灵活性受到了限制



#### **2、synchronized底层实现**

**使用方法：**主要的三种使⽤⽅式

​		**修饰实例⽅法:** 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁

​		**修饰静态⽅法:** 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员。

​		**修饰代码块:** 指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。

​		**总结：**synchronized锁住的资源只有两类：一个是**对象**，一个是**类**。

**底层实现：**

​		对象头是我们需要关注的重点，它是synchronized实现锁的基础，因为synchronized申请锁、上锁、释放锁都与对象头有关。对象头主要结构是由`Mark Word` 组成，**其中`Mark Word`存储对象的hashCode、锁信息或分代年龄或GC标志等信息**。

​		锁也分不同状态，JDK6之前只有两个状态：无锁、有锁（重量级锁），而在JDK6之后对synchronized进行了优化，新增了两种状态，总共就是四个状态：**无锁状态、偏向锁、轻量级锁、重量级锁**，其中无锁就是一种状态了。锁的类型和状态在对象头`Mark Word`中都有记录，在申请锁、锁升级等过程中JVM都需要读取对象的`Mark Word`数据。

​		同步代码块是利用 monitorenter 和 monitorexit 指令实现的，而同步方法则是利用 flags 实现的。



#### **3、ReenTrantLock底层实现**

​		由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能

**使用方法：**

​		基于API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成

**底层实现：**

​		ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

**和synchronized区别：**

​		1、**底层实现**：synchronized 是**JVM**层面的锁，是**Java关键字**，通过monitor对象来完成（monitorenter与monitorexit），ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的**API层面**的锁。

​		2、**实现原理****：synchronized 的实现涉及到**锁的升级**，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁；ReentrantLock实现则是通过利用**CAS**（CompareAndSwap）自旋机制保证线程操作的原子性和volatile保证数据可见性以实现锁的功能。

​		3、**是否可手动释放：**synchronized 不需要用户去手动释放锁，synchronized 代码执行完后系统会自动让线程释放对锁的占用； ReentrantLock则需要用户去手动释放锁，如果没有手动释放锁，就可能导致**死锁现象**。

​		4、**是否可中断**synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断。

​		5、**是否公平锁**synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁,公平锁性能非常低。



#### **4、公平锁和非公平锁区别**

**公平锁：**

​		公平锁自然是遵循**FIFO**（先进先出）原则的，先到的线程会优先获取资源，后到的会进行排队等待

​		**优点：**所有的线程都能得到资源，不会饿死在队列中。适合大任务

​		**缺点：**吞吐量会下降，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销大



**非公平锁：**

​		多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。

​		**优点：**可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。

​		**缺点：**你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁

<img src="https://s0.lgstatic.com/i/image3/M01/02/7D/Ciqah157DAiAK_DJAAC0JawhGp4730.png" alt="img" style="zoom:67%;" />

**公平锁效率低原因：**

​		公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在 wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面线程。这种情况下相比较非公平锁多了一次**挂起和唤醒**。

​		**线程切换的开销**，其实就是非公平锁效率高于公平锁的原因，因为**非公平锁减少了线程挂起的几率**，后来的线程有一定几率逃离被挂起的开销。



#### **5、使用层面锁优化**

​	【1】**减少锁的时间：**
​		不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；

​	【2】**减少锁的粒度：**
​		它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率，比如：

​		**ConcurrentHashMap：**

​		java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组：Segment< K,V >[] segments

​		Segment继承自ReenTrantLock，所以每个Segment是个可重入锁，每个Segment 有一个HashEntry< K,V >数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。

​	【3】**锁粗化：**
​		大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度; 

​		假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；

​	【4】**使用读写锁：**

​		ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写；

​	【5】**使用CAS：**

​		如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；



#### 6、系统层面锁优化

**自适应自旋锁：**

​		自旋锁可以避免等待竞争锁进入阻塞挂起状态被唤醒造成的**内核态和用户态之间的切换**的损耗，它们只需要等一等（自旋），但是如果锁被其他线程长时间占用，一直不释放CPU，死等会带来更多的性能开销；自旋次数默认值是10

​		对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的**自旋时间及锁的拥有者的状态**来决定，这就解决了自旋锁带来的缺点

**锁消除：**

​		锁削除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。Netty中无锁化设计pipeline中channelhandler会进行锁消除的优化。

**锁升级：**

​	**偏向锁：**

​		如果线程已经占有这个锁，当他在次试图去获取这个锁的时候，他会已最快的方式去拿到这个锁，而不需要在进行一些monitor操作，因为在大部分情况下是没有竞争的，所以使用偏向锁是可以提高性能的；

​	**轻量级锁：**

​		在竞争不激烈的情况下，通过CAS避免线程上下文切换，可以显著的提高性能。

​	**重量级锁：**

​		重量级锁的加锁、解锁过程造成的损耗是固定的，重量级锁适合于竞争激烈、高并发、同步块执行时间长的情况。



#### **7、ThreadLocal原理**

**ThreadLocal简介：**

​		通常情况下，我们创建的变量是可以被任何⼀个线程访问并修改的。如果想实现每⼀个线程都有⾃⼰的
专属本地变量该如何解决呢？ JDK中提供的 ThreadLocal 类正是为了解决这样的问题。类似操作系统中的TLAB

**原理：**

​		首先 ThreadLocal 是一个泛型类，保证可以接受任何类型的对象。因为一个线程内可以存在多个 ThreadLocal 对象，所以其实是 ThreadLocal 内部维护了一个 Map ，是 ThreadLocal 实现的一个叫做 ThreadLocalMap 的静态内部类。

​		最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。

​		我们使用的 get()、set() 方法其实都是调用了这个ThreadLocalMap类对应的 get()、set() 方法。例如下面的 

**如何使用：**

​		1）存储用户Session

```java
private static final ThreadLocal threadSession = new ThreadLocal();
```

​		2）解决线程安全的问题

```java
private static ThreadLocal<SimpleDateFormat> format1 = new ThreadLocal<SimpleDateFormat>()
```



**ThreadLocal内存泄漏的场景** 

​		实际上 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，⽽ value 是强引⽤。弱引用的特点是，如果这个对象持有弱引用，那么在下一次垃圾回收的时候必然会被清理掉。

​		所以如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来 ThreadLocalMap中使用这个 ThreadLocal 的 key 也会被清理掉。但是，value 是强引用，不会被清理，这样一来就会出现 key 为 null 的 value。 假如我们不做任何措施的话，value 永远⽆法被GC 回收，如果线程长时间不被销毁，可能会产⽣内存泄露。

<img src="https://s0.lgstatic.com/i/image3/M01/68/C4/Cgq2xl5Pld-AHFhJAADLtGXmSxc833.png" alt="img" style="zoom:67%;" />

​		ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。如果说会出现内存泄漏，那只有在出现了 key 为 null 的记录后，没有手动调用 remove() 方法，并且之后也不再调用 get()、set()、remove() 方法的情况下。因此使⽤完ThreadLocal ⽅法后，**最好⼿动调⽤ remove() ⽅法**。



#### **8、HashMap线程安全**

​	**死循环造成 CPU 100%**

​		HashMap 有可能会发生死循环并且造成  CPU 100% ，这种情况发生最主要的原因就是在**扩容**的时候，也就是内部**新建新的 HashMap** 的时候，扩容的逻辑会**反转散列桶中的节点顺序**，当有多个线程同时进行扩容的时候，由于 HashMap 并非线程安全的，所以如果**两个线程同时反转的话，便可能形成一个循环**，并且这种循环是链表的循环，相当于 A 节点指向 B 节点，B 节点又指回到 A 节点，这样一来，在下一次想要获取该 key 所对应的 value 的时候，便会在遍历链表的时候发生永远无法遍历结束的情况，也就发生 CPU 100% 的情况。

​		所以综上所述，HashMap 是线程不安全的，在多线程使用场景中推荐使用线程安全同时性能比较好的 ConcurrentHashMap。



#### 9、String不可变原因

1. 可以使用**字符串常量池**，多次创建同样的字符串会指向同一个内存地址

2. 可以很方便地用作 **HashMap 的 key**。通常建议把不可变对象作为 HashMap的 key

3. hashCode生成后就不会改变，使用时无需重新计算

4. 线程安全，因为具备不变性的对象一定是线程安全的

   

### 内存模型

​		Java 内存模型（Java Memory Model，JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了 Java 程序在各种平台下对内存的访问都能保证效果一致的机制及规范。

![img](https://s0.lgstatic.com/i/image3/M01/7A/05/Cgq2xl54fTKALhevAAB_l3axT_o532.png)

​		JMM 是一种规范，是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。

**原子性：**

​		在 Java 中，为了保证原子性，提供了两个高级的字节码指令 Monitorenter 和 Monitorexit。这两个字节码，在 Java 中对应的关键字就是 Synchronized。因此，在 Java 中可以使用 Synchronized 来保证方法和代码块内的操作是原子性的。

**可见性：**

​		Java 中的 Volatile 关键字修饰的变量在被修改后可以立即同步到主内存。被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用 Volatile 来保证多线程操作时变量的可见性。除了 Volatile，Java 中的 Synchronized 和 Final 两个关键字也可以实现可见性。只不过实现方式不同

**有序性**

​		在 Java 中，可以使用 Synchronized 和 Volatile 来保证多线程之间操作的有序性。区别：Volatile 禁止指令重排。Synchronized 保证同一时刻只允许一条线程操作。



#### **1、volatile底层实现**

**作用：**

​		保证数据的“可见性”：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。

​		禁止指令重排：在多线程操作情况下，指令重排会导致计算结果不一致

**底层实现：**

​		“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”

　　lock前缀指令实际上相当于一个**内存屏障**（也成内存栅栏），内存屏障会提供3个功能：

　　1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；

　　2）它会强制将对缓存的修改操作立即写入主存；

　　3）如果是写操作，它会导致其他CPU中对应的缓存行无效。

**单例模式中volatile的作用：**

防止代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。

```java
class Singleton{
    private volatile static Singleton instance = null;   //禁止指令重排
    private Singleton() {
         
    }
    public static Singleton getInstance() {
        if(instance==null) { //减少加锁的损耗
            synchronized (Singleton.class) {
                if(instance==null) //确认是否初始化完成
                    instance = new Singleton();
            }
        }
        return instance;
    }
}
```



#### **2、AQS思想** 

​		AQS的全称为（AbstractQueuedSynchronizer）抽象的队列式的同步器，是⼀个⽤来构建锁和同步器的框架，使⽤AQS能简单且⾼效地构造出应⽤⼴泛的⼤量的同步器，如：基于AQS实现的lock, CountDownLatch、CyclicBarrier、Semaphore需解决的问题：

```
状态的原子性管理
线程的阻塞与解除阻塞
队列的管理
```

​		AQS核⼼思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是⽤**CLH（虚拟的双向队列）**队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。

**lock：**

​		是一种可重入锁，除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。默认为非公平锁，但可以初始化为公平锁； 通过方法 lock()与 unlock()来进行加锁与解锁操作；

**CountDownLatch：**

​		通过计数法（倒计时器），让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒；该⼯具通常⽤来控制线程等待，它可以让某⼀个线程等待直到倒计时结束，再开始执⾏。具体可以使用countDownLatch.await()来等待结果。多用于多线程信息汇总。

**CompletableFuture：**

​		通过设置参数，可以完成CountDownLatch同样的多平台响应问题，但是可以针对其中部分返回结果做更加灵活的展示。

**CyclicBarrier：**

​		字面意思是可循环(Cyclic)使用的屏障（Barrier）。他要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await()方法。可以用于批量发送消息队列信息、异步限流。

**Semaphore：**

​		信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制。SpringHystrix限流的思想



#### 3、happens-before

​		用来描述和可见性相关问题：如果第一个操作 happens-before 第二个操作，那么我们就说第一个操作对于第二个操作是可见的

​		常见的happens-before：volatile 、锁、线程生命周期。







# 四、MySQL篇

### WhyMysql？

NoSQL数据库四大家族 

- 列存储 Hbase
- K-V存储 Redis
- 图像存储 Neo4j
- 文档存储 MongoDB

云存储OSS

#### 海量Aerospike

​	Aerospike（简称AS）是一个分布式，可扩展的键值存储的NoSQL**数据库**。T级别大数据高并发的结构化**数据存储，**采用混合架构，索引存储在内存中，而数据可存储在机械硬盘(HDD)或固态硬盘(SSD) 上，读写操作达微妙级，99%的响应可在1毫秒内实现。

|          | Aerospike                            | Redis                        |
| -------- | ------------------------------------ | ---------------------------- |
| 类型     | Nosql数据库                          | 缓存                         |
| 线程数   | 多线程                               | 单线程                       |
| 数据分片 | 自动处理相当于分片                   | 提供分片算法、平衡各分片数据 |
| 数据扩容 | 动态增加数据卷平衡流量               | 需停机                       |
| 数据同步 | 设置复制因子后可以透明的完成故障转移 | 手动故障转移和数据同步       |
| 载体     | 内存存储索引+SSD存储数据             | 内存                         |

​	Aerospike作为一个大容量的NoSql解决方案，适合对**容量要求比较大，QPS相对低**一些的场景，主要用在广告行业，**个性化推荐厂告**是建立在了和掌握消费者独特的偏好和习性的基础之上，对消费者的购买需求做出准确的预测或引导，在合适的位置、合适的时间，以合适的形式向消费者呈现与其需求高度吻合的广告，以此来促进用户的消费行为。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmam43b44bj30d90d4aa7.jpg" alt="image-20210103170039711" style="zoom:50%;" />

​	（ETL数据仓库技术）抽取（extract）、转换（transform）、加载（load）

- 用户行为日志收集系统收集日志之后推送到ETL做数据的清洗和转换

- 把ETL过后的数据发送到推荐引擎计算每个消费者的推荐结果，其中推荐逻辑包括规则和算法两部分

- 收集用户最近浏览、最长停留等特征，分析商品相似性、用户相似性、相似性等算法。

- 把推荐引擎的结果存入Aerospike集群中，并提供给广告投放引擎实时获取

  分别通过HDFS和HBASE对日志进行离线和实时的分析，然后把用户画像的标签(tag : 程序猿、宅男...)结果存入高性能的Nosql数据库Aerospike中，同时把数据备份到异地数据中心。前端广告投放请求通过决策引擎（投放引擎）向用户画像数据库中读取相应的用户画像数据，然后根据竞价算法出价进行竞价。竞价成功之后就可以展现广告了。而在竞价成功之后，具体给用户展现什么样的广告，就是有上面说的个性化推荐广告来完成的。

|      | Aerospike      | Mysql    |
| ---- | -------------- | -------- |
| 库名 | Namespace      | Database |
| 表名 | Set            | Table    |
| 记录 | Bin            | Column   |
| 字段 | Record         | Row      |
| 索引 | key 、 pk 、kv | pk       |



#### 图谱Neo4j

> Neo4j是一个开源基于java开发的图形noSql数据库，它将结构化数据存储在图中而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎。程序数据是在一个面向对象的、灵活的网络结构下，而不是严格的表中，但具备完全的事务特性、企业级的数据库的所有好处。

一种基于图的数据结构，由节点(Node)和边(Edge)组成。其中节点即实体，由一个全局唯一的ID标示，边就是关系用于连接两个节点。通俗地讲，知识图谱就是把所有不同种类的信息，连接在一起而得到的一个关系网络。知识图谱提供了从“关系”的角度去分析问题的能力。

互联网、大数据的背景下，谷歌、百度、搜狗等搜索引擎纷纷基于该背景，创建自己的知识图**Knowledge Graph（谷歌**）、**知心（百度）**和**知立方（搜狗）**，主要用于改进搜索质量。

自己项目主要用作好友推荐，图数据库(Graph database)指的是以图数据结构的形式来存储和查询数据的数据库。关系图谱中，关系的组织形式采用的就是图结构，所以非常适合用图库进行存储。

- ![image-20210103191540372](https://tva1.sinaimg.cn/large/0081Kckwly1gmaq0j9otdj30pz0en0vm.jpg)

  优势总结:

- 性能上，使用cql查询，对长程关系的查询速度快

- 擅于发现隐藏的关系，例如通过判断图上两点之间有没有走的通的路径，就可以发现事物间的关联

![image-20210103192653004](https://tva1.sinaimg.cn/large/0081Kckwly1gmaqc75y6bj30wc0d60u4.jpg)

```java
// 查询三层级关系节点如下：with可以将前面查询结果作为后面查询条件
match (na:Person)-[re]-(nb:Person) where na.name="林婉儿" WITH na,re,nb match (nb:Person)- [re2:Friends]->(nc:Person) return na,re,nb,re2,nc
// 直接拼接关系节点查询
match data=(na:Person{name:"范闲"})-[re]->(nb:Person)-[re2]->(nc:Person) return data
// 使用深度运算符
显然使用以上方式比较繁琐,可变数量的关系->节点可以使用-[:TYPE*minHops..maxHops]-。
match data=(na:Person{name:"范闲"})-[*1..2]-(nb:Person) return data
```



####  **文档MongoDB**

> MongoDB 是一个基于分布式文件存储的数据库，是非关系数据库中功能最丰富、最像关系数据库的。在高负载的情况下，通过添加更多的节点，可以保证服务器性能。由 C++ 编写，可以为 WEB 应用提供可扩展、高性能、易部署的数据存储解决方案。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaqyp75qsj312q0i8q5f.jpg" alt="image-20210103194830654" style="zoom:80%;" />

**什么是BSON**

> {key:value,key2:value2}和Json类似，是一种二进制形式的存储格式，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，比如 value包括字符串,double,Array,DateBSON可以做为网络数据交换的一种存储形式,它的优点是灵活性高，但它的缺点是空间利用率不是很理想。

BSON有三个特点：轻量性、可遍历性、高效性

```mysql
/* 查询 find() 方法可以传入多个键(key)，每个键(key)以逗号隔开*/
db.collection.find({key1:value1, key2:value2}).pretty()
/* 更新 $set ：设置字段值 $unset :删除指定字段 $inc：对修改的值进行自增*/
db.collection.update({where},{$set:{字段名:值}},{multi:true})
/* 删除 justOne :如果设为true，只删除一个文档，默认false，删除所有匹配条件的文档*/
db.collection.remove({where}, {justOne: <boolean>, writeConcern: <回执> } )
```

**优点：**

- **文档结构的存储方式，能够更便捷的获取数据。**

  对于一个层级式的数据结构来说，使用扁平式的，表状的结构来查询保存数据非常的困难。

- **内置GridFS，支持大容量的存储。**

  GridFS是一个出色的分布式文件系统，支持海量的数据存储，满足对大数据集的快速范围查询。

- **性能优越**

  千万级别的文档对象，近10G的数据，对有索引的ID的查询 不会比mysql慢，而对非索引字段的查询，则是全面胜出。 mysql实际无法胜任大数据量下任意字段的查询，而mongodb的查询性能实在牛逼。写入性能同样很令人满意，同样写入百万级别的数据，mongodb基本10分钟以下可以解决。

缺点：

- 不支持事务
- 磁盘占用空间大





MySQL 8.0 版本

**1. 性能**：MySQL 8.0 的速度要比 MySQL 5.7 快 2 倍。

**2. NoSQL**：MySQL 从 5.7 版本开始提供 NoSQL 存储功能，在 8.0 版本中nosql得到了更大的改进。

**3. 窗口函数**：实现若干新的查询方式。窗口函数与 SUM()、COUNT() 这种集合函数类似，但它不会将多行查询结果合并为一行，而是将结果放回多行当中，即窗口函数不需要 GROUP BY。

**4. 隐藏索引**：在 MySQL 8.0 中，索引可以被“隐藏”和“显示”。当对索引进行隐藏时，它不会被查询优化器所使用。我们可以使用这个特性用于性能调试，例如我们先隐藏一个索引，然后观察其对数据库的影响。如果数据库性能有所下降，说明这个索引是有用的，然后将其“恢复显示”即可；如果数据库性能看不出变化，说明这个索引是多余的，可以考虑删掉。



#### **云存储**

|        | OSS                                                          | 自建                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 可靠性 | 可用性不低于99.995%<br />数据设计持久性不低于99.9999999999%（12个9） | 受限于硬件可靠性，易出问题，一旦出现磁盘坏道，容易出现不可逆转的数据丢失。人工数据恢复困难、耗时、耗力。 |
| 安全   | 服务端加密、客户端加密、防盗链、IP黑白名单等。多用户资源隔离机制，支持异地容灾机制。 | 需要另外购买清洗和黑洞设备。需要单独实现安全机制。           |
| 成本   | 多线BGP骨干网络，无带宽限制，上行流量免费。无需运维人员与托管费用，0成本运维。 | 单线或双线接入速度慢，有带宽限制，峰值时期需人工扩容。需专人运维，成本高。 |

**使用步骤**

​	1、开通服务

​	2、创建存储空间

​	3、上传文件、下载文件、删除文件

​	4、域名绑定、日志记录

​	5、根据开放接口进行鉴权访问

**功能**

​	图片编辑（裁剪、模糊、水印）

​	视频截图

​	音频转码、视频修复

**CDN加速**

​	对象存储OSS与阿里云CDN服务结合，可优化静态热点文件下载加速的场景（即同一地区大量用户同时下载同一个静态文件的场景）。可以将OSS的存储空间（Bucket）作为源站，利用阿里云CDN将源内容发布到边缘节点。当大量终端用户重复访问同一文件时，可以直接从边缘节点获取已缓存的数据，提高访问的响应速度



#### **FastDFS**

> **开源的轻量级分布式文件系统**。它对文件进行管理，功能包括：**文件存储、文件同步、文件访问**（文件上传、文件下载）等，解决了**大容量存储和负载均衡**的问题。使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。如**相册网站、视频网站**等

**扩展能力:** 支持水平扩展，可以动态扩容；

**高可用性:** 一是整个文件系统的可用性，二是数据的完整和一致性；

**弹性存储:** 可以根据业务需要灵活地增删存储池中的资源，而不需要中断系统运行。

![image-20210107221022658](https://tva1.sinaimg.cn/large/008eGmZEly1gmfhjkvo59j30zu0b4dib.jpg)



特性

- 和流行的web server无缝衔接，FastDFS已提供apache和nginx扩展模块
- 文件ID由FastDFS生成，作为文件访问凭证，FastDFS不需要传统的name server
- 分组存储，灵活简洁、对等结构，不存在单点
- 文件不分块存储，上传的文件和OS文件系统中的文件一一对应
- 中、小文件均可以很好支持，支持海量小文件存储
- 支持相同内容的文件只保存一份，节约磁盘空间
- 支持多块磁盘，支持单盘数据恢复
- 支持在线扩容 支持主从文件
- 下载文件支持多线程方式，支持断点续传



**组成**

- **客户端（client）**

  通过专有接口，使用TCP/IP协议与跟踪器服务器或存储节点进行数据交互。

- **跟踪器（tracker）** 

  Trackerserver作用是负载均衡和调度，通过Tracker server在文件上传时可以根据策略找到文件上传的地址。Tracker在访问上起负载均衡的作用。

- **存储节点（storage）**

  Storageserver作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server**没有实现自己的文件系统而是利用操作系统的文件系统来管理文件**。存储节点中的服务器均可以**随时增加或下线而不会影响线上服务**。

**上传**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhvk0wwzj30ue0h4dlw.jpg" alt="image-20210107222155291" style="zoom:50%;" />

**下载**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfhww8zmfj30uw0g6n37.jpg" alt="image-20210107222312338" style="zoom:50%;" />

**断点续传**

​	续传涉及到的文件大小MD5不会改变。续传流程与文件上传类似，先**定位到源storage**，完成完整或部分上传，再**通过binlog进行同group内server文件同步**。

**配置优化**

配置文件：tracker.conf 和 storage.conf 

```java
// FastDFS采用内存池的做法。 
// v5.04对预分配采用增量方式，tracker一次预分配 1024个，storage一次预分配256个。 
max_connections = 10240
// 根据实际需要将 max_connections 设置为一个较大的数值，比如 10240 甚至更大。
// 同时需要将一个进程允许打开的最大文件数调大
vi /etc/security/limits.conf 重启系统生效 
* soft nofile 65535 
* hard nofile 65535
```

```java
work_threads = 4 
// 说明：为了避免CPU上下文切换的开销，以及不必要的资源消耗，不建议将本参数设置得过大。
// 公式为： work_threads + (reader_threads + writer_threads) = CPU数
```

```java
// 对于单盘挂载方式，磁盘读写线程分 别设置为 1即可 
// 如果磁盘做了RAID，那么需要酌情加大读写线程数，这样才能最大程度地发挥磁盘性能
disk_rw_separated：磁盘读写是否分离 
disk_reader_threads：单个磁盘读线程数 
disk_writer_threads：单个磁盘写线程数 
```

**避免重复**

​	如何避免文件重复上传 解决方案 上传成功后计算文件对应的MD5然后**存入MySQL**,添加文件时把**文件MD5和之前存入MYSQL中的存储的信息对比** 。DigestUtils.md5DigestAsHex(bytes)。

















### 事务

#### **1、事务4大特性** 

**事务4大特性：**原子性、一致性、隔离性、持久性

​	**原⼦性：** 事务是最⼩的执⾏单位，不允许分割。事务的原⼦性确保动作要么全部完成，要么全不执行

​	**一致性：** 执⾏事务前后，数据保持⼀致，多个事务对同⼀个数据读取的结果是相同的；

​	**隔离性：** 并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的；

​	**持久性：** ⼀个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发⽣故障也不应该对其有任何影响。

**实现保证：**

​		MySQL的存储引擎InnoDB使用重做日志保证一致性与持久性，回滚日志保证原子性，使用各种锁来保证隔离性。



#### **2、事务隔离级别**

**读未提交：**最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

**读已提交：**允许读取并发事务已经提交的数据，可以阻⽌脏读，但是幻读或不可重复读仍有可能发⽣。

**可重复读：**同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改，可以阻⽌脏读和不可重复读，会有幻读。

**串行化：**最⾼的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执⾏，这样事务之间就完全不可能产⽣⼲扰。

| 隔离级别 | 并发问题                         |
| -------- | -------------------------------- |
| 读未提交 | 可能会导致脏读、幻读或不可重复读 |
| 读已提交 | 可能会导致幻读或不可重复读       |
| 可重复读 | 可能会导致幻读                   |
| 可串行化 | 不会产⽣⼲扰                     |



#### **3、默认隔离级别-RR** 

**默认隔离级别：**可重复读；

​		同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改；

​		可重复读是有可能出现幻读的，如果要保证绝对的安全只能把隔离级别设置成SERIALIZABLE；这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多。

​		第二种方式，使用MVCC解决**快照读幻读问题**（如简单select），读取的不是最新的数据。维护一个字段作为version，这样可以控制到每次只能有一个人更新一个版本。

```mysql
select id from table_xx where id = ? and version = V
update id from table_xx where id = ? and version = V+1
```

​		第三种方式，如果需要读最新的数据，可以通过GapLock+Next-KeyLock可以解决**当前读幻读问题**，

```mysql
select id from table_xx where id > 100 for update;
select id from table_xx where id > 100 lock in share mode;
```



#### **4、RR和RC使用场景**

​		事务隔离级别RC(read commit)和RR（repeatable read）两种事务隔离级别基于多版本并发控制MVCC(multi-version concurrency control）来实现。

|        | RC                                   | RR                         |
| ------ | ------------------------------------ | -------------------------- |
| 实现   | 多条查询语句会创建多个不同的ReadView | 仅需要一个版本的ReadView   |
| 粒度   | 语句级读一致性                       | 事务级读一致性             |
| 准确性 | 每次语句执行时间点的数据             | 第一条语句执行时间点的数据 |



#### **5、行锁，表锁，意向锁** 

**InnoDB⽀持⾏级锁(row-level locking)和表级锁,默认为⾏级锁**	

​	InnoDB按照不同的分类的锁：

​	共享/排它锁(Shared and Exclusive Locks)：行级别锁，

​	意向锁(Intention Locks)，表级别锁

​	间隙锁(Gap Locks)，锁定一个区间

​	记录锁(Record Locks)，锁定一个行记录

**表级锁：（串行化）**

​		Mysql中锁定 粒度最大的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。

**行级锁：（RR、RC）**

​		Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB支持的行级锁，包括如下几种：

​		**记录锁（Record Lock）:** 对索引项加锁，锁定**符合条件的行**。其他事务不能修改和删除加锁项；

​		**间隙锁（Gap Lock）:** 对索引项之间的“间隙”加锁，锁定**记录的范围**，不包含索引项本身，其他事务不能在锁范围内插入数据。

​		**Next-key Lock：** 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。



InnoDB 支持多粒度锁（multiple granularity locking），它允许行级锁与表级锁共存，而意向锁就是其中的一种表锁。

**共享锁**（ shared lock, S ）锁允许持有锁读取行的事务。加锁时将自己和子节点全加S锁，父节点直到表头全加IS锁

**排他锁**（ exclusive lock， X ）锁允许持有锁修改行的事务。 加锁时将自己和子节点全加X锁，父节点直到表头全加IX锁  

**意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）

**意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

| 互斥性       | 共享锁（S） | 排它锁（X） | 意向共享锁IS | 意向排他锁IX |
| ------------ | ----------- | ----------- | ------------ | ------------ |
| 共享锁（S）  | ✅           | ❌           | ✅            | ❌            |
| 排它锁（X）  | ❌           | ❌           | ❌            | ❌            |
| 意向共享锁IS | ✅           | ❌           | ✅            | ✅            |
| 意向排他锁IX | ❌           | ❌           | ✅            | ✅            |



#### **6、MVCC多版本并发控制** 

​		MVCC是一种多版本并发控制机制，通过事务的可见性看到自己预期的数据，能降低其系统开销.（RC和RR级别工作）

​		InnoDB的MVCC,是通过在每行记录后面保存系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。

​		1.MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）.

​		2.Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.

​		3.简单的select快照度不会加锁，删改及select for update等需要当前读的场景会加锁

​		原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。客观上，mysql使用的是乐观锁的一整实现方式，就是每行都有版本号，保存时根据版本号决定是否成功。Innodb的MVCC使用到的快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。



**版本链**

在InnoDB引擎表中，它的聚簇索引记录中有两个必要的隐藏列：

**trx_id**

这个id用来存储的每次对某条聚簇索引记录进行修改的时候的事务id。

**roll_pointer**

每次对哪条聚簇索引记录有修改的时候，都会把老版本写入undo日志中。这个roll_pointer就是存了一个指针，它指向这条聚簇索引记录的上一个版本的位置，通过它来获得上一个版本的记录信息。(注意插入操作的undo日志没有这个属性，因为它没有老版本)

每次修改都会在版本链中记录。**SELECT可以去版本链中拿记录，这就实现了读-写，写-读的并发执行，**提升了系统的性能。



### 索引

#### **1、Innodb和Myisam引擎** 

**Myisam：**支持表锁，适合读密集的场景，不支持外键，不支持事务，索引与数据在不同的文件

**Innodb：**支持行、表锁，默认为行锁，适合并发场景，支持外键，支持事务，索引与数据同一文件



#### **2、哈希索引**

​		哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能



#### **3、B+树索引** 

**优点：**

​		B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描

​		B+树是B树的升级版，B+树只有叶节点存放数据，其余节点用来索引。索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而**提高范围查找的效率，增加的索引的范围**

​		在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘IO读写过于频繁，进而导致效率低下的情况。所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树与B+树可以有多个子女，从几十到上千，可以降低树的高度。

[^页存储]: 自mysql5.7后，提供了一个设定page大小的参数innodb_page_size，默认值是16K。我们可以通过来改变page的大小来间接改变m树B+树的m的大小。比如我们现在要存20G大小的数据，那么page=16K和page=4K，树的高度是不一样的。换句话说，树的高度是根据你要存下的数据是多少来决定的。

​		**磁盘预读原理**：将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。



#### 4、创建索引

```sql
CREATE  [UNIQUE | FULLTEXT]  INDEX  索引名 ON  表名(字段名) [USING 索引方法]；

说明：
UNIQUE:可选。表示索引为唯一性索引。
FULLTEXT:可选。表示索引为全文索引。
INDEX和KEY:用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。
索引名:可选。给创建的索引取一个新名称。
字段名1:指定索引对应的字段的名称，该字段必须是前面定义好的字段。
注：索引方法默认使用B+TREE。
```



#### **5、聚簇索引和非聚簇索引** 

​	**聚簇索引：**将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据（**主键索引**）

​	**非聚簇索引：**将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置（**辅助索引**）

​	聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。



#### 6、最左前缀问题

​		最左前缀原则主要使用在联合索引中，联合索引的B+Tree是按照第一个关键字进行索引排列的。

​		联合索引的底层是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于构建一棵B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。

​		采用>、<等进行匹配都会导致后面的列无法走索引，因为通过以上方式匹配到的数据是不可知的。

 



### SQL查询

#### **1、SQL语句的执行过程** 

**查询语句：**

```mysql
select * from student  A where A.age='18' and A.name='张三';
```

<img src="http://s0.lgstatic.com/i/image2/M01/8B/0F/CgotOV14ySKAMxohAAH2VHcAzkE612.png" alt="img" style="zoom: 67%;" />

结合上面的说明，我们分析下这个语句的执行流程：

①通过客户端/服务器通信协议与 MySQL 建立连接。并查询是否有权限

②Mysql8.0之前开看是否开启缓存，开启了 Query Cache 且命中完全相同的 SQL 语句，则将查询结果直接返回给客户端；

③由解析器进行语法语义解析，并生成解析树。如查询是select、表名tb_student、条件是id='1'

④查询优化器生成执行计划。根据索引看看是否可以优化

⑤查询执行引擎执行 SQL 语句，根据存储引擎类型，得到查询结果。若开启了 Query Cache，则缓存，否则直接返回。



#### **2、回表查询和覆盖索引** 

**普通索引**（唯一索引+联合索引+全文索引）需要扫描两遍索引树

（1）先通过普通索引定位到主键值id=5；

（2）在通过聚集索引定位到行记录；

这就是所谓的**回表查询**，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。

**覆盖索引**：主键索引==聚簇索引==覆盖索引

​	如果where条件的列和返回的数据在一个索引中，那么不需要回查表，那么就叫覆盖索引。

**实现覆盖索引**：常见的方法是，将被查询的字段，建立到联合索引里去。



#### 3、Explain及优化

参考：https://www.jianshu.com/p/8fab76bbf448

```mysql
mysql> explain select * from staff;
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
|  1 | SIMPLE      | staff | ALL  | NULL          | 索引  | NULL    | NULL |    2 | NULL  |
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
1 row in set
```

**索引优化：**

​	①最左前缀索引：like只用于'string%'，语句中的=和in会动态调整顺序

​	②唯一索引：唯一键区分度在0.1以上

​	③无法使用索引：!=  、is null 、 or、>< 、（**5.7以后根据数量自动判定）in 、not in**

​	④联合索引：避免select * ，查询列使用覆盖索引

```mysql
SELECT uid From user Where gid = 2 order by ctime asc limit 10
ALTER TABLE user add index idx_gid_ctime_uid(gid,ctime,uid) #创建联合覆盖索引，避免回表查询
```



**语句优化：**

​	①char固定长度查询效率高，varchar第一个字节记录数据长度

​	②应该针对Explain中Rows增加索引

​	③group/order by字段均会涉及索引

​	④Limit中分页查询会随着start值增大而变缓慢，通过子查询+表连接解决

```sql
select * from mytbl order by id limit 100000,10  改进后的SQL语句如下：
select * from mytbl where id >= ( select id from mytbl order by id limit 100000,1 ) limit 10
select * from mytbl inner ori join (select id from mytbl order by id limit 100000,10) as tmp on tmp.id=ori.id;
```

​	⑤count会进行全表扫描，如果估算可以使用explain

​	⑥delete删除表时会增加大量undo和redo日志， 确定删除可使用trancate

**表结构优化：**

​	①单库不超过200张表

​	②单表不超过500w数据

​	③单表不超过40列

​	④单表索引不超过5个

**数据库范式** ：

​	①第一范式（1NF）列不可分割

​	②第二范式（2NF）属性完全依赖于主键 [ 消除部分子函数依赖 ]

​	③第三范式（3NF）属性不依赖于其它非主属性 [ 消除传递依赖 ]

**配置优化：**

​	配置连接数、禁用Swap、增加内存、升级SSD硬盘



#### 4、JOIN查询 

<img src="https://image-static.segmentfault.com/276/780/2767807589-5c122586a23c4_articlex" style="align:left;zoom: 60%;" />

**left join(左联接)** 返回包括左表中的所有记录和右表中关联字段相等的记录 

**right join(右联接)** 返回包括右表中的所有记录和左表中关联字段相等的记录

**inner join(等值连接)** 只返回两个表中关联字段相等的行



### **集群**

#### 1、主从复制过程 

**MySQl主从复制：**

- **原理**：将主服务器的binlog日志复制到从服务器上执行一遍，达到主从数据的一致状态。
- **过程**：从库开启一个I/O线程，向主库请求Binlog日志。主节点开启一个binlog dump线程，检查自己的二进制日志，并发送给从节点；从库将接收到的数据保存到中继日志（Relay log）中，另外开启一个SQL线程，把Relay中的操作在自身机器上执行一遍
- **优点**：
  - 作为备用数据库，并且不影响业务
  - 可做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证数据的一致性

**binlog记录格式：**statement、row、mixed

​		基于语句statement的复制、基于行row的复制、基于语句和行（mix）的复制。其中基于row的复制方式更能保证主从库数据的一致性，但日志量较大，在设置时考虑磁盘的空间问题



#### 2、数据一致性问题

"主从复制有延时"，这个延时期间读取从库，可能读到不一致的数据。

**缓存记录写key法：**

​		在cache里记录哪些记录发生过的写请求，来路由读主库还是读从库

**异步复制：**

​		在异步复制中，主库执行完操作后，写入binlog日志后，就返回客户端，这一动作就结束了，并不会验证从库有没有收到，完不完整，所以这样可能**会造成数据的不一致**。

**半同步复制：**

​		当主库每提交一个事务后，不会立即返回，而是等待其中一个从库接收到Binlog并成功写入Relay-log中才返回客户端，通过一份在主库的Binlog，另一份在其中一个从库的Relay-log，可以保证了数据的安全性和一致性。

**全同步复制：**

​		指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的**性能必然会收到严重的影响**。



#### 3、集群架构

 **Keepalived + VIP + MySQL 主从/双主**

​		当写节点 Master db1 出现故障时，由 MMM Monitor 或 Keepalived 触发切换脚本，将 VIP 漂移到可用的 Master db2 上。当出现网络抖动或网络分区时，MMM Monitor 会误判，严重时来回切换写 VIP 导致集群双写，当数据复制延迟时，应用程序会出现数据错乱或数据冲突的故障。有效避免单点失效的架构就是采用共享存储，单点故障切换可以通过分布式哨兵系统监控。

<img src="http://s0.lgstatic.com/i/image2/M01/89/48/CgoB5l12KuGALf-cAAGuHVmMkHs743.png" alt="img" style="zoom: 67%;" />

 **架构选型：**MMM 集群  -> MHA集群 -> MHA+Arksentinel。

<img src="http://s0.lgstatic.com/i/image2/M01/89/68/CgotOV12KuKAe_HOAABl-wRATa0772.png" alt="img"  />



#### 4、故障转移和恢复

**转移方式及恢复方法**

    1. 虚拟IP或DNS服务 （Keepalived +VIP/DNS  和 MMM 架构）

​	问题：在虚拟 IP 运维过程中，刷新ARP过程中有时会出现一个 VIP 绑定在多台服务器同时提供连接的问题。这也是为什么要避免使用 Keepalived+VIP 和 MMM 架构的原因之一，因为它处理不了这类问题而导致集群多点写入。

    2. 提升备库为主库（MHA、QMHA）

​	尝试将原 Master 设置 read_only 为 on，避免集群多点写入。借助 binlog server 保留 Master 的 Binlog；当出现数据延迟时，再提升 Slave 为新 Master 之前需要进行数据补齐，否则会丢失数据。



### 面试题

#### 分库分表

##### 如何进行分库分表

> **分表**用户id进行分表，每个表控制在300万数据。
>
> **分库**根据业务场景和地域分库，每个库并发不超过2000

**Sharding-jdbc** 这种 client 层方案的**优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高**，但是各个系统都需要**耦合** Sharding-jdbc 的依赖，升级比较麻烦

**Mycat** 这种 proxy 层方案的**缺点在于需要部署**，自己运维一套中间件，运维成本高，但是**好处在于对于各个项目是透明的**，如果遇到升级之类的都是自己中间件那里搞就行了

**水平拆分**：一个表放到多个库，分担高并发，加快查询速度

- **id**保证业务在关联多张表时可以在同一库上操作
- **range**方便扩容和数据统计
- **hash**可以使得数据更加平均

**垂直拆分**：一个表拆成多个表，可以将一些冷数据拆分到冗余库中



> 不是写瓶颈优先进行分表

- 分库数据间的数据无法再通过数据库直接查询了。会产生深分页的问题

- 分库越多，出现问题的可能性越大，维护成本也变得更高。

- 分库后无法保障跨库间事务，只能借助其他中间件实现最终一致性。



分库首先需考虑满足业务最核心的场景：

1、订单数据按**用户**分库，可以**提升用户的全流程体验**

2、超级客户导致**数据倾斜**可以使用最细粒度唯一标识进行hash拆分

3、按照最细粒度如订单号拆分以后，数据库就无法进行单库排重了



三个问题：

- 富查询：采用分库分表之后，如何满足跨越分库的查询？**使用ES**的宽表

  借助**分库网关+分库业务**虽然能够实现**多维度查询的能力**，但整体上性能不佳且对正常的写入请求有一定的影响。业界应对**多维度实时查询**的最常见方式便是借助 **ElasticSearch**

- 数据倾斜：数据分库基础上再进行分表

- 分布式事务：跨多库的修改及多个微服务间的写操作导致的分布式事务问题？

- 深分页问题：按游标查询，或者叫每次查询都带上上一次查询经过排序后的最大 ID





#### 如何将老数据进行迁移

**双写不中断迁移**

- 线上系统里所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**
- 系统部署以后，还需要跑程序读老库数据写新库，写的时候需要判断updateTime
- 循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码就行了



#### 系统性能的评估及扩容

和家亲目前有1亿用户：场景 10万写并发，100万读并发，60亿数据量

设计时考虑极限情况，32库*32表~64个表，一共1000 ~ 2000张表

- 支持**3万**的写并发，配合MQ实现每秒10万的写入速度
- 读写分离**6万**读并发，配合分布式缓存每秒100读并发
- 2000张表每张300万，可以最多写入60亿的数据

- 32张用户表，支撑亿级用户，后续最多也就扩容一次

**动态扩容的步骤**

1. 推荐是 32 库 * 32 表，对于我们公司来说，可能几年都够了。
2. 配置路由的规则，uid % 32 = 库，uid / 32 % 32 = 表
3. 扩容的时候，申请增加更多的数据库服务器，呈倍数扩容
4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去
5. 修改一下配置，重新发布系统，上线，原先的路由规则变都不用变
6. 直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。



#### 如何生成自增的id主键

- 使用redis可以
- 并发不高可以单独起一个**服务**，生成自增id
- 设置数据库**step**自增步长可以支撑水平伸缩
- UUID适合文件名、编号，但是**不适合做主键**
- **snowflake雪花算法**，综合了**41时间**（ms）、**10机器**、**12序列号**（ms内自增）

其中机器预留的10bit可以根据自己的业务场景配置





### 线上故障及优化

#### 更新失败 | 主从同步延时

以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。

是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。

我们通过 MySQL 命令：

```
show slave status
```

查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。

一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，拆分为多个主库，每个主库的写并发就减少了几倍，主从延迟可以忽略不计。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
- 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**或者**延迟查询**。主从复制延迟一般不会超过50ms

#### **应用崩溃 | 分库分表优化**

​	我们有一个线上通行记录的表，由于数据量过大，进行了分库分表，当时分库分表初期经常产生一些问题。典型的就是通行记录查询中使用了深分页，通过一些工具如MAT、Jstack追踪到是由于sharding-jdbc内部引用造成的。

​	通行记录数据被存放在两个库中。如果没有提供**切分键**，查询语句就会被分发到所有的数据库中，比如查询语句是 limit 10、offset 1000，最终结果只需要返回 10 条记录，但是数据库中间件要完成这种计算，则需要 (1000+10)*2=2020 条记录来完成这个计算过程。如果 offset 的值过大，使用的内存就会暴涨。虽然 sharding-jdbc 使用归并算法进行了一些优化，但在实际场景中，深分页仍然引起了**内存和性能**问题。

​	这种在中间节点进行**归并聚合**的操作，在分布式框架中非常常见。比如在 ElasticSearch 中，就存在相似的数据获取逻辑，**不加限制的深分页**，同样会造成 ES 的内存问题。

**业界解决方案：**

**方法一：全局视野法**

（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y

（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录

这种方法随着翻页的进行，性能越来越低。

**方法二：业务折衷法-禁止跳页查询**

（1）用正常的方法取得第一页数据，并得到第一页记录的time_max

（2）每次翻页，将order by time offset X limit Y，改写成order by time where time>$time_max limit Y

以保证每次只返回一页数据，性能为常量。

**方法三：业务折衷法-允许模糊数据**

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y/N

**方法四：二次查询法**

（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y

（2）找到最小值time_min

（3）between二次查询，order by time between $time_min and $time_i_max

（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset

（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y





#### 查询异常 | SQL 调优

分库分表前，有一段用用户名来查询某个用户的 SQL 语句：

```python
select * from user where name = "xxx" and community="other";
```

为了达到动态拼接的效果，这句 SQL 语句被一位同事进行了如下修改。他的本意是，当 name 或者 community 传入为空的时候，动态去掉这些查询条件。这种写法，在 MyBaits 的配置文件中，也非常常见。大多数情况下，这种写法是没有问题的，因为结果集合是可以控制的。但随着系统的运行，用户表的记录越来越多，当传入的 name 和 community 全部为空时，悲剧的事情发生了:

```
select * from user where 1=1
```

数据库中的所有记录，都会被查询出来，载入到 JVM 的内存中。由于数据库记录实在太多，直接把内存给撑爆了。由于这种原因引起的内存溢出，发生的频率非常高，比如导入Excel文件时。

通常的解决方式是**强行加入分页功能**，或者对一些**必填的参数进行校验**

![img](https://tva1.sinaimg.cn/large/008eGmZEly1gobovqjvijj30zd0lctbp.jpg)

**Controller 层**

现在很多项目都采用前后端分离架构，所以 Controller 层的方法，一般使用 @ResponseBody 注解，把查询的结果，解析成 JSON 数据返回。这在数据集非常大的情况下，会占用很多内存资源。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用 20M 或者更多的内存

因此，保持结果集的精简，是非常有必要的，这也是 DTO（Data Transfer Object）存在的必要。互联网环境不怕小结果集的高并发请求，却非常恐惧大结果集的耗时请求，这是其中一方面的原因。

**Service 层**

Service 层用于处理具体的业务，更加贴合业务的功能需求。一个 Service，可能会被多个 Controller 层所使用，也可能会使用多个 dao 结构的查询结果进行计算、拼装。

```java
int getUserSize() {
        List<User> users = dao.getAllUser();
        return null == users ? 0 : users.size();
}
```

代码review中发现了定时炸弹，这种在数据量达到一定程度后，才会暴露问题。

**ORM 层**

比如使用Mybatis时，有一个批量导入服务，在 MyBatis 执行批量插入的时候，竟然产生了内存溢出，按道理这种插入操作是不会引起额外内存占用的，最后通过源码追踪到了问题。

这是因为 MyBatis 循环处理 batch 的时候，操作对象是数组，而我们在接口定义的时候，使用的是 List；当传入一个非常大的 List 时，它需要调用 List 的 toArray 方法将列表转换成数组（浅拷贝）；在最后的拼装阶段，又使用了 StringBuilder 来拼接最终的 SQL，所以实际使用的内存要比 List 多很多。

事实证明，不论是插入操作还是查询动作，只要涉及的数据集非常大，就容易出现问题。由于项目中众多框架的引入，想要分析这些具体的内存占用，就变得非常困难。所以保持小批量操作和结果集的干净，是一个非常好的习惯。

















# **五、Redis篇** 

### WhyRedis

​		速度快，完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件；

|        | GuavaCache  | Tair       | EVCache      | Aerospike         |
| ------ | ----------- | ---------- | ------------ | ----------------- |
| 类别   | 本地JVM缓存 | 分布式缓存 | 分布式缓存   | 分布式nosql数据库 |
| 应用   | 本地缓存    | 淘宝       | Netflix、AWS | 广告              |
| 性能   | 非常高      | 较高       | 很高         | 较高              |
| 持久化 | 无          | 有         | 有           | 有                |
| 集群   | 无          | 灵活配置   | 有           | 自动扩容          |

​		与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。

#### 1、简单高效

​		1）完全基于内存，绝大部分请求是纯粹的内存操作。数据存在内存中，类似于 HashMap，查找和操作的时间复杂度都是O(1)；

​		2）数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；

​		3）采用单线程，避免了多线程不必要的上下文切换和竞争条件，不存在加锁释放锁操作，减少了因为锁竞争导致的性能消耗；（6.0以后多线程）

​		4）使用EPOLL多路 I/O 复用模型，非阻塞 IO；

​		5）使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；



#### 2、Memcache

| redis                                 | Memcached                  |
| ------------------------------------- | -------------------------- |
| 内存高速数据库                        | 高性能分布式内存缓存数据库 |
| 支持hash、list、set、zset、string结构 | 只支持key-value结构        |
| 将大部分数据放到内存                  | 全部数据放到内存中         |
| 支持持久化、主从复制备份              | 不支持数据持久化及数据备份 |
| 数据丢失可通过AOF恢复                 | 挂掉后，数据不可恢复       |
| 单线程（2~4万TPS）                    | 多线程（20-40万TPS）       |

**使用场景：**

​	1、如果有持久方面的需求或对数据类型和处理有要求的应该选择redis。 
​	2、如果简单的key/value 存储应该选择memcached。	



#### 3、Tair

​	Tair(Taobao Pair)是淘宝开发的分布式Key-Value存储引擎，既可以做缓存也可以做数据源（三种引擎切换）

- MDB（Memcache）属于内存型产品,支持kv和类hashMap结构,性能最优
- RDB（Redis）支持List.Set.Zset等复杂的数据结构,性能次之,可提供缓存和持久化存储两种模式
- LDB（levelDB）属于持久化产品,支持kv和类hashmap结构,性能较前两者稍低,但持久化可靠性最高

**分布式缓存**

大访问少量临时数据的存储（kb左右）

用于缓存，降低对后端数据库的访问压力

session场景

高速访问某些数据结构的应用和计算（rdb）

**数据源存储**

快速读取数据（fdb）

持续大数据量的存入读取（ldb），交易快照

高频度的更新读取（ldb），库存

**痛点**：redis集群中，想借用缓存资源必须得指明redis服务器地址去要。这就增加了程序的维护复杂度。因为redis服务器很可能是需要频繁变动的。所以人家淘宝就想啊，为什么不能像操作分布式数据库或者hadoop那样。增加一个中央节点，让他去代理所有事情。在tair中程序只要跟tair中心节点交互就OK了。同时tair里还有配置服务器概念。又免去了像操作hadoop那样，还得每台hadoop一套一模一样配置文件。改配置文件得整个集群都跟着改。





#### 4、Guava

​		分布式缓存一致性更好一点，用于集群环境下多节点使用同一份缓存的情况；有网络IO，吞吐率与缓存的数据大小有较大关系；

​		本地缓存非常高效，本地缓存会占用堆内存，影响垃圾回收、影响系统性能。

**本地缓存设计：**

​		以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况，每个实例都需要各自保存一份缓存，缓存不具有一致性。

**解决缓存过期：**

​	1、将缓存过期时间调为永久

​	2、将缓存失效时间分散开，不要将缓存时间长度都设置成一样；比如我们可以在原有的失效时间基础上增加一个随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

**解决内存溢出：**

​	**第一步**，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)

　**第二步**，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。

　**第三步**，对代码进行走查和分析，找出可能发生内存溢出的位置。



**Google Guava Cache** 

**自己设计本地缓存痛点：**

- 不能按照一定的规则淘汰数据，如 LRU，LFU，FIFO 等。
- 清除数据时的回调通知
- 并发处理能力差，针对并发可以使用CurrentHashMap，但缓存的其他功能需要自行实现
- 缓存过期处理，缓存数据加载刷新等都需要手工实现

**Guava Cache 的场景：**

- 对性能有非常高的要求
- 不经常变化，占用内存不大
- 有访问整个集合的需求
- 数据允许不实时一致

**Guava Cache 的优势**：

- 缓存过期和淘汰机制

在GuavaCache中可以设置Key的过期时间，包括访问过期和创建过期。GuavaCache在缓存容量达到指定大小时，采用LRU的方式，将不常使用的键值从Cache中删除

- 并发处理能力

GuavaCache类似CurrentHashMap，是线程安全的。提供了设置并发级别的api，使得缓存支持并发的写入和读取，采用分离锁机制，分离锁能够减小锁力度，提升并发能力，分离锁是分拆锁定，把一个集合看分成若干partition, 每个partiton一把锁。更新锁定

- 防止缓存击穿

一般情况下，在缓存中查询某个key，如果不存在，则查源数据，并回填缓存。（Cache Aside Pattern）在高并发下会出现，多次查源并重复回填缓存，可能会造成源的宕机（DB），性能下降 GuavaCache可以在CacheLoader的load方法中加以控制，对同一个key，只让一个请求去读源并回填缓存，其他请求阻塞等待。（相当于集成数据源，方便用户使用）

- 监控缓存加载/命中情况

统计

**问题：**

​	OOM->设置过期时间、使用弱引用、配置过期策略



#### 5、EVCache

EVCache是一个Netflflix（网飞）公司开源、快速的分布式缓存，是基于Memcached的内存存储实现的，用以构建超大容量、高性能、低延时、跨区域的全球可用的缓存数据层。

E：Ephemeral：数据存储是短暂的，有自身的存活时间

V：Volatile：数据可以在任何时候消失

EVCache典型地适合对强一致性没有必须要求的场合

典型用例：Netflflix向用户推荐用户感兴趣的电影

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapdnh0yaj30ku0aigmc.jpg" alt="image-20210103185340548" style="zoom:50%;" />

**EVCache集群**在峰值每秒可以处理**200kb**的请求，

Netflflix生产系统中部署的EVCache经常要处理超过**每秒3000万个**请求，存储数十亿个对象，

跨数千台memcached服务器。整个EVCache集群**每天处理近2万亿个**请求。

EVCache集群响应平均延时大约是1-5毫秒，最多不会超过20毫秒。

EVCache集群的缓存命中率在99%左右。

**典型部署**

EVCache 是线性扩展的，可以在一分钟之内完成扩容，在几分钟之内完成负载均衡和缓存预热。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmapg99q8lj30ix0f3jrw.jpg" alt="image-20210103185611516" style="zoom:50%;" />

1、集群启动时，EVCache向服务注册中心（Zookeeper、Eureka）注册各个实例

2、在web应用启动时，查询命名服务中的EVCache服务器列表，并建立连接。

3、客户端通过key使用一致性hash算法，将数据分片到集群上。



#### 6、ETCD

​	**和Zookeeper一样，CP模型追求数据一致性，**越来越多的系统开始用它保存关键数据。比如，秒杀系统经常用它**保存各节点信**息，以便控制消费 MQ 的服务数量。还有些业务系统的**配置数据**，也会通过 etcd 实时同步给业务系统的各节点，比如，秒杀管理后台会使用 etcd 将秒杀活动的**配置数据实时同步给秒杀 API 服务各节点**。

![image-20210418174251742](/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418174251742.png)



### Redis底层

#### 1、redis数据类型

| 类型   | 底层      | 应用场景                                       | 编码类型              |
| ------ | --------- | ---------------------------------------------- | --------------------- |
| String | SDS数组   | 帖子、评论、热点数据、输入缓冲                 | RAW << EMBSTR << INT  |
| List   | QuickList | 评论列表、商品列表、发布与订阅、慢查询、监视器 | LINKEDLIST << ZIPLIST |
| Set    | intSet    | 适合交集、并集、查集操作，例如朋友关系         | HT << INSET           |
| Zset   | 跳跃表    | 去重后排序，适合排名场景                       | SKIPLIST << ZIPLIST   |
| Hash   | 哈希      | 结构化数据，比如存储对象                       | HT << ZIPLIST         |
| Stream | 紧凑列表  | 消息队列                                       |                       |



#### **2、相关API**

> http://redisdoc.com

|        |       |        |           |       |         |        |          |       |           |
| ------ | ----- | ------ | --------- | ----- | ------- | ------ | -------- | ----- | --------- |
| String | SET   | SETNX  | SETEX     | GET   | GETSET  | INCR   | DECR     | MSET  | MGET      |
| Hash   | HSET  | HSETNX | HGET      | HDEL  | HLEN    | HMSET  | HMGET    | HKEYS | HGETALL   |
| LIST   | LPUSH | LPOP   | RPUSH     | RPOP  | LINDEX  | LREM   | LRANGE   | LLEN  | RPOPLPUSH |
| ZSET   | ZADD  | ZREM   | ZSCORE    | ZCARD | ZRANGE  | ZRANK  | ZREVRANK |       | ZREVRANGE |
| SET    | SADD  | SREM   | SISMEMBER | SCARD | SINTER  | SUNION | SDIFF    | SPOP  | SMEMBERS  |
| 事务   | MULTI | EXEC   | DISCARD   | WATCH | UNWATCH |        |          |       |           |



#### 3、redis底层结构

**SDS数组结构**，用于存储字符串和整型数据及输入缓冲。

```java
struct sdshdr{ 
  int len;//记录buf数组中已使用字节的数量 
  int free; //记录 buf 数组中未使用字节的数量 
  char buf[];//字符数组，用于保存字符串
}
```

**跳跃表**：将有序链表中的部分节点分层，每一层都是一个有序链表。

​	1、可以快速查找到需要的节点 O(logn) ，额外存储了一倍的空间

​	2、可以在O(1)的时间复杂度下，快速获得跳跃表的头节点、尾结点、长度和高度。			

**字典dict:** 又称散列表(hash)，是用来存储键值对的一种数据结构。 

​	Redis整个数据库是用字典来存储的(K-V结构) —Hash+数组+链表

​	Redis字典实现包括:**字典(dict)、Hash表(dictht)、Hash表节点(dictEntry)**。

​	字典达到存储上限(阈值 0.75)，需要rehash(扩容)

​	1、初次申请默认容量为4个dictEntry，非初次申请为当前hash表容量的一倍。

​	2、rehashidx=0表示要进行rehash操作。

​	3、新增加的数据在新的hash表h[1] 、修改、删除、查询在老hash表h[0]

​	4、将老的hash表h[0]的数据重新计算索引值后全部迁移到新的hash表h[1]中，这个过程称为 rehash。

​	**渐进式rehash**

 	由于当数据量巨大时rehash的过程是非常缓慢的，所以需要进行优化。 可根据服务器空闲程度批量rehash部分节点

**压缩列表zipList**

​	压缩列表(ziplist)是由一系列特殊编码的连续内存块组成的顺序型数据结构，节省内容

​	**sorted-set和hash元素个数少**且是小整数或短字符串(直接使用) 

​	list用快速链表(quicklist)数据结构存储，而**快速链表是双向列表与压缩列表**的组合。(间接使用)

**整数集合intSet**

​	整数集合(intset)是一个有序的(整数升序)、存储整数的连续存储结构。 

​	当Redis集合类型的元素都是整数并且都处在64位有符号整数范围内(2^64)，使用该结构体存储。

**快速列表quickList**

​	快速列表(quicklist)是Redis底层重要的数据结构。是Redis3.2列表的底层实现。

​	(在Redis3.2之前，Redis采 用双向链表(adlist)和压缩列表(ziplist)实现。)

**Redis Stream**的底层主要使用了listpack(紧凑列表)和Rax树(基数树)。

​	**listpack**表示一个字符串列表的序列化，listpack可用于存储字符串或整数。用于存储stream的消息内 容。

​	**Rax树**是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操 作。



#### 4、Zset底层实现

​		跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为O(logN)。简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度

​		Zset**数据量少的时候使用压缩链表ziplist**实现，有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。 **数据量大的时候使用跳跃列表skiplist和哈希表hash_map**结合实现，查找删除插入的时间复杂度都是O(longN)

​		Redis使用跳表而不使用红黑树，是因为跳表的索引结构序列化和反序列化更加快速，方便持久化。

**搜索**

​		跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 *O(logN)，最坏 O(N) 。*

**插入**

  选用链表作为底层结构支持，为了高效地动态增删。因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。

**删除**

  如果该节点还在索引中，删除时不仅要删除单链表中的节点，还要删除索引中的节点；单链表在知道删除的节点是谁时，时间复杂度为O(1)，但针对单链表来说，删除时都需要拿到前驱节点O(logN)才可改变引用关系从而删除目标节点。



### **Redis可用性**

#### 1、redis持久化 

持久化就是把内存中的数据持久化到本地磁盘，防止服务器宕机了内存数据丢失

Redis 提供两种持久化机制 **RDB（默认）** 和 **AOF 机制**，Redis4.0以后采用混合持久化，用 AOF 来**保证数据不丢失**，作为数据恢复的第一选择; 用 RDB 来做不同程度的**冷备**

**RDB：**是Redis DataBase缩写快照

​		RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。

​	**优点：**

​	1）只有一个文件 dump.rdb，方便持久化；

​	2）容灾性好，一个文件可以保存到安全的磁盘。

​	3）性能最大化，fork 子进程来进行持久化写操作，让主进程继续处理命令，只存在毫秒级不响应请求。

​	4）相对于数据集大时，比 AOF 的启动效率更高。

​	**缺点：**

​	数据安全性低，RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。

**AOF：持久化**

​		AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。

​	**优点：**

​	1）数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。

​	2）通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。

**缺点：**

​	1）AOF 文件比 RDB 文件大，且恢复速度慢。

​	2）数据集大的时候，比 rdb 启动效率低。



#### 2、redis事务

​		事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。

**Redis事务的概念**

​		Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

Redis的事务总是具有ACID中的**一致性和隔离性**，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的

**事务命令：**

**MULTI：**用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。

**EXEC：**执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。

**WATCH ：**是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。（**秒杀场景**）

**DISCARD：**调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。

**UNWATCH**：命令可以取消watch对所有key的监控。



#### 3、redis失效策略 

**内存淘汰策略**

1）全局的键空间选择性移除

​	**noeviction**：当内存不足以容纳新写入数据时，新写入操作会报错。（字典库常用）

​	**allkeys-lru**：在键空间中，移除最近最少使用的key。（缓存常用）

​	**allkeys-random**：在键空间中，随机移除某个key。

2）设置过期时间的键空间选择性移除

​	**volatile-lru**：在设置了过期时间的键空间中，移除最近最少使用的key。

​	**volatile-random**：在设置了过期时间的键空间中，随机移除某个key。

​	**volatile-ttl**：在设置了过期时间的键空间中，有更早过期时间的key优先移除。

**缓存失效策略**

​	**定时清除：**针对每个设置过期时间的key都创建指定定时器

​	**惰性清除：**访问时判断，对内存不友好

​	**定时扫描清除：**定时100ms随机20个检查过期的字典，若存在25%以上则继续循环删除。

#### 4、redis读写模式

​	**CacheAside旁路缓存**

写请求更新数据库后删除缓存数据。读请求不命中查询数据库，查询完成写入缓存

<img src="https://img-blog.csdnimg.cn/20200806194316539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 15%;" />

<img src="https://img-blog.csdnimg.cn/20200806194300826.png" style="zoom: 15%;" />

​	业务端处理所有数据访问细节，同时利用 **Lazy 计算**的思想，更新 DB 后，直接删除 cache 并通过 DB 更新，确保数据以 DB 结果为准，则可以大幅降低 cache 和 DB 中数据不一致的概率

​	如果没有专门的存储服务，同时是对**数据一致性要求比较高的业务，或者是缓存数据更新比较复杂的业务**，适合使用 Cache Aside 模式。如微博发展初期，不少业务采用这种模式

```java
// 延迟双删，用以保证最终一致性,防止小概率旧数据读请求在第一次删除后更新数据库
public void write(String key,Object data){
	redis.delKey(key);
	db.updateData(data);
	Thread.sleep(1000);
	redis.delKey(key);
}
```

高并发下保证绝对的一致，先删缓存再更新数据，需要用到**内存队列做异步串行化**。非高并发场景，先更新数据再删除缓存，**延迟双删**策略基本满足了

- 先更新db后删除redis：删除redis失败则出现问题
- 先删redis后更新db：删除redis瞬间，旧数据被回填redis
- 先删redis后更新db休眠后删redis：同第二点，休眠后删除redis 可能宕机
- java内部jvm队列：不适用分布式场景且降低并发



​	**Read/Write Though**（读写穿透）

​		**先查询**缓存中数据是否存在,如果存在则直接返回,如果**不存在**,则由**缓存组件负责从数据库中同步加载数据.**

​	<img src="https://img-blog.csdnimg.cn/20200806194334623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

​	先查询要**写入的数据在缓存中**是否已经存在,如果已经存在,则**更新缓存中的数据**，并且由**缓存组件同步更新**到数据库中。

​	<img src="https://img-blog.csdnimg.cn/20200806194346642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2x6eF92aWN0b3J5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%" />

​	用户**读操作**较多.相较于Cache aside而言更适合缓存一致的场景。使用简单屏蔽了**底层数据库的操作**,只是操作缓存.

**场景：**

微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。

​	

**Write Behind Caching（异步缓存写入）**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gorlsg74i6j31950e3dhs.jpg" alt="img" style="zoom:35%;" />

比如对一些计数业务，一条 **Feed 被点赞** 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。



#### 5、多级缓存

**浏览器本地内存缓存：**专题活动，一旦上线，在活动期间是不会随意变更的。

**浏览器本地磁盘缓存：**Logo缓存，大图片懒加载

**服务端本地内存缓存：**由于没有持久化，重启时必定会被穿透

**服务端网络内存缓存**：Redis等，针对穿透的情况下可以继续分层，必须保证数据库不被压垮

**为什么不是使用服务器本地磁盘做缓存？**

​	当系统处理大量磁盘 IO 操作的时候，由于 CPU 和内存的速度远高于磁盘，可能导致 CPU 耗费太多时间等待磁盘返回处理的结果。对于这部分 CPU 在 IO 上的开销，我们称为 **iowait**



### Redis七大经典问题

#### 1、缓存雪崩

​		指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

​	**解决方案：**

- **Redis 高可用**，主从+哨兵，Redis cluster，避免全盘崩溃
- 本地 ehcache 缓存 + hystrix **限流&降级**，避免 MySQL 被打死
- 缓存数据的**过期时间设置随机**，防止同一时间大量数据过期现象发生。

- **逻辑上永不过期**给每一个缓存数据增加相应的**缓存标记**，缓存标记失效则更新数据缓存
- **多级缓存**，失效时通过二级更新一级，由第三方插件更新二级缓存。



#### **2、缓存穿透**

​		https://blog.csdn.net/lin777lin/article/details/105666839

​		缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

​	**解决方案：**

​	1）**接口层增加校验**，如用户鉴权校验，id做基础校验，id<=0的直接拦截；

​	2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将**key-value对写为key-null**，缓存有效时间可以设置短点，如30秒。这样可以防止攻击用户反复用同一个id暴力攻击；

​	3）采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。（宁可错杀一千不可放过一人）



#### **3、缓存击穿**

​		这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

​	**解决方案：**

​	1）设置**热点数据永远不过期**，异步线程处理。

​	2）加**写回操作加互斥锁**，查询失败默认值快速返回。

​	3）缓存预热

​		系统上线后，将相关**可预期（例如排行榜）**热点数据直接加载到缓存。

​		写一个缓存刷新页面，手动操作热点数据**（例如广告推广）**上下线。



#### 4、数据不一致

​	在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。

- Cache 更新失败后，可以进行重试，则将重试失败的 key 写入mq，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性

- 缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。

- 不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。



#### 5、数据并发竞争

​	数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成并发竞争读取的问题。

- ​	加**写回操作加互斥锁**，查询失败默认值快速返回。
- ​	对缓存数据保持多个备份，减少并发竞争的概率

​	

#### 6、热点key问题

​	明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618 等线上促销活动，都很容易出现 Hot key 的情况。

如何提前发现HotKey？

- 对于重要节假日、线上促销活动这些提前已知的事情，可以提前评估出可能的热 key 来。
- 而对于突发事件，无法提前评估，可以**通过 Spark，对应流任务进行实时分析**，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。

**解决方案：**

- 这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载

- 缓存集群可以单节点进行主从复制和垂直扩容

- 利用应用内的前置缓存，但是需注意需要设置上限

- 延迟不敏感，定时刷新，实时感知用主动刷新

- 和缓存穿透一样，限制逃逸流量，单请求进行数据回源并刷新前置

- 无论如何设计，最后都要写一个兜底逻辑，千万级流量说来就来

  

#### 7、BigKey问题

​	比如互联网系统中需要保存用户最新 1万 个粉丝的业务，比如一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等。微博的 feed 内容缓存也很容易出现，一般用户微博在 140 字以内，但很多用户也会发表 1千 字甚至更长的微博内容，这些长微博也就成了大 key

- 首先Redis底层数据结构里，根据Value的不同，会进行数据结构的重新选择
- 可以扩展新的数据结构，进行序列化构建，然后通过 restore 一次性写入
- 将大 key 分拆为多个 key，设置较长的过期时间



### Redis分区容错

#### **1、redis数据分区** 

**Hash：（不稳定）**

​		客户端分片：哈希+取余

​		节点伸缩：数据节点关系变化，导致数据迁移

​		迁移数量和添加节点数量有关：建议翻倍扩容

​		一个简单直观的想法是直接用Hash来计算，以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起。

**一致性Hash：（不均衡）**

​		客户端分片：哈希+顺时针（优化取余）

​		节点伸缩：只影响邻近节点，但是还是有数据迁移

​		翻倍伸缩：保证最小迁移数据和负载均衡

​		一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。但这又带来均匀性的问题，即使可以将存储节点等距排列，也会在**存储节点个数变化时带来数据的不均匀**。

**Codis的Hash槽**

​		Codis 将所有的 key 默认划分为 1024 个槽位(slot)，它首先对客户端传过来的 key 进行 crc32 运算计算 哈希值，再将 hash 后的整数值对 1024 这个整数进行取模得到一个余数，这个余数就是对应 key 的槽位。

**RedisCluster**

​		Redis-cluster把所有的物理节点映射到[0-16383]个**slot**上,对key采用crc16算法得到hash值后对16384取模，基本上采用平均分配和连续分配的方式。



#### **2、主从模式=简单**

​	主从模式最大的优点是**部署简单**，最少**两个节点便可以构成主从模式**，并且可以通过**读写分离避免读和写同时不可用**。不过，一旦 Master 节点出现故障，主从节点就**无法自动切换**，直接导致 SLA 下降。所以，主从模式一般**适合业务发展初期，并发量低，运维成本低**的情况

<img src="https://s0.lgstatic.com/i/image/M00/80/25/Ciqc1F_QgPOAaL8TAAC5EiNlvo4795.png" alt="Drawing 1.png" style="zoom:50%;" />



**主从复制原理：**

​	①通过从服务器发送到PSYNC命令给主服务器

​	②如果是首次连接，触发一次**全量复制**。此时主节点会启动一个后台线程，生成 RDB 快照文件

​	③主节点会将这个 RDB 发送给从节点，slave 会先写入本地磁盘，再从本地磁盘加载到内存中

​	④master会将此过程中的写命令写入缓存，从节点**实时同步**这些数据

​	⑤如果网络断开了连接，自动重连后主节点通过命令传播**增量复制**给从节点部分缺少的数据

**缺点**

​	所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决，redis4.0中引入psync2 解决了slave重启后仍然可以增量同步。



#### 3、**哨兵模式**=读多

​	由一个或多个sentinel实例组成sentinel集群可以监视一个或多个主服务器和多个从服务器。**哨兵模式适合读请求远多于写请求的业务场景，比如在秒杀系统**中用来缓存活动信息。 如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gluq6vlvglj30nw0e076f.jpg" alt="image-20201220231241725" style="zoom:50%;" />

当主服务器进入下线状态时，sentinel可以将该主服务器下的某一从服务器升级为主服务器继续提供服务，从而保证redis的高可用性。

**检测主观下线状态**

​	Sentinel每秒一次向所有与它建立了命令连接的实例(主服务器、从服务器和其他Sentinel)发送PING命 令

​	实例在down-after-milliseconds毫秒内返回无效回复Sentinel就会认为该实例主观下线(**SDown**)

**检查客观下线状态**

​	当一个Sentinel将一个主服务器判断为主观下线后 ，Sentinel会向监控这个主服务器的所有其他Sentinel发送查询主机状态的命令

​	如果达到Sentinel配置中的quorum数量的Sentinel实例都判断主服务器为主观下线，则该主服务器就会被判定为客观下线(**ODown**)。

**选举Leader Sentinel** 

​	当一个主服务器被判定为客观下线后，监视这个主服务器的所有Sentinel会通过选举算法(raft)，选出一个Leader Sentinel去执行**failover(故障转移)**操作。

​	**Raft算法**

​	Raft协议是用来解决分布式系统一致性问题的协议。 Raft协议描述的节点共有三种状态:Leader, Follower, Candidate。 Raft协议将时间切分为一个个的Term(任期)，可以认为是一种“逻辑时间”。 选举流程:
 	①Raft采用心跳机制触发Leader选举系统启动后，全部节点初始化为Follower，term为0

​	 ②节点如果收到了RequestVote或者AppendEntries，就会保持自己的Follower身份 

​	 ③节点如果一段时间内没收到AppendEntries消息，在该节点的超时时间内还没发现Leader，Follower就会转换成Candidate，自己开始竞选Leader。 一旦转化为Candidate，该节点立即开始下面几件事情:
​		--增加自己的term，启动一个新的定时器
​		--给自己投一票，向所有其他节点发送RequestVote，并等待其他节点的回复。

​	 ④如果在计时器超时前，节点收到多数节点的同意投票，就转换成Leader。同时通过 AppendEntries，向其他节点发送通知。

​	 ⑤每个节点在一个term内只能投一票，采取先到先得的策略，Candidate投自己， Follower会投给第一个收到RequestVote的节点。

​	 ⑥Raft协议的定时器采取随机超时时间（选举的关键），先转为Candidate的节点会先发起投票，从而获得多数票。

**主服务器的选择**

​	当选举出Leader Sentinel后，Leader Sentinel会根据以下规则去从服务器中选择出新的主服务器。

1. 过滤掉主观、客观下线的节点
2. 选择配置slave-priority最高的节点，如果有则返回没有就继续选择
3. 选择出复制偏移量最大的系节点，因为复制偏移量越大则数据复制的越完整
4. 选择run_id最小的节点，因为run_id越小说明重启次数越少

**故障转移**

​	当Leader Sentinel完成新的主服务器选择后，Leader Sentinel会对下线的主服务器执行故障转移操作，主要有三个步骤:

​	1、它会将失效 Master 的其中一个 Slave 升级为新的 Master , 并让失效 Master 的其他 Slave 改为复制新的 Master ;

​	2、当客户端试图连接失效的 Master 时，集群会向客户端返回新 Master 的地址，使得集群当前状态只有一个Master。

​	3、Master 和 Slave 服务器切换后， Master 的 redis.conf 、 Slave 的 redis.conf 和 sentinel.conf 的配置文件的内容都会发生相应的改变，即 Master 主服务器的 redis.conf配置文件中会多一行 replicaof 的配置， sentinel.conf 的监控目标会随之调换。



#### 4、集群模式=写多



​	为了避免单一节点负载过高导致不稳定，集群模式采用**一致性哈希算法或者哈希槽的方法**将 Key 分布到各个节点上。其中，每个 Master 节点后跟若干个 Slave 节点，用于**出现故障时做主备切换**，客户端可以**连接任意 Master 节点**，集群内部会按照**不同 key 将请求转发到不同的 Master** 节点

​	集群模式是如何实现高可用的呢？集群内部节点之间会**互相定时探测**对方是否存活，如果多数节点判断某个节点挂了，则会将其踢出集群，然后从 **Slave** 节点中选举出一个节点**替补**挂掉的 Master 节点。**整个原理基本和哨兵模式一致**

​	虽然集群模式避免了 Master 单节点的问题，但**集群内同步数据时会占用一定的带宽**。所以，只有在**写操作比较多的情况下人们才使用集群模式**，其他大多数情况，使用**哨兵模式**都能满足需求



#### 5、分布式锁

**利用Watch实现Redis乐观锁**

​	乐观锁基于CAS(Compare And Swap)比较并替换思想，不会产生锁等待而消耗资源，但是需要反复的重试，但也是因为重试的机制，能比较快的响应。因此我们可以利用redis来实现乐观锁**（秒杀）**。具体思路如下:

1、利用redis的watch功能，监控这个redisKey的状态值 
2、获取redisKey的值，创建redis事务，给这个key的值+1 
3、执行这个事务，如果key的值被修改过则回滚，key不加1

**利用setnx防止库存超卖**
	分布式锁是控制分布式系统之间同步访问共享资源的一种方式。 利用Redis的单线程特性对共享资源进行串行化处理

```java
// 获取锁推荐使用set的方式
String result = jedis.set(lockKey, requestId, "NX", "EX", expireTime);
String result = jedis.setnx(lockKey, requestId); //如线程死掉，其他线程无法获取到锁
```

```java
// 释放锁，非原子操作，可能会释放其他线程刚加上的锁
if (requestId.equals(jedis.get(lockKey))) { 
  jedis.del(lockKey);
}
// 推荐使用redis+lua脚本
String lua = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
Object result = jedis.eval(lua, Collections.singletonList(lockKey),
```



**分布式锁存在的问题**：

- **客户端长时间阻塞导致锁失效问题**

​	计算时间内异步启动另外一个线程去检查的问题，这个key是否超时，当锁超时时间快到期且逻辑未执行完，延长锁超时时间。

- **Redis服务器时钟漂移问题导致同时加锁
  redis的过期时间是依赖系统时钟的，如果时钟漂移过大时 理论上是可能出现的 **会影响到过期时间的计算。

- **单点实例故障，锁未及时同步导致丢失**

  **RedLock算法**

1. 获取当前时间戳T0，配置时钟漂移误差T1

2. 短时间内逐个获取全部N/2+1个锁，结束时间点T2

3. 实际锁能使用的处理时长变为：TTL - （T2 - T0）- T1

   该方案通过多节点来**防止Redis的单点故障**，效果一般，也无法防止：

- **主从切换导致的两个客户端同时持有锁**

  大部分情况下**持续时间极短**，而且使用**Redlock在切换的瞬间**获取到节点的锁，也存在问题。已经是极低概率的时间，无法避免。**Redis分布式锁适合幂等性事务**，如果一定要**保证安全**，应该**使用Zookeeper或者DB**，但是，**性能会急剧下降**。



**与zookeeper分布式锁对比**

- redis 分布式锁，其实**需要自己不断去尝试获取锁**，比较消耗性能。
- zk 分布式锁，注册个监听器即可，不需要不断主动尝试获取锁，ZK获取锁会按照加锁的顺序，所以是公平锁，性能和mysql差不多，和redis差别大





**Redission生产环境的分布式锁**

​	Redisson是基于NIO的Netty框架上的一个Java驻内存数据网格(In-Memory Data Grid)分布式锁开源组件。 

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1glurlfrrp4j30qk0g876c.jpg" alt="image-20201221000119586" style="zoom:67%;" />

但当业务必须要数据的强一致性，即不允许重复获得锁，比如金融场景(重复下单，重复转账)，**请不要使用redis分布式锁**。可以使用CP模型实现，比如:**zookeeper和etcd。**

|            | Redis    | zookeeper  | etcd       |
| ---------- | -------- | ---------- | ---------- |
| 一致性算法 | 无       | paxos(ZAB) | raft       |
| CAP        | AP       | CP         | CP         |
| 高可用     | 主从集群 | n+1        | n+1        |
| 实现       | setNX    | createNode | restfulAPI |





#### 6、redis心跳检测

在命令传播阶段，从服务器默认会以每秒一次的频率向主服务器发送ACK命令:

​	1、检测主从的连接状态 检测主从服务器的网络连接状态

​			lag的值应该在0或1之间跳动，如果超过1则说明主从之间的连接有 故障。

​	2、辅助实现min-slaves,Redis可以通过配置防止主服务器在不安全的情况下执行写命令

```yaml
min-slaves-to-write 3 (min-replicas-to-write 3 )

min-slaves-max-lag 10 (min-replicas-max-lag 10)
```

​		上面的配置表示:从服务器的数量少于3个，或者三个从服务器的延迟(lag)值都大于或等于10 秒时，主服务器将拒绝执行写命令。

​	3、检测命令丢失，增加重传机制

​		如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么当从服务器向主服务器发 送REPLCONF ACK命令时，主服务器将发觉从服务器当前的复制偏移量少于自己的复制偏移量， 然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据，并将这些数据重新发送给从服务器。



### Redis实战

#### 1、Redis优化

![img](https://tva1.sinaimg.cn/large/008eGmZEly1gorm5m7b4gj30uy0hjwfp.jpg)

**读写方式**
	简单来说就是不用**keys**等，用**range、contains**之类。比如，用户粉丝数，大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表只能部分获取。另外在判断某用户是否关注了另外一个用户时，也只需要关注列表上进行检查判断，然后返回 True/False 或 0/1 的方式更为高效。

**KV size**
	如果单个业务的 KV size 过大，需要分拆成多个 KV 来缓存。拆分时应**考虑访问频率**

**key 的数量**
	如果数据量巨大，则在缓存中尽可能只保留频繁访问的热数据，对于冷数据直接访问 DB。

**读写峰值**
	如果小于 10万 级别，简单分拆到独立 Cache 池即可
	如果达到 100万 级的QPS，则需要对 Cache 进行分层处理，可以同时使用 Local-Cache 配合远程 cache，甚至远程缓存内部继续分层叠加分池进行处理。**（多级缓存）**

**命中率**
	缓存的命中率对整个服务体系的性能影响甚大。对于核心高并发访问的业务，需要预留足够的容量，确保核心业务缓存维持较高的命中率。比如微博中的 Feed Vector Cache（**热点资讯**），常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。同时在部分缓存节点异常、命中率下降时，故障转移方案，需要考虑是采用一致性 Hash 分布的访问漂移策略，还是采用数据多层备份策略。

**过期策略**

​	可以设置较短的过期时间，让冷 key 自动过期；也可以让 key 带上时间戳，同时设置较长的过期时间，比如很多业务系统内部有这样一些 key：key_20190801。

**缓存穿透时间**
	平均缓存穿透加载时间在某些业务场景下也很重要，对于一些缓存穿透后，加载时间特别长或者需要复杂计算的数据，而且访问量还比较大的业务数据，要配置更多容量，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。

**缓存可运维性**
	对于缓存的可运维性考虑，则需要考虑缓存体系的集群管理，如何进行一键扩缩容，如何进行缓存组件的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。

**缓存安全性**
	对于缓存的安全性考虑，一方面可以限制来源 IP，只允许内网访问，同时加密鉴权访问。



#### 2、Redis热升级

> 在 Redis 需要升级版本或修复 bug 时，如果直接重启变更，由于需要数据恢复，这个过程需要近 10 分钟的时间，时间过长，会严重影响系统的可用性。面对这种问题，可以对 Redis 扩展热升级功能，从而在毫秒级完成升级操作，完全不影响业务访问。

热升级方案如下，首先构建一个 Redis 壳程序，将 redisServer 的所有属性（包括redisDb、client等）保存为全局变量。然后将 Redis 的处理逻辑代码全部封装到动态连接库 so 文件中。Redis 第一次启动，从磁盘加载恢复数据，在后续升级时，通过指令，壳程序重新加载 Redis 新的 redis-4.so 到 redis-5.so 文件，即可完成功能升级，毫秒级完成 Redis 的版本升级。而且整个过程中，所有 Client 连接仍然保留，在升级成功后，原有 Client 可以继续进行读写操作，整个过程对业务完全透明。









































# 六、Kafka篇

### Why kafka

消息队列的作用：**异步、削峰填谷、解耦**

**中小型公司**，技术实力较为一般，技术挑战不是特别高，用 **RabbitMQ** （开源、社区活跃）是不错的选择；**大型公司**，基础架构研发实力较强，用 **RocketMQ**（Java二次开发） 是很好的选择。

如果是**大数据领域**的实时计算、日志采集等场景，用 **Kafka** 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfiyienm0j30zu0hago7.jpg" alt="image-20210107225921930" style="zoom:50%;" />



**RabbitMQ**

RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款**支持AMQP**协议的产品之一。

**优点：**

- 轻量级，快速，部署使用方便
- 支持灵活的路由配置。RabbitMQ中，在生产者和队列之间有一个交换器模块。根据配置的路由规则，生产者发送的消息可以发送到不同的队列中。路由规则很灵活，还可以自己实现。
- RabbitMQ的客户端支持大多数的编程语言，支持**AMQP**协议。

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmfjicxzb2j30u80hx0uw.jpg" alt="image-20210107231826261" style="zoom:40%;" />

**缺点：**

- 如果有大量消息堆积在队列中，性能会急剧下降
- 每秒处理几万到几十万的消息。如果应用要求高的性能，不要选择RabbitMQ。 
- RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。



**RocketMQ**

借鉴了Kafka的设计并做了很多改进，**几乎具备了消息队列应该具备的所有特性和功能**。

- RocketMQ主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。
- 经过了历次的双11考验，性能，稳定性可靠性没的说。
- java开发，阅读源代码、扩展、二次开发很方便。
- 对电商领域的响应延迟做了很多优化。
- 每秒处理几十万的消息，同时响应在毫秒级。如果应用很关注响应时间，可以使用RocketMQ。
- 性能比RabbitMQ高一个数量级，。
- 支持死信队列，DLX 是一个非常有用的特性。它可以处理**异常情况下，消息不能够被消费者正确消费而被置入死信队列中**的情况，后续分析程序可以通过消费这个死信队列中的内容来分析当时所遇到的异常情况，进而可以**改善和优化系统**。

**缺点**：

​	跟周边系统的整合和兼容不是很好。



**Kafka**

**高可用**，几乎所有相关的开源软件都支持，满足大多数的应用场景，尤其是**大数据和流计算**领域，

- Kafka高效，可伸缩，消息持久化。支持分区、副本和容错。
- 对批处理和异步处理做了大量的设计，因此Kafka可以得到非常高的性能。
- 每秒处理几十万异步消息消息，如果开启了压缩，最终可以达到每秒处理2000w消息的级别。
- 但是由于是异步的和批处理的，延迟也会高，不适合电商场景。



### What Kafka

- Producer API：允许应用程序将记录流发布到一个或多个Kafka主题。
- Consumer API：允许应用程序订阅一个或多个主题并处理为其生成的记录流。
- Streams API：允许应用程序充当流处理器，将输入流转换为输出流。

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gme95cirjfj31000kb41j.jpg" alt="image-20210106203420526" style="zoom: 40%;" />



**消息Message**

​	Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。

**批次**

​	为了提高效率，消息被分批写入Kafka。提高吞吐量却加大了响应时间

**主题Topic**

​	通过主题进行分类，类似数据库中的表，

**分区Partition**

​	Topic可以被分成若干分区分布于kafka集群中，方便扩容

​	单个分区内是有序的，partition设置为一才能保证全局有序

**副本Replicas**

​	每个主题被分为若干个分区，每个分区有多个副本。

**生产者Producer**

​	生产者在默认情况下把**消息均衡地分布**到主题的所有分区上：

- 直接指定消息的分区
- 根据消息的key散列取模得出分区
- 轮询指定分区。

**消费者Comsumer**

​	消费者通过**偏移量**来区分已经读过的消息，从而消费消息。把每个分区最后读取的消息偏移量保存在Zookeeper 或Kafka上，如果消费者关闭或重启，它的**读取状态不会丢失**。

**消费组ComsumerGroup**

​	消费组保证**每个分区只能被一个消费者**使用，避免重复消费。如果群组内一个**消费者失效**，消费组里的其他消费者可以**接管失效消费者的工作再平衡**，重新分区

**节点Broker**

​	连接生产者和消费者，**单个**broker**可以轻松处理**数千个分区**以及**每秒百万级的消息量。

- broker接收来自生产者的消息，为消息设置偏移量，并提交**消息到磁盘保存**。
- broker为消费者提供服务，响应读取分区的请求，**返回已经提交到磁盘上的消息**。

**集群**

​	每隔分区都有一个**首领**，当分区被分配给多个broker时，会通过首领进行**分区复制**。	

**生产者Offset**

​	消息写入的时候，每一个分区都有一个offset，即每个分区的最新最大的offset。

**消费者Offset**

​	不同消费组中的消费者可以针对一个分区存储不同的Offset，互不影响

**LogSegment**

- 一个分区由多个LogSegment组成，
- 一个LogSegment由`.log .index .timeindex`组成
- `.log`追加是顺序写入的，文件名是以文件中第一条message的offset来命名的
- `.Index`进行日志删除的时候和数据查找的时候可以快速定位。
- `.timeStamp`则根据**时间戳查找对应的偏移量**。



### How Kafka

**优点**

- **高吞吐量**：单机每秒处理几十上百万的消息量。即使存储了TB及消息，也保持稳定的性能。
  - **零拷贝** 减少内核态到用户态的拷贝，磁盘通过sendfile实现**DMA** 拷贝Socket buffer
  - **顺序读写** 充分利用磁盘顺序读写的超高性能
  - **页缓存mmap**，将磁盘文件**映射**到内存, 用户通过修改内存就能修改磁盘文件。
- **高性能**：单节点支持上千个客户端，并保证零停机和零数据丢失。
- **持久化**：将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。
- **分布式系统**，易扩展。所有的组件均为分布式的，无需停机即可扩展机器。
- **可靠性** - Kafka是分布式，分区，复制和容错的。
- **客户端状态维护**：消息被处理的状态是在Consumer端维护，当失败时能自动平衡。

**应用场景**

- **日志收集：**用Kafka可以收集各种服务的Log，通过大数据平台进行处理；
- **消息系统：**解耦生产者和消费者、缓存消息等；
- **用户活动跟踪：**Kafka经常被用来记录Web用户或者App用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到Kafka的Topic中，然后消费者通过订阅这些Topic来做**运营数据**的实时的监控分析，也可保存到数据库；



### **生产消费基本流程**

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmeb1cw09gj313m0kgwgb.jpg" alt="image-20210106213944461" style="zoom:40%;" />

1. Producer创建时，会创建一个Sender线程并设置为守护线程。

2. 生产的消息先经过拦截器->序列化器->分区器，然后将消息缓存在缓冲区。

3. 批次发送的条件为：缓冲区数据大小达到**batch.size**或者**linger.ms**达到上限。

4. 批次发送后，发往指定分区，然后落盘到broker；

   - **acks=0**只要将消息放到缓冲区，就认为消息已经发送完成。

   - **acks=1**表示消息**只需要写到主分区**即可。在该情形下，如果主分区收到消息确认之后就宕机了，而副本分区还没来得及同步该消息，则该消息丢失。

   - **acks=all （默认）**首领分区会等待**所有的ISR副本分区确认记录**。该处理保证了只要有一个ISR副本分区存活，消息就不会丢失。

5. 如果生产者配置了**retrires参数大于0并且未收到确认**，那么客户端会对该消息进行重试。

6. 落盘到broker成功，返回生产元数据给生产者。



**Leader选举**

- Kafka会在Zookeeper上针对每个Topic维护一个称为ISR（in-sync replica）的集合

- 当集合中副本都跟Leader中的副本同步了之后，kafka才会认为消息已提交

- 只有这些跟Leader保持同步的Follower才应该被选作新的Leader

- 假设某个topic有N+1个副本，kafka可以容忍N个服务器不可用，冗余度较低

  如果ISR中的副本都丢失了，则：

  - 可以等待ISR中的副本任何一个恢复，接着对外提供服务，需要时间等待
  - 从OSR中选出一个副本做Leader副本，此时会造成数据丢失



**副本消息同步**

​	首先，Follower 发送 FETCH 请求给 Leader。接着，Leader 会读取底层日志文件中的消 息数据，再更新它内存中的 Follower 副本的 LEO 值，更新为 FETCH 请求中的 fetchOffset 值。最后，尝试更新分区高水位值。Follower 接收到 FETCH 响应之后，会把消息写入到底层日志，接着更新 LEO 和 HW 值。



**相关概念**：**LEO**和**HW**。

- LEO：即日志末端位移(log end offset)，记录了该副本日志中下一条消息的位移值。如果LEO=10，那么表示该副本保存了10条消息，位移值范围是[0, 9]
- HW：水位值HW（high watermark）即已备份位移。对于同一个副本对象而言，其HW值不会大于LEO值。小于等于HW值的所有消息都被认为是“已备份”的（replicated）



**Rebalance**

- 组成员数量发生变化
- 订阅主题数量发生变化
- 订阅主题的分区数发生变化

leader选举完成后，当以上三种情况发生时，Leader根据配置的**RangeAssignor**开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进**SyncGroup**请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。



**分区分配算法RangeAssignor**

- 原理是按照消费者总数和分区总数进行整除运算平均分配给所有的消费者。

- 订阅Topic的消费者按照名称的字典序排序，分均分配，剩下的字典序从前往后分配

  

**增删改查**

```bash
kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x 
								--partitions 1 --replication-factor 1
kafka-topics.sh --zookeeper localhost:2181/myKafka --delete --topic topic_x
kafka-topics.sh --zookeeper localhost:2181/myKafka --alter --topic topic_x
								--config max.message.bytes=1048576
kafka-topics.sh --zookeeper localhost:2181/myKafka --describe --topic topic_x
```

**如何查看偏移量为23的消息？**

通过查询跳跃表`ConcurrentSkipListMap`，定位到在00000000000000000000.index ，通过二分法在偏移量索引文件中找到不大于 23 的**最大索引项**，即offset 20 那栏，然后从日志分段文件中的物理位置为320 开始顺序查找偏移量为 23 的消息。

<img src="https://img-blog.csdnimg.cn/20191230225447849.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMjMzNzA2,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />





**切分文件**

- **大小分片** 当前日志分段文件的大小超过了 broker 端参数 `log.segment.bytes` 配置的值
- **时间分片** 当前日志分段中消息的最大时间戳与系统的时间戳的差值大于`log.roll.ms`配置的值
- **索引分片** 偏移量或时间戳索引文件大小达到broker端 `log.index.size.max.bytes`配置的值
- **偏移分片** 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于 Integer.MAX_VALUE 



### 一致性

**幂等性**

保证在消息重发的时候，消费者不会重复处理。即使在**消费者收到重复消息的时候，重复处理**，也

要**保证最终结果的一致性**。所谓幂等性，数学概念就是： f(f(x)) = f(x) 

![image-20210107000942286](https://tva1.sinaimg.cn/large/008eGmZEly1gmefdeas1vj315i0bgmya.jpg)

**如何实现？**

​	添加唯一ID，类似于数据库的主键，用于唯一标记一个消息。

```bash
ProducerID：#在每个新的Producer初始化时，会被分配一个唯一的PID
SequenceNumber：#对于每个PID发送数据的每个Topic都对应一个从0开始单调递增的SN值
```

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmefjpeet8j317e0cgmyp.jpg" alt="image-20210107001546404" style="zoom:80%;" />

**如何选举**

1. 使用 Zookeeper 的**分布式锁选举控制器**，并在节点加入集群或退出集群时通知控制器。
2. 控制器负责在节点加入或离开集群时进行分区Leader选举。
3. 控制器使用epoch`忽略小的纪元`来避免**脑裂**：两个节点同时认为自己是当前的控制器。





### 可用性

- 创建Topic的时候可以指定 --replication-factor 3 ，表示不超过broker的副本数
- 只有Leader是负责读写的节点，Follower定期地到Leader上Pull数据。
- ISR是Leader负责维护的与其保持同步的Replica列表，即当前活跃的副本列表。如果一个Follow落后太多，Leader会将它从ISR中移除。选举时优先从ISR中挑选Follower。 
- 设置 acks=all 。Leader收到了ISR中所有Replica的ACK，才向Producer发送ACK。





### 面试题

#### **线上问题rebalance**

> 因集群架构变动导致的消费组内重平衡，如果kafka集内节点较多，比如数百个，那重平衡可能会耗时导致**数分钟到数小时**，此时kafka基本处于不可用状态，对kafka的TPS影响极大

产生的原因：

- 组成员数量发生变化

- 订阅主题数量发生变化

- 订阅主题的分区数发生变化

  **组成员崩溃和组成员主动离开是两个不同的场景。**因为在崩溃时成员并不会主动地告知coordinator此事，coordinator有可能需要一个完整的session.timeout周期(心跳周期)才能检测到这种崩溃，这必然会造成consumer的滞后。可以说离开组是主动地发起rebalance；而崩溃则是被动地发起rebalance。

  ![img](https://tva1.sinaimg.cn/large/008eGmZEly1gooe9o07fvj30p00btju1.jpg)

解决方案：

```properties
加大超时时间 session.timout.ms=6s
加大心跳频率 heartbeat.interval.ms=2s
增长推送间隔 max.poll.interval.ms=t+1 minutes
```



#### ZooKeeper 的作用

目前，Kafka 使用 ZooKeeper 存放集群元数据、成员管理、Controller 选举，以及其他一些管理类任务。之后，等 KIP-500 提案完成后，Kafka 将完全不再依赖于 ZooKeeper。

- **存放元数据**是指主题分区的所有数据都保存在 ZooKeeper 中，其他“人”都要与它保持对齐。
- **成员管理**是指 Broker 节点的注册、注销以及属性变更等 。
- **Controller 选举**是指选举集群 Controller，包括但不限于主题删除、参数配置等。

一言以蔽之:**KIP-500 ，是使用社区自研的基于 Raft 的共识算法，实现 Controller 自选举**。

同样是存储元数据，这几年**基于Raft算法的etcd**认可度越来越高

​	越来越多的系统开始用它保存关键数据。比如，**秒杀系统经常用它保存各节点信息**，以便控制消费 MQ 的服务数量。还有些**业务系统的配置数据**，也会通过 etcd 实时**同步给业务系统的各节点**，比如，秒杀管理后台会使用 etcd 将**秒杀活动的配置数据实时同步给秒杀 API 服务各节点**。





#### Replica副本的作用

**Kafka 只有 Leader 副本才能 对外提供读写服务，响应 Clients 端的请求。Follower 副本只是采用拉(PULL)的方 式，被动地同步 Leader 副本中的数据，并且在 Leader 副本所在的 Broker 宕机后，随时准备应聘 Leader 副本。**

- **自 Kafka 2.4 版本开始**，社区可以通过配置参数，允许 Follower 副本有限度地提供读服务。
- 之前确保一致性的主要手段是高水位机制， 但高水位值无法保证 Leader 连续变更场景下的数据一致性，因此，社区引入了 **Leader Epoch** 机制，来修复高水位值的弊端。



#### 为什么不支持读写分离?

- **自 Kafka 2.4 之后**，Kafka 提供了有限度的读写分离。

- **场景不适用**。读写分离适用于那种读负载很大，而写操作相对不频繁的场景。
- **同步机制**。Kafka 采用 PULL 方式实现 Follower 的同步，同时复制延迟较大。





#### 如何防止重复消费

- 代码层面每次消费需提交offset
- 通过Mysql的**唯一键约束**，结合Redis查看**id是否被消费**，存Redis可以直接使用set方法
- 量大且允许误判的情况下，使用布隆过滤器也可以




#### **如何保证数据不会丢失**

- **生产者**生产消息可以通过comfirm配置**ack=all**解决
- **Broker**同步过程中leader宕机可以通过配置**ISR副本+重试**解决
- **消费者**丢失可以**关闭自动提交**offset功能，系统处理完成时提交offset



#### **如何保证顺序消费**

- 单 topic，单partition，单 consumer，单线程消费，吞吐量低，不推荐
- **如只需保证单key有序**，为每个key申请单独内存 queue，每个线程分别消费一个内存 queue 即可，这样就能保证单key（例如用户id、活动id）顺序性。



#### 【线上】如何解决积压消费

- **修复consumer**，使其具备消费能力，并且扩容N台
- 写一个**分发的程序**，将Topic均匀分发到临时Topic中
- 同时**起N台consumer**，消费不同的**临时Topic**



#### 如何避免消息积压

- 提高消费并行度
- 批量消费
- 减少组件IO的交互次数
- 优先级消费

```java
if (maxOffset - curOffset > 100000) {
  // TODO 消息堆积情况的优先处理逻辑
  // 未处理的消息可以选择丢弃或者打日志
  return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
// TODO 正常消费过程
return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
```



#### 如何设计消息队列

需要支持快速水平扩容，broker+partition，partition放不同的机器上，增加机器时将数据根据topic做迁移，分布式需要考虑一致性、可用性、分区容错性

- **一致性：**生产者的消息确认、消费者的幂等性、Broker的数据同步
- **可用性：**数据如何保证不丢不重、数据如何持久化、持久化时如何读写
- **分区容错：**采用何种选举机制、如何进行多副本同步
- **海量数据：**如何解决消息积压、海量Topic性能下降

性能上，可以借鉴**时间轮、零拷贝、IO多路复用、顺序读写、压缩批处理**





# 	七、Spring篇 

### 设计思想&Beans

#### **1、IOC 控制反转**

​		IoC（Inverse of Control:控制反转）是⼀种设计思想，就是将原本在程序中⼿动创建对象的控制权，交由Spring框架来管理。 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 

​		IoC 容器是 Spring⽤来实现 IoC 的载体， IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注⼊。这样可以很⼤程度上简化应⽤的开发，把应⽤从复杂的依赖关系中解放出来。 IoC 容器就像是⼀个⼯⼚⼀样，当我们需要创建⼀个对象的时候，只需要配置好配置⽂件/注解即可，完全不⽤考虑对象是如何被创建出来的。



**DI 依赖注入**

​	DI:（Dependancy Injection：依赖注入)站在容器的角度，将对象创建依赖的其他对象注入到对象中。



#### **2、AOP 动态代理**

​		AOP(Aspect-Oriented Programming:⾯向切⾯编程)能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑或责任（例如事务处理、⽇志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。

​		Spring AOP就是基于动态代理的，如果要代理的对象，实现了某个接⼝，那么Spring AOP会使⽤JDKProxy，去创建代理对象，⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，这时候Spring AOP会使⽤基于asm框架字节流的Cglib动态代理 ，这时候Spring AOP会使⽤ Cglib ⽣成⼀个被代理对象的⼦类来作为代理。



#### **3、Bean生命周期** 

**单例对象：** singleton                    

总结：单例对象的生命周期和容器相同        

**多例对象：** prototype           

出生：使用对象时spring框架为我们创建            

活着：对象只要是在使用过程中就一直活着            

死亡：当对象长时间不用且没有其它对象引用时，由java的垃圾回收机制回收

<img src="https://s0.lgstatic.com/i/image3/M01/89/0C/Cgq2xl6WvHqAdmt4AABGAn2eSiI631.png" alt="img" style="zoom:67%;" />

IOC容器初始化加载Bean流程：

```java
@Override
public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) {
  // 第一步:刷新前的预处理 
  prepareRefresh();
  //第二步: 获取BeanFactory并注册到 BeanDefitionRegistry
  ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
  // 第三步:加载BeanFactory的预准备工作(BeanFactory进行一些设置，比如context的类加载器等)
  prepareBeanFactory(beanFactory);
  try {
    // 第四步:完成BeanFactory准备工作后的前置处理工作 
    postProcessBeanFactory(beanFactory);
    // 第五步:实例化BeanFactoryPostProcessor接口的Bean 
    invokeBeanFactoryPostProcessors(beanFactory);
    // 第六步:注册BeanPostProcessor后置处理器，在创建bean的后执行 
    registerBeanPostProcessors(beanFactory);
    // 第七步:初始化MessageSource组件(做国际化功能;消息绑定，消息解析); 
    initMessageSource();
    // 第八步:注册初始化事件派发器 
    initApplicationEventMulticaster();
    // 第九步:子类重写这个方法，在容器刷新的时候可以自定义逻辑 
    onRefresh();
    // 第十步:注册应用的监听器。就是注册实现了ApplicationListener接口的监听器
    registerListeners();
    //第十一步:初始化所有剩下的非懒加载的单例bean 初始化创建非懒加载方式的单例Bean实例(未设置属性)
    finishBeanFactoryInitialization(beanFactory);
    //第十二步: 完成context的刷新。主要是调用LifecycleProcessor的onRefresh()方法，完成创建
    finishRefresh();
	}
  ……
} 
```

总结：

**四个阶段**

- 实例化 Instantiation
- 属性赋值 Populate
- 初始化 Initialization
- 销毁 Destruction

**多个扩展点**

- 影响多个Bean
  - BeanPostProcessor
  - InstantiationAwareBeanPostProcessor
- 影响单个Bean
  - Aware

**完整流程**  

1. 实例化一个Bean－－也就是我们常说的**new**；
2. 按照Spring上下文对实例化的Bean进行配置－－**也就是IOC注入**；
3. 如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，也就是根据就是Spring配置文件中**Bean的id和name进行传递**
4. 如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现setBeanFactory(BeanFactory)也就是Spring配置文件配置的**Spring工厂自身进行传递**；
5.  如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，和4传递的信息一样但是因为ApplicationContext是BeanFactory的子接口，所以**更加灵活**
6.  如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization()方法，BeanPostProcessor经常被用作是Bean内容的更改，由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于**内存或缓存技**术
7.  如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。
8.   如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization()，**打印日志或者三级缓存技术里面的bean升级**
9.   以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。
10.   当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，或者根据spring配置的destroy-method属性，调用实现的destroy()方法





#### **4**、Bean作用域

| 名称           | 作用域                                                       |
| -------------- | ------------------------------------------------------------ |
| **singleton**  | **单例对象，默认值的作用域**                                 |
| **prototype**  | **每次获取都会创建⼀个新的 bean 实例**                       |
| request        | 每⼀次HTTP请求都会产⽣⼀个新的bean，该bean仅在当前HTTP request内有效。 |
| session        | 在一次 HTTP session 中，容器将返回同一个实例                 |
| global-session | 将对象存入到web项目集群的session域中,若不存在集群,则global session相当于session |

默认作用域是singleton，多个线程访问同一个bean时会存在线程不安全问题

**保障线程安全方法：**

1. 在Bean对象中尽量避免定义可变的成员变量（不太现实）。

2. 在类中定义⼀个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中

  **ThreadLocal**：

  ​		每个线程中都有一个自己的ThreadLocalMap类对象，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。

  ​		将一个共用的ThreadLocal静态实例作为key，将不同对象的引用保存到不同线程的ThreadLocalMap中，然后**在线程执行的各处通过这个静态ThreadLocal实例的get()方法取得自己线程保存的那个对象**，避免了将这个对象作为参数传递的麻烦。



#### 5、循环依赖

​	循环依赖其实就是循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成闭环。比如A 依赖于B，B又依赖于A

Spring中循环依赖场景有: 

- prototype 原型 bean循环依赖

- 构造器的循环依赖（构造器注入）

- Field 属性的循环依赖（set注入）

  其中，构造器的循环依赖问题无法解决，在解决属性循环依赖时，可以使用懒加载，spring采用的是提前暴露对象的方法。

**懒加载@Lazy解决循环依赖问题**

​	Spring 启动的时候会把所有bean信息(包括XML和注解)解析转化成Spring能够识别的BeanDefinition并存到Hashmap里供下面的初始化时用，然后对每个 BeanDefinition 进行处理。普通 Bean 的初始化是在容器启动初始化阶段执行的，而被lazy-init=true修饰的 bean 则是在从容器里第一次进行**context.getBean() 时进行触发**。



**三级缓存解决循环依赖问题**

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1glv7ivru2lj31980qcn13.jpg" alt="循环依赖问题" style="zoom: 33%;" />

1. Spring容器初始化ClassA通过构造器初始化对象后提前暴露到Spring容器中的singletonFactorys（三级缓存中）。

2. ClassA调用setClassB方法，Spring首先尝试从容器中获取ClassB，此时ClassB不存在Spring 容器中。

3. Spring容器初始化ClassB，ClasssB首先将自己暴露在三级缓存中，然后从Spring容器一级、二级、三级缓存中一次中获取ClassA 。

4. 获取到ClassA后将自己实例化放入单例池中，实例 ClassA通过Spring容器获取到ClassB，完成了自己对象初始化操作。

5. 这样ClassA和ClassB都完成了对象初始化操作，从而解决了循环依赖问题。

   

### Spring注解

#### 1、@SpringBoot 

​	**声明bean的注解**

​	**@Component** 通⽤的注解，可标注任意类为  Spring 组件

​	**@Service** 在业务逻辑层使用（service层）

​	**@Repository** 在数据访问层使用（dao层）

​	**@Controller** 在展现层使用，控制器的声明（controller层）

​	**注入bean的注解**

​	**@Autowired**：默认按照类型来装配注入，**@Qualifier**：可以改成名称

​	**@Resource**：默认按照名称来装配注入，JDK的注解，新版本已经弃用



**@Autowired注解原理** 

​		 @Autowired的使用简化了我们的开发，

​				实现 AutowiredAnnotationBeanPostProcessor 类，该类实现了 Spring 框架的一些扩展接口。
​				实现 BeanFactoryAware 接口使其内部持有了 BeanFactory（可轻松的获取需要依赖的的 Bean）。
​				实现 MergedBeanDefinitionPostProcessor 接口，实例化Bean 前获取到 里面的 @Autowired 信息并缓存下来；
​				实现 postProcessPropertyValues 接口， 实例化Bean 后从缓存取出注解信息，通过反射将依赖对象设置到 Bean 属性里面。



**@SpringBootApplication**

```java
@SpringBootApplication
public class JpaApplication {
    public static void main(String[] args) {
        SpringApplication.run(JpaApplication.class, args);
    }
}
```

**@SpringBootApplication**注解等同于下面三个注解：

- **@SpringBootConfiguration：** 底层是**Configuration**注解，说白了就是支持**JavaConfig**的方式来进行配置
- **@EnableAutoConfiguration：**开启**自动配置**功能
- **@ComponentScan：**就是**扫描**注解，默认是扫描**当前类下**的package

其中`@EnableAutoConfiguration`是关键(启用自动配置)，内部实际上就去加载`META-INF/spring.factories`文件的信息，然后筛选出以`EnableAutoConfiguration`为key的数据，加载到IOC容器中，实现自动配置功能！

它主要加载了@SpringBootApplication注解主配置类，这个@SpringBootApplication注解主配置类里边最主要的功能就是SpringBoot开启了一个@EnableAutoConfiguration注解的自动配置功能。

 **@EnableAutoConfiguration作用：**

它主要利用了一个

EnableAutoConfigurationImportSelector选择器给Spring容器中来导入一些组件。

```java
@Import(EnableAutoConfigurationImportSelector.class)
public @interface EnableAutoConfiguration 
```





#### **2、@SpringMVC**

```java
@Controller 声明该类为SpringMVC中的Controller
@RequestMapping 用于映射Web请求
@ResponseBody 支持将返回值放在response内，而不是一个页面，通常用户返回json数据
@RequestBody 允许request的参数在request体中，而不是在直接连接在地址后面。
@PathVariable 用于接收路径参数
@RequestMapping("/hello/{name}")申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。
```

**SpringMVC原理** 

<img src="https://img-blog.csdn.net/20181022224058617?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F3YWtlX2xxaA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" style="zoom: 50%;" />

1. 客户端（浏览器）发送请求，直接请求到  DispatcherServlet 。
2. DispatcherServlet 根据请求信息调⽤  HandlerMapping ，解析请求对应的  Handler 。
3. 解析到对应的  Handler （也就是  Controller 控制器）后，开始由HandlerAdapter 适配器处理。
4. HandlerAdapter 会根据  Handler 来调⽤真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回⼀个  ModelAndView 对象， Model 是返回的数据对象
6. ViewResolver 会根据逻辑  View 查找实际的  View 。
7. DispaterServlet 把返回的  Model 传给  View （视图渲染）。
8. 把  View 返回给请求者（浏览器）



#### 3、@SpringMybatis

```java
@Insert ： 插入sql ,和xml insert sql语法完全一样
@Select ： 查询sql, 和xml select sql语法完全一样
@Update ： 更新sql, 和xml update sql语法完全一样
@Delete ： 删除sql, 和xml delete sql语法完全一样
@Param ： 入参
@Results ： 设置结果集合@Result ： 结果
@ResultMap ： 引用结果集合
@SelectKey ： 获取最新插入id 
```

**mybatis如何防止sql注入？**

​	简单的说就是#{}是经过预编译的，是安全的，**$**{}是未经过预编译的，仅仅是取变量的值，是非安全的，存在SQL注入。在编写mybatis的映射语句时，尽量采用**“#{xxx}”**这样的格式。如果需要实现动态传入表名、列名，还需要做如下修改：添加属性**statementType="STATEMENT"**，同时sql里的属有变量取值都改成**${xxxx}**



**Mybatis和Hibernate的区别** 

**Hibernate 框架：** 

​    **Hibernate**是一个开放源代码的对象关系映射框架,它对JDBC进行了非常轻量级的对象封装,建立对象与数据库表的映射。是一个全自动的、完全面向对象的持久层框架。

**Mybatis框架：**

​    **Mybatis**是一个开源对象关系映射框架，原名：ibatis,2010年由谷歌接管以后更名。是一个半自动化的持久层框架。

**区别：**

  **开发方面**

​    在项目开发过程当中，就速度而言：

​      hibernate开发中，sql语句已经被封装，直接可以使用，加快系统开发；

​      Mybatis 属于半自动化，sql需要手工完成，稍微繁琐；

​    但是，凡事都不是绝对的，如果对于庞大复杂的系统项目来说，复杂语句较多，hibernate 就不是好方案。

  **sql优化方面**

​    Hibernate 自动生成sql,有些语句较为繁琐，会多消耗一些性能；

​    Mybatis 手动编写sql，可以避免不需要的查询，提高系统性能；

  **对象管理比对**

​    Hibernate 是完整的对象-关系映射的框架，开发工程中，无需过多关注底层实现，只要去管理对象即可；

​    Mybatis 需要自行管理映射关系；



#### 4、@Transactional

```java
@EnableTransactionManagement 
@Transactional
```

注意事项：

​	①事务函数中不要处理耗时任务，会导致长期占有数据库连接。

​	②事务函数中不要处理无关业务，防止产生异常导致事务回滚。

**事务传播属性**

**1) REQUIRED（默认属性）** 如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。 

2) MANDATORY  支持当前事务，如果当前没有事务，就抛出异常。 

3) NEVER  以非事务方式执行，如果当前存在事务，则抛出异常。 

4) NOT_SUPPORTED  以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 

5) REQUIRES_NEW  新建事务，如果当前存在事务，把当前事务挂起。 

6) SUPPORTS  支持当前事务，如果当前没有事务，就以非事务方式执行。 

**7) NESTED** （**局部回滚**） 支持当前事务，新增Savepoint点，与当前事务同步提交或回滚。 **嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回滚。**



### Spring源码阅读

#### **1、Spring中的设计模式** 

参考：[spring中的设计模式](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485303&idx=1&sn=9e4626a1e3f001f9b0d84a6fa0cff04a&chksm=cea248bcf9d5c1aaf48b67cc52bac74eb29d6037848d6cf213b0e5466f2d1fda970db700ba41&token=255050878&lang=zh_CN%23rd)

**单例设计模式 :** Spring 中的 Bean 默认都是单例的。

**⼯⼚设计模式 :** Spring使⽤⼯⼚模式通过  BeanFactory 、 ApplicationContext 创建bean 对象。

**代理设计模式 :** Spring AOP 功能的实现。

**观察者模式：** Spring 事件驱动模型就是观察者模式很经典的⼀个应⽤。

**适配器模式：**Spring AOP 的增强或通知(Advice)使⽤到了适配器模式、spring MVC 中也是⽤到了适配器模式适配 Controller 。











# 八、SpringCloud篇

#### Why SpringCloud

> ​	Spring cloud 是一系列框架的有序集合。它利用 spring boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如**服务发现注册**、**配置中心**、**消息总线**、**负载均衡**、**断路器**、**数据监控**等，都可以用 spring boot 的开发风格做到一键启动和部署。

| SpringCloud（微服务解决方案）    | Dubbo（分布式服务治理框架） |
| -------------------------------- | --------------------------- |
| Rest API （轻量、灵活、swagger） | RPC远程调用（高效、耦合）   |
| Eureka、Nacos                    | Zookeeper                   |
| 使用方便                         | 性能好                      |
| 即将推出SpringCloud2.0           | 断档5年后17年重启           |

​	SpringBoot是Spring推出用于解决传统框架配置文件冗余,装配组件繁杂的基于Maven的解决方案,**旨在快速搭建单个微服务**，SpringCloud是依赖于SpringBoot的,而SpringBoot并不是依赖与SpringCloud,甚至还可以和Dubbo进行优秀的整合开发

​	MartinFlower 提出的微服务之间是通过RestFulApi进行通信，具体实现

- RestTemplate：基于HTTP协议
- Feign：封装了ribbon和Hystrix 、RestTemplate 简化了客户端开发工作量
- RPC：基于TCP协议，序列化和传输效率提升明显
- MQ：异步解耦微服务之间的调用

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmawejgpgwj30ht0bnt9d.jpg" alt="img" style="zoom:67%;" />

#### Spring Boot

> Spring Boot 通过**简单的步骤**就可以创建一个 Spring 应用。
>
> Spring Boot 为 Spring 整合第三方框架提供了**开箱即用功能**。
>
> Spring Boot 的核心思想是**约定大于配置**。

**Spring Boot 解决的问题**

- 搭建后端框架时需要手动添加 Maven 配置，涉及很多 XML 配置文件，增加了搭建难度和时间成本。

- 将项目编译成 war 包，部署到 Tomcat 中，项目部署依赖 Tomcat，这样非常不方便。

- 应用监控做的比较简单，通常都是通过一个没有任何逻辑的接口来判断应用的存活状态。

**Spring Boot 优点**

**自动装配：**Spring Boot 会根据某些规则对所有配置的 Bean 进行初始化。可以减少了很多重复性的工作。

​	比如使用 MongoDB 时，只需加入 MongoDB 的 Starter 包，然后配置  的连接信息，就可以直接使用 MongoTemplate 自动装配来操作数据库了。简化了 Maven Jar 包的依赖，降低了烦琐配置的出错几率。

**内嵌容器：**Spring Boot 应用程序可以不用部署到外部容器中，比如 Tomcat。

​	应用程序可以直接通过 Maven 命令编译成可执行的 jar 包，通过 java-jar 命令启动即可，非常方便。

**应用监控：**Spring Boot 中自带监控功能 Actuator，可以实现对程序内部运行情况进行监控，

​	比如 Bean 加载情况、环境变量、日志信息、线程信息等。当然也可以自定义跟业务相关的监控，通过Actuator 的端点信息进行暴露。

```java
spring-boot-starter-web          //用于快速构建基于 Spring MVC 的 Web 项目。
spring-boot-starter-data-redis   //用于快速整合并操作 Redis。
spring-boot-starter-data-mongodb //用于对 MongoDB 的集成。
spring-boot-starter-data-jpa     //用于操作 MySQL。
```

**自定义一个Starter**

1. 创建 Starter 项目，定义 Starter 需要的配置（Properties）类，比如数据库的连接信息；

2. 编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean；

3. 编写 spring.factories 文件加载自动配置类，Spring 启动的时候会扫描 spring.factories 文件，；

4. 编写配置提示文件 spring-configuration-metadata.json（不是必须的），在添加配置的时候，我们想要知道具体的配置项是什么作用，可以通过编写提示文件来提示；

5. 在项目中引入自定义 Starter 的 Maven 依赖，增加配置值后即可使用。

**Spring Boot Admin**（将 actuator 提供的数据进行可视化）

- 显示应用程序的监控状态、查看 JVM 和线程信息

- 应用程序上下线监控  

- 可视化的查看日志、动态切换日志级别

- HTTP 请求信息跟踪等实用功能



#### GateWay / Zuul

> GateWay⽬标是取代Netflflix Zuul，它基于Spring5.0+SpringBoot2.0+WebFlux等技术开发，提供**统⼀的路由**⽅式（反向代理）并且基于 **Filter**(定义过滤器对请求过滤，完成⼀些功能) 链的⽅式提供了⽹关基本的功能，例如：鉴权、流量控制、熔断、路径重写、⽇志监控。

**组成：**

- **路由route：** ⽹关最基础的⼯作单元。路由由⼀个ID、⼀个⽬标URL、⼀系列的断⾔（匹配条件判断）和Filter过滤器组成。如果断⾔为true，则匹配该路由。

- **断⾔predicates：**参考了Java8中的断⾔Predicate，匹配Http请求中的所有内容（类似于nginx中的location匹配⼀样），如果断⾔与请求相匹配则路由。

- **过滤器filter：**标准的Spring webFilter，使⽤过滤器在请求之前或者之后执⾏业务逻辑。

  请求前`pre`类型过滤器：做**参数校验**、**权限校验**、**流量监控**、**⽇志输出**、**协议转换**等，

  请求前`post`类型的过滤器：做**响应内容**、**响应头**的修改、**⽇志的输出**、**流量监控**等。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmc49l9babj31do0n7n13.jpg" alt="image-20210105001419761" style="zoom: 50%;" />

**GateWayFilter** 应⽤到单个路由路由上 、**GlobalFilter** 应⽤到所有的路由上











#### Eureka / Zookeeper

> 服务注册中⼼本质上是为了解耦服务提供者和服务消费者，为了⽀持弹性扩缩容特性，⼀个微服务的提供者的数量和分布往往是动态变化的。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmawwm3k7bj30o80ecq3u.jpg" alt="image-20210103231405882" style="zoom: 50%;" />

| 区别   | Zookeeper        | Eureka                       | Nacos              |
| ------ | ---------------- | ---------------------------- | ------------------ |
| CAP    | CP               | AP                           | CP/AP切换          |
| 可用性 | 选举期间不可用   | 自我保护机制，数据不是最新的 |                    |
| 组成   | Leader和Follower | 节点平等                     |                    |
| 优势   | 分布式协调       | 注册与发现                   | 注册中心和配置中心 |
| 底层   | 进程             | 服务                         | Jar包              |

**Eureka**通过**⼼跳检测**、**健康检查**和**客户端缓存**等机制，提⾼系统的灵活性、可伸缩性和可⽤性。

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaxc493qyj30ji0a6mxx.jpg" alt="image-20210103232900353" style="zoom:67%;" />

1. us-east-1c、us-east-1d，us-east-1e代表不同的机房，**每⼀个Eureka Server都是⼀个集群**。
2. Service作为服务提供者向Eureka中注册服务，Eureka接受到注册事件会在**集群和分区中进⾏数据同步**，Client作为消费端（服务消费者）可以从Eureka中获取到服务注册信息，进⾏服务调⽤。
3. 微服务启动后，会周期性地向Eureka**发送⼼跳**（默认周期为30秒）以续约⾃⼰的信息
4. Eureka在⼀定时间内**（默认90秒）没有接收**到某个微服务节点的⼼跳，Eureka将会注销该微服务节点
5. Eureka Client**会缓存Eureka Server中的信息**。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使⽤缓存中的信息找到服务提供者



**Eureka缓存**

> 新服务上线后，服务消费者**不能立即访问**到刚上线的新服务，需要过⼀段时间后才能访问？或是将服务下线后，服务还是会被调⽤到，⼀段时候后**才彻底停⽌服务**，访问前期会导致频繁报错！

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmaxmk97q0j30vw0j6gmu.jpg" alt="image-20210103233902439" style="zoom:50%;" />

​	服务注册到注册中⼼后，服务实例信息是**存储在Registry表**中的，也就是内存中。但Eureka为了提⾼响应速度，在内部做了优化，加⼊了两层的缓存结构，将Client需要的实例信息，直接缓存起来，获取的时候直接从缓存中拿数据然后响应给 Client。 

- 第⼀层缓存是**readOnlyCacheMap**，采⽤**ConcurrentHashMap**来存储数据的，主要负责定时与readWriteCacheMap进⾏数据同步，默认同步时间为 **30** 秒⼀次。

- 第⼆层缓存是**readWriteCacheMap**，采⽤**Guava**来实现缓存。缓存过期时间默认为**180**秒，当服务**下线、过期、注册、状态变更**等操作都会清除此缓存中的数据。

- 如果两级缓存都无法查询，会**触发缓存的加载**，从存储层拉取数据到缓存中，然后再返回给 Client。

  Eureka之所以设计⼆级缓存机制，也是为了**提⾼ Eureka Server 的响应速度**，缺点是缓存会导致 Client**获取不到最新的服务实例信息**，然后导致⽆法快速发现新的服务和已下线的服务。

**解决方案**

- 我们可以**缩短读缓存的更新时间**让服务发现变得更加及时，或者**直接将只读缓存关闭**，同时可以缩短客户端如ribbon服务的定时刷新间隔，多级缓存也导致C层⾯（数据⼀致性）很薄弱。
- Eureka Server 中会有**定时任务去检测失效**的服务，将服务实例信息从注册表中移除，也可以将这个失效检测的**时间缩短**，这样服务下线后就能够及时从注册表中清除。

**自我保护机制开启条件**

- 期望最小每分钟能够续租的次数（实例* 频率 * 比例==10* 2 *0.85）
- 期望的服务实例数量（10）

**健康检查**

- Eureka Client 会定时发送心跳给 Eureka Server 来证明自己处于健康的状态

- 集成SBA以后可以把所有健康状态信息一并返回给eureka

  

#### Feign / Ribbon

- Feign 可以与 Eureka 和 Ribbon 组合使用以支持负载均衡，
- Feign 可以与 Hystrix 组合使用，支持熔断回退
- Feign 可以与ProtoBuf实现快速的RPC调用

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmbxsh2rfnj30uo0fgmxz.jpg" alt="img" style="zoom:80%;" />

- **InvocationHandlerFactory 代理**

  采用 JDK 的动态代理方式生成代理对象，当我们调用这个接口，实际上是要去调用远程的 HTTP API

- **Contract 契约组件**

  比如请求类型是 GET 还是 POST，请求的 URI 是什么

- **Encoder 编码组件 \ Decoder 解码组件**

  通过该组件我们可以将请求信息采用指定的编码方式进行编解码后传输

- **Logger 日志记录**

  负责 Feign 中记录日志的，可以指定 Logger 的级别以及自定义日志的输出

- **Client 请求执行组件**

  负责 HTTP 请求执行的组件，Feign 中默认的 Client 是通过 JDK 的 HttpURLConnection 来发起请求的，在每次发送请求的时候，都会创建新的 HttpURLConnection 链接，Feign 的性能会很差，可以通过扩展该接口，使用 Apache HttpClient 等基于连接池的高性能 HTTP 客户端。

- **Retryer 重试组件**

  负责重试的组件，Feign 内置了重试器，当 HTTP 请求出现 IO 异常时，Feign 会限定一个最大重试次数来进行重试操作。

- **RequestInterceptor 请求拦截器**

  可以为 Feign 添加多个拦截器，在请求执行前设置一些扩展的参数信息。

**Feign最佳使用技巧**

- 继承特性

- 拦截器

  比如添加指定的请求头信息，这个可以用在服务间传递某些信息的时候。

- GET 请求多参数传递

- 日志配置

  FULL 会输出全部完整的请求信息。

- 异常解码器

  异常解码器中可以获取异常信息，而不是简单的一个code，然后转换成对应的异常对象返回。

- 源码查看是如何继承Hystrix

  HystrixFeign.builder 中可以看到继承了 Feign 的 Builder，增加了 Hystrix的SetterFactory， build 方法里，对 invocationHandlerFactory 进行了重写， create 的时候**返回HystrixInvocationHandler**， 在 invoke 的时候**会将请求包装成 HystrixCommand** 去执行，这里就自然的集成了 Hystrix



**Ribbon**

<img src="http://s0.lgstatic.com/i/image2/M01/93/96/CgotOV2Nux-AO2PcAAEcl4M1Zi4629.png" alt="img" style="zoom: 50%;" />



**使用方式**

- **原生 API**，Ribbon 是 Netflix 开源的，没有使用 Spring Cloud，需要使用 Ribbon 的原生 API。

- **Ribbon + RestTemplate**，整合Spring Cloud 后，可以基于 RestTemplate 提供负载均衡的服务

- **Ribbon + Feign**

  <img src="http://s0.lgstatic.com/i/image2/M01/93/76/CgoB5l2NuyCALoefAAAdV1DlSHY088.png" alt="img" style="zoom: 67%;" />

**负载均衡算法**

- RoundRobinRule 是**轮询的算法**，A和B轮流选择。

- RandomRule 是**随机算法**，这个就比较简单了，在服务列表中随机选取。

- BestAvailableRule 选择一个最**小的并发请求 server**

**自定义负载均衡算法**

- 实现 Irule 接口
- 继承 AbstractLoadBalancerRule 类

**自定义负载均衡使用场景**（核心）

- **灰度发布**

  灰度发布是能够平滑过渡的一种发布方式，在发布过程中，先发布一部分应用，让指定的用户使用刚发布的应用，等到测试没有问题后，再将其他的全部应用发布。如果新发布的有问题，只需要将这部分恢复即可，不用恢复所有的应用。

- **多版本隔离**

  多版本隔离跟灰度发布类似，为了兼容或者过度，某些应用会有多个版本，这个时候如何保证 1.0 版本的客户端不会调用到 1.1 版本的服务，就是我们需要考虑的问题。

- **故障隔离**

  当线上某个实例发生故障后，为了不影响用户，我们一般都会先留存证据，比如：线程信息、JVM 信息等，然后将这个实例重启或直接停止。然后线下根据一些信息分析故障原因，如果我能做到故障隔离，就可以直接将出问题的实例隔离，不让正常的用户请求访问到这个出问题的实例，只让指定的用户访问，这样就可以单独用特定的用户来对这个出问题的实例进行测试、故障分析等。



#### Hystrix / Sentinel

**服务雪崩场景**

自己即是服务消费者，同时也是服务提供者，同步调用等待结果导致资源耗尽

**解决方案**

服务方：扩容、限流，排查代码问题，增加硬件监控

消费方：使用Hystrix资源隔离，熔断降级，快速失败

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmby7y9ykzj30wr0ehac5.jpg" alt="img" style="zoom:150%;" />

**Hystrix断路保护器的作用**

- **封装请求**会将用户的操作进行统一封装，统一封装的目的在于进行统一控制。
- **资源隔离限流**会将对应的资源按照指定的类型进行隔离，比如**线程池**和**信号量**。
  - 计数器限流，例如5秒内技术1000请求，超数后限流，未超数重新计数
  - 滑动窗口限流，解决计数器不够精确的问题，把一个窗口拆分多滚动窗口
  - 令牌桶限流，类似景区售票，售票的速度是固定的，拿到令牌才能去处理请求
  - 漏桶限流，生产者消费者模型，实现了恒定速度处理请求，能够绝对防止突发流量
- **失败回退**其实是一个备用的方案，就是说当请求失败后，有没有备用方案来满足这个请求的需求。
- **断路器**这个是**最核心**的，，如果断路器处于打开的状态，那么所有请求都将失败，执行回退逻辑。如果断路器处于关闭状态，那么请求将会被正常执行。有些场景我们需要手动**打开断路器强制降级**。
- **指标监控**会对请求的生**命周期进行监控**，请求成功、失败、超时、拒绝等状态，都会被监控起来。

**Hystrix使用上遇到的坑**

- 配置可以对接**配置中心**进行动态调整

  Hystrix 的配置项非常多，如果不对接配置中心，所有的配置只能在代码里修改，在集群部署的难以应对紧急情况，我们项目只设置一个 CommandKey，其他的都在配置中心进行指定，紧急情况如需隔离部分请求时，只需在配置中心进行修改以后，强制更新即可。

- 回退逻辑中可以**手动埋点**或者通过**输出日志**进行告警

  当请求失败或者超时，会执行回退逻辑，如果有大量的回退，则证明某些服务出问题了，这个时候我们可以在回退的逻辑中进行埋点操作，上报数据给监控系统，也可以输出回退的日志，统一由日志收集的程序去进行处理，这些方式都可以将问题暴露出去，然后通过实时数据分析进行告警操作

- 用 **ThreadLocal**配合**线程池隔离**模式需当心

  当我们用了线程池隔离模式的时候，被隔离的方法会包装成一个 Command 丢入到独立的线程池中进行执行，这个时候就是从 A 线程切换到了 B 线程，ThreadLocal 的数据就会丢失

- **Gateway中**多用信号量隔离

  网关是所有请求的入口，路由的服务数量会很多，几十个到上百个都有可能，如果用线程池隔离，那么需要创建上百个独立的线程池，开销太大，用信号量隔离开销就小很多，还能起到限流的作用。
  
  

[^常见问题]: Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如重试3 次，Ribbon 的超时为 1 秒，那么Hystrix 的超时时间应该⼤于 3 秒，否则就会出现 Ribbon 还在重试中，⽽ Hystrix 已经超时的现象。



**Sentinel** 

> Sentinel是⼀个⾯向云原⽣微服务的流量控制、熔断降级组件。
>
> 替代Hystrix，针对问题：服务雪崩、服务降级、服务熔断、服务限流

Hystrix区别：

- 独⽴可部署Dashboard（基于 Spring Boot 开发）控制台组件
- 不依赖任何框架/库，减少代码开发，通过UI界⾯配置即可完成细粒度控制

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmbza4zixbj30kl09sq4p.jpg" alt="image-20210104212151598" style="zoom:80%;" />

**丰富的应⽤场景**：Sentinel 承接了阿⾥巴巴近 10 年的双⼗⼀⼤促流量的核⼼场景，例如秒杀、消息削峰填⾕、集群流量控制、实时熔断下游不可⽤应⽤等。

**完备的实时监控**：可以看到500 台以下规模的集群的汇总也可以看到单机的秒级数据。

**⼴泛的开源⽣态：**与 SpringCloud、Dubbo的整合。您只需要引⼊相应的依赖并进⾏简单的配置即可快速地接⼊ Sentinel。

**区别：**

- Sentinel不会像Hystrix那样放过⼀个请求尝试⾃我修复，就是明明确确按照时间窗⼝来，熔断触发后，时间窗⼝内拒绝请求，时间窗⼝后就恢复。
- Sentinel Dashboard中添加的规则数据存储在内存，微服务停掉规则数据就消失，在⽣产环境下不合适。可以将Sentinel规则数据持久化到Nacos配置中⼼，让微服务从Nacos获取。

| #              | Sentinel                                       | Hystrix                       |
| -------------- | ---------------------------------------------- | ----------------------------- |
| 隔离策略       | 信号量隔离                                     | 线程池隔离/信号量隔离         |
| 熔断降级策略   | 基于响应时间或失败比率                         | 基于失败比率                  |
| 实时指标实现   | 滑动窗口                                       | 滑动窗口（基于 RxJava）       |
| 扩展性         | 多个扩展点                                     | 插件的形式                    |
| 限流           | 基于 QPS，支持基于调用关系的限流               | 不支持                        |
| 流量整形       | 支持慢启动、匀速器模式                         | 不支持                        |
| 系统负载保护   | 支持                                           | 不支持                        |
| 控制台         | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善                        |
| 常见框架的适配 | Servlet、Spring Cloud、Dubbo、gRPC             | Servlet、Spring Cloud Netflix |





#### Config / Nacos

> Nacos是阿⾥巴巴开源的⼀个针对微服务架构中**服务发现**、**配置管理**和**服务管理平台**。
>
> Nacos就是**注册中⼼+配置中⼼**的组合（Nacos=Eureka+Confifig+Bus）
>

**Nacos**功能特性

- 服务发现与健康检查
- 动态配置管理
- 动态DNS服务
- 服务和元数据管理

**保护阈值：**

当服务A健康实例数/总实例数 < 保护阈值 的时候，说明健康实例真的不多了，这个时候保护阈值会被触发（状态true），nacos将会把该服务所有的实例信息（健康的+不健康的）全部提供给消费者，消费者可能访问到不健康的实例，请求失败，但这样也⽐造成雪崩要好，牺牲了⼀些请求，保证了整个系统的⼀个可⽤。

**Nacos** 数据模型（领域模型）

- **Namespace** 代表不同的环境，如开发dev、测试test、⽣产环境prod
- **Group** 代表某项⽬，⽐如爪哇云项⽬
- **Service** 某个项⽬中具体xxx服务
- **DataId** 某个项⽬中具体的xxx配置⽂件

可以通过 Spring Cloud 原⽣注解 `@RefreshScope` 实现配置⾃动更新



#### Bus / Stream

> Spring Cloud Stream 消息驱动组件帮助我们更快速，更⽅便的去构建**消息驱动**微服务的
>
> 本质：屏蔽掉了底层不同**MQ**消息中间件之间的差异，统⼀了**MQ**的编程模型，降低了学习、开发、维护**MQ**的成本，⽬前⽀持Rabbit、Kafka两种消息



#### **Sleuth / Zipkin**

**全链路追踪**

<img src="https://tva1.sinaimg.cn/large/0081Kckwly1gmc3avezqrj30xb0lw76z.jpg" alt="image-20210104234058218" style="zoom:67%;" />

**Trace ID**：当请求发送到分布式系统的⼊⼝端点时，Sleuth为该请求创建⼀个唯⼀的跟踪标识Trace ID，在分布式系统内部流转的时候，框架始终保持该唯⼀标识，直到返回给请求⽅

**Span ID**：为了统计各处理单元的时间延迟，当请求到达各个服务组件时，也是通过⼀个唯⼀标识SpanID来标记它的开始，具体过程以及结束。

Spring Cloud Sleuth （追踪服务框架）可以追踪服务之间的调⽤，Sleuth可以记录⼀个服务请求经过哪些服务、服务处理时⻓等，根据这些，我们能够理清各微服务间的调⽤关系及进⾏问题追踪分析。

**耗时分析**：通过 Sleuth 了解采样请求的耗时，分析服务性能问题（哪些服务调⽤⽐较耗时）

**链路优化**：发现频繁调⽤的服务，针对性优化等

**聚合展示**：数据信息发送给 Zipkin 进⾏聚合，利⽤ Zipkin 存储并展示数据。



### **安全认证**

- Session

  认证中最常用的一种方式，也是最简单的。存在**多节点session丢失**的情况，可通过**nginx粘性Cookie**和Redis集中式Session存储解决

- HTTP Basic Authentication 

  服务端针对请求头中base64加密的Authorization 和用户名和密码进行**校验**。

- Token

  Session 只是一个 key，**会话信息存储在后端**。而 Token 中会存储用户的信息，然后通过加密算法进行加密，只有服务端才能解密，**服务端拿到 Token 后进行解密获取用户信息**。

- JWT认证

> JWT（JSON Web Token）用户提供用户名和密码给认证服务器，服务器验证用户提交信息的合法性；如果验证成功，会产生并返回一个 Token，用户可以使用这个 Token 访问服务器上受保护的资源。

<img src="http://s0.lgstatic.com/i/image2/M01/AB/87/CgotOV3WUG2ARl98AAD_xcd-ElM857.png" alt="img" style="zoom:70%;" />

1. 认证服务提供认证的 API，校验用户信息，返回认证结果
2. 通过JWTUtils中的RSA算法，生成JWT token，token里封装用户id和有效期
3. 服务间参数通过请求头进行传递，服务内部通过 ThreadLocal 进行上下文传递。
4. Hystrix导致ThreadLocal失效的问题可以通过，重写 Hystrix 的 Callable 方法，传递需要的数据。

**Token最佳实践**

- 设置**较短（合理）的过期时间**。

- 注销的 Token **及时清除**（放入 Redis 中做一层过滤）。

  虽然不能修改 Token 的信息，但是能在验证层面做一层过滤来进行处理。

- 监控 Token 的**使用频率**。

  为了防止数据被别人爬取，最常见的就是监控使用频率，程序写出来的爬虫程序访问频率是有迹可循的 

- 核心功能敏感操作可以使用**动态验证**（验证码）。

  比如提现的功能，要求在提现时再次进行验证码的验证，防止不是本人操作。

- **网络环境、浏览器**信息等识别。

  银行 APP 对环境有很高的要求，使用时如果断网，APP 会自动退出，重新登录，因为网络环境跟之前使用的不一样了，还有一些浏览器的信息之类的判断，这些都是可以用来保证后端 API 的安全。

- **加密密钥**支持动态修改。

  如果 Token 的加密密钥泄露了，也就意味着别人可以伪造你的 Token，可以将密钥存储在配置中心，以支持动态修改刷新，需要注意的是建议在流量低峰的时候去做更换的操作，否则 Token 全部失效，所有在线的请求都会重新申请 Token，并发量会比较大。



### 灰度发布

**痛点：**

- 服务数量多，业务变动频繁，一周一发布

- 灰度发布能降低发布失败风险，**减少影响范围**

  通过灰度发布，先让一部分用户体验新的服务，或者只让测试人员进行测试，等功能正常后再全部发布，这样能降低发布失败带来的影响范围。 

- 当发布出现故障时，可以**快速回滚**，不影响用户

  灰度后如果发现这个节点有问题，那么只需回滚这个节点即可，当然不回滚也没关系，通过灰度策略隔离，也不会影响正常用户

可以通过Ribbon的负载均衡策略进行灰度发布，可以使用更可靠的Discovery

**Discovery**

> 基于Discovery 服务注册发现、Ribbon 负载均衡、Feign 和 RestTemplate 调用等组件的企业级微服务开源解决方案，包括灰度发布、灰度路由、服务隔离等功能

<img src="https://s0.lgstatic.com/i/image3/M01/54/41/CgpOIF3nXSaAB9bRAAE8rktrUyY037.png" alt="img" style="zoom:50%;" />

1. 首先将需要发布的服务从转发过程中移除，等流量剔除之后再发布。

2. 部分机器中的版本进行升级，用户默认还是请求老的服务，通过版本来支持测试请求。

3. 测试完成之后，让新的版本接收正常流量，然后部署下一个节点，以此类推。

```java
grayVersions = {"discovery-article-service":["1.01"]}
```



### 多版本隔离



<img src="https://s0.lgstatic.com/i/image3/M01/54/41/Cgq2xl3nXSeAZMTOAAE2sCaIhPE668.png" alt="img" style="zoom:50%;" />



**本地复用测试服务**-Eureka Zone亮点

​	**region** 地理上的分区，比如北京、上海等

​	**zone** 可以简单理解为 region 内的具体机房

​	在调用的过程中会优先选择相同的 zone 发起调用，当找不到相同名称的 zone 时会选择其他的 zone 进行调用，我们可以利用这个特性来解决本地需要启动多个服务的问题。

[^]: 当你访问修改的服务 A 时，这个服务依赖了 B、C 两个服务，B 和 C 本地没有启动，B 和 C 找不到相同的 zone 就会选择其他的 zone 进行调用，也就是会调用到测试环境部署的 B 和 C 服务，这样一来就解决了本地部署多个服务的问题。



#### **各组件调优**

当你对网关进行压测时，会发现并发量一直上不去，错误率也很高。因为你用的是默认配置，这个时候我们就需要去调整配置以达到最优的效果。

首先我们可以对容器进行调优，最常见的就是**内置的 Tomcat** 容器了，

```java
server.tomcat.accept-count //请求队列排队数
server.tomcat.max-threads //最大线程数
server.tomcat.max-connections //最大连接数
```

**Hystrix** 的信号量（semaphore）隔离模式，并发量上不去很大的原因都在这里，信号量默认值是 100，也就是最大并发只有 100，超过 100 就得等待。

```java
//信号量
zuul.semaphore.max-semaphores //信号量：最大并发数
//线程池
hystrix.threadpool.default.coreSize //最大线程数
hystrix.threadpool.default.maximumSize //队列的大
hystrix.threadpool.default.maxQueueSize //等参数
```

配置**Gateway**并发信息，

```java
gateway.host.max-per-route-connections //每个路由的连接数 
gateway.host.max-total-connections //总连接数
```

调整**Ribbon** 的并发配置，

```java
ribbon.MaxConnectionsPerHost //单服务并发数
ribbon.MaxTotalConnections   //总并发数
```

修改**Feign**默认的HttpURLConnection 替换成 httpclient 来提高性能

```java
feign.httpclient.max-connections-per-route//每个路由的连接数
feign.httpclient.max-connections //总连接数
```

Gateway+配置中心实现动态路由

Feign+配置中心实现动态日志



# **九、分布式篇**

> 分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。
>

### **发展历程**

- 入口级负载均衡
  - 网关负载均衡
  - 客户端负载均衡
- 单应用架构
  - 应用服务和数据服务分离
  - 应用服务集群
  - 应用服务中心化SAAS

- 数据库主备读写分离
  - 全文搜索引擎加快数据统计
  - 缓存集群缓解数据库读压力
  - 分布式消息中间件缓解数据库写压力
  - 数据库水平拆分适应微服务
  - 数据库垂直拆分解决慢查询

- 划分上下文拆分微服务
  - 服务注册发现（Eureka、Nacos）
  - 配置动态更新（Config、Apollo）
  - 业务灰度发布（Gateway、Feign）
  - 统一安全认证（Gateway、Auth）
  - 服务降级限流（Hystrix、Sentinel）
  - 接口检查监控（Actuator、Prometheus）
  - 服务全链路追踪（Sleuth、Zipkin）



### CAP

- **一致性**（2PC、3PC、Paxos、Raft）
  - 强一致性：**数据库一致性**，牺牲了性能
    - **ACID**：原子性、一致性、隔离性、持久性
  - 弱一致性：**数据库和缓存**，**延迟双删、重试**
  - 单调读一致性：**缓存一致性**，ID或者IP哈希
  - 最终一致性：**边缘业务**，消息队列
- **可用性**（多级缓存、读写分离）
  - **BASE** 基本可用：限流导致响应速度慢、降级导致用户体验差
    - Basically Availabe 基本可用  
    - Soft state 软状态
    - Eventual Consistency 最终一致性
- 分区容忍性（一致性Hash解决扩缩容问题）



### 一致性

#### XA方案

**2PC**协议：两阶段提交协议，P是指**准备**阶段，C是指**提交**阶段

- 准备阶段：询问是否可以开始，写Undo、Redo日志，收到响应
- 提交阶段：执行Redo日志进行**Commit**，执行Undo日志进行**Rollback** 



**3PC**协议：将提交阶段分为**CanCommit**、**PreCommit**、**DoCommit**三个阶段

**CanCommit**：发送canCommit请求，并开始等待

**PreCommit**：收到全部Yes，写Undo、Redo日志。超时或者No，则中断

**DoCommit**：执行Redo日志进行**Commit**，执行Undo日志进行**Rollback** 

区别是第二步，参与者**自身增加了超时**，如果**失败可以及时释放资源**



#### **Paxos算法**

> 如何在一个发生异常的分布式系统中，快速且正确地在集群内部对某个数据的值达成一致

​	参与者（例如Kafka）的一致性可以由协调者（例如Zookeeper）来保证，**协调者的一致性就只能由Paxos保证了**

Paxos算法中的角色：

- **Client**：客户端、例如，对分布式文件服务器中文件的写请求。
- **Proposer**：提案发起者，根据Accept返回选择最大N对应的V，发送[N+1,V]
- **Acceptor**：决策者，Accept以后会拒绝小于N的提案，并把自己的[N,V]返回给Proposer
- **Learners**：最终决策的学习者、学习者充当该协议的复制因素

```java
//算法约束
P1:一个Acceptor必须接受它收到的第一个提案。
//考虑到半数以上才作数，一个Accpter得接受多个相同v的提案
P2a:如果某个v的提案被accept，那么被Acceptor接受编号更高的提案必须也是v
P2b:如果某个v的提案被accept，那么从Proposal提出编号更高的提案必须也是v
//如何确保v的提案Accpter被选定后，Proposal都能提出编号更高的提案呢
针对任意的[Mid,Vid]，有半数以上的Accepter集合S，满足以下二选一：
  S中接受的提案都大于Mid
  S中接受的提案若小于Mid，编号最大的那个值为Vid
```

![image-20210112225118095](https://tva1.sinaimg.cn/large/008eGmZEly1gmlato63bnj319m0u0wmi.jpg)

面试题：如何保证Paxos算法活性

​	假设存在这样一种极端情况，有两个Proposer依次提出了一系列编号递增的提案，导致最终陷入死循环，没有value被选定

- **通过选取主Proposer**，规定只有主Proposer才能提出议案。只要主Proposer和过半的Acceptor能够正常网络通信，主Proposer提出一个编号更高的提案，该提案终将会被批准。
- 每个Proposer发送提交提案的时间设置为**一段时间内随机**，保证不会一直死循环



#### **ZAB算法**

#### Raft算法

> Raft 是一种为了管理复制日志的一致性算法

Raft使用**心跳机制**来触发选举。当server启动时，初始状态都是**follower**。每一个server都有一个定时器，超时时间为election timeout（**一般为150-300ms**），如果某server**没有超时的情况下收到**来自领导者或者候选者的任何消息，**定时器重启**，如果超时，它就**开始一次选举**。

**Leader异常**：异常期间Follower会超时选举，完成后Leader比较彼此步长

**Follower异常：**恢复后直接同步至Leader当前状态

**多个Candidate：**选举时失败，失败后超时继续选举



#### 数据库和Redis的一致性

**全量缓存保证高效读取**

<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185425386.png" alt="image-20210418185425386" style="zoom:50%;" />

所有数据都存储在缓存里，读服务在查询时不会再降级到数据库里，所有的请求都完全依赖缓存。此时，因降级到数据库导致的毛刺问题就解决了。但全量缓存并**没有解决更新时的分布式事务**问题，反而把问题放大了。因为全量缓存**对数据更新要求更加严格**，要求所有数据库**已有数据和实时更新**的数据必须完全同步至缓存，不能有遗漏。对于此问题，一种有效的方案是采用**订阅数据库的 Binlog** 实现数据同步

<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185457610.png" alt="image-20210418185457610" style="zoom:50%;" />

​	现在很多开源工具（如**阿里的 Canal**等）可以模拟主从复制的协议。通过模拟协议读取主数据库的 Binlog 文件，从而获取主库的所有变更。对于这些变更，它们开放了各种接口供业务服务获取数据。

<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185516743.png" alt="image-20210418185516743" style="zoom:50%;" />

​	将 Binlog 的中间件挂载至目标数据库上，就可以**实时获取该数据库的所有变更数据**。对这些变更数据解析后，便可**直接写入缓存里**。优点还有：

- 大幅提升了读取的速度，降低了延迟

- Binlog 的主从复制是基于 **ACK** 机制， 解决了分布式事务的问题

  如果同步缓存失败了，被消费的 Binlog 不会被确认，下一次会重复消费，数据最终会写入缓存中

**缺点**不可避免：1、增加复杂度 2、消耗缓存资源 3、需要筛选和压缩数据 4、极端情况数据丢失

<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185549520.png" alt="image-20210418185549520" style="zoom:50%;" />

可以通过异步校准方案进行补齐，但是会损耗数据库性能。但是此方案会隐藏中间件使用错误的细节，线上环境前期更重要的是记录日志排查在做后续优化，不能本末倒置。



### 可用性

#### **心跳检测**

> 以**固定的频率**向其他节点汇报当前节点状态的方式。收到心跳，说明网络和节点的状态是健康的。心跳汇报时，一般会携带一些附加的**状态、元数据，以便管理**

**周期检测心跳机制**：超时未返回

**累计失效检测机制**：重试超次数



#### **多机房实时热备**

<img src="/Users/suhongliu/Library/Application Support/typora-user-images/image-20210418185610597.png" alt="6.png" style="zoom:50%;" />

两套缓存集群可以分别部署到不同城市的机房。读服务也相应地部署到不同城市或不同分区。在承接请求时，不同机房或分区的读服务只依赖同样属性的缓存集群。此方案有两个好处。

1. **提升了性能。**读服务不要分层，读服务要尽可能地和缓存数据源靠近。
2. **增加了可用。**当单机房出现故障时，可以秒级将所有流量都切换至存活的机房或分区

此方案虽然带来了性能和可用性的提升，但代价是资源成本的上升。











### 分区容错性

> 分布式系统对于错误包容的能力

通过限流、降级、兜底、重试、负载均衡等方式增强系统的健壮性

#### 日志复制

![image-20210114154435003](https://i.loli.net/2021/01/14/fmYEJy9N7Zjp2Xd.png)

1. **Leader**把指令添加到日志中，发起 RPC 给其他的服务器，让他们复制这条信息
2. **Leader**会不断的重试，直到所有的 Follower响应了ACK并复制了所有的日志条目
3. 通知所有的**Follower**提交，同时Leader该表这条日志的状态，并返回给客户端



#### **主备（Master-Slave）**

​	主机宕机时，备机接管主机的一切工作，主机恢复正常后，以自动（**热备**）或手动（**冷备**）方式将服务切换到主机上运行，**Mysql**和**Redis**中常用。

​	MySQL之间数据复制的基础是**二进制日志文件**（binary log fifile）。它的数据库中所有操作都会以**“事件”**的方式记录在二进制日志中，其他数据库作为slave通过一个**I/O线程与主服务器保持通信**，并**监控**master的二进制日志文件的变化，如果发现master二进制日志文件**发生变化**，则会把变化复制到自己的**中继日志**中，然后slave的一个SQL线程会把相关的“事件”**执行**到自己的数据库中，以此实现从数据库和主数据库的**一致性**，也就实现了**主从复制**



#### **互备（Active-Active）**

​	指两台主机**同时运行**各自的服务工作且**相互监测**情况。在数据库高可用部分，常见的互备是**MM**模式。MM模式即**Multi-Master**模式，指一个系统存在多个master，每个master都具有**read-write**能力，会根据**时间戳**或**业务逻辑**合并版本。



#### **集群（Cluster）模式**

​	是指有多个节点在运行，同时可以通过主控节点**分担服务**请求。如Zookeeper。集群模式需要解决主控节点**本身的高可用**问题，一般采用主备模式。



### 分布式事务

#### XA方案 

**两阶段提交** | **三阶段提交**

- 准备阶段的资源锁定，存在性能问题，严重时会造成死锁问题
- 提交事务请求后，出现网络异常，部分数据收到并执行，会造成一致性问



#### TCC方案 

**Try Confirm Cancel / 短事务**

- **Try** 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行**锁定或者预留**

- **Confirm** 阶段：这个阶段说的是在各个服务中**执行实际的操作**

- **Cancel** 阶段：如果任何一个服务的业务方法执行出错，那么就需要**进行补偿**/回滚

  

#### **Saga方案** 

事务性补偿 / 长事务

- 流程**长**、流程**多**、调用第三方业务

  

#### **本地消息表（eBay）**

#### **MQ最终一致性**	

<img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmr1k3dfbxj31h00pkjy8.jpg" alt="image-20210117220405706" style="zoom:50%;" />

比如阿里的 RocketMQ 就支持消息事务（核心：**双端确认，重试幂等**）

1. A**(订单)** 系统先发送一个 **prepared** 消息到 mq，prepared 消息发送失败则取消操作不执行了
2. 发送成功后，那么执行本地事务，执行成功和和失败发送**确认和回滚**消息到mq
3. 如果发送了确认消息，那么此时 B**(仓储)** 系统会接收到确认消息，然后执行本地的事务
4. mq 会自动**定时轮询**所有 prepared 消息回调的接口，确认事务执行状态
5.  B 的事务失败后自动**不断重试**直到成功，达到一定次数后发送报警由人工来**手工回滚**和**补偿**



#### 最大努力通知方案（订单 -> 积分）

1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
2. 这里会有个专门消费 MQ 的**最大努力通知服务**，接着调用系统 B 的接口；
3. 要是系统 B 执行失败了，就定时尝试重新调用系统 B，**反复 N 次**，最后还是不行就**放弃**



你找一个严格**资金**要求绝对不能错的场景，你可以说你是用的 **TCC 方案**；

如果是一般的分布式事务场景，例如**积分**数据，可以用可靠消息**最终一致性方案**

如果分布式场景**允许不一致**，可以使用最大努力通知方案



### 面试题

#### 分布式Session实现方案

- 基于JWT的Token，数据从cache或者数据库中获取
- 基于Tomcat的Redis，简单配置conf文件
- 基于Spring的Redis，支持SpringCloud和Springb
