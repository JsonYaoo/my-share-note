# **十三、云原生篇**

### 1.1. 什么是云原生？

**云原生**，从字面上可分为云和原生两部分。

- **云**：和本地是相对的，使用云服务器相对于本地服务器，具有即买即用、租用成本低、有专门人员维护等优势。
- **原生**：土生土长的意思，应用运行在云环境中，可充分利用云资源弹性伸缩和分布式的优点。

可以简单地理解为：**云原生 = 微服务 + DevOps（开发即运维） + 持续交付（CI / CD） + 容器化**。

![1647417707915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647417707915.png)

### 1.2. 容器化技术出现原因？

1. **码头林立**：各种软硬件平台层出不穷，需要有一种的"**集装箱**"（Container）技术，来做统一的兼容器处理，这种"集装箱"技术，就是**容器化技术**。

   ![1647486093741](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486093741.png)

2. **微服务盛行**：

   - 1）微服务高可用，导致虚机需求数量多。
   - 2）每个微服务各自的环境需求差异大，比如 CPU 业务型、GPU 计算型、高吞吐 I/O 型。
   - 3）服务启动速度要求高。

   ![1647486158358](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486158358.png)

3. **DevOps 开发即运维文化盛行**：让开发处理专业的运维不现实，需要有一种简单的界面和处理方式，让开发就能进行各环境发布。

![1647486327631](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486327631.png)

### 1.3. 容器化技术演进历程？

![1647487118696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647487118696.png)

1. **猿人阶段**：W PAR，大型机独立任务管理。
2. **智人阶段**：Linux Namespace Group，Linux 资源控制制度，比如内核态用户态隔离。
3. **山顶洞人阶段**：Linux Container，LXC，Linux 容器隔离。
4. **现代人阶段**：Docker、Cloud  Foundry，成熟的容器化技术。
5. **未来阶段**：可能不会太关注某一个容器技术，而是立足于抽象技术，比如：
   - 1）平台化容器编排、Paas 公有云服务。
   - 2）ServerLess 无服务器化 （Lambda、Function）。
   - 3）容器技术生态圈化。

### 1.4. 什么是容器？

1. 容器，是一种轻量级的、可移植的、自包含的软件打包技术，使应用程序可以在几乎任何地方、以相同的方式运行。
2. 开发人员在自己笔记本上，创建并测试好的容器，无需任何修改，就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。

### 1.5. 容器 vs 虚拟机？

**相同点**：两者都是为应用提供封装和隔离。

**不同点**：

1. **容器**，由应用本身和应用依赖两部分组成，在操作系统的用户空间运行，与其他进程相互隔离，所有容器共享同一个操作系统，体积比虚拟机小，启动速度快，开销小，更容易迁移。
2. 而**虚拟机**，由部署应用、依赖以及操作系统组成，启动时，需要启动整个虚拟机操作系统，开销更大，启动速度慢。

### 1.5. 什么是 Docker？

![1647494464489](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647494464489.png)

Docker，go 语言开发，思想如 logo 一样，集装箱 Container 容器，主要任务是负责容器的运行和管理，通过隔离机制，使得每个容器间互不影响，以及通过限制每个容器的 CPU、内存和 I/O 资源，还能最大程度地压榨服务器资源。

### 1.6. Docker  vs VM？

![1647495378749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495378749.png)

1. VM 是虚拟机技术，而 Docker 是容器化技术。
2. VM 虚拟出完整的操作系统，而 Docker 则直接运行在宿主机的内核之上，没有自己的内核和虚拟硬件，更加小巧轻便，可以更高效地利用宿主机的资源。
3. VM 比 Docker 更重，更消耗资源，启动速度也远比 Docker 要慢，Docker 可以实现更快速的运维部署，更便捷的升级以及扩容和缩容。

### 1.7. Docker 架构原理？

![1647495796223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495796223.png)

#### 1）Client

 Docker 客户端模块，用于运行 Docker 命令以及 Restful API。

#### 2）Docker host

Docker 服务器模块，存在一个 Docker Daemon 后台进程，负责整个 Docker 容器的生命周期管理，连接 Registry 下载镜像，以及提供 Client 的 API 端口来处理发送过来的命令。

#### 3）Registry

Docker 镜像仓库。

Docker Hub：官方公有的镜像仓库。

https://hub.docker.com

Docker Datacenter：Docker 企业信任仓库。

Docker 私有仓库：内网自建仓库。

#### 4）Images

Docker 镜像，可本地制作，也可来源于镜像仓库，是容器运行前代码、配置、环境变量、操作系统资源的打包，运行起来了之后叫做容器，类似于 VM 的配置模板，通过 UnionFS 联合文件系统，支持镜像的一层层叠加。

![1647499834535](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647499834535.png)

#### 5）Containers

Docker 容器，每个容器共享主机的操作系统，通过 namespace 对 pid 进程、net 网络、ipc 信号量、mnt 文件系统、uts 用户组等进行**隔离**，通过 cgroup 对每个容器的 cpu、mem、io 等资源进行**限制**。

### 1.8. 如何使用 Docker？

![1647496057218](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647496057218.png)

#### 一、基本命令

##### 1）安装 Docker

```shell
sudo yum install docker-ce docker-ce-cli containerd.io
```

##### 2）启动 Docker

```shell
sudo systemctl start docker
```

##### 3）重新加载 Docker 配置

```shell
sudo systemctl daemon-reload
```

##### 4）重启 Docker

```shell
sudo systemctl restart docker
```

##### 5）查看 Docker 版本

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker version
Client: Docker Engine - Community
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.13.15  # go语⾔实现的
 Git commit:        48d30b5
 Built:             Fri Jan 29 14:33:08 2021
 OS/Arch:           linux/amd64
```

##### 6）查看 Docker 基本信息

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker info
Client:
 Context:    default
 Debug Mode: false
 Plugins:
  app: Docker App (Docker Inc., v0.9.1-beta3)
  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)
 
Server:
 Containers: 2   # 有容器两个
  Running: 1    # 1个运⾏中
  Paused: 0
  Stopped: 1    # 1个停⽌
 Images: 26
 Server Version: 20.10.3
 Storage Driver: overlay2
```

##### 7）查看 Docker 帮助命令

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps --help
 
Usage:  docker ps [OPTIONS]
List containers
Options:
  -a, --all             Show all containers (default shows just running)
  -f, --filter filter   Filter output based on conditions provided
      --format string   Pretty-print containers using a Go template
  -n, --last int        Show n last created containers (includes all 
states) (default -1)
  -l, --latest          Show the latest created container (includes all 
states)
      --no-trunc        Don't truncate output
  -q, --quiet           Only display container IDs
  -s, --size            Display total file sizes
```

##### 8）查看运行中的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps
CONTAINER ID   IMAGE          COMMAND       CREATED       STATUS       
PORTS     NAMES
bcd0201753a9   300e315adb2f   "/bin/bash"   6 hours ago   Up 6 hours       
      flamboyant_dirac
```

##### 9）查询所有的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps -a
CONTAINER ID   IMAGE          COMMAND       CREATED         STATUS         
            PORTS     NAMES
360354ed578c   hello-world    "/hello"      3 minutes ago   Exited (0) 3 
minutes ago             exciting_galois
bcd0201753a9   300e315adb2f   "/bin/bash"   6 hours ago     Up 6 hours     
                      flamboyant_dirac
```

##### 10）查看容器的进程状态

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker top bcd0201753a9
UID                 PID                 PPID                C               
    STIME               TTY                 TIME                CMD
root                13445               13426               0               
    14:38               pts/0               00:00:00            /bin/bash
root                13738               13426               0               
    14:50               pts/1               00:00:00            /bin/bash
root                13877               13426               0               
    14:52               ?                   00:00:00            /bin/bash
```

##### 11）查看所有容器的状态

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker stats
 
$ docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 
"discovery.type=single-node" elasticsearch:7.10.1
 
$ docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 
"discovery.type=single-node" -e ES_JAVA_OPTS="-Xms64m -Xmx512m" 
elasticsearch:7.10.1
```

##### 12）查看某个容器的元数据信息

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker inspect bcd0201753a9
[
    {
        "Id": 
"bcd0201753a943336ec4c5612e4a4e36388207d03e5d039472101880ef98c514",
        "Created": "2021-03-07T06:37:08.166894239Z",
        "Path": "/bin/bash",
        "Args": [],
        "State": {
            "Status": "running",
            "Running": true,
            "Paused": false,
```

##### 13）开启新的终端，进入容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker exec -it 7719397b904b 
/bin/bash
[root@7719397b904b /]# pwd
/
```

##### 14）复用已有终端，进入容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker attach 7719397b904b
[root@7719397b904b usr]# pwd
/usr
```

##### 15）拷贝主机文件到容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker cp /home/muse/test/a.txt 
7719397b904b:/
```

##### 16）拷贝容器文件到主机

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker cp 7719397b904b:/a.txt 
/home/muse/test
```

#### 二、镜像命令

##### 1）配置镜像源

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# cat /etc/docker/daemon.json
{
  "registry-mirrors": ["https://aa25jngun.mirror.aliyuncs.com"]
}
```

##### 2）列出本机的所有镜像

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker images
REPOSITORY         TAG        IMAGE ID       CREATED         SIZE
muse/centos        1.0        eb78333356a6   2 days ago      209MB
redis01            latest     84a8d576c57d   2 weeks ago     104MB
mysql              5.7        a70d36bc331a   6 weeks ago     449MB
rabbitmq           latest     7471fb821b97   7 weeks ago     167MB
```

##### 3）搜索镜像

https://hub.docker.com

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker search mysql
NAME                              DESCRIPTION                               
      STARS     OFFICIAL   AUTOMATED
mysql                             MySQL is a widely used, open-source 
relation…   10583     [OK]
mariadb                           MariaDB Server is a high performing open 
sou…   3960      [OK]
mysql/mysql-server                Optimized MySQL Server Docker images. 
Create…   776                  [OK]
percona                           Percona Server is a fork of the MySQL 
relati…   527       [OK]
centos/mysql-57-centos7           MySQL 5.7 SQL database server             
      87
```

##### 4）拉取最新镜像

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker pull rabbitmq
Using default tag: latest
latest: Pulling from library/rabbitmq
f22ccc0b8772: Pull complete
3cf8fb62ba5f: Pull complete
e80c964ece6a: Pull complete
c1d2d6c5864b: Pull complete
0adcf6f8f5f2: Pull complete
6d7425e3abe0: Pull complete
b03e46685eee: Pull complete
f83c4b83a829: Pull complete
fab4bdeccdff: Pull complete
02221abafa2c: Pull complete
Digest: 
sha256:5a6e86289ee2d03a6889341bfb3a76943de1d0c4d01b777c4159a944d8d3e9cd
Status: Downloaded newer image for rabbitmq:latest
docker.io/library/rabbitmq:latest
```

##### 5）拉取指定版本的镜像

```shell
docker pull mysql:5.7
```

##### 6）删除镜像

```shell
docker rmi -f [IMAGE ID]
docker rmi -f [IMAGE ID] [IMAGE ID] [IMAGE ID] [IMAGE ID]
docker rmi -f $(docker images -aq)
```

##### 7）Docker File 镜像制作

```shell
# 1、在/home/muse下，构造dockerfiles文件夹和dockerfile01文件

# 2、编写DockerFile（命令大写）
FROM centos
VOLUME ["muse01","muse02"]
CMD echo "------finish------"
CMD /bin/bash

# 3、构造镜像
# -f: 指定生成的Dockerfile路径
# -t：指定生成镜像的标签
docker build -f /home/muse/dockerfiles/dockerfile01 -t muse/centos:1.0 .

# 4、启动自己构建的镜像
# => 通过docker images查询出IMAGE ID为eb78333356a6
docker run -it eb78333356a6 /bin/bash
```

#### 三、容器命令

对容器进行生命周期管理。

##### 1）运行镜像、生成容器、进入容器

可用 `ctrl+p+q` 跳出容器。

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker run -it centos
```

##### 2）交互方式运行容器

```shell
docker run -it centos
```

##### 3）后台方式运行容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker run -d --name nginx1 -p 1111:80 
nginx
```

##### 4）强制删除运行中的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker rm -f c72b6628c15e
```

##### 5）关闭容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker stop e589400741f2
e589400741f2

# 或者杀死容器进程
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker kill e589400741f2
e589400741f2
```

##### 6）暂停容器

```shell
docker pause 398edf535ba8  
docker unpause 398edf535ba8  
```

##### 7）启动容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker start e589400741f2
e589400741f2
```

##### 8）重启容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker restart e589400741f2
e589400741f2
```

#### 四、数据卷命令

1. 由于 Docker 把应用和环境进行了打包，如果删掉容器的话，数据也会被同时删掉。
2. 如果需要**持久化**容器数据，或者容器之间进行**数据共享**的话，那么就可以使用**容器数据卷**。

![1647500082189](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500082189.png)

##### 1）查看挂载列表

```shell
docker volume ls
```

![1647500564024](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500564024.png)

##### 2）查看挂载元数据

```shell
docker volume inspect [VOLUME]
```

![1647500831275](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500831275.png)

##### 3）匿名挂载并执行容器

- **-d**：表示后台执行容器。
- **-P**：表示随机映射容器端口。
- **--name**：表示容器名称。
- **-v** ：指定 `：容器内部路径`。

```shell
docker run -d -P --name nginx1 -v :/etc/nginx nginx
```

![1647501166696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647501166696.png)

##### 4）具名挂载并执行容器 | 常用

- **-v** ：指定 `主机路径：容器内部路径`。

```shell
docker run -d -P --name nginx2 -v nginx2:/etc/nginx nginx
```

##### 5）数据卷容器

1. 数据卷容器，顾名思义，就是挂载另一个容器中已经创建好的数据卷。
2. 如果有一些持续更新的数据，需要在容器之间共享，最好创建数据卷容器。
3. 所以，其实数据卷容器就是一个正常的容器，专门用来提供数据卷，让其它容器挂载。

```shell
# 创建一个数据卷，—volumes-from参数，并不需要所挂载数据卷的容器保持运行状态
$ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres
734273f9ec0b0cf743a79a9da7b27b269ff9c34a02ec17d3df158cf0e3cedcd2
$ sudo docker ps -a
CONTAINER ID        IMAGE              COMMAND                CREATED             STATUS                     PORTS         NAMES
734273f9ec0b        training/postgres  "/docker-entrypoint.   17 seconds ago      Exited (0) 15 seconds ago                dbdata

# 创建容器，挂载该数据卷
# 如果删除了挂载的容器（包括 dbdata、db1 和 db2），数据卷并不会被自动删除。
# 如果要删除一个数据卷，必须删除最后一个还挂载着它的容器，可以使用docker rm -v命令来指定同时删除关联的容器
$ sudo docker run -d --volumes-from dbdata --name db1 training/postgres
$ sudo docker run -d --volumes-from dbdata --name db2 training/postgres
$ sudo docker ps
CONTAINER ID       IMAGE                COMMAND                CREATED             STATUS              PORTS               NAMES
7348cb189292       training/postgres    "/docker-entrypoint.   11 seconds ago      Up 10 seconds       5432/tcp            db2
a262c79688e8       training/postgres    "/docker-entrypoint.   33 seconds ago      Up 32 seconds       5432/tcp            db1
```

### 1.9. Iaas、Paas、Saas 云计算模式？

![1647511175588](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511175588.png)

**举例**：如何找披萨吃~

1. **传统数据中心**：Traditional data-center，本地服务，机房、网络、磁盘、服务器、虚机、操作系统、中间件、软件什么的，都需要自己亲力亲为去搭建，耗时耗力，成本高。
   - 好比从头做一个披萨，需要准备各种材料、亲自烧烤、还要买汽水摆盘各种操作，才可开餐。
2. **Iaas**：Infrastructure as a Service，基础设施即服务，通过购买云产品的基础设施，本地不用再考虑机房、网络、磁盘、服务器、虚机的问题，只需要保证操作系统、中间件的高可用，以及编写业务软件即可。
   - 好比买好冷冻的披萨，此时不需要再准备各种材料，而是从烧烤开始，最后买汽水摆盘即可开餐。
3. **Pass**：Platform as a Service，平台即服务，通过购买云产品的基础设施、平台设置，本地不用再考虑机房、网络、磁盘、服务器、虚机、操作系统、中间件的高可用问题，只需要编写业务软件即可。
   - 好比点披萨外卖，材料准备、烧烤的都不用了，直接买好汽水、摆好餐桌等外卖送到开吃就好。
4. **Saas**：Sofeware as a Service，软件即服务，通过购买一整套云产品，配置好对应的业务模板，即可搞定业务软件。
   - 好比出去餐厅吃披萨，材料、烧烤、买汽水、摆盘都由服务员解决，上菜直接开吃就好。

![1647511082155](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511082155.png)

### 2.0. Docker vs Cloud Foundry？

![1647511905639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511905639.png)

Infrastructure、VM 可以认为是做披萨时的准备材料，App Server、Runtime、Container 可以认为是烧烤过程，Application 可以认为是摆盘和买汽水过程。

1. Docker 完成的是摆盘和烧烤过程，即把应用和容器绑定在一起，关注的是应用和环境的打包过程。
2. Cloud Foundry 完成的是烧烤过程，即把应用上传好，由应用找到自适应的虚机进行发布，关注的是选择合适的应用支持。

=> 所以，个人认为使用 Docker 要关注结合过程，供应商只需要提供产品即可，而 Cloud Foundry 要关注选择过程，由供应商来提供产品的结果过程。 

### 2.1. 什么是 Cloud  Foundry？

![1647509134003](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647509134003.png)

容器化技术除了 Docker 外，著名的还有 Pivotal Cloud Foundry，**Spring** 自家产品，是业界第一个开源 **PaaS** 云平台，支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内，进行应用程序的部署和扩展，无需担心任何基础架构的问题。

其**特点**有：

1. **快速发布**：整个 Cloud Foundry 最核心的 一条命令就是 `CF Push`，可谓一招吃遍天。
2. **多语言支持**：几乎支持所有常见语言，包含 Java、Node.js、Go、Python、PHP、Ruby、.NET 等。
3. **网络和路由绑定**：Cloud Foundry 可以通过路由层（Routing）和应用执行层（Application Execution）的配合，可以很方便地实现内部、外部路由的解析和数据通信，解决 Docker 环境跨容器、跨服务器通信复杂的问题。
4. **用户和认证**：容器编码平台 K8S 并没有对这块给予很好的管理和集成，但这正式 Cloud Foundry 的优势所在。
5. **日志和监控**：Cloud Foundry 可以通过在平台里添加砖块（Tile）的方式，很自然地对接主流的监控平台。
6. **第三方支持**：有近 200+  主流产品提供第三方支持，用户可以从本地市场中，选择需要的服务，集成到各自的应用中。

### 2.2. Cloud Foundry 架构原理？

![1647513836355](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647513836355.png)

1. **底层**：可以基于 VMware、OpenStack 等私有环境的虚拟化技术，Amazon、Google、Windown Aware 等公有环境的虚拟化技术。
2. **BOSH**：解耦上层和底层，可对上层虚机自动恢复、备份。
3. **Cell**：虚拟机，Cloud Foundry 核心。
4. **Container**：容器。
5. **Service Brokers**：各容器通过 Service Broker 统一的 url 进行提供。
6. **Router**：url 服务的负载均衡通过 Router 来保证。
7. **Cloud Controller**：提供 CF API 的命令接口。

### 2.3. 如何选型容器化技术？

SWOT 分析法： Strengths 优势、Weaknesses 劣势、Opportunities 机会、Threats 威胁。

![1647514670543](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647514670543.png)

|          | Docker                                     | Cloud Foundry                                    |
| -------- | ------------------------------------------ | ------------------------------------------------ |
| **优势** | 生态圈第一者、环境准备非常方便、镜像胚胎多 | Spring 生态、多语言支持、网络通信方便            |
| **劣势** | 网络方案多且复杂                           | 前期准备麻烦、第三方服务定制复杂、不支持中文文档 |

### 2.4. 什么是容器编排？

容器编排，可以自动化部署、管理、扩展容器以及网络通信处理，为微服务应用提供了理想的应用程序部署单元，和独立的执行环境，使得微服务部署更加简单，同时还支持集成到 CI/CD 工作流，以提效 DevOps 团队工作，适合那些需要部署和管理成百上千个容器和主机的企业，是**云原生**应用程序的基础。

### 2.3. 什么是 K8S？

1. **Kubernetes**，又称作 K8S（中间的 8 个字母省略），是 Google 在 2014 年发布的一个开源项目。
2. 最初 Google 开发了一个叫 Borg 的系统（现在命名为 Omega），来调度近 20 多亿个容器，在积累了数十年的经验后，Google 决定重写这个容器管理系统，并贡献给开源社区，这个系统就是 Kubernetes，它也是 Omega 的开源版本。
3. 从 2014 年第一个版本发布以来，迅速得到了开源社区的追捧，目前，K8S 已经成为了发展最快、市场占有率最高的**容器编排**引擎产品。

其**特点**是：

1. **虚拟数据中心管理**：可以对数据中心资源和容器进行统一管理，同时支持开发、测试、生产各种环境。
2. **软件发布和回退**：部署软件可以像 `yum install` 一样方便，并且可以很方便地指定版本进行回退。
3. **网略和存储透明管理**：适合 DevOps 文化，无需开发人员专门学习存储和网络知识，其服务发现抽象了网络访问，PV / PC 两级管理技术抽象了存储配置，开发人员只需提交明确的配置，K8S 就可以自动完成资源的分配。
4. **弹性扩容**：可以根据策略，自动地增加资源或者释放资源，方便容器弹性扩缩容。
5. **高可用**：K8S 集群本身就是高可用的，且在其上发布的容器，可以通过负载均衡和 Service 功能，实现容器的高可用。

### 2.4. K8S 架构原理？

![1647516641430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647516641430.png)

**集群节点**：

1. **Kubernetes Cluster**：K8S 集群，是计算、存储和网络资源的集合，是掌握所有计算、存储、网络资源，进行统计管理、调度的节点群。

2. **Kubernets Maseter**：K8S 大脑节点，决定将应用放在哪里运行，它相比图中，该节点还隐藏了许多容器，比如：

   - **1）API Server**：API 服务端，通过控制台、网络，接收传过来的命令，判断是否符合语法标准，并根据实际环境进行处理。

   - **2）Scheduler**：调度执行器，对所有资源按照应用资源，执行统一调度，以及任务发布，负责决定将 Pod 放到哪⼀个 Node 上运⾏。

   - **3）Controller Manager**：核心节点，控制器管理器，负责 Cluster 各种资源的统筹管理。

     1. **replication controller**：负责跨节点部署、通信，实现标签管理、资源选择。
     2. **namespace controller**：管理虚拟化集群的资源隔离，跨节点应用高可用复制与管理。

     ![1647520902702](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647520902702.png)

   - **4）ETCD**：类似于 ZK，对 K8S 集群配置统一管理，保存 K8S 的相关配置和状态信息，如果 POD 有发⽣变化，那么它会迅速通知相关的组件进⾏处理。

   - **5）NetWork**：集群网络解决方案，包括 Flannel 法兰绒、Calico 印花布、Weave、Canal 组合方式等。

   - **6）Node's Components**：支持大脑节点当手脚节点用。

3. **Kubernets Node**：K8S 手脚节点，负责运行容器应用。

   - **1）Kubelet**：核心工作单元，是 K8S 里唯一一个没有以容器形式运行的组件，负责根据 Scheduler 发过来的信息（`--image` 、`volume` 等），去创建和运⾏容器，并向 Master 报告运⾏状态，是直接跟 **Docker** 进行沟通的容器生命管理模块。 

   - **2）Kube-proxy**：网络通讯、服务发现负载模块，是网络代理的概念，当 service 接收到请求后，转发到某个 node 时，会由该 node 的 kube-proxy 模块负责接收，然后转发到后端的容器中，如果有多个副本，还会提供负载均衡的能⼒。

   - **3）Docker daemon**：Docker 后台容器。

   - **4）Pod**：

     1. **K8S 的最小工作单元**（所以，K8S 最小工作单元不是容器！），是运行在 Node 手脚节点上的一堆容器集合，即**比容器更大的"集装箱"**，可以对网络共享、存储共享的**一堆容器**作为一个小单元进行管理，从而扩大管理粒度，降低管理复杂度。
     2. 比如，消息发送容器、消息接收容器、消息队列容器，可以封装成一个 Pod，实现统一部署，共享网络和存储。
     3. Pod 一旦发布，就只能在这个 Node上，与兄弟 Node 节点的 Pod 不同，即使承载的内容可能一样。

     ![1647567752066](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647567752066.png)

   - **5）Controller**：负责对 Pod 进行统一管理。

     1. **Deployment**：一个应用资源，基于 ReplicaSet，会产生一个部署请求，形成一堆 Pod。
     2. **ReplicaSet**：一个会在多个点节点部署多个的 Pod，以完成更多的功能。
     3. **DaemonSet**：一个在同一节点只会运行一份的 Pod。
     4. **StatefulSet**：一个有状态的服务，对外提供的 Pod 名称永远不变。
     5. **Job**：一个短时、定时作业的 Pod。

   - **6）Service**：

     1. **为 Pod 提供了负载均衡**：在当 Pod 之间需要相互访问时，会去 DNS Server 找到对应的 IP 地址，通过 Kube-proxy 服务发现功能，进行网络数据包转发，实现网络服务功能，以用于描述 Pod 和 Pod 之间的应用访问。
     2. **为客户端提供固定的 IP + 端口**：当 Pod 的 IP 发生变化时，Service 可以保证，客户端面对的 Pod 还是固定 IP 和端口。

     ![1647520164299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647520164299.png)

**其他概念**：

1. **Label**：对某些特殊的 Pod 打个标签，以区分不同的 Pod 或机器资源，方便进行查询、网络发现和服务发现。
2. **Namespace**：虚拟 K8S 集群，解决在同一个 Cluster 集群中，如何区分开 Controller 和 Pod 的问题，默认两个虚拟集群，`kube-system` 用于自身管理的集群，`kube-default` 用于应用部署的默认集群（不指定集群名称时）。

=> 综上，从下到上，组件结构为：**Docker 容器** ->(往上)-> **Pod** ->(往上)-> **Namespace** ->(往上)-> **Kubernetes Cluster**。

当需要执行部署应用，并指定两个副本时，**执行流程**如下所示：

1. kuberctl 发送部署请求到 API Server。
2. API Server 通知 Controller Manager 创建一个 deployment 资源。
3. Scheduler 执行调度任务，将两个副本 Pod 分发到 node1 和 node2 上。
4. node1 和 node2 上的 kubectl 在各自的节点上，创建并运行 Pod。

### 2.5. 如何使用 K8S？

#### 一、集群命令

##### 1）查看 k8s 集群版本

```shell
kubectl version
```

##### 2）查看 k8s API 版本

```shell
kubectl api-versions
```

##### 3）查看 k8s 集群健康状态

```shell
kubectl get cs
```

##### 4）查看 k8s 集群核心组件运行情况

```shell
kubectl cluster-info
```

##### 5）查看 k8s 集群所有 namespace

```shell
kubectl get namespaces
```

##### 4）查看 k8s 集群所有 Node 节点

```shell
kubectl get nodes
```

##### 6）删除 k8s Node 节点

```shell
kubectl delete node k8s2
```

#### 二、Pod

**生命周期**：

![1647567485849](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647567485849.png)

##### 1）查看所有 namespace#pods 运行情况

```shell
kubectl get pods --all-namespaces
```

##### 2）查看具体一个 namespace#pods

```shell
kubectl get pods kubernetes-dashboard-76479d66bb-nj8wr --namespace=kube-system
```

##### 3）查看 namespace#pods 的结构信息

```shell
# 重点，通过这个看日志分析错误（对控制器和服务，node等同样有效）
kubectl describe pods xxxxpodsname --namespace=xxxnamespace
```

##### 4）查看 pod 日志

```shell
kubectl logs $POD_NAME
```

=> 其他 Controller 控制器也类似，就是 kubectl get 控制器 控制器具体名称。

#### 三、Deployment

对于 Deployment，Controller 会通过动态创建和销毁 Pod，来保证其整体的健壮性。

因此，**Pod 是脆弱的，但 Deployment 是健壮的**。

##### 1）查看所有 deployment

```java
kubectl get deployment --all-namespaces
```

##### 2）查看具体一个 deployment

```shell
kubectl get deployment nginx-app
```

##### 3）查看未初始化的 namespace#pod

```shell
kubectl get pods --include-uninitialized
```

##### 4）直接创建

在 v1.18.0 以后，`–replicas` 已弃用 ,推荐用 `kubectl apply` 来创建 pods。

```shell
kubectl run nginx-deployment--image=nginx:1.7.9--replicas=2
```

##### 5）配置文件创建

通过配置文件和 `kubectl apply` 创建。

**步骤**：

1. 编写配置文件 nginx.yml。
2. 执行命令 `kubectl apply -f /home/muse/nginx.yml`。

**构建原理**：

![1647566268366](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647566268366.png)

通过 kubectl——>创建 Deployment ——>创建 ReplicaSet ——>创建 Pod，名称为堆叠的方式。

```shell
# API 版本号
apiVersion: apps/v1
# 类型，如：Pod/ReplicationController/Deployment/Service/Ingress
kind: Deployment
# metadata定义Pod的元数据
metadata:
  # Kind 的名称
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      # 容器标签的名字，发布 Service 时，selector 需要和这⾥对应
      app: nginx
  # 部署的实例数量，默认为1
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    # 描述Pod的规格，定义Pod中每一个容器的属性，name和image是必需的
    spec:
      # 配置容器，数组类型，说明可以配置多个容器
      containers:
      # 容器名称
      - name: nginx
        # 容器镜像
        image: nginx:1.17
        # 只有镜像不存在时，才会进⾏镜像拉取
        imagePullPolicy: IfNotPresent
        ports:
        # Pod 端⼝
        - containerPort: 80
```

##### 6）自动失败转移

1. 一开始设置了 pod 数为 3 个，Master 在 Node1 分配了 2 个 Pod，在 Node2 分配了 1 个 Pod。
2. 当 Node1 异常时，Master 会在 Node2 上面，生成新的 2 个 Pod，保证有 3 个 Pod 正常运行。
3. 当 Node1 恢复正常后，新创建的 Pod 将依然会在 Node2 上，并不会做迁移动作。

![1647566333333](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647566333333.png)

##### 7）指定 Node 部署

1. 默认配置下，Scheduler 会将 Pod 调度到所有可用的 Node 上。
2. 不过有些情况，可以通过 `lable` ，将 Pod 部署到指定的 Node 上，比如将有大量磁盘 I/O 的 Pod，部署到配置了 SSD 的 Node 上，或者 Pod 需要 GPU 时，则指定部署在配置了 GPU 的节点上。

```shell
# 先给k8s-node1节点，添加标签——disktype=ssd
kubectl label node k8s-node1disktype=ssd

# 修改nginx.yml配置文件，指定nodeSelector为上一步新建的label
nodeSelector:
  disktype: ssd
  
# 重新部署Deployment
kubectl apply -f nginx.yml

# 查看节点的标签信息
kubectl get node --show-labels
```

##### 8）删除 Deployment

```shell
# 删除pod，如果只是删除其中一个Pod，则依然会被deployment自动失败转移，再补充为n个pod
kubectl delete pod nginx-deployment-7f4fc68488-5v4m7

# 删除deployment，如果整个deployment删除时，则其配置的Pod也会随之自动被删除
kubectl delete deployment nginx-deployment
```

##### 9）动态伸缩 pod

```shell
# 将foo副本集变成3个
kubectl scale --replicas=3 rs/foo
# 将deployment/mysql从2个变成3个
kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
# 变更多个控制器的数量
kubectl scale --replicas=5 rc/foo rc/bar rc/baz
# 查看变更进度
kubectl rollout status deploy deployment/mysql
```

##### 10）自动滚动发布

![1647571435643](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647571435643.png)

1. k8s 滚动更新，是指一次只更新一小部分副本，成功后再更新更多的副本，最终完成所有副本的更新。
2. 滚动更新的最大好处是**零停机**，整个更新过程始终有副本在运行，从而保证了业务的连续性。

#### 四、DaemonSet

**区别**：

1. Deployment 部署的 Pod 会分布在各个 Node 上，每个 Node 都可能会运行好几个副本。
2. 而 DaemonSet 不同的地方在于，它会保证每个 Node 上，**最多只能运行 1 个副本**。

**典型应用场景**：用于存储、日志收集、监控的后台进程，比如 Prometheus Node Exporter。

##### 1）查看 k8s 自身的 DaemonSet 系统运行组件

```shell
kubectl get daemonset --namespace=kube-system
```

![1647568750538](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647568750538.png)

#### 五、Job

![1647568862407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647568862407.png)

1. 容器按照持续时间划分，可以分为服务类容器和工作类容器。
2. 服务类容器，通常持续提供服务，需要一直运行，比如 Http Server、Daemon 等，ReplicaSet 和 DaemonSet 都是用于管理服务类容器。
3. 工作类容器，是一次性任务，比如批处理程序，完成之后容器就会退出，Job 用于管理工作类容器。

##### 1）普通任务配置

```shell
[root@training3 ~]# cat hello.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    metadata:
      name: hello
    spec:
      containers:
      - name: hello
        image: busybox
        command: ["echo", "hello from feiyang"]
      restartPolicy: Never
```

##### 2）定时任务配置

```shell
[root@training3 ~]# cat myjob.yaml
apiVersion: batch/v2alpha1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: ["echo", "hello feiyang"]
          restartPolicy: Never
```

### 2.6. 什么是 Mesos？

![1647581552572](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647581552572.png)

Apache Mesos，是一个集群管理器，可跨分布式应用程序，提供有效的资源隔离和共享，相当于一个分布式操作系统内核，让用户像使用一台电脑一样**使用整个数据中心**，通过 API 为各种应用，提供跨数据中心和云资源调度的能力。

其**特点**有：

1. **轻量级的 Master**：仅保留各 Framework 和 Slave 的一些状态，易于重构，同时采用 ZK 解决 HA 问题。
2. **配合 Container 技术的 Slave**：利用 LXC 和 Docker 技术，可以实现任务间的 CPU 和内存资源隔离。
3. **资源分配调度简单**：默认的 DRF 优势资源公平算法（Dominant Resource Fairness，决定资源分配情况，最大化数据中心利益），可以轻松实现资源最大化利用，无需人工干预和配置。 

### 2.7. 什么是 Marathon？

![1647572643772](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572643772.png)

1. Marathon，马拉松，是 Mesos 应用调度框架中，最知名的一款软件，能够支持运行**长服务**，比如 WEB 应用等，将应用程序部署为长时间运行的 Mesos 服务，并调用 Mesos 管理的资源实现应用的业务需求。
2. 如果把 Mesos 类比为操作系统内核，负责资源调度，那么 Marathon 可以类比为服务管理模块，比如 `init`、`systemd` 或者 `upstart` 等，用来管理应用的 状态信息。

其**特点**有：

1. **高可用性**：Marathon 作为主动 / 被动集群运行，领导者选举可以实现 100% 高可用。
2. **资源分布可控**：可以允许每个节点仅放置一个应用程序实例，从而缓解单点故障的影响。
3. **服务发现和负载均衡**：可以通过 HA 和 DNS 等方式，实现自动负载均衡。
4. **健康检查**：可以使用 HTTP 或者 TCP，来检查、评估应用程序的运行状况。
5. **活动订阅**：提供 HTTP 端点，以接收通知，比如与外部的负载均衡集成。
6. **UI**：美丽而强调的 UI。
7. **API**：完美的 Rest API，易于集成和编写脚本。
8. **安全**：提供基础认证和 SSL 功能。
9. **监控**：以 json 格式，在 `/metrics` 查询它们，或者将它们推送到  `graphite`、`statsd`、`Datadog` 之类的系统。

### 2.8. Mesos 架构原理？

![1647572679607](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572679607.png)

Mesos 实现整个数据中心统一管理，其核心概念为**资源两级供给**和**作业两级调度**。

**从下而上的资源两级供给**：

1. **Mesos Slave -> Mesos Master**：在 Mesos 集群中，资源的供应方，都来自于 Mesos Slave 所在的物理节点，资源包括 CPU、内存、存储空间、I/O 吞吐能力等。这些资源通过供给的方式，从 Mesos Slave 提供给了 Mesos Master 的 Leader，为第一级的资源供给。
2. **Mesos Master -> Framework Scheduler**：Mesos Master 进一步将资源整合后，作为可选项，提供给各种  framework 框架，比如主流的 Marathon 长服务框架、Jenkins CI / CD 框架、Spark 大数据框架、Kafka 中间件框架、Chronos 任务管理框架、Aurora 应用管理框架等，各种框架可以有选择地对 Mesos Master 整合后的数据中心资源提出要求。

**从上而下的作业两级调度**：

1. **用户 -> Scheduler**：
   - 1）各个框架都有自己的调度  Scheduler，它会根据用户需求，启动特定的工作任务。
   - 2）调度器在上层第一级确定工作任务需要的资源情况，是否需要接收 Mesos 提供的 CPU、内存和存储资源，来运行特定的工作负载。
2. **Mesos Slave -> Executeor**：
   - 1）Mesos 对于上层框架的需求也不是予取予求，而是会采用默认的 DRF 优势资源公平算法，来决定各种框架任务的资源分配情况，从而使整个数据中心利益最大化。
   - 2）比如上层框架中的 Marathon 调度器需要启动 Nginx 任务，而同时 Spark 框架需要启动 Streaming 任务，那么 Mesos 的 DRF 算法，会根据框架提出的要求，将尽量多的内存和 CPU 分配给 Nginx 用于进行反向代理服务，同时将尽可能多的 I/O 吞吐性能提供给 Spark 进行流处理。

### 2.9. Mesos Marathon 整体架构？

![1647572413475](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572413475.png)

1. **CLI UI**：用户操作界面。
2. **Zookeeper**：多数派选举 Mesos Master Leader。
3. **Marathon Scheduler**：Marathon 调度器，对接 Mesos Master，提供容器编排和应用调度、与 Mesos Slave 端的 Docker Executor 紧密呼应。
4. **Mesos Master**：Leade + Flower 主备模式、沟通 Mesos Slave 整理资源、沟通 Framework 框架提供资源。
5. **Mesos Slave**：沟通 Mesos  Master 获取资源、为各种框架提供执行器环境、执行任务和容器管理。
6. **Docker  Executor**：Marathon 提供的 Docker 执行器。
7. **Docker Container**：运行中的 Docker 容器。

=> 如果想运行长任务，想结合管理数据中心多种形式的任务，同时应用之间也不需要太大的集群耦合性的话，Mesos + Marathon 这一堆数据中心操作系统解决方案，比较适合。

### 3.0. 如何选型容器编排技术？

SWOT 分析法： Strengths 优势、Weaknesses 劣势、Opportunities 机会、Threats 威胁。

![1647582756320](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647582756320.png)

|          | Kubernetes                                                   | Mesos + Marathon                                             |
| :------- | :----------------------------------------------------------- | ------------------------------------------------------------ |
| **优势** | 天然支持公有云（比如阿里云）、提供抽象的存储、支持容器弹性扩缩容、文档多，技术普及率高 | Mesos 资源统一管理，适合于数据中心、支持多个框架并存         |
| **劣势** | 离不开容器，只能进行容器管理，不能进行资源的统筹控制管理、Master 高可用节点安装相对复杂、不适合大数据虚拟机部署场景 | 不能做很复杂的存储抽象、功能需要多个框架拼装，导致可能没有对应的实现、公有云没有对应的实现 |

### 3.1. 什么是 Serverless？

- **问题背景**：

  1. **存在服务器资源成本浪费**：中长尾（大部分时间没有流量）应用，会固定的消耗服务器资源，但实际上，这些应用的调用率并不高，又不能直接做下线处理，因为有些应用是被强依赖的。
  2. **存在人力资源成本浪费**：后端要开发的非业务代码过多、前后端联调周期长。

- **解决方案**：推进 Serverless 方案，在 K8S 基础上，对开发、运维体系进一步抽象，给开发、运维提供一个极简模型。

- **概念**：

  一般来说，Serverless 的概念就如同它的字面含义：

  - **server**：需要关注服务器资源、部署情况，操作系统，软件依赖等细节。
  - **less**：更换少的。

  => 故，Serverless = `server` + `less` = 更少地关注服务端的运维工作 = 运维自动化。 

无论 Serverless 技术栈如何演进，但它始终都在沿着一个不变的目标前行着（NoOps ，No Operations，无运维，或者说简化服务端运维模型 ) 。

### 3.2. Serverless 架构原理？

![1647584496435](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647584496435.png)

#### 1）Serverless 整体架构

具体到开发人员，**狭义的 Serverless 定义**为:

应用程序 Serverless = Trigger 事件驱动 + FaaS 函数即服务 + BaaS 后端即服务。

其中，

- **Trigger**：事件驱动，可以指一次 HTTP/RPC 请求，或者一条订阅的 MQ 消息等。
- **FaaS**：Function As A Service，函数即服务：
  1. FaaS 函数可以理解为是一个容器镜像，镜像的内容可以是一个具备输入输出功能的单个函数代码，由外部的触发器 Trigger 触发后，会先被实例化成一个容器实例，然后执行其中的函数，最终返回结果给外部。
  2. 当 FaaS 函数在 FaaS 函数调用完成后，容器实例会被销毁，并回收资源。
  3. 因此，FaaS 实例实质上是一个**独立的容器实例**。
  4. FaaS 的主要作用是，随时随地的创建、使用、销毁一个函数，在并发量高时，可以进行横向扩容，而在没有流量时，又可以缩容到 0，提高服务器资源利用率。
- **BaaS**：Backend As A Service，后端即服务：
  1. 由于 Faas 函数无状态、实例会不停地扩缩容，所以，对于那些需要**持久化数据**的需求，采用 FaaS 来实现不合适时，可以使用 BaaS 后端即服务组件来解决。
  2. BaaS，一般是指具备**高可用性、弹性伸缩、免运维**的后端服务，专门用于支撑 FaaS，内部可以通过连接池、Local Cache 等方式去优化。
  3. BaaS 的主要作用是，保存状态即存储数据，需要保障稳定性，不能轻易被改动，当面对流量峰值、峰谷的流量差比较大时，能够按峰值去扩容节点，以抗住高流量，但在没有流量时，也要维持固定的开销。

#### 2）Faas 架构原理

![1647585253702](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647585253702.png)

在 FaaS 运行时中，存在 3 个**服务组件**：

- **函数触发器服务**：所有请求的统一入口，当外部事件发生时，会触发事件，通知函数服务，并且等待函数服务 执行返回后，将结果返回给等待的请求。
- **函数服务**：当触发器通知的事件到来时，会先查看一下，当前有没有闲置的函数实例，如果有，则调用函数实例进行处理；如果没有，则会创建函数实例，等函数实例创建完毕后，再调用函数实例处理事件。
- **函数实例**：运行时的函数代码（编写的业务函数），为一个 Docker 实例，在第一次实例化函数时，会从代码仓库中拉取代码，并构建函数实例。

一次 **FaaS 函数调用过程**为：

1. 当客户端第一次通过 HTTP 请求访问函数触发器时， 函数触发器就会 Hold 住客户端的 HTTP 请求，对 HTTP Request 对象进行封装，产生一个事件来通知函数服务。
2. 紧接着，函数服务就会检查有没有闲置的函数实例，如果没有闲着的函数实例，就去函数代码仓库中拉取相应的代码，来初始化并启动一个函数实例，传入事件对象作为函数的输入参数，并执行函数。
3. 函数执行完成后，函数的返回结果会返回给函数触发器，函数触发器再将结果包装成 HTTP Response，返回给等待的客户端。

#### 3）Baas 架构原理

![1647585651029](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647585651029.png)

BaaS 服务的一种实现方案是，使用 K8ssandra 作为底层的组件。

K8ssandra，是 Apache Cassandra 在 Kubernetes 上的一个发行版，致力于简化 Cassandra 集群在 Kubernetes 上的部署工作，由多个开源组件构建而成，支持监控、备份、同步和数据接口等。

BaaS **底层各组件**分别为：

1. **Stargate**：一款开源的开发接口平台，用于暴露 Cassandra 对数据 CRUD 接口的封装。
2. **Prometheus + Grafana**：Cassandra 监控和看板平台，提供 Cassandra 检测、报表查看功能。
3. **App Backend + App Frontend**：应用通过客户端，直接操作 Cassandra，存储数据。
4. **Reaper**：数据修复工具，保证数据的一致性。
5. **Cass-operator**：保证 Cassandra 集群正常运行。
6. **Medusa**：数据备份工具，支持 S3、GCP Cloud Storage 等。

