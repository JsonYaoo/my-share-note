# 七、Dubbo篇

### 1.1. 什么是集群、分布式、SOA、微服务架构？

#### 总结

| 架构   | 概念                                                         | 本质                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 集群   | 不同服务器部署**同一套应用**服务对外提供访问，实现服务的负载均衡，或者主从等，指同一种组件的多个实例，形成逻辑上的整体，其中的单个节点就可以提供完整服务。 | 节点的物理形态                                               |
| 分布式 | 服务的**不同模块**部署在不同的服务器上，其中的单个节点并不能提供完整服务，需要多个节点间通过交换信息协调提供服务 | 节点间的工作方式                                             |
| SOA    | Service Oriented Architecture，**面向服务的架构**，一种设计方法，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能，一个服务通常以独立的形式存在于某个操作系统进程中，各个服务之间通过网络进行调用 | ESB **中心化实现**，各服务通过 ESB 进行交互，解决**异构系统**之间的连通性，通过协议转换、消息解析、消息路由把服务提供者的数据传送到服务消费者；但由于所有服务都依赖于 ESB，最终会导致其承压过重，成为整体系统的一个瓶颈 |
| 微服务 | 微服务强调业务需要彻底的**组件化和服务化**，使原有的单个业务系统被拆分成多个可以独立开发、设计、运行的小应用，而这些小应用之间通过服务完成交换和集成 | SOA 架构的一种变体，其中**去中心化实现**是在 SOA 上做的升华  |

#### SOA VS 微服务

|      | SOA                          | 微服务                       |
| ---- | ---------------------------- | ---------------------------- |
| 目标 | 强调异构服务之间的协作与集成 | 拆分模块、快速拓展、快速开发 |
| 管理 | 着重中央管理                 | 重在分散管理                 |
| 粒度 | 通常粒度粗                   | 拆分粒度更细，职责单一       |

### 1.2. 详细介绍 RPC？

#### 背景概念

- **背景**：部署在 A 服务器的一个应用，想要调用 B 服务器上应用提供的方法，由于两个程序不在同一个内存空间，所以不能直接发起调用，需要通过网络来表达调用的语义和传达调用的数据，而 RPC 正是用来解决这种调用过程。
- **概念**：RPC，Remote Procedure Call，远程过程调用，是⼀种**技术思想**，⽽⾮⼀种规范或协议，是一种通过网络，使得程序能够像访问本地系统资源一样，去访问远端系统资源。

#### 架构组件

一个基本的 RPC 架构里面应该至少包含以下 4 个组件：

- **Client**：客户端，即服务调用方，也叫服务消费者。
- **Client Stub**：客户端存根，存放服务端地址信息，将客户端的请求参数打包成网络消息，再通过网络传输发送给服务端。
- **Server Stub**：服务端存根，接收客户端发送过来的请求消息，然后进行解包，再调用本地服务进行处理。
- **Server**：服务端，服务的真正提供者。

![1636547867858](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636547867858.png)

#### 实现基础

1. **高效的网络通信**：比如一般选择 Netty 作为网络通信框架。
   - **NIO 通信**：出于并发性能的考虑，传统阻塞式 IO并不合适，因此需要非阻塞的 NIO，比如可以选择 Netty 或者 MINA 来解决 NIO 数据传输的问题。
2. **高效的序列化框架**：比如 Kryo、FastJson 和 Protobuf 序列化框架。
   - **序列化和反序列化**：在网络中，所有数据都将会被转化为**字节**进行传送，所以为了能够使参数能在网络中进行传输，需要对这些参数进行序列化和反序列化操作。
     - **序列化**：把对象转换为字节序列的过程称为**对象的序列化**，也就是编码的过程。
     - **反序列化**：把字节序列恢复为对象的过程称为**对象的反序列化**，也就是解码的过程。
3. **可靠的寻址方式**：指服务发现，比如可以使用 Zookeeper 来注册服务等。
   - **服务注册中心**：比如 Redis、Zookeeper、Consul 、Etcd 等，一般使用 ZooKeeper 来提供服务注册与发现功能，以及解决注册中心单点故障和分布式部署的问题。
4. **会话和状态保持**：如果是带会话（状态）的 RPC 调用，还需要有会话和状态保持的功能。
   - **长连接**。
5. **接口动态代理**：生成客户端存根 `Client Stub` 和服务端存根 `Server Stub` 时，需要用到动态代理技术，比如JDK 动态代理、CGLib 动态代理、Javassist 字节码生成。

![1636299221043](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636299221043.png)

#### 调用过程

1. **客户端调用**：服务消费方通过调用本地服务的方式调用需要消费的服务。
2. **将方法入参等信息序列化**：客户端存根接收到调用请求后，负责将方法、入参等信息序列化，组装成能够进行网络传输的消息体。
3. **通过网络发送消息**：客户端存根找到远程的服务地址，并且将消息通过网络发送给服务端。
4. **发序列化操作**：服务端存根收到消息后进行反序列化解码操作。
5. **调用本地服务**：服务端存根根据解码得到的结果，调用本地的服务进行相关处理。
6. **服务端处理业务逻辑**：服务端本地服务执行具体业务逻辑。
7. **返回处理结果**：服务端把业务处理结果返回给服务端存根。
8. **返回消**息：服务端存根将返回结果重新序列化，打包成消息，并通过网络发送至消费方。
9. **反序列化操作**：客户端存根接收到消息，并进行反序列化解码操作。
10. **返回调用结果**：客户端存根返回解码得到的结果给服务消费方，服务消费方得到最终结果，完成一次 RPC 调用。

![1636298416654](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636298416654.png)

#### 实现目标

RPC 框架的实现目标是，把以上调用过程的第 2~10 步，调用、编码/解码的过程给封装起来，让开发人员使用时，在感觉上就像调用本地服务一样地调用远程服务。

#### 常⻅框架

RPC 常见框架实现有：阿里 Dubbo & HSF、当当 Dubbox、京东 JSF、Google GRPC、Facebook 的 Thrift、Twitter Finagle、Spring Cloud 等。

- **Dubbo**：阿⾥集团开源的⼀个极为出名的 RPC 框架，底层使用 Netty 框架，基于 TCP 协议传输的，配合 Hession 序列化完成 RPC 通信，在很多互联⽹公司和企业应⽤中⼴泛使⽤，其协议和序列化框架都可以插拔是极其鲜明的特⾊。
- **Dubbox**：当当网基于 Dubbo 做的一个扩展项目，比如加了服务可 Restful 调用，更新了开源组件等。
- **GRPC**：Google 开源 RPC 框架，基于 HTTP 2.0 协议，底层使⽤ Netty 框架，⽀持常⻅的众多编程语⾔。
- **Thrift**：Facebook 开源 RPC 框架，主要是⼀个跨语⾔的服务开发框架，⽤户只要在其之上进⾏⼆次开发就⾏，应⽤对于底层的 RPC 通讯等都是透明的，不过这个对于⽤户来说需要学习特定领域语⾔这个特性，还是有⼀定成本的。
- **Spring Cloud**：基于 Http 协议 REST 接口调用进行远程过程通信，相对来说 TCP 实现的  RPC 请求会有更大的报文，占的带宽也会更多，但是 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖。
  - Dubbo 是 SOA 时代的产物，以服务治理作为目标，关注点主要在于服务调用、流量分发、流量监控以及服务熔断。
  - Spring Cloud 诞生于微服务架构时代，依托了 Spring、Spring Boot，考虑的是微服务治理的方方面面，目的是打造一个生态。

#### RPC 与 HTTP 的区别

在大型网站内部子系统和接口都非常多的情况下，RPC 对比 Http 接口的优势有：

1. **长链接**：不必每次通信都要像 Http 那样去 3 次握手，减少了网络开销。
2. **服务治理**：RPC 框架一般都有注册中心，也有丰富的监控管理，来发布、下线接口、动态扩展等，这些对调用方来说是无感知、统一化的操作。

|              | RPC                                                          | HTTP                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 概念         | 远程过程调用，是⼀种**技术思想**，⽽⾮⼀种规范或协议         | 超长文本传输协议，是一种网络传输协议                         |
| 传输协议     | 基于 TCP 协议（网络 4 层），也可以基于 HTTP 协议             | 基于 HTTP 协议（网络 7 层）                                  |
| 传输效率     | 传输效率高，使⽤⾃定义的 TCP 协议，请求报⽂体积更⼩；或者使⽤ HTTP2 协议，也可以很好的减少报⽂的体积 | 如果是 HTTP1.1 协议，请求中会包含很多⽆⽤的内容；如果是 HTTP2.0 协议，进行简单封装可以作为⼀个 RPC 来使⽤，但对比标准 RPC 框架缺少了服务治理 |
| 性能消耗     | 可以基于 thrift 协议，实现⾼效的⼆进制传输                   | ⼤部分通过 json 来实现，字节⼤⼩和序列化都⽐ thrift 要更消耗性能 |
| 负载均衡     | RPC 框架基本都⾃带了负载均衡策略                             | 需要配置Nginx、HAProxy来实现                                 |
| 服务故障转移 | 能做到⾃动通知，不影响上游                                   | 需要事先通知，以修改下游的 Nginx、HAProxy 配置               |
| 总结         | 主要⽤于公司内部的服务调⽤，性能消耗低、传输效率⾼、服务治理⽅便 | 主要⽤于对外的异构环境，浏览器接⼝调⽤、APP接⼝调⽤、第三⽅接⼝调⽤等 |

### 1.3. 为什么要用 Dubbo？

####  单一应用架构

- **背景**：当⽹站流量很⼩时，只需⼀个应⽤，将所有功能都部署在⼀起，以减少部署节点和成本。
- **关键点**：此时，⽤于简化增删改查⼯作量的数据访问框架 **ORM** 是关键。

![1636254754534](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254754534.png)

#### 垂直应用架构

- **背景**：当访问量逐渐增⼤，单⼀应⽤增加机器带来的加速度越来越⼩，提升效率的⽅法之⼀是将应⽤拆成
  互不相⼲的⼏个应⽤，以提升效率。
- **关键点**：此时，⽤于加速前端⻚⾯开发的Web框架 **MVC** 是关键。

![1636254796925](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254796925.png)

#### 分布式服务架构

- **背景**：当垂直应⽤越来越多，应⽤之间交互不可避免，将核⼼业务抽取出来，作为独⽴的服务，逐渐形成
  稳定的服务中⼼，使前端应⽤能更快速的响应多变的市场需求。
- **关键点**：此时，⽤于提⾼业务复⽤及整合的分布式服务框架 **RPC** 是关键。

![1636254855881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254855881.png)

#### 流动计算架构（SOA）

- **背景**：随着服务化的进⼀步发展，服务越来越多，服务之间的调⽤和依赖关系也越来越复杂，诞⽣了⾯向
  服务的架构体系（SOA），也因此衍⽣出了⼀系列相应的技术，如对服务提供、服务调⽤、连接处理、通信协议、序列化⽅式、服务发现、服务路由、⽇志输出等⾏为进⾏封装的**服务治理框架**，比如 Dubbo。

![1636254950341](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254950341.png)

### 1.4. 什么是 Dubbo？

Apache Dubbo，是一款高性能、轻量级的开源服务框架，提供了六大核心能力：面向接口代理的高性能 RPC 调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度、可视化的服务治理与运维。

#### 1、面向接口代理的高性能RPC调用

提供高性能的、基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用的底层细节。

- 默认使用 **Dubbo 协议**，基于 TCP 协议实现，有着报文小占用带宽小、基于网络 4 层通信效率高的优点。

#### 2、智能负载均衡

内置多种负载均衡策略，可以智能感知下游节点的健康状况，显著减少了调用延迟，提高了系统的吞吐量。

- **负载均衡**：当服务越来越多时，F5 硬件负载均衡器的单点压⼒也越来越⼤，通过在消费⽅获取服务提供⽅地址列表，实现软负载均衡和集群容错。

#### 3、服务自动注册与发现

支持多种注册中心服务，能够做到服务实例上下线的实时感知。

- **地址维护**：当服务越来越多时，服务 URL 配置管理变得⾮常困难，这时候需要⼀个服务注册中⼼，来动态注册和发现服务，使服务的位置透明。

#### 4、高度可扩展能力

遵循微内核+插件的设计原则，Microkernel 只负责组装 Plugin，其所有核心能力如 Protocol、Transport、Serialization 都被设计为扩展点，能够平等对待内置实现和第三方实现。

- **微内核**：Micro kernel，是提供操作系统核心功能的内核精简版本，设计成在很小的内存空间内增加移植性，提供模块化设计，以使用户安装不同的接口，如 DOS、Workplace OS、Workplace UNIX 等。

#### 5、运行期流量调度

内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现灰度发布、同机房优先等功能。

- 比如服务限流、服务降级、蓝绿发布、金丝雀发布、权重路由、同区域优先等。

#### 6、可视化的服务治理与运维

提供丰富服务治理、运维工具，可以随时查询服务元数据、服务健康状态以及调用统计，实时下发路由策略、调整配置参数。

1. 当调⽤量越来越⼤，服务容量问题就会暴露出来，服务需要多少机器⽀撑？什么时候该加机器？
2. 为了解决这些问题，第⼀步，要将服务当前每天的调⽤量、响应时间都统计出来，作为容量规划的参考指标。
3. 其次，进行动态调整权重，在线上将某台机器的权重⼀直加⼤，并在加⼤的过程中记录其响应时间的变化，直到响应时间到达阈值时，记录此时的访问量，再以此访问量乘以机器数反推总容量。

### 1.5. 什么是蓝绿发布、金丝雀发布、灰度发布、滚动发布？

| 发布类型   | 概念                                                         |
| ---------- | ------------------------------------------------------------ |
| 蓝绿发布   | 在线上老版本继续运行的前提下，直接发布新版本，然后进行测试；当新版本测试通过后，再将流量切到新版本，最后将老版本同时也升级到新版本 |
| 金丝雀发布 | 在线上版本可用的情况下，同时发布一个新版本应用作为**金丝雀**；测试该新版本的性能和表现，在保障整体系统稳定的前提下，可以尽早发现问题并及时做出调整 |
| 灰度发布   | 只升级部分服务，让一部分用户继续用老版本，一部分用户开始用新版本；如果用户对新版本没什么意见，再逐步扩大范围，最后将所有用户都迁移到新版本上面来 |
| 滚动发布   | 每次只升级一个或多个服务，升级完成后加入生产环境，不断执行这个过程，直到集群中的全部旧版本都升级到新版本为止 |

### 1.6. 什么是 Dubbo 核心组件？

![1636292050935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636292050935.png)

#### 节点角色

| 节点      | 角色                                 |
| --------- | ------------------------------------ |
| Container | 服务运行容器                         |
| Provider  | 暴露服务的服务提供方                 |
| Registry  | 服务注册与发现的注册中心             |
| Consumer  | 调用远程服务的服务消费方             |
| Monitor   | 统计服务调用次数和调用时间的监控中心 |

#### 调用关系

1. 服务容器负责启动、加载、运⾏服务提供者。

2. 服务提供者在启动时，向注册中⼼注册⾃⼰提供的服务。
3. 服务消费者在启动时，向注册中⼼订阅⾃⼰所需的服务。
4. 注册中⼼返回服务提供者地址列表给消费者，如果有变更，注册中⼼将会基于⻓连接推送变更数据给消费者。
5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选⼀台服务提供者进⾏调⽤，如果调⽤失败，再选另⼀台调⽤。
6. 服务消费者和提供者，在内存中累计调⽤次数和调⽤时间，定时每分钟发送⼀次统计数据到监控中⼼。

#### 架构优点

Dubbo 架构具有以下⼏个优点，分别是连通性、健壮性、伸缩性、以及面向未来架构的升级性。

##### 1、连通性

注册中⼼，服务提供者，服务消费者三者之间均为⻓连接，监控中⼼除外，而注册中⼼和监控中⼼都是可选的，服务消费者可以直连服务提供者。

- **服务提供者**：向注册中⼼注册其提供的服务，并汇报调⽤时间到监控中⼼，此时间不包含⽹络开销。
- **注册中⼼**：
  1. 负责服务地址的注册与查找，相当于⽬录服务，服务提供者和消费者只在启动时与注册中⼼交互，不转发客户端请求，压⼒较⼩。
  2. 通过⻓连接感知服务提供者的存在，当服务提供者宕机时，注册中⼼会⽴即推送事件通知消费者。
- **服务消费者**：向注册中⼼获取服务提供者地址列表，并根据负载算法直接调⽤提供者，同时汇报调⽤时间到监控中⼼，此时间包含⽹络开销。
- **监控中⼼**：负责统计各服务调⽤次数，调⽤时间等，统计先在内存汇总后每分钟⼀次发送到监控中⼼服务器，并以报表展示。

##### 2、健壮性

- 任意⼀台**注册中⼼**宕掉后，将会⾃动切换到另⼀台，全部宕掉后，服务提供者和服务消费者仍能通过本地缓存进行通讯，但不能注册新服务。
- ⽆任意⼀台**服务提供者**宕掉后，不会影响使⽤，全部宕掉后，服务消费者将⽆法使⽤，并⽆限次重连等待，直到服务提供者恢复。
- **监控中⼼**宕掉后，不影响使⽤，只是丢失部分采样数据而已。

##### 3、伸缩性

- **注册中心集群**：注册中⼼是对等集群，可动态增加机器部署实例，所有客户端将会⾃动发现新的注册中⼼。
- **服务提供者集群**：服务提供者⽆状态，可动态增加机器部署实例，注册中⼼将推送新的服务提供者信息给消费者。

##### 4、面向未来架构的升级性

当服务集群规模进⼀步扩⼤，带动 IT 治理结构进⼀步升级，需要实现动态部署，进⾏流动计算，而基于现有分布式服务架构，那时将不会带来阻⼒。下图是未来可能的⼀种架构：

![1636293350069](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636293350069.png)

###### 节点角色

| 节点           | 角色                                           |
| -------------- | ---------------------------------------------- |
| **Admin**      | 统一管理控制台                                 |
| **Scheduler**  | 调度中心，可以基于访问压力，自动增减服务提供者 |
| **Deployer**   | 自动部署服务的本地代理                         |
| **Repository** | 版本仓库，用于存储服务应用发布所有代码包       |
| Container      | 服务运行容器                                   |
| Provider       | 暴露服务的服务提供方                           |
| Registry       | 服务注册与发现的注册中心                       |
| Consumer       | 调用远程服务的服务消费方                       |
| Monitor        | 统计服务调用次数和调用时间的监控中心           |

###### 调用关系

1. 统一管理控制台，不仅可以发布服务提供者的代码包到版本仓库，还可以通过大盘获取路由、流量统计等信息。
2. 调度中心会基于监控中心聚合过来的信息，进行动态增减服务提供者。
3. 当需要动态增加服务提供者时，会拉起新的服务运行容器。
4. 服务容器会先到版本仓库，拉取对应的代码包，然后负责启动、加载、运⾏服务提供者。
5. 服务提供者在启动时，向注册中⼼注册⾃⼰提供的服务。
6. 服务消费者在启动时，向注册中⼼订阅⾃⼰所需的服务。
7. 注册中⼼返回服务提供者地址列表给消费者，如果有变更，注册中⼼将会基于⻓连接推送变更数据给消费者。
8. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选⼀台服务提供者进⾏调⽤，如果调⽤失败，再选另⼀台调⽤。
9. 服务消费者和提供者，在内存中累计调⽤次数和调⽤时间，定时每分钟发送⼀次统计数据到监控中⼼。

### 1.7. Dubbo 基本使用方式？

#### 原生 POM 依赖

```xml
<!-- Dubbo -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 注册中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-registry-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 数据上报监控中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-metadata-report-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>
```

#### Provider | HelloWorld

##### XML 配置环境 & 接口

```xml
<beans "...">
    <!-- 应用配置 -->
    <dubbo:application name="demo-xml-provider" />
    <!-- 注册中心配置 -->                                         
    <dubbo:registry id="registry" address="zookeeper://127.0.0.1:2181"/>
    <!-- 协议配置 -->                                                         
    <dubbo:protocol name="dubbo" port="20880"/>
    <!-- 接口配置 -->
    <dubbo:service interface="com.end.dubbo.api.service.OrderService" ref="orderService"/>
   	<!-- SpringBean注入 -->
    <bean id="orderService" class="com.end.dubbo.service.OrderServiceImpl"/>
    <!-- 监控中心元数据上报配置 -->
    <dubbo:metadata-report address="zookeeper://127.0.0.1:2181"/>
</beans>
```

##### 实现类

```java
// 服务提供方
public class DubboXMLProvider {
    public static void main(String[] args) throws Exception {
        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("dubbo-provider.xml");
        context.start();

        System.out.println("xml provider 启动ing");
        System.in.read();
    }
}

// 订单服务
public class OrderServiceImpl implements OrderService {
    @Override
    public OrderDTO getOrder(String orderNo) {
        System.out.println("Provider OrderService getOrder start, orderNo:" + orderNo);
        OrderDTO orderDTO = new OrderDTO(1L, "no1", "订单1");
        System.out.println("Provider OrderService getOrder end, orderNo:" + orderNo + ", orderDTO:" + orderDTO.toString());
        return orderDTO;
    }
}
```

#### Consumer | HelloWorld

##### XML 配置环境 & 引用

```xml
<beans "...">
    <!-- SpringBean扫描 -->
    <context:component-scan base-package="com.end.dubbo.user.impl" />
	<!-- 应用配置 -->
    <dubbo:application name="demo-xml-consumer" />
	<!-- 注册中心配置 -->
    <dubbo:registry address="zookeeper://127.0.0.1:2181"/>
	<!-- 接口配置 -->
    <dubbo:reference id="orderService" interface="com.end.dubbo.api.service.OrderService" check="false"/>
</beans>
```

##### 调用类

```java
// user服务：服务消费方
public interface UserService {
    String getOrderInfo(String orderNo);
}
@Service
public class UserServiceImpl implements UserService {
    @Autowired
    private OrderService orderService;

    @Override
    public String getOrderInfo(String orderNo) {
        System.out.println("Consumer UserService getOrderInfo start, orderNo:" + orderNo);

        // 远程服务调用
        OrderDTO orderDTO = orderService.getOrder(orderNo);
        System.out.println("Consumer orderService.getOrderInfo end, orderNO:" + orderNo + ",orderDTO:" + orderDTO);
        return orderDTO.toString();
    }
}
```

#### SpringBoot POM 依赖

```xml
<!-- Dubbo、Spring整合 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-spring-boot-starter</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 注册中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-registry-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 数据上报监控中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-metadata-report-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>
```

#### SpringBoot Provider | HelloWorld

##### YML 配置环境

当然也可以用 XML 进行统一配置。

```yaml
dubbo:
  # 应用配置
  application:
    name: dubbo-annotation-provider
  # 注册中心配置
  registry:
    address: zookeeper://127.0.0.1:2181
  # 协议配置
  protocol:
    name: dubbo
    port: 20882
  # 数据上报监控中心
  metadata-report:
    address: zookeeper://127.0.0.1:2181
```

##### 注解配置接口

```java
// 订单服务
@org.apache.dubbo.config.annotation.Service(version = "1.0.0", group = "end1", methods = { 
    @Method(name = "getOrder", timeout = 1) 
})
public class OrderServiceImpl implements OrderService {
    @Override
    public OrderDTO getOrder(String orderNo) {
        System.out.println("Provider OrderService getOrder 2 start, orderNo:" + orderNo);
        OrderDTO orderDTO = new OrderDTO(1L, "no1", "订单11");
        System.out.println("Provider OrderService getOrder 2 end, orderNo:" + orderNo + ", orderDTO:" + orderDTO.toString());
        return orderDTO;
    }
}

// 服务提供方，启用Dubbo
@SpringBootApplication
@EnableDubbo
public class DubboAnnotationConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(DubboAnnotationConsumerApplication.class, args);
    }
}
```

#### SpringBoot Consumer | HelloWorld

##### YML 配置环境

```yaml
dubbo:
  # 应用配置
  application:
    name: dubbo-annotation-consumer
  # 注册中心配置
  registry:
    address: zookeeper://127.0.0.1:2181
  # 协议配置
  protocol:
    name: dubbo
    port: 20882
  # 数据上报监控中心
  metadata-report:
    address: zookeeper://127.0.0.1:2181
```

##### 注解配置引用

```java
// user服务
@Service
public class UserServiceImpl implements UserService {
    @org.apache.dubbo.config.annotation.Reference(
        group = "end1", version = "1.0.0", timeout = 2000, loadbalance = "roundrobin", cluster = ""
    )
    private OrderService orderService;

    @Override
    public String getOrderInfo(String orderNo) {
        System.out.println("annotation Consumer UserService getOrderInfo start, orderNo:" + orderNo);

        OrderDTO orderDTO = orderService.getOrder(orderNo);
        System.out.println("annotation Consumer orderService.getOrderInfo end, orderNO:" + orderNo + ",orderDTO:" + orderDTO);
        return orderDTO.toString();
    }
}

// 服务消费方，启用Dubbo
@SpringBootApplication
@EnableDubbo
public class DubboAnnotationConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(DubboAnnotationConsumerApplication.class, args);
    }
}
```

#### SpringBoot | Java Bean 配置1

```java
// 服务提供方Java Bean 配置1：注入实现类
@Configuration
@DubboComponentScan(basePackages = "com.end.dubbo.service.impl")
public class DubboDemoOtherProviderAPIConfig {
    @Bean
    public ServiceConfig<OrderService> orderServiceConfig(OrderService orderService){
        // 应用配置
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-demo-other-provider-api");

        // 注册中心配置
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("127.0.0.1:2181");

        // 协议配置
        ProtocolConfig protocolConfig = new ProtocolConfig();
        protocolConfig.setName("dubbo");
        protocolConfig.setPort(20881);

        // 元数据上报配置
        MetadataReportConfig metadataReportConfig = new MetadataReportConfig();
        metadataReportConfig.setAddress("zookeeper://127.0.0.1:2181");

        // 接口方法配置
        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName("getOrder");
        methodConfig.setTimeout(1);
        
        // 接口配置
        ServiceConfig<OrderService> serviceConfig = new ServiceConfig<>();
        serviceConfig.setInterface(OrderService.class);
        serviceConfig.setRef(orderService);
        serviceConfig.setVersion("1.0.0");
        serviceConfig.setGroup("end4");
        serviceConfig.setApplication(applicationConfig);
        serviceConfig.setRegistry(registryConfig);
        serviceConfig.setProtocol(protocolConfig);
        serviceConfig.setMetadataReportConfig(metadataReportConfig);
		serviceConfig.setMethods(Lists.newArrayList(methodConfig));
        
        // 服务暴露
        serviceConfig.export();
        return serviceConfig;
    }
}
```

#### SpringBoot | Java Bean 配置2

```java
// 服务提供方Java Bean 配置2：注入实现类
@Configuration
@DubboComponentScan(basePackages = "com.end.dubbo.service.impl")
public class DubboDemoOtherProviderConfig {
    // 应用配置
    @Bean
    public ApplicationConfig applicationConfig(){
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-demo-other-provider-api");
        return applicationConfig;
    }

    // 注册中心配置
    @Bean
    public RegistryConfig registryConfig(){
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("127.0.0.1:2181");
        return registryConfig;
    }

    // 协议配置
    @Bean
    public ProtocolConfig protocolConfig(){
        ProtocolConfig protocolConfig = new ProtocolConfig();
        protocolConfig.setName("dubbo");
        protocolConfig.setPort(20881);
        return protocolConfig;
    }

    // 元数据上报配置
    @Bean
    public MetadataReportConfig metadataReportConfig(){
        MetadataReportConfig metadataReportConfig = new MetadataReportConfig();
        metadataReportConfig.setAddress("zookeeper://127.0.0.1:2181");
        return metadataReportConfig;
    }

    // 服务配置
    @Bean
    public ServiceConfig<OrderService> orderServiceConfig(OrderService orderService){
        ServiceConfig<OrderService> serviceConfig = new ServiceConfig<>();
        serviceConfig.setInterface(OrderService.class);
        serviceConfig.setRef(orderService);
        serviceConfig.setVersion("1.0.0");
        serviceConfig.setGroup("end3");

        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName("getOrder");
        methodConfig.setTimeout(1);
        serviceConfig.setMethods(Lists.newArrayList(methodConfig));

        return serviceConfig;
    }
}
```

### 1.8. Dubbo 常用高级配置？

#### 开发与测试

##### 启动时检查

1. `check="true"` 默认会在应用启动时，检查依赖的服务是否可用，不可用则会抛出异常，阻止 Spring 初始化完成，以便上线前，能及早发现问题。
2. 可以通过 `check="false"` 关闭检查，比如测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动时。
3. 如果 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请设置 `check=false`，否则由于拿到 null 引用，代表服务临时不可用时，会抛出异常，而如果 `check="false"`，当服务恢复时，能自动连上，总是会返回引用，而不会报错。

| 标签            | 属性  | 作用                                           |
| --------------- | ----- | ---------------------------------------------- |
| dubbo:reference | check | 关闭**某个服务**的启动时检查，没有提供者时报错 |
| dubbo:consumer  | check | 关闭**所有服务**的启动时检查，没有提供者时报错 |
| dubbo:registry  | check | 关闭**注册中心**启动时检查，注册订阅失败时报错 |

##### 点对点直连

点对点直连方式，可以以服务接口为单位，忽略注册中心的提供者列表，另外，A 接口配置点对点，并不影响 B 接口从注册中心获取列表。

- 在**开发及测试**环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连。
- 为了避免复杂化线上环境，不要在线上使用这个功能，只应在**测试阶段**使用。

| 标签            | 属性 | 作用                                                  |
| --------------- | ---- | ----------------------------------------------------- |
| dubbo:reference | url  | 配置 url 指向提供者，绕过注册中心，多个地址用分号隔开 |

##### 多版本

- 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。
- 升级时，可以按照以下的步骤进行版本迁移：
  1. 在低压力时间段，先升级一半提供者为新版本。
  2. 再将所有消费者升级为新版本。
  3. 然后将剩下的一半提供者升级为新版本。

| 标签            | 属性    | 作用                         |
| --------------- | ------- | ---------------------------- |
| dubbo:service   | version | 提供服务的版本号，比如 1.0.0 |
| dubbo:reference | version | 消费服务的版本号，比如 1.0.0 |

##### 服务分组

当一个接口有多种实现时，可以用 group 区分，区分服务接口的不同实现。

| 标签            | 属性  | 作用           |
| --------------- | ----- | -------------- |
| dubbo:service   | group | 提供服务的分组 |
| dubbo:reference | group | 消费服务的分组 |

##### 泛化调用

Dubbo 支持 Json 字符串参数的泛化调用，即直接传递字符串来完成一次调用，无需具体的 JAR 包或接口。

- **优点**：扩展性、跨语⾔、轻量级。
- **使用场景**：⼀般使⽤在⽹关类项⽬中，在平常业务开发中基本不会使⽤。

###### API 方式

```java
// API方式 引用远程服务
// 该实例很重要，里面封装了所有与注册中心及服务提供方连接，请缓存
ReferenceConfig<GenericService> reference = new ReferenceConfig<GenericService>();
// 弱类型接口名
reference.setInterface("com.end.dubbo.api.service.OrderService");
// 声明为泛化接口
reference.setGeneric(true);
// 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用
GenericService genericService = reference.get();
Object result = genericService.$invoke("getOrder", new String[] { "java.lang.String" }, new Object[]{ "ccc" });
```

###### Spring 注入方式

| 标签            | 属性    | 作用                                                      |
| --------------- | ------- | --------------------------------------------------------- |
| dubbo:reference | generic | 默认为 false，代表不启用泛化调用，true 则代表启用泛化调用 |

```java
// <dubbo:reference id="orderService"  // interface="com.end.dubbo.api.service.OrderService" generic="true"/>

// 通过spring
ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("dubbo-generic-consumer.xml");
GenericService orderService = (GenericService) context.getBean("orderService");
```

#### 服务高可用

##### 服务超时

| 标签            | 属性    | 作用                                                  |
| --------------- | ------- | ----------------------------------------------------- |
| dubbo:service   | timeout | 远程服务调用的超时时间，默认为 1000ms                 |
| dubbo:reference | timeout | 服务方法调用的超时时间，默认为 dubbo:consumer#timeout |
| dubbo:consumer  | timeout | 服务方法调用的超时时间，默认为 1000ms                 |

##### 重试次数

Dubbo 服务在尝试调用一次之后，如出现非业务异常，比如服务突然不可用、超时等，默认会进行额外的最多 2 次的重试。

| 标签           | 属性    | 作用              |
| -------------- | ------- | ----------------- |
| dubbo:consumer | retries | 默认额外重试 2 次 |

##### 集群容错

在集群**调用失败**时，Dubbo 提供 6 种集群容错方案，缺省为 `failover` 失败自动切换，可通过 SPI 自行扩展。

| 标签            | 属性    | 作用                   |
| --------------- | ------- | ---------------------- |
| dubbo:service   | cluster | 服务提供方配置集群模式 |
| dubbo:service   | weight  | 服务权重               |
| dubbo:reference | cluster | 消费方配置集群模式     |

##### 负载均衡

在集群负载均衡时，Dubbo 提供了  4 种负载均衡策略，缺省为 `random` 随机调用，可通过 SPI 自行扩展。

| 标签                         | 属性        | 作用           |
| ---------------------------- | ----------- | -------------- |
| dubbo:service                | loadbalance | 服务端服务级别 |
| dubbo:service#dubbo:method   | loadbalance | 服务端方法级别 |
| dubbo:reference              | loadbalance | 客户端服务级别 |
| dubbo:reference#dubbo:method | loadbalance | 客户端方法级别 |

##### 服务降级

服务降级，可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。

```java
RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();

Registry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));

// 向注册中心写入动态配置覆盖规则
registry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&mock=force:return+null"));
```

| 降级策略               | 作用                                                         | 适用场景                                 |
| ---------------------- | ------------------------------------------------------------ | ---------------------------------------- |
| mock=force:return+null | 表示消费方对该服务的方法调用，都直接强制返回 null 值，不发起远程调用 | 用于屏蔽不重要服务不可用时对调用方的影响 |
| mock=fail:return+null  | 表示消费方对该服务的方法调用在失败后，才返回 null 值，而不抛异常 | 用来容忍不重要服务不稳定时对调用方的影响 |

##### 服务限流

| 标签            | 属性     | 作用                                                         |
| --------------- | -------- | ------------------------------------------------------------ |
| dubbo:service   | executes | 服务提供者的，每个服务的，每个方法的，最大可**并行**执行请求数 |
| dubbo:reference | actives  | 每个服务消费者的，每个服务的，每个方法的，最大**并发**调用数 |

#### 服务高性能

##### 请求派发策略

Dubbo 中的线程模型，可以通过不同的**请求派发策略**，和不同的**线程池类型**的组合，来应对不同的场景:

1. 如果事件处理的逻辑能**迅速完成**，并且不会发起新的 IO 请求，比如只是在内存中记个标识，则直接在 IO 线程上处理更快，因为减少了线程池调度。
2. 但如果事件处理**逻辑较慢**，或者需要发起新的 IO 请求，比如需要查询数据库，则必须派发到线程池，否则 IO 线程阻塞，将导致不能接收其它请求。
3. 如果用 IO 线程处理事件，又在事件处理过程中**发起新的 IO 请求**，比如在连接事件中发起登录请求，会报**“可能引发死锁”异常**，但不会真死锁。

| 标签           | 属性       | 作用         |
| -------------- | ---------- | ------------ |
| dubbo:protocol | dispatcher | 请求派发策略 |

##### 线程池类型

| 标签           | 属性       | 作用       |
| -------------- | ---------- | ---------- |
| dubbo:protocol | threadpool | 线程池类型 |
| dubbo:protocol | threads    | 最大线程数 |

##### 服务协议

###### 配置方式

| 标签          | 属性     | 作用                                                         |
| ------------- | -------- | ------------------------------------------------------------ |
| dubbo:service | protocol | 使用指定的协议暴露服务，在多协议时使用，值为 dubbo:protocol 的引用，并用逗号分隔 |

###### 协议汇总

| 协议       | 说明                                                         | 适用场景                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Dubbo      | 单一长连接和 NIO 异步通讯，基于 TCP 协议，默认采用 Hessian 序列化，是 Dubbo 推荐使用的协议 | 适合大并发、小数据量的服务调用，消费者远大于提供者的场景     |
| RMI        | JDK 标准的 RMI 协议实现，采用 Java 标准序列化机制，传输参数和返回参数对象都需要实现 Serializable 接口，阻塞式短连接，基于 TCP 协议，数据包大小混合，可支持传输文件 | 多个短连接同步传输，适用常规的远程服务调用以及 RMI 互操作，但在依赖低版本的 Common-Collections 包时，Java 序列化存在安全漏洞 |
| WebService | 基于 HTTP#WebService 协议，需要集成 CXF 实现，提供与原生 WebService 的互操作 | 多个短连接同步传输，适用于系统集成和跨语言调用               |
| HTTP       | 基于 Http 协议，使用 Spring#HttpInvoke 实现                  | 适用于多个短连接、数据包大小混合、提供者个数多于消费者、需要给应用程序和浏览器 JS 调用的场景 |
| Hessian    | 集成 Hessian 服务，基于 HTTP 协议，采用 Servlet 暴露服务，Dubbo 内嵌 Jetty 作为服务器时的默认实现，提供与 Hession 服务互操作，采用 Hessian 序列化 | 多个短连接同步传输，适用于传入参数较大、提供者大于消费者、提供者压力较大的场景，比如传输文件 |
| Memcache   | 基于 Memcache实现的 RPC 协议                                 | -                                                            |
| Redis      | 基于 Redis 实现的RPC协议                                     | -                                                            |

###### 性能压测

1. 1k string 场景，压测得到的平均响应时间为：dubbo 2 > dubbo 1 > hessian > rmi > http。 

   ![1636884067979](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636884067979.png)

2. 200k string 场景，压测得到的平均响应时间为：rmi > http > hessian > dubbo 2 > dubbo 1。 

   ![1636884139136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636884139136.png)

3. 因此，可见，小数据包传输时，Dubbo 2/Dubbo 1 性能最高，RMI/Http 性能最低；大数据包传输时，Http/RMI 性能最高，Dubbo 2/Dubbo 1 性能最低。

#### 配置总结

##### 配置方式汇总

XML 配置、注解配置、属性⽂件 properties/yaml 配置、-D JVM 参数配置、代码编码⽅式配置、配置中心配置。

##### XML 标签汇总

| 标签                   | 用途         | 解释                                                         |
| ---------------------- | ------------ | ------------------------------------------------------------ |
| 方法参数配置：         |              |                                                              |
| `<dubbo:argument/>`    | 参数配置     | 用于指定方法参数配置                                         |
| `<dubbo:method/>`      | 方法配置     | 用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息   |
|                        |              |                                                              |
| 服务提供方配置：       |              |                                                              |
| `<dubbo:service/>`     | 服务配置     | 用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心 |
| `<dubbo:provider/>`    | 提供方配置   | 当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选 |
| `<dubbo:protocol/>`    | 协议配置     | 用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受 |
|                        |              |                                                              |
| 服务消费方配置：       |              |                                                              |
| `<dubbo:reference/>`   | 引用配置     | 用于创建一个远程服务代理，一个引用可以指向多个注册中心       |
| `<dubbo:consumer/>`    | 消费方配置   | 当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选      |
|                        |              |                                                              |
| 其他应用级配置：       |              |                                                              |
| `<dubbo:application/>` | 应用配置     | 用于配置当前应用信息，不管该应用是提供者还是消费者           |
| `<dubbo:registry/>`    | 注册中心配置 | 用于配置连接注册中心相关信息                                 |
| `<dubbo:monitor/>`     | 监控中心配置 | 用于配置连接监控中心相关信息，可选                           |
| `<dubbo:module/>`      | 模块配置     | 用于配置当前模块信息，可选                                   |

##### 配置方式覆盖策略

精确优先（比如方法大于全局等）、就近优先（比如 JVM 大于配置文件、消费者大于提供者等）。

1. **配置中心/-D JVM参数 优先**：这样可以使用户在部署和启动时，进行参数重写，比如在启动时需改变协议的端口。
2. **XML/注解/代码配置 次之**：如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。
3. **properties/yml 最后**：相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。

![1636881626159](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636881626159.png)

##### XML  标签覆盖顺序

精确优先（比如方法大于全局等）、就近优先（比如 JVM 大于配置文件、消费者大于提供者等）。

1. **⽅法级优先**：当级别⼀样时，消费⽅优先，提供⽅次之。
   - 下面与这类似，提供方配置就像是消费方的缺省值，只有在无消费方配置时才会生效，这样可以留机会给消费方做配置改写。
   - 而全局配置就像是接口级的缺省值，接口级配置就像是方法级的缺省值，这样可以留机会到接口、方法层面做配置改写。
2. **接⼝级次之**：级别⼀样时，消费⽅优先，提供⽅次之。
3. **全局配置再次之**：级别⼀样时，消费⽅优先，提供⽅次之。

![1636882183556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636882183556.png)

### 1.9. 详细介绍 Dubbo 架构设计？

#### 整体设计

- 图中左边淡蓝背景的为**服务消费方**使用的接口，右边淡绿色背景的为**服务提供方**使用的接口，位于中轴线上的为双方都用到的接口。
- 图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的**依赖关系**，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。
- 图中绿色小块的为**扩展接口**，蓝色小块为**实现类**，图中只显示用于关联各层的实现类。
- 图中蓝色虚线为**初始化过程**，即启动时组装链，红色实线为**方法调用过程**，即运行时调时链，紫色三角箭头为**继承**，可以把子类看作父类的同一个节点，线上的文字为调用的方法。

![1636607155860](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636607155860.png)

#### 各层说明

1. **Service**：业务接⼝层，与业务逻辑相关，是**用户**根据 Provider 和 Consumer 的业务，设计对应的接⼝ `Interface` 和对应的实现 `Implement` 。
2. **config**：配置层，对外配置接口，可以直接初始化配置类，也可以通过 Spring 解析配置生成配置类。
3. **proxy**：服务代理层，服务接口透明代理，生成客户端和服务器端存根，封装了所有接口的透明化代理，再暴露给用户使用时，消费方使用 Proxy 将 `Invoker` 转成接口，提供方将接口实现转成 `Invoker`，所以，去掉 Proxy 层，RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务而已。
4. **registry**：注册中心层，封装服务地址的注册与发现，Registry 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
5. **cluster**：路由层，封装多个提供者的路由及负载均衡，并桥接注册中心，该层是一个外围概念，即将多个 `Invoker` 伪装成一个 `Invoker`，使得用户只要关注 Protocol 层 `Invoker` 即可，而加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，另外，只有一个提供者时，是不需要 Cluster 的。
6. **monitor**：监控层，记录 RPC 调用次数和调用时间的监控，Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
7. **protocol**：远程调用层，核心层，封装 RPC 调用，只要有该层的 `Invoker` + `Exporter` 就可以完成非透明的 RPC 调用。
8. **exchange**：信息交换层，封装请求响应模式、同步转异步，在 transport 层上封装了 Request-Response 的语义，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
9. **transport**：网络传输层，负责消息传输，是对 Mina、Netty、Grizzly 的抽象，也可以扩展为 UDP 传输，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
10. **serialize**：数据序列化层，提供一些相关工具，默认序列化使用 Hessian2Serialization，另外还有 FastJsonSerialization、JavaSerialization、ProtostuffSerialization 等序列化方式。

#### 模块分包

![1636636045364](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636636045364.png)

- **dubbo-common**：公共逻辑模块，包括 Util 类和通用模型。
  - `serialize` 层放在 common 模块中，以便更大程度复用。
- **dubbo-remoting**：远程通讯模块，Dubbo 协议的实现，如果 RPC 用 RMI协议，则不需要使用此包。
  - `transport` 层和 `exchange` 层都放在 remoting 模块中，作为 rpc 调用的通讯基础，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
- **dubbo-rpc**：远程调用模块，抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。
  - `protocol` 层和 `proxy` 层都放在该模块中，这两层是 rpc 的核心，在不需要集群即只有一个提供者时，只使用这两层即完成 rpc 调用。
- **dubbo-cluster**：集群模块，将多个服务提供方伪装为一个提供方，包括：负载均衡、容错、路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发的。
  - `cluster` 层，属于一个外围概念，即加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，另外，只有一个提供者时，是不需要 Cluster 的。
- **dubbo-registry**：注册中心模块，基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。
  - `Registry` 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
- **dubbo-monitor**：监控模块，统计服务调用次数、调用时间和调用链跟踪。
  - `Monitor` 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
- **dubbo-config**：配置模块，Dubbo 对外的 API，隐藏 Dubbo 所有细节，用户可通过 Config 使用 Dubbo。
  - `config` 配置层，对外配置接口，可以直接初始化配置类，也可以通过 Spring 解析配置生成配置类。
- **dubbo-container**：容器模块，是一个可独立启动的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性，因此没必要用 Web 容器去加载服务。
  - container 是服务容器，用于部署运行服务，所以没有在分层架构中画出。

#### 架构原理

![1636876443919](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636876443919.png)

- Provider 启动时，把所有接口注册到注册中心，并且订阅动态配置 configurators，以及后台启动定时器，定时发送统计数据给 Monitor。
- Consumer 启动时，会订阅 providers、configurators、routers，在这些订阅内容发生变化时，ZK 会推送相关订阅的信息，并且与 Provider 建立长连接，方便以后数据通信，以及后台启动定时器，定时发送统计数据给 Monitor。

### 2.0. Dubbo 源码术语汇总？

| 术语          | 作用                                                         | 分类                                                         |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| @Adaptive     | 动态扩展一个类或者一个方法，1）注解在类上，代表类本身就是一个装饰类，只经过人工编码，不会生成代理类；2）注解在方法上，代表会自动生成和编译一个动态类，比如 Protocol$Adaptive，该类使用代码模板技术，通过 javassist 动态代理，生成装饰方法，该方法添加了根据URL参数获取 SPI 扩展类的逻辑 | 两种注解方式，注解在类上和注解在方法上                       |
| ObjectFactory | 为 Dubbo IOC 提供所有对象                                    | 1）ExtensionLoader 的ObjectFactory 为 null；2）其余的在 Spring 环境下为SpringExtensionFactory |
| proxyFatory   | 获取一个接口的代理类，有两个方，getInvoker()：针对Server端，用于把实现类包装成一个Invoker javasist代理对象，getProxy()：针对Client端，用于创建服务引用接口的代理对象 | JavassistProxyFactory、JdkProxyFactory                       |
| Wrapper       | 包装一个接口或者类，以实现通过wrapper复制或者定制方法调用    | 多种 Wrapper 结尾的扩展类                                    |
| Protocol      | 服务域，是 Invoker 暴露和引⽤的主功能⼊⼝，负责 Invoker 的⽣命周期管理，有两个方法：1）export：针对Server端，暴露远程服务，把实现类代理Invoker通过协议、打开Netty服务器暴露外部；2）refer：针对客户端，？？？ | InjvmProtocol、RegistryProtocol、DubboProtocol、MockProtocolRedisProtocol、ThriftProtocol、MemcachedProtocol 等 |
| Invoker       | 实体域，是 Dubbo 的核⼼模型，一个可执行对象，能够根据方法的名称、参数得到相应的结果 | 多种实现类，但主要包括3种类型：1）本地执行类型的Invoker；2）远程通信类型的Invoker；3）包含多个远程通信Invoker聚合成的集群类型Invoker |
| Invocation    | 会话域，持有调⽤过程中的变量，⽐如⽅法名、参数等             | RpcInvocation                                                |
| exporter      | 维护Invoker的生命周期，可在exporters缓存map中获取各种包装了Invoker的exporters | InjvmExporter、DubboExporter、DestroyableExporter            |
| exchanger     | 信息交换层，封装请求响应模式，比如利用Netty NIO特性，把同步操作转换为I/O监听的异步操作 | HeaderExchanger                                              |
| transporter   | 网络传输层，用来抽象Netty和Mina的统一接口                    | netty.NettyTransporter、netty4.NettyTransporter、MinaTransporter、GrizzlyTransporter |
| ZK 结点       | 持久化结点：一旦被创建，除非主动删除掉，否则一直存储在 ZK 中；临时结点：与客户端会话绑定，一旦客户端会话失效，该客户端所创建的所有临时结点都会被删除，进而触发监听器事件的回调 | CreateMode.PERSISTENT（持久化结点）、CreateMode.EPHEMERAL（非持久化结点） |
| Directory     | 目录服务，装载各种Invoker，为提供Cluster查找的数据           | StaticDirectory，静态目录服务，Invoker是固定的，用于最外层的固定封装；RegistryDirectory，注册目录服务，Invoker来源于ZK，由于实现了NotifyListener接口，在ZK 通知服务信息发生变更时，会回调notify方法，然后刷新对应的Invoker集合 |

### 2.1. 什么是 Dubbo SPI？

#### API 与 SPI 的区别？

![1636461572100](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636461572100.png)

|          | API                                             | SPI                                                     |
| -------- | ----------------------------------------------- | ------------------------------------------------------- |
| 概念     | Application Programming Interface，应用程序接口 | Service Provider Interface，服务提供接口                |
| 接口实现 | 服务提供方，提供接口的不同实现                  | 客户消费方，不同消费方对同一接口，会提供不同的实现      |
| 接口调用 | 客户消费方，根据不同接口选择不同的实现          | 服务提供方，提供统一的接口                              |
| 应用场景 | 开发框架等提供的 API 支持                       | 数据库驱动、日志框架、Dubbo 扩展点、SpringBoot 自动装配 |

#### JDK SPI

##### 概念

一个简单的 JDK 服务提供者加载工具 `ServiceLoader`：

1. 通过在资源目录 `META-INF/services` 中，放置以 Provider 接口名作为配置文件名称，来标识 SPI 扩展点。
2. 其中，重复的扩展项将会被忽略。
3. 但是，`ServiceLoader` 非线程安全，不适用于多个并发线程。

##### 例子

###### 1、统一接口

```java
package jdk.spi;

// 动物接口
public interface Animal {
    void say();
}
```

###### 2、不同实现类

```java
// 猫实现类
public class Cat implements Animal {
    @Override
    public void say() {
        System.out.println("cat saying");
    }
}

// 狗实现类
public class Dog implements Animal {

    @Override
    public void say() {
        System.out.println("dog saying");
    }
}
```

###### 3、SPI 扩展配置

```properties
#./resources/META-INF/services/jdk.spi.Animal
jdk.impl.Dog
jdk.impl.Cat
```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ServiceLoader<Animal> serviceLoader = ServiceLoader.load(Animal.class);
        // dog saying，cat saying
        serviceLoader.forEach(Animal::say);
    }
}
```

##### 原理

1. 在 `ServiceLoader#load` ⽅法中，⾸先，会获取上下⽂类加载器，然后构造⼀个 `ServiceLoader`，而在 `ServiceLoader` 中有⼀个懒加载器，懒加载器会通过 `BufferedReader` 从 `META-INF/services` 路径下找到**对应的接⼝名**的全路径名⽂件，也就是SPI 扩展配置的⽂件。
2. 然后，通过⽂件的类解析器，读取⽂件中的内容。
3. 接着，再通过类加载器加载类的全路径，把所扩展的类加载到内存中。

```java
package java.util;

public final class ServiceLoader<S> implements Iterable<S>
{
	private static final String PREFIX = "META-INF/services/";

    // 1、使用当前线程的{@linkplain java.lang.Thread＃getContextClassLoader上下文类加载器}，为给定的服务类型创建一个新的服务加载器
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    
    // 2、为给定的服务类型和类加载器创建一个新的服务加载器。
    public static <S> ServiceLoader<S> load(Class<S> service,
                                            ClassLoader loader)
    {
        return new ServiceLoader<>(service, loader);
    }
    
    // 3、重新加载 -> 没作并发同步，所以非线程安全
    private ServiceLoader(Class<S> svc, ClassLoader cl) {
        service = Objects.requireNonNull(svc, "Service interface cannot be null");
        loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl;
        acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null;
        reload();
    }
    public void reload() {
        providers.clear();
        lookupIterator = new LazyIterator(service, loader);
    }
    
    // 4、SPI迭代器
    private class LazyIterator implements Iterator<S> {
        Class<S> service;
        ClassLoader loader;
        
        private LazyIterator(Class<S> service, ClassLoader loader) {
            this.service = service;
            this.loader = loader;
        }
        
        // 5、迭代器遍历时调用
        private S nextService() {
            if (!hasNextService())
                throw new NoSuchElementException();
            String cn = nextName;
            nextName = null;
            Class<?> c = null;
            try {
            	// 6、加载SPI扩展类
                c = Class.forName(cn, false, loader);
            } catch (ClassNotFoundException x) {
                fail(service, "Provider " + cn + " not found");
            }
            if (!service.isAssignableFrom(c)) {
                fail(service, "Provider " + cn  + " not a subtype");
            }
            try {
            	// 7、实例化SPI扩展类，实例化完成后并加入缓存
                S p = service.cast(c.newInstance());
                providers.put(cn, p);
                return p;
            } catch (Throwable x) {
                fail(service,
                     "Provider " + cn + " could not be instantiated",
                     x);
            }
            throw new Error();          // This cannot happen
        }
    }
}
```

#### Dubbo SPI

#####  例子 | 无 IOC

###### 1、统一接口

```java
package dubbo.spi;

// 人类接口 => 只有@SPI接口才会被SPI到
@org.apache.dubbo.common.extension.SPI
public interface Person {
    void say();
}
```

###### 2、不同实现类

```java
// 男人实现类
public class Man implements Person {
    @Override
    public void say() {
        System.out.println("man saying");
    }
}

// 女人实现类
public class Woman implements Person {
    @Override
    public void say() {
        System.out.println("woman saying");
    }
}
```

###### 3、SPI 扩展配置

```properties
# ./resources/META-INF/services/dubbo.spi.Person => 支持键值对形式配置
man=dubbo.impl.Man
woman=dubbo.impl.Woman
```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ExtensionLoader<Person> extensionLoader = ExtensionLoader.getExtensionLoader(Person.class);
        // 支持只加载某个键下的扩展类 => man saying
        Person man = extensionLoader.getExtension("man");
        man.say();
    }
}
```

##### 例子 | 有 IOC

###### 1、依赖 woman、cat

```java
public class Man implements Person {
    // 测试 Person IOC 注入
    private Person personDelegate;
    public void setWoman(Person personDelegate) {
        this.personDelegate = personDelegate;
    }
    
    // 测试 Animal IOC 注入
    private Animal animalDelegate;
    public void setCat(Animal animalDelegate) {
        this.animalDelegate = animalDelegate;
    }

    @Override
    public void say() {
        // 测试 Person IOC 注入 => woman saying
        personDelegate.say();
        // 测试 Animal IOC 注入 => cat saying
        animalDelegate.say();
    }
}
```

###### 2、注入 woman

$@Adaptive 动态代理类，代码生成模板格式：根据URL参数获取SPI扩展类。

![1636878858821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636878858821.png)

```java
// .resources/META-INF/services/dubbo.spi.Person
// woman=dubbo.impl.Woman
@SPI
public interface Person {
    @Adaptive
    void say();
}

// @Adaptive注解在类上：代表类本身就是一个装饰类，只经过人工编码，不会生成代理类
// @Adaptive注解在方法上：代表会自动生成和编译一个动态的$Adaptive类，比如Protocol$Adaptive，该类使用代码模板技术，通过javassist动态代理，生成装饰方法，该方法添加了根据URL参数获取SPI扩展类的逻辑
@Adaptive
public class Woman implements Person {
    // 这里的Woman类明显不是装饰类，只是用于测试而已，下面的Cat类也一样
    @Override
    public void say() {
        System.out.println("woman saying");
    }
}
```

###### 3、注入 cat

```java
// .resources/META-INF/services/dubbo.spi.Animal
// cat=jdk.impl.Cat

@SPI
public interface Animal {
    void say();
}

@Adaptive
public class Cat implements Animal {
    @Override
    public void say() {
        System.out.println("cat saying");
    }
}
```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ExtensionLoader<Person> personExtensionLoader = ExtensionLoader.getExtensionLoader(Person.class);
        Person man = personExtensionLoader.getExtension("man");
        man.say();// woman saying、cat saying
    }
}
```

##### 原理

![1636877812612](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636877812612.png)

```java
package org.apache.dubbo.common.extension;

public class ExtensionLoader<T> {
    // 1、获取type对应的getExtensionLoader
    public static <T> ExtensionLoader<T> getExtensionLoader(Class<T> type) {
        ...// SPI注解校验
        ExtensionLoader<T> loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);
        if (loader == null) {
            // 2、创建type对应的getExtensionLoader
            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader<T>(type));
            loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);
        }
        return loader;
    }
    
    // 3、根据key获取SPI扩展类
    public T getExtension(String name) {
        return getExtension(name, true);
    }
    public T getExtension(String name, boolean wrap) {
        ...// 4、先从缓存中获取
        // 5、缓存获取不到，则用双重检查锁实例化 => 线程安全
        if (instance == null) {
            synchronized (holder) {
                instance = holder.get();
                if (instance == null) {
                    instance = createExtension(name, wrap);
                    holder.set(instance);
                }
            }
        }
    }

    // 6、实例化key对应的SPI扩展类
    private T createExtension(String name, boolean wrap) {
        // 11、根据key从key-Classes形式缓存中获取对应的class
        Class<?> clazz = getExtensionClasses().get(name);
        ... 
        // 12、利用Dubbo SPI IOC 注入接口实现类的实例 -> 接口上要有@SPI、注入的实现类上要有@Adaptive
        injectExtension(instance);
        
        if (wrap) {
            ...
            // 13. 通过wrapper包装类实现 Dubbo SPI 对 AOP 的支持，即将instance作为参数传递给wrapper，通过反射创建wrapper，再向wrapper实例中注入依赖，最后把包装后的实例作为instance返回
            instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));
        }
        ...
        return instance;
    }

    // 12.1、Dobbo SPI IOC 注入核心方法
    private T injectExtension(T instance) {
        // 反射获取所有方法
        for (Method method : instance.getClass().getMethods()) {
            // 12.2、要有set方法
            if (!isSetter(method)) {
                continue;
            }
            
            // 12.3、可以注入
            if (method.getAnnotation(DisableInject.class) != null) {
                continue;
            }
            
            // 12.4、如果参数是基础类型就不注入, 因为这里注入指的是将加载的对象注入进来
            Class<?> pt = method.getParameterTypes()[0];
            if (ReflectUtils.isPrimitives(pt)) {
                continue;
            }
            
            // 12.5、获取要注入的属性名 -> 从@SPI扩展类中，获取对应接口和有@Adaptive的实现类
            String property = getSetterProperty(method);
            // ObjectFactory的作用是，为Dubbo IOC提供所有对象
            Object object = objectFactory.getExtension(pt, property);
            if (object != null) {
                // 12.6、反射调用set方法，完成注入
                method.invoke(instance, object);
            }
        }
    }
    
    private Map<String, Class<?>> getExtensionClasses() {
        ...
        // 7、加载SPI目录中所有的类，key-Classes形式放入缓存再返回
        classes = loadExtensionClasses();
        ...
    }
    
    // 8、SPI类加载核心方法
    private Map<String, Class<?>> loadExtensionClasses() {
        // 设置注解名称
        cacheDefaultExtensionName();
        
        // 9、加载读取配置文件：META-INF/services/、META-INF/dubbo/、META-INF/dubbo/internal/
         Map<String, Class<?>> extensionClasses = new HashMap<>();
        for (LoadingStrategy strategy : strategies) {
      		// 10、底层调用loadResource -> loadClass -> 加载对应Class -> extensionClasses
            loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages
            // com.alibaba => org.apache
            loadDirectory(extensionClasses, strategy.directory(), type.getName().replace("org.apache", "com.alibaba"), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages());
        }
        
        // key-Classes形式
        return extensionClasses;
    }
}
```

#### JDK SPI 与 Dubbo SPI 的区别？

|                | JDK SPI                                                      | Dubbo SPI                                                    |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 按需加载       | 不能按需加载，只能一次性加载所有的扩展实现，有的扩展加载很耗时，如果后面没用上，会很浪费资源，所以若想只加载某个扩展类的实现，使用 JDK SPI 就不现实了 | 可以按需加载，只加载⾃⼰想要加载的扩展实现，通过 key-全限定类名 配置扩展文件，最后用 key 来获取指定的扩展类 |
| IOC和 AOP 支持 | 类之间的依赖关系无法解决，无法把⼀个实现类，注⼊到容器中，不支持 IOC 和 AOP | 对扩展点支持 IOC 和 AOP，一个扩展点可以直接 `setter` 注⼊其它扩展点，可以很好的⽀持第三⽅ IOC 容器，比如`Spring Bean`，另外通过 Wrapper 包装类实现 Dubbo SPI 对 AOP 的支持 |
| 线程安全       | `ServiceLoader` 非线程安全，会有线程安全的问题，即并发时扩展类可能会加载错误 | `ExtensionLoader` 线程安全，对扩展类进行实例化时，使用双重检查锁保证线程安全 |

### 2.2. Dubbo 与 Spring 融合原理？

![1636889489122](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636889489122.png)

#### 1、Spring 解析 XML 回调

基于 dubbo.jar 内的 `META-INF/spring.handlers` 配置，Spring 在遇到 Dubbo XML 配置的名称空间 `http\://dubbo.apache.org/schema/dubbo` 时，会回调 `DubboNamespaceHandler` ，而 `http\://dubbo.apache.org/schema/dubbo/dubbo.xsd` 则定义了 Dubbo XML 的标签语法。

```properties
# ../dubbo-2.7.3.jar!/META-INF/spring.handlers
http\://dubbo.apache.org/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandler

# ../dubbo-2.7.3.jar!/META-INF/spring.schemas
http\://dubbo.apache.org/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd

# Dubbo XML配置头内容
<beans ... 
# DubboNamespaceHandler
http://dubbo.apache.org/schema/dubbo
# dubbo.xsd
http://dubbo.apache.org/schema/dubbo/dubbo.xsd">
</bean>
```

#### 2、 XML 标签解析成 Bean 

所有 dubbo 的标签，都统一用 `DubboBeanDefinitionParser` 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。

```java
package org.apache.dubbo.config.spring.schema;

// Dubbo XML配置统一解析器
public class DubboNamespaceHandler extends NamespaceHandlerSupport {
    @Override
    public void init() {
        ...
        // 这里主要看ServiceBean和ReferenceBean，其他的Dubbo配置解析也类似
        registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true));
        registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false));
        ...
    }
}
```

#### 3、Spring 加载时机回调

1. 在 `ServiceConfig.export()` 或 `ReferenceConfig.get()` 初始化时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 Dubbo#URL 的参数。
2. 然后将 Dubbo#URL 传给 Protocol 扩展点，基于扩展点的 SPI 机制，根据 Dubbo#URL 的协议头，进行不同协议的服务暴露或引用。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
    ...
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if (!isExported() && !isUnexported()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            // 实现Provider的服务发布
            export();
        }
    }
    ...
}

// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {
	...
    @Override
    public Object getObject() {
        // 实现Consumer的服务引用
        return get();
    }
    ...
}
```

### 2.3. Dubbo 服务发布原理？

![1636896497908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896497908.png)

1. `ServiceConfig` 类拿到对外提供实现类 ref。

2. 然后通过 `ProxyFactory#getInvoker（）` 为 ref 生成一个 `AbstractProxyInvoker` 实例，到这一步就完成具体服务到 `Invoker` 的转化。

3. 接下来就是 `Invoker` 转换到 `Exporter` 的过程，而**服务暴露的关键**就这个过程，即图中红色的部分，其转换分为两种类型：

   - **暴露本地服务**：指服务暴露和引用都在同一个 JVM 里，自己调用自己接口，没必要进行远程通信。
     1. `InjvmProtocol#export（）` 把 invoker 转换为 `InjvmExporter`，并存进 exporters 缓存中。
   - **暴露远程服务**：指服务暴露给远程客户端IP和端口号，以实现远程通信。
     1. `DubboProtocol#export（）`  把 invoker 转换为 `DubboExporter`，然后打开 Netty 服务器暴露服务，并存进 exporters 缓存中。
     2. `RegistryProtocol#register（）`，使用 Curator 客户端建立 ZK 连接，注册 provider 持久化结点、service 非持久化结点、configurators 非持久化结点，并设置监听器，当非持久化结点发生变更，则会回调监听器的 `notify（）`，修改 invoker 信息。

   ![1637067703250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637067703250.png)

#### 1、本地暴露服务

1. 构建实现类的动态代理对象，基于扩展点自适应机制，调用 `InjvmProtocol#export()` 方法获取 `InjvmExporter`，并存入 `exporters` 缓存中。

```java
// 1. ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
    ...
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if (!isExported() && !isUnexported()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            // 实现Provider的服务发布
            export();
        }
    }
    
    @Override
    public void export() {
        // 2. 实现Provider的服务发布
        super.export();
        publishExportEvent();
    }
}

// ServiceBean父类
public class ServiceConfig<T> extends AbstractServiceConfig {
    public synchronized void export() {
        ...
		doExport();
    }
    
    protected synchronized void doExport() {
        ...
        doExportUrls();
    }
    
    private void doExportUrls() {
        // 3. 获取dubbo.properties registry url配置
        List<URL> registryURLs = loadRegistries(true);
        
        // 4. 循环协议，说明一个服务支持多种协议
        for (ProtocolConfig protocolConfig : protocols) {
            String pathKey = URL.buildKey(getContextPath(protocolConfig).map(p -> p + "/" + path).orElse(path), group, version);
            ProviderModel providerModel = new ProviderModel(pathKey, ref, interfaceClass);
            ApplicationModel.initProviderModel(pathKey, providerModel);
            
            // 5. 根据协议配置，发布注册url
            doExportUrlsFor1Protocol(protocolConfig, registryURLs);
        }
    }
    
    private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 6. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 7. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            ...// 放在暴露远程服务中展开
        }
        ...
    }
    
    private void exportLocal(URL url) {
        ...
        // 9. 通过InjvmProtocol#export获取InjvmExporter
        Exporter<?> exporter = protocol.export(
            // 8. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, local));
        
        // 10. 最终目的：缓存每个服务的exporter到exporters中
        exporters.add(exporter);
        ...
    }
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        // 8.获取interfaceClass的javasist动态代理Wrapper包装类
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 动态代理调用实现类方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
}

// 9. 通过InjvmProtocol#export获取InjvmExporter
public class InjvmProtocol extends AbstractProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        return new InjvmExporter<T>(invoker, invoker.getUrl().getServiceKey(), exporterMap);
    }
}
```

#### 2、打开 Netty 服务器，远程暴露服务

![1636889534944](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636889534944.png)

1. 基于扩展点自适应机制，通过提供者 URL 的 `dubbo://` 协议头识别，就会调用 `DubboProtocol` 的 `export()` 方法，打开 Netty 服务器，利用 Netty NIO 特性，把同步操作转换为 I/O 监听的异步操作，以打开本地 Dubbo 服务，最后把 `DubboExporter` 缓存到 `exportes` 中。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
   	private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 1. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 2. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            // 3. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString()));
            DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);
            
            // 4. 通过RegistryProtocol#export暴露远程服务，获取对应的exporter
            Exporter<?> exporter = protocol.export(wrapperInvoker);
            
            // 18. 最终目的：缓存每个服务的exporter到exporters中
            exporters.add(exporter);
        }
        ...
    }
}    

public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 5. 打开Netty服务器，利用Netty NIO特性，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // ... 连接、订阅、监听ZK
    }
    
    private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
        String key = getCacheKey(originInvoker);
        return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
            Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
            // 6. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
            return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
        });
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 7. ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER));
    }
}

public class ProtocolListenerWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 8. ProtocolListenerWrapper监听扩展链装饰
        return new ListenerExporterWrapper<T>(protocol.export(invoker),            Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), EXPORTER_LISTENER_KEY)));
    }
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
		...
        // 9. 组装（key=xxx.DemoService：20880，value=DubboExporter）到exporterMap
        DubboExporter<T> exporter = new DubboExporter<T>(invoker, key, exporterMap);
        exporterMap.put(key, exporter);
        ...
        // 10. 打开Netty服务器，暴露本地Dubbo服务
        openServer(url);
        ...
    }
    
    private void openServer(URL url) {
        ...
        serverMap.put(key, createServer(url));
        ...
    }
    
    private ExchangeServer createServer(URL url) {
        ...
        // 11. 调用Exchangers绑定端口，打开Netty服务器
        server = Exchangers.bind(url, requestHandler);
    }
}

public class Exchangers {
   public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {
        ...
        // 12. SPI获取HeaderExchanger来绑定端口
        return getExchanger(url).bind(url, handler);
    }
}

public class HeaderExchanger implements Exchanger {
    @Override
    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {
        return new HeaderExchangeServer(
             // 13. 调用Transporters绑定端口，打开Netty服务器
            Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));
    }
}

public class Transporters {
    public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException {
        ...
        // 14. SPI获取remoting.transport.netty4.NettyTransporter来绑定端口
        return getTransporter().bind(url, handler);
    }
}

public class NettyTransporter implements Transporter {
    @Override
    public Server bind(URL url, ChannelHandler listener) throws RemotingException {
        // 15. 打开Netty服务器
        return new NettyServer(url, listener);
    }
}

// NettyServer抽象父类
public abstract class AbstractServer extends AbstractEndpoint implements Server {
    public AbstractServer(URL url, ChannelHandler handler) throws RemotingException     {
        ...
        // 16. 父类模板模式多态调用NettyServer#doOpen
        doOpen();
    }
    
    protected abstract void doOpen() throws Throwable;
}

public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 17. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}
```

#### 3、建立连接并监听 ZK

1. `ServiceConfig` 解析出的 URL 的格式为: `registry://registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode("dubbo://service-host/com.foo.FooService?version=1.0.0")`。
2. 基于扩展点自适应机制，通过 URL 的 `registry://` 协议头识别，就会调用 `RegistryProtocol` 的 `export()` 方法，将 `export` 参数中的提供者 URL，注册到注册中心。

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0. 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 1. 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
    }
    
    private Registry getRegistry(final Invoker<?> originInvoker) {
        URL registryUrl = getRegistryUrl(originInvoker);
        return registryFactory.getRegistry(registryUrl);
    }
}

public abstract class AbstractRegistryFactory implements RegistryFactory {
    @Override
    public Registry getRegistry(URL url) {
        ...
        // 2. 如果缓存中没有注册中心，则构建连接注册中心的客户端
        registry = createRegistry(url);
        ...
    }
    
    // 3. 父类模板模式多态调用RegistryFactory#createRegistry
    protected abstract Registry createRegistry(URL url);
}

public class ZookeeperRegistryFactory extends AbstractRegistryFactory {
    @Override
    public Registry createRegistry(URL url) {
        // 4. ZookeeperRegistryFactory子类构建ZK客户端
        return new ZookeeperRegistry(url, zookeeperTransporter);
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) {
        // 5. 调用父类加载、保存注册地址缓存文件
        super(url);
        
        // 7. 调用CuratorZookeeperTransporter#createZookeeperClient创建ZK客户端（Curator语法省略），并设置DISCONNECTED、CONNECTED、RECONNECTED事件的监听器
        zkClient = zookeeperTransporter.connect(url);
        
        // 8. 设置RECONNECTED事件的监听器 => 失败重连
        zkClient.addStateListener(state -> {
            if (state == StateListener.RECONNECTED) {
                try {
                    // 失败重连
                    recover();
                } catch (Exception e) {
                    logger.error(e.getMessage(), e);
                }
            }
        });
    }
}

public abstract class AbstractRegistry implements Registry {
    public AbstractRegistry(URL url) {
        ...
        // 6. 加载C：\Users\dubbo\.dubbo\dubbo-registry-192.168.48.117.cache缓存文件内容
        loadProperties();
        ...
    }
}
```

#### 4、注册 Provider、创建 ZK 结点

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.1 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 0.2 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
        // 1. 注册Provider到ZK注册中心
        register(registryUrl, registeredProviderUrl);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void register(URL url) {
        ...
        // 2. 注册Provider到ZK注册中心
        doRegister(url);
        ...
    }
    
    // 3. 父类模板模式多态调用ZookeeperRegistry#doRegister
    public abstract void doRegister(URL url);
}

public class ZookeeperRegistry extends FailbackRegistry {
    @Override
    public void doRegister(URL url) {
        // 4. Curator ZK客户端创建 /dubbo/xxx.DemoService/providers/... 前面的为持久化结点，后面的（...）为非持久化结点（Curator语法省略）
        zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true));
    }
}
```

#### 5、订阅 ZK 配置信息

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.1 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 0.2 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
        // 0.3. 注册Provider到ZK注册中心
        register(registryUrl, registeredProviderUrl);
        ...
        // 1. 订阅ZK配置信息，当有变更时自动推送
        registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);
        ...
        return new DestroyableExporter<>(exporter);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void subscribe(URL url, NotifyListener listener) {
        ...
        // 2. 向服务器端发送订阅请求
        doSubscribe(url, listener);
        ...  
    }
    
    @Override
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        // 5. 通知、写入缓存文件
        doNotify(url, listener, urls);
    }
    
    protected void doNotify(URL url, NotifyListener listener, List<URL> urls) {
        // 6. 通知、写入缓存文件
        super.notify(url, listener, urls);
    }
}

public abstract class AbstractRegistry implements Registry {
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        // 7. 刷新配置和Invoker列表
        listener.notify(categoryList);
        
        // 11. 线程池异步写入C：\Users\dubbo\.dubbo\dubbo-registry-192.168.48.117.cache缓存文件内容
        saveProperties(url);
    }
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        // 8. 刷新配置和Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 9. 刷新configurators配置
        overrideDirectoryUrl();
        
        // 10. 刷新RegistryDirectory中的Invoker列表
        refreshInvoker(urls);
    }
    private void overrideDirectoryUrl() {
        ...
        doOverrideUrl(localDynamicConfigurators);
    }
    private void doOverrideUrl(List<Configurator> configurators) {
        if (CollectionUtils.isNotEmpty(configurators)) {
            for (Configurator configurator : configurators) {
                this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);
            }
        }
    }
    private void refreshInvoker(List<URL> invokerUrls) {
        Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls);
        ...
        this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers;
        this.urlInvokerMap = newUrlInvokerMap;
        destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap);
        ...
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    protected void doSubscribe(final URL url, final NotifyListener listener) {
        // 3. 创建configurators配置信息（非持久化结点）
        zkClient.create(path, false);
        
        // 4. 通知、写入缓存文件
        notify(url, listener, urls);
    }
}
```

### 2.4. Dubbo 服务引用原理？

![1636896718809](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896718809.png)

1. 首先 `ReferenceConfig#init（）` ，调用 `Protocol#refer（）`生成 `Invoker` 实例（图中的红色部分），这是**服务消费的关键**。
   - **本地服务引用**：如果为本地暴露服务，则 `InjvmProtocol` 生成 `serviceType` 本地执行的 `InjvmInvoker` 。
   - **直连服务引用**：如果为直连服务，则 `DubboProtocol` 创建 Netty 客户端，连接 url 服务，构建 `DubboInvoker` 。
   - **远程服务引用**：如果为非直连的远程服务引用，则 `RegistryProtocol` 注册、订阅 ZK，拉取相关 url 和 配置信息，当有发生变更时，则触发监听器的回调函数，实际调用 `DubboProtocol#refer()` 生成 `DubboInvoker` ，并加入集群，最后默认伪装返回一个 `FailoverClusterInvoker`。
2. 接下来是利用动态代理，把 `Invoker` 转换为客户端需要的接口实现类。

![1637149757299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637149757299.png)

#### 1、本地服务引用

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {
	...
    @Override
    public Object getObject() {
        // 0. 实现Consumer的服务引用
        return get();
    }
}

public class ReferenceConfig<T> extends AbstractReferenceConfig {
    public synchronized T get() {
        checkAndUpdateSubConfigs();

        if (destroyed) {
            throw new IllegalStateException("The invoker of ReferenceConfig(" + url + ") has already destroyed!");
        }
        if (ref == null) {
            // 1. 实现Consumer的服务引用
            init();
        }
        return ref;
    }
    
    private void init() {
        ...
        // 2. 创建服务引用的动态代理
        ref = createProxy(map);
        ...
    }
    
    private T createProxy(Map<String, String> map) {
        // 3. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            ...
    	}
        
        // 5. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class InjvmProtocol extends AbstractProtocol implements Protocol {
    // 4. 生成本地执行的Invoker
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
        return new InjvmInvoker<T>(serviceType, url, url.getServiceKey(), exporterMap);
    }
}
```

#### 2、直连服务引用

1. 在没有注册中心，直连提供者的情况下，`ReferenceConfig` 解析出的 URL 的格式为：`dubbo://service-host/com.foo.FooService?version=1.0.0` 。
2. 基于扩展点自适应机制，通过 URL 的 `dubbo://` 协议头识别，直接调用 `DubboProtocol` 的 `refer()` 方法，建立 Netty 客户端连接，构建 `DubboInvoker`，并加入 invokers 缓存。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 21. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public abstract class AbstractProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 2. 调用protocolBindingRefer
        return new AsyncToSyncInvoker<>(protocolBindingRefer(type, url));
    }
    
    // 3. 模板方法，多态调用DubboProtocol#protocolBindingRefer
    protected abstract <T> Invoker<T> protocolBindingRefer(Class<T> type, URL url) throws RpcException;
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
		...
        //  19. 生成serviceType的invoker
        DubboInvoker<T> invoker = new DubboInvoker<T>(serviceType, url, 
                                                      // 4. 根据url获取客户端连接
                                                      getClients(url), invokers);
        
        // 20. 加入invokers缓存
        invokers.add(invoker);
        return invoker;
    }
    
    private ExchangeClient[] getClients(URL url) {
        ...
        // 5. 初始化客户端连接
        clients[i] = initClient(url);
        ...
    }
    
    private ExchangeClient initClient(URL url) {
        // 6. 进入Exchanger层，连接url服务
        ExchangeClient client = Exchangers.connect(url, requestHandler);
    }
}

public class Exchangers {
    public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {
        ...
        // 7. 进入Exchanger层，连接url服务
        return getExchanger(url).connect(url, handler);
    }
}

public class HeaderExchanger implements Exchanger {
    @Override
    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {
        return new HeaderExchangeClient(
            // 8. 进入Transporter层，连接url服务
            Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);
    }
}

public class Transporters {
    public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException {
        // 9. 进入Transporter层，连接url服务
        return getTransporter().connect(url, handler);
    }
}

public class NettyTransporter implements Transporter {
    @Override
    public Client connect(URL url, ChannelHandler listener) throws RemotingException {
        // 10. 默认打开Netty客户端，连接url服务
        return new NettyClient(url, listener);
    }
}

public class NettyClient extends AbstractClient {
    public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException {
        // 11. 默认打开Netty客户端，连接url服务
        super(url, wrapChannelHandler(url, handler));
    }
    
    @Override
    protected void doOpen() throws Throwable {
        // 14. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
    
    @Override
    protected void doConnect() throws Throwable {
        ...
        // 18. 利用Netty语法，发起url连接
        ChannelFuture future = bootstrap.connect(getConnectAddress());
        ...// 省略Netty语法
    }
}

public abstract class AbstractClient extends AbstractEndpoint implements Client {
    public AbstractClient(URL url, ChannelHandler handler) throws RemotingException {
        ...
        // 12. 打开Netty客户端
        doOpen();
        ...
        // 15. 发起url连接
        connect();
        ...
    }
    
    // 13. 模板方法，多态调用子类NettyClient#doOpen
    protected abstract void doOpen() throws Throwable;
    
    protected void connect() throws RemotingException {
        ...
        // 16. 发起url连接
        doConnect();
        ...
    }
    
    // 17. 模板方法，多态调用子类NettyClient#doConnect
    protected abstract void doConnect() throws Throwable;
}
```

#### 3、远程服务引用

![1637068993216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637068993216.png)

1. 在有注册中心，通过注册中心发现提供者地址的情况下，`ReferenceConfig` 解析出的 URL 的格式为： `registry://registry-host/org.apache.dubbo.registry.RegistryService?refer=URL.encode("consumer://consumer-host/com.foo.FooService?version=1.0.0") `。
2. 基于扩展点自适应机制，通过 URL 的 `registry://` 协议头识别，就会调用 `RegistryProtocol` 的 `refer()` 方法，基于 `refer` 参数中的条件，查询提供者 URL，如： `dubbo://service-host/com.foo.FooService?version=1.0.0` 。
3. 当订阅内容发生更新时，触发监听器回调，里面调用 `protocol.refer()`，基于扩展点自适应机制，通过提供者 URL 的 `dubbo://` 协议头识别，就会调用 `DubboProtocol#refer()` 方法，得到提供者引用。
4. 然后 `RegistryProtocol` 将多个提供者引用，通过 `Cluster` 扩展点，伪装成单个提供者引用 `FailoverClusterInvoker` 返回。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 28. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(url.getProtocol())) {
            return protocol.refer(type, url);
        }
        // 1.1 ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER);
    }
}

public class RegistryProtocol implements Protocol {
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        ...
        // 2. 建立zk的连接，和服务端发布一样（省略代码）
        Registry registry = registryFactory.getRegistry(url);
        ...
        // 3. 引用远程服务
        return doRefer(cluster, registry, type, url);
    }
    
    private <T> Invoker<T> doRefer(Cluster cluster, Registry registry, Class<T> type, URL url) {
        // 4. 建立url Invoker目录
        RegistryDirectory<T> directory = new RegistryDirectory<T>(type, url);
        ...
        // 5. 和服务端发布一样，注册ZK，创建zk的节点
        registry.register(directory.getRegisteredConsumerUrl());
        ...
        // 9. 和服务端发布一样，订阅ZK节点：/dubbo/com.alibaba.dubbo.demo.DemoService/providers，/dubbo/com.alibaba.dubbo.demo.DemoService/configurators，/dubbo/com.alibaba.dubbo.demo.DemoService/routers，url发生变化，则刷新Invoker
        directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY,
                                                      PROVIDERS_CATEGORY + "," + CONFIGURATORS_CATEGORY + "," + ROUTERS_CATEGORY));
        
        // 25. 根据directory，加入集群路由
        Invoker invoker = cluster.join(directory);
        ...
        return invoker;
    }
    
    public void subscribe(URL url) {
        ...
        // 10. 订阅ZK节点
        registry.subscribe(url, this);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void register(URL url) {
        // 6. 注册ZK，创建zk的节点
        doRegister(url);
    }
    
    // 7. 模板方法，多态调用ZookeeperRegistry#doRegister
    public abstract void doRegister(URL url);
    
    @Override
    public void subscribe(URL url, NotifyListener listener) {
        ...
        // 11. 订阅ZK节点
        doSubscribe(url, listener);
    }
    
    // 12. 模板方法，多态调用ZookeeperRegistry#doSubscribe
    public abstract void doSubscribe(URL url, NotifyListener listener);
    
    @Override
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 14. 通知更新url配置
        doNotify(url, listener, urls);
        ...
    }
    
    protected void doNotify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 15. 通知更新url配置
        super.notify(url, listener, urls);
        ...
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    @Override
    public void doRegister(URL url) {
        // 8. 创建ZK持久化：dubbo/com.alibaba.dubbo.demo.DemoService/consumers
        zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true));
    }
    
    @Override
    public void doSubscribe(final URL url, final NotifyListener listener) {
        ...
        // 13. 通知更新url配置 
        notify(url, listener, urls);
    }
}

public abstract class AbstractRegistry implements Registry {
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 19. 通知更新url配置，生成新的Invoker
        listener.notify(categoryList);
        // 29. 通过线程池，异步把服务端的注册url信息更新到C:\Users\bobo\.dubbo\dubbo-registry-192.168.48.117.cache
        saveProperties(url);
    }
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        ...
        // 16. 通知更新url配置，刷新Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 17. 更新configurators配置（和服务端一样，省略代码）
        overrideDirectoryUrl();
        // 18. 刷新Invoker列表
        refreshInvoker(urls);
    }
    
    private void refreshInvoker(List<URL> invokerUrls) {
        // 19. 根据url生成新的Invoker
        Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls);
        List<Invoker<T>> newInvokers = Collections.unmodifiableList(new ArrayList<>(newUrlInvokerMap.values()));
        routerChain.setInvokers(newInvokers);
        this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers;
        this.urlInvokerMap = newUrlInvokerMap;
    }
    
    private Map<String, Invoker<T>> toInvokers(List<URL> urls) {
        // 20. 调用父类AbstractProtocol#refer
        invoker = new InvokerDelegate<>(protocol.refer(serviceType, url), url, providerUrl);
        ...
    }
}

public abstract class AbstractProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 21. 调用protocolBindingRefer
        return new AsyncToSyncInvoker<>(protocolBindingRefer(type, url));
    }
    
    // 22. 模板方法，多态调用DubboProtocol#protocolBindingRefer
    protected abstract <T> Invoker<T> protocolBindingRefer(Class<T> type, URL url) throws RpcException;
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
        // 23. 和服务端一样，根据接口class和url，生成DubboInvoker
        DubboInvoker<T> invoker = new DubboInvoker<T>(serviceType, url, getClients(url), invokers);
        // 24. 加入invokers缓存
        invokers.add(invoker);
        return invoker;
    }
}

public class MockClusterWrapper implements Cluster {
    @Override
    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {
        return new MockClusterInvoker<T>(directory,
                // 26. MockCluster包装类
                this.cluster.join(directory));
    }
}

public class FailoverCluster implements Cluster {
    @Override
    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {
        // 27. 默认构建失败重试集群Invoker（省略构造函数）
        return new FailoverClusterInvoker<T>(directory);
    }
}
```

#### 4、生成接口的动态代理类

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 2. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class StubProxyFactoryWrapper implements ProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker) throws RpcException {
        // 3. 调用父类AbstractProxyFactory#getProxy
        T proxy = proxyFactory.getProxy(invoker);
        ...
        return proxy;
    }
}

public abstract class AbstractProxyFactory implements ProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker) throws RpcException {
        // 4. 调用非泛化方法生成代理对象
        return getProxy(invoker, false);
    }
    
    @Override
    public <T> T getProxy(Invoker<T> invoker, boolean generic) throws RpcException {
        ...
        // 5. 调用实现类#getProxy生成代理对象
        return getProxy(invoker, interfaces);
    }
    
    // 6. 模板方法，多态调用JavassistProxyFactory#getProxy生成代理对象
    public abstract <T> T getProxy(Invoker<T> invoker, Class<?>[] types);
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 7. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}
```

### 2.5. Dubbo 服务调用原理？

![1636896757166](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896757166.png)

1. 消费方使用的接口动态代理实现类，就是图中服务消费端的 proxy，用户代码通过这个 proxy 调用其对应的 `Invoker`，而该 `Invoker` 实现了真正的远程服务调用。

2. 而提供方的实现类，则会被封装成为一个 `AbstractProxyInvoker` ，然后生成一个 `Exporter` ，当服务提供方收到一个请求后，则会找到对应的 `Exporter` 实例，并调用它所对应的 `AbstractProxyInvoker` 实例，从而真正调用了服务提供者的代码。

3. 整个**消费方调用提供方**的调用链架构如下：

   ![1637150417647](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637150417647.png)

   1. **服务引用**：通过 Javassist 反向代理，代理调用 InvokerInvocationHandler#invoke 方法。
   2. 服务本地调用、**降级**、缓存。
   3. **集群容错与负载均衡**：非 mock Invoker 筛选，Invoker 目录查找，根据容错策略、负载均衡策略，挑选唯一的 Invoker。
   4. 服务**过滤链**、监听器、包装类 SPI 扩展。
   5. **服务协议**：根据协议，使用不同的 Invoker 调用不同的网络传输底层。
   6. **网络传输**：抽象 Netty、Mina 等统一接口，把消息序列化后发送到网络，传输给 Server 端。
   7. **消息接收与异步处理**：Server 端接收到消息后，经过反序列化后，交由线程池异步处理。
   8. **服务协议**：根据协议，选择不同的 Exporter 进行调用。
   9. 服务**过滤链**、监听器、包装类 SPI 扩展。
   10. **服务调用**：最后调用真正的接口实现类，得到方法执行结果。

4. 而**提供方响应消费方**的顺序为：

   1. **服务响应**：在得到方法执行结果后，通过网络传输底层，序列化后发送响应报文给客户端。
   2. **结果接收**：客户端接收到响应报文后，交由线程池异步处理程序，经过反序列化后塞回到 Future 对象中，完成一次服务调用。

#### 1、消费方发起服务请求

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 0. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

public class InvokerInvocationHandler implements InvocationHandler {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        ...
        // 1. 动态代理执行
		return invoker.invoke(new RpcInvocation(method, args)).recreate();
    }
}

public class MockClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        ...
        // 2. 交由抽象父类执行
        result = this.invoker.invoke(invocation);
        ...
    }
}

public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(final Invocation invocation) throws RpcException {
        ...
        // 3. 进入目录查找，从this.methodInvokerMap里面查找一个Invoker
        List<Invoker<T>> invokers = list(invocation);
        ...
        
        // 11. 进入集群，交由集群路由执行
        return doInvoke(invocation, invokers, loadbalance);
    }
    
    protected List<Invoker<T>> list(Invocation invocation) throws RpcException {
        // 4. 从this.methodInvokerMap里面查找一个Invoker
        return directory.list(invocation);
    }
    
    // 12. 模板方法，交由FailoverClusterInvoker#doInvoke执行
    protected abstract Result doInvoke(Invocation invocation, List<Invoker<T>> invokers,LoadBalance loadbalance) throws RpcException;
    
    protected Invoker<T> select(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
		// 14. 进入负载均衡
        Invoker<T> invoker = doSelect(loadbalance, invocation, invokers, selected);
        ...
    }
    
    private Invoker<T> doSelect(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
        // 15. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        Invoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);
        ...
    }
}

public abstract class AbstractDirectory<T> implements Directory<T> {
    @Override
    public List<Invoker<T>> list(Invocation invocation) throws RpcException {
        ...
        // 5. 从this.methodInvokerMap里面查找一个Invoker
        return doList(invocation);
    }
    
    // 6. 模板方法，多态调用子类RegistryDirectory#doList
    protected abstract List<Invoker<T>> doList(Invocation invocation) throws RpcException;
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public List<Invoker<T>> doList(Invocation invocation) {
        ...
        // 7. 进入路由 
        List<Invoker<T>> invokers = routerChain.route(getConsumerUrl(), invocation);
        ...
    }
}

public class RouterChain<T> {
    public List<Invoker<T>> route(URL url, Invocation invocation) {
        List<Invoker<T>> finalInvokers = invokers;
        for (Router router : routers) {
            // 8. 进入路由 
            finalInvokers = router.route(finalInvokers, url, invocation);
        }
        return finalInvokers;
    }
}

public class MockInvokersSelector extends AbstractRouter {
    @Override
    public <T> List<Invoker<T>> route(final List<Invoker<T>> invokers,
                                      URL url, final Invocation invocation) throws RpcException {
        ...
		// 9. 获取正常路径的Invoker
        return getNormalInvokers(invokers);
    }
    
    private <T> List<Invoker<T>> getNormalInvokers(final List<Invoker<T>> invokers) {
        if (!hasMockProviders(invokers)) {
            return invokers;
        } else {
            List<Invoker<T>> sInvokers = new ArrayList<Invoker<T>>(invokers.size());
            for (Invoker<T> invoker : invokers) {
                // 10. 过滤掉非正常路径的Invoker，即mock协议路径的Invoker不需要
                if (!invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) {
                    sInvokers.add(invoker);
                }
            }
            return sInvokers;
        }
    }
}

public class FailoverClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, final List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        // 13. 进入负载均衡
        Invoker<T> invoker = select(loadbalance, invocation, copyInvokers, invoked);
        ...
        
        // 20. 使用负载均衡得到的Invoker执行
        Result result = invoker.invoke(invocation);
        return result;
    }
}

public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 16. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 17. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
}

public class RandomLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 18. 根据随机权重得到Invoker索引
        int offset = ThreadLocalRandom.current().nextInt(totalWeight);
        ...
        // 19. 根据Invoker索引获取对应的Invoker
        return invokers.get(ThreadLocalRandom.current().nextInt(length));
    }
}

public class InvokerWrapper<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 21. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        last = new Invoker<T>() {
            public Result invoke(Invocation invocation) throws RpcException {
                ...
                // 22. 负载均衡得到的Invoker执行前，被过滤器拦截，用于添加一系列过滤器链
                Result asyncResult = filter.invoke(last, invocation);
                return asyncResult;
            }
        }
        ...
    }
}

// ... 可扩展一大堆包装类和过滤器

public class ConsumerInvokerWrapper<T> implements Invoker {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 23. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public class ListenerInvokerWrapper<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 24. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public abstract class AbstractInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation inv) throws RpcException {
        ...
        // 25. 负载均衡得到的Invoker执行前，先执行父类方法
        return doInvoke(invocation);
    }
    
    // 26. 模板方法，多态调用DubboInvoker#doInvoke => DubboInvoker为多态实例的原因见：RegistryDirectory.refreshInvoker.toInvokers#protocol.refer
    protected abstract Result doInvoke(Invocation invocation) throws Throwable;
}

public class DubboInvoker<T> extends AbstractInvoker<T> {
    @Override
    protected Result doInvoke(final Invocation invocation) throws Throwable {
        ...
        // 27. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        CompletableFuture<Object> responseFuture = currentClient.request(inv, timeout);
        ...
    }
}

final class ReferenceCountExchangeClient implements ExchangeClient {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        // 28. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        return client.request(request, timeout);
    }
}

public class HeaderExchangeClient implements ExchangeClient {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        // 29. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        return channel.request(request, timeout);
    }
}

final class HeaderExchangeChannel implements ExchangeChannel {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        ...
        // 30. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        channel.send(req);
        ...
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void send(Object message) throws RemotingException {
        // 31. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        send(message, url.getParameter(Constants.SENT_KEY, false));
    }
}

final class NettyChannel extends AbstractChannel {
    @Override
    public void send(Object message, boolean sent) throws RemotingException {
        ...
        // 32. 最后使用Netty客户端channel，向远程服务发起consumer#request请求
        ChannelFuture future = channel.writeAndFlush(message);
        ...
    }
}
```

#### 2、提供方接收并响应

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

public class NettyServerHandler extends ChannelDuplexHandler {
    // 1. Netty读事件
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler);
        // 2. 当有请求数据时，则调用handler进行接收、处理
        handler.received(channel, msg);
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void received(Channel ch, Object msg) throws RemotingException {
        ...
        // 3. 当有请求数据时，则调用handler进行接收、处理
        handler.received(ch, msg);
    }
}

public class HeartbeatHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 4. 当有请求数据时，则调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        // 4. 当有请求数据时，使用线程池异步接收、处理
        executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        ...
    }
}

public class ChannelEventRunnable implements Runnable {
    @Override
    public void run() {
        // 5. 数据接收事件，继续调用handler进行接收、处理
        if (state == ChannelState.RECEIVED) {
            handler.received(channel, message);
        } else {
           .... 
        }
    }
}

public class DecodeHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 6. 继续调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class HeaderExchangeHandler implements ChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 7. 如果报文属于来回传输类型，则调用handleRequest接收、处理，并响应客户端
        if (request.isTwoWay()) {
            handleRequest(exchangeChannel, request);
        }
        // 而如果报文属于onoWay单程传输类型，则调用received只接收、处理，不会响应客户端
        else {
            handler.received(exchangeChannel, request.getData());
        }
        ...
    }
    
    void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException {
        ...
        // 8. 调用reply处理方法，得到返回结果future
        CompletionStage<Object> future = handler.reply(channel, msg);
        future.whenComplete((appResult, t) -> {
            try {
                if (t == null) {
                    res.setStatus(Response.OK);
                    res.setResult(appResult);
                } else {
                    res.setStatus(Response.SERVICE_ERROR);
                    res.setErrorMessage(StringUtils.toString(t));
                }
                
                // 20. 最后把结果返回写回给客户端，发送流程类似于客户端请求流程（代码略）
                channel.send(res);
            } catch (RemotingException e) {
                logger.warn("Send result to consumer failed, channel is " + channel + ", msg is " + e);
            }
        });
        ...
    }
}

public class DubboProtocol extends AbstractProtocol {
    private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() {
        @Override
        public CompletableFuture<Object> reply(ExchangeChannel channel, Object message) throws RemotingException {
            ...
			// 9. 先根据报文，提取对应的Invoker
            Invoker<?> invoker = getInvoker(channel, inv);
            ...
            // 13. 调用提取到的Invoker#invoker方法
            Result result = invoker.invoke(inv);
            
            // 19. 最后把结果返回到外层
            return result.completionFuture().thenApply(Function.identity());
        }
    }
    
    Invoker<?> getInvoker(Channel channel, Invocation inv) throws RemotingException  {
        ...
        // 10. 端口+url+版本号+组号，组装成servicekey
        String serviceKey = serviceKey(port, path, inv.getAttachments().get(VERSION_KEY), inv.getAttachments().get(GROUP_KEY)); 
        // 11. 根据servicekey从之前缓存起来的exports中，提取出exporter
        DubboExporter<?> exporter = (DubboExporter<?>) exporterMap.get(serviceKey);
        ...
        // 12. 然后返回exporter中的Invoker
        return exporter.getInvoker();
    }
}

public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        last = new Invoker<T>() {
            public Result invoke(Invocation invocation) throws RpcException {
                // 14. invoker方法调用前，被过滤器拦截
                Result asyncResult = filter.invoke(last, invocation);
                return asyncResult;
            }
        }
    }
}

public class EchoFilter implements Filter {
    @Override
    public Result invoke(Invoker<?> invoker, Invocation inv) throws RpcException {
        ...
        // 15. invoker方法调用前，被过滤器拦截
        return invoker.invoke(inv);
    }
}

// ... 可扩展一大堆包装类和过滤器

public abstract class AbstractProxyInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 16. invoker方法调用前，过滤器、监听器、包装类执行后，还需要先执行父类的doInvoke方法
        Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments());
        ...
    }
    
    // 17. 模板方法，多态调用AbstractProxyInvoker#doInvoke方法
    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 18. 最后才调用回实际接口实现类的方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
}
```

#### 3、消费方接收服务响应

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

public class NettyClientHandler extends ChannelDuplexHandler {
    // 1. Netty读事件
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler);
        // 2. 读事件触发后，调用handler进行接收、处理
        handler.received(channel, msg);
        ...
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void received(Channel ch, Object msg) throws RemotingException {
        ...
        // 3. 调用handler进行接收、处理
        handler.received(ch, msg);
    }
}

public class MultiMessageHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 4. 调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class HeartbeatHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 5. 调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getExecutorService();
        // 6. 利用线程池，异步调用handler进行接收、处理
        executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        ...
    }
}

public class ChannelEventRunnable implements Runnable {
    @Override
    public void run() {
        // 7. 如果为数据接收类型，则继续调用handler进行接收、处理
        if (state == ChannelState.RECEIVED) {
            handler.received(channel, message);
        } else {
            ...
        }
    }
}

public class HeaderExchangeHandler implements ChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        if (message instanceof Request) {
            ...
        } else {
            // 8. 如果为响应报文，则继续调用handleResponse进行接收、处理
            handleResponse(channel, (Response) message);
        } else {
            ...
        }
    }
    
    static void handleResponse(Channel channel, Response response) throws RemotingException {
        if (response != null && !response.isHeartbeat()) {
            // 9. 如果为响应报文，则继续调用received进行接收、处理
            DefaultFuture.received(channel, response);
        }
    }
}

public class DefaultFuture extends CompletableFuture<Object> {
    public static void received(Channel channel, Response response) {
        // 10. 继续调用received进行接收、处理
        received(channel, response, false);
    }
    
    public static void received(Channel channel, Response response, boolean timeout) {
        ...
        // 11. 继续调用received进行接收、处理
        future.doReceived(response);
        ...
    }
    
    private void doReceived(Response res) {
 		...
        if (res.getStatus() == Response.OK) {
            // 12. 如果报文响应OK=20，则取出响应数据，设置到之前返回的future中
            this.complete(res.getResult());
        } else {
            ...
        }
    }
}
```

### 2.6. Dubbo 协议编解码原理？

#### 1、协议格式

![1637153667359](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637153667359.png)

Dubbo 协议，通过消息头（16 字节 = 4 + 8 + 4）+ 消息体（不限），来解决 TCP 拆包、粘包的问题。

| 头属性           | 长度   | 作用                                                         |
| ---------------- | ------ | ------------------------------------------------------------ |
| Magic            | 16 bit | 魔数，标识 Dubbo 协议                                        |
| Req/Res          | 1 bit  | 标识报文是请求（1）还是响应（0）                             |
| 2 Way            | 1 bit  | 双向或单向的标记 ，仅当 Req/Res 为 1（请求）时才有用，如果需要来自服务器的返回值，则会设置为 1 |
| Event            | 1 bit  | 标识事件消息与否，比如心跳事件，如果这是一个事件，则设置为 1，而请求是没有的 |
| Serialization ID | 5 bit  | 标识序列化类型，比如 fastjson 的值为 6                       |
| Status           | 8 bit  | 仅在 Req/Res 为 0（响应）时有用，标识响应状态：20 - OK，30 - CLIENT_TIMEOUT，31 - SERVER_TIMEOUT，40 - BAD_REQUEST，50 - BAD_RESPONSE，60 - SERVICE_NOT_FOUND，70 - SERVICE_ERROR，80 - SERVER_ERROR，90 - CLIENT_ERROR，100 - SERVER_THREADPOOL_EXHAUSTED_ERROR |
| Request ID       | 64 bit | 请求 ID，标识唯一的请求，long 类型数字                       |
| Data Length      | 32 bit | 请求体序列化后的长度，以字节为单位，int 类型数字             |
| Variable Part    | 不限   | 请求体，长度可变，每个部分是序列化后的字节数组，由序列化ID标识，最大长度为 Integer.MAX_VALUE |
#### 2、消费方编码请求

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalEncoder extends MessageToByteEncoder {
        @Override
        protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception {
            ...
            // 1. 调用codec进行编码
            codec.encode(channel, buffer, msg);
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 2. 调用codec进行编码
        codec.encode(channel, buffer, msg);
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 3. 如果消息为请求类型，则对请求进行编码
        if (msg instanceof Request) {
            encodeRequest(channel, buffer, (Request) msg);
        } else if (msg instanceof Response) {
            ...
        } else {
            ...
        }
    }
    
    protected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {
        ...
        // 4. 初始化消息头=16字节长的字节数组
        byte[] header = new byte[HEADER_LENGTH];
        
        // 5. 2字节长的魔数
        Bytes.short2bytes(MAGIC, header);
        
        // 6. 1字节长的请求标识、来回标识、序列化类型
        header[2] = (byte) (FLAG_REQUEST | serialization.getContentTypeId());
        if (req.isTwoWay()) {
            header[2] |= FLAG_TWOWAY;
        }
        // 7. 消费请求报文，没有Event事件标识，也没有status状态标识
        if (req.isEvent()) {
            header[2] |= FLAG_EVENT;
        }
        
        // 8. 8字节长的请求唯一ID
        Bytes.long2bytes(req.getId(), header, 4);
        ...
        // 9. 4字节长的请求体序列化后的长度
        int len = bos.writtenBytes();
        checkPayload(channel, len);
        Bytes.int2bytes(len, header, 12);
        ...
        // 10. write header.
        buffer.writeBytes(header); 
        ...
    }
}
```

#### 3、提供方解码请求

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalDecoder extends ByteToMessageDecoder {
        @Override
        protected void decode(ChannelHandlerContext ctx, ByteBuf input, List<Object> out) throws Exception {
            ...
            // 1. 调用codec解码
            Object msg = codec.decode(channel, message);
            ...
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        ...
        // 2. 调用codec解码
        Object obj = codec.decode(channel, buffer);
        ...
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        int readable = buffer.readableBytes();
        
        // 3. 读取16字节长的消息头
        byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];
        buffer.readBytes(header);
        
        // 4. 校验消息头，并解码消息体
        return decode(channel, buffer, readable, header);
    }
}
```

#### 4、提供方编码响应

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalEncoder extends MessageToByteEncoder {
        @Override
        protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception {
            ...
            // 1. 调用codec编码
            codec.encode(channel, buffer, msg);
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 2. 调用codec编码
        codec.encode(channel, buffer, msg);
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        if (msg instanceof Request) {
            ...
        } 
        // 3. 如果消息为响应类型，则对响应进行编码
        else if (msg instanceof Response) {
            encodeResponse(channel, buffer, (Response) msg);
        } else {
            ...
        }
    }
    
    protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException {
        // 4. 初始化消息头=16字节长的字节数组
        byte[] header = new byte[HEADER_LENGTH];
        
        // 5. 2字节长的魔数
        Bytes.short2bytes(MAGIC, header);
        
        // 6. 1字节长的请求标识、来回标识、序列化类型、Event事件标识（响应报文才有）
        header[2] = serialization.getContentTypeId();
        if (res.isHeartbeat()) {
            header[2] |= FLAG_EVENT;
        }
        
        // 7. 1字节长的响应状态码(响应报文才有)
        byte status = res.getStatus();
        header[3] = status;
        
        // 8. 8字节长的请求唯一标识
        Bytes.long2bytes(res.getId(), header, 4);
        ...
        // 9. 4字节长的请求体序列化后的长度
        int len = bos.writtenBytes();
        checkPayload(channel, len);
        Bytes.int2bytes(len, header, 12);
        ...
        // 10. write header.
        buffer.writeBytes(header); 
        ...
    }
}
```

#### 5、消费方解码响应

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalDecoder extends ByteToMessageDecoder {
        @Override
        protected void decode(ChannelHandlerContext ctx, ByteBuf input, List<Object> out) throws Exception {
            ...
			// 1. 调用codec解码
            Object msg = codec.decode(channel, message);
            ...
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        ...
        // 2. 调用codec解码
        Object obj = codec.decode(channel, buffer);
        ...
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        int readable = buffer.readableBytes();
        
        // 3. 读取16字节长的消息头
        byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];
        buffer.readBytes(header);
        
        // 4. 校验消息头，并解码消息体
        return decode(channel, buffer, readable, header);
    }
}
```

### 2.7. Dubbo 集群容错原理？

#### 集群容错策略

在集群**调用失败**时或者**发起调用前**，Dubbo 提供 6 种集群容错方案，缺省为 `failover` 失败自动切换，可通过 SPI 自行扩展。

| 集群模式          | 作用                                               | 适用场景                                                     |
| ----------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| Failover Cluster  | 默认配置，失败自动切换，当出现失败，重试其它服务器 | 通常用于读操作，但重试会带来更长延迟，可通过 `retries="2"` 来设置额外重试次数（不含第一次） |
| Failfast Cluster  | 快速失败，只发起一次调用，失败则立即报错           | 通常用于非幂等性的写操作，比如新增记录                       |
| Failsafe Cluster  | 安全失败，出现异常时，会直接忽略                   | 通常用于写入审计日志等操作                                   |
| Failback Cluster  | 失败自动恢复，后台记录失败请求，然后定时重发       | 通常用于消息通知操作                                         |
| Forking Cluster   | 并行调用多个服务器，只要一个成功即返回             | 通常用于实时性要求较高的读操作，但需要浪费更多服务资源，可通过 `forks="2"` 来设置最大并行数 |
| Broadcast Cluster | 广播调用所有提供者，逐个调用，任意一台报错则报错   | 通常用于通知所有提供者更新缓存或者日志等本地资源信息，可以通过 `broadcast.fail.percent` 配置节点调用失败的比例，当达到这个比例后，将不再调用其他节点，而是直接抛出异常，取值范围为 0 ~ 100，默认情况下当全部调用失败后，才会抛出异常 |

#### 策略实现原理

```java
public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(final Invocation invocation) throws RpcException {
        ...
        // 0.1. 进入目录查找，从this.methodInvokerMap里面查找一个Invoker
        List<Invoker<T>> invokers = list(invocation);
        ...
        
        // 0.2. 进入集群，交由集群路由执行
        return doInvoke(invocation, invokers, loadbalance);
    }
    
    // 0.3. 模板方法，交由*ClusterInvoker#doInvoke执行
    protected abstract Result doInvoke(Invocation invocation, List<Invoker<T>> invokers,LoadBalance loadbalance) throws RpcException;
}
```

##### Failover | 失败重试

```java
public class FailoverClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, final List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        // 1. 获取retries参数，默认额外重试2次
        int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1;

        // 2. 这里retries再加1，代表共尝试3次
        for (int i = 0; i < len; i++) {
            try {
                Result result = invoker.invoke(invocation);
                return result;
            } catch (RpcException e) {
                if (e.isBiz()) { // biz exception.
                    throw e;
                }
                le = e;
            } catch (Throwable e) {
                // 3. catch住异常，然后循环重试
                le = new RpcException(e.getMessage(), e);
            } finally {
                providers.add(invoker.getUrl().getAddress());
            }
        }
        
        // 4. 重试完毕后，如果还没返回结果，说明全部都失败了，则抛出异常
        throw new RpcException(...);
    }
}
```

##### Failfast | 快速失败

```java
public class FailfastClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        try {
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            if (e instanceof RpcException && ((RpcException) e).isBiz()) { // biz exception.
                throw (RpcException) e;
            }
            
            // 1. 发生异常直接抛出
            throw new RpcException(...);
        }
    }
}
```

##### Failsafe | 安全失败

```java
public class FailsafeClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        try {
            ...
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            // 1. 发生异常只打印到日志中，然后返回null
            logger.error("Failsafe ignore exception: " + e.getMessage(), e);
            return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore
        }
    }
}
```

##### Failback | 失败自动恢复

```java
public class FailbackClusterInvoker<T> extends AbstractClusterInvoker<T> {

    @Override
    protected Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        Invoker<T> invoker = null;
        try {
            ...
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            // 1. 发生异常不仅打印到日志中
            logger.error(...);
            
            // 2. 还设置定时任务，重试执行，并返回null，后面的重试再无返回值
            addFailed(loadbalance, invocation, invokers, invoker);
            return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore
        }
    }
    
    private void addFailed(LoadBalance loadbalance, Invocation invocation, List<Invoker<T>> invokers, Invoker<T> lastInvoker) {
        // 3. 双重检查锁创建定时器
        if (failTimer == null) {
            synchronized (this) {
                if (failTimer == null) {
                    failTimer = new HashedWheelTimer(
                            new NamedThreadFactory("failback-cluster-timer", true),
                            1,
                            TimeUnit.SECONDS, 32, failbackTasks);
                }
            }
        }
        
        // 4. 创建重试任务，每5s执行一次
        RetryTimerTask retryTimerTask = new RetryTimerTask(loadbalance, invocation, invokers, lastInvoker, retries, RETRY_FAILED_PERIOD);
        try {
            failTimer.newTimeout(retryTimerTask, RETRY_FAILED_PERIOD, TimeUnit.SECONDS);
        } catch (Throwable e) {
            logger.error("Failback background works error,invocation->" + invocation + ", exception: " + e.getMessage());
        }
    }
    
    private class RetryTimerTask implements TimerTask {
        @Override
        public void run(Timeout timeout) {
            try {
                ...
                // 5. 发起重新执行，无返回值，会一直重试！
                retryInvoker.invoke(invocation);
            } catch (Throwable e) {
                logger.error(...);
                if ((++retryTimes) >= retries) {
                    logger.error(...);
                } else {
                    // 6. 超过了最大重试次数retries，默认共3次，则重新添加定时任务，继续重试
                    rePut(timeout);
                }
            }
        }
        
        private void rePut(Timeout timeout) {
            if (timeout == null) {
                return;
            }

            Timer timer = timeout.timer();
            if (timer.isStop() || timeout.isCancelled()) {
                return;
            }

            // 7. 超过了最大重试次数retries，默认共3次，则重新添加定时任务，继续重试
            timer.newTimeout(timeout.task(), tick, TimeUnit.SECONDS);
        }
    }
}
```

##### Forking | 并行调用

```java
public class ForkingClusterInvoker<T> extends AbstractClusterInvoker<T> {
    
    // 0. 并行调用的缓存线程池
    private final ExecutorService executor = Executors.newCachedThreadPool(
            new NamedInternalThreadFactory("forking-cluster-timer", true));
    
    @Override
    public Result doInvoke(final Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        final List<Invoker<T>> selected;
        
        // 1. 获取并行调用数量，默认为2
        final int forks = getUrl().getParameter(FORKS_KEY, DEFAULT_FORKS);
        
        // 2. 设置并行调用的Invoker列表
        selected = new ArrayList<>();
        for (int i = 0; i < forks; i++) {
            Invoker<T> invoker = select(loadbalance, invocation, invokers, selected);
            if (!selected.contains(invoker)) {.
                selected.add(invoker);
            }
        }
        
        // 3. 遍历并行调用的Invoker列表，交由线程池并行调用
        final BlockingQueue<Object> ref = new LinkedBlockingQueue<>();
        for (final Invoker<T> invoker : selected) {
            executor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        Result result = invoker.invoke(invocation);
                        
                        // 4. 执行结果添加到LinkedBlockingQueue中
                        ref.offer(result);
                    } catch (Throwable e) {
                        int value = count.incrementAndGet();
                        if (value >= selected.size()) {
                            ref.offer(e);
                        }
                    }
                }
            });
        }
        
        try {
            // 5. 超时阻塞式从LinkedBlockingQueue中，取出第一个结果并返回，如果结果异常则抛出
            Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS);
            if (ret instanceof Throwable) {
                Throwable e = (Throwable) ret;
                throw new RpcException(...);
            }
            return (Result) ret;
        } catch (InterruptedException e) {
            throw new RpcException(...);
        }
        
        ...
    }
}
```

##### Broadcast | 逐个广播式调用

```java
public class BroadcastClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(final Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        RpcException exception = null;
        Result result = null;
        
        // 1. 不做任何的负载均衡
        for (Invoker<T> invoker : invokers) {
            try {
                // 2. 每个Invoker都执行一遍
                result = invoker.invoke(invocation);
            } catch (RpcException e) {
                exception = e;
                logger.warn(e.getMessage(), e);
            } catch (Throwable e) {
                exception = new RpcException(e.getMessage(), e);
                logger.warn(e.getMessage(), e);
            }
        }
        
        // 2. 任何一台报错则报错
        if (exception != null) {
            throw exception;
        }
        
        // 3. 只返回最后一次执行成功的结果
        return result;
    }
}
```

### 2.8. Dubbo 负载均衡原理？

#### 负载均衡策略

在集群负载均衡时，Dubbo 提供了 5 种负载均衡策略，缺省为 `random` 随机调用，可通过 SPI 自行扩展。

1. ⼀个请求从客户端发起，⽐如查询订单列表，要选择服务器进⾏处理，但是集群环境提供了 5 个服务器，每个服务器都有处理这个请求的能⼒，此时，客户端就必须选择⼀个服务器来进⾏处理，说⽩了，负载均衡就是⼀个选择的问题。
2. 当请求多了，负载均衡的优点则得以体现：可以均衡各服务器的负载，避免单个服务器响应同⼀请求，而导致的服务器宕机、崩溃等问题。

| 负载均衡策略                 | 作用                                                         | 特点                                                         |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Random LoadBalance           | 默认策略，随机，按权重设置随机概率                           | 在一个截面上碰撞的概率高，但调用量越大分布越**均匀**，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重 |
| RoundRobin LoadBalance       | 轮训，按公约后的权重设置轮训比率                             | 存在慢的提供者**累积请求**的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上 |
| LeastActive LoadBalance      | 最少活跃调用数，相同活跃数的则随机，活跃数指并发调用的数量   | 使并发少的提供者收到**更多请求**，因为并发越少的提供者，压力更小；使并发多的提供者收到**更少请求**，因为并发越的多提供者，压力更大 |
| ShortestResponse LoadBalance | 最短响应负载，优先选择平均调用成功时长短、响应效率高，而相同响应时长的则随机选取 | 使快的提供者收到**更多请求**，因为越快的提供者，调用的平均成功时长越小；使慢的提供者收到**更少请求**，因为越慢的提供者，调用的平均成功时长越大 |
| ConsistentHash LoadBalance   | 一致性 Hash，相同参数的请求总是发到同一提供者，缺省用 160 份虚拟节点，可通过 `dubbo:parameter` 进行修改 | 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，**不会引起剧烈变动** |

#### 策略实现原理

```java
public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    
    // 0.1. 从具体的ClusterInvoker#doInvoke中回调
    protected Invoker<T> select(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
		// 0.2. 进入负载均衡
        Invoker<T> invoker = doSelect(loadbalance, invocation, invokers, selected);
        ...
    }
    
    private Invoker<T> doSelect(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
        // 0.3. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        Invoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);
        ...
    }
}

public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 0.4. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 0.5. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
    
    // 0.6. 根据会话状态获取路由权重
    int getWeight(Invoker<?> invoker, Invocation invocation) {
        int weight;
        URL url = invoker.getUrl();

        // 0.7. 当有多个注册地址时,根据注册地址key 获取对应服务权重
        if (REGISTRY_SERVICE_REFERENCE_PATH.equals(url.getServiceInterface())) {
            weight = url.getParameter(REGISTRY_KEY + "." + WEIGHT_KEY, DEFAULT_WEIGHT);
        } else {
            // 0.8. 从url获取权重，默认100
            weight = url.getMethodParameter(invocation.getMethodName(), WEIGHT_KEY, DEFAULT_WEIGHT);
            if (weight > 0) {
                // 以下过程主要是，判断机器的启动时间和预热时间的差值(默认为10min), 为什么要预热? 
                // 1、服务预热是一个优化手段，与此类似的还有 JVM 预热，主要目的是让服务启动后“低功率”运行一段时间，使其效率慢慢提升至最佳状态，避免由此引发的调用超时问题。

                // 0.9. 获取启动时间
                long timestamp = invoker.getUrl().getParameter(TIMESTAMP_KEY, 0L);
                if (timestamp > 0L) {
                    // 0.91. 获取运行时间
                    long uptime = System.currentTimeMillis() - timestamp;
                    if (uptime < 0) {
                        return 1;
                    }
                    // 0.92. 获取服务预热时间，默认为10分钟
                    int warmup = invoker.getUrl().getParameter(WARMUP_KEY, DEFAULT_WARMUP);
                    if (uptime > 0 && uptime < warmup) {
                        // 0.93. 重新计算服务权重
                        weight = calculateWarmupWeight((int)uptime, warmup, weight);
                    }
                }
            }
        }

        return Math.max(weight, 0);
    }
    
    // 0.94. 重新计算服务权重，当服务运行时长小于服务预热时间时，则会对服务进行降权，以避免让服务在启动之初就处于高负载状态
    static int calculateWarmupWeight(int uptime, int warmup, int weight) {
        // 0.95. 计算权重，下面代码逻辑上形似于 (uptime / warmup) * weight，可见，随着服务运行时间 uptime 增大，权重计算值 ww 会慢慢接近配置值 weight
        int ww = (int) ( uptime / ((float) warmup / weight));
        return ww < 1 ? 1 : (Math.min(ww, weight));
    }
}
```

##### Random | 随机

1. 遍历 invokers 列表，获取它们降权后的路由权重，并累加它们的权重，然后比较它们的权重值是否相等。
2. 如果它们权重不相等，则根据权重和，求出一个**随机数**，并计算看该数落在权重数组的哪个区间段，然后取该区间段权重最大的 invoker 索引，去 invokers 集合中获取返回。
3. 如果它们权重都相等，则随机返回一个 invoker 即可。

```java
public class RandomLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        int length = invokers.size()
        boolean sameWeight = true;
        int[] weights = new int[length];
        int totalWeight = 0;
        
        // 1. 累加总权重
        for (int i = 0; i < length; i++) {
            // 2. 获取路由权重（包括预热降权）
            int weight = getWeight(invokers.get(i), invocation);
            totalWeight += weight;
            weights[i] = totalWeight;
            if (sameWeight && totalWeight != weight * (i + 1)) {
                sameWeight = false;
            }
        }
        
        // 3. 如果服务路由中，存在不一样的权重，根据权重和求出一个随机数,然后计算看该数落在哪个区间段
        if (totalWeight > 0 && !sameWeight) {
            int offset = ThreadLocalRandom.current().nextInt(totalWeight);
            for (int i = 0; i < length; i++) {
                if (offset < weights[i]) {
                    // 4. 只取区间中最大权重的一个invoker
                    return invokers.get(i);
                }
            }
        }
        
        // 5. 如果权重相同或总权重为0，则随机选一个，多线程产生随机数，然后取对应索引的invoker
        return invokers.get(ThreadLocalRandom.current().nextInt(length));
    }
}
```

##### RoundRobin | 轮训

1. 遍历 invokers 列表，累加它们的权重。
2. 如果它们权重不相等，则返回**权重最大**的一个 invoker。
3. 如果它们权重都相等，则返回第一个 invoker。

```java
public class RoundRobinLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 1. 遍历所有invoker
        for (Invoker<T> invoker : invokers) {
            ...
            // 2. 计算胡最大的路由权重，并取其invoker
            if (cur > maxCurrent) {
                maxCurrent = cur;
                selectedInvoker = invoker;
                selectedWRR = weightedRoundRobin;
            }
            totalWeight += weight;
        }
        if (selectedInvoker != null) {
            selectedWRR.sel(totalWeight);
            
            // 3. 返回权重最大的路由
            return selectedInvoker;
        }
        
        // 4. 如果所有路由权重都相同，则取第一个invoker
        return invokers.get(0);
    }
}
```

##### LeastActive | 最不活跃调用数

1. 遍历 invokers 列表，寻找**活跃数最小**的 Invoker。
2. 如果有多个 Invoker 具有相同的最小活跃数，则记录下这些 Invoker 在 invokers 集合中的下标，并累加它们的权重，比较它们的权重值是否相等。
3. 如果只有一个 Invoker 具有最小的活跃数，此时直接返回该 Invoker 即可。
4. 如果有多个 Invoker 具有最小活跃数，且它们的权重不相等，此时处理方式和 RandomLoadBalance 一致。
5. 如果有多个 Invoker 具有最小活跃数，但它们的权重相等，此时随机返回一个即可。

```java
public class LeastActiveLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        int length = invokers.size();
        // 1. 最小的活跃数
        int leastActive = -1;
        // 2.具有相同“最小活跃数”的服务者提供者（以下用 Invoker 代称）数量
        int leastCount = 0;
        // 3. leastIndexs 用于记录具有相同“最小活跃数”的 Invoker 在 invokers 列表中的下标信息
        int[] leastIndexes = new int[length];
        int[] weights = new int[length];
        int totalWeight = 0;
        // 4. 第一个最小活跃数的 Invoker 权重值，用于与其他具有相同最小活跃数的 Invoker 的权重进行对比， 以检测是否“所有具有相同最小活跃数的 Invoker 的权重”均相等
        int firstWeight = 0;
        boolean sameWeight = true;

        // 5. 遍历 invokers 列表
        for (int i = 0; i < length; i++) {
            Invoker<T> invoker = invokers.get(i);
            // 6. 获取 Invoker 对应的活跃数，记录方式见《限流原理》
            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive();
            // 7. 获取降权后的服务权重
            int afterWarmup = getWeight(invoker, invocation);
            weights[i] = afterWarmup;
            // 8. 对比查找更小的活跃数，重新开始
            if (leastActive == -1 || active < leastActive) {
                // 9. 使用当前活跃数 active 更新最小活跃数 leastActive
                leastActive = active;
                // 10. 更新 leastCount 为 1
                leastCount = 1;
                // 11. 记录当前下标值到 leastIndexs 中
                leastIndexes[0] = i;
                totalWeight = afterWarmup;
                firstWeight = afterWarmup;
                sameWeight = true;
            } 
  			// 12. 当前 Invoker 的活跃数 active 与最小活跃数 leastActive 相同
            else if (active == leastActive) {
                // 13. 在 leastIndexs 中记录下当前 Invoker 在 invokers 集合中的下标
                leastIndexes[leastCount++] = i;
                // 14. 累加权重
                totalWeight += afterWarmup;
                // 15. 检测当前 Invoker 的权重与 firstWeight 是否相等，不相等则将 sameWeight 置为 false
                if (sameWeight && afterWarmup != firstWeight) {
                    sameWeight = false;
                }
            }
        }

        // 16. 当只有一个 Invoker 具有最小活跃数，此时直接返回该 Invoker 即可
        if (leastCount == 1) {
            return invokers.get(leastIndexes[0]);
        }

        // 17. 有多个 Invoker 具有相同的最小活跃数，但它们之间的权重不同
        if (!sameWeight && totalWeight > 0) {
            // 18. 则随机生成一个 [0, totalWeight) 之间的数字
            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);
            // 19. 循环让随机数减去具有最小活跃数的 Invoker 的权重值， 当 offset 小于等于0时，返回相应的 Invoker
            for (int i = 0; i < leastCount; i++) {
                int leastIndex = leastIndexes[i];
                // 20. 获取权重值，并让随机数减去权重值
                offsetWeight -= weights[leastIndex];
                if (offsetWeight < 0) {
                    return invokers.get(leastIndex);
                }
            }
        }

        // 21. 如果权重相同或权重为0时，随机返回一个 Invoker
        return invokers.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]);
    }
}
```

##### ShortestResponse | 最短响应负载

1.  找到服务下，所有提供者中**响应时间最短**的⼀个或多个，并计算其权重和。
2. 如果响应时间最短的服务提供者只有⼀个，则直接返回给服务。
3. 如果响应时间最短的服务提供者⼤于1个，则分为以下 2 种情况：
   1. 如果所有服务权重值不同，则按 RandomLoadBalance（2） 过程，选出服务提供者。
   2. 如果所有服务权重相同，则随机返回⼀个。

```java
public class ShortestResponseLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
		...
        // 1. 遍历所有invoker
        for (int i = 0; i < length; i++) {
            // 2. 获取每个invoker的rpcStatus（记录着各种调用统计）
            Invoker<T> invoker = invokers.get(i);
            RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName());
            // 3. 获取平均成功调用时长 = 成功调用的总时长 / 成功调用总次数，记录方式见《限流原理》
            long succeededAverageElapsed = rpcStatus.getSucceededAverageElapsed();
            // 4. 获取此时并发调用数（活跃数，指从请求到未响应结果的调用），记录方式见《限流原理》
            int active = rpcStatus.getActive();
            // 5. 计算总响应时长 = 平均成功调用时长 * 并发调用数
            long estimateResponse = succeededAverageElapsed * active;
            // 6. 获取路由权重（包括预热降权）
            int afterWarmup = getWeight(invoker, invocation);
            weights[i] = afterWarmup;
            // 7. 判断路由最短响应时长、路由权重都相同
            if (estimateResponse < shortestResponse) {
                shortestResponse = estimateResponse;
                shortestCount = 1;
                shortestIndexes[0] = i;
                totalWeight = afterWarmup;
                firstWeight = afterWarmup;
                sameWeight = true;
            } else if (estimateResponse == shortestResponse) {
                shortestIndexes[shortestCount++] = i;
                totalWeight += afterWarmup;
                if (sameWeight && i > 0 && afterWarmup != firstWeight) {
                    sameWeight = false;
                }
            }
        }
        
        // 8. 如果路由最短响应时长的路由只有1个，则只返回第一个invoker
        if (shortestCount == 1) {
            return invokers.get(shortestIndexes[0]);
        }
        // 9. 如果不存在相同最短响应时长、相同权重的路由
        if (!sameWeight && totalWeight > 0) {
            // 10. 则随机计算权重
            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);
            // 11. 然后取响应时长中，某个区间内最响应时长最小的一个invoker
            for (int i = 0; i < shortestCount; i++) {
                int shortestIndex = shortestIndexes[i];
                offsetWeight -= weights[shortestIndex];
                if (offsetWeight < 0) {
                    return invokers.get(shortestIndex);
                }
            }
        }
        
        // 12. 如果所有路由最短响应时长、路由权重都相同，则随机取一个Invoker
        return invokers.get(shortestIndexes[ThreadLocalRandom.current().nextInt(shortestCount)]);
    }
}
```

##### ConsistentHash | 一致性哈希

- **概念**：⼀致性 hash 算法，由麻省理⼯学院的 Karger 及其合作者于 1997 年提出的，算法提出之初是⽤于⼤规模缓存系统的**负载均衡**。

- **⼯作过程**：

  ![1637325363460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637325363460.png)

  1. ⾸先根据 ip 或者其他的信息为缓存节点⽣成⼀个 hash，并将这个 hash 投射到 [0, 232 - 1] 的圆环上。
  2. 当有查询或写⼊请求时，则为缓存项的 key ⽣成⼀个 hash 值，然后查找**第⼀个**⼤于或等于该 hash 值的缓存节点，并到这个节点中查询或写⼊缓存项。
  3. 如果那个节点挂了，则在下⼀次查询或写⼊缓存时，为缓存项查找**另⼀个**⼤于其 hash 值的缓存节点即
     可。
  4. ⼤致效果如图所示，每个缓存节点在圆环上占据⼀个位置，如果缓存项的 key 的 hash 值⼩于缓存节点 hash 值，则到该缓存节点中存储或读取缓存项。
  5. ⽐如绿⾊点对应的缓存项将会被存储到 cache-2 节点中，而如果 cache-3 挂了，则原本应该存到该节点中的缓存项，最终会存储到 cache-4 节点中。

- **一致性 hash 在 Dubbo 中的应用**：

  ![1637325455225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637325455225.png)

  1. 首先把一致性 hash 环的缓存节点替换成 Dubbo#Invoker，相同颜色的则代表同属于同一个服务。
  2. ⽐如 Invoker1-1，Invoker1-2，……, Invoker1-160，这样做的⽬的是通过**引⼊虚拟节点**，让 Invoker 在圆环上分散开来，通过虚拟节点均衡各个节点的请求量，**避免数据倾斜问题**。
     - 所谓**数据倾斜**是指，由于节点不够分散，导致⼤量请求落到了同⼀个节点上，⽽其他节点只会接收到了少量请求的情况。

```java
public class ConsistentHashLoadBalance extends AbstractLoadBalance {
    
    private final ConcurrentMap<String, ConsistentHashSelector<?>> selectors = new ConcurrentHashMap<String, ConsistentHashSelector<?>>();
    
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        String methodName = RpcUtils.getMethodName(invocation);
        String key = invokers.get(0).getUrl().getServiceKey() + "." + 
methodName;
 
        // 1. 获取 invokers 原始的 hashcode，
        int identityHashCode = System.identityHashCode(invokers);
        ConsistentHashSelector<T> selector = (ConsistentHashSelector<T>) 
selectors.get(key);
        // 2. 由于 invokers 是⼀个新的 List 对象，如果selector.identityHashCode != identityHashCode，则意味着服务提供者数量发⽣了变化，因为正常情况下，key-Invokers是保持不变的
        if (selector == null || selector.identityHashCode != 
identityHashCode) {
            // 3. 则创建新的ConsistentHashSelector
            selectors.put(key, new ConsistentHashSelector<T>(invokers, 
methodName, identityHashCode));
            
            // 4. 更新为刚创建的selector
            selector = (ConsistentHashSelector<T>) selectors.get(key);
        }
        
        // 18. 调⽤ ConsistentHashSelector 的 select ⽅法选择 Invoker
        return selector.select(invocation);
    }
}

private static final class ConsistentHashSelector<T> {
    // 5. 使⽤ TreeMap 存储 Invoker 虚拟节点
    private final TreeMap<Long, Invoker<T>> virtualInvokers;
    // 6. 虚拟节点数量，默认为160
    private final int replicaNumber;
	// 7. selector的hashCode，用来标志invokers是否发生变化
    private final int identityHashCode;
	// 8. 方法参数索引，用于对指定某个方法实参进行hash
    private final int[] argumentIndex;
    
    ConsistentHashSelector(List<Invoker<T>> invokers, String methodName, 
                           int identityHashCode) {
		this.virtualInvokers = new TreeMap<Long, Invoker<T>>();
        this.identityHashCode = identityHashCode;
        URL url = invokers.get(0).getUrl();
        this.replicaNumber = url.getMethodParameter(methodName, 
"hash.nodes", 160);
        
        // 9. 获取参与 hash 计算的参数下标值，默认对第1个参数进⾏ hash 运算，可通过hash.arguments配置多个比如"0,1,2"等等
        String[] index = 
Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, 
"hash.arguments", "0"));
        argumentIndex = new int[index.length];
        for (int i = 0; i < index.length; i++) {
            argumentIndex[i] = Integer.parseInt(index[i]);
        }
        
        // 10. 遍历Invokers，准备建立虚拟节点
        for (Invoker<T> invoker : invokers) {
            String address = invoker.getUrl().getAddress();
            for (int i = 0; i < replicaNumber / 4; i++) {
                // 11. 对 address + i 进⾏ md5 运算，得到⼀个⻓度为16的字节数组
                byte[] digest = md5(address + i);
                // 12. 对 digest 部分字节进⾏ 4 次 hash 运算，得到四个不同的 long 型正整数
                for (int h = 0; h < 4; h++) {
                    // 13. h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进⾏位运算
                    // 14. h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进⾏位运算
                    // 15. h = 2 时，取 digest 中下标为 8 ~ 11 的4个字节进⾏位运算
                    // 16. h = 3 时，取 digest 中下标为 12 ~ 15 的4个字节进⾏位运算
                    long m = hash(digest, h);
                    // 17. 将（计算好的落环 hash 值 -> invoker 的映射关系）存储到 virtualInvokers 中，使用 TreeMap 提供⾼效的查询操作
                    virtualInvokers.put(m, invoker);
                }
            }
        }
    }
    
    // 13、14、15、16、23、虚拟节点哈希落环规则
    private long hash(byte[] digest, int number) {
        return (((long) (digest[3 + number * 4] & 0xFF) << 24)
                | ((long) (digest[2 + number * 4] & 0xFF) << 16)
                | ((long) (digest[1 + number * 4] & 0xFF) << 8)
                | (digest[number * 4] & 0xFF))
            & 0xFFFFFFFFL;
    }
    
    // 19. 调⽤ ConsistentHashSelector 的 select ⽅法选择 Invoker
    public Invoker<T> select(Invocation invocation) {
        // 20. 将参数转为 key
        String key = toKey(invocation.getArguments());
        // 22. 生成JDK MD5消息摘要
        byte[] digest = Bytes.getMD5(key);
        // 24. 根据落环后的hash值，寻找合适的 Invoker
        return selectForKey(
            // 23. h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进⾏位运算
            hash(digest, 0));
    }
    
    private String toKey(Object[] args) {
        StringBuilder buf = new StringBuilder();
        // 21. 根据hash.arguments配置的hash参数索引，进行拼凑成key，因此，同服务的Dubbo一致性哈希的负载均衡逻辑，只受参数值影响，具有相同参数值的请求将会被分配到同一个服务提供者，且没有权重的概念
        for (int i : argumentIndex) {
            if (i >= 0 && i < args.length) {
                buf.append(args[i]);
            }
        }
        return buf.toString();
    }
    
    private Invoker<T> selectForKey(long hash) {
        // 25. 根据落环的hash值，到 TreeMap 中查找第⼀个⼤于或等于当前 hash 的 Invoker
        Map.Entry<Long, Invoker<T>> entry = virtualInvokers.ceilingEntry(hash);
        // 26. 如果没找到，说明落环的 hash 值，已经⼤于所有 Invoker 在圆环上最⼤的位置，此时需要将 TreeMap 的头节点赋值给 entry，表示获取第一个 Invoker
        if (entry == null) {
            entry = virtualInvokers.firstEntry();
        }
        // 27. 最后返回找到的 Invoker，完成Dubbo一致性hash的负载均衡
        return entry.getValue();
    }
}
```

### 2.9. Dubbo 线程派发模型？

#### 请求派发策略

| 请求派发策略 | 特点                                                         | 对应 Netty Boss-Worker 模型                                  |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| all          | 全部派发，**默认**的请求派发策略，所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等 | Worker 线程接收到事件后，只会把事件提交到线程池，⾃⼰去处理其他事情 |
| direct       | 直接执行，所有消息都不派发到线程池，全部在 IO 线程上直接执行 | Worker 线程接收到事件后，只会由自己执⾏到底                  |
| message      | 派发请求和响应，只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO 线程上执行 | Worker 线程接收到事件后，只会把请求和响应消息派发到线程池，其他消息由自己执行到底 |
| execution    | 派发请求，只有请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行 | Worker 线程接收到事件后，只会把请求消息派发到线程池，其他消息由自己执行到底 |
| connection   | 在 IO 线程上执行连接与断开事件，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池 | Worker 线程接收到事件后，只会把连接和断开消息加入队列自己处理，其他消息则会派发到线程池 |

#### 策略实现原理

![1636383507769](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636383507769.png)

1. 上图是 Dubbo Server 端的请求派发流程，在 Dispatcher 节点，接收到 Client 请求后，根据不同的策略，派发到 ThreadPool 业务线程池中。

```java
public class NettyTransporter implements Transporter {
    @Override
    public Server bind(URL url, ChannelHandler listener) throws RemotingException {
        // 0. 打开Netty服务器
        return new NettyServer(url, listener);
    }
}

public class NettyServer extends AbstractServer implements RemotingServer {
    // 1. 构造NettyServer
    public NettyServer(URL url, ChannelHandler handler) throws RemotingException {
        super(ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME), 
              // 2. 使用请求派发策略包装 ChannelHandler
              ChannelHandlers.wrap(handler, url));
    }
}

public class ChannelHandlers {
    
    private static ChannelHandlers INSTANCE = new ChannelHandlers();

    protected ChannelHandlers() {
    }
    
    public static ChannelHandler wrap(ChannelHandler handler, URL url) {
        // 3. 获取ChannelHandlers单例，并根据请求派发策略包装ChannelHandler
        return ChannelHandlers.getInstance().wrapInternal(handler, url);
    }
    
    protected static ChannelHandlers getInstance() {
        return INSTANCE;
    }
    
    protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {
        return new MultiMessageHandler(new HeartbeatHandler(
             	// 4. SPI扩展请求派发策略
                ExtensionLoader.getExtensionLoader(Dispatcher.class)
                .getAdaptiveExtension()
                .dispatch(handler, url)));
    }
}
```

##### all | 全部派发

```java
public class AllDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建AllChannelHandler对ChannelHandler事件进行派发
        return new AllChannelHandler(handler, url);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void connected(Channel channel) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 1. 连接事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 2. 断开连接事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 3. 接收事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
        	...
        }
    }
    
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 4. 异常事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));
        } catch (Throwable t) {
            ...
        }
    }
}
```

##### direct | 全不派发

```java
public class DirectDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建DirectChannelHandler对ChannelHandler事件进行派发
        return new DirectChannelHandler(handler, url);
    }
}

public class DirectChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        if (executor instanceof ThreadlessExecutor) {
            try {
                // 1. 接收事件，使用 ThreadlessExecutor，将回调直接委托给发起调用的线程。
                executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
            } catch (Throwable t) {
                ...
            }
        } 
        // 2. 否则，判断后交由ChannelHandler IO线程去执行
        else {
            handler.received(channel, message);
        }
    }
}

public class WrappedChannelHandler implements ChannelHandlerDelegate {
    
    // 3. 连接事件，交由ChannelHandler IO线程去执行
    @Override
    public void connected(Channel channel) throws RemotingException {
        handler.connected(channel);
    }
    
    // 4. 断开连接事件，交由ChannelHandler IO线程去执行
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        handler.disconnected(channel);
    }
    
    // 5. 接收事件，交由ChannelHandler IO线程去执行，对于DirectChannelHandler不会执行，因为它重写了该方法
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        handler.received(channel, message);
    }
    
    // 6. 发送事件，交由ChannelHandler IO线程去执行
    @Override
    public void sent(Channel channel, Object message) throws RemotingException {
        handler.sent(channel, message);
    }
    
    // 7. 异常事件，交由ChannelHandler IO线程去执行
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        handler.caught(channel, exception);
    }
}
```

##### message | 只派发请求和响应

```java
public class MessageOnlyDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建MessageOnlyChannelHandler对ChannelHandler事件进行派发
        return new MessageOnlyChannelHandler(handler, url);
    }
}

public class MessageOnlyChannelHandler extends WrappedChannelHandler {
   @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 1. 接收事件，派发到业务线程池，其余地均交由ChannelHandler IO线程去执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
            ...
        }
    }
}
```

##### execution | 只派发请求

```java
public class ExecutionDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建ExecutionChannelHandler对ChannelHandler事件进行派发
        return new ExecutionChannelHandler(handler, url);
    }
}

public class ExecutionChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);

        // 1.只有请求接收事件，才会派发到业务线程池
        if (message instanceof Request) {
            try {
                executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
            } catch (Throwable t) {
                ...
            }
        } 
        // 2. 其余接收事件，使用 ThreadlessExecutor，将回调直接委托给发起调用的线程
        else if (executor instanceof ThreadlessExecutor) {
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } 
        // 3. 否则，判断后交由ChannelHandler IO线程去执行，与DirectChannelHandler类似
        else {
            handler.received(channel, message);
        }
    }
}
```

##### connection | 串行处理连接和断开事件

```java
public class ConnectionOrderedDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建ConnectionOrderedChannelHandler对ChannelHandler事件进行派发
        return new ConnectionOrderedChannelHandler(handler, url);
    }
}

public class ConnectionOrderedChannelHandler extends WrappedChannelHandler {
    
    protected final ThreadPoolExecutor connectionExecutor;
    
    public ConnectionOrderedChannelHandler(ChannelHandler handler, URL url) {
        ...
        // 1. 构造一个只有1个线程的无界阻塞队列线程池
        connectionExecutor = new ThreadPoolExecutor(1, 1,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>(url.getPositiveParameter(CONNECT_QUEUE_CAPACITY, Integer.MAX_VALUE)),
                new NamedThreadFactory(threadName, true),
                new AbortPolicyWithReport(threadName, url)
        );  
    }
    
    @Override
    public void connected(Channel channel) throws RemotingException {
        try {
            ...
            // 2. 连接事件，派发到队列中，串行执行
            connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        try {
            ...
            // 3. 断开连接事件，派发到队列中，串行执行
            connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 4. 接收事件，派发到业务线程池执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 5. 异常事件，派发到业务线程池执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));
        } catch (Throwable t) {
            ...
        }
    }
}
```

### 3.0. Dubbo 线程池类型？

#### 线程池类型

![1637247042637](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637247042637.png)

以默认的 all 派发策略，以及 Netty4 同步调用为例：

1. 客户端主线程，发出⼀个请求后获得 future 实例，在执⾏ get（）时，进⾏阻塞等待。
2. 服务端使⽤ worker 线程（Netty 通信模型），接收到请求后，会将请求提交到 Dubbo#Server 业务线程池中进⾏处理。
3. Dubbo#Server 业务线程，处理完成之后，将相应结果返回给客户端的 worker 线程池（Netty 通信模型）。
4. 最后，客户端的 worker 线程，将响应结果提交到 Dubbo#Client 业务线程池进⾏处理。
5. Dubbo#Client 业务线程，把响应结果填充到之前的 future 实例中，然后唤醒等待的客户端主线程。
6. 最后客户端主线程获取到结果，然后返回给客户端，完成一次 RPC 调用。

| 线程池类型 | 特点                                                         |
| ---------- | ------------------------------------------------------------ |
| fixed      | 默认类型，固定大小线程池，启动时建立线程，不关闭，一直持有   |
| cached     | 缓存线程池，空闲一分钟自动删除，需要时重建                   |
| limited    | 可伸缩线程池，但池中的线程数只会增长不会收缩，只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题 |
| eager      | 正常类型的线程池，即优先创建 `Worker` 线程池，在任务数量大于 `corePoolSize` 、小于 `maximumPoolSize` 时，优先创建 `Worker` 来处理任务。当任务数量大于 `maximumPoolSize` 时，将任务放入阻塞队列中。阻塞队列充满时抛出 `RejectedExecutionException`，相比于`cached` 缓存线程池，在任务数量超过 `maximumPoolSize` 时，不会抛出异常，而是将任务放入阻塞队列 |

#### 线程池实现原理

```java
public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        // 0.1. 获取线程池
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 0.2. 接收事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
        	...
        }
    }
}

public class WrappedChannelHandler implements ChannelHandlerDelegate {
    public ExecutorService getPreferredExecutorService(Object msg) {
        ...
        // 1. 获取Server端和Client端共享的业务线程池
        return getSharedExecutorService();
    }
    
    public ExecutorService getSharedExecutorService() {
        // 2. 获取线程池仓库DefaultExecutorRepository
        ExecutorRepository executorRepository =
  ExtensionLoader.getExtensionLoader(ExecutorRepository.class).getDefaultExtension();
        ExecutorService executor = executorRepository.getExecutor(url);
        if (executor == null) 
            // 3. SPI构造线程池
            executor = executorRepository.createExecutorIfAbsent(url);
        }
        return executor;
    }
}

public class DefaultExecutorRepository implements ExecutorRepository {
    public synchronized ExecutorService createExecutorIfAbsent(URL url) {
        ...
        // 4. SPI构造线程池
        executor = createExecutor(url);
        ...
    }
    
    private ExecutorService createExecutor(URL url) {
        // 5. SPI构造线程池，默认为fixed类型
        return (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class).getAdaptiveExtension().getExecutor(url);
    }
}
```

##### fixed | 固定大小型

```java
public class FixedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取threads配置参数，默认为200
        int threads = url.getParameter(THREADS_KEY, DEFAULT_THREADS);
        // 3. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 4. 默认构造200个固定线程、同步阻塞队列的线程池
        return new ThreadPoolExecutor(threads, threads, 0, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}
```

##### cached | 缓存型

```java
public class CachedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为Integer.MAX_VALUE，表示无界
        int threads = url.getParameter(THREADS_KEY, Integer.MAX_VALUE);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 读取alive配置参数，默认为60 * 1000，表示60s最大空闲时间，即空闲时最大缓存时间为60s
        int alive = url.getParameter(ALIVE_KEY, DEFAULT_ALIVE);
        // 6. 默认构造核心数为0，最大线程数为Integer.MAX_VALUE，60s最大空闲时间的同步阻塞队列的线程池
        return new ThreadPoolExecutor(cores, threads, alive, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}
```

##### limited | 可伸缩型（线程数只能增加不能减少）

```java
public class LimitedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为200
        int threads = url.getParameter(THREADS_KEY, DEFAULT_THREADS);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 默认构造核心数为0，最大线程数为200，用不过期的，线程数只能增加不能减少的线程池
        return new ThreadPoolExecutor(cores, threads, Long.MAX_VALUE, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}
```

##### eager | 正常型

```java
public class EagerThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为Integer.MAX_VALUE，表示无界
        int threads = url.getParameter(THREADS_KEY, Integer.MAX_VALUE);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 读取alive配置参数，默认为60 * 1000，表示60s最大空闲时间，即空闲时最大缓存时间为60s
        int alive = url.getParameter(ALIVE_KEY, DEFAULT_ALIVE);
        // 6. 默认构造1容量的TaskQueue
        TaskQueue<Runnable> taskQueue = new TaskQueue<Runnable>(queues <= 0 ? 1 : queues);
        // 8. 根据参数正常构造EagerThreadPoolExecutor
        EagerThreadPoolExecutor executor = new EagerThreadPoolExecutor(cores,
                threads,
                alive,
                TimeUnit.MILLISECONDS,
                taskQueue,
                new NamedInternalThreadFactory(name, true),
                new AbortPolicyWithReport(name, url));
        
        // 10. 最后还回写线程池实例到阻塞队列中（与正常线程池不同的地方，用于在添加任务时，获取线程池的线程数量，然后判断是否阻塞）
        taskQueue.setExecutor(executor);
        return executor;
    }
}

public class TaskQueue<R extends Runnable> extends LinkedBlockingQueue<Runnable> {
    public TaskQueue(int capacity) {
        // 7. TaskQueue等同于LinkedBlockingQueue
        super(capacity);
    }
}

public class EagerThreadPoolExecutor extends ThreadPoolExecutor {
    public EagerThreadPoolExecutor(int corePoolSize,
                                   int maximumPoolSize,
                                   long keepAliveTime,
                                   TimeUnit unit, TaskQueue<Runnable> workQueue,
                                   ThreadFactory threadFactory,
                                   RejectedExecutionHandler handler) {
        // 9. EagerThreadPoolExecutor等同于ThreadPoolExecutor
        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);
    }
}
```

### 3.1. Dubbo 限流原理？

```java
// 1. 使用ProtocolFilterWrapper#buildInvokerChain构造过滤器链，在服务端的export方法和消费端refer方法都会用到
public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        if (!filters.isEmpty()) {
            for (int i = filters.size() - 1; i >= 0; i--) {
                final Filter filter = filters.get(i);
                final Invoker<T> next = last;
                last = new Invoker<T>() {
                    ...
                    @Override
                    public Result invoke(Invocation invocation) throws RpcException {
                        Result asyncResult;
                        try {
                            // 2. 根据服务端和消费端，构造不同的过滤器
                            asyncResult = filter.invoke(next, invocation);
                        } catch (Exception e) {
                            ...
                        }
                        return asyncResult;
                    }
                    ...
                };
            }
        }
        ...
    }
}

// 3. 限流统计用到的核心类（服务端和消费端限流都会用到）
public class RpcStatus {
    // 4. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
    public static boolean beginCount(URL url, String methodName, int max) {
        max = (max <= 0) ? Integer.MAX_VALUE : max;
        // 5、 取出应用级别、方法级别的统计信息
        RpcStatus appStatus = getStatus(url);
        RpcStatus methodStatus = getStatus(url, methodName);
        // 6. 如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (methodStatus.active.get() == Integer.MAX_VALUE) {
            return false;
        }
        // 7. 否则进行自旋+1，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        for (int i; ; ) {
            i = methodStatus.active.get();
            if (i + 1 > max) {
                return false;
            }
            if (methodStatus.active.compareAndSet(i, i + 1)) {
                break;
            }
        }
        // 8. 最后不需要限流的，则应用级别的自旋+1，然后返回true
        appStatus.active.incrementAndGet();
        return true;
    }

    // 9. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
    public static void endCount(URL url, String methodName, long elapsed, boolean succeeded) {
        // 10. 结束应用级别单次调用的统计
        endCount(getStatus(url), elapsed, succeeded);
        // 11. 结束方法级别单词调用的统计
        endCount(getStatus(url, methodName), elapsed, succeeded);
    }

    private static void endCount(RpcStatus status, long elapsed, boolean succeeded) {
        // 12. 活跃数-1
        status.active.decrementAndGet();
        // 13. 调用总数+1
        status.total.incrementAndGet();
        // 14. 累加单次调用花费时间
        status.totalElapsed.addAndGet(elapsed);
        if (status.maxElapsed.get() < elapsed) {
            status.maxElapsed.set(elapsed);
        }
        // 15. 如果调用成功，则累加单次成功调用花费时间
        if (succeeded) {
            if (status.succeededMaxElapsed.get() < elapsed) {
                status.succeededMaxElapsed.set(elapsed);
            }
        } 
        // 16. 如果调用失败，则累加调用失败次数，以及累加单次失败调用花费的时间
        else {
            status.failed.incrementAndGet();
            status.failedElapsed.addAndGet(elapsed);
            if (status.failedMaxElapsed.get() < elapsed) {
                status.failedMaxElapsed.set(elapsed);
            }
        }
    }
}
```

#### 服务端限流

1. ExecuteLimitFilter 继承了 Filter.Listener，本质上也是一个监听器，提供 `onResponse()` 监听响应成功的方法，`onError` 监听响应异常的方法。
2. ExecuteLimitFilter 的 `invoke()` 先调⽤ `RpcStatus#beginCount()` 来判断是否可以通过，不通过则**抛出RpcException**。
3. 通过则记录开始执⾏的时间，则记录 `execute_limit_filter_start_time` 值，然后执⾏ `invoker.invoke()` 。
4. 执⾏结束时会回调 Listener 的`onResponse()` 或 `onError()` ，而它们都会调⽤ `RpcStatus#endCount()`，该⽅法会通过 `getElapsed()` ，取出 `execute_limit_filter_start_time` 值，以计算执⾏耗时。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
   	private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 0.1. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 0.2. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            // 0.3. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString()));
            DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);
            
            // 0.4. 通过RegistryProtocol#export暴露远程服务，获取对应的exporter
            Exporter<?> exporter = protocol.export(wrapperInvoker);
            ...
        }
        ...
    }
}    

public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.5. 打开Netty服务器，利用Netty NIO特性，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // ... 连接、订阅、监听ZK
    }
    
    private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
        String key = getCacheKey(originInvoker);
        return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
            Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
            // 0.6. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
            return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
        });
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 0.7. ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER));
    }
}

// 1. 服务端限流，则构造ExecuteLimitFilter
@Activate(group = CommonConstants.PROVIDER, value = EXECUTES_KEY)
public class ExecuteLimitFilter implements Filter, Filter.Listener {
    
    private static final String EXECUTE_LIMIT_FILTER_START_TIME = "execute_limit_filter_start_time";
    
    @Override
    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {
        // 2. 获取invoker的url和响应的方法名称
        URL url = invoker.getUrl();
        String methodName = invocation.getMethodName();
        // 3. 获取参数配置的executes，默认为0，表示服务提供者的，每个服务的，每个方法的，最大可并行执行请求数
        int max = url.getMethodParameter(methodName, EXECUTES_KEY, 0);
        // 4. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (!RpcStatus.beginCount(url, methodName, max)) {
            // 4.1. 如果进行了限流，则抛出异常
            throw new RpcException(...)
        }
        // 5. 远程调用前，先记录当前时间execute_limit_filter_start_time
        invocation.put(EXECUTE_LIMIT_FILTER_START_TIME, System.currentTimeMillis());
        try {
            // 6. 进行本地实现类的动态代理类的方法调用
            return invoker.invoke(invocation);
        } catch (Throwable t) {
            if (t instanceof RuntimeException) {
                throw (RuntimeException) t;
            } else {
                throw new RpcException(...);
            }
        }
    }

    // 7. 根据记录的execute_limit_filter_start_time，算出本地方法调用总共花费的时间
    private long getElapsed(Invocation invocation) {
        Object beginTime = invocation.get(EXECUTE_LIMIT_FILTER_START_TIME);
        return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0;
    }
                                   
    @Override
    public void onResponse(Result appResponse, Invoker<?> invoker, Invocation invocation) {
        // 8. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), true);
    }

    @Override
    public void onError(Throwable t, Invoker<?> invoker, Invocation invocation) {
        ...
  		// 9. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), false);
    }
}
```

#### 消费端限流

1. ActiveLimitFilter 继承了 Filter.Listener，本质上也是一个监听器，提供 `onResponse()` 监听响应成功的方法，`onError` 监听响应异常的方法。
2. ActiveLimitFilter 的 `invoke()` 先调⽤ `RpcStatus#beginCount()` 来判断是否可以通过，不通过则**阻塞当前线程**。
3. 通过则记录开始执⾏的时间，则记录 `activelimit_filter_start_time` 值，然后执⾏ `invoker.invoke()` 。
4. 执⾏结束时会回调 Listener 的`onResponse()` 或 `onError()` ，而它们都会调⽤ `RpcStatus#endCount()`，该⽅法会通过 `getElapsed()` ，取出 `activelimit_filter_start_time` 值，以计算执⾏耗时，并**唤醒单例rpcStatus阻塞的所有线程**。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 0.1 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        ...
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(url.getProtocol())) {
            return protocol.refer(type, url);
        }
        // 0.2 ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER);
    }
}

// 1. 消费端限流，则构造ActiveLimitFilter
@Activate(group = CONSUMER, value = ACTIVES_KEY)
public class ActiveLimitFilter implements Filter, Filter.Listener {
    
    private static final String ACTIVELIMIT_FILTER_START_TIME = "activelimit_filter_start_time";
    
    @Override
    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {
        // 2. 获取url和方法名称
        URL url = invoker.getUrl();
        String methodName = invocation.getMethodName();
        // 3. 获取参数配置的actives，默认为0，表示每个服务消费者的，每个服务的，每个方法的，最大并发调用数
        int max = invoker.getUrl().getMethodParameter(methodName, ACTIVES_KEY, 0);
        // 4. 从缓存中获取方法级别的单例rpcStatus（多个线程共享，用于synchronized）
        final RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName());
        // 5. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (!RpcStatus.beginCount(url, methodName, max)) {
            // 6. 获取参数配置的timeout，默认为0，表示超时时间
            long timeout = invoker.getUrl().getMethodParameter(invocation.getMethodName(), TIMEOUT_KEY, 0);
            long start = System.currentTimeMillis();
            long remain = timeout;
            synchronized (rpcStatus) {
                while (!RpcStatus.beginCount(url, methodName, max)) {
                    try {
                        // 7. 如果进行了限流，则阻塞当前线程，直到别的线程调用响应或者异常后，才会被唤醒
                        rpcStatus.wait(remain);
                    } catch (InterruptedException e) {
                        // ignore
                    }
                    // 8. 线程被唤醒后，则计算剩余超时时间，如果为负数，则抛出异常，代表调用超时
                    long elapsed = System.currentTimeMillis() - start;
                    remain = timeout - elapsed;
                    if (remain <= 0) {
                        throw new RpcException(...);
                    }
                }
            }
        }
        // 9. 如果没被进行限流，或者仍没有超时，则先记录activelimit_filter_start_time
        invocation.put(ACTIVELIMIT_FILTER_START_TIME, System.currentTimeMillis());
		// 10. 进行远程调用
        return invoker.invoke(invocation);
    }

    // 11. 根据记录的activelimit_filter_start_time，算出远程调用总共花费的时间
    private long getElapsed(Invocation invocation) {
        Object beginTime = invocation.get(ACTIVELIMIT_FILTER_START_TIME);
        return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0;
    }
    
    @Override
    public void onResponse(Result appResponse, Invoker<?> invoker, Invocation invocation) {
        ...
		// 12. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(url, methodName, getElapsed(invocation), true);
        // 13. 当前线程响应成功，则唤醒单例rpcStatus阻塞的所有线程
        notifyFinish(RpcStatus.getStatus(url, methodName), max);
    }

    @Override
    public void onError(Throwable t, Invoker<?> invoker, Invocation invocation) {
        ...
		// 15. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(url, methodName, getElapsed(invocation), false);
        // 16. 当前线程响应失败，则唤醒单例rpcStatus阻塞的所有线程 
        notifyFinish(RpcStatus.getStatus(url, methodName), max);
    }
    
    // 14. 唤醒单例rpcStatus阻塞的所有线程
    private void notifyFinish(final RpcStatus rpcStatus, int max) {
        if (max > 0) {
            synchronized (rpcStatus) {
                rpcStatus.notifyAll();
            }
        }
    }
}
```

### 3.2. Dubbo 降级原理？

#### 容错 | 失败处理

1. 当系统出现非业务异常（不可知、不可预测的异常），比如并发数太高导致的服务超时、网络异常等。
2. 为保证核心链路不受此异常影响，可对**该接口**进行降级处理，采用控制台动态配置 `mock=fail:return null`，失败时不对接口进行处理。

#### 屏蔽 | 强制屏蔽

1. 而对于大促、促销、双 11 等一些可预知、可预测的情况下，为保证核心链路不受非核心接口的影响，可以提前对**非核心接口**进行降级处理，采用控制台动态配置 `mock=force:return null` ，强制屏蔽接口。

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 0. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

public class InvokerInvocationHandler implements InvocationHandler {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        ...
        // 0.1 动态代理执行
		return invoker.invoke(new RpcInvocation(method, args)).recreate();
    }
}

public class MockClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        Result result = null;
        // 1. 获取参数配置的mock，默认为false
        String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim();
        // 2. 默认值不进行降级，则直接进行invoker调用
        if (value.length() == 0 || value.equalsIgnoreCase("false")) {
            result = this.invoker.invoke(invocation);
        } 
        else if (value.startsWith("force")) {
            ...
            // 3. 如果有值，且以force开头，说明为屏蔽，则调用doMockInvoke(invocation, null)
            result = doMockInvoke(invocation, null);
        } else {
            try {
                result = this.invoker.invoke(invocation);
            } catch (RpcException e) {
                ...
                // 4. 如果有值，但不以force开头，说明为容错，则异常时才调用doMockInvoke(invocation, e)，其中e是用来记录原始异常信息的，并没有其他作用
                result = doMockInvoke(invocation, e);
            }
        }
        
        // 9. 因此，对于屏蔽来说，则直接返回null；对于容错来说，则先远程调用，在调用异常时才进行降级处理，然后返回null
        return result;
    }
    
    private Result doMockInvoke(Invocation invocation, RpcException e) {
        ...
        try {
            // 5. 调用MockInvoker#invoker方法进行降级
            result = minvoker.invoke(invocation);
        } catch (RpcException me) {
            ...
        } catch (Throwable me) {
            ...
        }
        
        // 8. 降级后返回null
        return result;
    }
}

final public class MockInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        ...
        // 6. 提取参数配置的mock内容（降级的为return null），如果为return开头
        if (mock.startsWith(RETURN_PREFIX)) {
            mock = mock.substring(RETURN_PREFIX.length()).trim();
            try {
                Type[] returnTypes = RpcUtils.getReturnTypes(invocation);
                Object value = parseMockValue(mock, returnTypes);
                /// 7. 则直接返回null
                return AsyncRpcResult.newDefaultAsyncResult(value, invocation);
            } catch (Exception ew) {
                throw new RpcException(...);
            }
        } else if (mock.startsWith(THROW_PREFIX)) {
            ...
        } else {
            ...
        }
    }
}
```

### 3.3. Dubbo 设计模式？

#### 1、责任链模式

1. 责任链模式，在 Dubbo 中发挥的作⽤举⾜轻重，就像是 Dubbo 框架的⻣架。
2. Dubbo 调⽤链组织是⽤责任链模式串连起来的，责任链中的每个节点实现 Filter 接⼝，然后由
   **ProtocolFilterWrapper**，将所有 Filter 串连起来。
3. 通过 Filter 扩展实现了 Dubbo 许多功能，⽐如监控、⽇志、缓存、安全、telnet 以及 RPC 本身都是。
4. 如果把 Dubbo ⽐作⼀列⽕⻋，那么责任链就像是⽕⻋的各⻋厢，每个⻋厢的功能不同，如果需要加⼊新的功能，增加⻋厢就可以了，⾮常容易扩展。

```java
// 1. 使用ProtocolFilterWrapper#buildInvokerChain构造过滤器链，在服务端的export方法和消费端refer方法都会用到
public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        if (!filters.isEmpty()) {
            for (int i = filters.size() - 1; i >= 0; i--) {
                final Filter filter = filters.get(i);
                final Invoker<T> next = last;
                last = new Invoker<T>() {
                    ...
                    @Override
                    public Result invoke(Invocation invocation) throws RpcException {
                        Result asyncResult;
                        try {
                            // 2. 根据服务端和消费端，构造不同的过滤器
                            asyncResult = filter.invoke(next, invocation);
                        } catch (Exception e) {
                            ...
                        }
                        return asyncResult;
                    }
                    ...
                };
            }
        }
        ...
    }
}
```

#### 2、观察者模式

1. Dubbo 使⽤观察者模式最典型的例⼦是 RegistryService。
2. 消费者在初始化的时候回调⽤ subscribe ⽅法，会注册⼀个观察者，如果观察者引⽤的服务地址列表发⽣改变，就会通过 NotifyListener 通知消费者。
3. 此外，Dubbo的 InvokerListener、ExporterListener 也实现了观察者模式，只要实现该接⼝，并注册，就可以通知到 consumer 端调⽤ refer（）、provider 端调⽤ export（） 。

```java
public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        ...
        // 1. 通知更新url配置，刷新Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 2. 更新configurators配置（和服务端一样，省略代码）
        overrideDirectoryUrl();
        // 3. 刷新Invoker列表
        refreshInvoker(urls);
    }
}
```

#### 3、模板方法模式

1. 模板方法模式，指把通用的方法写到抽象父类，然后交由不同子类去实现，从而在不改变算法结构的情况下，重新定义具体的实现。
2. Dubbo 中比如 AbstractProtocol#protocolBindingRefer、AbstractProxyFactory#getProxy、AbstractClusterInvoker#doInvoke、AbstractDirectory#doList、AbstractLoadBalance#doSelect、AbstractInvoker#doInvoke、AbstractProxyInvoker#doInvoke 等，都是使用了模板方法模式，再结合 SPI 动态扩展机制，更改配置策略，就可以实现不同的算法效果，比如负载均衡、集群容错等。

```java
public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 1. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 2. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
}
```

#### 4、装饰者模式

1. Dubbo 中⼤量⽤到了修饰器模式。
2. ⽐如 ProtocolFilterWrapper 类是对 Protocol 类的修饰，在 export 和 refer ⽅法中，配合责任链模式，把Filter 组装成责任链，实现对 Protocol 功能的修饰。
3. 其他还有ProtocolListenerWrapper、 ListenerInvokerWrapper、InvokerWrapper等。
4. 不过，修饰器模式是⼀把双刃剑，⼀⽅⾯⽤它可以⽅便地扩展类的功能，⽽且对⽤户⽆感；但另⼀⽅⾯，过多地使⽤修饰器模式不利于理解，因为⼀个类可能经过层层修饰，最终的⾏为已经和原始⾏为偏离较⼤。

```java
private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
    String key = getCacheKey(originInvoker);
    return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
        Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
        // 1. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
        return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
    });
}
```

#### 5、代理模式

1. Dubbo 服务端，使用 Proxy 类来创建本地实现类的动态代理，对调用前做一定的包装，比如 Filter、Listener 等。
2. 而 Dubbo 消费端， 使⽤ Proxy 类来创建远程服务的动态代理，从而屏蔽⽹络通信的细节，使得⽤户在使⽤本地代理的时候，感觉和使⽤本地服务⼀样。

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    // Dubbo 服务端代理
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        // 1.获取interfaceClass的javasist动态代理Wrapper包装类
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 2. 动态代理调用实现类方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
    
    // Dubbo 消费端代理
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 3. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}
```

#### 6、适配器模式

1. 为了让⽤户根据⾃⼰的需求选择⽇志组件，Dubbo ⾃定义了⾃⼰的 Logger 接⼝，并为常⻅的⽇志组件，比如 jcl、jdk、log4j、slf4j 提供了相应的适配器。
2. 同时利⽤简单⼯⼚模式提供⼀个 LoggerFactory，客户可以创建抽象的 Dubbo ⾃定义Logger，⽽⽆需关⼼实际使⽤的⽇志组件类型。
3. 在 LoggerFactory 初始化时，客户通过设置系统变量的⽅式，来选择⾃⼰所⽤的⽇志组件，提供了很⼤的灵活性。

```java
// 实现类有：JclLoggerAdapter、JdkLoggerAdapter、Log4j2LoggerAdapter、Log4jLoggerAdapter、Slf4jLoggerAdapter
@SPI
public interface LoggerAdapter {
    Logger getLogger(Class<?> key);
    Logger getLogger(String key);
    Level getLevel();
    void setLevel(Level level);
    File getFile();
    void setFile(File file);
}
```

#### 7、工厂方法模式

1. CacheFactory 采⽤⼯⼚⽅法模式实现，它定义 getCache ⽅法，然后定义⼀个 AbstractCacheFactory 抽象类实现 CacheFactory，并将实际创建 cache 的 createCache（）分离出来，并设置为抽象⽅法，这样具体 cache 的创建⼯作，就留给具体的⼦类去完成。

```java
@SPI("lru")
public interface CacheFactory {
    @Adaptive("cache")
    Cache getCache(URL url, Invocation invocation);
}

public abstract class AbstractCacheFactory implements CacheFactory {
    ...
    // 模板方法，交由实现类去实现：ExpiringCacheFactory、JCacheFactory、LfuCacheFactory、LruCacheFactory、ThreadLocalCacheFactory
    protected abstract Cache createCache(URL url);
}
```

#### 8、抽象工厂模式

> 工厂方法模式，针对的是多个产品系列结构（同一个抽象产品角色, 同一个产品族）。
> 抽象工厂模式，针对的是多个产品族结构（多个抽象产品角色,多个产品族），一个产品族内有多个产品系列（同一个抽象产品角色, 同一个产品）。

1. ProxyFactory 及其⼦类，是Dubbo 中使⽤抽象⼯⼚模式的典型例⼦。
2. ProxyFactory 提供 getProxy（） 和 Invoker（），getProxy（）需要传⼊⼀个 Invoker 对象，针对的是消费端获取接口的动态代理；⽽ getInvoker（）需要传⼊⼀个 proxy 对象，针对的是服务端用于获取本地实现类的代理 invoker，从而创建对应的 exporter。
3. AbstractProxyFactory 实现了 ProxyFactory 接⼝，作为具体实现类的抽象⽗类，提供通用的实现。
4. 然后还定义了 JavassistProxyFactory 和 JdkProxyFactory 两个实现类，分别⽤来⽣产基于 javassist 代理机制和 jdk 代理机制的 Proxy 和 Invoker。

```java
@SPI("javassist")
public interface ProxyFactory {
    @Adaptive({PROXY_KEY})
    <T> T getProxy(Invoker<T> invoker) throws RpcException;
    
    @Adaptive({PROXY_KEY})
    <T> T getProxy(Invoker<T> invoker, boolean generic) throws RpcException;
    
    @Adaptive({PROXY_KEY})
    <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) throws RpcException;
}

public abstract class AbstractProxyFactory implements ProxyFactory {
    ...
    // 1. 模板方法，多态调用doInvoke方法，实现类：JavassistProxyFactory和JdkProxyFactory
    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;
}
```

#### 9、单例模式

1. 另外，在类创建方式方面，对于一些缓存变量，常常用单例模式实例化（线程安全+单例保证），比如 AbstractProxyFactory#INTERNAL_INTERFACES，ExtensionLoader#EXTENSION_LOADERS、EXTENSION_INSTANCES 等。

```java
public abstract class AbstractProxyFactory implements ProxyFactory {
    // 1. 饿汉式创建缓存单例
    private static final Class<?>[] INTERNAL_INTERFACES = new Class<?>[]{
            EchoService.class, Destroyable.class
    };
}

public class ExtensionLoader<T> {
    ...
    // 2. 饿汉式创建缓存单例
    private static final ConcurrentMap<Class<?>, ExtensionLoader<?>> EXTENSION_LOADERS = new ConcurrentHashMap<>();
    private static final ConcurrentMap<Class<?>, Object> EXTENSION_INSTANCES = new ConcurrentHashMap<>();
    ...
}
```

#### 10、建造者模式

1. 另外，在类创建方式方面，对于一些多参数变量，比如 org.apache.dubbo.common.URL 对象，则可以通过建造者模式构造出来（易于阅读、方便扩展）。

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 1. 通过URLBuilder来创建URL对象
        url = URLBuilder.from(url)
                .setProtocol(url.getParameter(REGISTRY_KEY, DEFAULT_REGISTRY))
                .removeParameter(REGISTRY_KEY)
                .build();
        Registry registry = registryFactory.getRegistry(url);
        ...
    }
}
```

### 3.4. Dubbo 最佳实践？

#### 1、Provider 多配置接口参数

1. 作为服务提供⽅，自己⽐消费⽅更清楚服务的这些接口参数的取值，比如超时时间、重试次数、负载均衡策略等。
2. 由于配置覆盖策略存在，在 Provider 端配置后，Consumer 端不配置则会使⽤ Provider 端配置，即 Provider 配置可以作为 Consumer 的缺省值。
3. 而如果 Provider 不配置，Consumer 也不直接配置，则会使⽤ Consumer 端的全局设置，这对于 Provider 是不可控的，并且往往是不合理的。
4. 因此，Provider 端尽量多配置、完善这些接口参数，让 Provider 实现者⼀开始就思考 Provider 端的服
   务特点和服务质量等问题。

#### 2、Provider 合理配置性能参数

比如，**threads**（服务线程池⼤⼩）、**executes**（服务提供者并发请求的上限）。

#### 3、服务使用固定端口

使⽤固定端⼝来暴露服务，不要使⽤随机端⼝，这样在注册中⼼推送延迟的情况下，消费端仍然能够通过缓存列表，调⽤到原地址+原端口的服务，保证调⽤成功。

#### 4、推荐使用 XML 进行配置

XML 配置优先级高于 properties 和 yml，且标签的配置方式更加容易阅读和理解。

#### 5、应用配置负责人参数

配置 `dubbo:application#owner` 负责人参数，这些可以在运维平台上看到，以便于在发现问题时，找到对应服务负责⼈。

# 八、SpringCloud篇

### 1.1. 如何权衡微服务的利弊？

#### 优点

![1638067092432](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638067092432.png)

##### 1、快速响应变更

1. 得益于微服务架构遵循了单一职责的架构理念，每块微服务都划进了自身的势力范围，再也不像单体应用那样改一发而动全身，天然适用于小步快跑的开发节奏。
2. 同时，每块微服务都可以独立部署，这样就可以不受限于单体应用的发布节奏与发布窗口等条件，特别适合互联网公司糙快猛的开发模式。

##### 2、独立拓展

微服务与微服务间有非常清晰的边界，且不过度受制于技术栈，可以在当前微服务的技术栈上，有更多的话语权，能够在保持整体技术栈相对统一情况下，给到各个微服务最大的技术自由度。

##### 3、精粒度业务控制

比如说，可以把某段特定的降级熔断逻辑，放在某个特定的微服务上，然后为其指定合理的调用策略和重试策略，还可以更精粒度的局部限流，提高利用率。

##### 4、面向业务和领域模型

1. 使用微服务架构，不再依赖于底层的数据模型，而是依赖于业务和领域模型，并不会暴露给底层数据模型给其他微服务，而只是暴露业务接口和业务对象，在对底层数据模型进行更改时，不会影响到其他业务方。
2. 同时基于业务模型也非常易于抽象，比如抽象到中台等。

#### 缺点

![1638067123418](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638067123418.png)

##### 1、部署结构复杂

微服务架构模块众多，每个微服务部署、中间件千差万别，并且天生就引入了一堆额外的组件，这样就会使得部署结构变得复杂，提高了运维的成本。

##### 2、依赖平台支撑

1. 微服务架构也考验着公司的整体技术实力，非常依赖于平台的支撑，比如注册中心、配置中心、调用链路分析、服务网关等。
2. 另外，在把单体架构拆分成微服务架构时，也需要投入额外的研发成本。

##### 3、分布式问题

1. 在微服务架构下会存在一致性问题，比如串联调用了多个上下游的微服务，来共同完成一个事务，这时就需要在强一致性、弱一致性和最终一致性方案间做出选择。
2. 如果采用了最终一致性方案，还需要考虑如果做好异常补偿。

##### 4、拆分的水平

1. 微服务的拆分强依赖于当前业务，如果架构师对业务理解不到位，导致微服务拆分的粒度过粗或者过细，使得微服务的优越性大打折扣，甚至王者变青铜。 

#### 考虑要点

##### 1、从业务角度考虑

微服务拆分，不能为了微服务而微服务，需要结合自身业务，围绕业务进行拆分，而在拆之前可以从一下两个业务角度去思考：

| 思考角度     | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| 业务规模     | 比如两个极端，在业务发展得非常大时拆，和在一开始就使用微服务，此时，微服务拆分则需要考虑，在这两个极端之间，评估所要支出的成本和所能带来的收益，**决定着微服务的拆还是不拆**。 |
| 理解业务领域 | 深入理解业务架构、业务流、未来的业务规划等，**决定着如何去拆微服务**。 |

##### 2、从技术角度考虑

微服务架构落地需要亲身躬行，靠实践经验的积累才能做好，在改造过程中，需要去攻克的技术难点有：

| 技术难点   | 含义                                                         |
| ---------- | ------------------------------------------------------------ |
| 服务治理   | 服务与服务间的调用，是微服务架构第一个需要解决的问题，而**服务治理**指的是，在集群中虚机的日常上下线、扩缩容情况下，动态探知各个服务节点的状态变化，了解哪些节点可以正常提供服务、哪些节点已下线等信息。 |
| 负载均衡   | **负载均衡**指的是，面对茫茫多的服务器，如何根据实际情况，把海量用户请求分发到不同的机器，同时考虑各机器性能强弱、各机房带宽大小、网络响应快慢等实际条件。 |
| 服务调用   | 从 Java 代码发起调用，需要构造 Header 和 Body，非常麻烦，需要解决服务通信的代码编写问题，使得调用一个服务就像调用本地接口一样方便 |
| 服务容错   | 在高并发场景下，有的服务会承担较大的访问请求，可能导致响应时间过慢，甚至超时，如果调用方经常发起重试，那么势必会进一步增加被调用应用的压力，导致一个恶性循环，而解决方案就是**降级和熔断**这两种服务容错技术。 |
| 配置管理   | **服务配置管理**，可以使得随时动态调整应用配置，而无需重启机器。 |
| 服务网关   | **服务网关**，可以在微服务架构下，把用户请求转发到每个不同的服务器上。 |
| 调用链追踪 | **调用链追踪**，可以从前到后展示整个微服务调用链的全景数据。 |
| 消息驱动   | 消息组件不仅可以用于**削峰填谷**，还可以用于微服务间的**系统解耦**。 |
| 服务限流   | 再厉害的系统也有性能瓶颈，而限流则可以通过在源头处削减系统压力，是最经济高效的稳定手段，而微服务后台的服务节点数量庞大，单机版的限流远不能解决问题，因此，需要在集群范围内引入**分布式限流**。 |

### 1.2. 微服务架构设计模式？

#### 1、聚合器模式 | 少见

![1638003414651](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638003414651.png)

1. 聚合器调用多个服务，从而实现系统所需的功能，每个服务都有自己的缓存和数据库。
2. 它可以是一个简单的 WEB 页面，把检索到的数据进行处理后再展示。
3. 它也可以是一个更高层次的组合服务，对检索到的数据增加业务逻辑后，进一步发布成一个新的微服务（**DRY 原则**），也有自己的缓存和数据库，可以沿 X轴（负载均衡、读写分离） 和 Z轴（分库分表） 独立扩展。
   - **DRY 原则**：
     1. Don't Repeat Yourself，不做重复的事，指在一个设计里，对于任何东西，都应该有且只有一个表示，其它的地方都应该引用这一处。
     2. 这样需要改动的时候，只需调整这一处，所有的地方就都变更过来了。
     3. 而在降低可管理单元复杂度的一个基本策略就是，将他们拆解成更小的单元。

#### 2、代理模式 | 网关

![1638003975019](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638003975019.png)

1. 类似聚合器模式，但是客户端并不聚合数据，而是会根据业务需求的差别，调用不同的微服务。
2. 代理模式可以仅仅是委派请求，也可以进行数据转换工作。

#### 3、链式模式 | 少见

![1638004098621](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004098621.png)

1. ServiceA 接收到请求后，会与 ServiceB 进行通信，类似地，ServiceB 也会同 ServiceC 进行通信。
2. 所有服务都使用同步消息传递，在整个链式调用完成之前，客户端会一直阻塞，因此，服务调用链不宜过长，以免客户端长时间等待，是一个**同步串行处理**过程，无法进行并行处理。

#### 4、分支模式 | 常见

![1638004209220](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004209220.png)

1. 允许同时调用两个微服务链，效率更高，适合于并行调用处理。

#### 5、数据共享模式 | 过渡

![1638004289487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004289487.png)

1. 自治是微服务的设计原则之一，就是说微服务是全栈式服务，但在重构现有的单体应用时，SQL 数据库反规范化拆分，可能会导致数据重复和不一致。
2. 因此，在单体应用到微服务架构的**过渡阶段**，可以使用这种设计模式，在这种情况下，部分微服务可能会共享缓存和数据库存储，不过，也只有在两个服务之间，存在**强耦合关系**时才可以。
3. 但这对于基于微服务的新建应用程序而言，是一种反模式，在正常的情况下，不推荐这么设计。

#### 6、异步消息模式 | 常见

![1638005387692](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638005387692.png)

1. RestFul 设计模式非常流行，但它是同步的，会造成阻塞。
2. 因此，部分基于微服务的架构，可能会选择使用消息队列，来代替 RESTFul 请求和响应，以提升吞吐量。

### 1.3. 微服务拆分原则？

1. **单一职责原则**：每个服务独立出去，有界限地工作，只需关注自身的业务，做到高内聚。
2. **服务自治原则**：每个服务做到独立开发、独立测试、独立构建、独立部署、独立运行，与其他服务解耦。
3. **轻量级通信原则**：每个服务间的调用是轻量级的，并且能够跨平台、跨语言，比如采用 Restful、消息队列等进行通信。
4. **粒度进化原则**：每个服务的粒度没有统一的标准，需要结合具体的业务问题，并且随着业务发展而进化，不要进行过度设计。

### 1.4. 微服务拆分经验方案？

微服务拆分没有一个绝对正确的方案，服务拆分的粒度完全要根据业务场景来规划，而随着业务的发展，原先的架构方案也需要做调整，其常见的拆分方案有：

#### 按压力模型拆分

压力模型，简单来说就是用户访问量，需要识别出某些**超高并发量**的业务，尽可能把这部分业务独立拆出来，其业务场景分类有：

##### 1、高频高并发场景

比如商品详情页，它是一个高频场景，同时也是一个高并发场景。

- **建议**：通常建议将高频高并发场景隔离出来，单独作为一个微服务模块，典型的就是商品详情页的后台服务。

##### 2、低频突发流量场景

比如秒杀，虽然它并不是高频场景，但是会产生突发流量。

- **建议**：对于低频突发流量场景，条件允许也可以剥离出来，但如果必须和其他业务包在一个微服务下，那一定要做好**流控**措施（比如削峰），同时还要考虑异常情况的补偿机制。

##### 3、低频流量场景

多为后台运营团队的服务接口，比如商品图文编辑、添加新的优惠计算规则、上架新商品等，即发生的频率比较低，而且不会造成很高的并发量。

- **建议**：对于低频流量场景，根据业务模型拆分就好。

#### 按业务模型拆分

业务模型拆分的维度有很多，在实际项目中应该综合各个不同维度做考量，其分类有：

##### 1、主链路拆分

主链路是正面战场，必须力保主链路不失守，比如电商中的，商品搜索 => 商品详情页 => 购物车模块 => 订单结算 => 支付业务等，其拆分的目的有：

- **异常容错**：可为主链路建立层次化的多级降级策略，以及合理的熔断策略。
- **调配资源**：主链路通常来讲都是高频场景，自然需要更多的计算资源，最主要的体现就是集群里分配的虚机数量多，因此，把主链路服务单独隔离出来，有利于根据需要指定不同的资源计划。
- **服务隔离**：主链路是主打输出的 C 位，把主链路与其他打辅助的业务隔离开来，可以避免边缘服务的异常情况影响到主链路。

##### 2、领域模型拆分

所谓领域模型，其实就是一套各司其职的服务集合，在做微服务规划时，需要确保各个领域之间有清晰的界限，比如商品服务和订单服务等。

##### 3、用户群体划分

1. 对每个不同的用户群体来说，即便是相同的业务领域，也有该群体独有的业务场景，比如运营、采购、客服、买家、卖家等。
2. 因此，用户群体相当于一个二级域，建立先根据主链路和领域模型一级域的拆分，再结合具体的业务分析，看是否需要在用户领域方向上做更细粒度的拆分。

##### 4、前后台业务分离

在实际项目中，通常会将前台业务和后台业务做一个隔离，符合高频业务（前台）和低频业务（后台）的隔离策略，比如手淘 APP 前台和后台商品管理系统等。

### 1.5. 什么是 SpringCloud？

#### 概念

- SpringCloud 是一系列**框架的有序集合**，利用 SpringBoot 的开发便利性，巧妙地简化了分布式系统基础设施的开发，如**服务注册与发现、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控**等，可以用 SpringBoot 的开发风格做到一键启动和部署。
- SpringCloud 并没有重复制造轮子，只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过SpringBoot 风格进行再封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署、易维护的**分布式系统开发工具包**。

|          | SpringCloud                                                  | SpringBoot                                         |
| -------- | ------------------------------------------------------------ | -------------------------------------------------- |
| 目标     | 关注全局的微服务协调整理治理框架，把 SpringBoot 开发的一个个微服务整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成服务 | 专注于快速方便地开发单个微服务                     |
| 依赖关系 | SpringCloud 离不开SpringBoot ，属于依赖的关系                | 可以离开SpringCloud 独立使用开发项目，没有依赖关系 |

#### 整体架构

![1638089272529](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638089272529.png)

- **Netflix**：奈非，一家大名鼎鼎的互联网传媒公司，经过自身业务漫长的微服务改造过程，沉淀出了一系列优秀的微服务组件，再经过 Pivotal（主导 Cloud Foundry）一系列封装后构成了初代的 SpringCloud。
- **Alibaba**：阿里巴巴，凭借 996 + 鸡血文化加持 + 国内互联网行业特有的糙快猛精神，在开源软件上不断开疆拓土，贡献了 SpringCloud Alibaba 组件库。
- **Spring Open Source**：Spring，独家挂牌开源，即**原配**组件。

| 应用功能       | Netfilx                           | Alibaba                  | Spring                   | 其他厂商                                                  |
| -------------- | --------------------------------- | ------------------------ | ------------------------ | --------------------------------------------------------- |
| **服务治理**   | **Eureka**                        | Nacos、Dubbo             | -                        | Google Consul                                             |
| **负载均衡**   | **Ribbon**                        | -                        | springcloud-loadbalancer | -                                                         |
| **服务调用**   | Fegin/**Open Feign**              | -                        | -                        | -                                                         |
| **服务容错**   | **Hystrix** + Turbine + Dashboard | **Sentinel** + Dashboard | -                        | -                                                         |
| **配置管理**   | Archaius                          | Alibaba Cloud ACM、Nacos | **Config**               | 携程 Apollo                                               |
| **服务网关**   | Zuul                              | -                        | **Gateway**              | -                                                         |
| **调用链追踪** | -                                 | -                        | **Sleuth**               | Elasticsearch B.V. ELK、Twitter Zipkin、Apache Skywalking |
| **消息驱动**   | -                                 | RocketMQ                 | **Stream**               | Apache Kafka、VMware RabbitMQ                             |
| **服务限流**   | -                                 | Sentinel + Dashboard     | **Gateway**              | -                                                         |
| 分布式任务调度 | -                                 | Alibaba Cloud SchedulerX | springcloud-task         | 当当网 Elastic-Job                                        |
| 分布式事务     | -                                 | Seata                    | -                        | -                                                         |

#### 优点

1. **系统耦合度低**：不会影响其他模块的开发。
2. **减轻团队的成本**：可以并行开发，不用关注其他人怎么开发，先关注自己的开发。
3. **配置比较简单**：基本用注解就能实现，不用使用过多的配置文件。
4. **微服务跨平台**：可以用任何一种语言开发。
5. **独立部署**：每个微服务可以有自己的独立的数据库也有用公共的数据库。
6. **前后端分离**：直接写后端的代码，不用关注前端怎么开发，直接写自己的后端代码即可，然后暴露接口，通过组件进行服务通信。

#### 缺点

1. **部署比较麻烦**：给运维工程师带来一定的麻烦。
2. **数据管理比较麻烦**：因为微服务可以每个微服务使用一个数据库。
3. **系统集成测试比较麻烦**：一个功能可能涉及多个微服务。
4. **性能监控比较麻烦**：最好开发一个大屏监控系统。

#### SpringCloud VS Dubbo

|              | SpringCloud                          | Dubbo                        |
| ------------ | ------------------------------------ | ---------------------------- |
| 框架定位     | 微服务解决方案，打造微服务生态       | 分布式服务治理框架           |
| 服务通信方式 | Rest API（轻量、灵活、支持 Swagger） | RPC 远程调用（高效、但耦合） |
| 注册中心     | Eureka、Nacos                        | Zookeeper                    |
| 优点         | 使用方便                             | 性能好                       |

### 1.6. 什么是服务治理？

#### 背景

1. 在传统的系统部署中，服务运行在一个固定的已知的IP和端口上，如果一个服务需要调用另一个服务，那么可以通过地址直接调用。
2. 但是，在虚拟化或者容器化的环境中，服务实例的启动和销毁是很频繁的，那么服务地址也是在动态变化的，因此，就产生了服务治理的概念。

#### 概念

![1638094365495](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638094365495.png)

服务治理就是，在微服务架构中，提供各微服务实例快速上下线、保持各服务正常通信能力的方案总称，可以实现各微服务实例的**自动化注册与服务发现**。

1. **高可用性**：在服务治理麾下的所有微服务节点，不论是被闪电击中，还是被挖掘机铲掉了电源，即使战至最后一个存活节点，服务治理框架也要保证服务的可用性。
2. **分布式调用**：
   1. 微服务节点通常散落在不同的网络环境中，要求服务治理框架具备即使在复杂网络环境下，也能准确获知服务节点的网络地址的能力。
   2. 作为服务消费者，也可以借助服务治理框架的精准制导能力，向服务节点发起请求。
3. **生命周期管理**：服务治理贯穿每个微服务的生命周期，包括从服务上线，持续运行，到服务下线。
4. **健康度检查**：服务治理框架要精准识别"不健康"的微服务节点，然后将其从服务列表中剔除。

#### 实现方案

1. **服务注册**：服务提供方自报家门。
2. **服务发现**：服务消费方拉取注册数据。
3. **心跳检测、服务续约、服务剔除**：一套由服务提供方和注册中心配合完成的去伪存真的过程。
4. **服务下线**：服务提供方发起主动下线。

#### 技术选型

|                  | Eureka   | Consul    | Nacos                        | Zookeeper               | Etcd           |
| ---------------- | -------- | --------- | ---------------------------- | ----------------------- | -------------- |
| SpringCloud 集成 | 支持     | 支持      | 支持                         | 支持                    | 支持           |
| 性能             | 快       | 较慢      | 快                           | 较慢                    | 较慢           |
| 一致性           | 弱一致   | raft      | raft                         | paxos                   | raft           |
| CAP              | AP       | CP        | AP、CP                       | CP                      | CP             |
| 网络协议         | http     | http、dns | http、dns、udp               | 客户端                  | http、grpc     |
| KV 存储服务      | 不支持   | 支持      | 支持                         | 支持                    | 支持           |
| 本质             | 服务     |           | Jar 包                       | 进程                    | Service        |
| 特点             | 节点平等 |           | AP/CP切换、注册/配置中心通用 | Leader 选举、Watch 监听 | 云原生         |
| 用途             | 注册中心 |           | 注册中心和配置中心           | 分布式协调              | 云原生注册中心 |

### 1.7. 详细介绍 Eureka？

#### 背景 

1. 在传统应用组件间调用，是通过接口规范约束来实现的，从而实现不同模块间良好协作。
2. 但是在被拆分成微服务后，每个微服务实例的网络地址和数量都可能**动态变化**，导致使用原来硬编码地址的方式极不方便，因此，需要一个中心化的组件来进行服务的登记和管理。

#### 概念

Eureak，是 SpringCloud 服务治理的一种具体解决方案，是 Netflix 开源微服务框架一系列项目中的一个，Spring Cloud 对其进行了 SpringBoot 二次封装，形成了 Spring Cloud Netflix 子项目。

- **Eureka Server**：
  1. 一个公共注册中心服务，为 Eureka Client 提供服务注册和服务发现的功能，维护已注册到自身的Eureka Client 的相关信息。
  2. 同时，提供接口给 Eureka Client 获取注册表中其他服务的信息，使得动态变化的Eureka Client 能够进行服务间的相互调用，实现服务治理。
- **Eureka Client**：
  1. **作为服务提供者**，可以将自己的服务信息，通过 Restful 的方式注册到 Eureka Server上，并在正常范围内维护自己信息一致性，方便其他服务发现自己。
  2. **作为服务消费者**：可以通过 Eureka Server 获取到自己依赖的其他服务信息，完成服务调用，并且内置了负载均衡器，用来进行基本的负载均衡。

=> 因此，Eureka 是**服务注册和服务发现**的基础组件，屏蔽了 Eureka Server 和 Eureka Client 的交互细节，使得开发者能够不再重点关注服务治理，从而把精力放在业务上。

#### 架构原理

![1638234417008](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638234417008.png)

**注册中心本质**，是存储每个服务客户端的注册信息，EurekaClient 从 EurekaServer 同步获取服务注册列表，通过一定的规则选择一个服务进行调用。

- **服务注册中心**：提供服务注册和发现的功能。每个Eureka Client向Eureka Server注册自己的信息，也可以通过Eureka Server获取到其他服务的信息达到发现和调用其他服务的目的。
- **服务提供者**：是一个 Eureka client，向 Eureka Server 注册和更新自己的信息，同时可以从 Eureka Server 注册表中获取到其他服务的信息。
  1. **服务注册**：服务提供者向 Eureka Server，注册自身的元数据以供服务发现。
  2. **服务续约**：通过发送心跳到 Eureka Server，维持和更新注册表中服务实例元数据的**有效性**，如果在一定时长内，Eureka Server 没有收到 Eureka Client的心跳信息，则默认认为它已下线，会把该服务实例信息从注册表中删除。
  3. **服务下线**：服务提供者在关闭时，主动向 Eureka Server 注销服务实例元数据，此时，该服务实例数据将会从 Eureka Server 注册表中删除。
- **服务消费者**：也是一个 Eureka client，通过从 Eureka Server 注册表中获取到其他服务的信息，找到所需要的服务，然后发起远程调用。
  1. **服务发现**：获取注册表信息，Eureka Client 向 Eureka Server 请求注册表信息，以供发起远程调用。

#### 使用方式

##### Eureka Server

###### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
```

###### 配置文件

```properties
spring.application.name=eureka-server
server.port=20000

# 注册中心自己不需要服务注册和服务拉取(默认需要拉取)
eureka.instance.hostname=localhost
eureka.client.register-with-eureka=false
eureka.client.fetch-registry=false

# 强制关闭注册中心服务自保功能(关闭后服务自保的自动开关不起作用)
eureka.server.enable-self-preservation=false
# 注册中心每隔多久触发一次服务剔除(服务端定时任务执行服务剔除操作)
eureka.server.eviction-interval-timer-in-ms=10000
```

###### 启动类

```java
// Eureka Server测试启动类
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}
```

##### Eureka Client

###### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

###### 配置文件

```properties
spring.application.name=eureka-client
server.port=30000

# Eureka注册中心地址: defaultZone是serviceUrl中的一个map属性, /eureka/为默认写法(可以更改)
#eureka.client.serviceUrl.defaultZone=http://localhost:20000/eureka/

# 测试Eureka集群+互备: 只配置单注册中心
#eureka.client.serviceUrl.defaultZone=http://localhost:20011/eureka/
# 测试Eureka集群+互备: 只配置双注册中心
eureka.client.serviceUrl.defaultZone=http://peer1:20000/eureka/,http://peer2:40000/eureka/

# 高可用服务改造(服务提供者): 客户端每个X秒钟, 向注册中心发送一条续约指令(服务续约)
eureka.instance.lease-renewal-interval-in-seconds=5
# 高可用服务改造(服务提供者): 如果X秒内, 注册中心依然没有收到客户端的续约请求, 则判定客户端服务过期(客户端声明服务剔除周期判定时间)
eureka.instance.lease-expiration-duration-in-seconds=10
```

###### 启动类

```java
// Eureka Client测试启动类(服务提供者，而消费者也类似)
@SpringBootApplication
@EnableDiscoveryClient
public class EurekaClientApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaClientApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}
```

##### Portal UI

![1638107108492](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638107108492.png)

![1638107129321](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638107129321.png)

![1638108556248](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638108556248.png)

| 模块                    | 属性                              | 释义                                                         |
| ----------------------- | --------------------------------- | ------------------------------------------------------------ |
| System Status           | Environment                       | 当前环境，默认值为 test，一般不用修改，为默认值就好          |
|                         | Data Center                       | 当前数据中心，默认值为 default，一般不用修改，为默认值就好   |
|                         | Current time                      | 当前系统时间，并不会主动刷新，只当浏览器刷新页面时才刷新     |
|                         | Uptime                            | 指 Eureka Server 从启动到至今所经历的时间，比如 01：30 表示已经运行了 1 小时 30 分钟 |
|                         | Lease expiration enabled          | 是否启用租约过期，跟服务续约、服务剔除、服务自保都有一定关系 |
|                         | Renews threshold                  | 每分钟最少的续约数，比如 3 表示每分钟至少收到 3 个续约请求   |
|                         | Renews（last min）                | 最近一分钟的续约数（不包括目前的一分钟）                     |
| EMERGENCY红字           | 情况一                            | 表示由于最近一分钟续约数小于每分钟最少的续约数，从而已进入自保状态 |
|                         | 情况二                            | 自我保护机关已被强制关闭                                     |
|                         | 情况三                            | 出现多数节点与 Eureka 续约出现问题                           |
| DS Replicas             | Application                       | 服务的应用名称，没指定时默认为 UNKOWN                        |
|                         | AMIs                              | 心跳检测机制                                                 |
|                         | Availability Zones                | （1）表示可用分区数                                          |
|                         | Status                            | 服务实例可用状态，（1）表示可用实例数                        |
| General Info            | total-avail-memory                | 当前 Eureka 实例可用内存                                     |
|                         | environment                       | 当前环境，默认值为 test，一般不用修改，为默认值就好          |
|                         | num-of-cpus                       | 当前 CPU 核数                                                |
|                         | current-memory-usage              | 当前已使用内存，44% 表示当前机器已使用 44% 的内存            |
|                         | server-uptime                     | 指 Eureka Server 从启动到至今所经历的时间，比如 01：30 表示已经运行了 1 小时 30 分钟 |
|                         | registered-replicas               | 其他已注册的 Eureka 集群副本                                 |
|                         | unavailable-replicas              | 其他不可用的 Eureka 集群副本                                 |
|                         | available-replicas                | 其他可用的 Eureka 集群副本                                   |
| Instance Info           | ipAddr                            | 当前机器的 IP 地址                                           |
|                         | status                            | 当前服务的状态，UP 表示已上线                                |
| LAST 1000 SINCE STARTUP | Last 1000 cancelled leases        | 过去最近 1000 个被取消的实例租约                             |
|                         | Last 1000 newly registered leases | 过去最近 1000 个新注册的实例租约                             |

##### 常用 Rest 接口

| 用途                     | URL                                                          |
| ------------------------ | ------------------------------------------------------------ |
| 查看所有服务的注册列表   | GET http://localhost:1001/eureka/apps                        |
| 查看某一个服务的注册列表 | GET http://localhost:1001/eureka/apps/SERVICE-NAME           |
| 服务下线                 | PUT http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME/status?value=OUT_OF_SERVICE |
| 服务下线后恢复           | PUT http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME/status?value=UP |
| 服务剔除                 | DELETE http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME |

#### 注册中心启动原理 | Eureka Server

##### 1、导入配置类

```java
// 1、@EnableEurekaServer
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Import(EurekaServerMarkerConfiguration.class)
public @interface EnableEurekaServer {

}

@Configuration
public class EurekaServerMarkerConfiguration {

    // 2、构造Marker实例，以标识注册中心允许启动
	@Bean
	public Marker eurekaServerMarkerBean() {
		return new Marker();
	}

	class Marker {

	}
}
```

##### 2、Spring SPI 配置

```properties
# ..\spring-cloud-netflix-eureka-server-2.1.1.RELEASE.jar\META-INF\spring.factories
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
  org.springframework.cloud.netflix.eureka.server.EurekaServerAutoConfiguration
```

##### 3、初始化 Bean 配置类

```java
// 1、标识当前类为配置类
@Configuration
// 2、注入Eureka Server启动核心类
@Import(EurekaServerInitializerConfiguration.class)
// 3、标识为true，才进行初始化
@ConditionalOnBean(EurekaServerMarkerConfiguration.Marker.class)
// 4、使没有@Component的配置类生效
@EnableConfigurationProperties({ EurekaDashboardProperties.class,
		InstanceRegistryProperties.class })
// 5、注入properties配置，属性需从Environment中获取
@PropertySource("classpath:/eureka/server.properties")
public class EurekaServerAutoConfiguration extends WebMvcConfigurerAdapter {

    ....
	// 6、注入Eureka服务端相关配置
	@Autowired
	private EurekaServerConfig eurekaServerConfig;
	// 7、注入Eureka客户端相关配置
	@Autowired
	private EurekaClientConfig eurekaClientConfig;
    
	// 8、初始化集群注册表——PeerAwareInstanceRegistry
	@Bean
	public PeerAwareInstanceRegistry peerAwareInstanceRegistry(ServerCodecs serverCodecs) {
		...
	}
    
	// 9、初始化集群节点集合——PeerEurekaNodes
	@Bean
	@ConditionalOnMissingBean
	public PeerEurekaNodes peerEurekaNodes(PeerAwareInstanceRegistry registry, ServerCodecs serverCodecs,
			ReplicationClientAdditionalFilters replicationClientAdditionalFilters) {
		...
	}
    
	// 10、Eureka服务端上下文——EurekaServerContext
	@Bean
	@ConditionalOnMissingBean
	public EurekaServerContext eurekaServerContext(ServerCodecs serverCodecs, PeerAwareInstanceRegistry registry, PeerEurekaNodes peerEurekaNodes) {
		...
	}
    
	// 11、 Eureka服务端启动类——EurekaServerBootstrap
	@Bean
	public EurekaServerBootstrap eurekaServerBootstrap(PeerAwareInstanceRegistry registry,EurekaServerContext serverContext) {
		...
	}
    
	// 12. jersey过滤器——FilterRegistrationBean
	@Bean
    public FilterRegistrationBean<?> jerseyFilterRegistration(javax.ws.rs.core.Application eurekaJerseyApp) {
        ...
    }
}

```

##### 4、LifecycleProcessor#onRefresh 回调

```java
package org.springframework.context.support;

public abstract class AbstractApplicationContext extends DefaultResourceLoader
implements ConfigurableApplicationContext {
	// 1、SpringBoot/Spring启动时调用
	@Override
    public void refresh() throws BeansException, IllegalStateException {
    	...
    	// 2、最后一步，完成最后的上下文刷新
    	finishRefresh();
    	...
    }
    
    protected void finishRefresh() {
   		...
    	// 3、上下文刷新的通知，比如用于自动启动组件
    	getLifecycleProcessor().onRefresh();
    	..
    }
}

public class DefaultLifecycleProcessor implements LifecycleProcessor, BeanFactoryAware {
	// 4、使用默认的生命周期后置处理器
	@Override
	public void onRefresh() {
		startBeans(true);
		this.running = true;
	}
	
    private void startBeans(boolean autoStartupOnly) {
    	...
    	// 5、启动每一个生命周期方法
    	phases.get(key).start();
    	...
    }
    
    // 维护一组应该启动的Lifecycle bean的Helper类
    private class LifecycleGroup {
        public void start() {
        	...
        	// 6、启动每一个生命周期方法
			doStart(this.lifecycleBeans, member.name, this.autoStartupOnly);
			...
        }
    }
    
    private void doStart(Map<String, ? extends Lifecycle> lifecycleBeans, String beanName, boolean autoStartupOnly) {
   		...
   		// 7、启动生命周期方法
    	bean.start();
    	...
    }
}

// 8、由于实现了SmartLifecycle接口，因此SpringBoot启动时会回调start方法
public class EurekaServerInitializerConfiguration
    implements ServletContextAware, SmartLifecycle, Ordered {
    
	@Override
    public void start() {
         // 9、异步启动任务
		new Thread(new Runnable() {
			@Override
			public void run() {
                // 10、初始化Eureka Server上下文
                eurekaServerBootstrap.contextInitialized(
                    EurekaServerInitializerConfiguration.this.servletContext);
                log.info("Started Eureka Server");
                ...// 发布完成事件等等
			}
		}).start();
    }
}

```

##### 5、初始化 Eureka Server 上下文

```java
public class EurekaServerBootstrap {
	public void contextInitialized(ServletContext context) {
        ...
		// 1、初始化Eureka环境
        initEurekaEnvironment();
        // 2、初始化Eureka上下文
        initEurekaServerContext();
        ...
	}
    
    protected void initEurekaServerContext() throws Exception {
        ...
		log.info("Initialized server context");

		// 3、向其他Eureka Server同步租约实例，如果已经注册了的，则在当前Eureka Server注册一次
		int registryCount = this.registry.syncUp();
        // 4、初始化启动变量，以及启动服务剔除定时任务
		this.registry.openForTraffic(this.applicationInfoManager, registryCount);
		// 5、注册所有监视统计信息
		EurekaMonitors.registerAllStats();
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
		// 4.1. 初始化启动变量，以及启动服务剔除定时任务
		super.openForTraffic(applicationInfoManager,
				count == 0 ? this.defaultOpenForTrafficCount : count);
	}
}

public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
    	// 4.2. 设置期望的客户端数量，这里为1
    	this.expectedNumberOfClientsSendingRenews = count;
    	// 4.3. 设置最小续租阈值数量 = (int) 1 * (60/30) * 0.85 = 1，用于开启自保开关
    	updateRenewsPerMinThreshold();
    	// 4.4. 设置系统启动时间
    	this.startupTime = System.currentTimeMillis();
    	...
    	// 4.5. 设置UP实例状态
    	applicationInfoManager.setInstanceStatus(InstanceStatus.UP);
    	// 4.6. 设置完毕，上下文后置初始化处理
    	super.postInit();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void postInit() {
   		// 4.7. 设置服务剔除任务
        evictionTaskRef.set(new EvictionTask());
        // 4.8. 默认延迟60s后开始执行任务，且每60s执行一次
        evictionTimer.schedule(evictionTaskRef.get(),
                serverConfig.getEvictionIntervalTimerInMs(),
                serverConfig.getEvictionIntervalTimerInMs());
    }
}

```

#### 客户端启动原理 | Eureka Client

##### 1、导入配置类

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
// 2. 导入配置类EnableDiscoveryClientImportSelector
@Import(EnableDiscoveryClientImportSelector.class)
public @interface EnableDiscoveryClient {
    // 1. 默认为true，所以不设置@EnableDiscoveryClient，服务也能完成注册和发现
    boolean autoRegister() default true;
}

// 3. ImportSelector接口的返回值会递归进行解析，把解析到的类全名按照@Configuration进行处理
@Order(Ordered.LOWEST_PRECEDENCE - 100)
public class EnableDiscoveryClientImportSelector
    extends SpringFactoryImportSelector<EnableDiscoveryClient> {
	@Override
    public String[] selectImports(AnnotationMetadata metadata) {
        ...
		if (autoRegister) {
			List<String> importsList = new ArrayList<>(Arrays.asList(imports));
            // 4. 指定导入AutoServiceRegistrationConfiguration
			importsList.add(
					"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationConfiguration");
			imports = importsList.toArray(new String[0]);
		}
        ...
    }
}

@Configuration
// 5. 读取spring.cloud.service-registry.auto-registration文件，并允许注入属性
@EnableConfigurationProperties(AutoServiceRegistrationProperties.class)
// 6. 默认设置spring.cloud.service-registry.auto-registration.enabled开关为true
@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
public class AutoServiceRegistrationConfiguration {

}

```

##### 2、Spring SPI 配置

```properties
# .../spring-cloud-netflix-eureka-client/2.1.1.RELEASE/spring-cloud-netflix-eureka-client-2.1.1.RELEASE.jar!/META-INF/spring.factories
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
# Eureka client自动配置类，负责client中关键beans的配置和初始化
org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\
# Ribbon负载均衡自动配置类
org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\
# 服务注册和健康检查器自动配置类
org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration

```

##### 3、服务注册 & 健康检查自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnClass(EurekaClientConfig.class)
// 1、默认设置eureka.client.enabl=true
@ConditionalOnProperty(value = "eureka.client.enabled", matchIfMissing = true)
@ConditionalOnDiscoveryEnabled
public class EurekaDiscoveryClientConfiguration {
    
    class Marker {

	}
    
    // 2、注入服务启动标识
	@Bean
	public Marker eurekaDiscoverClientMarker() {
		return new Marker();
	}
    
    // 3、默认关闭健康检查
    @Configuration
	@ConditionalOnProperty(value = "eureka.client.healthcheck.enabled", matchIfMissing = false)
    protected static class EurekaHealthCheckHandlerConfiguration {
        ...
    }
    
    // 4、注册Spring上下文刷新完毕监听器
    @Configuration
	@ConditionalOnClass(RefreshScopeRefreshedEvent.class)
	protected static class EurekaClientConfigurationRefresher
        implements ApplicationListener<RefreshScopeRefreshedEvent> {
        
		@Autowired(required = false)
		private EurekaClient eurekaClient;

		@Autowired(required = false)
		private EurekaAutoServiceRegistration autoRegistration;

		public void onApplicationEvent(RefreshScopeRefreshedEvent event) {
			...
            // 5、确保在Spring上下文刷新事件后不为空，否则将重新注册
			if (autoRegistration != null) {
				this.autoRegistration.stop();
				this.autoRegistration.start();
			}
		}
    }
}

```

##### 3、Eureka Client 自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnClass(EurekaClientConfig.class)
@Import(DiscoveryClientOptionalArgsConfiguration.class)
// 1、需要有服务启动标识，默认有
@ConditionalOnBean(EurekaDiscoveryClientConfiguration.Marker.class)
// 2、默认设置eureka.client.enabl=true
@ConditionalOnProperty(value = "eureka.client.enabled", matchIfMissing = true)
// 3、默认设置spring.cloud.discovery.enabled=true
@ConditionalOnDiscoveryEnabled
// 4、该类注入在下面这些类注入之前
@AutoConfigureBefore({ NoopDiscoveryClientAutoConfiguration.class,
		CommonsClientAutoConfiguration.class, ServiceRegistryAutoConfiguration.class })
// 5、该类注入在下面这些类注入之后
@AutoConfigureAfter(name = {
		"org.springframework.cloud.autoconfigure.RefreshAutoConfiguration",
"org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration",	"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationAutoConfiguration" })
public class EurekaClientAutoConfiguration {
    
    // 6、注入EurekaClient配置类
	@Bean
	@ConditionalOnMissingBean(value = EurekaClientConfig.class, search = SearchStrategy.CURRENT)
    public EurekaClientConfigBean eurekaClientConfigBean(ConfigurableEnvironment env) {
        ...
    }
    
    // 7、注入EurekaClient配置管理类
	@Bean
	@ConditionalOnMissingBean
	public ManagementMetadataProvider serviceManagementMetadataProvider() {
		return new DefaultManagementMetadataProvider();
	}
    
    // 8、读取eureka.instance.hostname、eureka.instance.prefer-ip-address、eureka.instance.ip-address、server.servlet.context-path、server.port等配置，注入EurekaInstanceConfigBean instance实例
    @Bean
	@ConditionalOnMissingBean(value = EurekaInstanceConfig.class, search = SearchStrategy.CURRENT)
	public EurekaInstanceConfigBean eurekaInstanceConfigBean(InetUtils inetUtils,
                                                             ManagementMetadataProvider managementMetadataProvider) {
        ...
    }
    
    // 9、注入DiscoveryClient，用于包装EurekaClient
    @Bean
	public DiscoveryClient discoveryClient(EurekaClient client,
			EurekaClientConfig clientConfig) {
		return new EurekaDiscoveryClient(client, clientConfig);
	}
    
    // 10、注入EurekaServiceRegistry
    @Bean
	public EurekaServiceRegistry eurekaServiceRegistry() {
		return new EurekaServiceRegistry();
	}
    
    // 11、注入EurekaAutoServiceRegistration，对应上面所说的《确保在Spring上下文刷新事件后不为空，否则将重新注册》
    @Bean
	@ConditionalOnBean(AutoServiceRegistrationProperties.class)
	@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
	public EurekaAutoServiceRegistration eurekaAutoServiceRegistration(
			ApplicationContext context, EurekaServiceRegistry registry,
			EurekaRegistration registration) {
		return new EurekaAutoServiceRegistration(context, registry, registration);
	}
    
    // #重点#
    @Configuration
	@ConditionalOnMissingRefreshScope
    protected static class EurekaClientConfiguration {
        ...
        // 12、注入EurekaClient核心类，且在销毁时调用EurekaClient#shutdown，进行服务下线
		@Bean(destroyMethod = "shutdown")
		@ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT)
		public EurekaClient eurekaClient(ApplicationInfoManager manager,
				EurekaClientConfig config) {
			return new CloudEurekaClient(manager, config, this.optionalArgs,
					this.context);
		}
        
        // 13、注入app管理器
		@Bean
		@ConditionalOnMissingBean(value = ApplicationInfoManager.class, search = SearchStrategy.CURRENT)
		public ApplicationInfoManager eurekaApplicationInfoManager(
				EurekaInstanceConfig config) {
			InstanceInfo instanceInfo = new InstanceInfoFactory().create(config);
			return new ApplicationInfoManager(config, instanceInfo);
		}
        
        // 14、注入服务注册实例
		@Bean
		@ConditionalOnBean(AutoServiceRegistrationProperties.class)
		@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
		public EurekaRegistration eurekaRegistration(EurekaClient eurekaClient,
				CloudEurekaInstanceConfig instanceConfig,
				ApplicationInfoManager applicationInfoManager,
				@Autowired(required = false) ObjectProvider<HealthCheckHandler> healthCheckHandler) {
			return EurekaRegistration.builder(instanceConfig).with(applicationInfoManager)
					.with(eurekaClient).with(healthCheckHandler).build();
		}
    }
    ...// 15、注入一些支持配置刷新的EurekaClient相关类、以及健康检查指标类等等
}

```

##### 4、注入 EurekaClient 核心类

```java
// 0. 在EurekaClientAutoConfiguration进行了自动注入，这里介绍如何创建EurekaClient核心类
public class CloudEurekaClient extends DiscoveryClient {
	public CloudEurekaClient(ApplicationInfoManager applicationInfoManager,
			EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs<?> args,
			ApplicationEventPublisher publisher) {
        // 1、调用父类DiscoveryClient构造器
		super(applicationInfoManager, config, args);
		...
	}
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    public DiscoveryClient(ApplicationInfoManager applicationInfoManager, final EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args) {
        // 2、调用其他构造器
        this(applicationInfoManager, config, args, new Provider<BackupRegistry>() {
            private volatile BackupRegistry backupRegistryInstance;

            @Override
            public synchronized BackupRegistry get() {
                ...
            }
        });
    }
    
    // 3、注入构造器参数实例ApplicationInfoManager、EurekaClientConfig config和AbstractDiscoveryClientOptionalArgs
    @Inject
    DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,
                    Provider<BackupRegistry> backupRegistryProvider) {
		...// 4、初始化一些配置参数
        try {
            // 5、构建2c、无边界线程、无边界容量的后台延迟线程池DiscoveryClient-n，用于定时执行
            scheduler = Executors.newScheduledThreadPool(2,
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-%d")
                            .setDaemon(true)
                            .build());
            // 6、构建1c、2max、0空闲、0容量的后台线程池DiscoveryClient-HeartbeatExecutor-n，用于执行心跳检测
            heartbeatExecutor = new ThreadPoolExecutor(
                    1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,
                    new SynchronousQueue<Runnable>(),
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-HeartbeatExecutor-%d")
                            .setDaemon(true)
                            .build()
            );
            
			// 7、构建1c、2max、0空闲、0容量的后台线程池DiscoveryClient-CacheRefreshExecutor-n，用于执行缓存刷新
            cacheRefreshExecutor = new ThreadPoolExecutor(
                    1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,
                    new SynchronousQueue<Runnable>(),
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-CacheRefreshExecutor-%d")
                            .setDaemon(true)
                            .build()
            );

            ...
        } catch (Throwable e) {
            throw new RuntimeException("Failed to initialize DiscoveryClient!", e);
        }
        
        // 8、根据fetch-registry配置参数，增量拉取拉取注册表信息
        if (clientConfig.shouldFetchRegistry() && !fetchRegistry(false)) {
            // 8.1. 由于拉取没发生异常，所以不会返回false，这里也就不会进来了
            fetchRegistryFromBackup();
        }
        
        ...// 先初始化一些注册前的信息
        
        // 9、根据register-with-eureka配置参数向服务端注册，这里由于客户端初始化无需强制执行初始注册，所以也不会进行先注册
        if (clientConfig.shouldRegisterWithEureka() && clientConfig.shouldEnforceRegistrationAtInit()) {
            try {
                if (!register() ) {
                    throw new IllegalStateException("Registration error at startup. Invalid server response.");
                }
            } catch (Throwable th) {
                logger.error("Registration error at startup: {}", th.getMessage());
                throw new IllegalStateException(th);
            }
        }
        
        // 10、最后，初始化调度任务（例如集群解析器、心跳、instanceInfo 复制器、获取注册表）
        initScheduledTasks();
        
        ...// 注册到监控中心、注册DiscoveryClient实例 & 配置实例到管理器中、设置initTimestampMs、打印日志等操作
    }
    
    // 初始化调度任务（例如集群解析器、心跳、instanceInfo 复制器、获取注册表）
    private void initScheduledTasks() {
        // 10.1、默认需要拉取注册表信息
        if (clientConfig.shouldFetchRegistry()) {
            ...
            // 10.2、启动超时时间30s，最大超时300s，延迟30s执行，交由cacheRefreshExecutor线程池处理的，以指定的时间间，隔获取注册表信息任务（服务发现）
            scheduler.schedule(
                    new TimedSupervisorTask(
                            "cacheRefresh",
                            scheduler,
                            cacheRefreshExecutor,
                            registryFetchIntervalSeconds,// 30s，超时时间
                            TimeUnit.SECONDS,
                            expBackOffBound,// 10s，30*10，用于计算最大超时时间
                            // 以指定的时间间，隔获取注册表信息任务
                            new CacheRefreshThread()
                    ),
                    // 30s，延迟执行时间
                    registryFetchIntervalSeconds, TimeUnit.SECONDS);
        }
        
        // 10.3、默认需要注册服务到Eureka
        if (clientConfig.shouldRegisterWithEureka()) {
            ...

            // 10.4、非默认参数，启动续租超时时间5s，最大超时50s，延迟5s执行，交由heartbeatExecutor线程池处理的，在给定的时间间隔内，更新租约的心跳任务（心跳检测）
            scheduler.schedule(
                    new TimedSupervisorTask(
                            "heartbeat",
                            scheduler,
                            heartbeatExecutor,
                            renewalIntervalInSecs,// 5s，续租超时时间
                            TimeUnit.SECONDS,
                            expBackOffBound,// 10s，5*10，用于计算最大超时时间
                        	// 在给定的时间间隔内，更新租约的心跳任务
                            new HeartbeatThread()
                    ),
               		 // 5s，延迟执行时间
                    renewalIntervalInSecs, TimeUnit.SECONDS);

            // 10.5、构建更新和复制本地实例信息到远程服务器的任务，副本同步周期30s
            instanceInfoReplicator = new InstanceInfoReplicator(
                    this,
                    instanceInfo,
                    clientConfig.getInstanceInfoReplicationIntervalSeconds(),// 30s
                    2);

            // 10.6、构造服务实例监听器
            statusChangeListener = new ApplicationInfoManager.StatusChangeListener() {
                ...// getId()
                    
                @Override
                public void notify(StatusChangeEvent statusChangeEvent) {
                    ...// 打印日志
                    // 10.7、在应用状态发生变化时，刷新服务实例信息，在服务实例信息发生改变时，向server注册 => 底层调用instanceInfoReplicator#run方法
                    instanceInfoReplicator.onDemandUpdate();
                }
            };
            
            // 10.8、默认设置监听器
            if (clientConfig.shouldOnDemandUpdateStatusChange()) {
       applicationInfoManager.registerStatusChangeListener(statusChangeListener);
            }

            // 10.9、启动服务实例更新任务，默认第一次延迟40s运行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp，表示第一次需要注册
            instanceInfoReplicator.start(
               clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()// 40s
            );
        } else {
            logger.info("Not registering with Eureka server per configuration");
        }
    }
    
    // 10.10、启动服务实例更新任务，默认第一次延迟40s执行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp脏时间戳（后面用于服务续约），表示第一次需要注册
    public void start(int initialDelayMs) {
        if (started.compareAndSet(false, true)) {
            instanceInfo.setIsDirty();
            Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS);
            scheduledPeriodicRef.set(next);
        }
    }
}

```

#### 服务注册原理

##### 发起请求 | Eureka Client

###### 1、第一次调用 InstanceInfoReplicator#run

| 配置                                  | 默认 | 说明                               |
| ------------------------------------- | ---- | ---------------------------------- |
| eureka.registration.enabled           | true | Eureka Client 是否开启服务注册     |
| eureka.appinfo.replicate.interval     | 30s  | 服务实例副本同步周期               |
| eureka.appinfo.initial.replicate.time | 40s  | 服务实例服务副本同步的初始延迟时间 |

```java
// 1、在构造EurekaClient时，调用了instanceInfoReplicator#start，来启动服务实例更新任务，默认第一次延迟40s运行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp（后面用于服务续约），表示第一次需要注册
class InstanceInfoReplicator implements Runnable {
    public void run() {
        try {
            // 2、刷新当前本地instanceInfo，在观察到更改的有效刷新后，instanceInfo#isDirty会被设置为true，并且更新lastDirtyTimestamp脏时间戳（用于后面的服务续约）
            discoveryClient.refreshInstanceInfo();

            // 3、获取lastDirtyTimestamp，如果存在，则需要当前服务重新发起注册
            Long dirtyTimestamp = instanceInfo.isDirtyWithTime();
            if (dirtyTimestamp != null) {
                // 4、重新发起注册，第一次调用InstanceInfoReplicator#run则必定发起注册
                discoveryClient.register();
                // 5、重新注册成功，则清空isDirty，设置isInstanceInfoDirty=false
                instanceInfo.unsetIsDirty(dirtyTimestamp);
            }
        } catch (Throwable t) {
            logger.warn("There was a problem with the instance info replicator", t);
        } finally {
            // 6、最后再延迟30s后重新执行该任务
            Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS);
            scheduledPeriodicRef.set(next);
        }
    }
}

```

###### 2、调用 DiscoveryClient#register

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 4.1、通过进行适当的 REST 调用来注册 eureka 服务
    boolean register() throws Throwable {
        logger.info(PREFIX + "{}: registering service...", appPathIdentifier);
        EurekaHttpResponse<Void> httpResponse;
        try {
            // 4.2、调用EurekaHttpClient#register进行服务注册
            httpResponse = eurekaTransport.registrationClient.register(instanceInfo);
        } catch (Exception e) {
            logger.warn(..., e);
            throw e;
        }
        if (logger.isInfoEnabled()) {
            logger.info(...);
        }
        // 4.24、响应成功，状态码等于NO_CONTENT(204, "No Content"),代表服务注册成功
        return httpResponse.getStatusCode() == Status.NO_CONTENT.getStatusCode();
    }
}

public abstract class EurekaHttpClientDecorator implements EurekaHttpClient {
    
    // 4.4、多态调用SessionedEurekaHttpClient#execute
    // 4.8、多态调用RetryableEurekaHttpClient#execute
    // 4.13、多态调用RedirectingEurekaHttpClient#execute
    // 4.17、多态调用MetricsCollectingEurekaHttpClient#execute
    protected abstract <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor);
     
    @Override
    public EurekaHttpResponse<Void> register(final InstanceInfo info) {
        // 4.3、调用模板execute方法
        // 4.7、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        // 4.12、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        // 4.16、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        return execute(new RequestExecutor<Void>() {
            @Override
            public EurekaHttpResponse<Void> execute(EurekaHttpClient delegate) {
                // 4.6、多态调用RetryableEurekaHttpClient#execute
                // 4.11、多态调用RedirectingEurekaHttpClient#execute
                // 4.15、多态调用MetricsCollectingEurekaHttpClient#execute
                return delegate.register(info);
            }

            @Override
            public RequestType getRequestType() {
                return RequestType.Register;
            }
        });
    }
}

```

###### 3、多态调用 SessionedEurekaHttpClient#execute

```java
public class SessionedEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        long now = System.currentTimeMillis();
        long delay = now - lastReconnectTimeStamp;
        
        // 4.4、更新session时间currentSessionDurationMs
        if (delay >= currentSessionDurationMs) {
            logger.debug("Ending a session and starting anew");
            lastReconnectTimeStamp = now;
            currentSessionDurationMs = randomizeSessionDuration(sessionDurationMs);
            TransportUtils.shutdown(eurekaHttpClientRef.getAndSet(null));
        }

        ...
        
        // 4.5、调用装饰者requestExecutor#execute
        // 4.23、响应成功，则直接返回结果
        return requestExecutor.execute(eurekaHttpClient);
    }
}

```

###### 4、多态调用 RetryableEurekaHttpClient#execute

```java
public class RetryableEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.9、默认最大重试3次
        for (int retry = 0; retry < numberOfRetries; retry++) {
            ...
            try {
                // 4.10、调用装饰者requestExecutor#execute
                EurekaHttpResponse<R> response = requestExecutor.execute(currentHttpClient);
                // 4.22、响应成功，设置当前客户端为调用成功的客户端，然后返回响应结果
                if (serverStatusEvaluator.accept(response.getStatusCode(), requestExecutor.getRequestType())) {
                    delegate.set(currentHttpClient);
                    if (retry > 0) {
                        logger.info("Request execution succeeded on retry #{}", retry);
                    }
                    return response;
                }
                logger.warn(...);
            } catch (Exception e) {
                logger.warn(...);
            }

            // 如果超过了最大重试次数，仍没调用成功，则会来到这里，则设置调用成功的客户端为null，代表没有调用成功过
            delegate.compareAndSet(currentHttpClient, null);
            // 然后把当前currentEndpoint加入失败列表
            if (currentEndpoint != null) {
                quarantineSet.add(currentEndpoint);
            }
        }
        throw new TransportException("Retry limit reached; giving up on completing the request");
    }
}

```

5、多态调用 RedirectingEurekaHttpClient#execute

```java
public class RedirectingEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.14、底层调用装饰者requestExecutor#execute
     	EurekaHttpResponse<R> response = executeOnNewServer(requestExecutor, currentEurekaClientRef);
        ...
        // 4.21、响应成功，无需重定向
        return response;
        ...
    }
}

```

###### 6、多态调用 MetricsCollectingEurekaHttpClient#execute

```java
public class MetricsCollectingEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.18、最后调用AbstractJerseyEurekaHttpClient#register方法
        EurekaHttpResponse<R> httpResponse = requestExecutor.execute(delegate);
        // 4.20、响应成功，记录调用结果
        requestMetrics.countersByStatus.get(mappedStatus(httpResponse)).increment();
        return httpResponse;
    }
}

```

###### 7、最后调用 AbstractJerseyEurekaHttpClient#register

```java
public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    @Override
    public EurekaHttpResponse<Void> register(InstanceInfo info) {
        // urlPath => apps/EUREKA-CLIENT
        String urlPath = "apps/" + info.getAppName();
        ClientResponse response = null;
        try {
            Builder resourceBuilder = jerseyClient.resource(serviceUrl).path(urlPath).getRequestBuilder();
            addExtraHeaders(resourceBuilder);
            
            // 4.19、正式发起post请求进行服务注册 => 这里返回NO_CONTENT(204, "No Content"),代表服务注册成功（此时在Eureka Portal中已经能看到该服务实例了）
            response = resourceBuilder
                    .header("Accept-Encoding", "gzip")
                    .type(MediaType.APPLICATION_JSON_TYPE)
                    .accept(MediaType.APPLICATION_JSON)
                    .post(ClientResponse.class, info);
            return anEurekaHttpResponse(response.getStatus()).headers(headersOf(response)).build();
        } finally {
            if (logger.isDebugEnabled()) {
                logger.debug(...);
            }
            if (response != null) {
                response.close();
            }
        }
    }
}

```

##### 响应请求 | Eureka Server

###### 1、请求分发到 addInstance 接口

```java
// jersey server resource，相当于MVC中的Controller
@Produces({"application/xml", "application/json"})
public class ApplicationResource {
    // 1、服务注册接口，相当于MVC中的RequestMapping
    @POST
    @Consumes({"application/json", "application/xml"})
    public Response addInstance(InstanceInfo info,
                                @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        ...// 一大堆校验
        // 2、调用注册方法，然后返回204给Eureka Client
        registry.register(info, "true".equals(isReplication));
        return Response.status(204).build();
    }
}

```

###### 2、调用 register，开始注册

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void register(final InstanceInfo info, final boolean isReplication) {
		...// 获取租约过期时间（默认为90s），打印日志等
		// 3、注册有关InstanceInfo信息，并复制将此信息发送给所有对等的Eureka节点，但如果这是来自其他副本节点的，那么不会再复制 => 这里是服务注册，所以isReplication为false
		super.register(info, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void register(final InstanceInfo info, final boolean isReplication) {
    	...// 获取租约过期时间（默认为90s）
        // 4、注册具有给定持续时间的新实例
        super.register(info, leaseDuration, isReplication);
        replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);
    }
}

```

###### 3、执行注册 & 写入服务实例

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
	// 服务实例ID instance-id="host：appnNme:port"
	// Eureka Server服务列表双重Map缓存=>{"appName"：{instance-id:InstanceInfo}}
    private final ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry = new ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>>();
            
	// 注册具有给定持续时间的新实例
    public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {
        try {
        	// 5、获取读锁
            read.lock();
            
            // 6、如果为第一次注册，则创建appName：空Map（服务实例的状态变化时，Server可能会收到多次，来自同一个实例的注册请求）
            Map<String, Lease<InstanceInfo>> gMap = registry.get(registrant.getAppName());
            REGISTER.increment(isReplication);
            if (gMap == null) {
                final ConcurrentHashMap<String, Lease<InstanceInfo>> gNewMap = new ConcurrentHashMap<String, Lease<InstanceInfo>>();
                gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap);
                if (gMap == null) {
                    gMap = gNewMap;
                }
            }
            
            // 如果已经有租约，则保留最后一个脏时间戳而不覆盖它
            Lease<InstanceInfo> existingLease = gMap.get(registrant.getId());
            if (existingLease != null && (existingLease.getHolder() != null)) {
            	// 7、如果双重Map缓存中的lastDirtyTimestamp比新传过来的lastDirtyTimestamp还要大/新，说明注册请求的时间落后，则继续使用缓存而不发生替换
                ...
            } else {
                // 8、租约不存在，因此是新注册
                synchronized (lock) {
                    if (this.expectedNumberOfClientsSendingRenews > 0) {
                        // 9、由于客户端要注册，增加客户端发送更新的数量
                        this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1;
                        // 10、更新每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
                        updateRenewsPerMinThreshold();
                    }
                }
                logger.debug(...);
            }
            
            // 9、如果租约不存在，或者租约是最新的租约，则设置或者更新到双重Map缓存中
            Lease<InstanceInfo> lease = new Lease<InstanceInfo>(registrant, leaseDuration);
            if (existingLease != null) {
                lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp());
            }
            gMap.put(registrant.getId(), lease);
            
            // 10、加入最新注册队列中
            synchronized (recentRegisteredQueue) {
                recentRegisteredQueue.add(new Pair<Long, String>(
                        System.currentTimeMillis(),
                        registrant.getAppName() + "(" + registrant.getId() + ")"));
            }
           
			...// 更新租约等状态
			// 11、更新租约最后更新时间
            registrant.setLastUpdatedTimestamp();
            // 12、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已重新加入服务列表，所以只读缓存也重新加入它，不过有一定的延迟（默认30s同步一次）
            invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress());
            logger.info(...);
        } finally {
        	// 13、释放读锁
            read.unlock();
        }
    }
}

```

#### 服务发现原理

##### 概念

服务发现分为两种实现方式，分别是客户端和服务端的服务发现，而 Eureka 正是客户端实现的服务发现。

###### 客户端服务发现

![1639056166351](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639056166351.png)

- **优点**：客户端知道所有可用服务的实际网络地址，可以非常方便的实现负载均衡功能。
- **缺点**：语言耦合性很强，针对不同的语言，每个服务的客户端都得实现一套服务发现的功能。

###### 服务端服务发现

![1639056226782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639056226782.png)

- **优点**：服务发现逻辑对客户端是透明的，客户端只管向 LOAD BALANCER 负载均衡器发送请求即可。
- **缺点**：需要关心 LOAD BALANCER 负载均衡器组件的高可用。

##### 发起请求 | Eureka Client

###### 1、调用服务列表拉取1 | 构建 DiscoveryClient 时

```java
@Singleton
public class CloudEurekaClient extends DiscoveryClient {
    @Inject
    DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,
                    Provider<BackupRegistry> backupRegistryProvider) {
        ...
        // 1、根据fetch-registry配置参数，增量拉取拉取注册表信息
        if (clientConfig.shouldFetchRegistry() && !fetchRegistry(false)) {
            // 2、 由于拉取没发生异常，所以不会返回false，这里也就不会进来了
            fetchRegistryFromBackup();
        }
        ...
    }
}

```

###### 2、调用服务列表拉取2 | 默认30s 定时拉取

| 配置                                               | 默认 | 说明                                |
| -------------------------------------------------- | ---- | ----------------------------------- |
| eureka.shouldFetchRegistry                         | true | Eureka Client 是否需要拉取服务列表  |
| eureka.client.refresh.interval                     | 30s  | 服务列表拉取周期                    |
| eureka.client.cacheRefresh.exponentialBackOffBound | 10倍 | 10 * 30，表示最大的服务拉取周期乘数 |

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、启动超时时间30s，最大超时300s，延迟30s执行，交由cacheRefreshExecutor线程池处理的，以指定的时间间，隔获取注册表信息任务（服务发现）
    class CacheRefreshThread implements Runnable {
        public void run() {
            refreshRegistry();
        }
    }
    @VisibleForTesting
    void refreshRegistry() {
        ...
        // 2、如果currentRemoteRegions不等于latestRemoteRegions，说明region发生了变化，则remoteRegionsModified=true，代表进行全量拉取；否则，默认按增量拉取
    	boolean success = fetchRegistry(remoteRegionsModified);
        ...
    }
}

```

###### 3、服务列表拉取

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、获取注册表信息，除非在协调Eureka服务器和客户端注册表信息时出现问题，否则，此方法尝试仅在第一次获取后获取增量，forceFullRegistryFetch 强制获取完整的注册表
    private boolean fetchRegistry(boolean forceFullRegistryFetch) {
        Stopwatch tracer = FETCH_REGISTRY_TIMER.start();

        try {
            Applications applications = getApplications();

            if (// 2、是否禁用了增量拉取，默认为false
                clientConfig.shouldDisableDelta() 
                // 3、是否关注某个VIP地址，默认为否
                ||                 (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress()))
                	// 4、是否需要拉取全量服务列表，默认为false
                    || forceFullRegistryFetch
                	// 5、apps是否为null，默认不为null
                    || (applications == null)
                	// 6、apps是否为空，注册时的拉取确实为空，定时拉取的一般不为空
                    || (applications.getRegisteredApplications().size() == 0)
                	// 7、客户端应用程序没有支持增量的最新库，默认支持
                    || (applications.getVersion() == -1))
            {
                ...// 日志打印
                // 8、全量拉取服务列表
                getAndStoreFullRegistry();
            } else {
                // 9、增量拉取服务列表
                getAndUpdateDelta(applications);
            }
            ...
        } catch (Throwable e) {
            logger.error(...);
            // 10、服务列表拉取异常，则返回false
            return false;
        } finally {
            if (tracer != null) {
                tracer.stop();
            }
        }

        // 11、更新实例远程状态前，通知缓存刷新
        onCacheRefreshed();

        // 12、根据缓存中保存的刷新数据，更新远程状态
        updateInstanceRemoteStatus();

        // 13、注册表已成功获取，因此返回 true
        return true;
    }
}

```

###### 4、全量拉取服务列表

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 全量拉取注册表信息
    private void getAndStoreFullRegistry() throws Throwable {
        ...     
        EurekaHttpResponse<Applications> httpResponse = 
            // 1、先判断是否对某个VIP地址感兴趣，这里没有配置
            clientConfig.getRegistryRefreshSingleVipAddress() == null?
            // 2、则拉取Regions的注册表，但这里没有任何已注册的信息
            eurekaTransport.queryClient.getApplications(remoteRegionsRef.get()): eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get());
        ...
        // 6、设置为本地服务列表
        localRegionApps.set(this.filterAndShuffle(apps));
        ...
    }   
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 4、最后实际调用AbstractJerseyEurekaHttpClient#getApplications方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Applications> getApplications(String... regions) {
        return getApplicationsInternal("apps/", regions);
    }
    
    private EurekaHttpResponse<Applications> getApplicationsInternal(String urlPath, String[] regions) {
		...
        try {
            // serviceUrl=http://localhost:20000/eureka/，urlPath=apps/
            WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);
            ...
            // 5、真正发起请求 => 响应 Client response status: 200
            response = requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class);
			...
        } finally {
            ...
        }
    }
}

```

###### 5、增量拉取服务列表

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    private void getAndUpdateDelta(Applications applications) throws Throwable {
        ...
        // 1、增量拉取Regions的注册表
        EurekaHttpResponse<Applications> httpResponse = eurekaTransport.queryClient.getDelta(remoteRegionsRef.get());
        ...// 5、如果拉取结果为null，还会全量去拉取一遍
        // 6、根据增量更新本地服务列表
        updateDelta(delta);
        ...
    }
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 2、最后实际调用AbstractJerseyEurekaHttpClient#getDelta方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Applications> getDelta(String... regions) {
        return getApplicationsInternal("apps/delta", regions);
    }
    
    private EurekaHttpResponse<Applications> getApplicationsInternal(String urlPath, String[] regions) {
		...
        try {
            // serviceUrl=http://localhost:20000/eureka/，urlPath=apps/delta
            WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);
            ...
            // 4、真正发起请求 => 响应 Client response status: 200
            response = requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class);
			...
        } finally {
            ...
        }
    }
}

```

##### 响应请求 | Eureka Server

###### 1、全量更新接口

```java
@Path("/{version}/apps")
@Produces({"application/xml", "application/json"})
public class ApplicationsResource {
    @GET
    public Response getContainers(@PathParam("version") String version,
                                  @HeaderParam(HEADER_ACCEPT) String acceptHeader,
                                  @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding,
                                  @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept,
                                  @Context UriInfo uriInfo,
                                  @Nullable @QueryParam("regions") String regionsStr) {
        ...
        Response response;
        if (acceptEncoding != null && acceptEncoding.contains(HEADER_GZIP_VALUE)) {
            // 1、从缓存中获取gzip部分（见两级缓存原理），eg：entity_name=ALL_APPS，hash_key=ApplicationALL_APPSJSONV2full
            response = Response.ok(responseCache.getGZIP(cacheKey))
                    .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE)
                    .header(HEADER_CONTENT_TYPE, returnMediaType)
                    .build();
        } else {
            // 2、否则直接从缓存中获取
            response = Response.ok(responseCache.get(cacheKey))
                    .build();
        }
        return response;
    }
}

```

###### 2、增量拉取接口

```java
@Path("/{version}/apps")
@Produces({"application/xml", "application/json"})
public class ApplicationsResource {
    @Path("delta")
    @GET
    public Response getContainerDifferential(
            @PathParam("version") String version,
            @HeaderParam(HEADER_ACCEPT) String acceptHeader,
            @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding,
            @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept,
        @Context UriInfo uriInfo, @Nullable @QueryParam("regions") String regionsStr) {
        if (acceptEncoding != null
                && acceptEncoding.contains(HEADER_GZIP_VALUE)) {
            // 1、从缓存中获取gzip部分（见两级缓存原理），eg：entity_name=ALL_APPS_DELTA，hash_key=ApplicationALL_APPS_DELTAJSONV2full
            return Response.ok(responseCache.getGZIP(cacheKey))
                    .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE)
                    .header(HEADER_CONTENT_TYPE, returnMediaType)
                    .build();
        } 
        // 2、否则直接从缓存中获取
        else {
            return Response.ok(responseCache.get(cacheKey))
                    .build();
        }
    }
}

```

#### 服务列表缓存原理

![1638705242665](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638705242665.png)

##### 两级缓存机制 | Eureka Server

###### 概念

1. 服务注册到注册中⼼后，服务实例信息存储在 `AbstractInstanceRegistry#registry` 中，即内存中。
2. 但 Eureka 为了提⾼响应速度，在内部做了优化，加⼊了两层的缓存结构，将 Client 需要的实例信息，直接缓存起来，获取时直接从缓存中拿数据，然后响应给 Client。 
   1. 第⼀层缓存是 `ResponseCacheImpl#readOnlyCacheMap`，采⽤ ConcurrentHashMap 来存储数据，定时与 ` ResponseCacheImpl#readWriteCacheMap` 进⾏数据同步，默认同步时间为 30s ⼀次。
   2. 第⼆层缓存是 `ResponseCacheImpl#readWriteCacheMap`，采⽤ Guava 来实现缓存，缓存过期时间默认为 180s，当服务下线、过期、注册、状态变更等操作，都会清除该缓存中的数据。
   3. 如果两级缓存都无法查询，则会触发 Guava 缓存的加载 `CacheLoader#load`，从存储层  `AbstractInstanceRegistry#registry`  拉取数据到二级缓存中，然后再返回给 Client。

###### 优点

两级缓存机制，提⾼了 Eureka Server 的响应速度，避免了同时读写 `registery` 内存造成的并发冲突问题。

###### 缺点

两级缓存机制，会导致数据⼀致性很薄弱，造成 Eureka Client 获取不到**最新**的服务实例信息（**AP 模型**），⽆法快速发现**新的服务和已下线的服务**。

1. 新服务上线后，服务消费者不能**立即访问**到刚上线的新服务，需要过⼀段时间后才能访问。
2. 或者服务下线后，服务还是会被调⽤到，⼀段时候后才彻底停⽌服务，访问前期会导致**频繁的报错**。

###### 解决方案

- **针对只读缓存**：
  1. 缩短更新时间 `eureka.server.responseCacheUpdateIntervalMs`，让服务发现变得更加及时。
  2. 或者直接关闭 `eureka.server.useReadOnlyResponseCache=false`。
- **针对读写缓存**：
  1. 缩短过期时间 `eureka.server.responseCacheAutoExpirationInSeconds`。
  2. 缩短服务剔除周期 `eureka.server.evictionIntervalTimerInMs`，让服务下线后，能够及时把其从注册表中清除。

###### 相关配置

| 配置                                               | 默认  | 说明                                                         |
| -------------------------------------------------- | ----- | ------------------------------------------------------------ |
| eureka.server.useReadOnlyResponseCache             | true  | true 代表 Eureka Client 会从 `readOnlyCacheMap` 更新数据，而 false 则代表跳过 `readOnlyCacheMap`，直接从`readWriteCacheMap` 中更新 |
| eureka.server.responseCacheUpdateIntervalMs        | 30000 | `readWriteCacheMap` 更新至`readOnlyCacheMap` 的时间周期      |
| eureka.server.responseCacheAutoExpirationInSeconds | 180   | `readWriteCacheMap` Guava 缓存的过期时间                     |
| eureka.server.evictionIntervalTimerInMs            | 60000 | 清理未续约节点的服务剔除周期                                 |

###### 源码分析 - registry

服务注册时添加，服务剔除时删除。

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
	// 服务实例ID instance-id="host：appnNme:port"
	// Eureka Server服务列表双重Map缓存=>{"appName"：{instance-id:InstanceInfo}}
    private final ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry = new ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>>();
            
	// 1、服务注册，注册具有给定持续时间的新实例
    public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {
        try {
            // 如果为第一次注册，则创建appName：空Map（服务实例的状态变化时，Server可能会收到多次，来自同一个实例的注册请求）
            Map<String, Lease<InstanceInfo>> gMap = registry.get(registrant.getAppName());
            REGISTER.increment(isReplication);
            if (gMap == null) {
                final ConcurrentHashMap<String, Lease<InstanceInfo>> gNewMap = new ConcurrentHashMap<String, Lease<InstanceInfo>>();
                gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap);
                if (gMap == null) {
                    gMap = gNewMap;
                }
            }
        }
    }
    
    // 2、服务剔除：剔除已过期的服务实例
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
        Map<String, Lease<InstanceInfo>> gMap = registry.get(appName);
        Lease<InstanceInfo> leaseToCancel = null;
        if (gMap != null) {
            leaseToCancel = gMap.remove(id);
        }
    }
}

```

###### 源码分析 - readWriteCacheMap

自动装配时构造，一级缓存找不到时加载，从 `registry` 或者 `recentlyChangedQueue` 中加载。

```java
...
// 1、自动装配时构造
public class EurekaServerAutoConfiguration extends WebMvcConfigurerAdapter {
    ....
	// Eureka服务端上下文——EurekaServerContext
	@Bean
	@ConditionalOnMissingBean
	public EurekaServerContext eurekaServerContext(ServerCodecs serverCodecs, PeerAwareInstanceRegistry registry, PeerEurekaNodes peerEurekaNodes) {
		return new DefaultEurekaServerContext(this.eurekaServerConfig, serverCodecs,
				registry, peerEurekaNodes, this.applicationInfoManager);
	}
    ...
}

@Singleton
public class DefaultEurekaServerContext implements EurekaServerContext {
    // 2、自动装配时构造
    @PostConstruct
    @Override
    public void initialize() {
        ...
        registry.init(peerEurekaNodes);
		...
    }
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    
    // 2、自动装配时构造
    @Override
    public void init(PeerEurekaNodes peerEurekaNodes) throws Exception {
		...
        initializedResponseCache();
        ...
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    // 3、自动装配时构造
    @Override
    public synchronized void initializedResponseCache() {
        if (responseCache == null) {
            responseCache = new ResponseCacheImpl(serverConfig, serverCodecs, this);
        }
    }
}

public class ResponseCacheImpl implements ResponseCache {
    ...
    // 读写缓存
    private final LoadingCache<Key, Value> readWriteCacheMap;
    
    // 4、自动装配时构造
    ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) {
        ...
        this.readWriteCacheMap = 
            CacheBuilder.newBuilder()
            .initialCapacity(serverConfig.getInitialCapacityOfResponseCache())
            .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS)
            .removalListener(new RemovalListener<Key, Value>() {...})
            .build(new CacheLoader<Key, Value>() {
                // 5、一级缓存找不到时加载
                @Override
                public Value load(Key key) throws Exception {
                    if (key.hasRegions()) {
                        Key cloneWithNoRegions = key.cloneWithoutRegions();
                        regionSpecificKeys.put(cloneWithNoRegions, key);
                    }
                    // 6、从registry/recentlyChangedQueue中加载
                    Value value = generatePayload(key);
                    return value;
                }
            });
        ...
    }
    
    private Value generatePayload(Key key) {
        ...
        if (ALL_APPS.equals(key.getName())) {
            ...
            // 7、全量拉取时，从registry中加载
            payload = getPayLoad(key, registry.getApplications());
        } else if (ALL_APPS_DELTA.equals(key.getName())) {
            ...
            // 8、全量拉取时，从recentlyChangedQueue中加载
            payload = getPayLoad(key, registry.getApplicationDeltas());
        } else {
            ...
        }
        ...
    }
}

```

###### 源码分析 - readOnlyCacheMap

自动装配时构造，定时同步读写缓存，服务发现时更新（有延迟）。

```java
public class ResponseCacheImpl implements ResponseCache {
    ...
    // 1、只读缓存，实例变量，自动装配时构造
    private final ConcurrentMap<Key, Value> readOnlyCacheMap = new ConcurrentHashMap<Key, Value>();
    
    ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) {
        ...
        if (shouldUseReadOnlyResponseCache) {
            // 2、定时同步读写缓存，默认延后30秒执行，执行周期为30s
            timer.schedule(getCacheUpdateTask(),
                    new Date(((System.currentTimeMillis() / responseCacheUpdateIntervalMs) * responseCacheUpdateIntervalMs)
                            + responseCacheUpdateIntervalMs),
                    responseCacheUpdateIntervalMs);
        }
        ...
    }
    
    private TimerTask getCacheUpdateTask() {
        return new TimerTask() {
            @Override
            public void run() {
                ...
                for (Key key : readOnlyCacheMap.keySet()) {
                    ...
                    try {
                        CurrentRequestVersion.set(key.getVersion());
                        Value cacheValue = readWriteCacheMap.get(key);
                        Value currentCacheValue = readOnlyCacheMap.get(key);
                        // 3、定时同步读写缓存
                        if (cacheValue != currentCacheValue) {
                            readOnlyCacheMap.put(key, cacheValue);
                        }
                    } catch (Throwable th) {
                        ...
                    }
                }
            }
        };
    }
    
    // 4、服务发现时更新（有延迟）：获取有关应用程序的压缩信息
    public byte[] getGZIP(Key key) {
        // 5、是否读取只读缓存，默认开启
        Value payload = getValue(key, shouldUseReadOnlyResponseCache);
        if (payload == null) {
            return null;
        }
        // 9、只返回gzip部分
        return payload.getGzipped();
    }
    
    @VisibleForTesting
    Value getValue(final Key key, boolean useReadOnlyCache) {
        Value payload = null;
        try {
            // 6、如果启动用了读取只读缓存，则先从只读缓存中获取（ConcurrentHashMap）
            if (useReadOnlyCache) {
                final Value currentPayload = readOnlyCacheMap.get(key);
                if (currentPayload != null) {
                    payload = currentPayload;
                } 
                // 7、如果只读缓存中获取不到，则还会从读写缓存中获取（com.google.common.cache.LoadingCache）
                else {
                    payload = readWriteCacheMap.get(key);
                    readOnlyCacheMap.put(key, payload);
                }
            }
            // 8、否则直接从读写缓存中获取（com.google.common.cache.LoadingCache）
            else {
                payload = readWriteCacheMap.get(key);
            }
        } catch (Throwable t) {
            ...
        }
        return payload;
    }
}

```

##### 本地内存缓存 | Eureka Client

###### 全量更新

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    
    // 本地服务列表内存缓存
    private final AtomicReference<Applications> localRegionApps = new AtomicReference<Applications>();
    
    // 1、全量更新
	private void getAndStoreFullRegistry() throws Throwable {
        ...// 2、服务列表全量拉取
        if (apps == null) {
            ...
        } 
        // 3、CAS更新服务列表版本
        else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            // 4、去除非UP服务列表，然后设置到本地内存缓存
            localRegionApps.set(this.filterAndShuffle(apps));
            ...
        } else {
            ...
        }
    }
}  

```

###### 增量更新

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    
    // 本地服务列表内存缓存
    private final AtomicReference<Applications> localRegionApps = new AtomicReference<Applications>();
    
    // 5、增量更新
    private void getAndUpdateDelta(Applications applications) throws Throwable {
        ...
        // 6、服务列表增量拉取
        if (delta == null) {
            ...
            // 7、如果结果为null，则还要重新发起全量拉取
            getAndStoreFullRegistry();
        } 
        // 8、CAS更新服务列表版本
        else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            ...
            if (fetchRegistryUpdateLock.tryLock()) {
                try {
                    // 9、去除非UP服务列表
                    updateDelta(delta);
                    reconcileHashCode = getReconcileHashCode(applications);
                } finally {
                    fetchRegistryUpdateLock.unlock();
                }
            } else {
                ...
            }
            // 10、服务列表的hashcode不同，则还要更新服务列表
            if (!reconcileHashCode.equals(delta.getAppsHashCode()) || clientConfig.shouldLogDeltaDiff()) {
                reconcileAndLogDifference(delta, reconcileHashCode);
            }
        } else {
            ...
        }
    }
    
    private void reconcileAndLogDifference(Applications delta, String reconcileHashCode) throws Throwable {
        // ... 11、服务列表的hashcode不同，则再全量拉取一次，用于更新服务列表
        // 12、CAS更新服务列表版本
        if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            // 13、设置到本地内存缓存
            localRegionApps.set(this.filterAndShuffle(serverApps));
            ..
        } else {
            ...
        }
    }
}

```

##### 服务调用缓存 | Ribbon

LoadBalancerClient 每选择一次不同的服务，则 RibbonClientConfiguration 就会构造一次，触发 updateAction#doUpdate 的服务调用缓存更新，详情见《服务调用原理 - 6、服务调用缓存实现》。

| 配置                                        | 默认 | 说明                                                       |
| ------------------------------------------- | ---- | ---------------------------------------------------------- |
| xxxService.ribbon.serverListRefreshInterval | 30s  | Ribbon 服务调用缓存，与 Eureka Client 服务列表缓存同步周期 |

```java
public class PollingServerListUpdater implements ServerListUpdater {
    @Override
    public synchronized void start(final UpdateAction updateAction) {
        if (isActive.compareAndSet(false, true)) {
            final Runnable wrapperRunnable = new Runnable() {
                @Override
                public void run() {
                    // 2、每次执行updateAction#doUpdate
                   	updateAction.doUpdate();
                }
            };
			
            // 1、延迟10s，默认周期为30s定时执行任务
            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(
                    wrapperRunnable,
                    initialDelayMs,
                    refreshIntervalMs,
                    TimeUnit.MILLISECONDS
            );
        } else {
            logger.info(...);
        }
    }
}

```

#### 服务调用原理 | Eureka Client

##### 1、Eureka 依赖 Ribbon 

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
</dependency>
<dependency>
    <groupId>com.netflix.ribbon</groupId>
    <artifactId>ribbon-eureka</artifactId>
</dependency>

```

##### 2、Spring SPI 配置

```properties
# .../spring-cloud-netflix-eureka-client/2.1.1.RELEASE/spring-cloud-netflix-eureka-client-2.1.1.RELEASE.jar!/META-INF/spring.factories
# Ribbon负载均衡自动配置类
org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\

```

##### 3、客户端负载均衡自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnRibbonAndEurekaEnabled
// 1、客户端负载均衡，自动装配
@AutoConfigureAfter(RibbonAutoConfiguration.class)
// Eureka客户端负载均衡预处理器，自动装配
@RibbonClients(defaultConfiguration = EurekaRibbonClientConfiguration.class)
public class RibbonEurekaAutoConfiguration {

}

@Configuration
@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)
@RibbonClients
// 3、在Eureka Client初始化之后，才注入当前类
@AutoConfigureAfter(name = "org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration")
// 4、loadbalancer自动装配
@AutoConfigureBefore({ 
    LoadBalancerAutoConfiguration.class,
	AsyncLoadBalancerAutoConfiguration.class 
 })
// 5、读取Ribbon配置
@EnableConfigurationProperties({ RibbonEagerLoadProperties.class,
		ServerIntrospectorProperties.class })
public class RibbonAutoConfiguration {
    ...  
	@Bean
	public SpringClientFactory springClientFactory() {
        // 6、配置负载均衡客户端的上下文工厂
		SpringClientFactory factory = new SpringClientFactory();
		factory.setConfigurations(this.configurations);
		return factory;
	}

	@Bean
	@ConditionalOnMissingBean(LoadBalancerClient.class)
	public LoadBalancerClient loadBalancerClient() {
        // 9、构造LoadBalancerClient实例RibbonLoadBalancerClient
		return new RibbonLoadBalancerClient(springClientFactory());
	}
    ...
}

// 创建客户端、负载均衡器和客户端配置实例的工厂，为每个客户端名称创建一个Spring ApplicationContext，并从那里提取需要的bean
public class SpringClientFactory extends NamedContextFactory<RibbonClientSpecification> {
    ...
    // 7、调用父类构造器，RibbonClientConfiguration在每个负载均衡客户端Bean实例构造时注入
	public SpringClientFactory() {
		super(RibbonClientConfiguration.class, NAMESPACE, "ribbon.client.name");
	}
    ...
}

// 创建一组子上下文，允许一组规范定义每个子上下文中的 bean，从spring-cloud-netflix FeignClientFactory和SpringClientFactory移植，实现DisposableBean，代表工厂用于构造一次性Bean
public abstract class NamedContextFactory<C extends NamedContextFactory.Specification>
implements DisposableBean, ApplicationContextAware {
	// 8、上下文工厂构造器，RibbonClientConfiguration在每个负载均衡客户端Bean实例构造时注入
	public NamedContextFactory(Class<?> defaultConfigType, String propertySourceName,
			String propertyName) {
		this.defaultConfigType = defaultConfigType;
		this.propertySourceName = propertySourceName;
		this.propertyName = propertyName;
	}
}

```

##### 4、Controller 注入 LoadBalancerClient

```java
// 1、Eureka Consumer测试前端控制类
@RestController
@Slf4j
public class ConsumerController {
    @Autowired
    private LoadBalancerClient loadBalancerClient;
    @Autowired
    private RestTemplate restTemplate;
    
    /**
     * 测试消费Post服务
     * @return
     */
    @PostMapping("/hello")
    public Friend helloPost(){
        // 2、使用loadBalancerClient，指定服务名，选择一个具体的服务实例
        ServiceInstance instance = loadBalancerClient.choose("eureka-client");
        if(instance == null){
            return null;
        }
        
        // 3、根据服务名拉取服务信息
        String targetUrl = String.format("http://%s:%s/sayHi", instance.getHost(), instance.getPort());
        log.info("url is {}", targetUrl);

        Friend friendParam = new Friend();
        friendParam.setName("Eureka Consumer");

        // 4、根据IP+端口发起远程调用
        return restTemplate.postForObject(targetUrl, friendParam, Friend.class);
    }
}

```

##### 5、LoadBalancerClient 服务实例选择原理

```java
public class RibbonLoadBalancerClient implements LoadBalancerClient {
    // 1、指定服务名，选择一个具体的服务实例，serviceId="eureka-client"
	@Override
	public ServiceInstance choose(String serviceId) {
		return choose(serviceId, null);
	}
    
	public ServiceInstance choose(String serviceId, Object hint) {
        // 3、根据服务名选择一个具体的服务实例
		Server server = getServer(
            // 2、根据服务名选择一个具体的负载均衡器
            getLoadBalancer(serviceId), hint
        );
		if (server == null) {
			return null;
		}
        // 4、构造RibbonServer返回
		return new RibbonServer(serviceId, server, isSecure(server, serviceId),
				serverIntrospector(serviceId).getMetadata(server));
	}
    
	protected ILoadBalancer getLoadBalancer(String serviceId) {
        // 2.1、使用SpringClientFactory负载均衡客户端的上下文工厂，构造一个负载均衡器Bean实例
		return this.clientFactory.getLoadBalancer(serviceId);
	}

    protected Server getServer(ILoadBalancer loadBalancer, Object hint) {
		if (loadBalancer == null) {
			return null;
		}
		// 3.1、选择默认的服务实例
		return loadBalancer.chooseServer(hint != null ? hint : "default");
	}
}

public class ZoneAwareLoadBalancer<T extends Server> extends DynamicServerListLoadBalancer<T> {
    @Override
    public Server chooseServer(Object key) {
     if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() <= 1) {
            logger.debug(...);
         	// 3.2、调用父类方法，选择默认的服务实例
            return super.chooseServer(key);
            ...
        }
    }
}

public class BaseLoadBalancer extends AbstractLoadBalancer implements
    PrimeConnections.PrimeConnectionListener, IClientConfigAware {
    public Server chooseServer(Object key) {
        ...
        // 3.3、以循环方式，从过滤列表中返回服务实例
        return rule.choose(key);
        ...
    }
    
    // 3.5、返回只可读的服务调用缓存（缓存实现见第6点）
    @Override
    public List<Server> getAllServers() {
        return Collections.unmodifiableList(allServerList);
    }
}

public abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule {
    @Override
    public Server choose(Object key) {
        ILoadBalancer lb = getLoadBalancer();
        // 3.6、根据服务名过滤服务列表
        Optional<Server> server = getPredicate().chooseRoundRobinAfterFiltering(
            //3.4、使用ZoneAwareLoadBalancer获取所有服务列表（服务调用缓存）
            lb.getAllServers(), key
        );
        if (server.isPresent()) {
            // 3.7、返回最后选择的服务实例
            return server.get();
        } else {
            return null;
        }       
    }
}

public class SpringClientFactory extends NamedContextFactory<RibbonClientSpecification> {
    
    // 2.2、构造一个负载均衡器ILoadBalancer Bean实例
	public ILoadBalancer getLoadBalancer(String name) {
		return getInstance(name, ILoadBalancer.class);
	}
    
	@Override
	public <C> C getInstance(String name, Class<C> type) {
        // 2.3、构造一个负载均衡器ILoadBalancer Bean实例并返回
		C instance = super.getInstance(name, type);
		if (instance != null) {
			return instance;
		}
		IClientConfig config = getInstance(name, IClientConfig.class);
		return instantiateWithConfig(getContext(name), type, config);
	}
}

public abstract class NamedContextFactory<C extends NamedContextFactory.Specification>
implements DisposableBean, ApplicationContextAware {

	public <T> T getInstance(String name, Class<T> type) {
		// 2.4、根据服务名获取对应的上下文配置
		AnnotationConfigApplicationContext context = getContext(name);
		if (BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context,
				type).length > 0) {
			// 2.7、Spring AbstractApplicationContext#getBean构造ILoadBalancer Bean实例ZoneAwareLoadBalancer
			return context.getBean(type);
		}
		return null;
	}
	
	protected AnnotationConfigApplicationContext getContext(String name) {
		if (!this.contexts.containsKey(name)) {
			synchronized (this.contexts) {
				if (!this.contexts.containsKey(name)) {
					// 2.5、第一次构造对应的上下文，然后服务名做key缓存起来
					this.contexts.put(name, createContext(name));
				}
			}
		}
		return this.contexts.get(name);
	}

	protected AnnotationConfigApplicationContext createContext(String name) {
		...
		// 2.6、底层调用Spring AbstractApplicationContext#refresh，触发RibbonClientConfiguration注入
		context.refresh();
		return context;
	}
}

```

##### 6、服务调用缓存实现

```java
// 1、RibbonClientConfiguration，每个服务名对应的服务均衡器构造时，都会重新refresh注入
@SuppressWarnings("deprecation")
@Configuration
@EnableConfigurationProperties
@Import({ HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,
		RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class })
public class RibbonClientConfiguration {
    ...
	@Bean
	@ConditionalOnMissingBean
	public ServerListUpdater ribbonServerListUpdater(IClientConfig config) {
        // 1、构造服务列表自动拉取的Updater
		return new PollingServerListUpdater(config);
	}
    
	@Bean
	@ConditionalOnMissingBean
	public ILoadBalancer ribbonLoadBalancer(IClientConfig config,
			ServerList<Server> serverList, ServerListFilter<Server> serverListFilter,
			IRule rule, IPing ping, ServerListUpdater serverListUpdater) {
		if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) {
			return this.propertiesFactory.get(ILoadBalancer.class, config, name);
		}
        // 2、根据Updater构造负载均衡器实例ZoneAwareLoadBalancer
		return new ZoneAwareLoadBalancer<>(config, rule, ping, serverList,
				serverListFilter, serverListUpdater);
	}
	...
}

public class PollingServerListUpdater implements ServerListUpdater {
    // 1.1、调用父类构造器，设置延迟10s，默认周期为30s定时执行任务的参数
    this(LISTOFSERVERS_CACHE_UPDATE_DELAY, getRefreshIntervalMs(clientConfig));
}

public class PollingServerListUpdater implements ServerListUpdater {
     // 1.2、设置延迟10s，默认周期为30s定时执行任务的参数
    public PollingServerListUpdater(final long initialDelayMs, final long refreshIntervalMs) {
        this.initialDelayMs = initialDelayMs;
        this.refreshIntervalMs = refreshIntervalMs;
    }
}

public class ZoneAwareLoadBalancer<T extends Server> extends DynamicServerListLoadBalancer<T> {
    public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList<T> serverList, ServerListFilter<T> filter, ServerListUpdater serverListUpdater) {
        // 2.1、调用父类构造器，启动调用服务缓存更新的定时任务
        super(clientConfig, rule, ping, serverList, filter, serverListUpdater);
    }
}

public class DynamicServerListLoadBalancer<T extends Server> extends BaseLoadBalancer {
     // DynamicServerListLoadBalancer构造器
     public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList<T> serverList, ServerListFilter<T> filter, ServerListUpdater serverListUpdater) {
        ...
        // 2.2、启动调用服务缓存更新的定时任务
        restOfInit(clientConfig);
    }
    
    void restOfInit(IClientConfig clientConfig) {
        ...
        // 2.3、启动调用服务缓存更新的定时任务
        enableAndInitLearnNewServersFeature();
        
		// 2.8. 第一次不等定时执行，立即执行一次updateAction#doUpdate，同步EurekaClient服务实例缓存，到调用缓存中
        updateListOfServers();
        ...
    }

    public void enableAndInitLearnNewServersFeature() {
        LOGGER.info(...);
        // 2.4、启动调用服务缓存更新的定时任务
        serverListUpdater.start(updateAction);
    }
    
    // 2.7、定时任务成员变量
    protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() {
        @Override
        public void doUpdate() {
            // 2.8. updateAction#doUpdate每次都同步EurekaClient服务实例缓存，到调用缓存中
            updateListOfServers();
        }
    };

    @VisibleForTesting
    public void updateListOfServers() {
        List<T> servers = new ArrayList<T>();
        if (serverListImpl != null) {
            // 2.9、拉取最新的EurekaClient服务实例缓存
            servers = serverListImpl.getUpdatedListOfServers();
            ...
        }
        // 2.14、更新服务调用缓存
        updateAllServerList(servers);
    }
    
    protected void updateAllServerList(List<T> ls) {
        if (serverListUpdateInProgress.compareAndSet(false, true)) {
            ...
            // 2.15、更新服务调用缓存
            setServersList(ls);
            ...
        }
    }
    
    @Override
    public void setServersList(List lsrv) {
        ...
        // 2.16、更新服务调用缓存
        super.setServersList(lsrv);
        ...
    }
}

public class BaseLoadBalancer extends AbstractLoadBalancer implements
    PrimeConnections.PrimeConnectionListener, IClientConfigAware {
    public void setServersList(List lsrv) {
        // 2.17、更新服务调用缓存
        ...
        allServerList = allServers;
        ...
    }
}

public class PollingServerListUpdater implements ServerListUpdater {
    @Override
    public synchronized void start(final UpdateAction updateAction) {
        if (isActive.compareAndSet(false, true)) {
            final Runnable wrapperRunnable = new Runnable() {
                @Override
                public void run() {
                    // 2.6、每次执行updateAction#doUpdate
                   	updateAction.doUpdate();
                }
            };
			
            // 2.5、延迟10s，默认周期为30s定时执行任务
            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(
                    wrapperRunnable,
                    initialDelayMs,
                    refreshIntervalMs,
                    TimeUnit.MILLISECONDS
            );
        } else {
            logger.info(...);
        }
    }
}

public class DomainExtractingServerList implements ServerList<DiscoveryEnabledServer> {
	@Override
	public List<DiscoveryEnabledServer> getUpdatedListOfServers() {
		List<DiscoveryEnabledServer> servers = setZones(
            	// 2.10、拉取最新的EurekaClient服务实例缓存
				this.list.getUpdatedListOfServers());
		return servers;
	}
}

public class DiscoveryEnabledNIWSServerList extends AbstractServerList<DiscoveryEnabledServer>{
    @Override
    public List<DiscoveryEnabledServer> getUpdatedListOfServers(){
        // 2.11、拉取最新的EurekaClient服务实例缓存
        return obtainServersViaDiscovery();
    }
    
    private List<DiscoveryEnabledServer> obtainServersViaDiscovery() {
        ...
        // 2.12、获取EurekaClient中的服务实例缓存
        List<InstanceInfo> listOfInstanceInfo = eurekaClient.getInstancesByVipAddress(vipAddress, isSecure, targetRegion);
        ...
    }
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    @Override
    public List<InstanceInfo> getInstancesByVipAddress(String vipAddress, boolean secure, @Nullable String region) {
        ...
        // 2.13、从原子变量中获取服务实例缓存
        applications = this.localRegionApps.get();
        ...
    }
}

```

#### 服务续约原理

##### 发起请求 | Eureka Client

###### 1、定时心跳检测 | 默认周期 30s

| 配置                                            | 默认 | 说明                                |
| ----------------------------------------------- | ---- | ----------------------------------- |
| eureka.instance.lease.renewalInterval           | 30s  | 服务实例续约周期                    |
| eureka.client.heartbeat.exponentialBackOffBound | 10倍 | 10 * 30，表示最大的服务续约周期乘数 |

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、非默认参数，启动续租超时时间5s，最大超时50s，延迟5s执行，交由heartbeatExecutor线程池处理的，在给定的时间间隔内，更新租约的心跳任务（心跳检测）
    private class HeartbeatThread implements Runnable {
        public void run() {
            if (renew()) {
                // 2、续约成功，则更新最后续约成功时间
                lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis();
            }
        }
    }
}

```

###### 2、发送续约心跳包

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    boolean renew() {
        EurekaHttpResponse<InstanceInfo> httpResponse;
        try {
            // 1、发送续约心跳包
            httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null);
            logger.debug(...);
            // 2、如果响应结果为 NOT_FOUND(404, "Not Found")
            if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) {
                REREGISTER_COUNTER.increment();
                logger.info(...);
                // 3、则设置isInstanceInfoDirty=true，刷新最后脏时间戳，并重新发起服务注册
                long timestamp = instanceInfo.setIsDirtyWithTime();
                boolean success = register();
                if (success) {
                    // 4、如果重新注册成功，则清除isInstanceInfoDirty（设置为false）
                    instanceInfo.unsetIsDirty(timestamp);
                }
                // 5、重新注册成功则返回true，否则返回false
                return success;
            }
            // 6、如果响应结果为 OK(200, "OK")，则直接返回 true
            return httpResponse.getStatusCode() == Status.OK.getStatusCode();
        } catch (Throwable e) {
            logger.error(...);
            // 7、处理异常，则也返回 false
            return false;
        }
    }  
}

```

###### 3、最后调用 AbstractJerseyEurekaHttpClient#sendHeartBeat

```java
public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 最后实际调用AbstractJerseyEurekaHttpClient#getDelta方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<InstanceInfo> sendHeartBeat(String appName, String id, InstanceInfo info, InstanceStatus overriddenStatus) {
        String urlPath = "apps/" + appName + '/' + id;
        ClientResponse response = null;
        try {
            // 1、serviceurl=http://localhost:20000/eureka/
            WebResource webResource = jerseyClient.resource(serviceUrl)
                	// 2、urlPath=apps/service-name/host:service-name:ip
                    .path(urlPath)
                	// 3、status=UP
                    .queryParam("status", info.getStatus().toString())
                	// 4、lastDirtyTimestamp=1638885398794
                    .queryParam("lastDirtyTimestamp", info.getLastDirtyTimestamp().toString());
            ...
            // 5、真正发起心跳包到Eureka Server
            response = requestBuilder.put(ClientResponse.class);
            ...
        } finally {
            ...
        }
    }
}

```

##### 响应请求 | Eureka Server

###### 1、续约心跳包接收接口

| 配置                                   | 默认 | 说明                             |
| -------------------------------------- | ---- | -------------------------------- |
| eureka.server.syncWhenTimestampDiffers | true | 检查是否在脏时间戳不同时同步实例 |

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    @PUT
    public Response renewLease(
            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication,
            @QueryParam("overriddenstatus") String overriddenStatus,
            @QueryParam("status") String status,
        @QueryParam("lastDirtyTimestamp") String lastDirtyTimestamp) {
        // 1、执行服务续约
        boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode);
        
        // 2、续约失败，返回404，代表客户端服务找不到，让客户端重新发起注册
        if (!isSuccess) {
            logger.warn("Not Found (Renew): {} - {}", app.getName(), id);
            return Response.status(Status.NOT_FOUND).build();
        }
        
        // 3、对比Eureka Server中的租约，检查是否需要根据脏时间戳进行同步，以及客户端实例是否可能已经更改了某些值
        Response response;
        if (lastDirtyTimestamp != null && serverConfig.shouldSyncWhenTimestampDiffers()) {
            // 4、租约验脏，如果需要在脏时间戳不同时，重新同步实例，则校验客户端传过来的脏时间戳
            response = this.validateDirtyTimestamp(Long.valueOf(lastDirtyTimestamp), isFromReplicaNode);
            // 5、如果是副本间同步，且租约状态发生变化，则覆盖租约实例
            if (response.getStatus() == Response.Status.NOT_FOUND.getStatusCode()
                    && (overriddenStatus != null)
                    && !(InstanceStatus.UNKNOWN.name().equals(overriddenStatus))
                    && isFromReplicaNode) {
                registry.storeOverriddenStatusIfRequired(app.getAppName(), id, InstanceStatus.valueOf(overriddenStatus));
            }
        } 
        // 6、如果无需重新同步，则直接返回ok
        else {
            response = Response.ok().build();
        }
        logger.debug(...);
        return response;
    }
}

```

###### 2、执行服务续约

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public boolean renew(final String appName, final String serverId,
			boolean isReplication) {
		log(...);
		// 1、获取Eureka Server缓存中的所有租约
		List<Application> applications = getSortedApplications();
		// 2、根据服务名获取对应的租约
		for (Application input : applications) {
			if (input.getName().equals(appName)) {
				InstanceInfo instance = null;
				for (InstanceInfo info : input.getInstances()) {
					if (info.getId().equals(serverId)) {
						instance = info;
						break;
					}
				}
				publishEvent(new EurekaInstanceRenewedEvent(this, appName, serverId,
						instance, isReplication));
				break;
			}
		}
		// 3、调用父类进行续租
		return super.renew(appName, serverId, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    public boolean renew(final String appName, final String id, final boolean isReplication) {
    	// 4、再调用父类进行续租
        if (super.renew(appName, id, isReplication)) {
        	// 7、如果续约成功，则还要将所有eureka操作复制到对等的其他eureka节点
            replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);
            return true;
        }
        return false;
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    public boolean renew(String appName, String id, boolean isReplication) {
    	...
    	// 5、租期续约
		leaseToRenew.renew();
		return true;
    }
}

public class Lease<T> {
    public void renew() {
    	// 6、租期续约，当前时间+客户端设置的租约过期时间（eureka.instance.lease-expiration-duration-in-seconds）
        lastUpdateTimestamp = System.currentTimeMillis() + duration;
    }
}

```

###### 3、租约验脏

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    private Response validateDirtyTimestamp(Long lastDirtyTimestamp,
                                            boolean isReplication) {
        // 1、获取Eureka Server缓存的服务租约
        InstanceInfo appInfo = registry.getInstanceByAppAndId(app.getName(), id, false);
        if (appInfo != null) {
            // 2、如果脏时间戳不一致
            if ((lastDirtyTimestamp != null) && (!lastDirtyTimestamp.equals(appInfo.getLastDirtyTimestamp()))) {
                Object[] args = {id, appInfo.getLastDirtyTimestamp(), lastDirtyTimestamp, isReplication};
				// 3、如果传过来的脏时间戳大，则认为Eureka Server中的租约落后，需要重新注册服务，则返回404给客户端，让其重新注册
                if (lastDirtyTimestamp > appInfo.getLastDirtyTimestamp()) {
                    logger.debug(...);
                    return Response.status(Status.NOT_FOUND).build();
                } 
                else if (appInfo.getLastDirtyTimestamp() > lastDirtyTimestamp) {
                    // 4、如果传过来的脏时间落后，且是副本间同步的话，则将注册表中的当前实例信息，发送给复制节点以与该节点同步
                    if (isReplication) {
                        logger.debug(...);
                        return Response.status(Status.CONFLICT).entity(appInfo).build();
                    } 
                    // 5、否则，返回ok，代表租约正常
                    else {
                        return Response.ok().build();
                    }
                }
            }
        }
        return Response.ok().build();
    } 
}

```

#### 服务剔除原理 | Eureka Server

##### 1、初始化 Eureka Server 上下文

| 配置                                    | 默认  | 说明                   |
| --------------------------------------- | ----- | ---------------------- |
| eureka.server.evictionIntervalTimerInMs | 60000 | 服务剔除任务的执行周期 |

```java
public class EurekaServerBootstrap {
	public void contextInitialized(ServletContext context) {
        ...
        // 1、注册中心启动时，初始化Eureka上下文，详情见《注册中心启动原理》
        initEurekaServerContext();
        ...
	}
    
    protected void initEurekaServerContext() throws Exception {
        ...
        // 2、初始化启动变量，以及启动服务剔除定时任务
		this.registry.openForTraffic(this.applicationInfoManager, registryCount);
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
		// 3. 初始化启动变量，以及启动服务剔除定时任务
		super.openForTraffic(applicationInfoManager,
				count == 0 ? this.defaultOpenForTrafficCount : count);
	}
}

public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
    	...
    	// 4.设置完毕，上下文后置初始化处理
    	super.postInit();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void postInit() {
   		// 5. 设置服务剔除任务
        evictionTaskRef.set(new EvictionTask());
        // 6. 默认延迟60s后开始执行任务，且每60s执行一次
        evictionTimer.schedule(evictionTaskRef.get(),
                serverConfig.getEvictionIntervalTimerInMs(),
                serverConfig.getEvictionIntervalTimerInMs());
    }
}

```

##### 2、执行服务剔除

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    
    class EvictionTask extends TimerTask {
        private final AtomicLong lastExecutionNanosRef = new AtomicLong(0l);

        @Override
        public void run() {
            try {
                // 1、计算补偿时间，定义为自上次迭代以来执行此任务的实际时间，与配置的执行时间量。 这对于时间变化（例如由于时钟偏差或 gc）导致实际驱逐任务执行晚于根据配置的周期所需的时间的情况很有用
                long compensationTimeMs = getCompensationTimeMs();
                logger.info(...);
                // 2、执行服务剔除
                evict(compensationTimeMs);
            } catch (Throwable e) {
                logger.error(...);
            }
        }
    }
    
    // additionalLeaseMs补偿时间，默认为0
    public void evict(long additionalLeaseMs) {
        logger.debug("Running the evict task");
        
        // 3、如果自我保护已经打开了（动态变化），则不进行服务剔除，直接返回
        if (!isLeaseExpirationEnabled()) {
            logger.debug("");
            return;
        }
        ...
        // 4、先收集所有过期的租约，判断租期是否已经过期，如果已经过期则加入过期列表
        if (lease.isExpired(additionalLeaseMs) && lease.getHolder() != null) {
            expiredLeases.add(lease);
        }
        ...
        // 6、然后随机顺序驱逐它们，对于大型驱逐集，如果我们不这样做，我们可能会在自我保护开始之前清除整个应用程序，而通过随机化它们，剔除后租约应该可以均匀分布在各个应用程序中
        int next = i + random.nextInt(expiredLeases.size() - i);
        Collections.swap(expiredLeases, i, next);
        Lease<InstanceInfo> lease = expiredLeases.get(i);
        String appName = lease.getHolder().getAppName();
        String id = lease.getHolder().getId();
        EXPIRED.increment();
        logger.warn("DS: Registry: expired lease for {}/{}", appName, id);
        // 7、取消服务租约
        internalCancel(appName, id, false);
    }
}

public class Lease<T> {
    public boolean isExpired(long additionalLeaseMs) {
        // 5、如果该租约经过过期了，或者最后心跳时间+最长续约时间+时间补偿，还大于了当前时间，则也认为该租约过期了
        return (evictionTimestamp > 0 || System.currentTimeMillis() > (lastUpdateTimestamp + duration + additionalLeaseMs));
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	protected boolean internalCancel(String appName, String id, boolean isReplication) 
		// 8、记录日志、发布租约取消事件
		handleCancelation(appName, id, isReplication);
		// 9、调用父类，取消服务租约
		return super.internalCancel(appName, id, isReplication);
	}
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
    	...
    	// 10、删除对应的服务列表
		leaseToCancel = gMap.remove(id);
		// 11、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已从服务列表删除，所以只读缓存也会清空该服务列表，不过有一定的延迟（默认30s同步一次）
		invalidateCache(appName, vip, svip);
		...
    }
}

```

#### 服务自保原理 | Eureka Server

##### 1、服务剔除

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    // 1、只有服务剔除才会触发服务自保，服务下线并不会有这判断
    public void evict(long additionalLeaseMs) {
       	...
        
        // 2、如果自我保护已经打开了（动态变化），则不进行服务剔除，直接返回
        if (!isLeaseExpirationEnabled()) {
            logger.debug("");
            return;
        }
        ...
    }
}

```

##### 2、服务自保判断

| 配置                                  | 默认 | 说明                         |
| ------------------------------------- | ---- | ---------------------------- |
| eureka.server.enableSelfPreservation  | true | 是否开启自我保护             |
| eureka.instance.lease.renewalInterval | 30s  | 服务实例续约周期             |
| eureka.server.renewalPercentThreshold | 0.85 | 服务实例续约到服务自保的阈值 |

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean isLeaseExpirationEnabled() {
        // 1、读取开关配置
        if (!isSelfPreservationModeEnabled()) {
            // 3、服务自保开关已被关闭，所以返回true，代表允许服务剔除，而不再判断自保条件
            return true;
        }
        // 4、如果服务自保开关已开启，则还需要判断自保条件，实例数量大于0，且上一分钟最少续约数 > 每分钟最少收到租约阈值（=实例数 * （60/续租周期）* 0.85）
        return numberOfRenewsPerMinThreshold > 0 && getNumOfRenewsInLastMin() > numberOfRenewsPerMinThreshold;
    }
    
    @Override
    public boolean isSelfPreservationModeEnabled() {
        // 2、eureka.server.enableSelfPreservation，默认为true，代表开启服务自保
        return serverConfig.shouldEnableSelfPreservation();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void updateRenewsPerMinThreshold() {
        // 4.1. 每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
        this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfClientsSendingRenews
                * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds())
                * serverConfig.getRenewalPercentThreshold());
    }
}

```

#### 服务下线原理

##### 发起请求 | Eureka Client

###### 1、Eureka Client 自动装配

```java
public class EurekaClientAutoConfiguration {
    ...
    @Configuration
	@ConditionalOnMissingRefreshScope
    protected static class EurekaClientConfiguration {
        ...
        // 1、注入EurekaClient核心类，且在销毁时调用EurekaClient#shutdown，进行服务下线
		@Bean(destroyMethod = "shutdown")
		@ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT)
		public EurekaClient eurekaClient(ApplicationInfoManager manager,
				EurekaClientConfig config) {
			return new CloudEurekaClient(manager, config, this.optionalArgs,
					this.context);
		}
    }
    ...
}

```

###### 2、服务手动下线

```java
@SpringBootApplication
@EnableDiscoveryClient
public class EurekaClientApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaClientApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
        LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(61));
        // 1、服务手动下线
        DiscoveryManager.getInstance().shutdownComponent();
    }
}

@Deprecated
public class DiscoveryManager {
    public void shutdownComponent() {
        if (discoveryClient != null) {
            try {
                // 2、服务手动下线
                discoveryClient.shutdown();
                discoveryClient = null;
            } catch (Throwable th) {
                logger.error("Error in shutting down client", th);
            }
        }
    }
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    @PreDestroy
    @Override
    public synchronized void shutdown() {
        if (isShutdown.compareAndSet(false, true)) {
            logger.info("Shutting down DiscoveryClient ...");

            // 3、取消监听服务状态变更事件
            if (statusChangeListener != null && applicationInfoManager != null) {
applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId());
            }

            // 4、销毁instanceInfoReplicator（本地刷新）、heartbeatExecutor（服务续约）、cacheRefreshExecutor（服务发现）、scheduler（DiscoveryClient定时器）
            cancelScheduledTasks();

            if (applicationInfoManager != null
                    && clientConfig.shouldRegisterWithEureka()
                    && clientConfig.shouldUnregisterOnShutdown()) {
                // 5、标记服务状态为DOWN
                applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN);
                
                // 6、发起取消注册请求
                unregister();
            }

            // 7、销毁各种Client
            if (eurekaTransport != null) {
                eurekaTransport.shutdown();
            }

            // 8、销毁心跳失效、服务租约失效监视器
            heartbeatStalenessMonitor.shutdown();
            registryStalenessMonitor.shutdown();

            logger.info("Completed shut down of DiscoveryClient");
        }
    }
}

```

###### 3、发起取消注册请求

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    void unregister() {
        ...
        // 1、发起取消注册请求
        EurekaHttpResponse<Void> httpResponse = eurekaTransport.registrationClient.cancel(instanceInfo.getAppName(), instanceInfo.getId());
        ...
    }
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
// 2、最后实际调用AbstractJerseyEurekaHttpClient#cancel方法，中间经历的代理跟注册的类似：
// 1) 多态调用SessionedEurekaHttpClient#execute
// 2) 多态调用RetryableEurekaHttpClient#execute
// 3) 多态调用RedirectingEurekaHttpClient#execute
// 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Void> cancel(String appName, String id) {
        // 3、urlPath=apps/service-name/host:service-name:port
        String urlPath = "apps/" + appName + '/' + id;
        ...
        try {
            ...
            // 4、真正发起取消注册的请求
            response = resourceBuilder.delete(ClientResponse.class);
            ...
        } finally {
            ...
        }
    }
}

```

##### 响应请求 | Eureka Server

###### 1、取消注册接口

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    @DELETE
    public Response cancelLease(
            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        try {
            // 1、取消服务注册
            boolean isSuccess = registry.cancel(app.getName(), id,
                "true".equals(isReplication));

            // 2、取消成功，则返回200，客户端打印状态
            if (isSuccess) {
                logger.debug("Found (Cancel): {} - {}", app.getName(), id);
                return Response.ok().build();
            } 
            // 3、取消失败，则返回404，客户端打印状态
            else {
                logger.info("Not Found (Cancel): {} - {}", app.getName(), id);
                return Response.status(Status.NOT_FOUND).build();
            }
        } 
        // 4、发生异常，则返回500，客户端打印状态
        catch (Throwable e) {
            logger.error("Error (cancel): {} - {}", app.getName(), id, e);
            return Response.serverError().build();
        }
    }
}

```

###### 2、取消服务注册

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public boolean cancel(String appName, String serverId, boolean isReplication) {
		// 1、打印日志、发布服务实例取消事件
		handleCancelation(appName, serverId, isReplication);
		// 2、调用父类方法，取消服务注册
		return super.cancel(appName, serverId, isReplication);
	}

	@Override
	protected boolean internalCancel(String appName, String id, boolean isReplication) {
		// 5、打印日志，发布服务租约取消事件
		handleCancelation(appName, id, isReplication);
		// 6、调用父类方法，取消服务租约（与服务剔除调用的是同一个方法）
		return super.internalCancel(appName, id, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean cancel(final String appName, final String id,
                          final boolean isReplication) {
        // 3、调用父类方法，取消服务注册
        if (super.cancel(appName, id, isReplication)) {
        	// 9、租约取消成功，则将所有eureka操作，复制到对等的其他eureka节点
            replicateToPeers(Action.Cancel, appName, id, null, null, isReplication);
            // 10、减少每分钟最少续租的阈值
            synchronized (lock) {
                if (this.expectedNumberOfClientsSendingRenews > 0) {
                    this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews - 1;
                    updateRenewsPerMinThreshold();
                }
            }
            // 11、返回true，代表取消注册成功
            return true;
        }
        // 12、返回false，代表取消注册失败
        return false;
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    @Override
    public boolean cancel(String appName, String id, boolean isReplication) {
    	// 4、调用子类实现，取消服务租约
        return internalCancel(appName, id, isReplication);
    }
    
    // 取消服务租约，与服务剔除调用的是同一个方法
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
    	...
    	// 7、删除对应的服务列表
		leaseToCancel = gMap.remove(id);
		// 8、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已从服务列表删除，所以只读缓存也会清空该服务列表，不过有一定的延迟（默认30s同步一次）
		invalidateCache(appName, vip, svip);
		...
    }
}

```

#### 集群同步原理 | Eureka Server

##### 1、服务注册后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void register(final InstanceInfo info, final boolean isReplication) {
        ...
        // 1、服务注册完毕
        super.register(info, leaseDuration, isReplication);
        // 2、集群服务实例同步
        replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);
    }
}

```

##### 2、服务续约后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    public boolean renew(final String appName, final String id, final boolean isReplication) {
        // 1、服务续约
        if (super.renew(appName, id, isReplication)) {
            // 2、如果服务续约成功，则进行集群服务实例同步
            replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);
            return true;
        }
        return false;
    }
}

```

##### 3、服务取消后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean cancel(final String appName, final String id,
                          final boolean isReplication) {
        // 1、取消服务注册
        if (super.cancel(appName, id, isReplication)) {
            // 2、如果取消成功，则进行集群服务实例同步
            replicateToPeers(Action.Cancel, appName, id, null, null, isReplication);
            ...
            return true;
        }
        return false;
    }
}

```

##### 4、集群同步请求处理 & 发送

```java
// 1、将所有当前Eureka操作，复制到对等的其他Eureka节点
private void replicateToPeers(Action action, String appName, String id,
                              InstanceInfo info /* optional */,
                              InstanceStatus newStatus /* optional */, boolean isReplication) {
    Stopwatch tracer = action.getTimer().start();
    try {
        // 2、期望副本数量加1
        if (isReplication) {
            numberOfReplicationsLastMin.increment();
        }
        // 3、如果该请求已经是一个集群同步请求，则直接返回即可，代表不再发起集群同步请求
        if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) {
            return;
        }
        // 4、否则需要发起集群同步请求
        for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) {
            // 5、如果url代表此主机，则直接跳过，不能发送同步请求到当前副本自己
            if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) {
                continue;
            }
            // 6、将所有实例的更改操作，复制到对等的其他Eureka节点
            replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);
        }
    } finally {
        tracer.stop();
    }
}

// 将所有实例的更改操作，复制到对等的其他Eureka节点
private void replicateInstanceActionsToPeers(Action action, String appName,
String id, InstanceInfo info, InstanceStatus newStatus,PeerEurekaNode node) {
    try {
        InstanceInfo infoFromRegistry = null;
        CurrentRequestVersion.set(Version.V2);
        switch (action) {
            case Cancel:
                // 7、如果为服务取消后同步，则调用最终调用AbstractJerseyEurekaHttpClient#cancel发送取消注册请求（同步客户端请求类似，但isReplication=true）
                node.cancel(appName, id);
                break;
            case Heartbeat:
                 // 8、如果为服务续约后同步，则调用最终调用AbstractJerseyEurekaHttpClient#sendHeartBeat发送服务续约请求（同步客户端请求类似，但isReplication=true）
                InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id);
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false);
                break;
            case Register:
                // 9、如果为服务注册后同步，则调用最终调用AbstractJerseyEurekaHttpClient#register发送服务注册请求（同步客户端请求类似，但isReplication=true）
                node.register(info);
                break;
            case StatusUpdate:
                // 10、手工接口调用操作，略
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.statusUpdate(appName, id, newStatus, infoFromRegistry);
                break;
            case DeleteStatusOverride:
                // 11、手工接口调用操作，略
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.deleteStatusOverride(appName, id, infoFromRegistry);
                break;
        }
    } catch (Throwable t) {
        logger.error(...);
    }
}

```

### 1.8. 详细介绍 Ribbon？

#### 背景

![1639058178382](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639058178382.png)

1. **负载均衡**，在系统架构中是非常重要的一个不得不做的事情，因为这是系统高可用、网络压力缓解和处理能力扩容的重要手段之一，比如有了负载均衡后，系统最大容量就可以近似于**单机容量 * 集群机器数**了。

2. 负载均衡，按**实现手段**分，可以分为硬件负载均衡和软件负载均衡：

   - **硬件负载均衡**：通过在服务器节点间，安装专门的设备来实现负载均衡。
   - **软件负载均衡**：只需要安装一些模块或者软件，即可完成请求分发等负载均衡工作，

3. 负载均衡，按**实现位置**分，可以分为客户端负载均衡和服务端负载均衡：但大型应用通常是客户端+服务端负载均衡搭配使用的。

   - **客户端负载均衡**：所有客户端节点，都维护着自己要访问的服务列表清单（来自注册中心），并且通过定时或者订阅等方式，维护服务列表清单的健康性。

     ![1639192959329](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639192959329.png)

   - **服务端负载均衡**：需要一个中间节点来实现请求的转发，比如 Nginx，此时需要考虑该节点的高可用。

     ![1639193020487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639193020487.png)

| 负载均衡 | 原理                                                         |
| -------- | ------------------------------------------------------------ |
| Ribbon   | 客户端负载均衡，从注册中心定时读取服务列表，根据策略挑选出目标服务器进行访问 |
| Dubbo    | 客户端负载均衡，拉取 + 订阅 ZK 上的服务列表，根据策略挑选出目标服务器进行访问 |
| Nginx    | 反向代理实现，通过拦截客户端请求，根据策略和 upstream 配置进行转发 |

#### 概念

Ribbon，前身 Netflix Ribbon，通过封装后，成为 Spring Cloud 中一个基于 HTTP 实现的客户端均衡组件，主要功能是提供**客户端的负载均衡算法**，简单来说，就是 Ribbon 基于某种规则（如简单轮询，随即连接等），自动让服务去连接这些机器。

| Ribbon 组件接口   | 默认实现                       | 作用                                                         |
| ----------------- | ------------------------------ | ------------------------------------------------------------ |
| ILoadBalancer     | ZoneAwareLoadBalancer          | 负载均衡器，定义了一系列的操作接口，比如选择服务实例         |
| IRule             | ZoneAvoidanceRule              | 负载均衡策略，内置了很多算法，用于为服务实例的选择提供策略   |
| ServerList        | ConfigurationBasedServerList   | Ribbon 服务列表，负责服务实例的获取和存储，可以从配置文件中读取，也可以从注册中心获取 |
| ServerListFilter  | ZonePreferenceServerListFilter | Ribbon 服务列表过滤器，过滤指定的或者动态获得的服务实例      |
| ServerListUpdater | PollingServerListUpdater       | Ribbon 服务列表更新器，负责更新 Ribbon 缓存的服务实例        |
| IPing             | DummyPing                      | 服务实例检查器，负责检查服务实例是否存活                     |
| IClientConfig     | DefaultClientConfigImpl        | Ribbon 客户端配置类，用于初始化 Ribbon 客户端和 LoadBalancer |

#### 架构原理

![1639281718549](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639281718549.png)



1. Ribbon 本质上使用 BaseLoadBalancer 存储 ServerList，IPing 机制进行服务实例的健康检查，ServrListFilter 进行服务实例过滤，ServrListUpdater 进行服务列表的更新。
2. 在客户端使用 ILoadBalancer 发起服务调用时，会根据 IRule 负载均衡策略，到 BaseLoadBalancer#ServerList 进行服务实例的筛选， 然后才发起对应的服务调用，从而实现负载均衡。

#### 使用方式

##### POM 依赖

```xml
<!-- spring-cloud-starter-netflix-eureka-client默认自带Ribbon依赖 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
</dependency>

```

##### 负载均衡调用方式

###### 直接使用 LoadBalancerClient

```java
@RestController
@Slf4j
public class ConsumerController {
    @Autowired
    private LoadBalancerClient loadBalancerClient;
    
    @PostMapping("/hello")
    public Friend helloPost(){
        // 1、使用LoadBalancerClient，根据服务名获取服务实例信息
        ServiceInstance instance = loadBalancerClient.choose("eureka-client");
        if(instance == null){
            return null;
        }

        // 2、获取服务地址进行参数组装
        String targetUrl = String.format("http://%s:%s/sayHi", instance.getHost(), instance.getPort());
        log.info("url is {}", targetUrl);

        Friend friendParam = new Friend();
        friendParam.setName("Eureka Consumer");

        // 3、最后使用原生RestTemplate进行服务调用
        return restTemplate.postForObject(targetUrl, friendParam, Friend.class);
    }
}

```

###### RestTemplate + @LoadBalanced

```java
// 1、RestTemplate配置类
@Configuration
public class RestTemplateConfig {
	// 2、配置@LoadBalanced注解
    @Bean("restTemplate")
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}

@RestController
public class RibbonConsumerController {
    // 3、注入配置好的RestTemplate
    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/sayHi")
    public String sayHi() {
        // 4、使用配置了@LoadBalanced注解的RestTemplate，直接发起服务调用，Ribbon底层会choose对应的服务实例进行调用
        return restTemplate.getForObject("http://eureka-client/sayHi", String.class);
    }
}

```

###### Feign + Ribbon

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启Feign
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

// 2、配置Feign要调用的服务
@FeignClient("eureka-client")
public interface IService {
	// 3、远程调用eureka-client服务提供者的方法
    @GetMapping("/sayHi")
    String sayHi();
}

@RestController
public class FeignConsumerController {
    // 4、注入对应的Fegin动态代理类
    @Resource
    private IService iService;

    @GetMapping("/sayHi")
    public String sayHi(){
        // 5、发起Feign代理请求，默认集成Ribbon来实现负载均衡
        return iService.sayHi();
    }
}

```

##### 负载均衡策略配置

###### 配置文件配置

```properties
# 配置文件配置，指定Ribbon某个服务的负载均衡策略(先加载, 优先级低)(=> xml->yml->yaml>properties)
eureka-client.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RoundRobinRule

```

###### Java Bean 注入

```java
// Ribbon配置类
@Configuration
public class RibbonConfiguration {
    // 1、指定Ribbon全局的负载均衡策略
    @Bean("defaultLBStrategy")
    public IRule defaultLBStrategy(){
        // 2. RandomRule: 随机访问服务结点
        return new RandomRule();
    }
}

```

###### @RibbonClient 注解配置

```java
@Configuration
// 注解方式配置，指定Ribbon某个服务的负载均衡策略(后加载, 优先级高)
@RibbonClient(name = "eureka-client", configuration = RandomRule.class)
public class RibbonConfiguration {

}

```

#### 负载均衡调用原理

##### LoadBalancerClient 原理

见《详细介绍 Eureka - 服务调用原理》

##### RestTemplate + @LoadBalanced 原理

###### 1、@LoadBalanced 注解打标

```java
@Target({ ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD })
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
// 0、@LoadBalanced继承于@Qualifier
@Qualifier
public @interface LoadBalanced {

}

// 1、（非源码）RestTemplate配置类
@Configuration
public class RestTemplateConfig {
	// 2、配置@LoadBalanced注解，表示打标一个Bean，并且打标的Bean名称等于@Bean配置的restTemplate
    @Bean("restTemplate")
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}

```

###### 2、Spring SPI 配置

```properties
# ./spring-cloud-commons/2.1.1.RELEASE/spring-cloud-commons-2.1.1.RELEASE.jar!/META-INF/spring.factories
# AutoConfiguration
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
# ...
org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration,\
# ...

```

###### 3、LoadBalancer  自动装配

```java
@Configuration
@ConditionalOnClass(RestTemplate.class)
@ConditionalOnBean(LoadBalancerClient.class)
@EnableConfigurationProperties(LoadBalancerRetryProperties.class)
public class LoadBalancerAutoConfiguration {
    
	@Configuration
	@ConditionalOnMissingClass("org.springframework.retry.support.RetryTemplate")
    static class LoadBalancerInterceptorConfig {
        // 1、注入LoadBalancerInterceptor，依赖之前RibbonAutoConfiguration注入的LoadBalancerClient和LoadBalancerRequestFactory
		@Bean
		public LoadBalancerInterceptor ribbonInterceptor(
				LoadBalancerClient loadBalancerClient,
				LoadBalancerRequestFactory requestFactory) {
			return new LoadBalancerInterceptor(loadBalancerClient, requestFactory);
		}
        
        // 2、注入RestTemplateCustomizer，依赖上面注入的LoadBalancerInterceptor
		@Bean
		@ConditionalOnMissingBean
		public RestTemplateCustomizer restTemplateCustomizer(
				final LoadBalancerInterceptor loadBalancerInterceptor) {
			return restTemplate -> {
				List<ClientHttpRequestInterceptor> list = new ArrayList<>(
						restTemplate.getInterceptors());
				list.add(loadBalancerInterceptor);
				restTemplate.setInterceptors(list);
			};
		}
    }
    
    // 3、注入List<RestTemplate>，依赖上面@LoadBalanced注解打标的RestTemplate
	@LoadBalanced
	@Autowired(required = false)
	private List<RestTemplate> restTemplates = Collections.emptyList();
    
	@Bean
	public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated(
			final ObjectProvider<List<RestTemplateCustomizer>> restTemplateCustomizers) {
		return () -> restTemplateCustomizers.ifAvailable(customizers -> {
			for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) {
				for (RestTemplateCustomizer customizer : customizers) {
                    // 4、使用上面注入的LoadBalancerInterceptor，装饰RestTemplate
					customizer.customize(restTemplate);
				}
			}
		});
	}
    ...
}

```

###### 4、RestTemplate 发起服务调用

```java
@RestController
public class RibbonConsumerController {
    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/sayHi")
    public String sayHi() {
        // 1、（非源码）使用被LoadBalancerInterceptor装饰过的RestTemplate，发起服务调用
        return restTemplate.getForObject("http://eureka-client/sayHi", String.class);
    }
}

```

###### 5、LoadBalancerInterceptor 拦截调用请求

```java
public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor {
	@Override
	public ClientHttpResponse intercept(final HttpRequest request, final byte[] body,
			final ClientHttpRequestExecution execution) throws IOException {
		...
        // 1、使用注入的LoadBalancerClient执行服务调用
		return this.loadBalancer.execute(serviceName,
				this.requestFactory.createRequest(request, body, execution));
	}
}

public class RibbonLoadBalancerClient implements LoadBalancerClient {
	@Override
	public <T> T execute(String serviceId, LoadBalancerRequest<T> request)
			throws IOException {
        // 2、使用注入的LoadBalancerClient执行服务调用
		return execute(serviceId, request, null);
	}
    
	public <T> T execute(String serviceId, LoadBalancerRequest<T> request, Object hint) throws IOException {
        // 3、同Eureka章节服务调用中的，RibbonLoadBalancerClient#getLoadBalancer => 使用SpringClientFactory负载均衡客户端的上下文工厂，构造一个负载均衡器Bean实例
		ILoadBalancer loadBalancer = getLoadBalancer(serviceId);
        
        // 4、同Eureka章节服务调用中的，RibbonLoadBalancerClient#getServer => 根据服务名选择一个具体的服务实例
		Server server = getServer(loadBalancer, hint);
		if (server == null) {
			throw new IllegalStateException("No instances available for " + serviceId);
		}
        
        // 5、构造RibbonServer
		RibbonServer ribbonServer = new RibbonServer(serviceId, server,
				isSecure(server, serviceId),
				serverIntrospector(serviceId).getMetadata(server));

        // 6、执行远程调用
		return execute(serviceId, ribbonServer, request);
	}
    
	@Override
	public <T> T execute(String serviceId, ServiceInstance serviceInstance,
			LoadBalancerRequest<T> request) throws IOException {
		...
        // 7. 底层依赖于org.springframework.http.client.AsyncClientHttpRequestExecution#executeAsync方法，执行异步远程调用
        T returnVal = request.apply(serviceInstance);
        statsRecorder.recordStats(returnVal);
        return returnVal;
		...
	}
}

```

##### Feign + Ribbon 原理

写到 Feign 时再回来补充。

#### 负载均衡策略原理

##### 负载均衡策略

| 负载均衡策略              | 作用                                                         | 特点                                                         |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| RandomRule                | 随机选择 Server                                              | 随机策略，使用**自旋重试**方式获取，直到服务器列表为空，或者找到有效服务实例为止 |
| RoundRobinRule            | 按顺序选择 Server                                            | 轮训策略，Ribbon 默认负载均衡策略，**CAS 索引计数器 + 自旋重试**，最多重试 10 次 |
| RetryRule                 | 在一个配置的时间段内（默认为 500ms），如果 Server 选择不成功，则会一直重新尝试选择，直到时间结束或者选到为止 | 重试策略，默认使用装饰类 RoundRobinRule 进行负载均衡，接口实现要注意**幂等性** |
| WeightedResponseTimeRule  | 根据 Server 的响应时间分配权重，响应时间越长，权重越低，则被选中的概率就越低；相反，响应时间越短，权重越高，则被选中的高绿就越高 | 最小响应时间策略，适用于**耗时主要在接口**上的重量级接口（RT 敏感模型） |
| BestAvailableRule         | 逐个检查 Server，如果 Server 的断路器已打开（当前发生熔断），则忽略该 Server，即只会从断路器关闭中进行选取，然后再选择并发连接最低的 Server | 最低并发策略，适用于耗时主要在网络上的短响应时间接口（连接数敏感模型） |
| AvailabilityFilteringRule | 过滤掉断路器已打开（当前发生熔断），或者当前并发数超过阈值的 Server | 可用性过滤策略                                               |
| ZoneAvoidanceRule         | 剔除不可用区域中的所有 Server，和区域中的不可用 Server（默认区域为1），在过滤后的服务列表中轮训选择 Server | 区域可用性过滤策略                                           |

##### 策略实现原理

###### RandomRule | 随机

```java
public class RandomRule extends AbstractLoadBalancerRule {
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            return null;
        }
        Server server = null;

        // 1、开始自旋
        while (server == null) {
            if (Thread.interrupted()) {
                return null;
            }
            List<Server> upList = lb.getReachableServers();
            List<Server> allList = lb.getAllServers();

            int serverCount = allList.size();
            if (serverCount == 0) {
                // 2、一台 Server 都没，则返回 null
                return null;
            }

            // 3、ThreadLocalRandom.current().nextInt(serverCount); => 从所有ServerCount中，返回一个索引
            int index = chooseRandomInt(serverCount);
            // 4、从在线的upList中，选择对应索引的Server（可能会越界！）
            server = upList.get(index);

            // 5、当前线程让步，继续自旋，直到服务器列表为空，或者找到为止
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 6、如果Server存活（通过ServerListUpdater.UpdateAction#doUpdate通过Eureka Client 定时更新），则返回该Server
            if (server.isAlive()) {
                return (server);
            }

            // 7、当前线程让步，继续自旋，直到服务器列表为空，或者找到为止
            server = null;
            Thread.yield();
        }

        return server;
    }
}

```

###### RoundRobinRule | 轮训

```java
public class RoundRobinRule extends AbstractLoadBalancerRule {
    
    private AtomicInteger nextServerCyclicCounter;
    
    public RoundRobinRule() {
        // 1、初始化索引计数器 => 如果某一时刻，大片服务器同时重启，则可能会有大量请求负载到第0个服务实例，但由于每台机器最终启动完成的时间与接收的请求数量并不相同，所以也不会给负载的服务实例造成太大压力
        nextServerCyclicCounter = new AtomicInteger(0);
    }
    
    // 4、int next = (current + 1) % modulo 取模，得到目标索引
    private int incrementAndGetModulo(int modulo) {
        for (;;) {
            int current = nextServerCyclicCounter.get();
            int next = (current + 1) % modulo;
            if (nextServerCyclicCounter.compareAndSet(current, next))
                return next;
        }
    }
    
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            log.warn("no load balancer");
            return null;
        }

        Server server = null;
        int count = 0;
        
        // 2、最多重试10次
        while (server == null && count++ < 10) {
            List<Server> reachableServers = lb.getReachableServers();
            List<Server> allServers = lb.getAllServers();
            int upCount = reachableServers.size();
            int serverCount = allServers.size();

            if ((upCount == 0) || (serverCount == 0)) {
                log.warn("No up servers available from load balancer: " + lb);
                return null;
            }

            // 3、int next = (current + 1) % modulo 取模，得到目标索引
            int nextServerIndex = incrementAndGetModulo(serverCount);
            server = allServers.get(nextServerIndex);

            // 4、服务实例为空，则线程让步，继续自旋
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 5、服务实例可用，则返回即可
            if (server.isAlive() && (server.isReadyToServe())) {
                return (server);
            }

            // 6、继续自旋
            server = null;
        }

        // 7、最多重试10次
        if (count >= 10) {
            log.warn("No available alive servers after 10 tries from load balancer: "
                    + lb);
        }
        return server;
    }
    ...
}

```

###### RetryRule | 重试

```java
public class RetryRule extends AbstractLoadBalancerRule {
    
    long maxRetryMillis = 500;
    IRule subRule = new RoundRobinRule();
    
    ....
    
   	public Server choose(ILoadBalancer lb, Object key) {
		long requestTime = System.currentTimeMillis();
		long deadline = requestTime + maxRetryMillis;

		Server answer = null;

        // 1、默认使用装饰类RoundRobinRule，进行负载均衡
		answer = subRule.choose(key);

        // 2、如果装饰类获取不到有效服务实例，且当前时间小于最大重试时间，则继续使用装饰类重试
		if (((answer == null) || (!answer.isAlive()))
				&& (System.currentTimeMillis() < deadline)) {

            // 3、根据最大重试时间开启定时任务，到点则中断当前线程
			InterruptTask task = new InterruptTask(deadline
					- System.currentTimeMillis());

            // 4、开始自旋
			while (!Thread.interrupted()) {
                // 5、继续使用装饰类重试
				answer = subRule.choose(key);

                // 6、如果还是获取不到有效服务实例，且没超出最大重试时间，则线程让步，继续自旋
				if (((answer == null) || (!answer.isAlive()))
						&& (System.currentTimeMillis() < deadline)) {
					Thread.yield();
				} 
                // 7、否则结束自旋
                else {
					break;
				}
			}

            // 8、取消定时任务
			task.cancel();
		}

        // 9、返回目标服务实例，如果无效则返回null
		if ((answer == null) || (!answer.isAlive())) {
			return null;
		} else {
			return answer;
		}
	}
	...
}

```

###### WeightedResponseTimeRule | 最小响应时间

```java
public class WeightedResponseTimeRule extends RoundRobinRule {
    
    public static final int DEFAULT_TIMER_INTERVAL = 30 * 1000;
    private int serverWeightTaskTimerInterval = DEFAULT_TIMER_INTERVAL;
    
    private volatile List<Double> accumulatedWeights = new ArrayList<Double>();
    protected Timer serverWeightTimer = null;
    protected AtomicBoolean serverWeightAssignmentInProgress = new AtomicBoolean(false);

    @Override
    public void setLoadBalancer(ILoadBalancer lb) {
        ...
        // 1、设置抽象父类的LoadBalancer后，初始化权重
        initialize(lb);
    }
    
    void initialize(ILoadBalancer lb) {
        ...
        // 2、不延迟执行，默认定期30s执行一次DynamicServerWeightTask，来初始化权重
        serverWeightTimer.schedule(new DynamicServerWeightTask(), 0,
                serverWeightTaskTimerInterval);
        
        // 3、立即调用一次，来初始化权重
        ServerWeight sw = new ServerWeight();
        sw.maintainWeights();
    }
    
    class DynamicServerWeightTask extends TimerTask {
        public void run() {
            ServerWeight serverWeight = new ServerWeight();
            try {
                // 4、初始化权重
                serverWeight.maintainWeights();
            } catch (Exception e) {
                logger.error("Error running DynamicServerWeightTask for {}", name, e);
            }
        }
    }
    
    
    class ServerWeight {
        // 初始化权重
        public void maintainWeights() {
            ...
            
            // 5、CAS设置服务权重更新中的标记为true，代表更新中
            if (!serverWeightAssignmentInProgress.compareAndSet(false,  true))  {
                return; 
            }
            
            try {
                ...
                
                // 找到最大 95% 的响应时间
                // 6、遍历全部Server，累加平均响应时间（在RibbonLoadBalancerClient#execute方法中，执行完远程调用后，会调用一次statsRecorder.recordStats来记录统计信息）
                double totalResponseTime = 0;
                for (Server server : nlb.getAllServers()) {
                    ServerStats ss = stats.getSingleServerStat(server);
                    totalResponseTime += ss.getResponseTimeAvg();
                }

                // 7、使用总的平均响应时间 - 每个服务实例的平均响应时间，可以得到响应时间的权重 => 响应时间越长，服务实例越靠前，权重越小；响应时间越短，服务实例越靠后，权重越大
                Double weightSoFar = 0.0;
                List<Double> finalWeights = new ArrayList<Double>();
                for (Server server : nlb.getAllServers()) {
                    ServerStats ss = stats.getSingleServerStat(server);
                    double weight = totalResponseTime - ss.getResponseTimeAvg();
                    weightSoFar += weight;
                    finalWeights.add(weightSoFar);   
                }
                // 8、设置服务权重列表
                setWeights(finalWeights);
            } catch (Exception e) {
                logger.error(...);
            } finally 
                // 10、最后CAS设置服务权重更新中的标记为false，代表更新完毕
                serverWeightAssignmentInProgress.set(false);
            }

        }
    }
    
    // 9、设置服务权重列表
    void setWeights(List<Double> weights) {
        this.accumulatedWeights = weights;
    }

    @Override
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            return null;
        }
        Server server = null;

        while (server == null) {
            // 11、获取当前时刻的服务权重列表（有可能下一刻就会被其他列表更新替换掉）
            List<Double> currentWeights = accumulatedWeights;
            if (Thread.interrupted()) {
                return null;
            }
            
            List<Server> allList = lb.getAllServers();
            int serverCount = allList.size();
            if (serverCount == 0) {
                return null;
            }
			int serverIndex = 0;
            
            // 12、列表中的最后一个，代表最大的服务权重
            double maxTotalWeight = currentWeights.size() == 0 ? 0 : currentWeights.get(currentWeights.size() - 1); 
            
            // 13、如果最大权重小于0.001，或者权重列表个数不等于服务列表个数，说明权重无效，则回退到父类RoundRobinRule规则，来获取服务实例
            if (maxTotalWeight < 0.001d || serverCount != currentWeights.size()) {
                // 14、以父类RoundRobinRule规则获取服务实例
                server =  super.choose(getLoadBalancer(), key);
                if(server == null) {
                    return server;
                }
            } 
            // 15、如果最大权重不小于0.001，且权重列表个数等于服务列表个数，说明权重有效，则进行权重筛选
            else {
                // 16、生成 [0，maxTotalWeight）之间的随机权重
                double randomWeight = random.nextDouble() * maxTotalWeight;
                
                // 17、获取权重列表中，第一个大于等于随机权重的服务实例，代表目标服务实例
                int n = 0;
                for (Double d : currentWeights) {
                    if (d >= randomWeight) {
                        serverIndex = n;
                        break;
                    } else {
                        n++;
                    }
                }

                server = allList.get(serverIndex);
            }

            // 18、如果实例为空，则线程让步，继续自旋
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 19、如果实例存活，则返回即可
            if (server.isAlive()) {
                return (server);
            }

            server = null;
        }
        return server;
    }
}

```

###### BestAvailableRule | 最低并发

```java
public class BestAvailableRule extends ClientConfigEnabledRoundRobinRule {
    @Override
    public Server choose(Object key) {
        // 1、如果没有服务统计信息，则使用父类默认的RoundRobinRule规则，进行服务实例选取
        if (loadBalancerStats == null) {
            return super.choose(key);
        }
        
        // 2、如果有服务统计信息，则获取当前系统时间
        List<Server> serverList = getLoadBalancer().getAllServers();
        int minimalConcurrentConnections = Integer.MAX_VALUE;
        long currentTime = System.currentTimeMillis();
        Server chosen = null;
        
        // 3、遍历所有服务列表
        for (Server server: serverList) {
            ServerStats serverStats = loadBalancerStats.getSingleServerStat(server);
            // 4、根据当前系统时间，判断服务实例的断路器是否已经打开
            if (!serverStats.isCircuitBreakerTripped(currentTime)) {
                // 8、如果该服务实例断路器没有被打开，则获取他当前系统时间的并发请求数量
                int concurrentConnections = serverStats.getActiveRequestsCount(currentTime);
                // 9、比较获取最小并发请求数量的服务实例，作为目标服务实例
                if (concurrentConnections < minimalConcurrentConnections) {
                    minimalConcurrentConnections = concurrentConnections;
                    chosen = server;
                }
            }
        }
        // 10、如果目标服务实例无效，则使用父类默认的RoundRobinRule规则，进行服务实例选取
        if (chosen == null) {
            return super.choose(key);
        } 
        // 11、如果目标服务实例有效，则返回即可
        else {
            return chosen;
        }
    }
}

public class ServerStats {
    // 5、根据当前系统时间，判断服务实例的断路器是否已经打开
    public boolean isCircuitBreakerTripped(long currentTime) {
        // 6、获取当前服务断路器的超时时间
        long circuitBreakerTimeout = getCircuitBreakerTimeout();
        
        // 7、如果该超时时间无效，或者已经小于了当前系统时间，则认为断路器已关闭，服务实例有效
        if (circuitBreakerTimeout <= 0) {
            return false;
        }
        return circuitBreakerTimeout > currentTime;
    }
    
    private long getCircuitBreakerTimeout() {
        // 6.1、 获取断路器持续周期
        long blackOutPeriod = getCircuitBreakerBlackoutPeriod();
        if (blackOutPeriod <= 0) {
            return 0;
        }
        // 6.6、断路器持续周期 + 最后连接失败的时间 = 断路器超时时间
        return lastConnectionFailedTimestamp + blackOutPeriod;
    }
    
    private long getCircuitBreakerBlackoutPeriod() {
        int failureCount = successiveConnectionFailureCount.get();
        int threshold = connectionFailureThreshold.get();
        
        // 6.2、如果调用失败的数量，没有达到阈值niws.loadbalancer.service-name.connectionFailureCountThreshold（默认为3），则返回0，表示不开启断路器
        if (failureCount < threshold) {
            return 0;
        }
        
        // 6.3、否则调用失败数量 - 断路器阈值，得到差值（最大为16）
        int diff = (failureCount - threshold) > 16 ? 16 : (failureCount - threshold);
        
        // 6.4、然后计算断路器持续周期/s = 差值 * niws.loadbalancer.service-name-.circuitTripTimeoutFactorSeconds（默认为10），即默认最大为160s（2min40s）
        int blackOutSeconds = (1 << diff) * circuitTrippedTimeoutFactor.get();
        if (blackOutSeconds > maxCircuitTrippedTimeout.get()) {
            blackOutSeconds = maxCircuitTrippedTimeout.get();
        }
        
        // 6.5、最后s转换为ms，并返回
        return blackOutSeconds * 1000L;
    }
}

```

###### AvailabilityFilteringRule | 可用性过滤

```java
public class AvailabilityFilteringRule extends PredicateBasedRule {
    
    private AbstractServerPredicate predicate;
    
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        // 1、初始化可用性断言
    	predicate = CompositePredicate.withPredicate(new AvailabilityPredicate(this, clientConfig)).addFallbackPredicate(AbstractServerPredicate.alwaysTrue()).build();
    }
    
    @Override
    public Server choose(Object key) {
        int count = 0;
        // 4、调用父类默认的RoundRobinRule规则，进行服务实例的选择
        Server server = roundRobinRule.choose(key);
        // 5、最多选择再选择10次服务实例+判断可用性断言是否成立
        while (count++ <= 10) {
            // 6、判断当前服务实例是否符合可用性断言，如果是则返回即可，否则继续获取服务实例来判断
            if (predicate.apply(new PredicateKey(server))) {
                return server;
            }
            server = roundRobinRule.choose(key);
        }
        // 7、如果10次判断都没有符合断言的服务实例，则再使用RoundRobinRule来获取最后一次
        return super.choose(key);
    }
}

public class AvailabilityPredicate extends  AbstractServerPredicate {
   
    public AvailabilityPredicate(IRule rule, IClientConfig clientConfig) {
        super(rule, clientConfig);
        // 2、初始化可用性断言
        initDynamicProperty(clientConfig);
    }
    
    private void initDynamicProperty(IClientConfig clientConfig) {
        String id = "default";
        if (clientConfig != null) {
            id = clientConfig.getClientName();
            // 3、设置activeConnectionsLimit，默认为niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit=Integer.MAX_VALUE
            activeConnectionsLimit = new ChainedDynamicProperty.IntProperty(id + "." + clientConfig.getNameSpace() + ".ActiveConnectionsLimit", ACTIVE_CONNECTIONS_LIMIT); 
        }               
    }
    
    @Override
    public boolean apply(@Nullable PredicateKey input) {
        LoadBalancerStats stats = getLBStats();
        if (stats == null) {
            return true;
        }
        // 6.1、判断当前服务实例是否符合可用性断言，如果shouldSkipServer返回true，则代表需要跳过，不能作为目标服务实例；否则说明可以作为目标服务实例
        return !shouldSkipServer(stats.getSingleServerStat(input.getServer()));
    }
    
    private boolean shouldSkipServer(ServerStats stats) {
        // 6.2、先看断路器过滤是否已经打开niws.loadbalancer.availabilityFilteringRule.filterCircuitTripped（默认为true），如果判断到断路器开关已经打开，说明发生了熔断，则直接返回true；否则，如果并发数超过了activeConnectionsLimit（默认最大Integer.MAX_VALUE），也返回true => 认为不可用，需要跳过
        if ((CIRCUIT_BREAKER_FILTERING.get() && stats.isCircuitBreakerTripped()) 
                || stats.getActiveRequestsCount() >= activeConnectionsLimit.get()) {
            return true;
        }
        // 6.3、如果既不熔断，又没超过最大并发数，则返回false，代表可用，不需要跳过
        return false;
    }
}

```

###### ZoneAvoidanceRule | 区域可用性过滤

```java
public class ZoneAvoidanceRule extends PredicateBasedRule {
    
    private CompositePredicate compositePredicate;
    
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        // 1、初始化ZoneAvoidancePredicate断言，在区域<=1时恒为true
        ZoneAvoidancePredicate zonePredicate = new ZoneAvoidancePredicate(this, clientConfig);
        // 2、初始化可用性断言，同AvailabilityFilteringRule的可用性过滤
        AvailabilityPredicate availabilityPredicate = new AvailabilityPredicate(this, clientConfig);
        // 3、组合断言compositePredicate，链式判断zonePredicate和availabilityPredicate
        compositePredicate = createCompositePredicate(zonePredicate, availabilityPredicate);
    }
    
    // 7、获取ZoneAvoidanceRule的断言compositePredicate
    @Override
    public AbstractServerPredicate getPredicate() {
        return compositePredicate;
    }
}

public abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule {
 	// 4、ZoneAvoidanceRule使用父类PredicateBasedRule，进行服务实例的选择
    @Override
    public Server choose(Object key) {
        ILoadBalancer lb = getLoadBalancer();
        Optional<Server> server = 
            // 5、多态获取ZoneAvoidanceRule的断言
            getPredicate()
            // 8、从过滤后的服务列表中，获取目标服务实例
            .chooseRoundRobinAfterFiltering(lb.getAllServers(), key);
        if (server.isPresent()) {
            return server.get();
        } else {
            return null;
        }       
    }
    
    // 6、多态获取ZoneAvoidanceRule的断言
    public abstract AbstractServerPredicate getPredicate();
}

public abstract class AbstractServerPredicate implements Predicate<PredicateKey> {
    public Optional<Server> chooseRoundRobinAfterFiltering(List<Server> servers, Object loadBalancerKey) {
        // 9、根据断言，获取过滤后的服务列表
        List<Server> eligible = getEligibleServers(servers, loadBalancerKey);
        if (eligible.size() == 0) {
            return Optional.absent();
        }
        return Optional.of(eligible.get(incrementAndGetModulo(eligible.size())));
    }
    
    public List<Server> getEligibleServers(List<Server> servers, Object loadBalancerKey) {
        if (loadBalancerKey == null) {
            return ImmutableList.copyOf(Iterables.filter(servers, this.getServerOnlyPredicate()));            
        } else {
            List<Server> results = Lists.newArrayList();
            for (Server server: servers) {
                // 10、应用组合断言compositePredicate，链式判断zonePredicate（区域<=1时恒为true）和availabilityPredicate（无熔断，并发数不超阈值时为true）
                if (this.apply(new PredicateKey(loadBalancerKey, server))) {
                    results.add(server);
                }
            }
            return results;            
        }
    }
}

```

##### 自定义负载均衡算法 | 一致性 Hash

```java
// 自定义负载均衡算法，一致性Hash => 实现 IRule 接口，继承 AbstractLoadBalancerRule 抽象类
public class ConsistentHashRule extends AbstractLoadBalancerRule implements IRule {
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {

    }
    
    @Override
    public Server choose(Object key) {
        // 1、获取请求标识，用于计算hash，这里用了服务路径+请求参数
        HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();
        String uri = request.getServletPath() + "?" + request.getQueryString();
  		// 2、先获取全部服务实例，然后根据hash值，获取目标服务实例
        return route(uri.hashCode(), getLoadBalancer().getAllServers());
    }
    
    public Server route(int hashId, List<Server> addressList){
        if(CollectionUtils.isEmpty(addressList)){
            return null;
        }

        // 3、虚化Server结点, 假设这里每个Server拥有8个虚化结点 => 可以参考Dubbo 160个虚拟结点的hash环
        TreeMap<Long, Server> address = new TreeMap<>();
        addressList.stream().forEach(server -> {
            // 4、虚化Server结点到环上
            for(int i = 0; i < 8; i++){
                // 5、加入服务实例ID作为变数
                long hash = hash(server.getId() + i);
                address.put(hash, server);
            }
        });

        // 6、tailMap取比当前hash大的且离他最近的一个结点 => 顺时针方向: tailMap有序, 会拿到所有比他大的结点
        long hash = hash(String.valueOf(hashId));
        SortedMap<Long, Server> lastSevers = address.tailMap(hash);

        // 7、如果拿不到比他大的结点, 说明我们的hash到了末尾, 需要取最小的结点, 从而虚化成一个环
        if(lastSevers.isEmpty()){
            return address.firstEntry().getValue();
        }

        // 8、如果拿得到比他大的结点, 则取大集中的最小值
        return lastSevers.get(lastSevers.firstKey());
    }
    
    // 5.1、哈希函数
    public long hash(String key){
        MessageDigest md5 = null;
        try {
            md5 = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        }

        byte[] keyBytes = null;
        try {
            keyBytes = key.getBytes("UTF-8");
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }

        // 5.2、根据Key的字节数组生成16字节(128位)的MD5摘要
        md5.update(keyBytes);
        byte[] digest = md5.digest();

        // 5.3、计算long长度的hashCode => 这里做测试, 只取低4个字节整成long型数字作为hashCode, 其中高4个字节都取0, 这里与0xFF避免字节本身为1开头时移位带来的问题
        long hashCode = (digest[3] & 0xFF) << 24    // 高16位
                      | (digest[2] & 0xFF) << 16    // 高8位
                      | (digest[1] & 0xFF) << 8     // 低16位
                      | (digest[0] & 0xFF);         // 低8位

        // 5.4、只取低8字节作为long型返回, 一个long型数字占8个字节
        return hashCode & 0xFFFFFFFFL;
    }
}

```

### 1.9. 详细介绍 Feign？

#### 概念

Feign 是声明式的服务客户端，使得调用远程方法就像调用本地接口一样方便，只需把要调用的服务方法，定义成接口，然后直接调用就行，而无需手动构建 Http 请求再发起服务调用。

| @Feign Client 属性 | 默认值     | 作用                                                         |
| ------------------ | ---------- | ------------------------------------------------------------ |
| value              | ""         | 将要调用的服务名称，是 name 属性的别名                       |
| serviceId          | ""         | 已废弃，将要调用的服务id，作用和 name 属性相同               |
| name               | ""         | 将要调用的服务名称，是 name 属性的别名                       |
| url                | ""         | 全服务路径地址，或者 hostname                                |
| decode404          | false      | 响应状态码为 404 时，是否应该抛出 FeginException             |
| configuration      | {}         | 自定义当前 Feign Client 配置                                 |
| fallback           | void.class | 降级机制（需启用 @EnableHystrix），调用失败时走的一些回退方法，可以用来抛出异常或者给出默认返回的数据 |
| fallbackFactory    | void.class | 为当前 Feign Client接口定义一个降级工厂，用于生成降级类的实例 |
| path               | ""         | 自动给所有方法的 @RequestMapping 加上前缀，类似于 Controller 类上的 @RequestMapping |
| primary            | true       | 是否将当前 Feign Client 标记为第一个注入 Bean                |

#### 架构原理

![1639579104510](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639579104510.png)

| 组件                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| InvocationHandlerFactory | 代理对象生成组件，采用 JDK 的动态代理方式生成代理对象，当调用 Feign 接口时，实际上是去调用远程的 HTTP API |
| Contract                 | 协议组件，解析 @Feign 配置的参数，比如请求类型是 GET 还是 POST，请求的 URI 是什么 |
| MethodHander             | 实际处理组件，当调用 Feign 接口时，实际上是交由该类，来进行远程调用的相关处理 |
| Encoder/Decoder          | 编码/解码组件，通过它们，可以将请求信息，采用指定的方式进行编/解码后再传输/接收 |
| Logger                   | 日志组件，负责记录 Feign 中的日志。其中，可以指定 Logger 的级别以及自定义日志的输出 |
| Client                   | 请求执行组件，负责 HTTP 请求的执行。其中，Feign 默认的 Client 是通过 JDK#HttpURLConnection 发起请求的，在每次发送请求时，都会创建新的 HttpURLConnection 连接，性能很差；因此，可以通过扩展该接口，使用比如 Apache HttpClient 等，基于连接池的高性能 HTTP 客户端来进行优化 |
| Retryer                  | 重试组件，负责重试请求调用，Feign 内置了重试器，当 HTTP 请求出现 IO 异常时，Feign 会限定一个最大重试次数，来进行重试操作 |
| RequestInterceptor       | 请求拦截器组件，可以为 Feign 添加多个拦截器，在请求执行前设置一些扩展的参数信息 |

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>

```

##### 配置 Feign 接口

```java
@FeignClient(value = "feign-client")
public interface IService {
    @GetMapping("/sayHi")
    public String sayHi();
}

```

##### 使用 Feign 接口

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启FeignClient扫描
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

@RestController
public class FeignConsumerController {
    // 2、注入Feign接口代理类
    @Resource
    private IService iService;

    @GetMapping("/sayHi")
    public String sayHi(){
        // 3、发起Http调用
        return iService.sayHi();
    }
}

```

##### 超时重试配置

下面这些配置只是针对 feign-client 服务的配置，对于全局服务的配置参数名一样，不同的是没有服务名作为配置前缀，而是使用 `feign.client.config.default` 作为前缀。

```properties
# 只对服务消费者设置超时与重试策略:
# Ribbon指定服务的超时策略: 请求服务的连接超时时间: Http连接所花费的时间(ms)
feign-client.ribbon.ConnectTimeout=1000
# Ribbon指定服务的超时策略: 服务的业务处理超时时间(ms)
feign-client.ribbon.ReadTimeout=2000

# Ribbon指定服务的重试策略: 允许在所有Http Method都进行重试策略(Get/Post/Put/Delete...)
feign-client.ribbon.OkToRetryOnAllOperations=true
# Ribbon指定服务的重试策略: 每台机器最大的服务超时重试次数 => 因此, 每台机器的请求次数 = 1 + 2 = 3次
feign-client.ribbon.MaxAutoRetries=2
# Ribbon指定服务的重试策略: 服务重试超时时, 还可以再重试几台机器 => 因此, 一共可以请求机器数 = 1 + 2 = 3台, 如果只有1台机器, 那么会继续请求该台机器
feign-client.ribbon.MaxAutoRetriesNextServer=2
# 因此, 一次服务请求的最大超时次数 = (1000 + 2000) * (1 + 2) * (1 + 2) = 27000ms = 27s

```

##### 高性能客户端配置

```yml
feign:
  # 使用okhttp高性能客户端
  okhttp: true
  # 使用Apache httpclient高性能客户端
  # httpclient: true

```

##### 调用日志配置

```yaml
feign:
  client:
    config:
      # Feign全局配置
      default:
        # 记录请求和响应的标头、正文和元数据
        loggerLevel: full

```

##### 请求包压缩配置

```yaml
feign:
  compression:
    request:
      # 开启请求GZIP压缩
      enabled: true
      # 配置压缩数据⼤大⼩小的下限
      min-request-size: 2048
      # 配置支持压缩的MIME TYPE
      mime-types: text/xml,application/xml,application/json
    response:
      #开启响应GZIP压缩
      enabled: true

```

##### 拦截器扩展

```java
@Component
@Slf4j
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate requestTemplate) {
        // 在Header设置Feign Client请求标志
        requestTemplate.header(ProjectConstant.FEIGN_CLIENT_REQUEST_FLAG, "true");
    }
}

```

##### 自定义包装类解码器

```java
// 1、自定义Feign解码器: 解决Feign Sever结果统一包装的问题
@Component
class FeignResultDecoder implements Decoder {
    @Autowired
    private ObjectMapper objectMapper;

    @Override
    public Object decode(Response response, Type type) throws IOException, DecodeException, FeignException {
        if (response.body() == null)
            throw new DecodeException(...);

        // 2、解析body, 得到Result包装类实例
        Result result = objectMapper.readValue(Util.toString(response.body().asReader(Util.UTF_8)), Result.class);
        if (ResultCode.ERROR_CODE.equals(result.getRetCode()))
            throw new DecodeException(...);

        // 3、重新解析包装类Result#data实例并返回
        return objectMapper.readValue(objectMapper.writeValueAsString(result.getData()), TypeFactory.defaultInstance().constructType(type));
    }
}

```

##### Hystrix 降级熔断配置

```java
// 1、直接配置降级熔断处理类IFallbackHandler
@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
public interface HystrixFallbackService extends IService {

}

// 2、配置降级工厂类HystrixClientFallbackFactory，用于生成降级熔断处理类
@FeignClient(value = "feign-client", fallback = HystrixClientFallbackFactory.class)
public interface HystrixFallbackService extends IService {

}

@Component
public class HystrixClientFallbackFactory implements FallbackFactory<HystrixFallbackService> {
    @Override
    public HystrixFallbackService create(Throwable cause) {
        // 2.1、手动实现一个HystrixFallbackService降级熔断处理类
        return new HystrixFallbackService(){
            ...
        }
    }
}

```

#### 动态代理原理

##### 1、开启 FeignClient 扫描

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启FeignClient扫描
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.TYPE)
@Documented
// 2、导入FeignClientsRegistrar
@Import(FeignClientsRegistrar.class)
public @interface EnableFeignClients {
    ...
}



```

##### 2、扫描 @FeignClient 注解

```java
class FeignClientsRegistrar
    implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware {
	@Override
	public void registerBeanDefinitions(AnnotationMetadata metadata,
			BeanDefinitionRegistry registry) {
        // 1、读取并注册@EnableFeignClients#defaultConfiguration配置
		registerDefaultConfiguration(metadata, registry);
        // 2、扫描并注册FeignClient
		registerFeignClients(metadata, registry);
	}
    
    public void registerFeignClients(AnnotationMetadata metadata,
                                     BeanDefinitionRegistry registry) {
        // 3、获取注解扫描器
		ClassPathScanningCandidateComponentProvider scanner = getScanner();
		scanner.setResourceLoader(this.resourceLoader);

		Set<String> basePackages;

        // 4、读取@EnableFeignClients#clients属性
		Map<String, Object> attrs = metadata
				.getAnnotationAttributes(EnableFeignClients.class.getName());
		final Class<?>[] clients = attrs == null ? null
				: (Class<?>[]) attrs.get("clients");
        
        // 5、如果@EnableFeignClients没配置clients属性，则配置@FeignClient注解扫描过滤器
        AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(
            FeignClient.class);
		if (clients == null || clients.length == 0) {
			scanner.addIncludeFilter(annotationTypeFilter);
            // 5.1、从@EnableFeignClients配置的value、basePackages、basePackageClasses，以及springbootApplication启动类包中，选出要扫描的包
			basePackages = getBasePackages(metadata);
		}
        // 6、否则，@EnableFeignClients#clients属性所在的包名加入basePackages
		else {
			...
		}

        // 7、扫描basePackages下的注解
		for (String basePackage : basePackages) {
			Set<BeanDefinition> candidateComponents = scanner
					.findCandidateComponents(basePackage);
			for (BeanDefinition candidateComponent : candidateComponents) {
				if (candidateComponent instanceof AnnotatedBeanDefinition) {
					AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;
					AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();
					Assert.isTrue(...);

                    // 8、扫描basePackages下的@FeignClient组件
					Map<String, Object> attributes = annotationMetadata
							.getAnnotationAttributes(
									FeignClient.class.getCanonicalName());

                    // 9、获取@FeignClient#contextId、value、name、serviceId属性
					String name = getClientName(attributes);
                    
                    // 10、注册@FeignClient#configuration
					registerClientConfiguration(registry, name,
							attributes.get("configuration"));

                    // 11、注册 FeignClientFactoryBean
					registerFeignClient(registry, annotationMetadata, attributes);
				}
			}
		}
    }
}

```

##### 3、注册 FeignClientFactoryBean

```java
class FeignClientsRegistrar
    implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware {
    
	private void registerFeignClient(BeanDefinitionRegistry registry,
			AnnotationMetadata annotationMetadata, Map<String, Object> attributes) {
        ...
        // 1、获取FeignClientFactoryBean#BeanDefinitionBuilder
        BeanDefinitionBuilder definition = BeanDefinitionBuilder
            .genericBeanDefinition(FeignClientFactoryBean.class);
		...
        // 2、构造FeignClientFactoryBean#BeanDefinition
		AbstractBeanDefinition beanDefinition = definition.getBeanDefinition();
        BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] { alias });
        // 3、注册FeignClientFactoryBean
		BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);
	}
}

```

##### 4、注入 FeignClient

```java
class FeignClientFactoryBean
    implements FactoryBean<Object>, InitializingBean, ApplicationContextAware {
    // 1、@Autowire在注入时调用FactoryBean#getObject
	@Override
	public Object getObject() throws Exception {
		return getTarget();
	}

    <T> T getTarget() {
        // 2、获取SPI#FeignAutoConfiguration注入的FeignContext Bean实例
        FeignContext context = this.applicationContext.getBean(FeignContext.class);
        
        // 3、根据上下文构造Feign.Builder
        Feign.Builder builder = feign(context);
        
        // 4、@FeignClient#uri属性为空
		if (!StringUtils.hasText(this.url)) {
            // 5、则追加http+@FeignClient#name
			if (!this.name.startsWith("http")) {
				this.url = "http://" + this.name;
			}
			else {
				this.url = this.name;
			}
			this.url += cleanPath();
            
            // 6、对已注入的FeignClient进行代理
			return (T) loadBalance(builder, context,
					new HardCodedTarget<>(this.type, this.name, this.url));
		}
        // 4、否则使用uri对已注入的FeignClient进行代理
    }

    protected <T> T loadBalance(Feign.Builder builder, FeignContext context,
			HardCodedTarget<T> target) {
        // 7、获取已注入的LoadBalancerFeignClient实例 => DefaultFeignLoadBalancedConfiguration自动装配注入
		Client client = getOptional(context, Client.class);
		if (client != null) {
			builder.client(client);
            // 8、获取代理生产类HystrixTargeter => SPI#FeignAutoConfiguration注入
			Targeter targeter = get(context, Targeter.class);
            // 9、获取FeignClient目标代理
			return targeter.target(this, builder, context, target);
		}

		throw new IllegalStateException(...);
	}
    
    // 根据上下文构造Feign.Builder
	protected Feign.Builder feign(FeignContext context) {
        ...
        // 3.1、获取Feign.Builder实例 => FeignClientsConfiguration自动装配注入
		Feign.Builder builder = get(context, Feign.Builder.class)
            // 3.2、配置当前类作为日志记录者logger 
            .logger(logger)
            // 3.3、配置Encoder实例SpringDecoder => FeignClientsConfiguration自动装配注入，Missing Encoder Bean 时默认注入（可扩展修改）
            .encoder(get(context, Encoder.class))
            // 3.4、配置Decoder实例SpringEncoder => FeignClientsConfiguration自动装配注入，Missing Decoder Bean 时默认注入
            .decoder(get(context, Decoder.class))
       // 3.5. 配置Contract实例SpringMvcContract，用于限定 @FeignClient 的配置规则 => FeignClientsConfiguration自动装配注入，Missing Contract Bean 时默认注入（可扩展修改）
            .contract(get(context, Contract.class));
		// 3.6 配置Feign，比如RequestInterceptor
        configureFeign(context, builder);
        // 3.7. 返回Feign Builder
		return builder;
	}
}

```

##### 5、获取 FeignClient 目标代理

```java
class HystrixTargeter implements Targeter {

	@Override
	public <T> T target(FeignClientFactoryBean factory, Feign.Builder feign,
                        FeignContext context, Target.HardCodedTarget<T> target) {
        // 1、Feign.Builder实例 => FeignClientsConfiguration自动装配注入
		if (!(feign instanceof feign.hystrix.HystrixFeign.Builder)) {
            // 2、进入Feign代理逻辑
			return feign.target(target);
		}
        ...// 1、否则进入Hystrix熔断逻辑
    }
}

public abstract class Feign {
    ...
    public static class Builder {
        public <T> T target(Target<T> target) {
            // 3、构造ReflectiveFeign实例，其中包括设置SynchronousMethodHandler.Factory
      		return build().newInstance(target);
    	}
    }
    ...
}

public class ReflectiveFeign extends Feign { 
  	@Override
    public <T> T newInstance(Target<T> target) {
        // 4、为@FeignClient接口里的方法，使用SynchronousMethodHandler.Factory构建SynchronousMethodHandler实例
        Map<String, MethodHandler> nameToHandler = targetToHandlersByName.apply(target);
        ...
        // 4、为@FeignClient接口设置JDK动态代理处理类FeignInvocationHandler
        InvocationHandler handler = factory.create(target, methodToHandler);
        // 5、创建@FeignClient接口动态代理类
        T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(),
        	new Class<?>[] {target.type()}, handler);
        ...
        return proxy;
    }
}

```

#### 服务调用原理

##### 1、FeignInvocationHandler#invoke

```java
public class ReflectiveFeign extends Feign {
    ...
    static class FeignInvocationHandler implements InvocationHandler {
        ...
        // 1、JDK动态代理
    	@Override
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
           ...
           // 2、调用SynchronousMethodHandler#invoke
           return dispatch.get(method).invoke(args);
        }
    }
}

```

##### 2、SynchronousMethodHandler#invoke

```java
final class SynchronousMethodHandler implements MethodHandler {
    @Override
    public Object invoke(Object[] argv) throws Throwable {
        // 1、获取请求模板 => GET /sayHi HTTP/1.1 Binary data
        RequestTemplate template = buildTemplateFromArgs.create(argv);
        // 2、默认从不重试 => FeignClientsConfiguration#Retryer.NEVER_RETRY注入
        Retryer retryer = this.retryer.clone();
        // 3、开始自旋重试
        while (true) {
            try {
                // 4、执行请求和解码响应
                return executeAndDecode(template);
            } catch (RetryableException e) {
                try {
                    // 5、由于默认不重试，所以重试时会报错
                    retryer.continueOrPropagate(e);
                } catch (RetryableException th) {
                    ...
                }
                // 6、记录日志
                if (logLevel != Logger.Level.NONE) {
                    logger.logRetry(metadata.configKey(), logLevel);
                }
                continue;
            }
        }
    }
}

```

##### 3、SynchronousMethodHandler#executeAndDecode

```java
final class SynchronousMethodHandler implements MethodHandler {
    
    Object executeAndDecode(RequestTemplate template) throws Throwable {
        // 1、请求前拦截
        Request request = targetRequest(template);
		...
        // 2、调用LoadBalancerFeignClient（修饰了feign.Client#Default）发起请求
        response = client.execute(request, options);
        ...
        if (response.status() >= 200 && response.status() < 300) {
            if (void.class == metadata.returnType()) {
                return null;
            } else {
                // 3、响应200，解码（默认为SpringEncoder编码,SpringDecoder解码）
                Object result = decode(response);
                shouldClose = closeAfterDecode;
                return result;
            }
        } else if (decode404 && response.status() == 404 && void.class != metadata.returnType()) {
            // 4、响应404，解码（默认为SpringEncoder编码,SpringDecoder解码）
            Object result = decode(response);
            shouldClose = closeAfterDecode;
            return result;
        } else {
        // 5、ErrorDecoder异常解码，默认为ErrorDecoder.Default，用于抛出RetryableException
            throw errorDecoder.decode(metadata.configKey(), response);
        }
    }

    Request targetRequest(RequestTemplate template) {
        // 1.1、请求前拦截
        for (RequestInterceptor interceptor : requestInterceptors) {
            interceptor.apply(template);
        }
        // 1.2、构造feign.Request实例
        return target.apply(template);
    }
}

```

##### 4、LoadBalancerFeignClient#execute

```java
package org.springframework.cloud.openfeign.ribbon;

public class LoadBalancerFeignClient implements Client {
	@Override
    public Response execute(Request request, Request.Options options) throws IOException {
        ...// 1、组装uri、host和RibbonRequest实例
        // 2、类似于Ribbon调用SpringClientFactory，底层实质调用Spring AbstractApplicationContext#refresh，触发RibbonClientConfiguration注入，然后就有了Ribbon服务列表缓存和其他注入的实例
        IClientConfig requestConfig = getClientConfig(options, clientName);
        // 3、底层构造FeignLoadBalancer（默认修饰Ribbon#ZoneAwareLoadBalancer）
        return lbClient(clientName)
            // 4、调用AbstractLoadBalancerAwareClient#executeWithLoadBalancer
            .executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse();
    }
}

public abstract class AbstractLoadBalancerAwareClient<S extends ClientRequest, T extends IResponse> extends LoadBalancerContext implements IClient<S, T>, IClientConfigAware {
    public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException {
        ...// RXJava语法略
        return Observable.just(
            // 5、调用FeignLoadBalancer#execute方法
            AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));
    }
}

```

##### 5、FeignLoadBalancer#execute

```java
public class FeignLoadBalancer extends
    AbstractLoadBalancerAwareClient<FeignLoadBalancer.RibbonRequest, FeignLoadBalancer.RibbonResponse> {
	@Override
	public RibbonResponse execute(RibbonRequest request, IClientConfig configOverride) throws IOException {
		...
        // 1、最终调用feign.Client#execute方法
		Response response = request.client().execute(request.toRequest(), options);
		return new RibbonResponse(request.getUri(), response);
	}
}

public interface Client {
    @Override
    public Response execute(Request request, Options options) throws IOException {
      // 2、建立连接，发送请求
      HttpURLConnection connection = convertAndSend(request, options);
      // 3、把连接和请求转换为响应实例
      return convertResponse(connection, request);
    }
    
    HttpURLConnection convertAndSend(Request request, Options options) throws IOException {
        // 2.1、建立连接
        final HttpURLConnection connection =
            (HttpURLConnection) new URL(request.url()).openConnection();
        ...// 2.2、设置连接超时、读超时等属性
        // 2.3、如果存在请求体，则发送请求体
        if (request.body() != null) {
            ...
			out.write(request.body());
            ...
        }
        ...
        // 2.4、最后返回建立好的连接
        return connection;
    }
    
    Response convertResponse(HttpURLConnection connection, Request request) throws IOException {
        // 3.1、获取响应码
        int status = connection.getResponseCode();
        // 3.2、获取响应内容
        String reason = connection.getResponseMessage();
        // 3.3、构造返回响应实例
        return Response.builder()
            .status(status)
            .reason(reason)
            .headers(headers)
            .request(request)
            .body(stream, length)
            .build();
    }
}

```

### 2.0. 详细介绍 Hystrix？

#### 背景

1. 当一个服务调用另一个服务时，由于网络或者自身等原因，在调用期间出现问题，调用者就会一直等待被调用者的响应，当越来越多的服务请求到这些出问题的资源，则会导致更多的请求等待，从而发生**雪崩效应**。
2. **雪崩效应**是指，在微服务项目中，由于微服务之间调用是互通的，高并发的数据库访问量会导致服务线程阻塞，使单个服务宕机时，其服务的不可用会蔓延到其他服务，引起整体服务不可用的灾难性后果。
   - **举例**：电商系统很多模块都依赖营销优惠服务，其负载可谓非常之高，如果这个服务出现了异常，导致响应超时，那么所有依赖它的下游系统的响应时间都会被拉长，从而引发一个滚雪球的雪崩效应，由最上游的系统问题，引发一系列下游系统响应超时，最终导致整个系统被拖垮。
3. 其中，雪崩效应产生的**根本原因**是，由于 Tomcat 在默认情况下，只有一个线程池来维护接收到的请求，此时，如果某接口在某时刻被大量访问，就会占据 Tomcat 线程池中的所有线程（即**请求处理资源耗尽**），使得其他请求处于等待状态，无法连接到服务接口。
   - **解决方案**：扩容、限流、增加硬件监控、排查代码问题，使用 Hystrix 进行资源隔离、熔断降级、快速失败等。

#### 概念

1. Hystrix，中文含义为豪猪，因其背上长满棘刺，从而拥有了自我保护的能力，基于此特征的引申，Netflix 公司在分布式微服务架构的践行下，将其保护服务的稳定性而设计的**断路器熔断解决方案**，称之为 Hystrix。
2. Hystrix，是 SpringCloud 中一个防止服务雪崩的**容错框架**，具有**服务降级、服务熔断、服务隔离、服务监控**等技术，从而实现服务保护的效果。
   - **服务降级**：接口调用失败时，为了防止客户端一直等待，其不会再处理业务代码，而是直接返回一个友好的提示给客户端，即调用接口提前定义好的**降级方法**，比如返回一个 NULL。
   - **服务熔断**：
     1. 服务熔断，是在服务降级的基础上，做的一个更直接的保护方式。
     2. 指在统计时间范围内，请求失败数达到了阈值 `requestVolumeThreshold`  + 请求错误率也达到了阈值 `errorThresholdPercentage` 时， 则打开断路器，使得之后的请求直接走**降级方法**，不再走业务代码，并且，在 `sleepWindowInMilliseconds` 后尝试恢复。
   - **服务隔离**：
     1. 指隔离服务资源间的相互影响，使得在高并发的场景下，不影响到其他服务。
     2. 服务隔离有**线程池和信号量**两种实现方式，一般使用线程池方式，即为隔离的服务开启一个独立的线程池。
   - **服务监控**：比如接口调用时，把每秒请求数、成功请求数、失败请求数、请求拒绝数等运行指标都记录下来。

#### 架构原理

##### 服务降级

假如  HystrixClient 调用目标请求时发生了异常，此时 Hystrix 会自动把该请求转发到**降级逻辑**中，由于服务调用方来编写异常处理逻辑，比如**调用超时**等。

![1644325501264](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644325501264.png)

##### 服务熔断

- 服务熔断是建立在服务降级之上的一个异常处理措施，可以看作是服务降级的升级版，引入了一种**断路器（熔断器）**的机制，当断路器打开时，对服务的调用请求不会发送到目标服务节点，而是直接转向**降级逻辑**中。

  ![1644325922862](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644325922862.png)

- 断路器，可以显著缓解由 QPS （Query Per Second，每秒访问请求，用于衡量系统当前压力）激增导致的雪崩效应，断路器打开后，由于请求直接转向降级逻辑，而不会发起服务调用，因此会大幅降低承压服务的系统压力，熔断打开状态的判断维度有：

  - 在一定时间窗口内，发生异常的请求数量达到临界值 `circuitBreaker.requestVolumeThreshold`，默认为 20。
  - 在一定时间窗口内，发生异常的请求数量占请求总数量的一定比例 `circuitBreaker.errorThresholdPercentage`，默认为 50。

  | 状态      | 作用                                                         |
  | --------- | ------------------------------------------------------------ |
  | OPEN      | 打开状态，服务熔断中，在一段时间内不得像外部发起服务调用，调用者想调用该服务则会一律走到降级逻辑中 |
  | HALF-OPEN | 半开状态，可尝试发起一个真实的服务调用，但一切都会被监视着，调用失败的从新回到打开状态，等待下一次半开状态 |
  | CLOSED    | 关闭状态，上一步调用成功了，则可以停止服务熔断，重新恢复正常 |

##### 线程隔离

- Hystrix 通过线程隔离的方案，将执行服务调用的代码，和容器本身的线程池进行隔离，同时允许配置每个服务所需线程的最大数量，使得即便一个服务的线程池被吃满，也不会影响其他服务。

  ![1644326225115](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644326225115.png)

- Hystrix 提供了两种线程隔离的方式，分别是线程池技术和信号量技术，两者业务流程上是一致的，在默认情况下，Hystrix 使用的是**线程池**的方式。

|            | 概念                                                         | 超时判定                                             | 性能                                                         | 使用场景                                                     |
| ---------- | ------------------------------------------------------------ | ---------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 线程池技术 | 使用 Hystrix 内建的线程池去执行方法调用，而不是使用容器线程  | 非容器线程，因此可以直接对执行阶段超时做**主动判定** | 涉及线程创建、销毁、任务调度，在资源利用率和效率的角度上看，线程池技术会比较慢 | 一般场景下尽量使用，但要注意线程切换导致的 ThreadLocal 变量的问题 |
| 信号量技术 | 直接使用容器线程去执行方法，不会另外创建新的线程，只是当开关和计数器的作用，其中，获取到信号量的线程才可以执行方法，没获取到的就会转到降级流程 | 容器线程，只能等待诸如网络请求超时等做**被动判定**   | 没有额外的系统资源开销，性能方面有优势                       | 超高并发下，线程开销大，对接口无需再调用外部服务的场景       |

```properties
# 切换线程隔离方式为信号量方式
execution.isolation.strategy = ExecutionIsolationStrategy.SEMAPHORE

```

#### 使用方式

##### Feign +  Hystrix

```java 
/**
 * 测试HystrixFallback降级应用
 */
@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients
@EnableCircuitBreaker
public class HystrixFallbackApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(HystrixFallbackApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

/**
 * 测试HystrixFallback降级服务
 */
// 允许Bean同名覆盖: 不配置会报"feign-client.FeignClientSpecification"错误, 因为Feign的代理对象名称是使用里面的服务属性拼凑的, 所以可以配置允许Bean同名覆盖
//@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
public interface IHystrixFallbackService extends ICommonService {

}

@Component
@Slf4j
public class IFallbackHandler implements IHystrixFallbackService {
    /**
     * 直接异常降级实现
     * @return
     */
    @Override
    public String error() {
        log.info("Fallback: I'm not a black sheep any more.");
        return "Fallback: I'm not a black sheep any more.";
    }
}

```

##### @HystrixCommand

```java
/**
 * 测试HystrixFallback降级服务: 测试Hystrix RequestCache
 */
@Service
@Slf4j
public class IRequestCacheService {
    /**
     * 使用name作为CacheKey, 只有key同样, 才返回Hystrix上下文缓存:
     * => 配置口令: 121: 1个HystrixRequestContext上下文, 2个Cache注解@CacheResult和@CacheKey, 1个Command注解@HystrixCommand
     * @param name
     * @return
     */
    // 指定服务降级的第二种写法
    @HystrixCommand(commandKey = "requestCache", fallbackMethod = "requestCacheFallback")
    // 注意@CacheResult是作用在@HystrixCommand注定的方法, 所以还需要配置@HystrixCommand
    @CacheResult
    public Friend requestCache(@CacheKey String name){
        ...
    }
    
    /**
     * 测试RequestCache降级服务: 可见, Hystrix是通过开启一个新的线程来实现降级的, 两不冲突
     * => 测试成功, Hystrix降级时, 会打断@HystrixCommand指定的线程
     * @param name
     * @return
     */
    private Friend requestCacheFallback(String name){...}
}

```

#### 使用经验

##### HystrixCommand + 配置中心

1. Hystrix 配置项非常多，如果不对接配置中心，所有配置只能在代码里修改，在集群部署情况下，难以应对紧急情况。
2. 因此，可以在项目中只设置一个 `CommandKey`，其他配置都在配置中心进行指定，这样出现紧急情况，比如需隔离部分请求时，只需在配置中心进行修改以后，强制更新即可。

##### 降级逻辑 + 手动埋点

1. 当请求失败或者超时，会执行降级逻辑，但如果出现大量的降级，则说明某些服务出问题了。
2. 此时，可以在降级逻辑中加入手动埋点的操作，上报数据给监控系统，并输出降级日志，统一由日志收集的程序去进行处理。
3. 这样就可以把问题暴露出去，然后通过实时数据分析进行告警操作。

##### Gateway + 信号量隔离

1. Gateway 网关，是所有请求的入口，路由服务数量会有很多，几十个到上百个都有可能。
2. 如果用线程池隔离，那么需要创建上百个独立的线程池，开销太大，不建议。
3. 而用信号量隔离，则开销就小很多，同时还能起到限流的作用。

##### 超时控制

Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如重试3 次，Ribbon 的超时为 1 秒，那么Hystrix 的超时时间应该⼤于 3 秒，否则就会出现 Ribbon 还在重试中，⽽ Hystrix 已经超时的现象。

##### 常用降级方案

真实项目里的降级逻辑有很多，但目标都是相同的，那就是把异常对系统的影响**降到最低**。

- **静默处理**：所谓的静默处理，就是什么也不干，在降级逻辑中直接返回一个 null。
- **默认值**：瞒天过海，说一个假话，在并不确定真实结果的情况下，返回一个默认值。
- **缓存异常**：对于非热点数据，在缓存故障无法处理时，可在降级逻辑里转而访问数据库。
- **主备切换**：在主从库都发生故障时，可以在降级逻辑里，先于人工干预自动访问备库数据，该场景主要用于主链路接口上，平常不要随意访问备库，以免造成脏读幻读。
- **重试**：虽然 Ribbon 可以进行超时重试，但对于接口非超时等其他异常，可以在降级逻辑中自己实现重新调用的逻辑。
- **多级降级**：进入降级逻辑后，如果还发生异常，那么可以对其进行二次、三次等多次降级。
- **人工干预**：对于一些及其重要的接口，可在降级逻辑中启动人工干预流程，比如日志打点、监控报警、通知人工介入等。

### 2.1. 详细介绍 Sentinel？

#### 概念

Sentinel是⼀个⾯向云原⽣微服务的流量控制、熔断降级组件，可用于替代 Hystrix，针对的问题有：**服务雪崩、服务降级、服务熔断、服务限流**，可不依赖任何框架，通过 UI 界⾯配置即可完成细粒度控制。

#### 优点

![1644385609542](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644385609542.png)

- **丰富的应⽤场景**：Sentinel 承接了阿⾥巴巴近 10 年的双⼗⼀⼤促流量的核⼼场景，例如秒杀、消息削峰填⾕、集群流量控制、实时熔断下游不可⽤应⽤等。
- **完备的实时监控**：可以看到 500 台以下规模的集群的汇总，也可以看到单机的秒级数据。
- **⼴泛的开源⽣态**：与 SpringCloud、Dubbo的整合，只需要引⼊相应的依赖并进⾏简单的配置即可快速地接⼊ Sentinel。

#### 原理

##### 限流

- 假设系统可以处理 1w 的并发，但某时刻并发数为 2w，那么限流机制就会保证 1w 用户是正常使用的，否则请求量过大，会将系统可用性拖垮。
- 限流的主要目的是，通过**限制并发访问数**，或者**限制一个时间窗口**内允许处理的请求数量，来保护系统，一旦达到限制流量，则对当前请求进行处理，采取对应的拒绝策略，比如跳转错误页面、进行排队、服务降级等。

##### 熔断

服务熔断是指，当某个服务提供者无法正常为服务调用者提供服务时，比如请求超时、服务异常等，为了防止整个系统出现雪崩效应，**暂时地将出现故障的接口隔离出来**，断绝与外部接口额度联系，即当触发熔断之后，后续一段时间内，该服务调用者的请求都会直接失败，直到目标服务恢复正常。

#### 使用方式

##### 流控 | HelloWorld

```java
/**
 * Sentinel快速入门
 */
public class HelloWorld {

    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 初始化流控规则
     */
    private static void initFlowRules() {
        ArrayList<FlowRule> flowRules = new ArrayList<>();
        FlowRule flowRule = new FlowRule();

        // 注意, 记得把规则和资源绑定起来, 一般一个规则对应一个资源, 但也可以一个规则对应多个资源
        flowRule.setResource(RESOURCE_NAME);

        // 设置QPS维度的流控规则
        flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS);

        // 设置QPS为20个
        flowRule.setCount(20);

        // 交由流控管理器管理
        flowRules.add(flowRule);
        FlowRuleManager.loadRules(flowRules);
    }

    /**
     * 	对主流的5种流控策略做了 底层的抽象和资源的封装
     *
     * 	对于规则： FlowRule 、DegradeRule、ParamFlowRule、SystemRule、AuthorityRule
     * 	对于管理器：FlowRuleManager、DegradeRuleManager、ParamFlowRuleManager、SystemRuleManager、AuthorityRuleManager
     *  对于异常：FlowException、DegradeException、ParamFlowException、SystemBlockException、AuthorityException
     */
    public static void main(String[] args) throws InterruptedException {
        // 0. 引入Maven依赖
        /**
         *         <dependency>
         *             <groupId>com.alibaba.csp</groupId>
         *             <artifactId>sentinel-core</artifactId>
         *             <version>1.8.2-SNAPSHOT</version>
         *         </dependency>
         */

        // 1. 定义规则
        initFlowRules();

        // 2. 定义资源
        while (true) {
            // 流控的Entry
            Entry entry = null;
            try {
                // 2.1. 定义资源名称
                entry = SphU.entry(RESOURCE_NAME);

                // 2.2. 执行业务代码
                System.out.println("执行业务代码...");
                Thread.sleep(20);
            } catch (BlockException e) {
                // 2.3. 抛出异常, 表示被流控住了, 执行流控逻辑
                System.err.println("要访问的资源被流控了, 执行流控逻辑!");
            } finally {
                if(entry != null){
                    // 2.4. 关闭资源
                    entry.exit();
                }
            }
        }

        // 3. 查看结果

        // 4. 配置控制台
    }
}

```

##### 降级 | HelloWorld

```java
/**
 * 初始化降级规则
 */
private static void initDradeRules() {
    ArrayList<DegradeRule> degradeRules = new ArrayList<>();
    DegradeRule degradeRule = new DegradeRule();
    degradeRule.setResource("com.jsonyao.sentinel.controller.IndexController:degrade:test");
    degradeRule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT);
    degradeRule.setCount(2);
    degradeRules.add(degradeRule);
    DegradeRuleManager.loadRules(degradeRules);
}

```

##### 流控 | 注解

```java
// 切面@Around代理@SentinelResource
@Configuration
public class AopConfiguration {
    @Bean
    public SentinelResourceAspect sentinelResourceAspect() {
        return new SentinelResourceAspect();
    }
}

/**
 * 测试注解设置流控
 */
@Service
public class FlowService {

    /**
     * 测试注解设置流控
     *
     * 	blockHandler: 流控降级异常的时候进入的兜底函数
     *  fallback: 抛出业务异常的时候进入的兜底函数
     *  (1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理)
     *
     * @return
     */
    @SentinelResource(
            value = "com.jsonyao.sentinel.service.FlowService:flow",
            // 资源调用的流量类型, 表示控制出口流量, 注意系统规则只会对入口流量生效
            entryType = EntryType.OUT,
            blockHandler = "flowBlockHandler"
//            , fallback = ""
    )
    public String flow() {
        System.err.println("----> 正常执行flow方法");
        return "flow";
    }

    /**
     * 触发流控
     * @param ex
     * @return
     */
    public String flowBlockHandler(BlockException ex) {
        System.err.println("----> 触发流控策略:" + ex);
        return "执行流控方法";
    }
}

```

##### 降级 | 注解

```java
// 切面@Around代理@SentinelResource
@Configuration
public class AopConfiguration {
    @Bean
    public SentinelResourceAspect sentinelResourceAspect() {
        return new SentinelResourceAspect();
    }
}

/**
 * 测试注解降级流控
 */
@Service
public class DegradeService {

    /**
     * 用于测试注解降级流控
     */
    private AtomicInteger counts = new AtomicInteger(0);

    /**
     * 测试注解降级流控
     *
     * 	blockHandler: 流控降级异常的时候进入的兜底函数
     *  fallback: 抛出业务异常的时候进入的兜底函数
     *  (1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理)
     *
     * @return
     */
    @SentinelResource(
            value = "com.jsonyao.sentinel.service.DegradeService:degrade",
            // 资源调用的流量类型, 表示控制出口流量, 注意系统规则只会对入口流量生效
            entryType = EntryType.OUT,
            blockHandler = "degradeBlockHandler",
            fallback = "degradeFallback"
    )
    public String degrade() {
        System.err.println("----> 正常执行degrade方法");

        if(counts.incrementAndGet() % 2 == 0){
            throw new RuntimeException("抛出业务异常");
        }

        return "degrade";
    }

    /**
     * 触发降级流控
     * @param ex
     * @return
     */
    public String degradeBlockHandler(BlockException ex) {
        System.err.println("----> 触发降级流控策略:" + ex);
        return "执行降级流控方法";
    }

    /**
     * 触发业务异常降级
     * @param t
     * @return
     */
    public String degradeFallback(Throwable t) {
        System.err.println("----> 触发异常时的降级策略:" + t);
        return "执行异常降级方法";
    }
}


```

##### 流控 | 控制台

```java
@RestController
public class IndexController {
    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 控制台流控测试： 控制台配置、读取规则
     * @return
     */
    @RequestMapping("/flow")
    public String flow(){
        // 1. 定义规则 => main方法中加载
//        initFlowRules();

        // 2. 定义资源
        Entry entry = null;// 流控的Entry
        try {
            // 2.1. 定义资源名称
            entry = SphU.entry(RESOURCE_NAME);

            // 2.2. 执行业务代码
            System.out.println("执行业务代码...");
            Thread.sleep(20);
        } catch (BlockException e) {
            // 2.3. 抛出异常, 表示被流控住了, 执行流控逻辑
            System.err.println("要访问的资源被流控了, 执行流控逻辑!");
        } catch (InterruptedException e) {

        } finally {
            if(entry != null){
                // 2.4. 关闭资源
                entry.exit();
            }
        }

        return "flow";
    }
}

```

##### 降级 | 控制台

```java
@RestController
public class IndexController {
    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 控制台降级测试: 控制台配置、读取规则
     * @return
     */
    public AtomicInteger counts = new AtomicInteger(0);
    @RequestMapping("/degrade")
    public String degrade() {
        Entry entry = null;// 流控的Entry
        try {
            String resourceName = "com.jsonyao.sentinel.controller.IndexController:degrade:test";
            entry = SphU.entry(resourceName);

            System.out.println("执行业务代码...");
            if(counts.getAndIncrement() % 2 == 0){
                Thread.sleep(100);
            }

            Thread.sleep(20);
        } catch (BlockException e) {
            System.err.println("要访问的资源被流控了, 执行流控逻辑!");
        } catch (InterruptedException e) {

        } finally {
            if(entry != null){
                entry.exit();
            }
        }

        return "degrade";
    }
}

```

#### Sentinel vs Hystrix

1. **机制不同**：Sentinel 不会像 Hystrix 那样，只在半开状态才放过⼀个请求尝试⾃我修复，就是明明确确地**按时间窗⼝**来，熔断触发后，时间窗⼝内拒绝请求，时间窗⼝后就恢复。
2. **更方便**：Sentinel Dashboard 中添加的规则数据存储在内存，微服务停掉规则数据就消失，在⽣产环境下不合适，可以将 Sentinel 规则数据持久化到 Nacos **配置中⼼**，让微服务从配置中心获取。
3. **其他区别**：

| 维度           | Sentinel                                       | Hystrix                       |
| -------------- | ---------------------------------------------- | ----------------------------- |
| 隔离策略       | 信号量                                         | 线程池/信号量                 |
| 熔断降级策略   | 基于响应时间、基于失败比率                     | 基于失败比率                  |
| 实时指标实现   | 滑动窗口                                       | 滑动窗口（RxJava）            |
| 扩展性         | 多个扩展点                                     | 插件的形式                    |
| 限流           | 基于 QPS，支持基于调用关系的限流               | 不支持                        |
| 流量整形       | 支持慢启动、匀速器模式                         | 不支持                        |
| 系统负载保护   | 支持                                           | 不支持                        |
| 控制台         | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善                        |
| 常见框架的适配 | Servlet、Spring Cloud、Dubbo、gRPC             | Servlet、Spring Cloud Netflix |

### 2.2. 详细介绍 Config？

#### 概念

![1644387119633](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644387119633.png)

Config，Spring Cloud 官方指定配置中心，在配置管理方面主要提供了三个功能：

- **统一配置**：提供了一个中心化的配置方案，将各个项目中的配置内容，集中在 Config Server 一端。
- **环境隔离**：Config Server 提供了多种环境隔离机制，Client 可以根据自身所处的项目环境（比如测试、生产等）加载对应的配置文件。
- **动态刷新**：支持**运行期间**动态改变配置属性。

#### 架构原理

##### Config Server 原理

![1644387439409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644387439409.png)

###### 1、自动装配

1）启动类

```java
/**
 * 配置中心: 可拉取远端的配置文件
 */
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(ConfigServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }

    //    获取配置文件的不同URL姿势，都是GET请求, 如果不指定{label}的话默认用master
    // 1. http://localhost:60000/{label}/{application}-{profile}.* (yml, properties, json)
    // 2. http://localhost:60000/{application}/{profile}/{label}
}

```

2）@EnableConfigServer

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Import(ConfigServerConfiguration.class)
public @interface EnableConfigServer {

}

```

3）org.springframework.cloud.config.server.config.ConfigServerConfiguration

```java
@Configuration
public class ConfigServerConfiguration {

	@Bean
	public Marker enableConfigServerMarker() {
		return new Marker();
	}

	class Marker {

	}

}

```

4）org.springframework.cloud.config.server.config.ConfigServerConfiguration.Marker

```java
@Configuration
public class ConfigServerConfiguration {

	@Bean
	public Marker enableConfigServerMarker() {
		return new Marker();
	}

	class Marker {

	}

}

```

5）org.springframework.cloud.config.server.config.ConfigServerAutoConfiguration

```java
@Configuration
@ConditionalOnBean(ConfigServerConfiguration.Marker.class)
@EnableConfigurationProperties(ConfigServerProperties.class)
@Import({ 
    	// 环境仓库配置
    	EnvironmentRepositoryConfiguration.class, 
    	CompositeConfiguration.class,
		ResourceRepositoryConfiguration.class, ConfigServerEncryptionConfiguration.class,
    	// Rest接口配置
		ConfigServerMvcConfiguration.class })
public class ConfigServerAutoConfiguration {

}


```

###### 2、环境仓库配置

```java
...
public class EnvironmentRepositoryConfiguration {
    ...
    // 支持JDBC、SVN、GITHUB和本地文件，默认基于GITHUB
	@Configuration
	@ConditionalOnClass(TransportConfigCallback.class)
	static class JGitFactoryConfig {

		@Bean
		public MultipleJGitEnvironmentRepositoryFactory gitEnvironmentRepositoryFactory(
				ConfigurableEnvironment environment, ConfigServerProperties server,
				Optional<ConfigurableHttpConnectionFactory> jgitHttpConnectionFactory,
				Optional<TransportConfigCallback> customTransportConfigCallback) {
			return new MultipleJGitEnvironmentRepositoryFactory(environment, server,
					jgitHttpConnectionFactory, customTransportConfigCallback);
		}

	}

	@Configuration
	@ConditionalOnClass({ HttpClient.class, TransportConfigCallback.class })
	static class JGitHttpClientConfig {

		@Bean
		public ConfigurableHttpConnectionFactory httpClientConnectionFactory() {
			return new HttpClientConfigurableHttpConnectionFactory();
		}

	}
    ...
}

```

###### 3、对外 REST 接口

1）org.springframework.cloud.config.server.config.ConfigServerMvcConfiguration}

```java
@Configuration
@ConditionalOnWebApplication
public class ConfigServerMvcConfiguration extends WebMvcConfigurerAdapter {
    ...
	@Bean
	public EnvironmentController environmentController(
			EnvironmentRepository envRepository, ConfigServerProperties server) {
		EnvironmentController controller = new EnvironmentController(
				encrypted(envRepository, server), this.objectMapper);
		controller.setStripDocumentFromYaml(server.isStripDocumentFromYaml());
		controller.setAcceptEmpty(server.isAcceptEmpty());
		return controller;
	}

	@Bean
	@ConditionalOnBean(ResourceRepository.class)
	public ResourceController resourceController(ResourceRepository repository,
			EnvironmentRepository envRepository, ConfigServerProperties server) {
		ResourceController controller = new ResourceController(repository,
				encrypted(envRepository, server));
		return controller;
	}
    ...
}

```

##### Config Client 原理

- **配置 `${value}`**：某个属性的值，在配置文件中使用 `${value}` 来配置，放到 bootstrap.yml 中配置的话，可以使得其在所有文件加载前加载，从而保证程序顺利完成启动。

- **初始化 `${value}`**：

  ![1644388710373](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644388710373.png)

###### 1、SpringBoot 构建 Context

```java
public class SpringApplication {
    public ConfigurableApplicationContext run(String... args) {
        ...
        prepareContext(context, environment, listeners, applicationArguments,
					printedBanner);
        ...
    }
    
    private void prepareContext(ConfigurableApplicationContext context,
      ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) {
        ...
		applyInitializers(context);
        ...
    }
    
	protected void applyInitializers(ConfigurableApplicationContext context) {
		for (ApplicationContextInitializer initializer : getInitializers()) {
			Class<?> requiredType = GenericTypeResolver.resolveTypeArgument(
					initializer.getClass(), ApplicationContextInitializer.class);
			Assert.isInstanceOf(requiredType, context, "Unable to call initializer.");
			initializer.initialize(context);
		}
	}
}

```

###### 2、加载 initializer

```java
@Configuration
@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)
public class PropertySourceBootstrapConfiguration implements
    ApplicationContextInitializer<ConfigurableApplicationContext>, Ordered {
   	@Override
    public void initialize(ConfigurableApplicationContext applicationContext) {
        ...
        for (PropertySourceLocator locator : this.propertySourceLocators) {
			PropertySource<?> source = null;
			source = locator.locate(environment);
			if (source == null) {
				continue;
			}
			logger.info("Located property source: " + source);
			composite.addPropertySource(source);
			empty = false;
		}
        ...
    }
}

```

###### 3、初始化属性资源

```java
// 越小优先级越高, 0代表最优先执行
@Order(0)
public class ConfigServicePropertySourceLocator implements PropertySourceLocator {
	@Override
	@Retryable(interceptor = "configServerRetryInterceptor")
	public org.springframework.core.env.PropertySource<?> locate(
        org.springframework.core.env.Environment environment) {
        	...
			for (String label : labels) {
                ...
				Environment result = getRemoteEnvironment(restTemplate, properties,
						label.trim(), state);
                ...
            }
        	...
    	}
    }
}	

```

###### 4、拉取远程文件

```java
@Order(0)
public class ConfigServicePropertySourceLocator implements PropertySourceLocator {
	private Environment getRemoteEnvironment(RestTemplate restTemplate,
                                             ConfigClientProperties properties, String label, String state) {
       	String path = "/{name}/{profile}";
		String name = properties.getName();
		String profile = properties.getProfile();
		String token = properties.getToken();
        ...
        ResponseEntity<Environment> response = null;
        ...
        final HttpEntity<Void> entity = new HttpEntity<>((Void) null, headers);
        response = restTemplate.exchange(uri + path, HttpMethod.GET, entity,
                                         Environment.class, args);
        ...
    }
}

```

##### 属性动态刷新原理

![1644390259593](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644390259593.png)

1. **发送刷新请求**：选择一个服务节点，通过 post 请求 `/actuator/refresh`，此后该节点会向 Config Server 发起一个请求。
2. **拉取文件**：Config Server 收到上述节点的请求后，默认会访问 GITHUB，拉取最新的配置内容，并把配制文件下载到本地。
3. **获取更新内容**：服务节点从 ConfigServer 获取并更新配置信息后，然后销毁所有 RefreshScope 作用域的 Bean，由于 @RefreshScope 是懒加载模式，所以下次用到时会重新去 Config Server 中加载。

###### 1、RefreshEndpoint#refresh

```java
@Endpoint(id = "refresh")
public class RefreshEndpoint {

	private ContextRefresher contextRefresher;

	public RefreshEndpoint(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@WriteOperation
	public Collection<String> refresh() {
		Set<String> keys = this.contextRefresher.refresh();
		return keys;
	}

}

```

###### 2、ContextRefresher#refresh

方法逻辑同《BUS - 作业流程 - RefreshRemoteApplicationEvent#refresh》。

```java
public class ContextRefresher {
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
}

```

#### 使用方式

##### Config Server

###### POM 依赖

```xml
<!-- 配置中心化的配置中心: 可拉取远端的配置文件 -->
<dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-config-server</artifactId>
    </dependency>
</dependencies>

```

###### yml 配置

```yaml
server:
  port: 60000

spring:
  application:
    name: config-server
  cloud:
    # 配置配置中心
    config:
      server:
        # 使用git方式拉取配置文件
        git:
          # 强制拉取资源文件, 默认为false
          force-pull: true
          # git仓库地址
          uri: https://github.com/JsonYaoo/config-repo.git
          # git仓库下配置文件所在的子目录名称: eg => abc, def...
#          search-paths:
          # 仓库登录用户名: public项目不需要
#          username:
          # 仓库登录用户密码: public项目不需要
#          password:

```

###### @EnableConfigServer

```java
/**
 * 配置中心: 可拉取远端的配置文件
 */
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(ConfigServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }

    //    获取配置文件的不同URL姿势，都是GET请求, 如果不指定{label}的话默认用master
    // 1. http://localhost:60000/{label}/{application}-{profile}.* (yml, properties, json)
    // 2. http://localhost:60000/{application}/{profile}/{label}
}

```

##### Config Client

###### POM 依赖

```xml
<!-- 配置配置中心的客户端: 拉取配置中心的配置文件属性 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-config</artifactId>
</dependency>

<!-- 配置配置中心的客户端: 动态刷新配置文件 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- 配置高可用的配置中心的客户端: 从Eureka那里拉取配置中心列表 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>

```

###### yaml 配置

```yaml
server:
  port: 61000

spring:
  application:
    name: config-client
  cloud:
    config:
      # 指定拉取配置中心中配置文件的applicationName, 默认为spring application name
      name: config-consumer
      # 指定基础版的配置中心地址
#      uri: http://localhost:60000
      # 指定高可用的配置中心ID
      discovery:
        enabled: true
        service-id: config-server-eureka
      # 指定拉取的配置文件profile, 但一般是在环境中配置(比如args或者系统环境变量中设置)
      profile: prod
      # 指定拉取的配置文件所在的分支, 默认为master
      label: master

# Eureka注册中心地址
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:20000/eureka/

# Actuator配置: 这里主要是为了能够动态刷新配置文件:
management:
  # 已过期, 可不配
#  security:
#    enabled: false
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    health:
      show-details: always

# 通过拉取到的配置文件中的配置属性, 注入到本地的配置变量中
myWords: ${words}

```

###### 测试属性加载

```java
/**
 * 配置中心客户端: 前端控制器
 */
@RestController
public class ConfigClientController {

    /**
     * 测试直接注入配置中心的配置属性
     */
    @Value("${name}")
    private String name;

    /**
     * 测试配置中心注入到本地配置文件的配置属性
     */
    @Value("${myWords}")
    private String words;

    /**
     * 测试直接注入配置中心的配置属性
     * @return
     */
    @GetMapping("/name")
    public String getName(){
        return name;
    }

    /**
     * 测试配置中心注入到本地配置文件的配置属性
     * @return
     */
    @GetMapping("/words")
    public String getWords(){
        return words;
    }
}

```

###### 测试属性动态刷新

```java
/**
 * 配置中心客户端: 动态刷新配置文件
 */
@RestController
@RequestMapping("/refresh")
// 运行期进行刷新这个Bean, 在下一次方法调用时会对所有上下游依赖重新注入
@RefreshScope
public class ConfigClientRefreshController {

    /**
     * 测试配置中心动态刷新到本地配置文件的配置属性
     */
    @Value("${myWords}")
    private String words;

    /**
     * 测试配置中心使用秘钥进行解密
     */
    @Value("${food}")
    private String food;

    /**
     * 测试配置中心动态刷新到本地配置文件的配置属性
     * @return
     */
    @GetMapping("/words")
    public String getWords(){
        return words;
    }

    /**
     * 测试配置中心使用秘钥进行解密
     * @return
     */
    @GetMapping("/dinner")
    public String dinner(){
        return "May I have on " + food;
    }
}

```

### 2.3. 详细介绍 Bus？

#### 概念

Bus，消息总线，可以将消息变更发送给所有的服务节点，从而实现广播状态更改，比如配置变更或者其他管理指令。

#### 架构原理

##### 作业流程

![1644390995665](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644390995665.png)

- **MQ/Kafka**：BUS 只是一个调用的封装，背后还是需要依赖消息中间件，来完成底层的消息分发，实际项目中最常用的还是 RabbitMQ 和 Kafka。
- **BUS**：作为对接上游应用和下游中间件系统的中间层，当接到刷新请求时，会通知底层中间件向所有服务节点推送消息。
- **Refresh 请求**： BUS 节点接收到 refresh 请求后，会发布 RefreshRemoteApplicationEvent 事件，被服务节点监听到后，服务节点会从 ConfigServer 更新配置信息，然后销毁所有 RefreshScope 作用域的 Bean，由于 @RefreshScope 是懒加载模式，所以下次用到时会重新去 Config Server 中加载。

###### 1、请求 bus-refresh

```java
@Endpoint(id = "bus-refresh") // TODO: document new id
public class RefreshBusEndpoint extends AbstractBusEndpoint {

	public RefreshBusEndpoint(ApplicationEventPublisher context, String id) {
		super(context, id);
	}

	...
        
	@WriteOperation
	public void busRefresh() {
		publish(new RefreshRemoteApplicationEvent(this, getInstanceId(), null));
	}
}

```

###### 2、BUS 节点发布 RefreshRemoteApplicationEvent

```java
@SuppressWarnings("serial")
public class RefreshRemoteApplicationEvent extends RemoteApplicationEvent {

	@SuppressWarnings("unused")
	private RefreshRemoteApplicationEvent() {
		// for serializers
	}

	public RefreshRemoteApplicationEvent(Object source, String originService,
			String destinationService) {
		super(source, originService, destinationService);
	}

}

@SuppressWarnings("serial")
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
@JsonIgnoreProperties("source")
public abstract class RemoteApplicationEvent extends ApplicationEvent {
	protected RemoteApplicationEvent(Object source, String originService,
                                     String destinationService) {
        ...
    }
}

```

###### 3、服务节点监听 RefreshRemoteApplicationEvent

```java
public class RefreshListener
		implements ApplicationListener<RefreshRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(RefreshListener.class);

	private ContextRefresher contextRefresher;

	public RefreshListener(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@Override
	public void onApplicationEvent(RefreshRemoteApplicationEvent event) {
		Set<String> keys = this.contextRefresher.refresh();
		log.info("Received remote refresh request. Keys refreshed " + keys);
	}
    
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
}

```

###### 4、服务节点更新配置信息

```java
public class ContextRefresher {
	public synchronized Set<String> refreshEnvironment() {
        // 加载内存中的配置
		Map<String, Object> before = extract(
				this.context.getEnvironment().getPropertySources());
        // 单独启动一个内部容器, 进行新的远程配置加载
		addConfigFilesToEnvironment();
        // 交叉对比、更新配置信息
		Set<String> keys = changes(before,
			extract(this.context.getEnvironment().getPropertySources())).keySet();
        // 发布缓存变更事件
		this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys));
		return keys;
	}
}

```

###### 5、服务节点销毁 RefreshScope 作用域的 Bean

FactoryBean 对象，下次再获取这些 Refresh Scope 的 Bean 后会重新加载。

```java
@ManagedResource
public class RefreshScope extends GenericScope implements ApplicationContextAware,
ApplicationListener<ContextRefreshedEvent>, Ordered {
	public void refreshAll() {
		super.destroy();
		this.context.publishEvent(new RefreshScopeRefreshedEvent());
	}
}

```

##### 事件对象

```java
@SuppressWarnings("serial")
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
@JsonIgnoreProperties("source")
public abstract class RemoteApplicationEvent extends ApplicationEvent {

	private static final Object TRANSIENT_SOURCE = new Object();

	private final String originService;

	private final String destinationService;

	private final String id;
    
    protected RemoteApplicationEvent(Object source, String originService,
                                     String destinationService) {
        ...
    }
}

```

| 维度                | 解释                                                         |
| ------------------- | ------------------------------------------------------------ |
| Source              | 必填，包含一个事件想要表达的信息，可以hi一个自定义可被序列化的对象 |
| Original Service    | 消息来源方，通常是事件发布方的机器 ID 或者 AppID 等          |
| Destination Serivce | 目标机器，BUS 会根据 Destination Serivce 指定的过滤条件（比如服务名、端口等），只让指定的监听者响应事件 |

##### 消息发布者

BUS 通过 /actuator 对外提供 2 个 endpoint 作为消息发布者，可发布 2 种事件。 

###### bus - env

EnvironmentChangeRemoteApplicationEvent，表示一个远程环境变更事件，事件监听者收到这个事件后，会将事件中的 values 添加到 Spring 环境变量中，由 Spring Cloud 的 EnvironmentManager 负责具体处理，从而达到**修改环境变量**的目的。

```java
@SuppressWarnings("serial")
public class EnvironmentChangeRemoteApplicationEvent extends RemoteApplicationEvent {

	private final Map<String, String> values;

	@SuppressWarnings("unused")
	private EnvironmentChangeRemoteApplicationEvent() {
		// for serializers
		this.values = null;
	}

	public EnvironmentChangeRemoteApplicationEvent(Object source, String originService,
			String destinationService, Map<String, String> values) {
		super(source, originService, destinationService);
		this.values = values;
	}

	public Map<String, String> getValues() {
		return this.values;
	}
    ...
}

```

###### bus - refresh

RefreshRemoteApplicationEvent，表示一个远程配置刷新事件，会触发 **@RefreshScope** 所修饰类中的属性刷新。

```java
public class RefreshRemoteApplicationEvent extends RemoteApplicationEvent {

	@SuppressWarnings("unused")
	private RefreshRemoteApplicationEvent() {
		// for serializers
	}

	public RefreshRemoteApplicationEvent(Object source, String originService,
			String destinationService) {
		super(source, originService, destinationService);
	}

}

```

##### 消息监听者

BUS 默认创建了 2 个消息监听器，分别对应上面的两个消息发布 endpoints。

###### bus - env

EnvironmentChangeListener，用于监听远程环境变更事件，将事件中传递的环境变量挨个加入 Spring 本地上下文中。

```java
public class EnvironmentChangeListener
		implements ApplicationListener<EnvironmentChangeRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(EnvironmentChangeListener.class);

	@Autowired
	private EnvironmentManager env;

	@Override
	public void onApplicationEvent(EnvironmentChangeRemoteApplicationEvent event) {
		Map<String, String> values = event.getValues();
		log.info("Received remote environment change request. Keys/values to update "
				+ values);
		for (Map.Entry<String, String> entry : values.entrySet()) {
			this.env.setProperty(entry.getKey(), entry.getValue());
		}
	}

}

```

###### bus - refresh

RefreshListener，用于监听远程配置刷新事件，底层通过触发 EnvironmentChangeEvent 和 RefreshScopeRefreshedEvent 事件，最终实现**属性刷新**。

```java
public class RefreshListener
		implements ApplicationListener<RefreshRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(RefreshListener.class);

	private ContextRefresher contextRefresher;

	public RefreshListener(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@Override
	public void onApplicationEvent(RefreshRemoteApplicationEvent event) {
		Set<String> keys = this.contextRefresher.refresh();
		log.info("Received remote refresh request. Keys refreshed " + keys);
	}
}

public class ContextRefresher {
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
    
	public synchronized Set<String> refreshEnvironment() {
		Map<String, Object> before = extract(
				this.context.getEnvironment().getPropertySources());
		addConfigFilesToEnvironment();
		Set<String> keys = changes(before,
				extract(this.context.getEnvironment().getPropertySources())).keySet();
		this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys));
		return keys;
	}

   	public void refreshAll() {
		super.destroy();
		this.context.publishEvent(new RefreshScopeRefreshedEvent());
	}
}

```

##### 发布 - 订阅模型

![1644392911868](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644392911868.png)

BUS 事件推送由三个角色构成：

- 事件对象：BUS 事件类，通常是一个 Pojo 对象，包含消费者需要的信息。
- 事件发布：BUS 消息生产者，将事件对象通过广播的形式发布出去。
- 事件监听：由 BUS 事件消费者监听 BUS 事件的发布动作，当获取到事件对象后，会调用处理方法进行消费。

###### 1、自定义事件对象

```java
public class MyEvent extends RemoteApplicationEvent {

   public MyEvent() {
   }

   public MyEvent(Object body, String originService, String destinationService) {
       super(body, originService, destinationService);
   }
}


```

###### 2、注册事件对象

```java
@Configuration
@RemoteApplicationEventScan(basePackageClasses = MyEvent.class)
public class BusExtConfiguration {

}


```

###### 3、监听事件

```java
@Component
public class MyEventListener implements ApplicationListener<MyEvent> {
    
    @Override
    public void onApplicationEvent(MyEvent event) {
        logger.info("Received MyCustomRemoteEvent - message: ");
    }
}


```

###### 4、发布事件

```java
@PostMapping("/bus/publish/myevent")
public boolean publishMyEvent(@RequestBody EventBody body) {
   MyEvent event = new MyEvent(body, applicationContext.getId(), "");
   try {
       // 可以注入ApplicationEventPublisher来发送event
       eventPublisher.publishEvent(event);
       // 也可以直接使用 
       // applicationContext.publishEvent(event)
       return true;   
   } catch (Exception e) {
            log.error("failed in publishing event", e);  
   }  
   return false;
}


```

#### 应用场景

- **清空缓存**：通知所有服务监听者清空某项业务的本地缓存信息，也可以在消息体中加入具体的业务属性，使其定点清除某个特定业务对象的缓存。
- **数据同步**：子系统依赖实时的数据库记录变动，触发相应的业务逻辑，比如可以把 binlog 抓取出来，通过广播功能同步到所有监听器，从而起到数据同步的作用。

### 2.4. 详细介绍 Stream？

#### 概念

Spring Cloud Stream，是基于 Spring Boot 构建的，专门用于**消息驱动服务**所设计的应用框架，底层使用 Spring Integration（一体化） 来为消息代理层提供网络连接支持。

![1644397898722](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644397898722.png)

| 关键词               | 解释                                                         |
| -------------------- | ------------------------------------------------------------ |
| 应用模型             | Stream 提供了应用模型的抽象，引入了三个角色，分别是输入通道 Input、输出通道 Output 和通道与底层中间件之间的代理 Binder |
| 适配层抽象           | Stream 将组件与底层中间件之间的通信过程抽象成了 Binder 层，使得应用层不需要关心底层中间件是 Kafka 还是 RabbitMQ，只需要关注自身的业务逻辑就好 |
| 插件式适配层         | Binder 层采用一种插件形式来提供服务，开发人员可以很方便地自定义适配逻辑 |
| 持久化的发布订阅模型 | 发布订阅是所有消息组件最核心的功能                           |
| 消费组               | Stream 允许将多个 Consumer 加入到一个消费者组，作用是确保一条消息只被组内的一个实例消费 |
| 分区                 | Stream 支持在多个消费者实例之间创建分区，以便于通过某些特征量做消息分发，保证相同标识的消息**总是**能被同一个消费者处理 |

#### 架构原理

![1644398403640](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644398403640.png)

Stream 体系架构主要包括 Input、Output 和 Binder 三部分组成：

##### Input 通道

Input，输入通道（Spring 输入到消息队列），作用是将消息组件中获取到的 Message 传递给消息者进行消费，使用 Stream 可以在接口中使用 @Iutput 注解，声明并定义一个输出通道。

```java
public interface MyTopic {
    @Input
    SubscribableChannel input();
}

```

##### Output 通道

Output，输出通道（消息队列输出到 Spring），作用是把生产者生产的新消息发送到对应的 Topic 中去，使用 Stream 可以在接口中使用 @Output 注解，声明并定义一个输出通道。

```java
public interface MyTopic {

	// 这里可以给Output自定义目标通道名称，比如@Output("myTarget")
    @Output
    MessageChannel output();
}

```

##### Binder

- Stream 提供了一个 Binder 抽象层，作为连接外部消息中间件的桥梁，针对每一个不同的 Broker（比如 Kafka 或者 RabbitMQ），Stream 都有一个对应的 Binder 具体实现来做适配。
- Broker 作为一个适配层，对上层应用程序和底层消息组件之间做了一层屏障，使得应用程序无需关注底层的中间件，只管用注解开启响应的消息通道，剩下的事交给 Binder 来搞定就行。
- 而在更改底层中间件时，只需要变更 Binder 的依赖项，然后修改配置文件就可以了，对于应用程序来说几乎是无感知的。 

![1644399728162](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644399728162.png)

##### 目的地绑定

如果想要 @Input 和 @Output 使用不同名字，但又想绑定同一个 Topic，那么可以进行目的地绑定配置：

```properties
spring.cloud.stream.bindings.<@Input名/@Output名>.destination=<Topic名>

```

#### 使用方式

##### 公共消息实体

```java
/**
 * Stream测试应用: 消息实体
 */
@Data
public class MessageBean {

    /**
     * 消息体
     */
    private String payload;
}

```

##### 广播消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 广播Topic
 */
public interface BroadcastTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "broadcastTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "broadcastTopic-producer";

    /**
     * BroadcastTopic Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * BroadcastTopic Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 配置Stream自定义广播消息Topic: 绑定消费者、生产者信道到broadcastTopic
spring.cloud.stream.bindings.broadcastTopic-consumer.destination=broadcastTopic
spring.cloud.stream.bindings.broadcastTopic-producer.destination=broadcastTopic

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {    
    /**
     * 快速入门 HelloWord: 测试消费者消费
     * @param payload
     */
    // Stream默认的信道, 用于测试消费者消费
    @StreamListener(Sink.INPUT)
    public void consumer(Object payload) {
        log.info("message consumed successfully, payload={}", payload);
    }

    /**
     * 测试自定义广播消息
     * @param payload
     */
    @StreamListener(BroadcastTopic.INPUT)
    public void consumerBroadcastTopic(Object payload) {
        log.info("Broadcast message consumed successfully, payload={}", payload);
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private BroadcastTopic broadcastTopic;
    
    /**
     * 测试广播: 写@RequestParams后, 如果value没变, 但入参名称变了还是可以保持请求报文入参不变, 便于维持前端代码不变
     * @param body
     */
    @PostMapping("send")
    public void sendMessage(@RequestParam(value = "body") String body){
        Message<String> message = MessageBuilder.withPayload(body).build();
        broadcastTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

##### 单播消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 单播Topic
 */
public interface GroupTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "groupTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "groupTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试单播: 绑定消费者、生产者信道到groupTopic
spring.cloud.stream.bindings.groupTopic-consumer.destination=groupTopic
spring.cloud.stream.bindings.groupTopic-producer.destination=groupTopic

# 测试单播: 配置消费者分组 => 实际上是一个组一个queue, 每个queue有多个Consumer
spring.cloud.stream.bindings.groupTopic-consumer.group=GroupA

# 测试单播: 配置消息分区 => 经测试可知, 消息分区和消费组可以合起来使用, 消费组可用来实现单播(组内轮训消费), 消息分区可用来隔离消费组(只有满足条件即SpEL匹配的消费组才能消费消息)
# 打开消费者的消费分区功能
spring.cloud.stream.bindings.groupTopic-consumer.consumer.partitioned=true
# 指定当前消费者实例的总数
spring.cloud.stream.instance-count=2
# 指定当前消费者实例的索引号, 最大值为count-1, 用于测试消息分区
spring.cloud.stream.instance-index=1
# 指定生产者拥有两个消息分区
spring.cloud.stream.bindings.groupTopic-producer.producer.partition-count=2
# SpEL => Key Resolver解析, 表示只有节点为1的消费者才能消费消息, 即SpEL匹配才能消费
spring.cloud.stream.bindings..groupTopic-producer.producer.partition-key-expression=1

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {    
    /**
     * 测试单播消息
     * @param payload
     */
    @StreamListener(GroupTopic.INPUT)
    public void consumerGroupTopic(Object payload) {
        log.info("Group message consumed successfully, payload={}", payload);
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private GroupTopic groupTopic;
    
    /**
     * 测试单播
     * @param body
     */
    @PostMapping("sendToGroup")
    public void sendMessageToGroup(@RequestParam(value = "body") String body){
        Message<String> message = MessageBuilder.withPayload(body).build();
        groupTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

##### 延迟消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 延迟Topic，需要中间件支持延迟消息
 */
public interface DelayedTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "delayedTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "delayedTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试延迟消息: 绑定消费者、生产者信道到delayedTopic
spring.cloud.stream.bindings.delayedTopic-consumer.destination=delayedTopic
spring.cloud.stream.bindings.delayedTopic-producer.destination=delayedTopic

# 测试延迟消息: 生产者允许生成延迟交换机与延迟队列(都只有一个)
spring.cloud.stream.rabbit.bindings.delayedTopic-producer.producer.delayed-exchange=true

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试延迟消息
     * @param messageBean
     */
    @StreamListener(DelayedTopic.INPUT)
    public void consumerDelayedTopic(MessageBean messageBean) {
        log.info("Delayed message consumed successfully, payload={}", messageBean.getPayload());
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private DelayedTopic delayedTopic;
    
    /**
     * 测试延迟消息
     * @param body
     */
    @PostMapping("sendDelayedMessage")
    public void sendDelayedMessage(@RequestParam(value = "body") String body,
                                   @RequestParam(value = "seconds") Integer seconds){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);

        log.info("ready to send delayed message");

        // 注意, Rabbitmq延迟消息必须在header里添加x-delay参数: 表示多少ms后延迟队列会对延迟消息进行消费
        Message<MessageBean> message = MessageBuilder
                .withPayload(msg)
                .setHeader("x-delay", 1000 * seconds)
                .build();
        delayedTopic.output().send(message);

        log.info("发送完毕 {}" + message);
    }
}

```

##### 异常重试

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
 */
public interface ExceptionTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "exceptionTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "exceptionTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitm: 绑定消费者、生产者信道到exceptionTopic
spring.cloud.stream.bindings.exceptionTopic-consumer.destination=exceptionTopic
spring.cloud.stream.bindings.exceptionTopic-producer.destination=exceptionTopic

# 测试测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitm: 配置本机重试次数, 次数为1代表不重试
spring.cloud.stream.bindings.exceptionTopic-consumer.consumer.max-attempts=2

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
 
    /**
     * 异常重试计数器
     */
    private AtomicInteger count = new AtomicInteger(1);

    @Autowired
    private ExceptionTopic exceptionTopic;
    
    /**
     * 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
     * @param messageBean
     */
    @StreamListener(ExceptionTopic.INPUT)
    public void consumerExceptionTopic(MessageBean messageBean) {
        log.info("Are you OK?");

        // 由于初始值为1, 所以只会重试2次就成功了
        if(count.incrementAndGet() % 3 == 0){
            log.info("Fine, thank you. And you?");
            // 清0, 下次重试测试时, 由于初始值是0, 当重试次数用完还是有异常, 则会一次性抛出所有异常, 否则如果最终能消费成功, 则不会抛出异常
            count.set(0);
        } else {
            log.info("What's your problem?");
            throw new RuntimeException("I'm not OK!");
        }
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private ExceptionTopic exceptionTopic;
    
    /**
     * 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
     * @param body
     */
    @PostMapping("sendException")
    public void sendException(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        exceptionTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

##### 重回队列

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
 */
public interface RequeueTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "requeueTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "requeueTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部: 绑定消费者、生产者信道到requeueTopic
spring.cloud.stream.bindings.requeueTopic-consumer.destination=requeueTopic
spring.cloud.stream.bindings.requeueTopic-producer.destination=requeueTopic

# 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部: 对指定Consumer配置重新入队
#spring.cloud.stream.rabbit.bindings.requeueTopic-consumer.consumer.requeueRejected=true
# 默认全局开启Direct重新入队(不过会被Consumer重试覆盖)
#spring.rabbitmq.listener.direct.default-requeue-rejected=true
# 所以配置Consumer只能重试1次
spring.cloud.stream.bindings.requeueTopic-consumer.consumer.max-attempts=1
# 测试不同分组的消费者消费Requeue消息 => 实际上Group、Topic的名称最好都用-作为连接, 而不是驼峰标识
spring.cloud.stream.bindings.requeueTopic-consumer.group=requeue-group

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
     * @param messageBean
     */
    @StreamListener(RequeueTopic.INPUT)
    public void consumerRequeueTopic(MessageBean messageBean) {
        log.info("Are you OK?");

        try {
            Thread.sleep(3000);
        } catch (Exception e) {
            // do nothing
        }

        throw new RuntimeException("I'm not OK!");
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private RequeueTopic requeueTopic;
    
    /**
     * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
     * @param body
     */
    @PostMapping("requeue")
    public void requeue(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        requeueTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

##### 死信队列

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试死信队列Topic
 */
public interface DlqTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "dlqTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "dlqTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试死信队列Topic: 绑定消费者、生产者信道到dlqTopic
spring.cloud.stream.bindings.dlqTopic-consumer.destination=dlqTopic
spring.cloud.stream.bindings.dlqTopic-producer.destination=dlqTopic
spring.cloud.stream.bindings.dlqTopic-consumer.consumer.max-attempts=2
spring.cloud.stream.bindings.dlqTopic-consumer.group=dlq-group
# 开启死信队列(默认名称为${dlqTopic}.dlq, 复杂的需要自己指定DLK), 允许指定Consumer绑定DLQ
# => rabbitmq-plugins enable rabbitmq_shovel rabbitmq_shovel_management, 管理控制台开启重推消息其他队列功能
spring.cloud.stream.rabbit.bindings.dlqTopic-consumer.consumer.auto-bind-dlq=true

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试死信队列Topic
     * @param messageBean
     */
    @StreamListener(DlqTopic.INPUT)
    public void consumerDlqTopic(MessageBean messageBean) {
        log.info("DLQ: Are you OK?");

        // 由于初始值为1, 所以只会重试2次就成功了
        if(count.incrementAndGet() % 3 == 0){
            // 死信队列重推消息到该队列时, 由于count已经大于3, 则会消费成功
            log.info("DLQ: Fine, thank you. And you?");
        } else {
            // 当重试次数用完还是有异常, 则会一次性抛出所有异常, 进入死信队列, 否则如果最终能消费成功, 则不会抛出异常
            log.info("DLQ: What's your problem?");
            throw new RuntimeException("DLQ: I'm not OK!");
        }
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private DlqTopic dlqTopic;
    
    /**
     * 测试Stream应用: 测试死信队列Topic
     * @param body
     */
    @PostMapping("dlq")
    public void dlq(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        dlqTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

##### 异常降级

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常降级, 自定义异常逻辑 + 接口升版
 */
public interface FallbackTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "fallbackTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "fallbackTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}

```

###### 2、目的地绑定

```properties
# 测试异常降级, 自定义异常逻辑 + 接口升版: 绑定消费者、生产者信道到dlqTopic
spring.cloud.stream.bindings.fallbackTopic-consumer.destination=fallback-Topic
spring.cloud.stream.bindings.fallbackTopic-producer.destination=fallback-Topic
spring.cloud.stream.bindings.fallbackTopic-consumer.consumer.max-attempts=2
spring.cloud.stream.bindings.fallbackTopic-consumer.group=fallback-group
# errors 是规定写死的
# inputChannel => fallback-Topic.fallback-group.errors

```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试异常降级, 自定义异常逻辑 + 接口升版
     * @param messageBean
     */
    @StreamListener(FallbackTopic.INPUT)
    public void consumerFallbackTopic(MessageBean messageBean, @Header("version") String version) {
        log.info("Fallback: Are you OK?");

        // 接口升版: 可以根据不同的版本走不同的逻辑
        if("1.0".equalsIgnoreCase(version)){
            log.info("Fallback: Fine, thank you. And you?");
        } else if("2.0".equalsIgnoreCase(version)){
            // 当重试次数用完还是有异常, 则会一次性抛出所有异常, 进入具体异常降级逻辑, 否则如果最终能消费成功, 则不会抛出异常
            log.info("Fallback: unsupported version?");
            throw new RuntimeException("Fallback: I'm not OK!");
        } else {
            log.info("Fallback: version={}", version);
        }
    }

    /**
     * 具体异常降级逻辑
     * @param message
     */
    // 当前方法用于处理MQTT消息, inputChannel参数指定了用于接收消息的channel
    @ServiceActivator(inputChannel = "fallback-Topic.fallback-group.errors")
    public void fallback(Message<?> message){
        log.info("fallback entered, message={}", message);
    }
}

```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private FallbackTopic fallbackTopic;
    
    /**
     * 测试Stream应用: 测试异常降级, 自定义异常逻辑 + 接口升版
     * @param body
     */
    @PostMapping("fallback")
    public void fallback(@RequestParam(value = "body") String body,
                         @RequestParam(value = "version", defaultValue = "1.0") String version){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        // 设置接口版本: V1 => queue1, V2 => queue2
        Message<MessageBean> message = MessageBuilder
                .withPayload(msg)
                .setHeader("version", version)
                .build();
        fallbackTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}

```

#### 应用场景

![1644400521818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644400521818.png)

在每次运营修改商品数据时，如果帧听到主属性发生变化，需要清空本地缓存和 Tair 缓存中，所有保存了该商品额度数据，可以用发布订阅模式来解决：每次主商品发生修改时， 会向 MetaQ 发布一条对应 Topic 的消息，此时可以对这个 Topic 配置一个广播和单播的监听器：

- **广播组**：包括所有商品详情页的后台服务节点，商品修改的消息被每个服务节点消费，清空它们本地缓存中对应的商品信息。
- **单播组**：单播消息只会被消费一次，用于删除 Tair 分布式缓存中对应的商品信息，因此，这里只配置了一个消费组，保证消息只会被组内的某一台机器所消费。

### 2.5.  详细介绍 Sleuth？

#### 概念

![1644458483392](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644458483392.png)

Sleuth，中文意思大侦探，是为了对微服务之间调用链进行跟踪的一个组件，在一个用户请求发起到结束的整个过程中，该 Request 经过的所有服务都会  Sleuth 梳理出来，从而很容易就可以追溯链路上下游所有的调用。

#### 优点

- **无业务侵入**：Sleuth 在设计上秉承低侵入的概念，无需对业务代码做任何改动，即可静默接入链路追踪功能。
- **高性能**：一般认为在代码里加入完善的同步 log（10 行代码对应 2 条 log），会让接口降低 5% 左右的性能，而通过链路追踪在 log 里做埋点，多多少少也会影响一定性能的，所以 Sleuth 在埋点过程中力求性能影响降低到最小，同时还提供了**采样率配置**来进一步降低开销。

#### 架构原理

##### 集成 Log 系统

- Sleuth 底层采用集成 Log 系统来实现业务埋点，链路信息会传递给底层 log 组件，同时 log 组件会在每行 log 头部输出这些数据。

- log 业务埋点，就需要把链路追踪信息加入开发人员写的业务 log 中，而不是 Sleuth 生产出一行 log，所以，Sleuth 使用 `MDC` + `Format Pattern` 的方式输出信息。

- 比如，当使用 `log.info` 打印日志时，Log 组件会将写入动作，封装成一个 LogEvent 事件，用于生成 Log 文件，而这个事件的具体表现形式由 `MDC` + `Format Pattern` 共同控制：

  - `Format Pattern`：决定了 log 的输出样式，其中集成 Sleuth 后的 log 输出格式为：

    ```properties
    "%5p [sleuth-traceA,%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]"
    
    ```

  - `MDC`：决定了 log 输出内容，其通过 InheritableThreadLocal 来实现，可以携带当前线程的上下文信息，Sleuth 借助了 AOP 机制，在方法调用时配置了切面，将链路追踪数据加入到了 `MDC` 中，这样在 log 打印时就能从 `MDC` 获取到这些值，然后填入 `Format Pattern` 中配置的占位符了。

![1644459405453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644459405453.png)

##### Sleuth 数据结构

- **Trace**：
  - 由一系列 spans 组成的一个树状结构，包含一个请求从头贯穿到尾的调用链 ID，即 TraceID。
  - 在一次请求中，不管调用链中途访问了多少服务节点，在每个节点 log 中打印的都是同一个 TraceID。
- **Span**：
  - Sleuth 的一个基本工作单元，包含一个独一无二的单元 ID，即 SpanID，在服务 A 发起对服务 B 的调用，这个事件就可以看作是一个独立单元，生成一个独立的 SpanID。
  - Span 还包含了时间戳，用于标识一个事件从开始到结束经过的时间，可用于统计接口的执行时间。
  - Span 还包含了一些特殊的标记 Annotation，用于标识这个 Span 在执行过程中发起的一些特殊事件。
- **Annotation**：
  - 标记，用来及时记录一个事件的存在，一个 Span 可以包含多个 Annotation，每个 Annotation 表示一个**特殊事件**，同时含有一个时间戳字段，可以用来分析一个 Span 内每个事件的起始和结束时间。
    - **Client Sent**：cs，客户端发起一个请求，描述了某个 span 的开始。
    - **Server Received**：sr，服务端获得请求并准备开始处理它，sr - cs = 本次请求的网络延迟时间。
    - **Server Sent**：ss，服务端请求处理完成，将要把 Response 返回给客户端，ss - sr = 本次请求服务端处理的时间。
    - **Client Received**：cr，客户端成功接收到服务端的回复，表示一个 span 的结束，cr - cs = 客户端从服务端获取回复所需的时间。

![1644460217838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644460217838.png)

##### 服务节点间的 ID 传递

Sleuth 通过 Filter 向 Http Header 中添加链路追踪信息，使得下游系统可以识别出当前的 TraceID 以及前置的 SpanID 是什么。

| 请求头名称        | 请求头内容     | 解释            |
| ----------------- | -------------- | --------------- |
| X-B3-TraceId      | Trace ID       | 链路全局唯一 ID |
| X-B3-SpanId       | Span ID        | 当前 Span ID    |
| X-B3-ParentSpanId | Parent Span ID | 前置 Span ID    |
| X-Span-Export     | boolean        | 是否可以被采样  |

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>

<!-- Logstash for ELK，非Sleuth！ -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>5.2</version>
</dependency>

```

##### 采样率配置

```properties
# Sleuth采样率配置 => eg: 1为100%收集, 但如果没有Zipkin收集的话, 显示还是为false
spring.sleuth.sampler.probability=1

```

##### 控制台日志格式配置

```xml
<!-- 日志格式： 关键是 -%5p 
	 对应的输出内容：10:53:47.520  INFO [-,,,] 14264 --- [           main] msg...
-->
<property name="CONSOLE_LOG_PATTERN"
          value="%clr(%d{HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}" />

```

##### LogStash 日志格式配置

```xml
<!-- Logstash -->
<!-- 为logstash输出的JSON格式的Appender -->
<appender name="logstash"
          class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    <destination>192.168.1.150:5044</destination>
    <!-- 日志输出编码 -->
    <encoder
             class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
        <providers>
            <timestamp>
                <timeZone>UTC</timeZone>
            </timestamp>
            <pattern>
                <pattern>
                    {
                    "severity": "%level",
                    "service": "${springAppName:-}",
                    "trace": "%X{X-B3-TraceId:-}",
                    "span": "%X{X-B3-SpanId:-}",
                    "exportable": "%X{X-Span-Export:-}",
                    "pid": "${PID:-}",
                    "thread": "%thread",
                    "class": "%logger{40}",
                    "rest": "%message"
                    }
                </pattern>
            </pattern>
        </providers>
    </encoder>
</appender>

```

#### 应用场景

借助 Sleuth 的链路追踪能力，还可以完成一些其他的任务：

- **线上故障定位**：结合 TracingID + ELK 可以寻找出上下游链路中所有的日志信息，来协助定位故障。
- **依赖分析梳理**：梳理上下游依赖关系，理清整个系统中所有微服务之间的依赖关系。
- **链路优化**：通过对链路调用情况的统计分析，识别出转化率最高的业务场景，从而为以后的产品设计提供指导意见。
- **性能分析**：梳理各个环节的时间消耗，找出性能瓶颈，为性能优化、软硬件资源调配指明方向。

### 2.6. 详细介绍 Gateway？

#### 网关层概念

##### 背景

1. **路由维护成本高**：微服务下，部署包非常多，提供给外部用户访问的 url+端口也各不相同，如果由前端负责配置，则会拖慢项目进度，且页面在一大堆 url 跳来跳去，用户体验可能也不好，如果由运维团队负责配置，则增加、删除服务节点，导致的 IP 变化时又要重新配置，十分麻烦。
2. **安全性问题**：不同服务的访问控制可能会不一样，如果让每个服务都实现同样的访问验证逻辑，未免有些太繁琐，且如果有一天需要更改权限认证方案，所有服务都得跟着改，也是麻烦。

##### 架构

引入网关层后，微服务架构变更为以下样子，网关层作为唯一的对外服务，外部请求不直接访问服务层，而是由网关层承接所有的 Http 请求，且可与 Nginx 一同使用。

![1644463270083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644463270083.png)

##### 作用

- **路由规则**：解决**微服务路由维护成本高**的问题，包含 2 个方面：
  1. **服务寻址**：依赖微服务的服务发现机制和负载均衡机制，实现服务寻址和负载均衡。
  2. **URL 映射**：客户端访问的 URL 不再是真实的路径，是需要经过网关层的路径规则，把来访的 URL 映射成真正的服务路径，再去请求对应的服务。
- **访问控制**：访问控制的具体实现并不是由网关层提供，但网关层却是作为一个载体，承载 2 个相关方面的任务：
  - **拦截请求**：网关层可以检查访问请求中，是否携带令牌等身份信息，如果没有说明还没有登录，则直接返回 403 即可。
  - **鉴权**：对于携带有令牌的请求，网关层还可以调用其他服务，来验证令牌的真假，对令牌校验失败或者已过期的请求，拒绝执行服务请求。

#### Gateway 概念

- Gateway，是 Spring Cloud 中的第二代网关，⽬标是取代 Zuul，在各项指标上都领先 Zuul。
- Gateway，基于 Spring 5.0 + SpringBoot 2.0 + WebFlux + Netty 等技术开发，提供**统⼀的路由**⽅式，并且**基于 Filter 链**的⽅式提供了⽹关基本的功能，比如：鉴权、流量控制、熔断、路径重写、⽇志监控等。

#### 架构原理

##### 集成 Netty

![1644474442817](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644474442817.png)

Netty，是一个非阻塞、高性能、高可靠的异步输入输出框架，在网络领域是黄金 AK 般的存在，性能非常高，其在 Gateway 中主要应用在以下几个地方：

1. **发起服务调用**：由 NettyRoutingFilter 实现，底层基于 Netty#Http Client 来发起外部服务调用。
2. **Response 调用**：由 NettyResponseFilter 实现，外部服务调用结束后，把 Response 回传给 Gateway 调用者。
3. **Socket 连接**：Gateway 的 Socket 连接具体由 ReactorNettyWebSocketClient 类承接，其底层也是基于 Netty#Http Client 发起连接请求。

=> 客户端发起请求到 Gateway，由 NettyRoutingFilter 底层的 Netty#HttpClient 向服务发起调用，调用结束后的 Response 再由 NettyResponseFilter 回传给客户端，可见，Netty 贯穿了从 Request 发起到 Response 结束的整个过程，承担了所有和网络调用相关的任务，也因为有了 Netty 的加持，Gateway 相对于 Zuul 1.x#Servlet 网络请求效率大幅提升。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
	@Configuration
    // reactor.netty.http.client.HttpClient
	@ConditionalOnClass(HttpClient.class)
    protected static class NettyConfiguration {
        @Bean
		@ConditionalOnMissingBean
        public HttpClient httpClient(HttpClientProperties properties) {
            ...
        }
        
		@Bean
		public HttpClientProperties httpClientProperties() {
			return new HttpClientProperties();
		}

		@Bean
		public NettyRoutingFilter routingFilter(HttpClient httpClient,
				ObjectProvider<List<HttpHeadersFilter>> headersFilters,
				HttpClientProperties properties) {
			return new NettyRoutingFilter(httpClient, headersFilters, properties);
		}

		@Bean
		public NettyWriteResponseFilter nettyWriteResponseFilter(
				GatewayProperties properties) {
			return new NettyWriteResponseFilter(properties.getStreamingMediaTypes());
		}

		@Bean
		public ReactorNettyWebSocketClient reactorNettyWebSocketClient(
				HttpClient httpClient) {
			return new ReactorNettyWebSocketClient(httpClient);
		}
    }
}

```

##### Gateway 自动装配

![1644475101295](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644475101295.png)

- **GatewayAutoConfiguration**：核心自动装配主类，负责初始化所有的 Route 路由规则、Predicate 断言工厂和 Filter 过滤器（包括 Global Filter 和 Route Filter），以及加载 Netty 相关配置，用于完成基本的路由功能。
- **GatewayLoadBalancerClientAutoConfiguration**：在 GatewayAutoConfiguration 自动装配完成后，负责加载 Ribbon 和一系列负载均衡配置。
- **GatewayClassPathWarningAutoConfiguration**：在 GatewayAutoConfiguration 自动装配完成后，负责检查项目中的 Spring WebFlux 是否加载了正确的配置。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
    ...// 初始化路由规则、断言工厂、过滤器等Bean
}

```

- **GatewayRedisAutoConfiguration**：负责限流功能的自动装配。
- **GatewayMetricsAutoConfiguration**：负责做一些统计的工作，比如运行时长和调用次数的统计。
- **GatewayDiscoveryClientAutoConfiguration**：负责服务发现功能的自动装配。

```properties
# Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.cloud.gateway.config.GatewayClassPathWarningAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayLoadBalancerClientAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayNoLoadBalancerClientAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayMetricsAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayRedisAutoConfiguration,\
org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration
org.springframework.boot.env.EnvironmentPostProcessor=\
org.springframework.cloud.gateway.config.GatewayEnvironmentPostProcessor

```

##### Route 数据结构

![1644475772551](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644475772551.png)

Route，路由，是**最基础的工作单元**，Gateway 中可以定义很多个 Route，一个 Route 就是一套包含完整转发规则的路由，主要由三部分组成：

- **断言集合**：Predicates，是路由处理的第一个环节，是路由的匹配规则，决定了一个网络请求是否可以匹配给当前 Route 来处理，当 Route 断言集合中的每个 Predicate 都匹配成功以后，才算匹配 Route，才能走到 Filter 环节。
- **过滤器集合**：Filters，如果请求通过了前面的 Predicate，那么就表示该请求正式被当前 Route 路由接手了，接下来就需要经过一系列的过滤器集合，在请求前或者后执⾏业务逻辑。
- **UR**I：如果请求顺利通过了过滤器的处理，那么接下来就是转发请求了，URI 是统一资源标识符，可以是一个具体的网址，也可以是 IP+端口，也可以是在 Eureka 中注册的服务名称。

```java
public class Route implements Ordered {

	private final String id;

	private final URI uri;

	private final int order;

	private final AsyncPredicate<ServerWebExchange> predicate;

	private final List<GatewayFilter> gatewayFilters;
   	...
    public static class Builder extends AbstractBuilder<Builder> {

		protected Predicate<ServerWebExchange> predicate;
        ...
    }
}

```

##### Route 工作流程

![1644476775581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644476775581.png)

- **RoutePredicateHandlerMapping**：获取所有已配置的路由集，然后依次循环每个 Route，把本次请求与 Route 中配置的所有断言进行匹配，选定该**第一个**所有的断言**都通过**的 Route 来接手后面的工作。
- **FilteringWebHandler**：在前一步选中 Route 后，由 FilteringWebHandler 把请求交给过滤器，不仅当前 Route 的过滤器会生效，在项目中添加的全局过滤器 Global Filter 也会生效，在请求前或者后执⾏业务逻辑：
  - **请求前 `pre` 类型过滤器**：参数校验、权限校验（鉴权）、流量监控、⽇志输出、协议转换等。
  - **请求后 `post` 类型过滤器**：响应内容、响应头修改、⽇志输出、流量监控等。
- **寻址**：如果请求顺利通过了过滤器的处理，那么接下来就是转发请求了，URI 可以是一个具体的网址，也可以是 IP+端口，也可以是在 Eureka 中注册的服务名称：
  - **负载均衡**：Gateway 转发过程可以采用 Eurea 注册的服务名称方式来调用，底层借助 Ribbon 来实现负载均衡，配置方式为 `lb://服务名称/`。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
    ...
	@Bean
	public RoutePredicateHandlerMapping routePredicateHandlerMapping(
			FilteringWebHandler webHandler, RouteLocator routeLocator,
			GlobalCorsProperties globalCorsProperties, Environment environment) {
		return new RoutePredicateHandlerMapping(webHandler, routeLocator,
				globalCorsProperties, environment);
	}
    ...
}

```

##### 断言 Predicate

Gateway 提供了十多种内置的断言，常用的有：

| 内置断言种类 | 用法                                                         | 作用                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 路径断言     | .route(r -> r.path("/gateway/**").uri(...))                  | 当请求的URL与断言中的 "/gateway/**"规则匹配，才继续下发（下发到过滤、url 转发中） |
| 方法断言     | .route(r -> r.path("/gateway/**").and().method(HttpMethod.GET).uri(...)) | 当请求的 Http Method 与断言中的匹配时，才继续下发            |
| 请求参数断言 | .route(r -> r.path("/gateway/**").and().and().query("name", "test").and().query("age").uri(...)) | 分为属性名验证（名称相同即算匹配）和属性值验证（名称+值都相同才算匹配），才继续下发 |
| 请求头断言   | .route(r -> r.path("/gateway/**").and().header("Authorization").uri(...)) | 分为属性名验证（名称相同即算匹配）和属性值验证（名称+值都相同才算匹配），才继续下发 |
| Cookie断言   | .route(r -> r.path("/gateway/**").and().cookie("name", "test").uri(...)) | 只有当名称+值都相同才算匹配，才继续下发                      |
| 时间片断言   | .route(r -> r.path("/gateway/**")<br/>.and().before(ZonedDateTime.now().plusMinutes(1)).uri(...)) | 分为 Before、Between 和 After 三种，分别指定了是在是什么时间之前、之间、之后才算匹配，才继续下发 |

##### 过滤器 Filter

Gateway 中的过滤器，会经过优先级排列，所有网关调用请求从最高优先级的过滤器开始，一路走到被最后一个过滤器处理才返回。

###### 按执行阶段分

1）**请求前 `pre` 类型过滤器**：order=0，代表优先级最低，越晚被执行，order=MAX，代表优先级最高，越早被执行。

```java
@Override
public GatewayFilter apply(NameValueConfig config) {
	return (exchange, chain) -> {
        // 在Response中添加Header信息
        exchange.getResponse().getHeaders().add(config.getName(), config.getValue());
        return chain.filter(exchange);
    };
}

```

2）**请求后 `post` 类型过滤器**：与 pre 相反，order=0，代表优先级最高，越早被执行，order=MAX，代表优先级最低，越晚被执行。

```java
return chain.filter(exchange)
    	// then是回调函数，在下级调用链路都完成以后才被执行
    	.then(Mono.fromRunnable(() -> {
		// 业务逻辑...
		}));

```

###### 按功能类型分

1）**请求头过滤器**：

```java
// 为Response增加who请求头
.filters(f -> f.addResponseHeader("who", "gateway-header"))

```

2）**前缀截断过滤器**：

```java
.route(r -> r.path("/gateway-test/**")
       		// 截取去掉/gateway-test前缀
             .filters(f -> f.stripPrefix(1))
             .uri("lb://FEIGN-SERVICE-PROVIDER/")
)

```

3）**前缀加入过滤器**：

```java
.route(r -> r.path("/gateway-test/**")
       		// 在/gateway-test前面加入/go/前缀
             .filters(f -> f.prefixPath("go"))
             .uri("lb://FEIGN-SERVICE-PROVIDER/")
)

```

4）**重定向过滤器**：

```java
.filters(f -> f.redirect(302, "https://www.imooc.com/"))

```

5）**会话过滤器**：

```java
// 基于Spring-Session或者Spring-Security时，在调用服务前强制保存Session
.filters(f -> f.saveSession())

```

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>

```

##### 配置文件配置 Route

```yaml
spring:
  application:
    name: gateway-service
  cloud:
    gateway:
      discovery:
        # 开启时, 会自动配置默认路由规则
        locator:
          enabled: true
          # 使用小写的服务ID(默认为大写): 配置后Gateway对大写的服务ID将不生效, 自定义的路由规则可以实现既大写又小写
          lower-case-service-id: true
      # 配置自定义路由规则
      routes:
      # 设置路由ID列表(不允许重复?)
      - id: feignclient
        predicates:
        # 设置路径断言列表: 匹配yml的所有请求都会被转发到下面的uri(可以配置多个路由断言共同作用)
        - Path=/yml/**
        filters:
        # 设置路由过滤器: 截去路径断言中的path, 拼接uri进行转发(可以配置多个过滤器共同作用)
        - StripPrefix=1
        # 设置转发路径/服务
        uri: lb://FEIGN-CLIENT

```

##### Configuration 配置 Route

```java
/**
 * Gateway配置测试类: 测试自定义路由规则
 */
@Configuration
// @ConditionalOnBean没用, 注入的AuthFilter还是为null => 解决方式: GatewayConfiguration必须与自定义的Filter在同级目录注入时才不会为null
//@ConditionalOnBean({TimerFilter.class, AuthFilter.class})
public class GatewayConfiguration {

    // 利用Gateway实现Zuul After Filter
    @Autowired
    private TimerFilter timerFilter;

    /**
     * 测试网关JWT鉴权过滤器
     */
    @Autowired
    private AuthFilter authFilter;

    @Bean
    @Order
    public RouteLocator customizedRoutes(RouteLocatorBuilder routeLocatorBuilder){
        return routeLocatorBuilder.routes()
                // 第一个路由规则
                .route(r ->
                        // 配置路径断言
                        r.path("/java/**")
                        // 配置请求方法断言
                        .and().method(HttpMethod.POST)
                        // 配置header断言
                        .and().header("name")
                        // 配置过滤器
                        .filters(f ->
                                // 配置截去再拼接过滤器
                                f.stripPrefix(1)
                                // 配置响应header过滤器
                                .addResponseHeader("java-param", "gateway-config")
                                // 利用Gateway实现Zuul After Filter
                                .filter(timerFilter)
                                // 测试网关JWT鉴权
                                .filter(authFilter)
                        )
                        // 配置转发uri
                        .uri("lb://FEIGN-CLIENT")
                )
                // 第二个路由规则
                .route(r ->
                        // 配置路径断言
                        r.path("/seckill/**")
                                // 配置After断言: 服务器启动后的2分钟生效
                                .and().after(ZonedDateTime.now().plusMinutes(2))
                                // 配置过滤器
                                .filters(f ->
                                        // 配置截去再拼接过滤器
                                        f.stripPrefix(1)
                                )
                                // 配置转发uri
                                .uri("lb://FEIGN-CLIENT")
                )
                .build();
    }
}

```

##### 自定义 Gateway Filter

```java
/**
 * 测试网关JWT鉴权: 网关鉴权核心逻辑
 */
@Component
@Slf4j
// 全局Global过滤器 GlobalFilter
public class AuthFilter implements GatewayFilter, Ordered {
    /**
     * 执行过滤逻辑
     * @param exchange
     * @param chain
     * @return
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ...
    }
    
    /**
     * 高优先级: 小, 低优先级: 大 => 后置过滤器则反过来(钩子)
     * @return
     */
    @Override
    public int getOrder() {
        return 0;
    }
}

```

##### 自定义 Global Filter

```java
/**
 * 利用Gateway实现Zuul After Filter
 */
@Component
@Slf4j
// 全局Global过滤器 GlobalFilter
public class TimerFilter implements GlobalFilter, Ordered {
    /**
     * 执行过滤逻辑
     * @param exchange
     * @param chain
     * @return
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ...
    }
    
    /**
     * 高优先级: 小, 低优先级: 大 => 后置过滤器则反过来(钩子)
     * @return
     */
    @Override
    public int getOrder() {
        return 0;
    }
}

```

