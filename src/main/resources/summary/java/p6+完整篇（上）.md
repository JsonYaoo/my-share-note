# 一、基础篇

## 1. 网络基础

### 1.1. TCP是什么？

TCP，Transmission Control Protocol，传输控制协议，是一种面向连接的、面向字节流的、可靠的传输层通信协议。

### 1.2. UDP是什么？

UDP，User Datagram Protocol，用户数据报协议，是一种无连接的、面向报文的、不可靠的传输层协议，为应用程序提供一种无需建立连接就可以发送封装好的IP数据包的方法。

### 1.3. TCP与UDP的差别？

|                     | TCP                                          | UDP                                  |
| ------------------- | -------------------------------------------- | ------------------------------------ |
| 是否连接            | 面向连接的                                   | 无连接的                             |
| 传输方式            | 面向字节流的（流入进程或进程流出的字节序列） | 面向报文的（完整的报文）             |
| 连接对象个数        | 只能 一对一、可全双工通信                    | 支持一对一、一对多、多对一和多对多   |
| 是否使用拥塞控制    | **<u>流量控制和拥塞控制</u>***               | 无流量控制和拥塞控制                 |
| 是否可靠            | 可靠的                                       | 不可靠的，尽最大努力交付             |
| **<u>首部开销</u>** | 8个字节                                      | 20~60字节（选项可达40个字节）        |
| 性能                | 传输效率低，所需资源多                       | 传输效率高，所需资源少               |
| 适用场景            | 文件、邮件                                   | 语音、视频、直播                     |
| 应用的协议          | HTTP、FTP、SMTP                              | **<u>RIP</u>**、DNS、**<u>SNMP</u>** |

### 1.4. TCP与UDP应用的协议？



![1620099899187](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620099899187.png)

### 1.5. TCP如何保证数据可靠传输？

> 思路：当出现差错时能让发送方重传出现差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度。
>
> TCP主要通过确认应答和超时重传机制、检验和、最大报文长度、滑动窗口控制、流量控制以及拥塞控制等方法实现数据的可靠性传输。

#### **1. 确认应答和超时重传机制**

1. 作用：发送方通过对字节流每个字节进行顺序标号发送，接收方需要对接收到的数据中最高需要给出确认（不应超过0.5s），如果在规定的时间内，发送方没有收到确认应答，则需要重传已发送的报文段。
2. 工作原理：

- **序号**：占4个字节，范围[0，2^32  - 1]，使用mod 2^32运算，n序号表示第n字节，共可表示2^40位（4GB）数据。
- **确认号**：占4个字节，表示期望收到对方下一个报文段的第一个数据字节的序号。若确认号=N，则表明到序号N-1为止的所有数据都已正确收到。
- **确认ACK**：占1位，仅当ACK=1时确认号有效，TCP规定，在连接建立后，所有传送的报文都必须把ACK置为1。

#### **2. 检验和**

1. 作用：通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。
2. 工作原理：

- **二进制反码求和运算**：
  - 0+0=0，但要产生进位1
  - 0+1=1，不需要产生进位1
  - 1+1=0，不需要产生进位1
  - 最高位产生进位1，最后结果需要+1
- 发送方：取12位TPC伪首部+TCP首部+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
- 接收方：取12位TPC伪首部+TCP首部（此时检验和已经不是全0了）+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

![1620126724402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620126724402.png)

#### **3. 最大报文段长度**

MSS，Maximum Segment Size，是指每一个TCP报文段中数据字段的最大长度 = TCP报文段长度 - TCP首部长度 

1. 作用：在连接建立过程中，双方选项上写入自己能支持的MSS（默认536字节），要保证在IP层传输时不需要再分片，减少网络开销，提高网络利用率。
2. 工作原理：

- MSS较小时，传输时加上TCP首部+IP首部+链路层首部，造成花费大开销实现少量数据传输，网络利用率低下。
- MSS较大时，TCP报文段非常长，在IP层传输被分解成多个短的数据报片，造成在终点时要把收到的各个短数据报片装配成原TCP报文段，而且分片多传输出错的概率大，还需要重传，使得花销增大。

#### **4. 以字节为单位的滑动窗口控制**

1. 作用：在没有收到接收方确认的情况下，发送方可以连续把窗口内的数据都发送出去，凡是已经发送过的数据，在未收到确认之前都必须暂时保留以便在超时重传时使用。这样可以提高超时重传机制下的发送效率和信道利用率。
2. 工作原理：

- 发送窗口里面的序号表示允许发送的序号，后沿后面部分表示已发送且已收到的确认，前沿前面部分表示不允许发送。*后沿变化有两种可能即不动（没有收到新的确认）和前移（收到了新的确认）。前沿通常是不断向前的，但也可能不动（收到通知窗口变小），还有可能向后收缩（不推荐）*。
- 接收窗口后沿部分表示已经发送过确认，已经交付主机了，不需要再保留这些数据，窗口内的需要是允许接收的。

![1620130103782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130103782.png)

#### **5. 利用滑动窗口实现的流量控制**

1. 作用：控制发送方速率不要太快，要让接收方来得及接收。*是点对点通信量的控制，是个端对端的问题（接收端控制发送端）。*
2. 工作原理：

- rwnd，receiver window，即通知窗口，发送方的发送窗口不能超过接收方给出的接收窗口数值。
- *持续计时器，persistence timer，收到零窗口通知时开启，时间到期后会发送一个零窗口探测报文段（仅携带1字节的数据），对方在这个探测报文段给出现在窗口值，如果仍然是零，则还会重新设置持续计时器。以解决零窗口互相等待问题。*

![1620130650215](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130650215.png)

#### 6. 拥塞控制

1. 作用：防止过多的数据注入到网络中，避免网络中的路由器和链路过载。*拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的因素。*
2. 工作原理：

- cwnd，congestion window，拥塞窗口，发送方维持的一个状态变量，大小取决于网络的拥塞程度，并且动态变化。**发送方窗口上限值 = Min[rwnd，cwnd]**
- SMSS，Sender Maximum Segment Size，最大报文段。
- 慢开始门限，ssthresh，cwnd < ssthresh => 慢开始算法，cwnd > ssthresh时 => 拥塞避免算法。
- 慢开始，slow-start，先发送小字节探测一下（2~4个SMSS），由小到大逐渐增大拥塞窗口。在每收到一个对新的报文段的确认后，就可以把拥塞窗口增多一个SMSS数值（△cwnd = min[N，SMSS]，N指原先未被确认的、但现在刚刚收到确认的字节数）。
- 拥塞避免，congestion avoidance，cwnd缓慢增大，每经过1个往返时间RTT只把cwnd+1，不像慢开始阶段那样指数规律增长，而是按线性规律增长增长。如果网络出现了超时，发送方判断为网络拥塞，需要调整ssthresh为原来的一半，同时cwnd设置为1，重新进入慢开始阶段。
- 快重传，fast retransmit，接收方没收到某报文段时，需要立即返回3个缺失报文段的重复确认给发送方。发送方只要一收到3个重复确认（3 - ACK），则认为接收方确实没有收到该报文段，则进行重传，而不会误认为是网络拥塞。
- 快恢复，fast recovery，发送方知道只是丢失个别报文段后，不启动慢开始而是执行快恢复算法，调整ssthresh为cwnd/2，同时设置cwnd=ssthresh，并执行拥塞避免算法。

![1620132158175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620132158175.png)

### 1.6. TCP三次握手？

*服务端TCP进程先创建传输控制块TCB（TCP连接表、指向发送和接收缓存的指针、指向重传队列的指针、当前发送和接收序号等），处于LISTEN（收听）状态，等待客户端的连接请求。*

*客户端TCP进程创建传输控制块，打算建立TCP连接，向服务端发起连接请求报文段。*

- TCP规定，SYN报文段不能携带数据，但要消耗一个序号。
- TCP规定，ACK报文段可以携带数据，如果不携带数据则不用消耗序号。

1. 一次握手：客户端发送SYN=1，seq=x的请求报文段，随后客户端进入SYN-SENT（同步已发送）状态。
2. 二次握手：服务端返回ACK=1，ack=x+1，SYN=1，seq=y的确认报文段，随后服务器进入SYN-RECD（同步收到）状态。
3. 三次握手：客户端返回ACK=1，ack=y+1，seq=x+1的确认报文段，此时TCP连接已建立，客户端进入ESTABLISHED（已建立连接）状态。

*当服务端收到客户端的确认报文段后，也进入ESTABLISHED（已建立连接）状态。*

![1620138485517](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620138485517.png)

### 1.7. 为什么TCP需要三次握手，两次行吗？

- 三次握手的原因：主要是为了建立可靠的全双工通信信道，保证客户端与服务端同时具备发送与接收数据的能力。
- 两次握手不行的原因：

1. **两次握手只能保证单向连接是通畅的**。根据TCP确认应答和超时重传机制，通信双方必须维护一个序列号，发送方根据序列号标识哪些报文段是已经发送出去的，接收方也要根据序列号应答哪些报文段是已经确认的。**而三次握手的过程就是双方互相告知起始序列号的过程**，即客户端标记服务端确认，服务端标记客户端确认。如果只是两次握手，那么至多只有客户端的起始序列号得以确认，而另一方的序列号得不到确认，即只能确保单向连接是顺畅的。
2. **第三次握手可以防止已失效的连接请求报文段突然又传送到服务端，建立了多余的连接，造成资源的浪费。**

### 1.8. TCP四次挥手？

*客户端TCP进程先发起TCP释放报文段，并停止发送数据，主动关闭TCP连接。*

- TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
- TCP规定，ACK报文段可以携带数据，如果不携带数据则不用消耗序号。
- MSL，Maximum Segment LifeTime，最长报文段寿命，建议设置为2分钟。

1. 一次挥手：客户端发起FIN=1，seq=u的连接释放报文段，随后进入FIN-WAIT-1（终止等待1）状态，等待服务端确认。
2. 二次挥手：服务端返回ACK=1，ack=u+1，seq=v的确认报文段，随后进入CLOSE-WAIT（关闭等待）状态，此时客户端到服务端方向的连接已释放，TCP连接处于HALF-CLOSE（半关闭）状态。接着，客户端收到确认报文段后，进入FIN-WAIT-2（终止等待2）状态，等待服务端发出连接释放报文段。
3. 三次挥手：服务端TCP进程发起ACK=1，ack=u+1，FIN=1，seq=w的连接释放报文段，随后进入              LAST-ACK（最后确认）状态，等待客户端的确认。
4. 四次挥手：客户端返回ACK=1，ack=w+1，seq=u+1的确认报文段，随后进入TIME-WAIT（时间等待）状态，服务端接收到确认报文段后，进入CLOSE（关闭）状态。此时TCP连接还没有释放掉，必须经过时间等待计时器（TIME-WAIT timer）设置的2MSL时间后，客户端才进入CLOSED（关闭）状态。

![1620141320603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620141320603.png)

### 1.9. 为什么TCP需要四次挥手？

- 四次挥手的原因：因为需要确保客户端与服务端的数据能够完成传输。前两次挥手后，关闭客户端到服务端方向的连接，服务端通知上层应用程序做好最后的准备，进入CLOSE-WAIT（等待关闭）状态。第三次挥手由服务端TCP进程发起连接释放报文段，根据TCP确认应答和超时重传机制，客户端必须返回确认报文段，所以产生第四次挥手。

### 2.0. 为什么TCP客户端需要等待2MSL才进入关闭状态？

- MSL，Maximum Segment LifeTime，最长报文段寿命，建议设置为2分钟。

1. **为了保证客户端发送的最后一个确认报文段能够达到服务器。**如果上一个确认报文丢失，设置2MSL能够在这个时间内，客户端再次收到服务端的FIN+ACK连接释放报文段，保证服务端释放TCP连接。
2. **还为了防止已失效的连接请求报文段突然又传送到服务端，建立了多余的连接，造成资源的浪费。**设置2MSL，可以使本次TCP连接持续的时间内所产生的报文段在网络中消失，确保下一个新的连接不会出现这种旧的连接请求报文段。

### 2.1. 如何查看TIME-WAIT状态的连接数量？

netstat -an | grep TIME_WAIT | wc -l

### 2.2. 为什么会TIME-WAIT过多？如何解决？

- 可能原因：在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接时，会出现大量socket处于TIME-WAIT状态。此时如果客户端的并发量持续很高，那么部分客户端就可能显示连接不上。
- 解决：

1. vim /etc/sysctl.conf，打开系统的TIME-WAIT重用和快速回收。

```shell
# 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1
# 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_tw_recycle = 1
```

2. /sbin/sysctl -p，使参数生效。

### 2.3. TCP报文段格式？

![1620179962619](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620179962619.png)

> TCP报文首部占用20~60字节。

- **源端口和目的端口**：各占2个字节，分别写入源端口号和目的端口号，实现TCP分功能。两个值分别加上IP首部的源端IP地址和目的端IP地址，可以唯一确定一个TCP连接。
- **序号**：占4个字节，范围[0，2^32  - 1]，使用mod 2^32运算，n序号表示第n字节，共可表示2^40位（4GB）数据。
- **确认号**：占4个字节，表示期望收到对方下一个报文段的第一个数据字节的序号。若确认号=N，则表明到序号N-1为止的所有数据都已正确收到。
- **数据偏移**：占4位，指TCP报文段的数据起始处，距离TCP报文段的起始处有多远即TCP报文段的**首部长度**。单位是32位字（4个字节），而4位二进制最大表示15，意味着**TCP首部长度最大长度为60字节**（即选项长度不能超过40字节）。
- **保留**：占6位，保留为今后使用，目前应置为0。
- **标志字段**：各占1位，共6位
  - **紧急URG**：URGent，当URG=1时，表名**紧急指针**有效，需要与**紧急指针**配合使用。URG告诉系统，此报文段中有紧急数据，应尽快传送（相当于高优先级的数据），而不要按原来的排队顺序来传送。
  - **确认ACK**：ACKnowledgment，仅当ACK=1时确认号有效，TCP规定，在连接建立后，所有传送的报文都必须把ACK置为1。
  - **推送PSH**：PuSH，发送方TCP把PSH置为1，则应该立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，则应该尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。
  - **复位RST**：ReSeT，当RST=1时，表明TCP连接出现严重差错，必须释放连接再重新建立连接。
  - **同步SYN**：SYNchronization，在连接建立时用来同步序号。SYN=1，表示这是一个连接请求或连接接受报文。
  - **终止FIN**：FINish，用来释放一个连接。当FIN=1时，表明此报文段发送方的数据已发送完毕，并要求释放连接。
- **窗口**：占2个字节，[0, 2^16 - 1]，指的是发送本报文段的一方的接收窗口，指明从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。窗口值作为接收方让发送方设置其发送窗口的依据，经常动态变化着。
- **检验和**：占2个字节，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。
  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方：取12位TPC伪首部+TCP首部+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
  - 接收方：取12位TPC伪首部+TCP首部（此时检验和已经不是全0了）+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

![1620126724402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620126724402.png)

- **紧急指针**：占2个字节，紧急指针仅在**URG=1**时才有意义，指出本报文段中紧急数据的字节数（序号值+字节数=偏移量），即指出了紧急数据的末尾在报文段中的位置。窗口为零时也可发送紧急数据。
- **选项**：长度可变，最大可达40字节。常见的有**最大报文段长度MSS**、**窗口扩大选项**、**时间戳选项**、**选择确认选项**等。

### 2.4. UDP用户数据报格式？

![1620182389880](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620182389880.png)

> UDP报文首部占8个字节。

- **源端口**：占2字节，源端口号，在需要对方回信时选用，否则全0。

- **目的端口**：占2个字节，目的端口号，在终点交付报文时必须使用。

- **长度**：占2个字节，UDP用户数据报的长度，最小值是8（仅有首部时），最大表示2^16 - 1=65535个字节。

- **检验和**：占2个字节，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。

  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方：取12位UDP伪首部+UDP首部+UDP用户数据报的数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
  - 接收方：取12位UDP伪首部+UDP首部（此时检验和已经不是全0了）+UDP用户数据报的数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

  ![1620182690813](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620182690813.png)

### 2.5. IP数据报格式？

![1620185300666](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620185300666.png)

> IP报文首部占20~60字节。

- **版本**：占4位，指IP协议的版本。通信双方使用的IP协议版本必须一致。IPv4的版本号为4，IPv6的版本号为6。
- **首部长度**：占4位，IP分组的首部长度，单位是32位字（4个字节），最小值是5，而4位二进制最大表示15，意味着**IP分组首部长度最大长度为60字节**（即选项字段不能超过40字节）。IP分组的首部长度如果不是4字节的整数倍时，必须利用最后的填充字段加以补充。
- **区分服务**：DS，Differentiated Services，也叫服务类型。占8位，用来获得更好的服务：*最小时延、最大吞吐量、最高可靠性、最小费用*。一般情况下都不使用这个字段。
- **总长度**：占16位，[0, 2^16 - 1]，指**首部和数据之和的长度**，最大长度为65535个字节。若所传送的数据报长度超过**数据链路层MTU（最大传送单元，默认1500字节）**，就必须把过长的数据报进行分片处理，分片该字段的值也会发生改变，即此时指**分片后的每一个分片的首部长度与该分片的数据长度的总和**。*IP协议规定，在互联网中所有的主机和路由器，必须能够接受长度不超过576字节的数据报，MSS+TCP固定首部+IP固定首部=536+20+20=576字节。*
- **标识**：identification，占16位，IP软件在存储器中维持了一个计数器，每产生一个数据报计数器就+1，并将此值赋给标识字段。**相同的标识字段的值可以使分片后的各数据报片重装为原来的数据报**。
- **标志**：flag，占3位，目前只有两位有意义。
  - **最低位MF**：More Fragment，MF=1表示后面还有分片的数据报，MF=0表示这个已经是若干数据报片中的最后一个了。
  - **中间位DF**：Don't Fragment，DF=1表示不能分片，DF=0表示允许分片。
- **片偏移**：占13位，指较长的分组经过分片后，某片在原分组中的相对位置，以8个字节为偏移单位，即原偏移1400字节，偏移量=1400/8=175。
- **生存时间**：TTL，Time to Live，占8位，指数据报在网络中的寿命。现表示跳数限制，单位是**跳数**，指路由器每次转发数据报之前需要把TTL值-1，若TTL值减小到零，就丢弃这个数据报不再转发。即**TTL表明数据报在互联网中至少可经过多少个路由器**，最大值为255。
- **协议**：占8位，协议字段指出此数据报携带的数据使用何种协议，以便使目的主机IP层知道应该将数据部分上交给哪个协议进行处理。TCP为6，UDP为17。
- **首部检验和**：占16位，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。**只检验数据报的首部部分，不检验数据部分。**ICMP、IGMP、UDP、TCP均同时检验首部部分和数据部分。
  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方对首部部分16位字使用**二进制反码求和运算**， 把结果**取反**写入首部检验和字段。
  - 接收方对首部部分16位字使用**二进制反码求和运算**（此时首部检验和已经不是全0了），当无差错时结果取反应为全0，否则就表明有差错出现。
- **源地址**：占32位。
- **目的地址**：占32位。
- **可选字段**：最大占40个字节，用来支持排错、测量以及安全检测等措施。必要时需要用全0的填充字段来补齐成为4字节的整数倍。实际上很少被使用。

### 2.6. 以太网MAC帧格式？

![1620190340385](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620190340385.png)

> 常用的以太网MAC帧格式有两种标准，一种是DIX Ethernet V2标准（即以太网V2标准），另一种是IEEE的802.3标准，现在市场上流行的都是以太网V2的MAC帧，但大家也常常把它称为IEEE 802.3标准的MAC帧。

MAC帧首部固定长度18个字节，有效MAC帧长度=首部长度+数据长度=64~1518字节。

- **目的地址**：6个字节，是指网卡的硬件地址（MAC地址），占48位，在网卡出厂时固化。
- **源地址**：6个字节，是指网卡的硬件地址（MAC地址），占48位，在网卡出厂时固化。
- **类型字段**：2个字节，用来标志上一层使用的是什么协议，以便把收到的MAC帧的数据上交给上一层的协议。*如值为0x0800，就表示上层的是IP数据报。*
- **数据字段**：长度在46~1500字节，46=64-18，1500=**以太网最大传输单元MTU**。当数据字段的长度小于46字节时，MAC子层会在数据字段后面加入一个整数字节的填充字段，以**保证以太网MAC帧不小于64字节**。上层协议具有识别有效的数据长度长度的功能，比如IP层就可以把填充的字节丢弃掉。
- **帧检验序列FCS**：使用CRC检验。

从MAC子层向下传到物理层时，还要在帧的前面插入8个字节（由硬件生成）

- 前7个字节是**前同步码**（1和0交替码），作用是使接收端的适配器在接收MAC帧时能够迅速调整其时钟频率，使它和发送端的时钟同步，也就是实现位同步（比特同步）。
- 最后一个字节是**帧开始界定符**，定义为10101011，最后两个连续的1表示MAC帧马上要开始了。

> 在以太网上传送数据时是以**帧**为单位传送的，各帧之间还必须有一定的间隙。
>
> 由于存在**帧开始界定符**，所以以外网不需要使用帧结束定界符，也不需要使用字节插入来保证透明传输。
>
> **以太网不负责重传丢弃的帧。**

### 2.7. 子网掩码的作用？

为了能够从IP数据报的首部看出源主机或目的主机所连接的网络是否进行了子网划分。

### 2.8. OSI与TCP/IP模型？

![1620196369515](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620196369515.png)

> OSI七层体系协议结构概念请求、理论完整，但既复杂又不使用。
>
> TCP/IP四层体系结构使用更为广泛。
>
> 五层协议体系结构总和了OSI和TCP/IP的优点，为介绍网络原理而设计出来的。

- OSI七层模型：物理层、数据链路层、网络层、运输层、会话层、表示层、应用层
- TCP/IP四层模型：网络接口层、网际层、运输层、应用层
- 五层协议模型：物理层、数据链路层、网络层、运输层、应用层
  - **物理层**：physical layer，以**比特**为单位，负责在发送双方**传送1和0**。
  - **数据链路层**：data link layer，以**帧**为单位，负责在两个相邻结点之间的链路上**传送帧**，包括控制信息（如同步信息、地址信息、差错控制等）。
  - **网络层**：network layer，以**IP数据报**为单位，负责为在分组交换网上的不同主机提供**通信服务**。在发送数据时，把运输层产生的报文或用户数据报封装成IP数据报进行传送。
  - **运输层**：transport layer，TCP以**报文段**为单位，UDP以**用户数据报**为单位，负责向两台主机中进程之间的通信提供**通用的数据传输服务**。
  - **应用层**：application layer，以**报文**为单位，负责通过应用进程之间的交互来完成**特定网络应用**。

### 2.9 常见的网络服务分层示例

| 分层       | 示例                                |
| ---------- | ----------------------------------- |
| 物理层     | 中继器、集线器                      |
| 数据链路层 | 网卡、网桥、交换机                  |
| 网络层     | 路由器、防火墙、ARP、IP、ICMP、IGMP |
| 运输层     | TCP、UDP                            |
| 应用层     | HTTP、SMTP、DNS、FTP                |

- **ARP**：Address Resolution Protocol，地址解析协议，从网络层使用的IP地址，解析出在数据链路层使用的硬件地址。
- **ICMP**：Internet Control Message Protocol，网际控制报文协议，允许主机或路由器报告差错情况和提供有关异常情况的报告，可以更有效地转发IP数据报，提高交付成功的机会。
- **IGMP**：Internet Group Management Protocol，网际组管理协议，让连接在本地局域网上的多播路由器**知道**本局域网上是否有主机（即主机中的某个进程）参加或退出了某个多播组。

### 3.0. TCP拆包、粘包？原因？解决方法？

- **TCP拆包**：

  - **概念**：如果要发送的数据包过大，就会被拆分成多个TCP报文分开传输，即**一个完整的包可能会被TCP拆分成多个包进行发送**。
  - **直接原因**：
    - 应用程序写入的数据大于套接字缓冲区的大小。
    - TCP报文段的数据部分长度大于MSS(536字节)，导致在IP层传输被分解成多个短的数据报片。
  - **根本原因**：网络层所收到上层交付的数据报长度，超过**数据链路层MTU（最大传送单元，默认1500字节）**，需要把过长的数据报进行IP分片处理。

- **TCP粘包**：

  - **概念**：**多个小的包可能会被TCP封装成一个大的数据包发送**。
  - **直接原因**：
    - 应用程序写入的数据小于套接字缓冲区的大小
    - 接收方不及时读取套接字缓冲区数据
  - **根本原因**：
    - **发送方原因**：TCP默认使用**Nagle算法**（通过减少必须发送包的个数，来增加网络软件系统的效率），即TCP会收集多个小分组，在一个确认到来时才一起发送，导致可能在发送方出现粘包问题。
    - **接收方原因**：TCP将接收到的数据包保存在接收缓存里，如果TCP接收数据包到缓存的速度，大于应用程序从缓存中读取数据包的数据，那么多个包就会被缓存起来，而应用程序就有可能读取到多个首尾相连粘在一起的包。
    - **TCP原因**：TCP是**面向字节流**的协议，报文格式不像UDP那样有专门的长度字段来记录实际报文的长度，交付上层的数据没有边界，导致粘包的发生。

- **解决方法**：

  最本质的原因在于**接收方无法分辨消息与消息之间的边界在哪**，因此，思路就是，通过某种方案给出边界。

  - **消息定长，空格补位**：每个消息的大小都一样，接收方只要累计接收数据，直到数据等到一个定长的指就将它作为一个消息。
  - **包尾加特殊字符作为边界**：比如FTP协议就是在包尾加上\r\n标记作为边界的。但问题在于通信双方要约定在数据正文中，不出现该特殊字符，否则会误判为消息的边界。
  - **包首部记录包体长度**：每个包首部至少包含数据包的长度，这样接收方可以通过读取包首部的长度字段，就知道每一个包的实际长度。

### 3.1. HTTP是什么？

HTTP，hypertext Transfer Protocol，超长文本传输协议，是一个**通常运行在TCP之上的**应用层协议，定义了浏览器怎么向万维网服务器请求万维网文档以及服务器怎么把文档传送给浏览器。

- **事务**：指一系列的信息交换是一个不可分割的整体，即要么所有的信息交换都完成，要么一次交换都不进行。
- **无连接**：指通信双方在交换HTTP报文之前不需要先建立HTTP连接。
- **无状态**：指同一个客户第二次访问同一个服务器上的页面时，服务器的响应与第一次访问时的相同（假设不会更新）。

### 3.2. HTTP协议/1.0/1.1/2.0？

- **HTTP/1.0**：
  - **概述**：每一个请求建立一个TCP连接，请求完成后立马断开连接（**短连接**）。
  - **缺点**：
    - **连接无法复用**，每次请求都要经历三次握手和慢启动，导致在并发量大的情况下服务器的压力负担大，以及带宽无法被充分利用。
- **HTTP/1.1**：
  - **概述：**多个http请求可以复用一个TCP连接，使用Connection Header（close/keep-alive）来区分**短/长连接**。服务器按照FIFO原则来处理不同请求。
  - **缺点**：在同一时间，针对同一域名下的请求有一定的限制，超过限制数目的请求会被阻塞。
- **HTTP/2.0**：
  - **概述**：**多路复用**（二进制帧的设计）允许同时通过单一的连接发起多重的请求-响应信息，可以很容易地去实现并行地在同一个TCP连接上双向交换信息，而不用依赖建立多个TCP连接。
  - **缺点**：普及速度慢，与HTTP1.1并存。

### 3.3. HTTP/1.0/1.1的主要区别？

1. **长连接**：减少了建立和关闭连接的消耗和延迟。
2. **Host头处理**：支持Host头域，不在以IP为请求方标志，解决一台物理机存在多个虚拟主机，共享IP地址的问题。
3. **错误状态码增多**：1.1新增了24个错误状态响应码，更加明确各个状态，如409（表示请求的资源与资源当前状态发生冲突）、410（表示服务器某个资源被永久性的删除）。
4. **网络连接的优化**：1.1支持断点续传，在请求头引入range头域（允许只请求资源的某个部分，返回码206），方便充分利用带宽和连接。
5. **提供更多的缓存控制策略**：

| 缓存控制头          | 解释                                                         | 备注     |
| ------------------- | ------------------------------------------------------------ | -------- |
| If-Modified-Since   | 允许在对应的资源未被修改的情况下，返回304未修改              | 1.0、1.1 |
| Expires             | 指定一个日期/时间，超过该时间则认为此响应已过期              | 1.0、1.1 |
| ETag                | Entity tag，对于某个资源的某个特定版本的一个表示符，通常是一个消息三列 | 1.1新增  |
| If-Unmodified-Since | 仅当该实体某个特定时间以来未被修改的情况下，才发送响应。     | 1.1新增  |
| If-Match            | 仅当客户端提供的实体与服务器对应的实体相匹配时，才进行对应的操作。主要用于PUT这样的方法中，仅当从用户上次更新某个资源后，该资源未被修改的情况下，才更新该资源。 | 1.1新增  |
| If-None-Match       | 允许在对应的内容未被修改的情况下，返回304未修改              | 1.1新增  |

### 3.4 HTTP/1.1/2.0的主要区别？

1. **多路复用**：2.0连接共享，不同的Request可以使用同一个连接传输，最后根据每个Request id组合成正常的请求。
2. **新的传输格式**：2.0使用二进制格式（基于二进制帧的设计），1.0依然使用基于文本的格式（基于文本分割解析）。
3. **Header压缩**：由于1.X中Header带有大量的信息，并且得重复传输，2.0使用Encoder来减少需要传输的Header大小。
4. **服务端推送**：2.0中，服务器可以对客户端的一个请求发送多个响应。

### 3.5. HTTPS连接的建立过程？

> HTTPS，Hyper Text  Transfer Protocol over SecureSocket Layer，是以安全为目标的HTTP通道，在HTTP的基础上通过传输加密和身份认证保证传输过程的安全性。

- HTTPS在内容传输的加密上使用的是**对称加密**（速度快），在证书验证阶段使用**非对称加密**（安全性高）。
- **对称加密**：双方持有**相同的密钥**，加密速度快。典型的对称加密算法有：DES、AES**。**
- **非对称加密**：**密钥成对出现（私钥和公钥）**。私钥只有自己知道，不在网络中传输。公钥可以公开，A使用B公钥加密后，B使用B的私钥解密。加密速度慢。典型的非对称加密算法有：RSA、DSA。

1. **发起请求**：首先客户端将它所支持的算法列表和一个用作产生密钥的**随机数1**发送给服务器。
2. **返回证书**：服务器从算法列表中选择一种算法，并将它和一份包含**服务器公钥**的证书以及**随机数2**返回给客户端，包含用于认证目的的服务器标识。
3. **证书验证**：客户端对服务器的证书进行验证（**数字签名**），抽取**服务器公钥**，再产生一个**预主密钥（pre_master_secret）**的随机密码串 + **服务器公钥**，使用非对称加密，将**加密后的信息**发送给服务器。此时，客户端使用**随机数1、随机数2、预主密钥**，独立计算出**加密和MAC密钥**，作为接下来的**会话密钥**。
4. **服务器解密**：服务器通过**服务器私钥**对传送过来的加密信息进行解密，得到**预主密钥**，与**随机数1、随机数2**独立计算出**加密和MAC密钥**，作为接下来的**会话密钥**。
5. **客户端发起测试**：客户端将握手消息经过**会话密钥**使用对称加密得到的MAC值发送给服务端，验证服务器能否正常接受客户端加密的消息。
6. **服务器响应测试**：服务器将握手消息经过**会话密钥**使用对称加密得到的MAC值返回给客户端，如果客户端能够接受并返回确认报文的MAC值，则SSL层建立完成。

### 3.6. HTTP与HTTPS的区别？

| HTTP                           | HTTPS                                     |
| ------------------------------ | ----------------------------------------- |
| 默认端口80                     | 默认端口443                               |
| URL以http://开头               | URL以https://开头                         |
| 明文传输、数据未加密、安全性差 | 传输过程SSL加密、安全性好、需要用到CA证书 |
| 消耗资源少、响应速度快         | 消耗资源多、响应速度慢                    |

### 3.7. HTTP请求报文有哪些方法？

| 方法    | 描述                                                     |
| ------- | -------------------------------------------------------- |
| GET     | 向特定资源发送请求，查询数据并返回实体                   |
| POST    | 向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |
| PUT     | 向服务器上传新的内容                                     |
| HEAD    | 类似于GET请求，返回的响应中没有具体的内容，用于获取报头  |
| DELETE  | 请求服务器删除特定的资源                                 |
| OPTIONS | 可以用来向服务器发送请求，来测试服务器的功能特性         |
| TRACE   | 回显服务器收到的请求，用于测试或者诊断                   |
| CONNECT | 用于代理服务器                                           |

### **3.8. Get和Post请求区别**？

|          | GET                                                          | POST                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 可见性   | 数据在URL中，所有人可见                                      | 数据不会显示在URL中                                          |
| 安全性   | 发送的数据是URL的一部分，安全性较差                          | 参数不会被保存在浏览器历史或者web服务器日志中，安全性较好    |
| 数据长度 | 受限制，最大2KB=2^10字节                                     | 无限制                                                       |
| 编码类型 | application/x-www-form-urlencoded                            | multipart/form-data                                          |
| 缓存     | 能被缓存，会保存在浏览器的浏览记录中，URL能够被作作为书签保存 | 不能被缓存                                                   |
| 意义     | 用于向特定资源发送请求，查询数据并返回实体                   | 用于向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |

### 3.9. HTTP常见响应状态码？

> 1xx表示通知信息，如请求收到了或者正在进行处理。
>
> 2xx表示成功，如已接受或已知道。
>
> 3xx表示重定向，如要完成请求还必须采取进一步的行动。
>
> 4xx表示客户的差错，如请求中有错误的语法或者不能完车。
>
> 5xx表示服务器的差错，如服务器失效无法完成请求。

- 100：Continue，继续，客户端应继续请求。
- 200：OK，请求成功，一般用于GET和POST请求。
- 301：Move Permanently，资源永久重定向。
- 302：Found，资源暂时重定向。
- 400：Bad Request，客户端请求的语法错误，服务器无法理解。
- 403：Forbidden，服务器理解客户端的请求，但是拒绝执行此请求。
- 404：Not Found，服务器无法根据客户端的请求找到资源。
- 500：Internal Sever Error，服务器内容错误，无法完成请求。
- 502：Bad Gateway，作为**网关或者代理服务器**尝试执行请求时，从远程服务器中接收到了无效的响应。

### 4.0. 重定向与转发的区别？

|            | 重定向（Redirect）                                     | 转发（Forward）                                   |
| ---------- | ------------------------------------------------------ | ------------------------------------------------- |
| 地址栏路径 | 发生变化                                               | 不变                                              |
| 其他站点   | 可以访问其他站点（服务器）的资源                       | 只能访问当前服务器下的资源                        |
| 请求的次数 | 是两次请求，不能使用Request域对象来共享数据            | 是同一次请求，共享同一个Request域对象             |
| 效率       | 速度慢                                                 | 速度快                                            |
| 执行主体   | web容器，在同一个web容器中转发，对于客户端来说是透明的 | 客户端，服务器返回302状态码，客户端执行重定向操作 |

### 4.1. Cookie与Session的区别？

|          | Cookie                                                       | Session                                                      |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 共同点   | 用来跟踪浏览器用户身份                                       | 用来跟踪浏览器用户身份                                       |
| 位置     | 保存在客户端（浏览器）                                       | 保存在服务端                                                 |
| 安全性   | 不是很安全，可以分析本地的Cookie进行欺骗                     | 较安全                                                       |
| 作用     | 一般用来保存信息                                             | 记录用户的状态                                               |
| 产生机制 | 服务器通过设置响应头提示浏览器生成或者直接使用客户端脚本产生，然后请求时可以发送给服务器 | 客户端请求时，一般服务器会创建JSessionId标识，存放session值到散列表中 |

### 4.2. 在浏览器输入URL再回车确认后发生了什么？

URL判断、DNS查询、TCP连接、浏览器发起HTTP请求、服务器处理并响应HTTP请求、浏览器渲染页面

| 过程              | 过程                                                         | 使用的协议 |
| ----------------- | ------------------------------------------------------------ | ---------- |
| 1、URL判断        | 浏览器判断URL是否合法                                        | 无         |
| 2、DNS查询        | 浏览器查找DNS得到域名对应的IP地址，查找过程：浏览器缓存 -> 操作系统缓存 -> 路由器缓存 -> DNS缓存 -> 域名服务器 | DNS        |
| 3、TCP连接        | 根据IP地址与端口建立TCP连接                                  | TCP        |
| 4、HTTP请求       | 浏览器向服务器发送HTTP请求                                   | HTTP       |
| 5、响应HTTP请求   | 服务器处理并响应HTTP请求                                     | HTTP       |
| 6、浏览器渲染页面 | 浏览器接收HTTP响应并渲染页面                                 | 无         |

### 4.3. HTTP请求与响应报文格式？

![1620215152917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620215152917.png)

- **开始行**：用于区分是请求报文还是响应报文。在请求报文中的开始行叫做**请求行**，在响应报文中的开始行叫**状态行**。开始行的**三个字段都以空格隔开**，最后的“CR”与"LF”分别代表"回车"和“换行”。
  - 请求报文：方法、URL、版本
  - 响应报文：版本、状态码、短语
- **首部行**：用来说明浏览器、服务器或者主体的一些信息，可以有好几行，也可以不用。每一个首部行都以CRLF结尾。在整个首部行结束时，**还有一空行将首部行和实体主体分开**。
- **实体主体**：请求包体或者响应包体。

## 2. 加解密基础

### 1.1. 常见签名与加密相关用语？

#### 1. 转义

转义字符能使其开头的序列具有不同于普通字符数列的语义。常见作用有：

- 如果不进行转义就可能与语法规定的某些**内容产生混淆**，所以某些内容需要转义。如Java的转义字符"\\"，用来区分字符串中，哪些是分割符，哪些是字符本身。
- 字符引用，用于转义键盘录入的字符，如字符串中的回车符和换行符，使其不可见，从而更容易表达其他内容。

#### 2. 编码解码

编码是采用一种新的载体来表示前一个载体所表达的信息，本质上是信息形式的转换，并没有保密的作用（因为编解码算法是公开的），目的是将信息转换成统一的格式，方便在不同系统中传输。

eg：信息 -> 编码 -> 二进制 -> 解码 -> 信息

*如果解码之后无法正确还原原来所表达的信息，此时就出现了**乱码**。通常是因为选用的解码和编码方式不同所导致的。*

常见编码类型有：

- **文本文件编码**：
  - 作用：将文本内容编码为**二进制数据**，以实现二进制数据进行存储或者传输的目的。
  - 相关技术：ASCII（1字节）、ISO8859-1、GBK（汉字2字节）、GBK2312、UTF-8（汉字0到4字节）、UTF-16、UTF-32等。
- **可打印字符编码**：
  - 作用：将二进制数据编码为**可打印的字符**，以实现通过可打印字符的形式进行存储或者传输的目的。
  - 场景：Web场景（图片）、公钥证书、电子邮件附件等（因为ASCII码128~255字符不可见，不方便路由传输）。
  - 相关技术：HEX、Base64等。
    - HEX：16进制字符，只有字母A~F，4位一组。
    - Base64：a-zA-Z0-9+=，64个字符，6位一组，再对照ASCII码表。

![1620302838656](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620302838656.png)

```java
        // 1、编码技术: 很多消息摘要、加解密算法都是针对二进制的
        try {
            // Base64编码: Q0FG => 6位一组, 3 * 8 = 4 * 6, 压缩率比HEX高, 可能会出现+、=符号
            String base64Str = Base64.getEncoder().encodeToString("CAF".getBytes("ASCII"));
            System.err.println(base64Str);

            // Base64解码: CAF
            String base64Org = new String(Base64.getDecoder().decode(base64Str), "ASCII");
            System.err.println(base64Org);
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }
```

- **URL编码**：
  - 作用：通过使用安全的字符去表示不安全字符从而达到适合传输的目的。
  - 场景：作为URL参数时：中文、空格、&、？、=

#### 3. 消息摘要

- 作用：为了校验**信息的完整性**，保证信息在传输过程中不被篡改。
- 场景：校验密码是否正确、校验下载文件是否完整无损。
- 相关技术：MD5（32字符16字节定长）、SHA、SHA256等。
- 特点：无法逆推、（优秀的Hash算法）结果定长、碰撞率低、相同输入相同输出、不同输入输出千差万别。
- 缺点：简单的摘要可通过穷举、撞库的方式得到原文，因此需要加盐增加算法的安全度。

```java
        // 2、消息摘要: 16字节, MD5、SHA, 哈希的算法, 单向的不能逆推, 优秀的哈希产生的结果是定长的, 碰撞率比较低, 少量Hash就千差万别
        // 作用: 用于验证原消息是否有改变、不同输入不同输出、相同输入相同输出、在数字签名中可以用来证明消息没被别人篡改过
        String input = "hello world";

        // MD5国内一般都使用HEX格式编码, 但事实上Base64也可
        System.err.println(MD5(input));// HEX是一个字符占4位, 16个字节, 共32个字符 => 5EB63BBBE01EEED093CB22BB8F5ACDC3
        System.err.println(MD5(MD5(input) + "加盐"));// MD5加盐(随机字符串), 极大加强安全性: 1FEED1AECF760C313879517FA3A8F2B6
        System.err.println(SHA1(input));// HEX是一个字符占4位, 20个字节, 共40个字符 => 2AAE6C35C94FCFB415DBE95F408B9CE91EE846ED
        System.err.println(SHA256(input));// HEX是一个字符占4位, 32个字节, 共64个字符 => B94D27B9934D3E08A52E52D7DA7DABFAC484EFE37A5380EE9088F7ACE2EFCDE9
```

```java
// MD5消息摘要
    public static String MD5(String str) {
        try {
            MessageDigest md5 = MessageDigest.getInstance("MD5");// 算法类型
            md5.update(str.getBytes("UTF-8"));// 字符集
            byte[] digest = md5.digest();// MD5范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA1不太安全
    public static String SHA1(String str) {
        try {
            MessageDigest SHA1 = MessageDigest.getInstance("SHA");
            SHA1.update(str.getBytes("UTF-8"));
            byte[] digest = SHA1.digest();// SHA1范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA256比较安全
    public static String SHA256(String str) {
        try {
            MessageDigest SHA256 = MessageDigest.getInstance("SHA-256");
            SHA256.update(str.getBytes("UTF-8"));
            byte[] digest = SHA256.digest();// SHA256范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }
```

#### 4. 加密解密

对原来的明文按照某种算法进行处理，使其成为不可读的一段代码，即密文。

- 作用：保护数据不被非法人窃取、阅读，保证发送**消息的保密性**。

- 算法类型：

  - **对称加密**：
    - 概念：加密和解密时使用的**密钥是同一个**，因此又称为共享密钥加密算法。
    - 优点：算法公开、计算量小、速度快、效率高。
    - 缺点：发送双发使用相同的密钥，密钥容易泄露，安全性较弱。
    - 相关技术：DES（速度快、容易被破解）、AES（难以被破解）等。
  - **非对称加密**：
    - 概念：加密和解密使用**不同的密钥**，包含一个公开密钥（公钥）和一个私有密钥（私钥），因此又称为公开密钥加密算法。
    - 优点：密钥成对出现，且私钥存在传输泄露的风险，大大增加了安全性。
    - 缺点：算法复杂，速度远远低于对称加密算法、不适用于数据量较大的场景。
    - 相关技术：RSA等。

  *注意点：算法类型、字符集、使用哪个密钥、编码类型*

```java
        // 3、加密算法: RSA跨平台, 不推荐使用JAVA方式(PKCS8)来生成私钥和公钥, 推荐用OPEN SSL(Git Hub)方式生成(PKCS1 | PKCS8)
        //      1) 对称加密: 收发双方约定同一个Key, Key被劫持了就不安全了
        //      2) 非对称加密: 收发双发约定一对Key, 只把一半在网上流传, 另一半不流传
        // RSA非对称加密默认使用Base64格式编码
        String publicKeyStr = "MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDTse/HAlvTdgaUn4uCFiC6o++G\n" +
                "SPQ9XN3DjBOyitzOO0atlTG68KZnhEoUMZGJ2grKgWu49xjV8XY+8AUziAZfFJ5g\n" +
                "LXN/e9QuJ+yLm7hPfEmOAZorGLLxUV1ms266RqD9V9l2UJGlmVqo4ZV9pRnbxW8a\n" +
                "7sh2iR/2pIM5p3atiwIDAQAB";
        String privateKeyStr = "MIICdwIBADANBgkqhkiG9w0BAQEFAASCAmEwggJdAgEAAoGBANOx78cCW9N2BpSf\n" +
                "i4IWILqj74ZI9D1c3cOME7KK3M47Rq2VMbrwpmeEShQxkYnaCsqBa7j3GNXxdj7w\n" +
                "BTOIBl8UnmAtc3971C4n7IubuE98SY4BmisYsvFRXWazbrpGoP1X2XZQkaWZWqjh\n" +
                "lX2lGdvFbxruyHaJH/akgzmndq2LAgMBAAECgYEAgKkZeNNXKdsGvteEu4hlVeoC\n" +
                "zpOSVaUWZx3Abvf0oSbnmuIdOme+SxXczA8gTC8H9fHYna8YGhdJ7ZCFKL+YVqA3\n" +
                "y3ytx3VPcUR/DIexfsUKTQwxWbmwFOXjimHd1EOWglhP16jX+JqJdcYO8WUDaYJY\n" +
                "fII+52w4IBqXQzV0ROECQQDsjP6eVx+ocT3vPWKuO4k68xNIbJYv0rI6OUirq+iW\n" +
                "fEyt+qQg46p7cVcwjVy+smTEOcALljGp3qvBF+c9cEgbAkEA5RnFOnG4OWfEkzPF\n" +
                "bJPqZ49E59Yt6Gh0EC163IzFtirB/GMumrT70Gs1vItrZb8iYuhaK1uZB0lJLJPB\n" +
                "ppdnUQJBAKVa2hHtbR/eKSE3k+efjoo6qNwTq9i6PAQfTwFSJkArm55yepDTFLU9\n" +
                "wWkbKB3VrkLM68Yts4G/Oei8wNRdzMkCQE6LwE/iTzv3NLEXLdek+teYihJGHyUw\n" +
                "MqKdRSM6bEqhbDKguoi2BiOVri2/SwnuNtbcPJXi6JtT5++NlPYNsJECQAsU+Ama\n" +
                "zDNyx8oq/s/JmB/jk6HmNMUaujsBd4N3yvO9awaLEgeghD02lIa0smd9qgqLVhm8\n" +
                "rl0xPQV91p5pcFU=";

        // 如果不采用读文件的, 需要手动清理IDE加的"\n"
        publicKeyStr = publicKeyStr.replace("\n", "");
        privateKeyStr = privateKeyStr.replace("\n", "");

        String rsaEncryptStr = rsaEncrypt(input, toPublicKey(publicKeyStr));
        System.err.println(rsaEncryptStr);// UdYxJbZirWPDAHhIaTLA4q6jrdh0MWNu+OFZaAP5rZqvR9Vzynl53uyUe6OisyRxHS++q8EnHu6hEaFGdJNimuZ99yo0Lpq8AxudlUd7j9JvFd2EmAo+phA1KnC+SHn1BOF6qYVymhjxnsWnB2IHACIcFhWcHinC7txSVjZHQo0=
        String rsaDecryptStr = rsaDECRYPT(rsaEncryptStr, toPrivateKey(privateKeyStr));
        System.err.println(rsaDecryptStr);// hello world
```

```java
// Java生成RSA非对称加密公钥对象
    public static PublicKey toPublicKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(bytes);// 公钥统一标准X509编码
            return keyFactory.generatePublic(x509EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java生成RSA非对称加密私钥对象
    public static PrivateKey toPrivateKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(bytes);// JAVA私钥只能读PKCS8格式
            return keyFactory.generatePrivate(pkcs8EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

   // RSA非对称加密
    public static String rsaEncrypt(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.ENCRYPT_MODE, key);// 加密模式
            byte[] bytes = str.getBytes("UTF-8");// 字符集
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // RSA通常使用Base64编码
            return Base64.getEncoder().encodeToString(doFinal);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        }

        return null;
    }

    // RSA非对称解密
    public static String rsaDECRYPT(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.DECRYPT_MODE, key);// 解密模式
            byte[] bytes = Base64.getDecoder().decode(str);// RSA通常使用Base64编码
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // 这里采用UAT-8字符集
            return new String(doFinal,"UTF-8");
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }

        return null;
    }
```

#### 5. 数字签名

- 作用：身份认证发送方，具有消息的不可抵赖性，同时保证消息的完整性。
- 相关技术：消息摘要算法 + 加密解密算法。

```java
        // 4、数字签名: 散列+加密 = 消息摘要 + 非对称加密
        //      1) 证明消息没被别人篡改过 => 消息摘要
        //      2) 证明确实是发送方发过来的 => 非对称加密, 使用自己的私钥加密消息
        String sign = rsaSign(toPrivateKey(privateKeyStr), input);
        System.err.println(sign);// PDhFYAx3FSIajHFYwP35PInipQxmFA/qtuCJXPALOoUf2nZlIC3Xt9qfSK/hovhhXBIuOSReTnKLCHDuvXJ0rfNVC1SqO4yYl5PXeiHgOjUj18VLxKyId0H9Z4+L47Uhb3JSsNv+X8trE6Q4dDj29xjVeVEBkfsKYdqjc8QxSPQ=
        boolean res = rsaVerifySign(toPublicKey(publicKeyStr), input, sign);
        System.err.println(res);// true
```

```java
    // Java利用MD5WithRSA实现数字签名, 一定要用自己的私钥进行数字签名
    public static String rsaSign(PrivateKey privateKey, String str) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initSign(privateKey);// 初始化私钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] sign = signature.sign();// 数字签名范围到此为止
            return Base64.getEncoder().encodeToString(sign);// 通常数字签名使用Base64编码
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java利用MD5WithRSA实现数字验签, 一定要用对方的公钥进行验签
    public static boolean rsaVerifySign(PublicKey publicKey, String str, String sign) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initVerify(publicKey);// 初始化公钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] bytes = Base64.getDecoder().decode(sign);// 通常数字签名使用Base64编码
            return signature.verify(bytes);// 数字验签范围到此为止
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return false;
    }
```

### 1.2. 数字签名与数据加密的区别？

- **数字签名**：

![1620308002223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620308002223.png)

1. 发送方先使用Hash函数对将要发送的明文生成**消息摘要**。
2. 发送方使用**自己的私钥**签名消息摘要，生成**已签名的消息摘要**。
3. 发送方把将要发送的**明文**和**已签名的消息摘要**，一起发送给接收方。
4. 接收方再使用**发送方的公钥**对收到的**已签名的消息摘要**进行验证，验证通过可以得到原始的消息摘要。此步验证了**发送方的身份**。
5. 接收方使用相同的Hash函数对收到的**明文**生成**消息摘要**，与解密出来的消息摘要进行比对，判断两者是否一致。此步验证了**消息的完整性**。

- **数据加密**：

（基于大质数分解数学原理的非对称加密，一般大的数值对作为私钥，小的数值对作为公钥）

![1620305224976](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305224976.png)

![1620305447877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305447877.png)

1. 发送方先生成一个**对称密钥**，使用此密钥将对称加密将要发送的明文，生成密文。
2. 发送方使用**接收方的公钥**非对称加密上述生成的**对称密钥**，生成加密后的密钥。
3. 发送者将**密文**与**加密后的密钥**（*成为数字信封*），一起发送给接收方。
4. 接收者使用**自己的私钥**解密加密后的密钥得到原始的**对称密钥**，再用该对称密钥解密密文，得到真正的明文。

- **数字签名与数据加密的区别**：（共同点：都使用了公开密钥体系）

|                    | 数字签名                                                     | 数据加密                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 加密方式（发送时） | 使用发送方的私钥                                             | 使用接收方的公钥                                             |
| 解密方式（接收时） | 使用发送方的公钥                                             | 使用接收方的私钥                                             |
| 映射关系           | 一对多，只有拥有私钥的才能代表发送，任何拥有公钥的人都可以解密 | 多对一，任何拥有公钥的人都可以加密发送，只有拥有私钥的才能解密成功 |
| 使用的算法         | 非对称加密                                                   | 对称加密明文、非对称加密**对称密钥**                         |
| 作用               | 保证发送的消息的**完整性、身份认证和不可抵赖性**             | 发送的消息的**保密性**                                       |

### 1.3. PKCS1与PKCS8的区别？

使用OPEN SSL生成私钥和公钥：

- **PKCS1**：
  - 概念：一种标准的生成私钥Key的方法，是RSA的密钥的原本格式。
  - 特点：BEGIN 开头：BEGIN RSA PUBLIC KEY
  - 作用：生成私钥。
  - 语法：
    - 生成私钥：genrsa -out private 1024
    - 生成公钥：rsa -in private -pubout -out public

![1620305778221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305778221.png)

![1620305830513](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305830513.png)

![1620305962240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305962240.png)

- PKCS8：
  - 概念：用于转换私钥，在PKCS1数据上增加了一些信息，使其可存储更多的元信息。
  - 特点：与PKCS1能够相互转换、可以用于非RSA对称加密算法、JAVA只认PKCS8。
  - 语法：
    - KCS1转换成PKCS8：pkcs8 -topk8 in private -nocrypt -out private_pkcs8

![1620306139689](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620306139689.png)



## **3. 操作系统基础**

### 1.1. 进程和线程的区别？

- **进程**：是**资源分配的最小单位**。
  - 在Java中，启动main函数相当于启动一个进程，而main函数所在的线程该进程中的线程，称为主线程。
- **线程**：是**任务调度和执行的最小单位**，线程并行执行，会存在资源竞争和上下文切换的问题。
  - 在Java中，一个进程可以有多个线程，多个线程共享进程的堆和方法区资源，但不共享栈和程序计数器，每个线程有自己的本地方法栈、虚拟机栈和程序计数器。各个线程之间切换工作时，负担要比进程小得多，所以线程也被称为轻量级进程。
- **协程**：是一种比线程更加轻量级的存在，一个线程可以拥有多个协程，协程没有增加线程数量，只是在线程的基础之上通过**分用复用**的方式运行多个协程。**协程只有和异步I/O结合起来才能发挥出最大的威力**，这是因为：
  - 对于计算密集型任务本身并不需要大量的线程切换（一般只需要C + 1），此时使用协程的作用非常有限，反而还增加了协程切换的开销。
  - 由于操作线程是任务调度和执行的最小单位，即操作系统只知道线程，并不知道协程的存在，所以在协程调用阻塞I/O时，操作系统会让线程进入阻塞状态，导致绑定在该线程之上的其他协程都会陷入阻塞而得不到调度（应该启动个新的线程或者封装I/O为异步非阻塞/O）。
- *管程：指的是管理共享变量以及对共享变量的操作过程，以让他们支持并发，是一种进程同步互斥工具。*
  - 作用：解决信号量机制变成麻烦，容易出错的问题。
  - 特点：各外部进程/线程只能通过管程提供的特定入口才能访问共享数据，且每次仅允许一个进程在管程内执行某个内部过程。
  - 场景：Java中的synchronized、wait()、notify()、notifyAll()等。

### 1.2. 进程间的通信方式？

1. **管道**：亲缘关系使用无名管道，非亲缘关系使用有名管道，遵循FIFO，是**半双工**通信方式，数据只能单向流动。
   - 无名管道：pipe，管道是一种半双工的通信方式，数据只能单向流动，且只能在具有亲缘关系的进程间使用（如父子进程）。
   - 高级管道：popen，指在当前程序进程中启动另一个程序进程，把其当做是当前程序进程的子进程。
   - 有名管道：named pipe，同样是半双工，但允许无亲缘关系进程间通信。
2. **信号**：signal，信号是一种比较复杂的通信方式，用于**通知接收进程某个事情已经发送了**。比如用户调用kill命令将信号发送给其他进程。
3. **消息队列**：message queue，消息队列即消息的链表， 存放在内核中并由消息队列标识符标识，克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等特点。
4. **共享内存**：shared memory，共享内存就是映射一段能被其他进程所访问的内存。
   - 这段共享内存由一个进程创建，多个进程都可以直接读写，是**最快的IPC方式**，是针对其他进程间通信方式运行效率低而专门设计的。
   - 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。
5. **信号量**，semophore，信号量是一个计数器，用于控制多个进程对共享资源的访问，常作为**进程间以及同一进程不同线程之间的同步手段**。
6. **套接字**：socket，与其他通信机制不同，它是通信双方的一种约定，用于**不同机器间的进程通信**。

### 1.3. 核心态与用户态？

> 特权指令是拥有特殊权限的指令，用于调用系统函数或系统软件等。比如内存清理、重置时钟、分配系统资源、修改虚存段表和页表、修改用户访问权限等。
>
> 非特权指令是普通权限的指令，在程序执行时都可以调用。

核心态与用户态是两种处理器状态：

- **核心态（Kernel Mode）**：
  - 当程序运行在0特权级时（RING0~3），称之为运行在**核心态**。RING0是最高的特权级。
  - 运行操作系统程序（**内核程序**），可以**执行特权指令和执行非特权指令**。CPU可以访问内存的所有数据，包括外围设备等硬件资源。
  - 处于核心态时，进程能访问所有的内存和对象，且所占有的处理器不允许被抢占。
- **用户态（User Mode）**：
  - 当程序运行在3级特权级时（RING0~3），称之为运行在**用户态**，RING3是最低的特权级，是普通用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。
  - 运行**应用程序**，只能执行**非特权指令**。只能**受限地**访问内存。
  - 处于用户态时，进程所能访问的内存空间和对象受到限制，其所占有的处理器可能被抢占。

### 1.4. 为什么要有核心态和用户态？

- 由于特权指令权限重大，如果使用不当将会导致整个系统崩溃，为了**保证系统安全**，这类指令只能用于操作系统或者其他系统软件，不直接提供给用户使用，所以CPU状态区分为核心态和用户态：
  - 特权指令必须在核心态执行，且内核态可以使用全部指令。
  - 用户态只能使用非特权指令，当用户态下使用特权指令时，将产生中断以阻止用户使用特权指令。

### 1.5. 用户态与核心态之间的切换？

- **用户态 -> 核心态**：通过**中断**实现，且**中断是用户态到核心态的唯一途径**。
  - *这里的中断指的是广义的中断，包括异常和狭义的中断。*
  - 因为发生中断意味着需要操作系统介入，开展管理工作，而操作系统的管理工作（如进程切换、分配I/O设备等）需要使用特权指令，所以CPU需要从用户态转为核心态。**中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。**
- **核心态 -> 用户态**：通过执行一个特权指令，将程序状态字（PSW）标志位设置为用户态即可。

### 1.6. 内中断与外中断？

广义的中断可以分为内中断和外中断：

- **内中断**：也称为**异常**、例外、陷入，信号来源于CPU内部，与当前执行指令有关。
  - **陷阱、陷入**：trap，有意而为之的异常，如系统调用。
  - **故障**：fault，由错误条件引起的，可能被故障处理程序修复，如缺页中断。
  - **终止**：abort，不可修复的致命错误造成的结果，终止处理程序不再将控制返回给引入终止的应用，如整数除以0。
- **外中断**：是**狭义的中断**，信号来源于CPU外部，与当前执行的指令有关。
  - **外设请求**：如外围设备的中断，即I/O操作完成发出的中断信号。
  - **人工干预**：如用户强行终止一个进程。

### 1.7. Linux的进程地址空间？

![1620546981765](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620546981765.png)

- **栈**：stack，进程运行的栈，存储局部变量、临时变量，函数调用时，存储函数的返回指针，用于控制函数调用和返回。在程序块开始时自动分配内存，结束时自动释放内存，其操作方式类似于数据结构中的栈。
- **内存映射段**：memory mapping space（mmap），系统调用使用的空间，通常用于文件映射到内存，在进程创建时，会将程序用到的平台、动态链接库加载到该区域。
- **堆**：heap，是能够动态分配的内存空间，需要程序员手工分配，分配方式类似于链表。
- **未初始化过的数据**：bss segment，存储未初始化的全局或者静态变量。
- **初始化过的数据**：data segment，存储已经初始化的全局或者静态变量。
- **程序段**：text segment，是程序代码在内存中的映射，存放函数体的二进制代码。

### 1.9. 内存保护、覆盖技术、内存交换、紧凑技术、虚拟内存技术？

- **内存保护**：保护各进程在自己的内存空间内运行，不会越界访问。
- **覆盖技术**：将程序分为多个段（即多个模块），常用的段常驻固定区，不常用段在需要时才调入覆盖区，替换覆盖区中原有的段。
- **内存交换**：内存紧张时，换出某些进程以腾出内存空间，再换入某些进程。
- **紧凑技术**：用于解决分区分配遗留碎片的问题，通过在内存中移动程序，将所有小的空闲区域合并为大的空闲区域。
- **虚拟内存技术**：允许一个作业分多次调入内存，其实现建立在离散分配的内存管理方式基础上，分为**请求分页存储管理**、**请求分段存储管理**以及**请求段页式存储管理**。
  - **请求调页功能**：访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存。
  - **页面置换功能**：内存空间不够时，将内存暂时用不到的信息换出到外存。

### 2.0. 外部碎片与内部碎片？

- **外部碎片**：指内存中某些空闲分区由于太小而难以利用上。
- **内部碎片**：指分配给某进程的内存区域中，如果有些部分没有用上，那么就说有内部碎片。

### 2.1. 操作系统内存管理方式？

> 连续分配管理，指为一个用户程序分配一个**连续的内存空间**，分为单一连续分配、固定分区分配和动态分区分配。
>
> 非连续分配管理，允许一个程序**分散**地装入到不相邻的内存分区中，分为基本分页存储管理、基本分段存储管理和基本段页式管理方式。

#### 连续分配管理

##### 1. 单一连续分配

- 思想：内存被分为**系统区和用户区**，系统区通常位于内存的低地址部分，用于存放操作系统相关数据。用户区用于存放用户进程相关数据。
- 特点：内存中只能有一道用户程序，用户程序独占整个用户区。
- 优点：实现简单、无外部碎片、无需进行内存保护。
- 缺点：只能用于单用户、单任务的操作系统中，有内部碎片，存储器利用率极低。
- ![1620549393027](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620549393027.png)

##### 2. 固定分区分配

- 思想：将整个用户空间划分为若干个**固定大小的分区**，在每个分区中只装入一道作业。
- 特点：该方式是最早、最简单的一种可运行多道程序的内存管理方式。
- 分类：分区大小相等、分区大小不等（需要有分区说明表）。
- 优点：实现简单、无外部碎片。
- 缺点：
  - 当用户程序太大时，可能所有的分区都满足不了要求，此时不得不采用覆盖技术来解决，降低性能。
  - 会产生内部碎片、内存利用率低。
- ![1620549849883](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620549849883.png)

##### 3. 动态分区分配

- 思想：又称可变分区分配，该方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小**动态地建立分区**，使分区大小适合程序的需要。
- 特点：系统分区大小和数目可变。
- 内存使用记录方式：
  - 空闲分区表：每个空闲分区对应一个表项，包含分区号、分区大小、分区起始地址信息等。
  - 空闲分区链：每个分区的起始部分和末尾部分分别设置前向指针和后向指针，其中起始部分可记录分区大小等信息。
- 动态分区分配算法：
  - 首次适应算法：First Fit，空闲分区按**地址递增**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 优点：最简单、性能最好。
    - 缺点：低地址部分会出现很多很小的空闲分区，增加查找的开销。
  - 最佳适应算法：Best Fit，空闲分区按**容量递增**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 缺点：会产生很多、很小、难以利用的外部碎片。
  - 最坏适应算法：Worst Fit，又称最大适应算法，空闲分区按**容量递减**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 缺点：每次都选择最大的分区分配，会导致后面的大进程无大分区可分配。
  - 邻近适应算法：Next Fit，空闲分区以**地址递增**的次序链接（循环链表），分配内存时从**上次查找结束的位置**开始查找，找到满足要求的第一个空闲分区。
    - 缺点：相比首次适应算法，会出现高地址部分被分割成多个小分区，导致后面的大进程无大分区可配。
- 优点：可根据装入进行大小动态分配、没有内部碎片、支持多道程序。
- 缺点：有外部碎片，可以通过**紧凑技术**来解决外部碎片。
- ![1620550822833](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620550822833.png)

#### 非连续分配管理

##### 1. 基本分页存储管理

- 思想：把**内存分为一个个相等的小分区**，再按照分区大小把**进程拆分一个个小部分**。

- 相关概念：

  ![1620554821838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620554821838.png)

  - 页框：又称页帧、内存块、物理块，是指将内存空间分为一个个大小相等的分区。
  - 页框号：又称页帧号、内存块号、、物理块号，是指每个页框的编号，是从0开始的。
  - 页面：又称页，是指将用户进程的地址空间分为与页框大小相等的一个个区域。
  - 页号：是指每个页面的编号，也是从0开始的。注意的是，进程最后一个页面可能没有一个页框那么大，所以当页框过大时，会产生过大的内部碎片。
  - 页面长度：又称页面大小，每个页面的内存大小，一般要为2的整数幂，且等同于页框大小。
  - 页面始址：对应页面在内存中的起始物理地址。
  - 页内偏移量：又称页内地址，逻辑地址在页面内的偏移量。
  - 页表：负责记录进程页面和实际存放的内存块之间的对应关系。
  - 页表长度：指这个页表中一共有几个页表项，即一共有几页。
  - 页表项：进程每一页对应一个页表项，页表项 = 页号 + 块号。而**每个页表项长度是相同的，所以页号是隐含的**（因为可以算出来最大页表项长度）。页表项也是存放在页框中的，实际应用中，往往会使得每个页框恰好可以装得下整数个页表项（这样不会有内部碎片）。
  - 页表项长度：每个页表项的内存大小。最大页表项长度 = 总内存大小 / 页面长度。

- 特点：

  - 操作系统以页框为单位，为各个进程分配内存空间，进程的每个页面分别放入一个页框中，即进程的页面和内存的页框是一一对应的关系。
  - 各个进程页面不必连续存放，也不必按照先后顺序来存放，可以放到不相邻的各个页框中。
  - 页面外的实际物理地址是离散的，页面内的实际物理地址是连续的。
  - **页式管理中的地址是一维的**，即只要给出了一个逻辑地址，系统就可以自动算出页号、页内偏移量，并不需要显示告诉页内偏移量占多少位，因为页面大小是系统确定好了的（页面大小确定则逻辑地址结构也确定了）。

- **物理地址转换**：

  - 页号 = 逻辑地址 / 页面长度
    - M位内存，K位页面大小时，高（M - K）位表示页号。
  - 页内偏移量 = 逻辑地址 % 页面长度
    - M位内存，K位页面大小时，低K位表示页内偏移量。
    - K位页内偏移量，则页面大小为2^K大小。
  - 页面始址 = 内存块号 * 内存块大小
  - 物理地址 = 页面始址 + 页内偏移量

- **基本地址变换机构**：

  - 作用：用于实现逻辑地址到物理地址转换的一组硬件机构，即**硬件实现物理地址转换**。
  - 相关概念：
    - 页表寄存器：PTR，存放页表在内存中的起始地址F和页表长度M。在进程未执行时，页表始址和页表长度放在进程控制块PCB中，当进程被调度时，操作系统内核才会把它们放到PTR中。
  - 计算过程：

  ![1620555134892](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620555134892.png)

  1. 根据逻辑地址，计算出页号（高M-K位）和页内偏移量（低K位）。
  2. 判断页号是否越界：页号 <= 页表长度 - 1。
  3. 第一次访存（可用快表优化）：查询页表，找到页号对应的页表项，确定页面的内存块号：页表项地址 = 页表起始地址 + 页号 * 页表项长度。
  4. 用内存块号和页内偏移量，计算得到物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  5. 第二次访存：访问目标内存单元。

- **具有快表的地址变换机构**：

  - 作用：是基本地址变换机构的改进版本，**加快访存速度**。
  - 相关概念：
    - **局部性原理**：
      - **时间局部性**：如果执行了程序中的某条指令，那么在不久之后很可能再被执行。如果某个数据被访问过，那么在不久之后很可能再被访问。（因为程序中存在大量的循环）
      - **空间局部性**：如果程序访问了某个存储单元，那么在不久之后其附近的存储单元很有可能被访问。（因为很多数据在内存中都是连续存放的）
      - 应用：由于局部性原理，程序很有可能连续多次查询同一个页面，即同一个页表项，因此产生了**快表**机制。
    - 快表：TLB，联想寄存器，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的**若干页表项**，以加速地址变换的过程。而内存中的页表成为慢表。
  - 计算过程：

  ![1620559002478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620559002478.png)

  1. 根据逻辑地址，计算出页号（高M-K位）和页内偏移量（低K位）。
  2. 判断页号是否越界：页号 <= 页表长度 - 1。
  3. **先查询快表**，如果要访问的页表项在快表中有副本，则直接取出，否则需要第一次访存：查询页表，找到页号对应的页表项，再**把页表项拷贝一份到快表中**。接着确定页面的内存块号：页表项地址 = 页表起始地址 + 页号 * 页表项长度。
  4. 用内存块号和页内偏移量，计算得到物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  5. 第二次访存：访问目标内存单元。

- **两级页表**：

  - 作用：**离散存储页表项**、页表项需要是调入内存（**虚拟内存技术**：页表项中增加是否已调入的标志位）。

  - 相关概念：

    ![1620560132360](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620560132360.png)

    - 二级页表：用于将常常的页表项分页。
    - 页目录表：又称外层页表、顶层页表，用于记录分页页表项后的二级页表的目录。
    - 逻辑地址结构：32位 = 10位一级页号 + 10位二级页号 + 页内偏移量

##### 2. 基本分段存储管理

- 思想：按照程序自身的逻辑关系，划分程序为若干个段，每一段都有一个段名（从0开始）。内存分配时，以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。

- 相关概念：

  - 段号：段名，段号的位数决定了每个进程最多可以分几个段。
  - 段内地址：即段内偏移量，段内地址的位数决定了每个段的最大长度是多少。
  - 段表：记录进程各个逻辑的段在内存中的存放位置，每个进程一张，包括段号、段长、段基址。
  - 段表项：进程的每一段逻辑段对应一个段表项。每个段表项长度是相同的，所以段号是可以隐含的，不需要占存储空间。
  - 段表项长度：每个段表项的内存大小。最大段表项长度 = 最大段长位数 + 最大地址位数。

- 物理地址变换过程：

  ![1620561048183](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620561048183.png)

  1. 根据逻辑地址，得到段号（高M/2位）、段内地址（低M/2位）。
  2. 判断段号是否越界：段号 <= 段表长度 - 1。
  3. 第一次访存（可用快表优化）：查询段表，找到对应的段表项：段表项始址 = 段表始址 + 段号 * 段表项长度。
  4. 检查段内地是否超过段长：段内地址 <= 段长。
  5. 计算得到物理地址：物理地址 = 段基址 + 段内地址。
  6. 第二次访存：访问目标内存单元。

##### 3. 段页式管理

- 思想：将进程按逻辑模块分段，接着将各段分页，再将内存空间分为大小相同的内存块，最后进程将各页面分别装入各内存块中。

- 作用：结合分段管理的优点和分页管理的优点，既能有效提高内存利用率，也容易实现信息的共享与保护。

- 物理地址变换过程：

  ![1620562681599](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620562681599.png)

  1. 根据逻辑地址，得到段号（高M/2位）、页号（低M/2-K位）、页内偏移量（低K位）。
  2. 判断段号是否越界：段号 <= 段表长度 - 1。
  3. 第一次访存（可用快表优化）：查询段表，找到对应的段表项：段表项始址 = 段表始址 + 段号 * 段表项长度。
  4. 检查页号是否越界：页号 <= 页表长度 - 1。
  5. 第二次访存（可用快表优化），根据段表中的页表存放块号、页号查询页表，找到对应的页表项：页表项始址 = 页表始址 + 页号 * 页表项长度。
  6. 根据页表项中的内存块号、页内偏移量，计算得出物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  7. 第三次访存，访问目标内存单元。

### 2.2. 分页管理与分段管理的区别？

|                  | 分页管理                                           | 分段管理                                                     |
| ---------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 管理维度         | 内存分区、进程分页，页是信息的物理单位             | 进程分段，段是信息的逻辑单位                                 |
| 透明度           | 对用户是透明的                                     | 对用户可见，用户编程需要显示给出段名                         |
| 单位大小         | 页大小固定，由系统决定                             | 段长度不固定，取决于编写的程序                               |
| 用户进程地址空间 | 是一维的，用户只需要给出一个助记符表示逻辑地址即可 | 是二维的，用户既要给出段名，也要给出段内地址                 |
| 目的             | 为了实现离散分配，提高内存利用率                   | 为了更好地满足用户需求                                       |
| 共享与保护       | 不容易实现信息共享与保护                           | 纯代码或可重入代码，更容易实现信息的共享与保护，只需要各进程指向同一个段即可实现共享 |
| 优点             | 内存空间利用率高、不会产生外部碎片                 | 没有内部碎片、容易实现信息共享与保护                         |
| 缺点             | 会产生少量的页内碎片、不容易实现信息共享与保护     | 段长过大难以分配连续空间、会产生外部碎片（可通过紧凑技术解决） |

### 2.3. 请求分页管理？

> **虚拟内存技术**：允许一个作业分多次调入内存，其实现建立在离散分配的内存管理方式基础上，分为**请求分页存储管理**、**请求分段存储管理**以及**请求段页式存储管理**。
>
> **请求调页功能**：访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存。
>
> **页面置换功能**：内存空间不够时，将内存暂时用不到的信息换出到外存。

- 特点：请求分页存储管理与基本分页存储管理的主要区别：需要操作系统提供**请求调页**（调入）以及**页面置换**（调出）功能。

- **页表机制**：也叫请求页表，是实现请求调页和页面置换功能的基础。对比基本分页存储管理的页表增加了4个字段：

  - 状态位：表示当前页面是否已经调入了内存。状态位为0代表当前页面还没有存在内存中。
  - 访问字段：用于记录当前页面最近被访问过几次，或者上次访问的时间，以供置换算法选择换出页面时参考。
  - 修改位：用于标记当前页面调入内存后是否被修改过（没有被修改过的页面是不需要写会外存的）。
  - 外存地址：表示当前页面在外存中的存放位置。

- **缺页中断机构**：**请求调页**的基础，在请求分页系统中，当要访问的页面不存在时，会产生一个**缺页中断**（内中断-故障），然后操作系统的缺页中断处理程序处理该中断。此时的缺页进程会**阻塞**，被放入阻塞队列，在调页完成后，操作系统才将其唤醒，放回就绪队列。

  缺页中断机构处理中断逻辑如下：

  - 如果内存中有空闲块，则为进程分配一个空闲块，将所缺失的页面装入该块，并修改请求页表中相应的页表项。
  - 如果内存中没有空闲块，则由**页面置换算法**选择一个页面淘汰，同时若该页面在内存期间被修改过，则还需要将其写回外存，而未修改过的页面则不需要写回外存。

- **地址变换机构**：

  与基本分页存储管理的页表不同的是：

  - 找到页表项时，需要判断页面是否在内存中。
  - 若页面不在内存中，则需要请求调页。
  - 如果调入页面内存空间不够时，需要进行页面置换。
  - 页面被访问、页面调入以及页面调出后，需要修改请求页表中相应的页表项。

![1620573633869](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620573633869.png)

### 2.4. 页面置换算法？

请求分页系统中，在内存空间不够时，由操作系统负责将内存中暂时用不到的信息换出到外存。

页面置换算法用于决定应该换出**哪个页面**到外存。

**页面的换入、换出**需要磁盘I/O，开销比较大，因此好的页面置换算法应该追求**更少的缺页率**，以减少页面换入、换出的次数。

缺页不等于页面置换，只有在缺少空闲内存块才需要发生页面置换。

#### 1. 最佳置换算法OPT

- 概念：optimal，每次淘汰**未来永不使用**或者**未来最长时间不再被访问**（顺方向）的页面。
- 优点：可以保持**最低的缺页率**。
- 缺点：**实际上无法实现**，因为操作系统无法提前预判未来的页面访问序列。

![1620648468359](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620648468359.png)

#### 2. 先换先出置换算法FIFO

- 概念：first in first out，每次淘汰**最早进入内存**的页面。
- 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时，只需要选择对头页面即可。
- **Belady异常**：贝拉底异常，指当为进程分配的内存块增大时，缺页的次数不减反增的异常现象。FIFO算法是唯一一个会出现Belady异常的页面置换算法。
- 优点：实现简单。
- 缺点：会有Belady异常，与运行时的规律不适应（因为先进入的页面后面也有可能最经常被访问），性能极差。 

![1620650037437](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620650037437.png)

![1620650005876](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620650005876.png)

#### 3. 最近最久未使用算法LRU

- 概念：least recently used，每次淘汰**最近最久未使用**（逆方向）的页面。
- 实现方法：在每个页面对应的页表项中，用**访问字段**来记录该页面从上次被访问到现在经历的时间t，当要淘汰页面时，选择页面中t值最大的，就是最近最久未使用的页面了。
- 优点：考虑到了时间局部性，性能好，实际应用较多。
- 缺点：实现困难，开销大，实现需要专门的硬件支持。

![1620649947028](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620649947028.png)

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:29
 **/
public class LRUCache {
    private LinkedHashMap<Integer,Integer> cache;
    private int capacity;   //容量大小

    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        cache = new LinkedHashMap<>(capacity);
        this.capacity = capacity;
    }

    // 使用过则需要放到链表尾部, 代表经常被使用，而链头代表的是最近最久未被使用的结点
    public int get(int key) {
        //缓存中不存在此key，直接返回
        if(!cache.containsKey(key)) {
            return -1;
        }

        int res = cache.get(key);
        cache.remove(key);   //先从链表中删除
        cache.put(key,res);  //再把该节点放到链表末尾处
        return res;
    }

    // 使用过则需要放到链表尾部, 代表经常被使用，而链头代表的是最近最久未被使用的结点
    // 在链表满时，还需要删除最近最久未被使用的结点，即链头结点
    public void put(int key,int value) {
        if(cache.containsKey(key)) {
            cache.remove(key); //已经存在，在当前链表移除
        }
        if(capacity == cache.size()) {
            //cache已满，删除链表头位置
            Set<Integer> keySet = cache.keySet();
            Iterator<Integer> iterator = keySet.iterator();
            cache.remove(iterator.next());
        }
        cache.put(key,value);  //插入到链表末尾
    }
}

```

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap内部removeEldestEntry方法实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:59
 **/
class LRUCache {
    private Map<Integer, Integer> map;
    private int capacity;
	
    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        this.capacity = capacity;
        map = new LinkedHashMap<Integer, Integer>(capacity, 0.75f, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry eldest) {
                // 容量大于capacity 时就删除，删除最近最久未被使用的空闲结点
                return size() > capacity;
            }
        };
    }
    public int get(int key) {
        //返回key对应的value值，若不存在，返回-1
        return map.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        map.put(key, value);
    }
}
```

#### 4. 时钟置换算法CLOCK

- 概念：又称最近未用算法（NRU，not Recently Used），对比OPT和LRU，这是一种**性能和开销较平衡**的算法。
- 实现方法：

1. 为每个页面设置访问位（**访问位为1表示最近访问过，访问位为0表示最近没有访问过**），再将内存中的页面通过链表指针链接成一个循环队列。
2. 当页面被访问时，访问位将置为1。
3. 在淘汰页面时，循环检查访问位，把为1的置为0，为0的淘汰，如果第一轮全为1，则置换为0后进行第二轮扫描，所以**最多会经过2轮扫描**。
4. 而被置换进行的页面会被置为1，且扫描指针指向下一个页面。

- 优点：实现简单、算法开销小。
- 缺点：未考虑页面是否被修改过。

![1620651040375](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620651040375.png)

#### 5. 改进型时钟置换算法

- 概念：由于淘汰被修改过的页面时，需要写回外存，所以在时钟置换算法CLOCK的基础上，应该优先淘汰**最新没被修改过、没被访问过的**页面，避免写回外存的I/O操作。
- 实现方法：

1. 每个页面增加修改位（**修改位为0表示没有被修改过，修改位为1表示页面被修改过**），用（访问位，修改位表示），将所有可能被置换的页面排成一个循环队列。
2. 第一轮扫描：扫描第一个（0，0）即**最近没被修改过、没被访问过**的页面，本轮扫描不修改任何标志位。
3. 第二轮扫描：第一轮失败后，需要重新扫描。扫描第一个（0，1）即**最近被修改过、没被访问过**的页面用于替换，本轮扫描过的访问位置为0。
4. 第三轮扫描：第二轮失败后，需要重新扫描。扫描第一个（0，0）即**最近没被修改过、但被访问过**的页面用于替换，本轮扫描不修改任何标志位。
5. 第四轮扫描：第三轮失败后，需要重新扫描。扫描第一个（0，1）即**最近被修改过、也被访问过**的页面用于替换。改进型CLOCK算法淘汰一个页面**最多经过4轮扫描**。

- 优点：算法开销较小、性能也不错、考虑了页面是否被修改过（有修改位和访问位）。

![1620652055064](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620652055064.png)

### 2.5. 死锁的条件与解决方式？

> 哲学家进餐问题：每位哲学家都在等待自己右边的人放下筷子，即这些哲学家进程都因等待筷子资源而被阻塞，这就是发生了死锁。

- **死锁**：指在并发环境，**各进程因竞争资源而造成的一种互相等待对方手里资源**，导致各进程都阻塞，无法向前推进的现象。发生死锁后，若无外力干涉，这些进程都将无法向前推进。

- **死锁产生的必要条件**：产生死锁必须**同时满足**以下四个条件，只要其中任一条件不成立，死锁就不会发生。

  - **互斥条件**：进程对所分配的**资源不允许其他进程访问**，若其他进程访问该资源，只能等待至占有该资源的进程释放该资源。
  - **不剥夺条件**：进程所获得的资源在未使用完之前，**不可被剥夺**，只能主动释放。
  - **请求和保持条件**：进程获得一定的资源后，又对其他资源发出请求，且由于互斥条件进入阻塞状态后，还对自己占有的资源**保持不放**。
  - **循环等待条件**：存在一种**进程资源的循环等待链**，链中的每一个进程占有的资源被下一个进程所等待。
    - 注意！发生死锁时一定有循环等待，但发生循环等待时未必发生死锁（循环等待是死锁的必要不充分条件）。但如果系统中每类资源都只有一个，那循环等待则是死锁的充分必要条件。

- **死锁场景**：**对不可剥夺资源的不合理分配，可能会导致死锁。**

  - 对系统资源的竞争：各进程对不可剥夺资源的竞争可能引起死锁（如打印机），而对可剥夺资源的竞争是不会引起死锁的（如CPU）。
  - 进程推进顺序非法：请求和释放资源的顺序不当从而导致死锁。

- **死锁的处理策略**：

  - **预防死锁**：是**不允许死锁发生的静态策略**，破坏死锁的四个必要条件中的某一个。

    - **破坏互斥条件**：
      - 操作系统层面：采用SPOOLING技术，指操作系统用于把独占设备在逻辑上改造成共享设备。
      - 缺点：并不是所有的资源都可以改造成可共享使用的资源。很多时候都无法破坏互斥条件。
      - **Java层面**：乐观锁，CAS。
    - **破坏不可剥夺条件**：
      - 操作系统层面：进程请求不到其他资源时，必须立即释放保持的所有资源，或者考虑进程优先级强行剥夺想要的资源。
      - 缺点：实现比较复杂、释放资源可能会造成进程前一阶段的工作失效、反复申请和释放资源会增加系统开销，降低系统吞吐量、方案一可能会导致进程饥饿的发生。
      - **Java层面**：悲观锁，synchronized、ReentrantLock。
    - **破坏请求和保持条件**：
      - 操作系统层面：采用**静态分配方式**，进程运行需要一次申请完所有需要的资源，未满足则不能投入运行。一旦运行后，资源一直归它所有，且它不会再请求其他资源。
      - 缺点：资源利用率极低、可能会导致别的进程发生饥饿。
      - **Java层面**：数据库deadLock超时，即数据库通过锁定等待超时解决死锁。
    - **破坏循环等待条件**：
      - 操作系统层面：采用**顺序资源分配方式**，对系统该资源编号，规定每个进程必须按编号递增的顺序请求资源，对于编号相同的资源会一次申请完。
      - 缺点：不方便增加新的设备、实际使用资源的顺序可能和编号递增顺序不一致，可能会导致资源浪费、用户变成麻烦。

  - **避免死锁**：是**不允许死锁发生的动态策略**，避免系统进入**不安全状态**。

    - **安全序列**：指如果系统按照这种序列分配资源，每个进程都能顺利完成（安全序列可能有多个）。此时系统为**安全状态**，一定不会发生死锁。而如果分配资源后，系统中找不出任何一个安全序列，则系统进入了**不安全状态**，意味着之后可能发生死锁。

    - **银行家算法**：在资源分配之前先预判本次分配是否会导致系统进入不安全状态，从而决定是否答应该分配的请求，用于**避免死锁**。

      - 实现思路：保证优先分配资源给进程后，进程能够顺利执行完并归还资源，确保是安全状态。
      - 实现方法：Max矩阵、Allocation矩阵、Need矩阵、Available数组、Request数组、预判计算、回溯资源。

      ![1620737316076](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737316076.png)

  - **死锁的检测和解除**：**允许死锁发生**，系统负责检测出死锁并解除。

    - 死锁的检测：

      - 数据结构：两种结点（进程结点、资源结点），两种边（请求边、分配边）。
      - 算法思想：最终能消除所有变，则称这个图是可完全被简化的，此时一定没有发生死锁（相当于找到了一个安全序列）。反之，如果**最终不能消除所有边，那么此时就发生了死锁（死锁定理）**。
      - 实现方法：找到孤点进程（有向边相连以及不阻塞的进程）、简化边、继续简化...

      ![1620737385049](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737385049.png)

    - **死锁的解除**：

      - 死锁的进程：用死锁检测算法化简资源分配图后，还连着边的那些进程才是死锁进程。
      - **主要方法有**：
        - **资源剥夺法**：**挂起（暂时放到外存上）某些死锁进程，并抢占它的资源**，将这些资源分配给其他死锁的进程。
          - 缺点：需要防止进程挂起过久导致出现饥饿问题。
        - **撤销进程法**：又称**终止进程法**，强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。
          - 缺点：虽然实现简单，但付出的代价是很大的。
        - **进程回退法**：让一个或者多个死锁进程回退到足以避免死锁的地步。
          - 缺点：操作系统需要记录进程的历史记录，设置还原点。
      - **考虑的维度**：进程优先级低的、执行时间少的、距离完成时间较久的、持有资源多的、批处理式的死锁进程。 

### 2.6. 死锁、饥饿、死循环？

- **死锁**：指各进程互相等待对方手里资源，导致各进程都阻塞，无法向前推进的现象。比如哲学家进餐问题。

- **饥饿**：指由于长期得不到想要的资源，某进程无法向前推进的现象。比如短进程优先（SPF）算法，会导致长进程饥饿问题。

- **死循环**：指某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序员故意设计的。

  |          | 死锁                                                         | 饥饿                                                         | 死循环                                 |
  | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------- |
  | 共同点   | 都是进程无法向前顺利推进的现象                               | -                                                            | -                                      |
  | 进程数量 | 至少有两个或者两个以上的进程                                 | 可能只有一个进程                                             | 可能只有一个进程                       |
  | 进程状态 | 一定处于阻塞状态                                             | 可能是阻塞状态（长期得不到I/O设备），也可能是就绪状态（长期得不到处理机） | 可以是运行状态                         |
  | 原因     | 由于**操作系统**分配资源策略不合理导致的（各进程互相等待对方手里的资源） | 由于**操作系统**分配资源策略不合理导致的                     | 由代码逻辑错误导致的（**管理者问题**） |



## 4. 设计模式基础

### 1.1. 六大原则

|              | 总结                                                     |
| ------------ | -------------------------------------------------------- |
| 单一职责原则 | 实现类要职责单一                                         |
| 里氏替换原则 | 不要破坏继承体系                                         |
| 依赖倒置原则 | 要面向接口编程                                           |
| 接口隔离原则 | 设计接口时要精简单一                                     |
| 迪米特法则   | 要减少对其他类的直接依赖、减少类对外暴露的方法，降低耦合 |
| 开放原则     | 要对扩展开放，对修改关闭                                 |

#### 1. 单一职责原则

- 概念：**一个类只负责一项职责**，不要存在本职责外导致类发生变更的原因。
- 问题由来：如果类T负责两个不同的职责P1和P2，当职责P1需求发生改变修改T时，可能会导致P2功能发生故障。
- 原因分析：出现了职责扩散。
- 解决方案：
  - 根据P1和P2职责，划分为类1和类2。
  - 在职责扩散到无法控制之前，对代码进行部分重构。
- 优点：
  - 可以降低类的复杂度，一个类只负责一项职责，逻辑简单清晰。
  - 可提高类的可读性和系统的可维护性。
  - 减少需求变更时对其他功能的影响，减少出现的风险。
- 总结：
  - 只有逻辑足够简单，才可以在代码级别上违反单一职责原则。
  - 只有类中方法数量足够少，才可以在方法级别上违反单一职责原则。
  - 模块化的程序设计以及在员工工作安排上面，都适合单一职责原则。

#### 2. 里氏替换原则

- 概念：子类可以扩展父类的功能，但不能改变父类原有的功能；子类可以替换父类，但方法或者行为不能发生改变。即**子类可以扩展父类的功能，但不能改变父类原有的功能**。
- 问题由来：子类B在扩展新功能时，有可能会导致父类原有的功能发生故障。
- 原因分析：继承的弊端，会给程序代理侵入性，使得程序的可移植性减低，增加了对象的耦合性。
- 解决方案：
  - 类B扩展新功能时，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。
  - 如果子类对父类实现的方法进行修改，会对整个继承体系造成破坏，当子类要修改时，必须考虑所有的子类。并且，如果修改了父类，那么所有的子类功能可能都会发生故障。
- 优点：如果不遵循里氏替换原则，一开始程序可能是好好的，但是在之后的迭代过程中，代码出现问题的几率会大大增加，尤其当另外一个人接手项目之后。
- 总结：
  - 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。
  - 子类中可以增加自己独特的方法。
  - 当子类的方法重载父类的方法时，方法的前置条件（形参）要比父类方法更宽松。
  - 当子类的方法实现父类的抽象方法时，方法的后置条件（返回值）要比父类更严格。

#### 3. 依赖倒置原则

- 概念：**高层模块不能依赖底层模块**，二者都应该依赖其抽象；**抽象不应该依赖细节**，细节应该依赖抽象。
- 问题由来：类A（高层模块）本来依赖类B（低层模块），但现在要修改类A依赖类C（低层模块），修改程序时可能会导致不必要的风险。
- 解决方案：将类A改为依赖接口T，而类B和类C分别实现接口T，此时**类A可以通过接口T，间接访问类B和类C，大打降低了修改类A的几率**。
- 总结：
  - 相对于细节的多变性，抽象的东西要稳定得多。依赖倒置原则的核心思想是面向接口编程，通过使用接口或者抽象类来制定好规范和契约，不用去涉及任何具体的操作，将展开细节的任务交给实现类去完成，以达到解耦的目的。
  - 低层模块尽量都要有接口或者抽象类，高层模块尽量通过接口或者抽象类的形式访问低层模块。
  - 使用抽象类时，要遵循里氏替换原则。

#### 4. 接口隔离原则

- 概念：客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖都应该建立在**最小的接口**上面。
- 问题由来：类A通过接口T依赖了类B和类D，但类D不是类A想要依赖的。
- 解决方案：将臃肿的接口T拆分为独立的Tb和Td接口，类A只需要依赖Tb即可。
- 优点：提高内聚，减少对外交互，用最少的方法完成最多的事情。
- 总结：
  - 尽量细化接口，建立单一接口，使得接口中的方法尽量少。但要有限度，过小则会导致接口数量过多，增加复杂度。
  - 为单个类建立专用的接口，不要包含太多。依赖几个专用的接口要比依赖一个综合的接口灵活得多，即可以提高系统的灵活性和可维护性。
  - 为依赖接口的类定制服务，只暴露给调用类需要的方法，建立最小的依赖关系。
- 区别单一职责：
  - 单一职责注重的是职责；接口隔离注重的是接口依赖的隔离。
  - 单一职责约束的是实现类，其次才是接口和方法，针对的是程序中的实现细节；接口隔离约束的是接口，针对的是抽象和整体框架的构建。

#### 5. 迪米特法则

- 概念：又称**最少知道原则**，要求一个对象应该对其他对象有最少的了解。
- 优点：降低类之间的耦合，每个类尽量减少对其他类的依赖，尽量减少对外暴露的方法，使得功能模块独立，低耦合。
- 总结：
  - 减少对其他类的依赖，只通过成员变量、方法的输入输出参数来对类进行注入，减少方法体内部类的直接使用。
  - 减少类对外暴露的方法。
  - 虽然遵循迪米特法则可以避免和非直接的类通信，但如果要通信，则必然会通过一个中介发生联系，而过分地使用迪米特法则，会产生大量的中介和中间传递类，导致系统复杂度变高。

#### 6. 开闭原则

- 概念：软件中的对象（类、模块、函数等）应该**对于扩展是开放的，对与修改是关闭的**。
- 问题由来：对软件原有代码进行修改时，可能会将错误引入原本已经测试过的代码中，破坏原有系统。
- 解决方案：当软件需求发生变化时，尽量通过扩展实体的行为实现需求变化，而不是通过修改原有的代码来应对变化。

### 1.2. UML图

#### 1. 类UML

![1620827681262](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827681262.png)

#### 2. 接口UML

![1620827737253](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827737253.png)

#### 3. 类图UML

![1620827711036](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827711036.png)

#### 4. 实现关系UML

![1620827793083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827793083.png)

#### 5. 泛化（继承）关系UML

![1620827830674](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827830674.png)

#### 6. 依赖关系UML

![1620827777826](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827777826.png)

#### 7. 一般关联关系UML

![1620827947066](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827947066.png)

#### 8. 组合关系UML

![1620827976361](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827976361.png)

#### 9. 聚合关系UML

![1620827988535](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827988535.png)

### 1.3. 单例模式

某个类只能生成一个实例，该实例被全局访问，比如Spring容器一级缓存里的单例池。

- 优点：唯一访问、提高性能
- 缺点：不适合有状态且需要变更的实例
- 实现方式：**所有方式都会被反序列破坏，但是都可以通过单例对象添加Object#readResolve() 方法, 直接返回单例对象即可防止破坏。**

|                       | 懒加载 | 线程安全 | 其他优点     | 缺点                       | 推荐 |
| --------------------- | ------ | -------- | ------------ | -------------------------- | ---- |
| 饿汉式                | 否     | 是       | 简单、速度快 | 提早占用内存、不可参数构造 | 是   |
| 懒汉式                | 是     | 否       | 可参数构造   | 线程不安全                 | 否   |
| 懒汉式-锁实现         | 是     | 是       | 可参数构造   | 加锁导致效率低下           | 否   |
| 懒汉式-静态内部类实现 | 是     | 是       | -            | 不可参数构造               | 是   |
| 双重检查锁            | 是     | 是       | 可参数构造   | 实现较复杂、可被反射破坏   | 是   |
| 枚举类                | 是     | 是       | 不被反射破坏 | 实现较复杂、不可参数构造   | 是   |

#### 1. 饿汉式

```java
/**
 * 1、饿汉式
 */
public class Singleton1 implements Serializable {
    private static final Singleton1 instance = new Singleton1();

    public static Singleton1 getInstance(){
        return instance;
    }
    
    private Singleton1() {
        // 防⽌反射获取多个对象的漏洞 true
        if(instance != null){
            throw new RuntimeException("获取单例异常!");
        }
    }
    
    // 防止反序列化获取多个对象的漏洞
    private Object readResolve() throws ObjectStreamException {
        return instance;
    }

}
```

#### 2. 懒汉式

```java
/**
 * 2、懒汉式-线程不安全
 */
public class Singleton2 implements Serializable {

    private static Singleton2 instance;// 类初始化为null

    public static Singleton2 getInstance(int code){
        if(instance == null){
            instance = new Singleton2(code);
        }
        return instance;
    }
}
```

#### 3. 懒汉式-锁实现

```java
/**
 * 3、懒汉式-线程安全-锁方法实现
 */
public class Singleton3 implements Serializable {
    
    private static Singleton3 instance;// 类初始化为null

    public static synchronized Singleton3 getInstance(int code){
        if(instance == null){
            instance = new Singleton3(code);
        }
        return instance;
    }
}
```

#### 4. 懒汉式-静态内部类实现

```java
/**
 * 4、懒汉式-线程安全-静态内部类
 */
public class Singleton4 implements Serializable {
    
    private static class Holder {
        private static final Singleton4 SINGLE_TON = new Singleton4();
    }
    
    public static Singleton4 getInstance(){
        return Holder.SINGLE_TON;
    }
}

```

#### 5. 双重检查锁

```java
/**
 * 5、双重检查锁
 */
public class Singleton5 implements Serializable {

    // volatile防止重排序导致实例化未完成
    private volatile static Singleton5 instance;// 必须要保证可见性

    public static Singleton5 getInstance(int code){
        // 第一次减少锁的开销
        if(instance == null){
            synchronized (Singleton5.class){
                // 第二次防止重复
                if(instance == null){
                    instance = new Singleton5(code);
                }
            }
        }

        return instance;
    }
}
```

#### 6. 枚举类

```java
/**
 * 6、枚举(JDK 1.5后)
 */
public class Singleton6 implements Serializable {

    private static enum SingletonEum {
        INSTANCE;// 创建一个枚举类, 天生就是单例的

        private Singleton6 singleton6;

        SingletonEum() {// 创建时创建singleton6单例对象
            singleton6 = new Singleton6();
        }

        public Singleton6 getInstance(){
            return singleton6;
        }
    }

    // 调用getInstance()才使用枚举类, 才对枚举类进行加载, 再枚举类的构造方法中创建了单例
    public static Singleton6 getInstance() {
        return SingletonEum.INSTANCE.getInstance();
    }
}
```

### 1.4. 工厂模式

#### 1. 简单工厂模式

简单工厂模式是**由一个工厂对象决定创建出哪一种产品类的实例**，是工厂模式家族中最简单实用的模式，可以理解为是不同工厂模式的一个特殊实现。

- 组成：
  - 工厂类角色：简单工厂类，即是根据类型创建具体产品，是具体产品的逻辑封装。
  - 抽象产品角色：一般是指具体产品继承的父类或实现的接口。
  - 具体产品角色：具体的实现类，相当于抽象业务的落地。
- 优点：
  - 解耦：实现了对责任的分割，专门的工厂类用于创建产品，客户类免除了除直接创建产品对象的责任，而仅仅是消费产品。
  - 简单：客户类无须知道所创建的具体产品类的类名，只需要知道具体产品类的对应参数即可。
  - 可配置（解决方案）：通过引入配置文件，可以在不修改任何客户类代码的情况下，更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。
- 缺点：
  - 中心化：由于工厂类集中了所有产品的创建逻辑，一旦不能工作, 整个系统都要受到影响。
  - 类爆炸：使用简单工厂模式将会增加系统中类的个数，在一定程度上增加了系统的复杂度和理解度。
  - 不灵活：系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。
  - 不够体系化：由于使用了静态工厂方法，造成了工厂角色无法形成基于继承的等级结构。
- 使用场景：
  - 工厂类负责创建的对象比较少时。
  - 客户类只知道传入工厂的参数，对于如何创建对象逻辑不关心时。
  - 由于简单工厂很容易违反高内聚责任分配原则，因此一般只在很简单的情况下应用。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        SimpleFatory simpleFatory = new SimpleFatory();
        simpleFatory.createProduct("HighLvA");
        simpleFatory.createProduct("B");
    }
}

// 抽象接口
public abstract class Product {

    public Product() {

    }
}

// 具体产品实现类
public class ProductA extends Product{

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }
}

// 简单工厂类
public class SimpleFatory {

    public Product createProduct(String type){
        switch (type){
            case "HighLvA":
                return new ProductA();
            case "B":
                return new ProductB();
            default:
                break;
        }

        return null;
    }
}
```

#### 2. 工厂方法模式

工厂方法模式的核心思想是**封装类中变化的部分**，提取其中个性化善变的部分为独立类，通过依赖注入以达到解耦、复用和方便后期维护拓展的目的。工厂方法模式是对简单工厂模式的**工厂做了抽象**。

- 组成：
  - 抽象工厂角色：工厂方法模式的核心，是具体工厂角色必须实现的接口或必须继承的父类，也就是对具体工厂的抽象。
  - 具体工厂角色：含有和具体业务逻辑有关的代码, 由客户类指明创建, 用于创建对应具体的产品对象。
  - 抽象产品角色：对比简单工厂模式，抽象逻辑没变。一般是指具体产品继承的父类或实现的接口。
  - 具体产品角色：对比简单工厂模式，抽象逻辑没变。具体的实现类，相当于抽象业务的落地。
- 优点：
  - 去中心化：工厂方法模式去掉了简单工厂模式中工厂的静态属性，使得它可以被子类继承，这样在简单工厂模式里集中在工厂方法上的压力，就可以由工厂方法模式里不同的工厂子类分担。
  - 开闭原则： 当有新的产品产生时，只要按照抽象产品角色、抽象工厂角色提供的合同来生成，那么就可以被客户使用，而不必去修改任何已有的代码。
- 缺点：
  - 类爆炸：在添加新产品时需要编写新的具体产品类，而且还要提供与之对应的具体工厂类。可见系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，而更多的类需要编译和运行，会给系统带来一些额外的开销。
- 使用场景：
  - 对于某种产品，调用者清楚地知道应该使用哪个具体工厂服务，从而实例化该具体工厂，生产出具体的产品。比如Java Collection中的iterator()方法。
  - 只是需要一种产品，而不想知道，也不需要知道究竟是哪个工厂生产的，即最终选用哪个具体工厂的决定权在生产者一方，生产者根据当前系统的情况来实例化一个具体的工厂返回给使用者，而这个决策过程对于**使用者来说是透明的**。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        FactoryProductA factoryProductA = new FactoryProductA();
        factoryProductA.createProduct();

        FactoryProductB factoryProductB = new FactoryProductB();
        factoryProductB.createProduct();
    }
}

// 抽象产品类
public abstract class Product {

    public Product() {

    }
}

// 产品实现类
public class ProductA extends Product {

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }
}

// 抽象工厂类
public interface AbstractFatory {

    public Product createProduct();
}

// 工厂实现类
public class FactoryProductA implements AbstractFatory{

    @Override
    public Product createProduct() {
        return new ProductA();
    }
}
```

#### 3. 抽象工厂模式

抽象工厂是指当有**多个抽象角色**时使用的一种工厂模式，可以向客户提供提供一个接口，使客户在不必指定产品的具体参数情况下（工厂方法模式），创建**多个产品族中**的产品对象（由于有抽象工厂角色对多个工厂进行聚合, 暴露各种产品生产的接口）。

> 工厂方法模式，针对的是多个产品系列结构（同一个抽象产品角色, 同一个产品族）。
>
> 抽象工厂模式，针对的是多个产品族结构（多个抽象产品角色,多个产品族）。
>
> 一个产品族内有多个产品系列（同一个抽象产品角色, 同一个产品）。

- 核心思想：在抽象工厂中，增加创建其他产品族的生产接口，并在具体子工厂中实现。
- 优点：
  - 抽象工厂：也是工厂方法模式的优点，分离了具体的类，客户通过抽象接口操纵实例，产品的类名也在具体工厂的实现中被分离，它们不出现在客户代码中。
  - 多产品族：易于交换产品系列，只需要改变具体工厂或者调用不同的接口，即可生产不同的产品。
  - 产品一致：有利于产品的一致性，当一个系列的产品对象被设计成一起工作时，抽象工厂很容易实现一个应用一次只能使用同一个系列的对象。
- 缺点：
  - 难以支持新种类的产品：产品族扩展费力，因为抽象工厂接口确定了可以被创建的产品集合，假如产品族需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。因此使用抽象工厂模式时，对产品等级结构的划分非常重要。
- 使用场景：
  - 一个系统要独立于它的产品创建、组合和表示时（无关性）。
  - 一个系统要由**多个产品系列**中的一个来配置时。
  - 需要强调一系列相关的产品对象的设计以便进行联合使用时。
  - 提供一个产品类库, 而只想显示它们的接口而不是实现时。
  - 如果创建的产品是一系列相互关联或者相互依赖的产品组时，可以使用抽象工厂模式。而如果产品间不存在关联或约束时，则使用多个独立的工厂来对产品进行创建，则更适合一点。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        FactoryProductA factoryProductA = new FactoryProductA();
        factoryProductA.createProduct();
        factoryProductA.createNewProduct();

        FactoryProductB factoryProductB = new FactoryProductB();
        factoryProductB.createProduct();
        factoryProductB.createNewProduct();
    }
}

// 抽象产品类
public abstract class Product {

    public Product() {

    }
}

// 产品实现类
public class ProductA extends Product {

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }

}

// 抽象工厂类
public interface AbstractFatory {

    public Product createProduct();

    public NewProduct createNewProduct();
}

// 工厂实现类
public class FactoryProductA implements AbstractFatory {

    @Override
    public Product createProduct() {
        return new ProductA();
    }

    @Override
    public NewProduct createNewProduct() {
        return new NewProductA();
    }
}
```

### 1.5. 策略模式

定义一组算法，将**每一种算法**封装起来，从而使它们可以相互切换。

- 组成：
  - 策略封装角色：上层访问策略入口，持有抽象策略的引用（聚合关系）。
  - 抽象策略角色：提供接口或抽象类，定义策略组必须拥有的方法和属性。
  - 具体策略角色：实现抽象策略，定义具体的算法逻辑。
- 优点：
  - 重用：策略模式提供了管理相关**算法族**的方法，其等级结构定义了一个算法或者行为族，恰当使用继承和接口可以把公共的代码进行抽取，避免代码重复。
  - 减少嵌套：if-else语句不易维护，使用策略模式可以避免使用多重条件if-else语句。如果把采取哪一种算法或行为的逻辑与算法或行为本身的逻辑混合在了一起，统统列在一个语句里面，那这样比使用继承的办法还要原始和落后。
- 缺点：
  - 算法列表：客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择适当的算法类，因此，策略模式只适用于客户端知道算法或者行为的情况。
  - 类爆炸：由于策略模式把每个具体的策略实现都单独封装成类，如果备选的策略很多，那么对象的数目就会很可观。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Context context = new Context(new StrategyB());
        context.useStrateyAlgorithmLogic();
    }
}

// 策略封装上下文对象
public class Context {

    private Strategy strategy;

    public Context(Strategy strategy) {
        this.strategy = strategy;
    }

    /**
     * 调用策略
     */
    public void useStrateyAlgorithmLogic(){
        strategy.algorithmLogic();
    }
}

// 策略抽象接口
public interface Strategy {

    // 具体算法逻辑
    public void algorithmLogic();
}

// 具体策略A
public class StrategyA implements Strategy{

    @Override
    public void algorithmLogic() {
        System.out.println("这是策略A...");
    }
}
```

### 1.6. 命令模式

将一个请求封装为一个对象，从而可以使用不同的请求对客户进行**参数化、请求排队、记录请求日志、命令撤销**等操作。

- 特点：当需要向某些对象发送请求，但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个时使用命令模式时使用，可以使得请求发送者与请求接收者相解耦。
- 组成：
  - 抽象命令类：Command，抽象出命令对象，可以根据不同的命令类型，写出不同的实现类。
  - 具体命令类：ConcreteCommand，实现了抽象命令对象的具体实现。
  - 调用者/请求者：Invoker，请求的发送者，通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令之间存在关联。
  - 接收者：Receiver，执行与请求相关的操作，真正执行命令的对象，具体实现对请求业务的处理。
  - 客户类：Client，在客户类中创建调用者对象，具体命令类对象，在创建具体命令对象时指定对应的接收者。
- 优点：
  - 解耦：可以降低系统的耦合度。
  - 易用：可以容易地将新的命令加入到系统中。
  - 设计方便：可以容易地设计一个命令队列和宏命令（组合命令）。
  - 可撤销与重试：可以方便地实现对请求的Undo和Redo。
- 缺点：
  - 类爆炸：由于针对每一个命令都需要设计一个具体命令类，所以在使用命令模式时，可能会导致某些系统有过多的具体命令类。当某些系统可能需要大量具体命令类时，将会影响命令模式的使用。
- 使用场景：
  - 网络传输：命令的调用者和命令执行者之间存在不同的生命周期，意味着命令发送了并不是立即执行。即命令发送出去后，原先的请求发出者可能已经不存在了，而命令对象本身还在，可以通过网络传输到另一台机器，给执行者执行。比如, Struts2中的action调用。
  - 统一管理：命令需要进行各种管理逻辑，比如对多个命令的统一控制。
  - 撤销重试：系统需要支持撤销（反撤销)）或者重试操作时。命令对象可以把状态存储起来，等到客户端需要撤销命令所产生的效果时，可以调用undo（）方法，把命令所产生的效果撤销掉。命令对象还可以提供redo()方法，以供客户端在需要时再重新实施命令效果。比如数据库中的事务机制底层实现。
  - 回调：回调callBack（）系统的使用，其中callBack（）讲的就是先将一个函数登记上，然后在以后调用此函数。
  - 命令日志：将系统中所有命令记录在日志里，待系统奔溃时，可以根据日志中一条一条命令重新调用execute（）， 从而恢复系统在崩溃前所做的数据更新。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Receiver receiver = new Receiver();
        RemoteInvoker remoteInvoker = new RemoteInvoker(new TurnUpCommand(receiver), new TurnDownCommand(receiver));

        // 操作遥控器
        remoteInvoker.turnDownButton();
        remoteInvoker.turnUpButton();
        remoteInvoker.undoButton();
        remoteInvoker.undoButton();
        remoteInvoker.redoButton();
        remoteInvoker.redoButton();
    }
}

// 接收者实现类-电视机
public class Receiver {

    public void turnUp(){
        System.out.println("跳转到上一个台...");
    }

    public void turnDown(){
        System.out.println("跳转到下一个台...");
    }
}

// 请求发送实现类-遥控器
public class RemoteInvoker {

    private Command turnUpCommand;
    private Command turnDownCommand;

    private Stack<Command> undoCommadStack;
    private Stack<Command> redoCommadStack;

    public RemoteInvoker(Command turnUpCommand, Command turnDownCommand) {
        this.turnUpCommand = turnUpCommand;
        this.turnDownCommand = turnDownCommand;

        undoCommadStack = new Stack<>();
        redoCommadStack = new Stack<>();
    }

    // 遥控器-切上一个台的按钮实现
    public void turnUpButton(){
        turnUpCommand.execute();
        undoCommadStack.push(turnUpCommand);
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.clear();
        }
    }

    // 遥控器-切下一个台的按钮实现
    public void turnDownButton(){
        turnDownCommand.execute();
        undoCommadStack.push(turnDownCommand);
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.clear();
        }
    }

    // 遥控器-undo按钮实现
    public void undoButton(){
        if(!undoCommadStack.isEmpty()){
            Command command = undoCommadStack.pop();
            command.undo();
            redoCommadStack.push(command);
        }else {
            System.out.println("按钮无效...");
        }
    }

    // 遥控器-redo按钮实现
    public void redoButton(){
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.pop().execute();
        }else {
            System.out.println("按钮无效...");
        }
    }
}

// 命令接口
public interface Command {

    // 执行命令
    public void execute();

    // 撤销命令
    public void undo();
}

// 转上一个台具体命令
public class TurnUpCommand implements Command{

    private Receiver receiver;

    public TurnUpCommand(Receiver receiver) {
        this.receiver = receiver;
    }

    @Override
    public void execute() {
        receiver.turnUp();
    }

    @Override
    public void undo() {
        receiver.turnDown();
    }
}

// 转下一个台具体命令
public class TurnDownCommand implements Command{

    private Receiver receiver;

    public TurnDownCommand(Receiver receiver) {
        this.receiver = receiver;
    }

    @Override
    public void execute() {
        receiver.turnDown();
    }

    @Override
    public void undo() {
        receiver.turnUp();
    }
}
```

### 1.7. 代理模式

为其他对象**提供一种代理**，以控制对这个对象的访问。在某种情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到**中介**的作用。

- 组成：
  - 抽象角色：通过接口或者抽象类声明真实角色实现的业务方法。
  - 代理角色：实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法，来实现抽象方法（持有真实角色对象的引用），并可以附加自己的操作。
  - 真实角色：实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。
- 分类：
  - 静态代理：静态代理，是由程序员创建或者工具生成代理类的源码，再在编译生成代理类。所谓静态，也就是程序运行前就已经存在**代理类的字节码文件**，这时代理类和委托了类的关系在运行前就确定了。
  - 动态代理：动态代理在实现阶段不用关心代理类，而在**运行阶段**才指定哪一个对象。
    - 分类：JDK动态代理、CGLIB动态代理。
    - [2.6. 动态代理？](#2.6. 动态代理？)
- 优点：
  - 职责清晰：真实角色就是实现实际业务逻辑的，不用去关心其他非本职的业务。而通过后期的代理去完成那些非真实角色本职的业务，编程简洁清晰。
  - 保护目标对象：在客户端和目标对象中间存在代理对象，起到中介以及保护目标对象的作用。
  - 高扩展性：符合开闭原则，代理类的实现不是通过修改原有的代码，而是通过扩展的方式，织入新的业务代码。符合对修改关闭，对扩展开放的原则。

```java
// 客户类(静态代理)
public class Client {

    public static void main(String[] args) throws Throwable {
        UserService userService = new UserServiceImplStaticProxy(new UserServiceImpl());
        userService.save();       
    }
}

/**
 * 抽象角色: 用户服务接口
 */
public interface UserService {

    public void save();
}

/**
 * 真实角色: 用户服务接口实现类
 */
public class UserServiceImpl implements UserService {

    @Override
    public void save() {
        System.out.println("保存用户信息...");
    }
}

/**
 * 代理角色: 用户服务实现静态代理类
 */
public class UserServiceImplStaticProxy implements UserService{

    private UserService userService;

    public UserServiceImplStaticProxy(UserService userService) {
        this.userService = userService;
    }

    @Override
    public void save() {
        System.out.println("静态代理前...");
        userService.save();
        System.out.println("静态代理后...");
    }
}
```

### 1.8. 模板方法模式

定义一个操作中算法的骨架，将一些步骤延迟到子类中，使得子类可以不改变算法结构即可**重定义**该算法的某些特定步骤。

- 组成：
  - 抽象父类：实现了模板方法，定义了算法的骨架。
  - 具体类：实现抽象类的抽象方法，即不同对象实现不同的具体细节。
- 优点：
  - 灵活：具体细节步骤实现定义在子类中，子类定义详细处理算法不会改变算法整体结构。
  - 代码复用：代码复用的基本技术，在数据库设计中尤为重要。
  - 开闭原则：存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合开闭原则。
- 缺点：
  - 类爆炸：每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。
- 使用场景：Spring、JDBC等各种框架中均有使用。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        /**
         * 模板方法模式:
         * a. 假设做菜有3步: 备料、做菜、上菜, 这三步是算法的骨架
         * b. 然后做不同菜需要不同的料, 做时不同的方法, 以及如何盛装给客人, 这些就是不同的实现细节
         */
        // 番茄炒蛋
        DodishTemplate eggsWithTomato = new EggsWithTomato();
        eggsWithTomato.dodish();

        // 红烧肉
        DodishTemplate braisedPork = new BraisedPork();
        braisedPork.dodish();
    }
}

// 抽象角色: 做菜的抽象父类
public abstract class DodishTemplate {

    /**
     * 做菜, 定义算法骨架
     */
    protected void dodish(){
        this.preparation();
        this.doing();
        this.carriedDishes();
    }

    /**
     * 备菜
     */
    protected abstract void preparation();

    /**
     * 做菜
     */
    protected abstract void doing();

    /**
     * 上菜
     */
    protected abstract void carriedDishes();
}

// 具体角色: 番茄炒蛋
public class EggsWithTomato extends DodishTemplate{

    @Override
    protected void preparation() {
        System.out.println("洗并切西红柿, 打鸡蛋...");
    }

    @Override
    protected void doing() {
        System.out.println("鸡蛋倒入锅里, 然后倒入西红柿一起炒...");
    }

    @Override
    protected void carriedDishes() {
        System.out.println("将炒好的西红寺鸡蛋装入碟子里, 端给客人吃...");
    }
}
```

### 1.9. 复合模式（MVC模式）

将多个模式结合起来形成一个框架，以解决一般性问题，在形式上，**复合模式是多个模式的结合**。

- 使用场景：
  - MVC就是典型的多个模式结合：
    - 观察者模式：V和C都是M的观察者，Model的状态更新要及时通知V更新视图，或者通知C做相应逻辑处理。
    - 策略模式：C是V的策略，所以V包含的控制逻辑就是选择策略，也就是选择控制器Controller。
    - 组合模式：V的自身实现应用了组合模式，即调用顶层容器的repaint方法，容器内的所有组件都会进行重绘。
  - MVC应用了多个模式，并能够较好的解决设计上的一般性问题，所以被成为复合模式。但应用复合模式的框架远不止MVC一个。

### 2.0. 适配器模式

定义一个包装类，用于**包装不兼容接口的对象**。把一个类的接口变换成客户端所期待的另一种接口，从而使原本接口不匹配而无法工作的两个类能够一起工作。

- 组成：
  - 包装类：适配器Adapter。
  - 被包装对象：适配器Adaptee，即被适配的类。
- 分类：
  - 类的适配器模式：
    - 特点：使用对象继承的方式实现，是静态的定义方式。
    - 优点：使用方便，代码简化，仅仅引入一个对象，并不需要额外地字段来引用Power实例。
    - 缺点：高耦合，灵活性低。在需要同时适配源类和其子类时，由于类的适配器不能和Adaptee子类一起工作，所以选择对象的适配器比较合适。
  - 对象的适配器模式：
    - 特点：使用对象组合的方式，是动态组合的方式。
    - 优点：灵活性高、低耦合。
    - 缺点：使用复杂、需要引入对象实例。在需要重新定义Adaptee部分行为时，由于类适配器可以重定义Adaptee部分行为，相当于子类覆盖父类的部分实现方法，所以选择类的适配器比较合适。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        // 获取进口电视机
        ImportedTv importedTv = new ImportedTv();
        
        // 类的适配器模式
        // 获取电视机电源适配器(实际上是一个电视机插头, 但也是个电源)
        TvPlug tvPlug = new PowerAdapter();
        // 开始转换电压
        tvPlug.converTo110v();
        // 开启电视机
        importedTv.work();
        
        // 对象的适配器模式
        // 获取新的电视机电源适配器(实际上是一个电视机插头, 但也是个电源)
        NewPowerAdapter newPowerAdapter = new NewPowerAdapter(new Power());
        // 开始转换电压
        newPowerAdapter.converTo110v();
        // 开启电视机
        importedTv.work();
    }
}

// 进口电视机
public class ImportedTv {

    public void work(){
        System.out.println("电视机正在开启...");
    }
}

// 被包装对象：电视机插头
public interface TvPlug {

    public void converTo110v();
}

// 被包装对象：电源
public class Power {

    public void supply220v(){
        System.out.println("提供220v电源...");
    }
}

// 包装对象：类的适配器模式-电视机电源适配器
public class PowerAdapter extends Power implements TvPlug {

    @Override
    public void converTo110v() {
        super.supply220v();
        System.out.println("开启转换电压...");
    }
}

// 包装对象：对象的适配器模式-电视机电源适配器
public class NewPowerAdapter implements TvPlug{

    private Power power;

    public NewPowerAdapter(Power power) {
        this.power = power;
    }

    public void converTo110v() {
        power.supply220v();
        System.out.println("开启转换电压...");
    }
}
```

### 2.1. 装饰者模式

通过创建一个包装对象，也就是用装饰来包裹真实的对象，在不必改变原类文件和使用继承的情况下，**动态地扩展**一个对象的功能。

- 特点：
  - 装饰对象和真实对象具有相同的接口，这样客户端对象就能以和真实对象相同的方式和装饰对象交互了。
  - 装饰对象包含一个真实对象的引用。
  - 装饰对象接收所有来自客户端的请求，它把这些请求转发给真实的对象。
  - 装饰对象可以在转发这些请求以前或者以后增加一些附加功能，这样就确保了在运行时，不用修改指定对象的结构就可以在外部增加附加的功能。
- 组成：
  - 顶层抽象父类：具有最一般的特性，是真实对象以及装饰组件的共同抽象。
  - 真实对象：代表的是具有业务意义的，能被修饰的底层对象。
  - 组件抽象父类：具有装饰组件的一般性，是装饰组件的抽象。
  - 包装对象：代表的是能够装饰真实对象的组件，实现了组件抽象父类。
- 优点：
  - 灵活：装饰者模式与继承关系的目的都是扩展对象功能，但是装饰者模式可以提供比继承更多的灵活性。
  - 高扩展：通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合。
- 缺点：
  - 复杂：这种比继承更加灵活机动的特性，也同时意味着更多的复杂性。
  - 类爆炸：装饰者模式会导致设计中出现许多小类，如果过度使用，会使程序变得很复杂。
- 使用场景：
  - 需要扩展一个类的功能，或者给一个类添加附加职责。
  - 需要动态地给一个对象添加功能，这些功能可以再动态的撤销。
  - 需要增加由一些基本功能的排列组合而产生了非常大量的功能，而如果使用继承关系变得不现实。比如JDK中的IO类便使用了装饰者模式，其中的InputStream是顶层抽象父类，FilterInputStream是组件抽象父类。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        /**
         * 开始下单
         */
        // 要一杯 深焙咖啡, 摩卡, 奶泡
        Beverage beverage1 = new DarkRoast();
        beverage1 = new Mocha(beverage1);
        beverage1 = new Whip(beverage1);
        System.out.println(getDescAndCost(beverage1.getDescription(), beverage1.cost()));
    }

    public static String getDescAndCost(String desc, BigDecimal cost){
        return String.format("Description: %s, $%f", desc, cost);
    }
}

// 顶层抽象父类-饮料抽象类
public abstract class Beverage {

    private String description = "Unkown Beverage";

    /**
     * 获取饮料描述-子类中重写
     * @return
     */
    public String getDescription() {
        return description;
    }

    /**
     * 获取饮料价格-子类中实现
     * @return
     */
    public abstract BigDecimal cost();
}

// 真实对象：深焙咖啡类-一种具体的饮料
public class DarkRoast extends Beverage {

    @Override
    public String getDescription() {
        return "深焙咖啡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("3.00");
    }
}

// 组件抽象父类-因为调料叠加以后也是一种饮料, 所以能继承饮料抽象类
public abstract class CondimentDecorator extends Beverage {

    /**
     * 所有的具体调料装饰者都必须实现getDescription(), 这样才能够用递归的方式来得到所选饮料的整体描述
     * @return
     */
    public abstract String getDescription();
}

// 包装对象-摩卡调料类-一种具体的调料
public class Mocha extends CondimentDecorator {

    /**
     * 持有一个具体饮料的引用
     */
    private Beverage beverage;

    public Mocha(Beverage beverage) {
        this.beverage = beverage;
    }

    @Override
    public String getDescription() {
        return beverage.getDescription() + ", 摩卡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("0.2").add(beverage.cost());
    }
}

// 包装对象-奶泡调料类-一种具体的调料
public class Whip extends CondimentDecorator {

    /**
     * 持有一个具体饮料的引用
     */
    private Beverage beverage;

    public Whip(Beverage beverage) {
        this.beverage = beverage;
    }

    @Override
    public String getDescription() {
        return beverage.getDescription() + ", 奶泡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("0.4").add(beverage.cost());
    }
}
```

### 2.2. 观察者模式

一个目标物件管理所有相依于它的观察者物件，并且在它本身的**状态改变**时主动发出通知，透过呼叫各观察者所提供的方法来实现，通常被用来实现事件处理系统。

- 特点：
  - 当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新，完美地将观察者模式和被观察者的对象分离开，在模块之间划定了清晰的界限，提高了应用程序的可维护性和重用性。
  - 将一个系统分割成一些类相互协作的类有一个不好的副作用，那就是需要维护相关对象之间的一致性，当不希望为了维持一致性，而使各类紧密耦合导致会给维护、扩展和重用都带来不便时，可以使用观察者模式来解决这类耦合关系。
- 组成：
  - 抽象主题：Subject，抽象主题提供一个接口，可以增加和删除观察者对象。它把所有观察者对象的引用保存到一个聚集里，每个主题都可以有任意数量的观察者。
  - 具体主题：Concrete Subject，将有关状态存入具体观察者对象，在具体主题内部状态改变时，给所有登记过的观察者发出通知。
  - 抽象观察者：Observer，为所有具体的观察者定义一个接口，在得到主题通知时更新自己。
  - 具体观察者：Concrete Observer，实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题状态协调。
- 优点：
  - 解耦：观察者模式解除了主题和具体观察者的耦合，让耦合的双方都依赖于抽象，不依赖具体，从而使得各自的变化都不会影响另一边的变化。
- 缺点：
  - 需考虑异步：在应用观察者模式时需要考虑以下开发短路问题，程序中包括一个被观察者和多个观察者，开发和调试比较复杂，而且Java中的消息通知默认是顺序执行的，一个观察者的卡顿会影响整体的执行效率，因此，在这种情况下，一般考虑采用异步的方式。
  - 需考虑进一步解耦：如果依赖关系未完全解除，如抽象通知者依旧依赖抽象的观察者，这时可以采用委托的方式（引用方法类型）来解决。
- 使用场景：
  - 当一个抽象模型有两个方面，其中一个方面依赖于另一个方面，需要将二者封装在独立的对象中，以使它们可以各自独立地改变和复用时。
  - 当一个对象的改变需要同时改变其他对象，但又不知道具体有多少对象需要改变时。
  - 当一个对象必须通知其他对象，但它又不知道其他对象是谁时，也就是希望这些对象之间不是紧密耦合的。

```java
// 客户类
public class Client {
    public static void main(String[] args) {
        CustomerA customerA = new CustomerA();
        customerA.addObserver(new Cashier(customerA));
        customerA.addObserver(new Accountant(customerA));
        customerA.addObserver(new Dilliveryman(customerA));
        customerA.payOrder();
    }
}

// 客户主题抽象类
public abstract class CustomerSubject {

    private Vector<JobStation> observers = new Vector<>();

    private String state;

    public void addObserver(JobStation jobStation){
        observers.add(jobStation);
    }

    public void removeObserver(JobStation jobStation){
        observers.remove(jobStation);
    }

    public abstract void payOrder();

    public Vector<JobStation> getObservers() {
        return observers;
    }

    public String getState() {
        return state;
    }

    public void setState(String state) {
        this.state = state;
    }
}

// 具体主题类：具体客户类A
public class CustomerA extends CustomerSubject {

    @Override
    public void payOrder() {
        super.setState("已付款");
        System.out.println("我是用户, 我已经完成订单付款...");
        for(JobStation jobStation : super.getObservers()){
            jobStation.updateJobState();
        }
    }
}

// 抽象观察者: 工作岗位接口
public interface JobStation {

    public void updateJobState();
}

// 具体观察者：出纳工作人员
public class Cashier implements JobStation{

    private String state;

    private CustomerSubject customerSubject;

    public Cashier(CustomerSubject customerSubject) {
        this.customerSubject = customerSubject;
    }

    @Override
    public void updateJobState() {
        if(customerSubject.getState().equals("已付款")){
            this.state = "已入账";
            System.out.println(String.format("我是出纳员, 我来登记入账 => %s.", this.state));
        }
    }
}
```

### 2.3. 建造者模式

将一个复杂对象的**构造与他的表示分离**，使同样的构建过程可以创建不同的表示。

- 特点：
  - 将一个复杂的对象分解为多个简单的对象，然后一步步构建而成，它将变与不变相分离，即产品的组成部分是不变的，但每一部分是可以灵活选择的。
  - 当需要创建的产品具备复杂创建过程时，可以抽取公共创建过程，然后交由具体实现类自定义创建流程， 使得同样得创建行为可以生产出不同的产品，分离了创建与表示，使创建的产品灵活性大大增加。
- 组成：
  - 指挥者：Director，它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体的产品信息。
  - 抽象构造者：Builder，它是一个包含创建产品各个子部分的抽象方法的接口，通常还包含一个返回复杂产品的getResult()方法。
  - 具体构造者：Concrete Builder，实现Builder接口，完成复杂产品的各个部件的具体方法。
  - 产品：它是包含多个部件的复杂对象，由具体建造者来创建其各个零部件。
- 过程：

1. 指挥者Director直接和客户Client进行需求沟通。
2. 沟通后，指挥者将客户创建产品的需求划分为各个部件的建造请求Builder。
3. 将各个部件的建造请求委派到具体的建造者ConcreteBuilder。
4. 各个具体建造者ConcreteBuilder负责进行产品部件的构建。
5. 最终构建成具体产品Product。

- 优点：
  - 封装性好：构建和表示分离，即同样的构建过程能取到不同的表示。
  - 扩展性好：各个具体的构造者独立，有利于系统的解耦。
  - 易用：客户端不必知道产品内部组成的细节，建造者可以对创建过程逐步细化，而不对其他模块产生任何影响，便于控制细节风险。
  - 灵活：改造多参数构造对象可以使得传递参数更加灵活，代码具有更高的可读性。
- 缺点：
  - 范围限制：产品的组成部分必须相同，这限制了其使用范围。
  - 维护成本高：如果产品的内部变化复杂，当产品内部发生变化时，则建造者也要同步修改，后期维护成本较大。
- 使用场景：
  - 相同的方法，当有不同的执行顺序时，产生不同的结果时。
  - 多个部件零件，都可以装配到一个对象中，但是产生的结果又不相同时。
  - 产品类非常复杂，或者产品类中不同的调用顺序产生不同的作用时。
  - 初始化一个对象特别复杂，参数多， 而且很多参数都具有默认值时。
- 建造者模式 VS 工厂模式：
  - 建造者模式注重零部件的**组装过程**，而工厂模式更注重零部件的**创建过程**，但两者可以结合使用。
  - 建造者模式注重方法的**调用顺序,** 而工厂模式注重**创建对象**。
  - **创建对象的方式不同**：建造者模式通过指挥类来指导如何生成对象，包括对象的组装过程和构造步骤。而工厂模式是通过客户端实例化工厂类，然后调用工厂方法获取所需的产品对象。
  - **关注重点不一样**：建造者模式不仅要创建出对象，还要知道对象由哪些部件组成。而工厂模式只需要把对象创建出来就可以了。
  - **创建对象的粒度不同**：建造者模式创建复杂对象，由各种复杂的部件组成，建造顺序不同最终对象部件也会不一样。而工厂模式创建出来的对象都一样或者是一系列的产品族。
  - 如果将抽象工厂模式看成**汽车配件生产工厂**，生产一个产品族的产品，那么建造者模式就相当于一个**汽车组装工厂**，通过对部件的组装生成出一辆完整的汽车。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Director directorA =  new Director(new ConcreteBuildA());
        Director directorB =  new Director(new ConcreteBuildB());

        // 获取产品A
        directorA.assembledProduct();

        // 获取产品B
        directorB.assembledProduct();
    }
}

// 指挥者类
public class Director {

    private Builder builder;

    public Director(Builder builder) {
        this.builder = builder;
    }

    // 组装产品
    public Product assembledProduct(){
        builder.buildNilProduct();
        builder.buildPartA();
        builder.buildPartB();
        builder.buildPartC();
        return builder.getProduct();
    }
}

// 抽象Builder类
public abstract class Builder {

    // 构造空属性产品
    protected Product product;

    public abstract void buildPartA();

    public abstract void buildPartB();

    public abstract void buildPartC();

    // 获取产品
    public void buildNilProduct() {
        this.product = new Product();
    }

    // 获取产品
    public Product getProduct() {
        return product;
    }
}

// 具体建造者类A
public class ConcreteBuildA extends Builder{

    @Override
    public void buildPartA() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartA("我是A Part A.");
        System.out.println("A建造者建造了Part A...");
    }

    @Override
    public void buildPartB() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartB("我是A Part B.");
        System.out.println("A建造者建造了Part B...");
    }

    @Override
    public void buildPartC() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartC("我是A Part C.");
        System.out.println("A建造者建造了Part C...");
    }
}

// 产品类
public class Product {

    private String partA;
    private String partB;
    private String partC;

    public String getPartA() {
        return partA;
    }

    public void setPartA(String partA) {
        this.partA = partA;
    }

    public String getPartB() {
        return partB;
    }

    public void setPartB(String partB) {
        this.partB = partB;
    }

    public String getPartC() {
        return partC;
    }

    public void setPartC(String partC) {
        this.partC = partC;
    }
}
```



## **5. Java基础**

### 1.1. 面向对象三大特性？

**封装、继承、多态**

- **封装**：对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法。
- **继承**：子类扩展新的数据域或者功能，并复用父类的属性与功能，单继承、多实现。
- **多态**：通过继承（多个子类对同一方法的重写），也可以用过接口（实现接口）。

### 1.2. Java与C++的区别？

Java和C++都是面向对象语言，都能够实现面向对象思想（即**封装、继承、多态**）。

|          | Java                         | C++                |
| -------- | ---------------------------- | ------------------ |
| 继承     | 单继承，可通过接口实现多继承 | 多继承             |
| 访存     | 不提供指针直接访存           | 有指针的概念       |
| 内存管理 | JVM自动管理                  | 程序员需要手动管理 |

### 1.3. 多态是什么？

多态，按字面意思就是多种状态。**在面向对象语言中，接口的多种不同实现方式即为多态，允许将基类的指针或者引用指向派生类的对象，在具体访问时实现方法的动态绑定。**

- 条件：
  - 多态建立在继承的基础上，先有继承才能有多态。
  - 多态另一个条件是，在创建子类时必须使用父类指针以及new实际的子类类型。

### 1.4. static和final关键字？

- **static**：可以修饰属性和方法
  - 修饰属性：
    - 代表类级别属性，所有对象共享一份，随着类的加载而加载，只加载一次，先于对象的创建。
    - 可以使用类名直接调用。
  - 修饰方法：
    - 随着类的加载而加载。
    - 可以使用类名直接调用。
    - 在静态方法中，只能调用静态的成员，以及不可以使用this。
- **final**：最要用于变量、方法、类。
  - 修饰变量：
    - 如果变量是基本数据类型，则其数值一旦在初始化后就不能更改了。
    - 如果是引用类型的变量，则其在初始化后就不能更改指向的对象了。
  - 修饰方法：
    - 锁定方法，防止任何继承类重写其含义（类中所有的private方法都隐式地指定为了final修饰）。
  - 修饰类：
    - 表名这个类不能被继承，其中该类中的所有成员、方法都会被隐式地指定为final修饰。
    - *另：要使一个类不能被继承，除了final关键字外，还可以私有化构造器（不能继承内部类）。*

### 1.4. 抽象类和接口？

- **抽象类**：
  - 包含抽象方法的类，使用abstract修饰。
  - 抽象类不能被实例化。
  - 抽象类只能被继承，所以不能使用final修饰。
  - 使用场景：既想约束子类具有共同的行为，不在乎其如何实现，又想拥有缺省的方法以及拥有实例变量时。
- **接口**：
  - 是一个抽象类型，是抽象方法的集合。
  - 支持多继承，接口中定义的方法默认是public abstract修饰的抽象方法。
  - 使用场景：想要约束多个实现类具有统一行为，不在乎每个实现类如何实现，又想实现类各个功能之间可以没有任何联系（多继承）时。
- 相同点：都不能被实例化、都可以定义抽象方法，靠子类/实现类实现抽象方法。
- 不同点：

| 抽象类                     | 接口                                      |
| -------------------------- | ----------------------------------------- |
| 有构造方法                 | 没有构造方法                              |
| 可以包含普通方法           | JDK7前只能是"抽象方法"                    |
| 只能单继承                 | 支持多继承                                |
| 可以定义各种类型的成员变量 | 只能定义public static final修饰的静态常量 |

### 1.5. 泛型和泛型擦除？

泛型的本质是**参数化类型**。

- 使用方式：可以用在类、接口和方法上，分别成为泛型类、泛型接口和泛型方法，还可以用在方法的参数和返回值上（此时该方法只是普通方法）。
  - 泛型类：
    - 当指定了泛型类型，整个类泛型都必须同一类型。
    - 没有指定泛型类型，整个类可以为任意类型（Object类型）。
  - 泛型接口：
    - 实现泛型接口时，当接口指定泛型类型时，实现类必须保持相同的泛型类型。
    - 当接口没指定泛型类型时，实现类可以不指定泛型类型（Object类型）。
  - 泛型方法：
    - 在修饰符和返回值之间的位置，声明了泛型的才是泛型方法。
    - 而只使用泛型类型参数和返回值的，只是普通方法。
  - 泛型通配符：
    - 泛型的上限：<? extends 类型>，作为实参传递时，只能传递子类及本类类型。
    - 泛型的下限：<? super 类型>，作为实参传递时，只能传递父类级本类类型。
  - 泛型数组：
    - 不可以创建一个确切泛型类型的数组，比如不能List<String>[] ls = new ArrayList<String>[10];
    - 但可以创建一个确切通配符类型的数组，且获取时必须进行类型转换。比如可以List<?>[] ls = new ArrayList<?>[10];
- **泛型擦除**：
  - Java的泛型是伪泛型，使用泛型的时需要加上类型参数，在编译器编译生成字节码时会被去掉，这个过程称为泛型擦除。
  - 比如List<String>类型，在编译之后都会 成为List类型，JVM看到的只是List，因此泛型附加的类型信息对JVM来说是不可见的，**只在编译期间有效，在运行期间无效**。
- **泛型优点**：
  - 可以指定类型，不用强转，代码简洁，提高了编码期间的可读性
  - 保证集合中存的元素都是同一类型的元素，程序更加健壮。
- 桥接方法：
  - 概念：在子类继承泛型父类或者实现泛型接口，并且指定了泛型类型时，编译器会自动在子类中生成桥接方法。
  - 原因：如果不生成桥接方法，在泛型擦除后，父类类型变为了Object类型，而子类方法参数还是指定的类型，此时就不算实现父类或者接口方法了。因此，为了**维持多态性**，会在子类中生成Object类型的桥接方法，其实现是把Object参数强转成指定的类型，方便指向具体的实现方法。

```java
/**
 * 泛型类
 */
public class MyGeneric<T> {

    private T genericCode;

    // 静态方法-不含泛型
    public static void main(String[] args) {

    }

    // 静态泛型方法-含泛型
    public static <E> E test(E args) {
        return args;
    }

    // 构造方法-使用类的泛型
    public MyGeneric(T genericCode) {
        this.genericCode = genericCode;
    }

    // 普通方法-使用类的泛型
    public T getGenericCode() {
        return genericCode;
    }

    // 普通方法-使用类的泛型
    public void setGenericCode(T genericCode) {
        this.genericCode = genericCode;
    }
}
```

### 1.6. Java异常体系？

![1621048569059](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1621048569059.png)

- **Throwalbe**：Java中所有错误或者异常的超类。
- **Error**：指Java运行时系统内部的错误以及资源耗尽的错误。应用程序不会抛出该类对象，如果出现这样的错误，除了告知用户，剩下的就是尽力使程序安全地终止。
- **Exception**：
  - **RuntimeException**：运行时异常，程序应该从逻辑角度尽可能避免这类异常的发生。
  - **非运行时异常**：这类异常必须使用try-catch进行捕捉处理，否则编译器报错。比如IOExceptin、SQLException。

### 1.7. 反射原理以及使用场景？

指在运行状态中，对于任意一个类，都能够知道这个类所有的属性和方法，并且都能够调用它的任意一个方法。

- 原理：首先获取反射类的字节码，然后将字节码中的方法、变量、构造函数等映射成相应的Method、Field、Constructor等对象。
- 反射类Class对象获取方式：
  - **类名.class**：Class personClazz = Person.class，就一份字节码，所以是同一个Class对象。
  - **Object#getClass（）**：每一个对象都有getClass（）方法，用于返回对象真实的Class对象（对象的元数据）。
  - **Class.forName（String）**：根据一个类的权限定名来构建Class对象。
- 使用场景：通用框架开发、动态代理、自定义注解。

### 1.8. Java构造方法？

构造方法，也叫构造函数，是Java中一种特殊的函数，函数名与类名相同，无返回值。

- 一般用于**初始化成员属性和成员方法**，在对象创建时运行，只运行一次。
- 构造方法可以被重载，只有当类中没有显式声明任何构造方法时，才会有默认的无参构造方法。

### 1.9. Java初始化块？

代码初始化块是类的成员之一，每次类的创建会隐式调用它，本质上是一个代码块或者方法体。

初始化块分为**静态初始化块**和**非静态初始化块**，其好处是减少多个构造器内重用的代码。

- **静态初始化**块优先级最高，会在类第一次被加载时最先执行（也在main方法前），在**非静态初始化块**之前执行。

### 2.0. Java this关键字？

- 关键字this代表**当前对象的引用**：当前对象指的是调用类中的属性或者方法的对象。
- 关键字this不可以在静态方法中使用：因为静态方法不依赖于当前类的实例。

### 2.1. 重载与重写的区别？

- **重载**：指可以在同一个类中定义多个同名方法，但要求参数列表不同，与方法返回值无关。成员方法和构造方法都可以进行重载，可以通过重载构造方法来实现多种初始化行为。重载要求如下：
  - 方法必须都在同一个类中。
  - 方法名相同。
  - 方法参数个数或者参数类型不同。
  - 与方法返回值、返回类型、方法修饰符无关。
- **重写**：指子类中方法签名与父类相同的方法，使用@override注解标识。重写要写如下：
  - 方法在父类和子类不同的类中。
  - 方法名相同。
  - 方法参数个数和参数类型都要相同。
  - 方法返回值类型相同，或者子类方法返回值类型是父类方法返回值的一个子类类型。
  - 子类方法不能缩小方法的访问权限。

### 2.2. 基本数据类型与包装类？

**三类八种基本数据类型**，每个基本类型都有对应的包装类。包装类变量是个指针，没初始化前默认为null。

| 种类   | 基本数据类型           | 存储位数 | 取值范围                                                     | 默认值         | 包装类    |
| ------ | ---------------------- | -------- | ------------------------------------------------------------ | -------------- | --------- |
| 数值型 | byte（位）             | 8 bit    | -2^7到2^7 -1                                                 | 0              | Byte      |
| 数值型 | short（短整数）        | 16 bit   | -2^15到2^15 -1                                               | 0              | Short     |
| 数值型 | int（整数）            | 32 bit   | -2^31到2^31 - 1                                              | 0              | Integer   |
| 数值型 | long（长整数）         | 64 bit   | -2^63到2^63 - 1                                              | 0L             | Long      |
| 数值型 | float（单精度浮点数）  | 32 bit   | 负数范围：-3.402823E+38到-1.401298E-45，正数范围：1.401298E-45到3.402823E+38 | 0.0F           | Float     |
| 数值型 | double（双精度浮点数） | 64 bit   | 负数范围：-1.797693E+308到-4.9000000E-324，正数范围：4.9000000E-324到1.797693E+308 | 0.0D           | Double    |
| 字符型 | char（字符）           | 16 bit   | 0到2^16 - 1                                                  | '\u0000'（空） | Character |
| 布尔型 | boolean                | 1 bit    | true和false                                                  | false          | Boolean   |

### 2.3. 序列化与反序列化？

- **序列化**：
  - 指将Java对象转化为字节序列的过程，即将对象的状态转化成字节流，然后可以通过这些值再生成相同状态的对象。
  - 对象序列化，是对象持久化的一种实现方法，是将对象的属性和方法转化为一种序列化的形式，用于存储和传输。
- **反序列化**：
  - 指将字节序列转化为Java对象的过程，即将对象字节序列重建对象的过程。
- 优点：
  - 实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上，通常是放在文件里，比如Redis的RDB。
  - 利用序列化实现远程通信，即在网络上传送对象的字节序列，比如Google的ProtoBuf。
- 反序列失败场景：
  - 如果SerialVersionUID不一致，会导致反序列化失败。

### 2.4. Object类？

**Object类是所有类的父类**，在使用任何类都可以使用Object类中的方法：

- toString（）：默认是 类名+hashCode，一般需要重写。

- equals（）：

  - 默认为==，比较对象的引用地址是否相同。
  - 实际上往往需要重写，用于判断两个类的实例是否逻辑（内容）相等。

- hashCode（）：

  - 对象的哈希码，协定声明相等对象必须具有相等的哈希码，即对象equal则hashCode一定相等，hashCode不等则对象一定不equal；对象不euqal时hashCode可能相等，hashCode相等时可能不equal，比如HashMap散列冲突。

  - 因此**重写equals（）方法时必须重写hashCode（）方法**，因为HashMap#get(String)时使用

    first.hash == hash && ((k = first.key) == key || (key != null && key.equals(k)))

    即hash相等且（地址相同或者对象equal）来获取key对象的值，如果修改后，对象equal但hashCode不等，则HashMap会出错。

- finalize（）：

  - 在垃圾回收前调用，默认为空实现。
  - 子类可以重写finalize（）方法，以配置系统资源或执行其他清除。

- clone（）：深拷贝，类需要实现Cloneable接口。

- getClass（）：用于返回对象真实的Class对象（对象的元数据）。

- wait（）、wait（long）、wait（long，int）、notify（）、notifyAll（）：用于线程等待或唤醒。

### 2.5. String类？

- **String**：使用**数组**存储内容，由于数组使用final修饰，因此String定义的字符串的值是不可变的。
- **StringBuffer**：对方法都加了synchronize关键字，是线程安全的，适用于多线程环境下在字符缓冲区进行大量操作，但效率不如StringBuilder。
- **StringBuilder**：StringBuilder方法没有加synchronzie关键字，是非线程安全的，适用于单线程环境下在字符缓冲区进行大量操作，效率比StringBuffer高。

#### String不可变的好处

1. 可以使用**字符串常量池**，多次创建同样的字符串，可以指向同一个内存地址。
2. 可以很方便地用作HashMap的key，因为通常建议把不可变对象作为HashMap的key。
3. hashCode生成后就不会改变，使用时无需重新计算。
4. 线程安全，因为具备不变性的对象一定是线程安全的。

### 2.6. 动态代理？

[1.7. 代理模式](#1.7. 代理模式)&nbsp;

动态代理，指在实现阶段不用关心代理类，而在**运行阶段**才指定哪一个对象。

> **JDK动态代理**：Proxy类利用反射机制以及一个**实现InvocationHandler的处理类**，生成一个实现了原委托类接口（为了可以调用被代理方法） 和 继承了Proxy类（为了持有已经实现InvocationHandler实例的引用） 的代理类，使得在调用代理类具体方法时去调用实现InvocationHandler接口的处理类里的方法。
>
> **CGLIB动态代理**：利用ASM开源包，通过**修改委托类的Class文件的字节码生成子类**来处理，其中主要是生成的子类去覆盖原本委托类中的方法，并在覆盖方法中实现增强，但是因为采用的是继承，所以对于final类或者方法是无法继承和代理的。

#### 1. JDK动态代理 VS CGLIB动态代理

- JDK动态代理：在调用代理类方法时，是通过引用调用InvocationHandler实现类的invoke方法，然后再反射调用委托类的方法，**属于反射调用，存在一定的性能花销**。
- CGLIB动态代理：在调用代理类方法时，是通过引用调用MethodInterceptor实现类的intercept方法，然后通过方法签名的index索引，去代理类的FastClass查找到代理类中具体的方法，最后该方法调用父类（原委托类）的方法, **属于父类方法调用，性能花销小**。

|               | JDK动态代理                              | CGLIB动态代理                                                |
| ------------- | ---------------------------------------- | ------------------------------------------------------------ |
| 生成代理Class | 生成效率高                               | 每次都会生成新的FastClass文件，所以Class生成效率会比JDK动态代理的低 |
| 方法调用      | 属于反射调用，调用效率较低               | 属于父类方法调用，所以调用效率会比JDK动态代理的高            |
| 实现原理      | 如果原委托类没有实现接口时，则不可以使用 | 原委托类有无实现接口一样可以使用，但不可以代理private和final修饰的方法 |
| 使用场景      | 比较适合代理非代理对象                   | 无需频繁创建代理对象，比较适合代理单例对象                   |
| 迭代状态      | 每个JDK版本都有迭代，性能得到增强        | 止步不前                                                     |

#### **2. JDK动态代理**

为了解决静态代理中代理类接口过多的问题，可以通过JDK自带的java.lang.reflect.Proxy类，通过反射实现动态代理。

##### 使用步骤

1. 编写一个委托类的接口：如UserService，把实现方法save（）声明出去。
2. 实现一个真正的委托类：即UserServiceImpl，实现接口save（）方法。
3. 创建一个动态代理类：实现InvocationHandler接口，并重写invoke方法，在实际调用前后编写需要代理的业务逻辑。其中**动态代理类需要持有委托类的引用**，用于反射调用委托类的save()实现方法。
4. 客户端生成代理对象：在客户端中生成动态代理类对象，调用声明的save（）方法。

- **newProxyInstance（）方法参数**：
  - **ClassLoader loader**：原委托类的类加载器。
  - **Class<?>[] interfaces**：原委托类实现的接口类型数组。
  - **InvocationHandler**：事件处理类，代理对象方法调用的实际处理者。在执行原委托类方法时，会触发该事件处理器，把原委托类的方法作为Method参数传入，供代理对象使用。

```java
// 委托类接口：用户服务接口
public interface UserService {

    public void save();
}

// 真正的委托类：用户服务接口实现类
public class UserServiceImpl implements UserService {

    @Override
    public void save() {
        System.out.println("保存用户信息...");
    }
}

// 动态代理类：用户服务实现JDK动态代理类
public class UserServiceImplJdkProxy implements InvocationHandler {

    private UserService userService;

    public UserServiceImplJdkProxy(UserService userService) {
        this.userService = userService;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理前...");

        Object result = method.invoke(userService, args);

        System.out.println("JDK动态代理后...");
        return result;
    }
}

// 客户端生成代理对象
public class Client {

    public static void main(String[] args) throws Throwable {
        UserServiceImplJdkProxy userServiceImplJdkProxy = new UserServiceImplJdkProxy(new UserServiceImpl());
        
        UserService userService = (UserService) Proxy.newProxyInstance(
                UserServiceImpl.class.getClassLoader(), new Class[]{UserService.class}, userServiceImplJdkProxy);
        
        userService.save();
    }
}
```

##### 实现原理

- **源码分析**：

1. newProxyInstance（）通过反射生成含有接口方法的Proxy Class，其中Proxy Class又继承了Proxy类。
2. $Proxy0构造方法中，调用父类的构造方法，Proxy父类得到InvocationHandler的实例引用。
3. 最后该代理对象的所有方法调用，都会反射转发到InvocationHandler.invoke（）方法。
4. InvocationHandler.invoke（）：允许在原委托类的业务方法的反射调用前后，织入其他代码，从而实现动态代理。

```java
// com/sun/proxy/$Proxy0.java
public final class $Proxy0 extends Proxy implements UserService
{
    private static Method m3;// com.jsonyao.cs.proxyPattern.UserServic => save()

    static
    {
            // 反射获取UserService接口的save()方法
            m3 = Class.forName("com.jsonyao.cs.proxyPattern.UserService").getMethod("save", new Class[0]);
            ...
    }
    
    // 20201112 构造方法
    public $Proxy0(InvocationHandler invocationhandler)
    {
        // 20201112 调用父类构造器, 赋值自定义InvocationHandler
        super(invocationhandler);
    }
    
    // 20201112 实现了UserService的save()方法
    public final void save()
    {
            // 20201112 调用父类注入的invocationHandler实例实现的invoke()方法
            // 20201112 参数分别为Object proxy, Method method, Object[] args
            super.h.invoke(this, m3, null);
            return;
    }
    
    ...
}
```

#### 3. CGLIB动态代理

解决委托类没有实现任何接口时的动态代理。

##### 使用步骤

1. 实现一个MethodInterceptor：方法调用会被转发到该类的intercept（）方法。
2. 客户端构建CGLIB Enhacner：指定原委托类，以及回调接口实现类MethodInterceptor。
3. 客户端获取代理对象执行业务方法：调用Enhacner#create（）方法得到代理对象，使用代理对象调用业务方法。

```java
// CGLIB动态代理方法拦截类
public class MyMethodInterceptor implements MethodInterceptor {

    public static final HelloCglib helloCglib = new HelloCglib();

    /**
     * @param obj => 20201113 增强后的代理对象
     * @param method => 20201113 原始方法
     * @param objects => 20201113 参数数组
     * @param methodProxy => 20201113 可以使用methodProxy#invokeSuper调用FastClass方法
     */
    @Override
    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理前...");

// 20201113 实际是调用了FastClass的invoke方法, 去调用父类的原方法, 对比JDK动态代理提高了性能
        Object object = methodProxy.invokeSuper(o, objects);
     
        System.out.println("CGLIB动态代理后...");
        return object;
    }
}

public class Client {

    public static void main(String[] args) throws Throwable {
        // 设置代理类生成的目录
        System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, ".\\cglib\\classes");

        // 构建CGLIB Enhacner, 指定原委托类，以及回调接口实现类MethodInterceptor
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(HelloCglib.class);
        enhancer.setCallback(new MyMethodInterceptor());
        
        // 客户端获取代理对象执行业务方法：final方法不会被代理
        HelloCglib helloCglib = (HelloCglib) enhancer.create();
        helloCglib.helloAagin();
    }
}
```

##### 实现原理

- 利用ASM开源包，通过**修改委托类Class文件的字节码**生成子类，去覆盖原委托类的方法，并在覆盖方法中实现了增强。
- 在调用代理类方法时，通过引用调用MethodInterceptor实现类的invoke方法，然后通过**方法签名的index索引去代理类的FastClass中查找**代理类中具体的方法，最后调用该方法时调用父类即原委托类的方法，从而实现动态代理。
- **源码分析**：
  1. Enhancer#setSuperclass（Class）：设置委托类为Enhancer的成员变量。
  2. Enhancer#setCallback（Callback）：设置回调函数实例为Enhancer的成员变量。
  3. Enhancer#create（）：使用父类、接口、过滤器、回调函数、版本号等信息生成标识类的key -> 构造出multi-values key对象 => 用于获取/设置缓存。
  4. AbstractClassGenerator#create（Object key）：生成字节码增强文件，并设置multi-values key对应的缓存。
  5. Enhancer#createUsingReflection（Class）：设置代理对象的回调函数实例（其中MethodInterceptor实现了Callback接口，实际上callback就是实现的MethodInterceptor实例）以及反射生成代理对象实例。
  6. 代理对象HelloCglib$$EnhancerByCGLIB$$6bf7bfad的static初始化块：调用MethodProxy.create生成原委托类方法、代理对象代理方法的签名。
  7. MethodProxy.create（Class, Class, String，String, String）：生成原委托类方法、代理对象代理方法的签名。
  8. MethodProxy#invokeSuper(o, objects)：o: 增强后的代理对象, objects参数列表。
  9. 代理对象的FastClass HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271#getIndex（Signature）：根据原委托类方法、代理对象的代理方法的签名生成FastClassInfo索引。
  10. 代理对象的FastClass HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271#invoke(int , Object , Object)：根据代理方法索引、代理对象、参数列表调用FastClass方法。
  11. 代理对象HelloCglib$$EnhancerByCGLIB$$6bf7bfad#CGLIB$helloAagin$5()：调用代理对象的CGLIB$helloAagin$5()方法。
  12. 原委托类HelloCglib#helloAagin（）：调用父类HelloCglib原委托类的helloAagin方法，避免反射调用，提高性能。

```java
// Enhance类
public class Enhancer extends AbstractClassGenerator
{
    // 1. 设置委托类为Enhancer的成员变量
    public void setSuperclass(Class superclass) {
    	...
        // 如果不是接口且父类不是Object类, 则设置父类为自己本身
        this.superclass = superclass;
    }
    
    // 2. 设置回调函数为Enhancer的成员变量
    public void setCallback(final Callback callback) {
        setCallbacks(new Callback[]{ callback });
    }
    
    // 3. Enhancer#create()
    private Object createHelper() {
    	...
        // 使用父类、接口、过滤器、回调函数、版本号等信息生成标识类的key -> 构造出multi-values key对象 => 用于获取/设置缓存
        return super.create(KEY_FACTORY.newInstance((superclass != null) ? superclass.getName() : null, ReflectUtils.getNames(interfaces), 
        											filter,
                                                    callbackTypes,
                                                    useFactory,
                                                    interceptDuringConstruction,
                                                    serialVersionUID));
                                                    
    // 类abstract public class AbstractClassGenerator implements ClassGenerator
    // 4. super#create()生成字节码增强文件，并设置multi-values key对应的缓存
    protected Object create(Object key) {
    	...
		if (gen == null) {
			// 根据默认策略生成代理对象的Class文件字节流
			byte[] b = strategy.generate(this);
			// 根据字节流获取Class文件名
			String className = ClassNameReader.getClassName(new ClassReader(b));
			// 添加Class文件名到类加载器中
			getClassNameCache(loader).add(className);
			// 根据Class文件名 & Class文件字节流 & 类加载器生成代理对象的Class
			gen = ReflectUtils.defineClass(className, b, loader);
		}
		// 添加代理类Class对象到类加载器缓存中
		if (useCache) {
			cache2.put(key, new WeakReference(gen));
		}
		
		// 5. 生成代理对象实例
		return firstInstance(gen);
    }
    // 类abstract public class AbstractClassGenerator implements ClassGenerator
    
    // 5. Enhancer类生成代理对象实例
    protected Object firstInstance(Class type) throws Exception {
        if (classOnly) {
            return type;
        } else {
            return createUsingReflection(type);
        }
    }
    private Object createUsingReflection(Class type) {
        // 5. 设置代理对象的回调函数, 其中MethodInterceptor实现了Callback接口, 实际上callback就是实现的MethodInterceptor
        setThreadCallbacks(type, callbacks);
        ...
        // 5. 反射生成代理对象实例
        return ReflectUtils.newInstance(type);
    }
}

// CGLIB代理类，原委托类为HelloCglib
public class HelloCglib$$EnhancerByCGLIB$$6bf7bfad extends HelloCglib implements Factory
{
	    static void CGLIB$STATICHOOK1()
    {
    	// Method数组: 含动态代理生成的方法 & 原委托类所有非Final的方法
        Method amethod[];
        // 之前设置的回调函数
        CGLIB$THREAD_CALLBACKS = new ThreadLocal();
        // 代理对象的Class对象
        Class class1 = Class.forName("com.jsonyao.cs.proxyPattern.HelloCglib$$EnhancerByCGLIB$$6bf7bfad");
        // 原委托类的Class对象
        Class class2;
        
        // 6. 静态代码块: 调用MethodProxy#create生成原委托类方法、代理对象代理方法的签名
        CGLIB$helloAagin$5$Proxy = MethodProxy.create(class2, class1, "()V", "helloAagin", "CGLIB$helloAagin$5");
        ...
    }
    
    // 11. 调用代理对象的CGLIB$helloAagin$5()
    final void CGLIB$helloAagin$5()
    {
    	// 12. 最后一步：调用父类HelloCglib原委托类的helloAagin方法，避免反射调用，提高性能
        super.helloAagin();
    }
}

// MyMethodInterceptor#invoke（）入参：MethodProxy
public class MethodProxy {

    // 7. 生成原委托类方法、代理对象代理方法的签名
    public static MethodProxy create(Class c1, Class c2, String desc, String name1, String name2) {
        MethodProxy proxy = new MethodProxy();
        proxy.sig1 = new Signature(name1, desc);
        proxy.sig2 = new Signature(name2, desc);
        proxy.createInfo = new CreateInfo(c1, c2);
        return proxy;
    }

    // 8. Object object = methodProxy.invokeSuper(o, objects);
    // 8. o: 增强后的代理对象, objects参数列表
    public Object invokeSuper(Object obj, Object[] args) throws Throwable {
        try {
        	// 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
            init();
            FastClassInfo fci = fastClassInfo;
            
            // 10. 根据代理方法索引、代理对象、参数列表调用FastClass方法
            return fci.f2.invoke(fci.i2, obj, args);
        } catch (InvocationTargetException e) {
            throw e.getTargetException();
        }
    }
    
    private static class FastClassInfo
    {
        FastClass f1;
        FastClass f2;
        int i1;
        int i2;
    }
    
    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
    private void init()
    {
        if (fastClassInfo == null)
        {
            synchronized (initLock)
            {
                if (fastClassInfo == null)
                {
                    CreateInfo ci = createInfo;

                    FastClassInfo fci = new FastClassInfo();
                    fci.f1 = helper(ci, ci.c1);
                    fci.f2 = helper(ci, ci.c2);
                    fci.i1 = fci.f1.getIndex(sig1);
                    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
                    fci.i2 = fci.f2.getIndex(sig2);
                    fastClassInfo = fci;
                    createInfo = null;
                }
            }
        }
    }
}

// FastClass抽象父类
abstract public class FastClass
{
	abstract public int getIndex(Signature sig);
    
    abstract public Object invoke(int index, Object obj, Object[] args) throws InvocationTargetException；
}

// 20201113 HelloCglib代理后的FastClass文件
public class HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271 extends FastClass {
    
    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
     public int getIndex(Signature var1) {
        String var10000 = var1.toString();
         switch(var10000.hashCode()) {
            ...
        	case -1512990617:
            	if (var10000.equals("CGLIB$helloAagin$5()V")) {
                	return 16;
            	}
            	break;  
            ...
         }
     }
    
    // 10. 根据代理方法索引、代理对象、参数列表调用FastClass方法
    public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException {
        6bf7bfad var10000 = (6bf7bfad)var2;
        int var10001 = var1;
        try {
            switch(var10001) {
                ...
                case 16:
                    // 11. 调用代理对象的CGLIB$helloAagin$5()
                	var10000.CGLIB$helloAagin$5();
                	return null;
                ...
            }
        }
    }
}
```

### 2.7. 值传递、引用赋值、引用复制？

- **值传递**：基本类型变量的赋值为**值传递**，比如int i = 1。
- **引用赋值**：对象变量的赋值为**引用赋值**，即新变量和老变量具有相同的引用。
- **引用复制**：对象作为方法参数传递，传递的是原对象引用的副本，即发生了**引用复制**。
  - 在引用副本所引用的对象，如果没有提供操作对象成员变量的方法，该引用副本不会修改原引用的对象，比如String。
  - 在引用副本所引用的对象，如果有提供操作对象成员变量的方法，该引用副本会修改原引用的对象，比如StringBuilder.append(i)。
  - 引用副本在被更改后，不会影响到原引用的值。

### 2.8. 基本类型、对象类型、数组类型引用的内存分布情况？

- **基本类型**：boolean、byte、short、char、int、float以及对应的引用类型**在栈上**占4个字节，long、double在栈上占8字节。也就是此时对于每个方法来说，栈上的空间在编译时已经确定了的。
- **对象类型**：比如new Object（）**在堆中分配空间**，再由**栈引用指向堆中的对象**。
  - **字符串类型**：比如String str = new String("hello")，此时类似于对象类型的内存分布情况，**栈中的str**引用指向**堆中**的String对象的首地址，而String对象里有char[] chars、int startIndex、int length属性，其中chars引用指向‘h’ ‘e’ ‘l’ ‘l’ ‘o’**字符数组**的首地址。
- **数组类型**：**栈中**的引用指向**一维数组（行）**的首地址，**堆中**开辟实际数组的空间。
  - **一维数组**：比如int[] arr = new int[2]，此时栈中的arr引用占4个字节，指向堆中开辟的2个连续的int 4个字节空间的首地址。
  - **二维数组**：比如int[][] arr2 = new int[2] [4]，此时栈中的arr2引用还是占4个字节，指向堆中开辟的2个连续的int[]4个字节的空间的首地址，而每个int[]引用又指向堆中开辟的4个连续的int 4个字节空间的首地址。
    - **二维空数组**：比如int[][] arr3 = new int[2] []，此时栈中的arr2引用还是占4个字节，指向堆中开辟的2个连续的int[] 4个字节的空间的首地址，而每个int[]引用为null。

### 2.9. 引用与指针？

- **引用**：**引用一旦指向了对象，则不能再被更改，即使对象变了引用的东西也会跟着变，强调的是对象的不变性**（即一定要"小明干活"），**类似于对象的别名**，比如对象（员工）"小明"改名为了"小强"，此时引用（上司）还是知道那个对象叫是"小强"，即引用强调的是员工（对象）的不变性。
- **指针**：**指针允许自由操作地址的指向，强调的是指向的地址是自由的**，即关系自由性（谁干活不重要, 但一定要有人干），比如指针（上司）与地址"小明"分配工作内容，但第二天地址"小明"辞职了，这时指针（上司）可以把活分配给新的地址"小强"，即改变了指向的地址。
- **混淆点**：引用类似于指针，与指针一样，查看引用可以知道具体指向的地址，但引用并不能操作该地址的指向。但是**Java中没有指针，只有引用**：
  - **Java中谈引用是从内存分析的角度思考的**，分析引用指向那个对象，这种引用的对象到底什么时候可以被回收等等。
  - 而**谈的“指针’”是从数据结构的角度思考**，比如这个链表头指针移动到哪里哪里等等，实际上移动到哪里哪里，但实际也还是引用的赋值，因为从内存的角度来说，就是把新的头节点的引用赋值给原来的头节点，因此也还是引用。
  - 所以**Java没有指针，只有引用**。

### 3.0. Java四种引用类型？

![1623655664473](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1623655664473.png)

#### 强引用

- **概念**：
  - jdk 1.8包中没有这个类，是普通类的引用。
  - M m = new M（），此时m为强引用对象。
- **特点**：
  - **强引用“引用”（动词）的对象永远不会被垃圾收集器回收**，即使将要发生OOM（OutOfMemoryError）。
  - **普通引用**就是强引用对象，可直接访问“引用”的对象。
- **使用场景**：直接访问“引用”的对象，做业务操作。

#### 软引用

- **概念**：
  - SoftReference，Reference引用抽象基类的实现类。
  - SoftReference m = new SoftReference（new M（）)，此时m为软引用对象。要注意的是，虽然m为软引用对象SoftReference，但在内存分布中，栈m到堆SR之间是强引用（普通引用）关系，而**SR内部到M才是真正的软引用关系**。
- **特点**：
  - 只被软引用“引用”的对象不会被垃圾收集器立即回收，垃圾收集器会根据内存需求自行是否决定清除“引用”的对象：**只有在堆内存不足时**，垃圾收集器才会去回收只被软引用“引用”的对象。
  - 在虚拟机抛出 OutOfMemoryError 之前，保证清除软可达对象的所有软引用，鼓励虚拟机实现偏向于**清除最近创建或最近使用的软引用**。
  - **先清除软引用，再将软引用加入引用队列**：垃圾收集器在某个时间点确定被软引用"引用"的对象是软可达的，此时会以原子方式清除“引用”的对象的所有软引用，以及对任何其他软可达对象的所有软引用，**同时或稍后会将已经注册到引用队列的新清除的软引用加入引用队列**。
- **使用场景**：常用于实现内存敏感的缓存，比如Guava中的LocalCache。

#### 弱引用

- **概念**：
  - WeakReference，Reference引用抽象基类的实现类。
  - WeakReference m = new WeakReference(new M（）)，此时m为弱引用对象。要注意的是，虽然m为弱引用对象WeakReference，但在内存分布中，栈m到堆WR之间是强引用（普通引用）关系，而**WR内部到M才是真正的弱引用关系**。
- **特点**：
  - 垃圾收集器一旦发现了只被弱引用“引用”的对象，**无论堆内存是否足够**，都会回收“引用”的对象的内存。
  - **先清除弱引用，再将弱引用加入引用队列**：垃圾收集器在某个时间点确定被弱引用“引用”的对象是弱可达的，此时会以原子方式清除“引用”的对象的所有弱引用，以及对任何其他弱可达对象的所有弱引用，以及声明所有以前弱可达的对象是可终结的，**同时或稍后会将已注册到引用队列的弱引用加入队列**。
- **使用场景**：
  - 常用于实现规范化Map集合，如ThreadLocal的Entry#Key对象。
  - 这是因为在Map集合实现的缓存中，会出现**无用Key对象被Map实例强引用导致出现内存泄露问题**（即没用的对象没被释放掉），这时弱引用包装的真实的Key对象，使用弱引用实例来作为key，可以缩短Key的生命周期，使得Key可以更快地被垃圾收集器回收掉，从而解决无用Key对象带来的内存泄露问题。
  - 要注意的是，如果使用弱引用包装Key对象，在真实的Key对象被回收后，弱引用实例的Key会被置为null，形成null-Value的键值对，导致**出现无用Value对象的内存泄露问题**。这就需要真实的Key对象被回收时，删除对应的弱引用实例-Value键值对，解决无用Value对象带来的内存泄露问题。

#### 虚引用

- **概念**：
  - PhantomReference，Reference引用抽象基类的实现类。
  - PhantomReference m = new PhantomReference（new M（），new ReferenceQueue（）），此时m为虚引用对象。要注意的是，虽然m为虚引用对象PhantomReference，但在内存分布中，栈m到堆PR之间是强引用（普通引用）关系，而**PR内部到M才是真正的虚引用关系**，且虚引用创建时必须绑定一个引用队列。
- **特点**：
  - 只被虚引用“引用”的对象跟没有被“引用”是一样的，**“引用”的对象随时会被垃圾收集器回收**。
  - 虚引用“引用”的对象不能被检索到，即通过**调用虚引用的get（）总是返回null**。
  - **加入引用队列不需要先清除与对象的“引用”**：在垃圾收集器确定**“引用”的对象可能会被回收后**，会将其上的虚引用对象加入引用队列进行排队（此时没有清除与对象之间的“引用”）。
- **使用场景**：常用于调度预检清理操作，比如JVM用于管理堆外内存（直接内存）的释放。

![1623670905412](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1623670905412.png)

### 3.1. ArrayList与LinkedList？

|                    | ArrayList                                      | LinkedList                         |
| ------------------ | ---------------------------------------------- | ---------------------------------- |
| 实现接口           | List                                           | List、Deque                        |
| 数据结构           | 基于数组实现                                   | 基于双向链表实现                   |
| 提供的API          | List方法                                       | 栈、队列、双端队列方法             |
| 插入元素           | 数组尾部                                       | 链头、链尾两个方向都可以           |
| 初始容量与扩容机制 | 10，每次扩容1.5倍容量                          | 无容量限制，无扩容机制             |
| 适用场景           | 支持对元素进行快速随机访问，适合随机查找和遍历 | 适合数据的动态插入和删除           |
| 不适合场景         | 不适合大量插入和删除                           | 不支持元素的随机访问，必须遍历链表 |

### 3.2. 如何实现List线程安全？

- List API外层使用**锁**保证线程安全。
- **Collections内部类SynchronizedList**，通过持有传入的List引用，以及Object mutex对象锁，提供synchronized关键字修饰List接口方法，从而包装成线程安全的List。
- **Vector**，可增长数组，默认容量10，默认容量扩容2倍，通过使用synchronized关键字修饰方法保证线程安全。
- **CopyOnWriteArrayList**，写时复制，读操作不需要加锁，只保证数据最终一致性，无法保证实时性。

### 3.3. 快速失败fail-fast机制？

- **大多数迭代器都是快速失败的**，即如果在创建迭代器后的任何时间**对结构进行结构修改（modCount）**，则除了通过迭代器自己的remove方法之外，该迭代器都将抛出{ @link ConcurrentModificationException}。
- 这在**面对并发修改时，迭代器可以快速干净地失败**，而不是在未来不确定的时间冒着任意、非确定性行为的风险去修改。
- 无法保证迭代器的快速失败行为，因为一般而言，在存在非同步并发修改的情况下，不可能做出任何硬保证，**只会尽最大努力抛出ConcurrentModificationException，**因此，编写一个依赖于这个异常来保证其正确性的程序是错误的，**快速失败行为只适用于检测错误**。

### 3.4. 详细介绍HashMap?

#### 特点

- **HashMap，Map接口基于散列表的非线程安全的实现，允许null值和null键，不保证元素的顺序**。所以，在散列表均匀分散元素的情况下，get和put方法时间复杂度为O（1），而迭代所需的时间与其**容量**（散列表桶数）和**实际大小**（键值对数）成正比，因此不要设置过高的初始容量或者过低的负载因子（会导致大容量）。
- 几个重要的参数：
  - **当前容量**：当前容量是散列表中存储桶的数量，而初始容量只是创建散列表的容量。
  - **负载因子**：等于实际大小 / 当前容量，当散列表中的条目数超过阈值（负载因子和当前容量的乘积）时，HashMap发生扩容，使散列表具有大约两倍容量（桶数）。
  - **阈值**：等于负载因子 * 当前容量，默认为16（即默认容量），当table为空表时，则在扩容时用作新表的容量；否则，用作判断是否扩容的条件，如果当前容量大于阈值，则需要扩容散列表。
  - **实际大小**：HashMap所有的条目总数。
- **默认提供的负载因子0.75，在时间和空间成本之间提供了很好的权衡**：
  - 较高会减少空间的开销，但增加了查找的成本（由于高负载因子，导致扩容次数减少，桶拉链变长）。
  - 较低会增加扩容的次数，增加空间的开销，但好在桶拉链变短，查找效率高，哈希冲突少。
- HashMap的所有迭代器都是**快速失败**的，即如果在创建迭代器后的任何时间对结构进行结构修改，则除了通过迭代器自己的remove方法之外，该迭代器都将抛出{ @link ConcurrentModificationException}。

#### 数据结构

数组 + 链表 + 红黑树：

![1625405326188](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625405326188.png)

#### 构造方法

- 4个构造方法，分别为空参的、指定初始容量的、指定初始容量和负载因子的、指定复制集合的。
- 默认负载因子为0.75，默认容量为16。

#### HashCode扰动函数

- **hash（Object）**，将HashCode右移16位，从而混合HashCode的高位和低位，加大低位的随机性，减少哈希碰撞发生的概率，是一种**性能、效用和质量**的折衷方案。
  - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查
    找效率。
  - HashCode右移16位，使得高位能被利用起来，保证了效用性。
  - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。

#### 哈希索引的计算方法

- **（n - 1） & hash，相当于hash % n**：n指散列表的当前容量（桶数量），hash指获取hash（key）即key的hashCode扰动后结果。
  - **不能直接使用HashCode作为索引的原因**：int类型的hashCode，范围为[-2^32，2^32 - 1]，如果散列表
    数组与HashCode一一对应，需要40亿的空间（int[40亿]），明显这在内存是放不下的，也就是说明
    hashCode是不能直接作为数组索引的。因此，如果使用hashCode对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组也还能利用上hashCode。
  - **n为2的幂次原因**：为了解决hashCode对散列表数组长度取模，设计了HashCode的扰动函数以及为2幂次的容量n，可以通过n-1来获得取模操作的低位掩码，此时**只需要通过低位掩码与扰动后的**
    **hashCode（hash值）进行一次与运算**，即可得到该hash值在散列表数组中的索引。其次通过在扩容方
    法中，经过hash值与低位掩码相与，可以保证扩容后，**只会移动少部分相与结果高位为1的桶链表**，其他
    保持不变，减少了扩容时的时间。
- **通过tableSizeFor（int）返回给定目标容量的2的幂次**，底层通过-1，右移1、2、4、8、16位，再+1得到目标容量。

#### resize扩容方法

1. **扩容前分3种情况判断，来确定新容量和阈值**：
   - 当前容量 > 0，则容量 * 2，阈值 * 2。
   - 当前容量 <= 0，且阈值 > 0，说明HashMap已被初始化且表为空表，则使用阈值作为新的容量。
   - 当前容量 <= 0，且阈值 <= 0，说明HashMap还没被初始化，则使用默认容量16以及默认阈值12=16 * 0.75。
2. **创建新容量的散列表**：(Node<K,V>[])new Node[newCap]；
3. **从头遍历散列表，移动结点**：
   - 如果桶j只有一个元素，则重新计算哈希索引，转移元素到新表即可。
   - 如果桶j为红黑树，则调用红黑树的split方法，拆分红黑树，以重新计算每个结点的哈希索引。根据哈希索引是否不变，拆分成高低lo和hi链表，lo链表移动到新桶时保持原桶位置不动，hi链表往前移动oldCap长度的位置。其中如果拆分后的链表长度小于等于6时，则会把**红黑树退化成普通链表**。
   - 如果桶j为普通链表，则重新计算每个结点的哈希索引，根据哈希索引是否不变，拆分成高低lo和hi链表，lo链表移动到新桶时保持原桶位置不动，hi链表往前移动oldCap长度的位置。

#### put方法

3个常用的顶层API方法put、putIfAbsent、putAll，它们依赖于putVal方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果p桶为null，则直接new Node放到该桶即可。
3. 如果p桶不为null，则分4种情况判断：
   - 如果桶头结点p的hash值相等且（key相等 或者 equals），说明p就是要找的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 否则，如果桶头结点p为红黑树结点，则使用**TreeNode的实例方法putTreeVal**添加key：value。
   - 否则，p为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 如果找不到对应的结点，则在链尾new Node一个结点，并且添加后如果当前链表至少有8个结点，则调用**HashMap的实例方法treeBin**将当前桶链表树化为红黑树（treeBin还会判断散列表容量是否大于等于64）。
4. 如果发生的不是值替换，则更新修改模数、实际大小，如果实际大小大于阈值，则还需要调用resize（）进行扩容并转移结点。最后返回null，代表结点插入成功。

#### remove方法

2个常用的顶层API方法remove（Object）和remove（Object，Object），它们都依赖removeNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果桶p为null，则返回null，代表HashMap不存在对应的结点。
3. 如果p桶不为null，则分4种情况判断：
   - 如果桶头结点p的hash值相等且（key相等 或者 equals），说明p就是要找的结点，将p引用赋值给node引用，待后面做删除操作。
   - 否则，如果桶头结点p没有后继，则将p引用赋值给node引用，待后面做删除操作。
   - 否则，如果p有后继且p为红黑树结点，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点，并将其引用赋值给node引用，待后面做删除操作。
   - 如果p有后继且p为普通结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，并将其引用赋值给node引用，待后面做删除操作。如果找不到，则设置node引用为null。
4. 如果node引用为null，则返回null，代表HashMap不存在对应的结点；如果node引用不为null，说明找到了对应结点（如果此时matchValue为true，则还需要判断value是否equals），则分为3种情况判断：
   - 如果node为红黑树结点，则调用**TreeNode的实例方法removeTreeNode**删除该结点。
   - 如果node为普通结点，且为桶头结点，则脱钩node结点，并更新桶头结点为它的后继。
   - 如果node为普通结点，但不为桶头结点，则链接它的前驱和后继，脱钩node结点。
5. 最后如果脱钩结点成功，则更新修改模数、实际大小，返回node结点。

#### get方法

2个常用的顶层API方法get、getOrDefault，它们都依赖getNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶first。
2. 如果桶first为null，则返回null，代表HashMap不存在对应的结点。
3. 如果first桶不为null，则分4种情况判断：
   - 如果桶头结点first的hash值相等且（key相等 或者 equals），说明first就是要找的结点，则直接返回first结点。
   - 否则，如果桶头结点first没有后继，则返回null，代表HashMap不存在对应的结点。
   - 否则，如果first有后继且first为红黑树结点，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点并返回。
   - 如果first有后继且first为普通结点，则遍历first链表，如果找到hash值相等且（key相等 或者 equals）的结点并返回。如果找不到，则返回null，代表HashMap不存在对应的结点。

### 3.5. HashMap红黑树？

#### TreeNode性质

- **性质1**：红黑树的结点要么是红色，要么是黑色。
- **性质2**：红黑树的根结点是黑色的。
- **性质3**：红黑树的叶子结点（nil）都是黑色的。
- **性质4**：红黑树的红色结点必须有两个黑色结点。
  - **推论**：从根结点到每个叶子结点的所有路径上，不可能存在两个连续的红色结点。
- **性质5**：红黑树是黑色平衡的，即从根结点到每个叶子结点的所有路径中，所经过的黑色结点数都是一样的。
  - **推论**：如果一个结点右黑色的子结点，那么该结点一定是有两个孩子结点，因为必须有另一半才能保证该
    结点黑色平衡。

#### 旋转

- 背景：在结点的添加和删除后，**为了避免子树高度变化，需要通过子树内部调整来保证树达到平衡**，其中2-3-4树是通过结点旋转和结点元素变化实现的，红黑树是通过结点**旋转和变色**实现。
- **左旋**：口诀，**左右左右右**，即以x结点作为旋转点进行**左**旋，旋转后，x的**右**结点p成为x的父结点，p原本的**左**结点成为x结点的**右**结点，p原本的**右**结点保持不变。
- **右旋**：口诀，**右左右左左**，即以x结点作为旋转点进行**右**旋，旋转后，x的**左**结点p成为x的父结点，p原本的**右**结点成为x结点的**左**结点，p原本的**左**结点保持不变。

#### 插入后平衡红黑树

**balanceInsertion（TreeNode，TreeNode）**：对应2-3-4树的情况：

- **a. 空结点新增**：成为一个2结点，插入前树为null，插入后x需要变黑色，作为根结点。
- **b. 合并到2结点中**：成为一个3结点，插入前2结点为黑色，插入后无论是（上黑下左红 |  上黑下右红）, 都符合3结点要求，因此无需调整。
- **c. 合并到3结点中**：成为一个4结点，插入前为3结点（上黑下左红 |  上黑下右红），插入后成为4结点黑红红的情况，根据x插入位置不同分为6种情况：
  - **c.2.1.**  左三(中左左*) ，黑红红，不符合红黑树定义 => 需要调整，则中1右旋，中1变红，左1变黑。
  - **c.2.2.** 中左右*(其实就相当于左三，因为对父结点进行左旋，即得到左三) ，黑红红，不符合红黑树定义 => 需要调整，则左1左旋（得到左三），中1右旋，中1变红，新左变黑。
  - **c.2.3.** 右三(中 右右*) ，黑红红，不符合红黑树定义 => 需要调整，则中1左旋，中1变红，右1变黑。
  - **c.2.4.** 中 右左*(其实就相当于右三，因为对父结点进行右旋，即得到右三) 黑红红，不符合红黑树定义 => 需要调整，则右1右旋（得到右三），中1左旋，中1变红，新右变黑。
  - **c.2.5.** 中左 右*，黑红 红，符合红黑树定义 => 无需调整。
  - **c.2.6.** 中左* 右，黑红 红，符合红黑树定义 => 无需调整。
- **d. 合并到4结点中**：成为一个裂变状态（变色后相当于升元了），插入前为4结点（黑红红），插入后4结点颜色反转，爷结点成为新的x结点，准备下一轮的向上调整，根据x插入的位置不同分为4种情况：
  - **d.2.1.** 中左左* 右(黑红红 红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，左2保持为红， 右1变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.2.** 中左右* 右(黑红红 红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，右1保持为红，右2变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.3.** 中左 右左*(黑红 红红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，左2保持为红，右1变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.4.** 中左 右右*(黑红 红红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，右1变黑，右2保持为红，中看作为“插入结点”，继续向上调整。

#### 删除结点前/后平衡红黑树

**balanceDeletion（TreeNode，TreeNode）**：删除结点前/后平衡红黑树，如果x所在结点为2-3-4树的2结点，则平衡后再删除，如果x所在结点为3结点或者4结点，在平衡前对应的结点就已经删除了，此时x作为该结点的替代结点而保留下来：

- **x自己搞得定**：
  - 自己搞得定的意思就是，可以**在自己结点内部处理完毕**（对应2-3-4树结构），不影响其他树的结构。
  - **a.1. x为3结点或者4结点的红结点**：直接置黑返回x结点即可调整完毕（因为x是作为替代结点而保留下来的），然后交由上层方法删除x结点。
- **x自己搞不定，兄弟搞得定**：
  - 自己搞不定的意思就是，自身结点为黑结点，如果直接删除会导致父结点所在的树黑色不平衡。
  - 兄弟搞得定的意思就是，**兄弟结点存在多余的子结点**（即兄弟结点为3结点或者4结点），此时，x的父结点就可以借出结点下来合并到x结点中，兄弟结点再借出结点合并到父结点中，这样x就可以顺利删除了，同时2-3-4树的结构还保持不变。
  - 但是，**前提是x的兄弟结点是真正的兄弟结点，即为黑色的结点**，如果为红色的结点，说明其只是父结点（3结点）的红结点，此时需要对父结点进行旋转，以保证x有真正的兄弟结点。
  - **b.1. 兄弟结点为3结点，但无右（左）**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr无右孩子在对父结点左旋时，会导致xpr为null，导致2-3-4树的结构不正确，因此，**b.1是一个临时情况，需要对xpr进行右旋，转换为b.2有右进一步处理**。x为右子树一方时则相反。
  - **b.2. 兄弟结点为3结点，但有右（左）**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr有右，则可以顺利地对父结点xp进行左旋。左旋后，在2-3-4树结构看来，xp作为xpr的左孩子（相当于父结点借出去一个结点，合并到x结点中），xpr作为xp的父亲（**相当于兄弟结点借出去一个结点，合并到父结点中**），xpr借出去的结点颜色为xp借出去的结点颜色，xp借出去的结点颜色一定要为黑色（相当于3结点），xpr剩余结点一定要为黑色（相当于叶子结点），返回x结点即可调整完毕，交由上层方法删除x结点。x为右子树一方时则相反。
  - **b.3. 兄弟结点为4结点，肯定有右**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr有右，则可以顺利地对父结点xp进行左旋。左旋后，在2-3-4树结构看来，xp作为xpr的左孩子（相当于父结点借出去一个结点，合并到x结点中），xpr作为xp的父亲（**相当于兄弟结点借出去一个结点，合并到父结点中，而且还多借出左孩子合并到x结点中**），xpr合并到父结点的颜色为xp借出去的结点颜色（而借出去的左孩子本来为红色所以不用变），xp借出去的结点颜色一定要为黑色（相当于4结点），xpr剩余结点一定要为黑色（相当于叶子结点），返回x结点即可调整完毕，交由上层方法删除x结点。x为右子树一方时则相反。
  - 在b.3中对于兄弟结点为4结点时，兄弟结点可以借出1个结点（需要旋转两次）或者2个结点（只需要旋转一次），**在JDK中无论是HashMap还是TreeMap，都选择借出2个结点，因为可以减少花销。**
- **x自己搞不定，而且兄弟也搞不定**：
  - 自己搞不定的意思就是，自身结点为黑结点，如果直接删除会导致父结点所在的树黑色不平衡。
  - 兄弟也搞不定的意思就是，**兄弟结点也为黑结点，没有多余的子结点**，如果直接删除x，则导致叔结点所在路径多了一个黑色结点，造成黑色不平衡。
  - **c.1. 兄弟结点为2结点**：此时，为了让x能够顺利删除，**兄弟结点需要置红（自损）**，这样x在删除后，x父结点所在树还是黑色平衡的。但是，如果x父结点为黑色，x爷结点所在树则不黑色平衡了（因为父结点这边少了一个黑色结点），所以父结点的叔结点要也要被置红。**因此需要一路向上自损，直到碰到任意一个终止条件即可结束**：
    - **自损的终止条件1（向上碰到根结点）**：经过一路置红叔结点（置红叔结点是没问题的，因为出现该情况是叶子结点为3结点黑黑黑的时候，此时如果叔结点没有孩子结点即为黑色，而对于更上层的叔结点来说，貌似不会出现叔为黑红红这种情况），直到循环到根结点时（因为上面已经没有父节点了），则代表自损完毕，此时整棵树都是黑色平衡的了（都减少了一个黑色结点）。
    - **自损的终止条件2（向上碰到红结点）**：如果碰到红色结点时，只需要把该结点置黑，则不需要在置红叔结点了，此时相当于在父结点这边子树补回了一个黑色结点，而不影响叔结点那边子树的黑色结点数目，因此整棵树还是黑色平衡的。

#### 链表树化成红黑树

HashMap的实例方法treeBin，先判断散列表容量是否大于等于64，如果不是则调用resize扩容即可，否则维护桶链表为**双向无环链表**，接着底层调用**TreeNode的实例方法treeify**树化该链表成为红黑树，其步骤为：

1. 取桶头结点作为根结点，置黑。
2. 遍历桶链表，比较根结点hash值比较当前结点x的hash值大小，小于等于的继续遍历左子树，大于的遍历右子树，然后插入当前遍历结点到对应的位置，再平衡红黑树。

#### 红黑树退化成普通链表

**untreeify（HashMap）**：

1. 遍历桶链表，重新构建后继为null的Node结点，再重新维护每个结点的next指针。
2. 遍历结束，最后返回链头指针hd即可。

#### 添加红黑树结点

**putTreeVal（HashMap，Node，int，K，V）**：红黑树结点的添加方法（插入成功则返回null，插入失败则
返回已经存在的结点）。其步骤为：

1. 从根结点遍历比较插入结点x的hash值，小于等于0的说明x应该在左边，大于0的说明
   x应该在右边。
2. 找到合适位置后（叶子结点），构建TreeNode结点，维护x与父结点、prev结点、next结点的关系。
3. 插入后平衡红黑树，返回null，表示插入成功。

#### 删除红黑树结点

**removeTreeNode（HashMap，Node，boolean）**：

- **替代结点**：红黑树是一种自平衡的二叉搜索树，而二叉搜索树删除，本质上是**找前驱或者后继结点来替代删除**（这里是replacement替代p然后删除p）。
- **A. 如果要删除的结点是叶子结点**：则直接删除即可（肯定为黑色）。
- **B. 如果要删除的结点只有一个孩子结点**：则使用孩子结点进行替代，然后删除"替代结点"。
- **C. 如果要删除的结点有两个孩子结点**：则需要找到前驱或者后继进行替代，然后删除"替代结点"。
  - **C.1. 如果替代结点没有孩子结点**：此时所在的结点为2-3-4树的2结点，则直接要"替代结点"即可。
  - **C.2. 如果替代结点有孩子结点且孩子结点为替代方向**：此时所在的结点为2-3-4树的3结点或者4结点，则继续使用孩子结点进行替代，然后“替代结点”即可（二次替代）。
- 无论是哪种情况，红黑树结点的删除方法，都要调用平衡红黑树的方法，在删除结点前/后平衡红黑树。

#### 获取红黑树结点

**getTreeNode（int，Object）**：

1. 根据hash值和key值，从根结点开始查找红黑树结点，小于等于0的说明x应该在左边，大于0的说明x应该在右边。
2. 直到找到hash值相等且（key相等 或者 equals），说明该结点就是要找的结点，则返回即可。
3. 如果找不到，则返回null，代表没找到对应的结点。

### 3.6. JDK1.7 HashMap与JDK1.8 HashMap的区别？

JDK1.8 主要解决或者优化了以下问题：

- resize（）扩容优化：取消了rehash，分高低位转移链表，保证转移后结点相对顺序不变，从而解决了多线程死循环问题。但HashMap仍是非线程安全的，并发添加结点可能会造成数据丢失。
- 插入方式改成尾插法，同时引用红黑树，避免链表过长影响查找效率，同时保证插入的性能。

|                  | JDK1.7 HashMap                                               | JDK1.8 HashMap                                               |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据结构         | 数组 + 链表                                                  | 数组 + 链表 + 红黑树                                         |
| HashCode扰动函数 | 9次扰动（4次移位，5次异或），有哈希种子影响                  | 2次扰动（1次移位，1次异或），无哈希种子                      |
| 扩容方法         | 可以rehash（容量 > 哈希种子阈值时），转移后结点相对顺序反转（头插法） | 无rehash，分高低位转移链表，转移后结点相对顺序不变           |
| 插入方法         | 无冲突，则插入数组；有冲突，则插入链表（头插法）             | 无冲突，则插入数组；有冲突，则插入链表（尾插法）；有冲突 & 插入后链表长度 >= 8，且散列表容量 >=64，则把链表树化成红黑树 |

#### JDK 1.7 HashMap导致CPU 100%的原因？

在多线程环境下，使用HashMap进行put操作时，可能会产生**循环链表**，在下次获取其所在桶链时导致**死循环**，导致CPU利用率飙升，甚至接近100%，因此，在高并发情况下是不能使用HashMap的。

- **原因**：当多个线程并发扩容时，同时进入了transfer转移结点的方法，由于该方法没有做线程同步的处理，且采用的是头插法，在获取**e结点和newTable[i]**时，有可能获取到同一个结点（肯定是旧表的尾结点），接着在后面的e.next = newTable[i]中，对e的后继赋值了e，导致在e结点上产生了**循环链表**。

```java
// 头插法：注意！头插法转移元素会使用的当前链表元素顺序反转，导致并发扩容时获取newTable[i]得到别的线程转移完成的尾结点，从而出现循环链表。而JDK8 HashMap中的分高低位链表转移+尾插法的方式，既可以解决key需要重新计算索引，也可以解决循环链表的出现。
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while(null != e) {
            // 0. 模拟循环链表产生的情况，两个线程A、B并发执行到这里，一个结点e
            // 1. B失去CPU时间片，回到就绪态；A继续执行
            // 3. 此时，B得到CPU时间片，重新回到运行态，获取到的e已经在新桶中了，next为null
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            
            // 2. A执行下面三句后，e放进了新散列表中，此时e.next为null，然后把这个循环链表放在了新散列表的i索引上，而由于next为null，赋值给e后则退出循环，完成结点的转移操作
            // 4. B获取新桶的i索引得到e，此时设置e.next为了e，产生了循环链表！然后把这个循环链表放在了新散列表的i索引上，而由于next为null，赋值给e后则退出循环，完成结点的转移操作
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```

### 3.7. 如果实现散列表线程安全？

- HashMap API外层使用**锁**保证线程安全。
- **Collections内部类SynchronizedMap**，通过持有传入的Map引用，以及Object mutex对象锁，提供synchronized关键字修饰Map接口方法，从而包装成线程安全的Map。
- **HashTable**，散列表的线程安全实现类，默认初始容量11，默认负载因子0.75，不允许为null键和null值，通过使用synchronized关键字修饰方法保证线程安全，效率低下。
- **ConcurrentHashMap**，支持高并发检索和更新的散列表实现类，默认初始容量和负载因子与HashMap一样，不允许为null键和null值，可在保持并发可读的同时最小化锁竞争。

### 3.8. 详细介绍ConcurrentHashMap？

#### 特点

- ConcurrentHashMap，**一个支持高并发检索和高并发更新的散列表实现类**，实现ConcurrentHashMap接口，不允许为null键和null值。其主要设计目标是**保持并发可读性，同时最小化更新时的锁争用**，次要目标是保持与java.util.HashMap相同或更好的空间消耗，并支持许多线程对空表的高初始插入率（自旋+CAS保证）。
- 几个重要的参数：
  - **当前容量**：当前容量是散列表中存储桶的数量，而初始容量只是创建散列表的容量。
  - **控制变量sizeCtl**：通常等于通常等于0.75 * 容量，但在构造函数中等于初始容量；散列表初始化时为-1；散列表在扩容时，高16位为扩容标记，低16位为并发扩容线程数（从2开始, 步长为+1）。
  - **分布计数变量**：计数基数baseCount，分布计数单元格数组counterCells，单元格繁忙标记cellsBusy。
  - **转移相关变量**：转移最小块索引transferIndex，可以减少协助转移结点时的竞争；转移目标散列表nextTable。
- 几种类型的结点：
  - **Node**：实现Map.Entry，是ConcurrentHashMap中最普通的链表结点，拥有hash、key、val、next成员变量，是其他类型结点的父类，其中val和next使用volatile修饰，保证线程可见性。
  - **TreeNode**：继承Node结点，是ConcurrentHashMap中的红黑树结点，在Node结点的基础上还维护了parent、left、right、red红黑树成员变量。
  - **TreeBins**：
    - 继承Node结点，是ConcurrentHashMap中红黑树的桶结点，hash值为-2，持有红黑树根结点root指针和链头first指针，不保存键和值。
    - 同时维护了读写锁，强迫写线程必须等待所有读线程完成后，才能进行红黑树结点操作。
    - 当读时不存在并发写线程，使用root指针走红黑树遍历方式查找结点；当读时存在并发写线程，使用first指针走链表遍历方式查找结点。
  - **ForwardingNode**：
    - 继承Node结点，是ConcurrentHashMap中的转发结点，hash值为-1，持有nextTable引用，没有键和值。
    - 在线程协助转移结点到新表后，会在旧表原位置维护一个Forwarding结点，以标识旧表正在发生扩容操作，让下一个线程碰到时可以协助进行转移旧表结点。
  - ReservationNodes：（不懂不要说）不保存hash值、key和value。用作占位符，同时在computeIfAbsent和相关方法中建立值。
- 几个重要方法：
  - **get方法**：
    - 一般不会阻塞，可与put和remove等更新方法同时执行，**反映的是最近完成更新的结果**，因此，对于putAll操作，并发检索可能只反映出插入的某些条目。
    - 类似的，迭代器反映的也是散列表在迭代器创建时，或者创建后的某个时刻的状态的
      元素，不会抛出 {@link java.util.ConcurrentModificationException
      ConcurrentModificationException}。
  - **size方法**：
    - 通常仅在Map不存在并发更新时才有用，否则结果反映的是瞬态状态，并不是准确的数值。
    - 因此可以用于监测或估计目的，而不适用于程序控制。
    - 其中size并发计数实现参考的是LongAdder，CounterCell计数数组机制避免了更新计数时的锁争用，但如果在并发访问期间读取过于频繁，可能会遇到缓存抖动（为了保证缓存一致性而出现的等待）。
  - **put与remove方法**：
    - 对于hash值为-1的ForwardingNode结点，会协助进行转移结点。
    - 对于hash值为-2的TreeBins结点，会先对结点进行加锁，获取到锁后才再用红黑树方式添加key-value。
    - 对于普通Node结点，会对桶头结点进行加锁，获取到锁后再使用链表方法添加key-value。
  - **扩容方法**：
    - 当散列表容量超过阈值时（ 0.75），则需要扩容散列表，sizeCtl字段中的生成戳resizeStamp，可保证其扩容不会重复执行。
    - 在启动扩容和设置nextTable之后，任何注意到forwarding结点或者桶过满的线程，都可以协助转移散列表结点，转移线程会根据transferIndex索引字段，小块小块地进行转移结点，从而减少争用。然而，这些线程可能会继续进行插入等操作，而不是停顿。
    - 由于散列表根据2的幂次进行扩容，所以每个桶中的元素要么保持相同的索引，或者以2次幂的偏移量
      进行移动。通过捕获可以重用的旧结点，来消除不必要的结点创建，因为它们的next指针不会改变。
    - 在结点转移后，会在旧表桶中保留一个特殊的转发节点（具有哈希字段“MOVED”），在遇到转发节点时，访问和更新操作会使用持有的nextTab作为新的散列表而重新启动。

#### 数据结构

数组 + 链表 + 红黑树，锁有CAS+自旋锁、synchronized可重入锁、TreeBin读写锁。

![1625493877273](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625493877273.png)

#### 构造方法

- 5个构造方法，分别为空参的、指定初始容量的、指定初始容量和负载因子的、指定初始容量、负载因子和并发线程数的（concurrencyLevel只是为了兼容JDK1.7 ，第一不为负数就好，第二在initialCapacity < concurrencyLevel时赋值initialCapacity 为concurrencyLevel）、指定复制集合的。
- 默认负载因子为0.75，默认容量为16。

#### HashCode扰动函数

- **spread（int）**：HashCode右移16位，从而**混合HashCode的高位和低位，加大低位的随机性，减少哈希碰**
  **撞发生的概率**，是一种性能、效用和质量的折衷方案。
  - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查
    找效率。
  - HashCode右移16位，使得高位能被利用起来，保证了效用性。
  - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。

#### 哈希索引的计算方法

- **（n - 1） & hash，相当于hash % n**：n指散列表的当前容量（桶数量），hash指获取hash（key）即key的hashCode扰动后结果。
  - **不能直接使用HashCode作为索引的原因**：int类型的hashCode，范围为[-2^32，2^32 - 1]，如果散列表
    数组与HashCode一一对应，需要40亿的空间（int[40亿]），明显这在内存是放不下的，也就是说明
    hashCode是不能直接作为数组索引的。因此，如果使用hashCode对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组也还能利用上hashCode。
  - **n为2的幂次原因**：为了解决hashCode对散列表数组长度取模，设计了HashCode的扰动函数以及为2幂次的容量n，可以通过n-1来获得取模操作的低位掩码，此时**只需要通过低位掩码与扰动后的**
    **hashCode（hash值）进行一次与运算**，即可得到该hash值在散列表数组中的索引。其次通过在扩容方
    法中，经过hash值与低位掩码相与，可以保证扩容后，**只会移动少部分相与结果高位为1的桶链表**，其他
    保持不变，减少了扩容时的时间。
- **通过tableSizeFor（int）返回给定目标容量的2的幂次**，底层通过-1，右移1、2、4、8、16位，再+1得到目标容量。

#### 获取扩容标记方法

- **resizeStamp（int）**：
  - 获取容量n的扩容标记位，用于更新为sizeCtrl。
  - 等于容量n的高0位数值 | 1 << 15。高16为扩容标记，第16位为并发扩容线程数(从2开始, 步长+1)。结果肯定为负数。

#### 并发计数更新方法

在putVal和removeNode方法更新元素后，先并发叠加计数x，叠加成功后做扩容判断。其并发叠加计数x步骤为：

1. 先尝试在baseCount叠加x，如果叠加成功，则继续做扩容判断。
2. 如果baseCount叠加x失败，则根据当前线程哈希值h=ThreadLocalRandom.getProbe()，尝试在CounterCell[h * (n-1)]叠加x，如果叠加成功，则继续做扩容判断。
3. 如果CountCell叠加x失败，则调用fullAddCount 自旋+CAS 竞争添加到CounterCell[] as，其步骤为：
   - 如果as不为null，则判断CounterCell[h & (n-1)]是否为null：
     - 如果CounterCell[h & (n-1)]为null，则CAS竞争创建CounterCell[h & (n-1)]，竞争成功则叠加x结束自旋，竞争失败则继续自旋，如果创建前as繁忙（as正在初始化/扩容/叠加x），则标志为已冲突，获取新的线程哈希值h，继续自旋。
     - 如果CounterCell[h & (n-1)]不为null，则CAS竞争在CounterCell[h & (n-1)]上叠加x，竞争成功则结束自旋，竞争失败则获取新的线程哈希值h，继续自旋。
     - 否则，如果CounterCells数组引用发生变更或者长度超出CPU核心数，则也会标志为已冲突，获取新的线程哈希值h，继续自旋。
     - 否则，如果连续冲突2次，还没竞争叠加x成功，则扩容2倍CounterCells数组，扩容完毕后继续自旋。
   - 如果as为null或者为空，则CAS竞争初始化as = new CounterCell[2]，竞争成功则叠加x到as[h & 1]中，结束自旋。
   - 如果as竞争初始化失败，则叠加x到baseCount中，结束自旋。

#### 并发扩容方法

- 并发扩容时使用到的一些判断条件：

```java
// 第一个扩容线程时，CAS更新并发阈值sizeCtl，此时sc为rs <<< 16 + 2
U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)
    
// 其他协助转移线程加入结点转移工作时，CAS更新并发阈值sizeCtl，此时sc + 1
U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)
    
// 通过sizeCtl判断当前线程扩容是否为ConcurrentHashMap的同一次扩容
(sc >>> RESIZE_STAMP_SHIFT) == rs 

// 当前线程完成转移工作后，CAS更新并发阈值sizeCtl，此时sc-1
U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)
    
// 通过sizeCtl判断当前线程是否为最后一个提交转移工作的线程
(sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT
```

- 启动扩容前判断：如果sumCount（）> sizeCtl且 当前容量 < 最大容量，则说明需要扩容，扩容启动步骤为：
  1. resizeStamp（n）获取扩容标记rs，如果rs小于0，说明散列表正在被其他线程扩容，则CAS更新sizeCtrl=sc+1，更新成功后调用transfer(tab, nt)，加入扩容一起转移结点。
  2. 如果rs大于等于0，说明散列表还没被扩容，则CAS更新sizeCtrl=(rs << RESIZE_STAMP_SHIFT) + 2)，更新成功后调用transfer(tab, null)，开始扩容创建nextTab并转移结点。
  3. 要注意的是，在addCount（long，int）方法中，转移tab到nextTab完成返回后，还要继续判断nextTab是否需要扩容，如果nextTab也在扩容中，则加入扩容一起转移结点。
- transfer（Node[]，Node[]）：转移旧散列表tab中的结点到新散列表nextTab中，会在启动扩容、协助扩容处调用。其转移结点的步骤为：
  - 如果nextTab还没创建，则先创建nextTab。
  - 如果nextTab已创建，则转移线程步骤为：
    - 划分转移区间 -> i为转移结点 -> 继续前进划分转移区间，直到没有划分到散列表开头。
    - 划分转移区间 -> i为业务结点-> 锁桶头+转移普通链表/红黑树 -> 转移完成（会在桶处留下forwarding结点） -> 继续前进划分转移区间，直到没有划分到散列表开头。
    - 如果当前线程不为最后一个转移完成线程，即**(sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT**，则直接返回即可，无需提交新散列表nextTab。
    - 如果当前线程为最后一个转移完成线程，即**(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT**，则进行最后一次检查i与transferIndex（是否到散列表开头），没问题则提交新散列表nextTab（设置为table）。

#### put方法

3个常用的顶层API方法put、putIfAbsent、putAll，它们依赖于putVal方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果散列表为null或者n为0，则初始化容量为16的散列表，sizeCtl为12=16 * 0.75。
3. 否则，如果p桶为null，则直接new Node再CAS放到该桶即可。
4. 否则，如果p桶结点hash值-2，说明p为Forwardding结点，则当前线程加入扩容一起转移结点。
5. 否则，如果p不为Forwardding结点，则对桶头结点进行加synchronized锁，再判断桶头结点的哈希值：
   - 如果桶头结点的hash值大于等于0，说明它为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 如果找不到对应的结点，则在链尾new Node一个结点，并且添加后如果当前链表至少有8个结点，则调用**ConcurrentHashMap的实例方法treeBin**将当前桶链表树化为红黑树（treeBin还会判断散列表容量是否大于等于64）。
   - 否则，如果桶头结点的hash小于0即TreeBin结点，说明p为红黑树，则使用**TreeBin的实例方法putTreeVal**添加key：value。
6. 如果发生的不是值替换，则并发更新计数、判断是否需要扩容（要的话则发起扩容）。最后返回null，代表结点插入成功。

#### remove方法

2个常用的顶层API方法remove（Object）和remove（Object，Object），它们都依赖replaceNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果散列表为null或者n为0，则返回null，代表ConcurrentHashMap不存在对应的结点。
3. 如果桶p为null，则返回null，代表ConcurrentHashMap不存在对应的结点。
4. 否则，如果桶头结点hash值为-2，说明它为Forwardding结点，则当前线程加入扩容一起转移结点。
5. 否则，如果p不为Forwardding结点，则对桶头结点进行加synchronized锁，再判断桶头结点的哈希值：
   - 如果桶头结点的hash值大于等于0，说明它为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点（如果此时指定了value，则还需要判断value是否equals），则脱钩该结点。
   - 如果找不到，则返回null，代表ConcurrentHashMap不存在对应的结点。
   - 否则，如果桶头结点的hash小于0即TreeBin结点，说明p为红黑树，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点，调用**TreeNode的实例方法removeTreeNode**删除该结点。
6. 最后如果脱钩结点成功，则并发更新计数，返回旧值，代表删除成功。

#### get方法

2个常用的顶层API方法get、getOrDefault，getOrDefault依赖get方法，其中val和next使用volatile修饰，保证线程可见性，所以get方法可以不加锁地照常遍历，而读红黑树由于会涉及到旋转，所以有写时会走链表读，树读时不能写。其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶e。
2. 如果散列表为null或者n为0，则返回null，代表ConcurrentHashMap不存在对应的结点。
3. 如果桶e为null，则返回null，代表ConcurrentHashMap不存在对应的结点。
4. 如果e桶不为null，则分4种情况判断：
   - 如果桶头结点e的hash值相等且（key相等 或者 equals），说明e就是要找的结点，则直接返回e结点。
   - 否则，如果e的hash小于0，说明e可能为转发结点、红黑树结点、computeIfAbsent临时结点，则根据调用各自实现的find方法：
     - 如果e为转发结点，则根据hash以及key对象查找nextTable结点，找到hash相等，且Key
       相等或者equals的结点并返回。
     - 如果e为红黑树结点，则根据hash值和key值，从根结点开始查找红黑树结点 => 同
       HashMap#getTreeNode（int，Object）。
     - 如果e为computeIfAbsent临时结点，则返回null。
   - 否则，如果桶头没找e结点, 则继续遍历e链表, 找到hash值相等, 且Key相等或者equals结点并返回。
5. 最后如果实在找不到key对应的结点，则返回null，代表ConcurrentHashMap不存在对应的结点。

### 3.9. ConcurrentHashMap红黑树？

- 红黑树过程与HashMap类似，但不同的地方在于，TreeBin维护了一个读写锁（写时加锁），读红黑树由于会涉及到旋转，所以有写时会走链表读，树读时不能写。
- 对于TreeBin#putTreeVal或者TreeBin#removeTreeNode方法，即使外层有获取可重入锁synchronized，在操作红黑树之前，也要调用lockRoot()，调用完成后再unlockRoot()。其原理如下：

1. TreeBin持有lockState读写锁状态（WRITER=1，WAITER=2，READER=4，读/写状态可与等待状态结合），以及waiter等待写锁线程。
2. 调用lockRoot时，首先CAS竞争更新lockState为【WRITER】，竞争成功则说明当前线程持有写锁成功，可以继续做红黑树操作，操作完后unlockRoot释放写锁，置lockState为0。
3. 竞争失败，则调用contendedLock继续**争抢写锁**，争抢不到写锁的会进入阻塞状态，直到所有调用TreeBin#find（int，Object）的线程调用完毕后才会被唤醒，然后重新争抢写锁。
   - 如果当前红黑树不存在写或者读线程【((s = lockState) & ~WAITER) == 0】，则当前线程去竞争写锁，如果竞争成功则返回，否则继续自旋。
   - 否则，如果还不存在等待写锁的线程【(s & WAITER) == 0】，则当前线程去竞争成为等待写锁的线程，竞争成功则成为等待写锁的线程，否则继续自旋。
   - 否则，说明当前线程为等待锁的线程，但竞争写锁还是失败，则进入阻塞状态。而那些争抢不到写锁, 也进入不了阻塞状态成为等待写锁的线程，会一直自旋等待锁状态变更。
4. TreeBin#find（int，Object）**更新读锁状态**：
   - 如果当前红黑树存在写线程或者等待写锁线程【((s = lockState) & (WAITER|WRITER)) != 0】, 为了减少锁竞争以便写操作尽快完成，则以遍历链表的方式去遍历出红黑树结点并返回。
   - 否则，说明当前红黑树没有写线程或者等待写锁线程，则CAS叠加lockState读锁状态（每个读线程叠加一次【READER】）， 然后再以红黑树方式去遍历红黑树结点并返回。

### 4.0. JDK1.7 ConcurrentHashMap与JDK1.8 ConcurrentHashMap的区别？

JDK1.8 主要优化了以下内容：

- 取消Segment[]+HashEntry[]+链表的数据结构，改用Node[]+链表+红黑树的数据结构，提升查找效率。
- 取消了hashSeed参与HashCode扰动。
- 取消了Segment+HashEntry+ReentrantLock分段锁，改用Node+CAS自旋锁+synchronized+TreeBin读写锁来保证并发安全，其中synchronized只锁定桶结点，红黑树读写锁使并发读性能得到提升。
- 取消了concurrencyLevel作为Segment[]长度，JDK 1.8 ConcurrentHashMap的concurrencyLevel为了兼容JDK1.7 ConcurrentHashMap，实际意义不大（第一不为负数就好，第二在initialCapacity < concurrencyLevel时赋值initialCapacity 为concurrencyLevel）。
- 取消了获取可重入锁后添加结点+计数+扩容的方式，改用添加结点后，释放synchronized+CAS自旋锁+并发计数+并发扩容方式提高并发量。

|                  | JDK1.7 HashMap                                        | JDK1.8 HashMap                                               |
| ---------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 数据结构         | 数组 + 链表                                           | 数组 + 链表 + 红黑树                                         |
| HashCode扰动函数 | 16次扰动（7次移位，4次相加，5次异或），有哈希种子影响 | 2次扰动（1次移位，1次异或），无哈希种子                      |
| 并发安全原理     | Segment+HashEntry+ReentrantLock分段锁                 | Node+CAS自旋锁+synchronized+TreeBin读写锁                    |
| 构造方法         | concurrencyLevel作为Segment[]长度                     | concurrencyLevel为了兼容JDK1.7 ConcurrentHashMap，实际意义不大 |
| 扩容方法         | 获取可重入锁后，添加结点+计数+扩容                    | 添加结点后，释放synchronized+CAS自旋锁+并发计数+并发扩容     |

# 二、JVM篇 

### 1.1. JDK、JRE、JVM的区别？

![1625884268478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625884268478.png)

从图中可以看出，**JDK包含了JRE，而JRE又包含了JVM**。

- **JDK**，Java Development Kit，是Java的软件开发工具包（SDK），包含JRE和Java工具。
- **JRE**，Java Runtime Environment，是Java的运行时环境，大部分都是C和C++语言编写的，可以在其上运行、测试应用程序的Java平台，包括JVM和Java核心类库。
- **JVM**，Java Virtual Machine，Java虚拟机，是一种用于计算设备的规范，是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的，屏蔽了与具体平台相关的信息，使得Java语言编译程序只需要在Java虚拟机上运行的字节码，就可以不加修改地在多种平台上运行。

### 1.2.  JVM整体架构？

![1625963806257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625963806257.png)

- JVM包含**2个子系统和2个组件**：2个子系统分别为Class Loader（类加载子系统）、Execution Engine（执行引擎）；2个组件分为别Runtime data area（运行时数据区）、Native Interface（本地接口）。
  - **Class loader（类加载子系统）**：根据给定的全限定名类名（如java.lang.Object）来装载class文件到Runtime data area中的Method Area（方法区）。
  - **Runtime data area（运行时数据区域）**：这就是我们常说的JVM的内存。
  - **Execution engine（执行引擎）**：执行class文件中的指令。
  - **Native Interface（本地接口）**：与native libraries交互，是其它编程语言交互的接口。
- 架构整体流程：

1. 通过编译器把 Java 代码转换成字节码，**类加载器（ClassLoader）**再把字节码加载到内存中，将其放在**运行时数据区（Runtime data area）**的方法区内。
2. 而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器**执行引擎（Execution Engine）**，将字节码翻译成底层系统指令，再交由 CPU 去执行。
3. 而这个过程中需要调用其他语言的**本地接口（Native Interface）**来实现整个程序的功能。

### 1.3. 详细介绍类加载机制？

![1625975271139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625975271139.png)

程序主动使用某个类时，如果这个类还未被加载到内存中，则JVM会通过**加载、链接、初始化**3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时也把这个3个步骤统称为**类加载或类初始化**。

1. **加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。
   - 加载过程需要**类加载器**参与。类加载器，可以从不同来源加载类的二进制数据，比如：本地Class文件、Jar包Class文件、网络Class文件等等。
   - Java类加载器由JVM提供，是所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。
   - 除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。
   - Java的类加载是动态的，不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类完全加载到JVM中。至于其他类，则**在需要的时候才加载**（为了节省内存开销）。
     - **隐式加载**：程序在运行过程中，当碰到通过new 方式生成对象时，将会隐式调用类装载器，加载对应的类到JVM中。
     - **显式加载**：通过class.forname（）反射方法，显式加载需要的类。
2. **链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：
   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
     - 文件验证：是否以0xCAFEBABE开头、版本号是否合理等。
     - 元数据验证：是否有父类、是否继承了final类、非抽象类是否实现了所有抽象方法等。
     - 字节码验证：运行检查、栈数据类型和操作码的操作参数是否吻合（不能大于栈空间）、跳转指令是否指向合理的位置。
     - 符号引用验证：常量池中描述的类是否存在、访问的方法或字段是否存在且有足够的权限。
     - 可使用**-Xverify:none**关闭验证：比如提高IDEA的启动速度。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。
   - 实际上，JVM不一定完全按照类加载机制顺序执行，比如解析操作有可能会发生在初始化操作之后。
3. **初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。
   - 执行< clinit >方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。
     - 初始化的顺序和源文件中的顺序一致。
     - 子类的< clinit >被调用前，会先调用父类的< clinit >。
     - JVM会保证clinit方法的线程安全性。
   - 即执行顺序为：JVMTest5静态块 -> super静态块 -> Sub静态块 -> Super构造块 -> Super构造方法 -> Sub构造块 -> Sub构造方法。
     - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
     - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
     - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

```java
// JVMTest5不用被实例化，所以不会调用JVMTest5的构造块和构造方法
public class JVMTest5 {
    static {
        System.out.println("JVMTest5静态块");
    }

    {
        System.out.println("JVMTest5构造块");
    }

    public JVMTest5() {
        System.out.println("JVMTest5构造方法");
    }

    public static void main(String[] args) {
        new Sub();
    }
}

class Super {
    static {
        System.out.println("Super静态块");
    }

    public Super() {
        System.out.println("Super构造方法");
    }

    {
        System.out.println("Super构造块");
    }
}

class Sub extends Super {
    static {
        System.out.println("Sub静态块");
    }

    public Sub() {
        System.out.println("Sub构造方法");
    }

    {
        System.out.println("Sub构造块");
    }
}
```

### 1.4. 什么是类加载器？类加载器有哪些？

![1625986988156](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625986988156.png)

**类加载器**，是能够实现通过类的全限定名，获取该类的二进制字节流的**代码块**。JVM提供了3种类加载器，启动类加载器、扩展类加载器、系统类加载器（也叫应用类加载器），以及用户自定义的类加载器（其父类为应用类加载器）。

- **启动类加载器**：Bootstrap ClassLoader，该类加载使用C++实现，其引用为null，无法被java程序直接引用。用于加载Java核心类库，即负责把**/lib**目录下或者**-Xbootclasspath**参数指定路径下的Jar包加载到内存中。
  - 注意，JVM是按照文件名识别加载Jar包，如rt.jar，如果文件名不被虚拟机识别，即使把Jar包丢到lib目录下也是没有作用的。
  - 处于安全考虑，启动类加载器只能加载包名为java、javax、sun等开头的类。
- **扩展类加载器**：ExtClassLoader，由Java实现，父类加载器为启动类加载器（持有为null的parent引用，并不是真正的继承关系）。用于加载 Java 的扩展库，即负责把**/lib/ext**目录下或者**-Djava.ext.dir**参数指定路径下的类库加载到内存中。
  - 开发者可以直接使用标准的扩展类加载器。
- **系统类加载器**：AppClassLoader，也叫应用类加载器，由Java实现，父类加载器为ExtClassLoader（持有ExtClassLoader的parent引用，并不是真正的继承关系）。用于加载一般的Java 应用类，即负责把**java -classpath**或者**-D java.class.path**指定路径下的类库加载到内存中。
  - 一般情况下，系统类加载器是程序中默认的类加载器。
  - 开发者可以直接使用应用类加载器，可以通过**ClassLoader.getSystemClassLoader（）**来获取。
- **用户自定义的类加载器**：用户可以通过继承 java.lang.ClassLoader类的方式，来自定义自己的加载器。
  - 应用场景：
    - 加密编译后的class字节码 ->  自定义ClassLoader -> 加载该class时解密字节码。
    - 自定义ClassLoader，加载时从非标准来源加载字节码：比如数据库、网络上。

### 1.5. 什么是双亲委派机制？

#### 概念

加载器之间存在着"父子关系"（区别于Java里的继承），子加载器保存着父加载器的引用。

1. 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回。
2. 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到，则解析或者返回。
3. 如果找不到，才会交还子加载器加载目标类，查找逻辑交由子加载器实现。

#### 实现原理

- **java.lang.ClassLoader**：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法。
- **loadClass（String，boolean）**：类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找。
- **findClass（String）**：加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用**defineClass（String，Resource）**方法生成Class对象。
- **resolveClass（Class<?>）**： 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值。
- **defineClass（String，Resource）**：在Java堆区生成Class对象。

```java
// java.lang.ClassLoader#loadClass：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法
public abstract class ClassLoader {
    
    // 类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            // 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回
            Class<?> c = findLoadedClass(name);// native方法
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    // 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到则解析或者返回
                    if (parent != null) {
                        c = parent.loadClass(name, false);
                    } 
                    // 交由启动类加载器加载
                    else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }

            // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
            if (resolve) {
                resolveClass(c);
            }

            // 返回class
            return c;
        }
    }
    protected final Class<?> findLoadedClass(String name) {
        if (!checkName(name))
            return null;
        return findLoadedClass0(name);
    }
    private native final Class<?> findLoadedClass0(String name);
    
    // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
    private native void resolveClass0(Class<?> c);

    // 加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用defineClass(String，Resource)方法生成Class对象
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
}
```

#### 双亲委派模型好处

- 此机制保证了Java核心类库被优先加载，避免了用户编写的类动态替换Java核心类的错误，使得Java程序能够稳定运⾏。
- 同时也避免了类的重复加载，使用双亲委派模型，JVM能够根据**类的完整类名+ClassLoader实例对象**来区分不同的类。如果不使⽤双亲委派模型，⽽是每个类加载器⾃⼰加载的话，会出现⼀些问题。⽐如编写⼀个称为 java.lang.Object 类的话，在程序运⾏的时候，系统会有多个不同的Object 类，此时会出现Object类的选择问题。

#### 双亲委派模型局限

1. SPI接口，Service Provider Interface，允许第三方为其提供实现，如JDBC、JNDI等 。
2. SPI接口属于Java核心类库，由启动类加载器加载（rt.jar），而SPI的第三方代码则是作为Java应用所依赖的Jar中（Classpath下）。
3. 其中SPI接口中的代码经常需要加载具体的第三方实现类，并调用其相关方法，此时由于双亲委派模型的存在，启动类加载器无法直接加载SPI实现类，也无法反向委托给系统类加载器加载，从而让JDK SPI机制产生了问题。

#### 打破双亲委派模型

如果不想打破双亲委派模型，则只需要重写findClass方法即可；如果想打破双亲委派模型，则需要重写整个loadClass方法。

##### 线程上下文类加载器

- **背景**：由于双亲委派模型存在SPI局限，需要一种特殊的类加载器来加载第三方类库，此时线程上下文加载器是个很好的选择。
- **线程上线文类加载器**：是从JDK 1.2开始引入的，可以通过java.lang.Thread#getContextClassLoader（）和setContextClassLoader（ClassLoader）方法来获取和设置线程的上下文类加载器。如果没有手动设置，则线程将会继承父线程的上下文类加载器，默认为系统类加载器，即在线程中运行的代码可以通过此类来加载Classpath下的类和资源。
- **打破双亲委派**：从图中可以看到，启动类加载器委派线程上下文加载器，把jdbc.jar中的实现类加载到内存中以便SPI相关类使用，因此打破了双亲委派模型，使得Java类加载更加灵活。

![1625996283343](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625996283343.png)

- **实现原理**：
  - contextClassLoader是在ClassLoader.SystemClassLoaderAction#run（）方法进行了赋值，其中构造了**java.system.class.loader**加载器实例（实际上为AppClassLoader？），并持有当前加载器的parent作为其父加载器。
  - 接着，ClassLoader.SystemClassLoaderAction#run（）方法通过Thread#setContextClassLoader（ClassLoader）设置到当前线程的实例变量中，从而使得当前Thread实例持有contextClassLoader的引用。
  - 最后，java.sql.DriverManager在调用sevice.loader（Driver.class）时，jdbc.jar中在META-INF/sevice/java.sql.Driver配置的**com.mysql.cj.jdbc.Driver**，就会在java.util.ServiceLoader#load（Class）方法调用Thread.currentThread().getContextClassLoader()时进行类加载，从而达到SPI的目的。
  - 可以看出虽然java.util.ServiceLoader是rt.jat包的核心类库，由启动类加载器加载，但通过Thread.currentThread().getContextClassLoader()确实加载到了第三方包下的com.mysql.cj.jdbc.Driver，因此线程上下文类加载器可以打破双亲委派模型。

```java
// java.sql.DriverManager，启动类加载器加载
public class DriverManager {
 	static {
        loadInitialDrivers();
        println("JDBC DriverManager initialized");
    }
    
    private static void loadInitialDrivers() {
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                // SPI加载
                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
                Iterator<Driver> driversIterator = loadedDrivers.iterator();
            }
            ...
        }
    }      
}    


// java.util.ServiceLoader，启动类加载器加载
public final class ServiceLoader<S>implements Iterable<S> {  
    // SPI加载: 获取当前线程上下文类加载器进行SPI加载，从而打破了双亲委派模型
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    ...
}
```

##### Tomcat类加载机制

- **背景**：
  - a. 一个web容器可能要部署两个或者多个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，因此要保证每一个应用程序的类库都是**独立、相互隔离**的。
  - b. 同一个web容器中的**相同类库的相同版本**可以共享，否则会有**重复的类被加载进JVM**。
  - c. **web容器也有自己的类库**，不能和应用程序的类库混淆，基于安全考虑，需要相互隔离。
  - d. Jsp文件也是要编译成class文件的，web容器需要支持在**Jsp**文件修改后，可以实现**HostSwap（热替换）**的功能。

![1626065847576](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626065847576.png)

- **类加载器逻辑关系**：

  Common、Catalina、Shared类加载器（本质上是URLClassLoader）分别加载/common/、/server/、/shared/路径下的Class，但在Tomcat6后已经统一合并到了/lib目录下了。

  - **CommonClassLoader**：Tomcat最基本的类加载器，加载对应路径中的Class，可**以被Tomcat容器本身以及各个webapp访问**。
  - **CatalinaClassLoader**：Tomcat容器私有的类加载器，加载对应路径中的class，**对于webapp不可见**。
  - **SharedClassLoader**：各个webapp共享的类加载器，加载对应路径中的class，**对于所有webapp可见，但对于Tomcat容器不可见**。
  - **WebappClassLoader**：各个webapp私有的类加载器，每一个webapp对应一个WebAppClassLoader实例，加载路径中的class，**只对当前webapp可见**。
  - **JasperClassLoader**：
    - 每一个Jsp文件对应一个JasperClassLoader实例，**加载范围仅仅是这个Jsp文件所编译出来的那一个Class文件**。
    - JasperClassLoad出现的目的就是为了被丢弃，当Web容器检测到Jsp文件被修改时，会替换掉目前的JasperClassLoader实例，并通过重新建立一个新的JasperClassLoader实例来实现JSP文件的HostSwap（热替换）功能。

![1626066067882](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626066067882.png)

![1626090586657](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090586657.png)

- **类加载流程**：WebappClassLoaderBase#loadClass(String, boolean)流程：

1. 先查找Tomcat缓存，如果找得到，则返回Tomcat缓存中的Class对象。
2. 如果Tomcat缓存中找不到，则查找JVM缓存，如果找得到，则返回JVM缓存中的Class对象。
3. 如果JVM缓存中也找不到，则用扩展类加载器来加载（**重点！这里并没有首先使用系统类加载器，而是直接使用了扩展类加载器来加载，也就是打破了系统类加载器的双亲委派机制**），根据双亲委派机制，扩展类加载器会委派启动类加载器来加载Class，从而保证了JRE核心类库不会被重复加载。
4. 如果指定了delegateLoad（需要先委托父类加载），则**先调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保持顺序加载机制），如果找不到**才调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），找到则返回，找不到则抛出ClassNotFoundException异常。
5. 如果没有指定delegateLoad（需要先委托父类加载），则**先调用调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），如果找不到**才调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保底机制），找到则返回，找不到则抛出ClassNotFoundException异常。

![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

- **总结**：可以看到，Tomcat#WebappClassLoaderBase的类加载机制是**打破了双亲委派模型**的：
  - **ext -> bootstarp模型**：保证了JRE核心类库不会被重复加载，满足了背景b加载JVM共同类库的需求。
  - **ext -> webapp模型**：实现了每个web应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离，满足了背景a的需求。
  - **webapp -> share -> common模型**：实现了所有web应用之间、web与Tomcat之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了背景b加载其他共同类库的需求。
  - **（不确定）catalina -> 父类加载器模型**：实现了只加载Tomcat容器自身的类库，对于webapp是看不到的（可在config/catalina.properties的server.loader中配置jar和class的路径），满足了背景c的需求。
  - **（不确定）Jsp -> webapp -> 父类加载器模型**：通过在jsp修改后卸载再生成新的Jsp类加载器，重新加载新生成的Jsp class，从而实现Jsp的HostSwap（热替换），满足了背景d的需求。

### 1.6. JVM运行时数据区？

![1626181528728](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181528728.png)

JVM在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。

这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着JVM进程的启动而存在（**线程共享**），有些区域则是依赖线程的启动和结束而建立和销毁（**非线程共享**）。

JVM所管理的内存被划分为如下几个区域：

- **程序计数器**：Program Counter Register，非线程共享，JVM当前线程所执行的**字节码的行号指示器**，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。
- **虚拟机栈**：Java Virtual Machine Stacks，非线程共享，每个方法在执行的同时都会在Java 虚拟机栈中创建一个栈帧（Stack Frame），用于存储**局部变量表、操作数栈、动态链接和方法返回地址**；
- **本地方法栈**：Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。

### 1.7. 详细介绍程序计数器？

- **概念**：程序计数器，Program Counter Register，非线程共享，JVM当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。

- **出现的原因**：由于JVM多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，需要**记住原线程的下一条指令的位置**，所以每条线程都要有一个独立存储、互不影响的程序计数器，称之为“**线程私有**”的内存。

- **例子**：

  1. 比如线程A在看直播。
  2. 突然，线程B来了一个视频电话，就会抢夺线程A的时间片，就会打断了线程A，线程A就会挂起。
  3. 然后，视频电话结束，如果没有线程计数器，此时线程A就不知道要干什么了；如果有线程计数器，此时线程A就可以想起来要去看直播了。

  => 线程是最小的执行单位，不具备“记忆”功能，只负责去干，这就需要**由程序计数器来为线程提供保护和恢复现场**的功能。

### 1.8. 详细介绍虚拟机栈？

![1626137840755](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626137840755.png)

Java虚拟机栈**是线程私有的（非线程共享）**，每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致。单位是**栈帧**，在每个方法执行的时候，都会创建一个栈帧，在被调用直至执行完毕的过程，对应一个栈帧在虚拟机栈中**从入栈到出栈**的过程。

每个栈帧都存放着**局部变量表、操作数栈、动态链接和方法返回地址**。

> 在JVM规范中，对此区域规定了两种异常状况：在固定情况下，如果线程请求的栈深度大于虚拟机所允许的最大栈深度，则会抛出**StackOverflowError**异常；在可动态扩展情况下，如果虚拟机栈无法申请到足够的内存，或者在创建新线程的时候没有足够的内存去创建对应的虚拟机栈，则会抛出**OutOfMemoryError**异常。

在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

- **局部变量表**：

  - 是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。
  - 存放了编译期可知的各种**基本数据类型**（boolean、byte、char、short、int、float、long、double，对包装类型在栈中保存地址、在堆中保存值）、**对象引用**（Reference类型，可能是一个指向对象起始地址的引用指针，也可能是一个代表对象的句柄或者其他与对象相关的位置）和**returnAddress类型**（指向下一条字节码指令的地址）。
  - 局部变量表所需的内存空间在编译期间完成分配，方法在运行之前，该局部变量表所需要的内存空间是固定的，运行期间不会发生改变。

- **操作数栈**：

  - 用于保存计算过程中的**中间结果**，同时作为计算过程中变量临时的存储空间。
  - 操作数栈在方法的执行过程中，根据字节码指令往操作数栈中写入数据或提取数据，即入栈和出栈操作。
  - 比如add（）方法执行过程中，其操作数栈与局部变量表的交互顺序为：15入栈（操作数栈写入数据） -> 15出栈（操作数栈提取数据到局部变量表） -> 1入栈（操作数栈写入数据） -> 1出栈（操作数栈提取数据到局部变量表） -> 15入栈（加载局部变量表变量15） -> 1入栈（加载局部变量表变量1） -> iadd（执行相加15 + 1指令） -> 16出栈（操作数栈提取结果到局部变量表）-> return（如果返回值为void，则当前栈帧出栈即可，如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中）。

  ```java
  public class Test {
      public void add() {
          int a = 15;
          int b = 1;
          int c = a + b;
      }
  }
  ```

- **动态链接**：

  - 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接（Dynamic Linking）。
  - Class 文件的常量池中存在大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数，这些符号引用一部分会在类加载阶段或**第一次使用时转化为直接引用，这种转化成为静态解析**。另一部分将在**每一次运行期间转化为直接引用，这部分称为动态连接**。

- **方法返回地址**：returnAddress类型（**指向下一条字节码指令的地址**）:

  - 当一个方法开始执行后，只有两种方式可以退出这个方法。一种是执行引擎遇到**任意一个方法返回的字节码指令**，这时候可能会有返回值传递给上层方法的调用者，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为**正常完成出口**。
  - 另一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是 Java 虚拟机内部产生的异常，还是代码中使用 athrow 字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种称为**异常完成出口**。一个方法使用异常完成出口的方式退出，是不会给上层调用者产生任何返回值的。
  - 无论采用何种退出方式，在方法退出后都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来恢复它的上层方法的执行状态。一般来说，方法正常退出时，**调用者的PC计数器的值可以作为返回地址**，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。
  - 方法退出的过程实际上就等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上次方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，**调整PC计数器的值以指向方法调用指令后面的一条指令等**。

- 附加信息：虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如与调试相关的信息，这部分信息完全取决于具体的虚拟机实现。实际开发中，一般会把动态连接、方法返回地址与其他附加信息全部归为一类，成为栈帧信息。

### 1.9. 详细介绍本地方法栈？

- 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- Native方法是看不到的，必须要去oracle官网去下载才可以看的到，而且native关键字修饰的大部分源码都是C和C++的代码。
- 在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，因此同样会抛StackOverflowError异常，以及OutOfMemoryError异常。
  - 在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

### 2.0. 详细介绍堆？

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
  - 非栈上分配情况下，**创建的对象会存储在堆内存中，在栈上存储该对象的引用**（栈空间只包含方法基础数据类型的局部变量以及引用堆对象的引用变量）。
  - ClassA a = new ClassA（）；此时a叫实例，不能说a对象，**实例在栈上，对象在堆中**，操作实例实际上是通过实例指针间接操作对象，多个实例可以指向同一个对象。
  - 栈中的数据和堆中的数据销毁并不是同步的，方法一旦结束，**栈中的局部变量会立即销毁**；堆中的对象不一定会销毁，因为可能有其他变量也指向了该对象，直到没有变量指向该对象，才有可能会被垃圾回收。
  - 类的成员变量在对象中，每个对象都有自己成员变量的存储空间；而**类的方法只有一套**，存储在方法区中，被该类的所有对象共享，对象在使用方法的时候才会将方法压入栈中，而**方法在不使用时并不会占用内存**。
- 对象在堆中分配好以后，会在栈中保存一个4字节的实例（指向对象堆内存地址），用来定位对应的对象在堆中的位置，便于找到该对象。但在开启逃逸分析后，某些未逃逸的对象也可以通过标量替换的方式在**栈上分配**。
- 堆是垃圾回收（GC）的主要场所，从内存回收角度来看，可以分为**新生代和老年代，默认内存大小比值为1：2**，对于新生代又可以分为**Eden区（伊甸园）、Survivor区（存活区），默认内存大小比值默认为8：2**，而Survivor区又分为**Surviver0（From Survivor）和Survivor1（To Survivor），默认内存大小比值默认为1：1**。
- **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **优点 - 加速对象分配**：
    - 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM底层采用CAS + 失败重试的方式来做同步处理，如果多线程竞争非常激烈，那么此时在堆中分配对象性能是非常差的。因此，JVM设计了TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **缺点 - 大对象无法分配**：TLAB空间比较小，所以大对象无法在TLAB分配，这时只能直接分配到线程共享的堆里面。
- 堆可以处于物理上不连续的内存空间中，可通过 -Xmx（最大堆内存）和 -Xms（初始堆内存） 来扩展空间大小。如果堆中没有内存可以完成对象分配，且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

### 2.1. 详细介绍方法区？

![1626181213768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181213768.png)

- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - **永久代**：是Hotspot虚拟机特有的概念（在别的JVM没有），是方法区的一种实现，主要存放类信息、常量等方法区内容。
    - 在JDK1.6 中，方法区中包含的数据，除了JIT编译生成的代码是存放在native memory的CodeCache区域，其他都存放在永久代。
    - 移除永久代的工作从JDK1.7就开始了，在JDK1.7中，存储在永久代的部分数据就已经转移到了Java Heap或者是Native Heap。但永久代仍存在于JDK1.7中，并没完全移除，比如**符号引用**（Symbols）转移到了native heap，**字面量**（interned strings，见字符串常量池）转移到了java heap，**类的静态变量**（class statics）转移到了java heap。
    - 在Java 8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存：元空间（Metaspace）中，此时‑XX：MaxPermSize 参数失去了意义，取而代之的是-XX：MaxMetaspaceSize。
  - **元空间**：JDK8后用于替代永久代，存储类的元数据信息，存放在本地内存中。
    - **元空间与永久代最大的区别**：元空间并不是在JVM虚拟机中 ，而是使用了本地内存，默认情况下，元空间的大小仅受本地内存限制，解决了永久代容易溢出的问题。
  - **元空间替代永久代的原因**：
    - 字符串存在永久代中，容易出现性能问题和内存溢出。
    - 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则会导致空间的浪费。
    - JRockit虚拟机方法区没有永久代的实现，Oracle需要将HotSpot与JRockit合二为一 ，剔除永久代。
    - （？）永久代会为GC带来不必要的复杂度，并且回收效率偏低。
- 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。
  - **常量池 - 静态常量池**：也叫class文件常量池，即class文件中的常量池，占用class文件绝大部分空间。主要存放：
    - **字面量**：相当于Java语言层面常量的概念，如文本字符串、final修饰的变量。
    - **符号引用**：属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
  - **常量池 - 运行时常量池**：当class文件加载到内存后，JVM会将静态常量池中的内容存放到运行时常量池中，这就是常说的“常量池”，主要存放：
    - 编译期间产生的字面量、符号引用。
    - 注意，运行时常量池具有动态性，也就是并非只有通过class文件常量池才能进入，运行期间也可能将新的常量放入池中，比如调用String#intern（）方法。
  - **常量池 - 字符串常量池**：可以理解为运行时常量池中分出来的一部分，当类加载到内存时，**字符串**会存到字符串常量池里面，即在编译阶段把所有字符串放到一个常量池中。
    - String#intern（）方法，native方法，返回规范的字符串，equals判断常量池是否有存在的字符串，如果没有则会将实参字符串加入常量池。
    - 程序运行时，除非手动向常量池中添加常量，比如调用String#intern（）方法，否则JVM不会自动添加常量到常量池。
    - 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量则会加入常量池；如果是变量，由于地址不能确定，所以在不调用String#intern（）时是并不会加入常量池的。
    - JDK5以后，除了有字符串常量池，实际上还有数值型常量池，也就是Java中大部分基本类型的包装类都实现了常量池技术，比如Byte、Short、Integer、Long、Character、Boolean，而两种浮点数类型的包装类Float、Double并没有实现常量池技术。其中，只有Integer常量池缓存区间（-128~127），可通过-XX:AutoBoxCacheMax参数进行设置。
  - **常量池的好处**：
    - 常量池是为了避免频繁的创建和销毁对象而影响系统性能，实现了对象的共享。
    - 常量池可以节省内存空间：常量池中所有相同的字符串常量被合并，只占用一个空间。
    - 常量池可以节省运行时间：在比较字符串时，==比equals（）快，所以对于两个引用变量，只用==判断引用是否相等，就可以判断实际值是否相等了。
- 垃圾回收在方法区出现得比较少，这个区域回收的目的主要是针对**常量池的回收和类的卸载**。
- 方法区也是可以由内存不连续的内存区域组成，也是可扩展的，当方法区无法满足内存分配需求时，则会抛出OutOfMemoryError异常。

### 2.2. 堆和虚拟机栈的区别？

|              | 堆                                                           | 虚拟机栈                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 物理地址     | 堆的物理地址是不连续的，因此分配对象的速度较慢               | 虚拟机栈使用的是栈数据结构，物理地址是连续的，因此分配对象的速度较快 |
| 内存大小     | 由于堆是不连续的，所以分配到的内存是在运行期才确定的，因此大小不固定，一般堆大小远远大于虚拟机栈 | 虚拟机栈是连续的，所以分配到的内存大小在编译期就已经确定好了，因此大小是固定的 |
| 存放内容     | 堆存放的是对象的实例和数组，所以更关注的是数据的存储         | 虚拟机栈存放的是局部变量、操作数栈、动态链接和方法返回地址，所以更关注的是程序方法的执行 |
| 程序的可见性 | 堆是线程共享的                                               | 栈是线程私有的，只对于线程是可见                             |
| 生命周期     | 堆的生命周期与JVM的生命周期相等                              | 虚拟机栈的生命周期与所在线程的生命周期相等                   |

### 2.3. 详细介绍直接内存？

- **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，是利用本地方法库直接在堆外申请的内存区域，这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。

- 直接内存（堆外内存）的使用，**避免了在I/O操作时Java堆和Native堆中来回复制数据**，从而提高性能。

  - 在JVM层面，每当程序需要执行一个I/O操作时，都需要将数据先从**Java Heap**复制到**C Heap**中，才能够触发系统调用完成操作。
  - 其中，C Heap内存站在JVM角度来看，属于堆外内存，但是站在操作系统的角度来看，其实都属于进程的Heap，**操作系统并不知道JVM的存在**，所以认为都是普通的用户程序。因此，JVM在I/O时永远比使用Native方法多一次数据复制。
  - **为什么必须有这一次的数据复制呢**？
    - 这是因为JVM只是一个用户程序，本身并没有直接访问硬件的能力，所有的I/O操作都需要借助于系统调用来实现。在Linux系统中，与I/O相关的read（）和write（）系统调用，都需要传入一个指向在程序中分配的一片内存区域的起始地址指针，然后操作系统才会将数据填入到这片区域或者从这片区域中读出数据。
    - 如果直接使用JVM堆中对应byte[]类型的地址的话，则会有两个无法解决的问题：一是，**Java中的对象实际的内存布局跟C不一样**，不同的JVM可能有不同的实现，byte[]的首地址可能只是个对象头，并不是真实的数据；二是，**垃圾收集器的存在使得JVM会经常移动对象的位置**，这样同一个对象的真实内存地址随时都有可能发生变化，而虽然JVM知道对象地址变了，但是操作系统并不知道。
  - 因此，在适当的位置直接使用直接内存，可以避免数据从JVM Heap到C Heap的拷贝。

- **API上**：可以使用**Unsafe**类或者**ByteBuffer**类分配直接内存：

  - **Unsafe**：Unsafe.allocateMemory（size）：
    - Unsafe可用来直接访问系统内存资源并自主管理，在提升Java运行效率、增强Java语言底层操作能力方面起了很大的作用。
    - 可以认为，**Unsafe类是Java中留下的后门**，提供了一些底层的操作，比如直接访问内存、线程调度等。
    - Unsafe不属于Java标准，官方并不建议使用Unsafe，并且从JDK 9开始去Unsafe，然而目前业界有很多好用的类库大量用了Unsafe类，比如JUC atomic包下的类、Netty、Hadoop、Kafka等，所以了解一下还是有好处的。
    - 不同JDK版本中，Unsafe类有区别：在JDK 8中归属于sun.misc包下；在JDK 11中归属于sun.misc包下与jdk.internal.misc下（这个功能更强大）。

  ```java
  public class DirectMemoryTest1 {
      private static final int MB_1 = 1024 * 1024;
  
      public static void main(String[] args) throws IllegalAccessException, NoSuchFieldException {
          //通过反射获取Unsafe类并通过其分配直接内存
          Field unsafeField = Unsafe.class.getDeclaredFields()[0];
          unsafeField.setAccessible(true);
          Unsafe unsafe = (Unsafe) unsafeField.get(null);
  
          // 分配1M内存，并返回这块内存的起始地址
          long address = unsafe.allocateMemory(MB_1);
  
          // 向内存地址中设置对象
          unsafe.putByte(address, (byte) 1);
  
          // 从内存中获取对象
          byte aByte = unsafe.getByte(address);
          System.out.println(aByte);
  
          // 释放内存
          unsafe.freeMemory(address);
      }
  }
  ```

  - **ByteBuffer**：ByteBuffer.allocateDirect（size）：

  ```java
  public class DirectMemoryTest2 {
      private static final int ONE_MB = 1024 * 1024;
  
      public static void main(String[] args) {
          // 底层使用unsafe分配内存，unsafe.freeMemory(address)释放内存
          ByteBuffer buffer = ByteBuffer.allocateDirect(ONE_MB);
          
          // 相对写，向position的位置写入一个byte，并将postion+1，为下次读写作准备
          buffer.put("abcde".getBytes());
          buffer.put("fghij".getBytes());
  
          // 转换为读取模式
          buffer.flip();
  
          // 相对读，从position位置读取一个byte，并将position+1，为下次读写作准备
          // 读取第1个字节(a)
          System.out.println((char) buffer.get());
  
          // 读取第2个字节
          System.out.println((char) buffer.get());
  
          // 绝对读，读取byteBuffer底层的bytes中下标为index的byte，不改变position
          // 读取第3个字节
          System.out.println((char) buffer.get(2));
      }
  }
  ```

- **JVM参数上**：可以使用-XX：MaxDirectMemorySize控制，默认是0，表示不控制。

- **优点**：

  - **减少了垃圾回收的工作**：因为直接内存是由操作系统直接管理的内存，分配到直接内存的对象不受JVM管理，也就不用JVM对其进行垃圾回收了。
  - **I/O效率高**：由于I/O操作中，使用直接内存可以减少一次Java Heap与C Heap之间的内存拷贝，从而提高了性能。

- **缺点**：

  - **直接内存难以控制**：直接内存不受JVM管理，需要用户自己来释放内存，当发生内存溢出时排查问题可能会变得非常困难。

- **适用场景**：

  - **需要存储的数据大且生命周期长**。
  - **频繁的I/O操作**，比如并发网络通信。

### 2.4. JVM执行引擎？

- JVM核心的组件就是**执行引擎**，负责执行虚拟机的字节码，一般会先编译成机器码后执行。
- “虚拟机”是一个相对于“物理机”的概念，虚拟机的字节码是不能直接在物理机上运行的，需要执行引擎编译成机器码后才可在物理机上执行。

### 2.5. 编译器优化机制？

#### 字节码运行模式

- **解释执行**：由解释器一行一行翻译字节码执行。
  - 优势在于没有编译的等待时间，可以节省内存（不存放到CodeCache），但由于要一行一行去翻译性，所以能差一些。
- **编译执行**：把字节码编译成字节码，直接执行机器码。
  - 运行效率会高很多，一般比解释执行快一个数量级，但带来了额外的内存（CodeCache）和CPU的开销。
- 相关命令：

| JVM参数              | 显示值                             | 说明                                                  |
| -------------------- | ---------------------------------- | ----------------------------------------------------- |
| java -version        | mixed mode，表示混合模式           | 查看字节码运行模式                                    |
| java -Xint -version  | interpreted mode，表示解释执行模式 | 指定解释执行模式                                      |
| java -Xcomp -version | compiled mode，表示编译执行模式    | 指定JVM优先以编译模式运行，不能编译的再以解释模式运行 |
| java -Xmixed         | mixed mode，表示混合模式           | 指定以混合模式运行（默认）                            |

#### JIT即时编译器

- **背景**：

  - JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。
  - 为了提高热点代码的执行效率，JVM会使用**即时编译器**，把这些热点代码编译成与本地平台相关的机器码，并进行**各层次的优化**。

- **概念**：Just In Time Compiler，JIT即时编译器，简称JIT编译器，在运行时JVM将会把热点代码编译成与本地平台相关的机器码，并进行各种层次的优化（比如锁粗化等），从而提高热点代码的执行效率。

  - **Hotspot - C1即时编译器**：也被称为Client  Compiler，是一个简单快速的编译器，主要关注局部性的优化，适用于执行时间较短或者对启动性能有要求的程序。比如GUI应用对界面启动速度就有一定的要求，此时适合用C1 编译器。
  - **Hotspot - C2 即时编译器**：也被称为Server Compiler，是为长期运行的服务器端应用程序做性能调优的编译器，适用于执行时间长或者对峰值性能有要求的程序。
  - **javac是前端编译**（也叫前期编译），负责把java代码编译成class字节码；而**JIT是后端编译**，负责把字节码编译成本地平台相关的机器码。

- **分层编译优化**：

  - level 0：解释执行。
  - level 1：简单的C1编译，使用C1编译器进行一些简单的优化，不开启Profiling（JVM的性能监控）。
  - level 2：受限的C1编译，仅执行**带方法调用次数**以及**循环回边执行次数**Pofiling的C1编译。
  - level 3：完全的C1编译，会执行带有所有Profiling的C1代码。
  - level 4：C2编译，使用C2编译器进行优化，该级别会启用一些编译耗时较长的优化，在一些情况下，会根据性能监控信息进行一些非常激进的性能优化。

  => 级别越高，应用启动越慢，优化的 开销越高，峰值性能也越高。

| JVM参数                                          | 默认值 | 说明                    |
| ------------------------------------------------ | ------ | ----------------------- |
| -XX：-TieredCompilation                          | ？     | 只开启C2（禁用123层）   |
| -XX：+TieredCompilation -XX：TieredStopAtLevel=1 | -      | 只开启C1（只开启0~1层） |

#### CodeCache

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。

#### 热点代码

- **概念**：JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。

- **探测方法**：

  - **基于采样的热点探测**：周期性检查各个线程的栈顶，经常出现在栈顶的则为热点方法。
  - **基于计数器的热点探测**：Hotspot使用的方法，思路是为每个方法或者代码块建立一个**计数器**，统计其执行的次数，如果超过某个阈值，则认为它是热点代码。

- **Hotspot内置计数器**：

  - **方法调用计数器**：Invocation Counter，用于统计方法被调用的次数（不是绝对次数，而是在一个相对的执行频率，即一段时间内方法被调用的次数），在不开启分层编译的情况下，默认C1阈值为1500次，C2为10000次。

  | JVM参数                  | 默认值 | 说明                                                     |
  | ------------------------ | ------ | -------------------------------------------------------- |
  | -XX：CompileThreshold=？ | ？     | 指定方法调用计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626357990780](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626357990780.png)

  - **回边计数器**：

    - 回边，Back Edge，指定的是在字节码中遇到控制流向后跳转的指令。
    - 回边计数器，Back Edge Counter，用于统计一个方法中循环体代码执行的次数，在不开启分层编译的情况下，默认C1为13995次，C2为10700次。
    - 建立回边计数器的目的是为了触发OSR，OnStackReplacement编译，是一种在运行时替换正在运行函数或者方法的栈帧的技术，是一种用于提升benchmark跑分非常有效的技术。

    | JVM参数                         | 默认值 | 说明                                                 |
    | ------------------------------- | ------ | ---------------------------------------------------- |
    | -XX：OnStackReplacePercentage=? | ?      | 指定回边计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626358121407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626358121407.png)

#### 方法内联

- **概念**：把目标方法的代码复制到发起调用的方法之中，即方法内联，避免发生真实的方法调用，从而减少方法调用时压栈和出栈的操作，以减少内存消耗和操作的时间，提高系统性能。
  - 方法内联，本质上是空间换时间的方式，也就是即时编译器在编译期间把方法调用连接起来，从而减少入栈和出栈的开销。
- **内联条件**：
  - **方法体足够小**：
    - 热点方法，方法体小于325字节会尝试内联，可用-XX：FreqInlineSize命令修改阈值大小。
    - 非热点方法，方法体小于35字节会尝试内联，可用-XX：MaxInlineSize命令修改阈值大小。
  - **被调用的方法运行时的实现可以被唯一确定**：
    - static方法、private方法以及final方法，JIT可以唯一确定具体的实现代码，此时会尝试内联。
    - 而public的实例方法，指向的实现可能是自身、父类或者子类的代码，仅当JIT能够唯一确定其唯一实现时，才有可能完成内联。
- **内联带来的问题**：
  - 由于经过内联后的代码会变多，其增加的代码量取决于方法的调用次数和方法本身的大小，在一些极端情况下，内联可能会引起CodeCahce溢出，可能会导致JVM退化成解释执行模式。
    - CodeCahce：是热点代码的一个缓存区，即时编译器编译后的代码以及本地方法代码都会存放在这个区间内，空间大小比较有限（JDK 8中只有240M内存），比较容易出现CodeCahce溢出。

| JVM参数                             | 默认值 | 说明                                                         |
| ----------------------------------- | ------ | ------------------------------------------------------------ |
| -XX：+Printlnlining                 | -      | 打印内联详情，该参数需和-XX：+UnlockDiagnosticVMOption配合使用 |
| -XX：+UnlockDiagnosticVMOption      | -      | 打印JVM诊断相关的信息                                        |
| -XX：MaxlnlineSize=？               | 35     | 如果非热点方法的字节码超过该值（单位字节），则无法内联       |
| -XX：FreqlnlineSize=？              | 325    | 如果热点方法的字节码超过该值（单位字节），则无法内联         |
| -XX：lnlineSmallCode=？             | 1000   | 如果目标编译后生成的机器码大小大于该值（单位字节），则无法内联 |
| -XX：MaxlnlineLevel=？              | 9      | 内联方法的最大调用帧数（嵌套调用的最大内联深度）             |
| -XX：MaxTrivialSize=？              | 6      | 如果方法的字节码少于该值（单位字节），则直接内联             |
| -XX：MinlnlingThreshold=？          | 250    | 如果目标方法的调用次数低于该值，则不去内联                   |
| -XX：LiveNodeCountlnliningCutoff=？ | 40000  | 编译过程中最大活动节点（IR节点）的上限，仅对C2编译器有效     |
| -XX：lnliningFrequencyCount=？      | 100    | 如果方法的调用点（call site）的执行次数超过该值，则触发内联  |
| -XX：MaxRecursivelnlining Level=？  | 1      | 如果递归调用大于该值，则不去内联                             |
| -XX：+lnlineSynchronizedMethods     | 开启   | 是否允许同步方法的内联                                       |

#### 逃逸分析

- **概念**：分析变量能否逃出它的作用域。

- **4种逃逸场景**：

  - **全局变量赋值逃逸**：局部变量作用域放大到全局变量。

  ```java
  public static SomeClass someClass;
  
  // 全局变量赋值逃逸
  public void globalVariablePointerEscape() {
      someClass = new SomeClass();
  }
  ```

  - **方法返回值逃逸**：变量作用域随着方法返回而放大。

  ```java
  // someMethod(){
  //   SomeClass someClass = methodPointerEscape();// 方法返回值逃逸
  // }
  public SomeClass methodPointerEscape() {
      return new SomeClass();
  }
  ```

  - **实例引用逃逸**：变量作用域随着方法参数逃逸到其他作用域。

  ```java
  // 实例引用传递逃逸
  public void instancePassPointerEscape() {
      this.methodPointerEscape().printClassName(this);
  }
  
  
  ```

  - **线程逃逸**：类变量或者可以被其他线程中访问的实例变量，即共享变量，可以随着线程共享发生的逃逸。

- **逃逸状态标记**：JVM针对每个逃逸场景进行分析，分析后会给对象做一个逃逸状态标记。

  - **全局逃逸标记**：一个对象可能从**方法**或者**线程**中逃逸，即其他方法或者其他线程也可以访问这个对象。
    - 对象被作为方法的返回值。
    - 对象作为静态字段或者成员变量。
    - 如果某个类重写了析构函数finalize（）方法，则整个类的对象都会被标记为全局逃逸状态，并且一定会放到堆内存里面。
  - **参数逃逸状态**：一个对象被作为参数传递给一个方法，但在接收参数的方法之外无法访问该对象，且该对象对其他线程也是不可见的。
  - **无逃逸状态**：一个对象不会发生逃逸。

| JVM参数                    | 默认值       | 说明             |
| -------------------------- | ------------ | ---------------- |
| -XX：+DoEscapeAnalysis     | JDK8默认开启 | 是否开启逃逸分析 |
| -XX：+EliminateAllocations | JDK8默认开启 | 开启标量替换     |
| -XX：+EliminateLocks       | JDK8默认开启 | 是否开启锁消除   |

#### 逃逸分析优化 - 标量替换

标量替换指的是，在通过逃逸分析确定对象不会被外部访问，且对象可以进一步被分解后（聚合量），JVM不会创建该对象，而是创建其成员变量（标量）去代替。

- **标量**：不能被进一步分配的量，比如基础数据类型和对象的地址引用。
- **聚合量**：可以进一步分解的量，可以由标量聚合而成，比如字符串、自己定义变量。

```java
public void someTest() {
    // someTest没有逃逸时, 且可以进一步分解, 则可以进行标量替换
    SomeTest someTest = new SomeTest();
    someTest.age = 1;
    someTest.id = 1;

    // 开启标量替换之后, 上述代码会被优化成: 并不会创建SomeTest对象
    int age = 1;
    int id = 1;
}


```

#### 逃逸分析优化 - 栈上分配

栈上分配指的是，在通过逃逸分析确定对象不会被外部访问后，并且对象足够的小，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。

#### 逃逸分析优化 - 锁消除

等到并发章节再写。

### 2.6. 详细介绍创建一个对象的步骤？

**步骤：类加载检查、类加载（加载、链接、初始化）、分配内存、初始化零值、设置对象头、执行init方法**

1. **类加载检查** ：当JVM遇到new指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。

2. **类加载 - 加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。

3. **类加载 - 链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：

   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。

4. **类加载 - 初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。

   - 执行clinit 方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。

5. **分配内存**：在确定对象需要创建后，接下来JVM将为对象分配内存，分配⽅式有 **“指针碰撞”** 和 **“空闲列表”** 两种，在分配内存的过程中，需要注意使用的是哪一种垃圾收集算法，因为垃圾收集算法的不同会导致内存块是否规整，从而影响到分配内存的方式是使用指针碰撞还是使用空闲列表。

   - 在进行内存分配的时候，如果使用的是指针碰撞方法，还需要注意并发情况下，内存的分配是否是线程安全的。一般使用**加同步块**的方式和**线程私有分配缓存区**这两种方式解决线程安全的问题。

6. **初始化零值**：对象内存分配完成后，JVM需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的**实例字段**在Java代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。

7. **设置对象头**： 初始化零值完成之后，JVM要对对象进⾏必要的设置，比如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息将存放在对象头中。另外，根据JVM当前运⾏状态的不同，比如是否启⽤偏向锁等，对象头会有不同的设置⽅式。

   - **对象头主要包括两部分**：用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）以及类型指针（即对象指向该类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例）。

   ![1626822381182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626822381182.png)

8. **执⾏init⽅法**： 从JVM的视⻆来看，⼀个新的对象已经产⽣了，但从Java程序的视⻆来看， init⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏new指令之后会接着执⾏init⽅法，这样⼀个真正可⽤的对象才算产⽣出来。

   - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
   - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
   - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

### 2.7. 对象内存分配过程？

![1626823040622](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626823040622.png)

1. 对象首先尝试栈上分配，如果栈上分配成功，则直接在栈上分配对象。
   - **栈上分配**指的是，在通过**逃逸分析**确定对象不会被外部访问后，并且**对象足够的小**，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。
2. 如果不能在栈上分配，且**对象也足够的小**，则尝试TLAB分配，如果TLAB分配成功，则直接在TLAB分配对象。
   - **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配**小对象**，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
3. 如果也不能在TLAB分配（大部分对象），则对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
4. 然而，**新建的对象不一定直接分配到Eden区**：如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
5. 同时还要注意的是，**由于JVM有动态年龄判定机制，对象不一定要达到年龄才能进入老年代**：
   - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

### 2.8. Java垃圾回收机制？

- **背景**：
  - 在Java中，程序员是**不需要显式去释放一个对象的内存**的，而是由虚拟机自行执行。
  - 在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。
- **使用场景原则**：
  - **内存要求**：内存不够，则需要想办法提高对象的回收率，以多回收一些对象，从而腾出更多的内存。
  - **CPU要求**：CPU不够，则需要降低垃圾回收频率，让CPU多去执行业务，而不是垃圾回收。
- **垃圾回收的区域**：虚拟机栈、本地方法栈和程序计数器是线程独享的，是随着线程的创建而创建的，随着线程的销毁而销毁的， 是不需要考虑垃圾回收的；而堆和方法区是线程共享的，需要关注垃圾回收。
  - **堆**：是垃圾回收的主要区域，用于回收创建的对象。
  - **方法区**：用于回收废弃的常量以及不需要的类。
- **回收时机**：由对象存活算法决定。

### 2.9. 对象存活算法？

#### 引用计数法

通过对象的引用计数器，来判断该对象是否被引用，比如有对象引用就+1，其引用失效就-1，当为0时，则代表该对象没有被引用。

- **优缺点**：实现简单，判断效率高；但无法解决对象循环引用的问题，**目前Java并不使用该算法**。

![1626436324696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436324696.png)

#### 可达性分析

以**根对象（GC Roots）**作为起点向下搜索，走过的路径被称为**引用链**（Reference Chain），如果某个对象到根对象之间没有引用链相连，则认为该对象是不可达的，是可以被回收的。**Java使用的是该存活算法**。

- **根对象**包括：
  - 虚拟机栈（栈帧中的局部变量表）中Reference对象所引用的对象。
  - 方法区中类的静态属性（static）Reference对象所引用的对象。
  - 方法区中常量（final）Reference对象所引用的对象。
  - 本地方法栈中JNI（即Native方法）Reference对象所引用的对象。

![1626436445717](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436445717.png)

- **可达性分析完整流程**：注意，一个对象即使不可达，也不一定会被回收，还要继续判断有无必要执行析构函数**finalize（）**方法，如果方法里面重新建立了与根对象之间的引用链，则不会去回收，否则还是会被回收。
  - **两次标记过程**：
    - 第一次标记不在“关系网”中的对象。
    - 第二次先判断该对象有没有实现finalize（）方法，如果没有实现，则直接判断该对象可回收；如果实现了，则会先放在一个队列中，并由JVM建立的一个低优先级的线程去执行它，随后会进行第二次的小规模标记，而在这次被标记的对象就会真正地被回收了。
  - **使用建议**：
    - 避免使用finalize（）方法，操作不当可能会导致问题。
    - finalize（）方法优先级低，什么时候会被调用也无法确定，因为什么时候发生GC是不确定的。
    - 建议使用try...catch...finally来代替finalzie（）方法。

![1626437028531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437028531.png)

### 3.0. JVM垃圾回收算法

分为**基础垃圾回收算法**（标记清除算法、标记整理算法和复制算法）和**综合垃圾回收算法**（分代搜集算法和增量算法）。

#### 基础 - 标记清除算法

- **优缺点**：实现简单；但存在内存碎片，影响对象的内存分配速度，在极端情况下需要遍历整个内存链表。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 再清理掉要回收的对象。

![1626437545225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437545225.png)

#### 基础 - 标记整理算法

也叫标记压缩算法。

- **优缺点**：无内存碎片；但由于整理需要计算和时间整理对象到一端，存在CPU和时间的开销。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 然后把所有存活对象压缩到内存的一端。
3. 再清理掉边界外的所有空间。

![1626437785184](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437785184.png)

#### 基础 - 复制算法

- **优缺点**：性能好（无需标记所有对象，只需找出存活的并移动即可），无内存碎片；但内存利用率低，最多才达到50%。
- **算法流程**：

1. 把内存分为两块，每次只使用其中一块。
2. 通过可达性分析，将存活的对象复制到另一块未使用的内存中，然后清除掉正在使用的那块内存中的所有对象。
3. 最后交换两块内存块的角色，等待下次回收重复执行上述操作。

![1626437874675](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437874675.png)

#### 综合 - 分代收集算法

- **概念**：

  - 各种商业虚拟机堆内存的垃圾收集基本上都采用了分代收集算法。
  - 根据对象的存活周期，把内存分为多个区域，**不同区域使用不同的回收算法**来回收对象，以提升整体性能。
  - 堆是垃圾回收的主要区域，其内存可以划分为以下区域：

  ![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **垃圾回收类型**：

  - **新生代回收**：Minor GC或者Young GC
  - **老年代回收**：Major GC，执行Major GC往往伴随一次Minor GC，所以**Major GC  ≈ Full GC**。
  - **清理整个堆**：Full GC = Major GC + Minor GC。

- **对象内存分配过程**：

  - **典型模型**：
    - **回收新生代使用复制算法**，因此新生代需要有两块内存（Eden区和Survivor区，8：2），Survivor区也有两块内存（From Survivor和To Survivor，1：1）。
      1. 对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。
      2. 而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。
      3. 对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
    - **回收老年代使用标记清除或者标记整理算法**，老年代：新生代，默认内存大小比值为2：1。
  - **新建的对象不一定直接分配到Eden区**：
    - 如果对象大于-XX：PretenureSizeThreshold（默认为0，表示所有对象都优先在Eden区分配），则会直接分配到老年代。
    - 如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
  - **对象不一定要达到年龄才能进入老年代**：
    - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

- **触发垃圾回收的条件**：

  - **新生代Minor GC**：Eden区空间不足时。
  - **老年代/Full GC**：
    - **老年代空间不足**：没有足够空间，或者内存碎片过多导致没有足够的连续空间去分配对象。
    - **元空间不足**：方法区的元空间不足也会触发Full GC。
    - **显示调用System.gc（）**：该方法的作用是建议垃圾回收器执行垃圾回收，会触发Full GC，可以使用-XX：+DisableExplicitGC参数忽略System.gc（）的调用。

- **分代收集算法的好处**：

  - **更有效的清除不再需要的对象**：对于生命周期比较短的对象，在新生代就会被回收掉了。
  - **提升了垃圾回收的效率**：如果不做分代处理，每次回收需要扫描整个堆的对象，而分代回收则需要扫描新生代或者老年代就可以了。

- **分代收集算法的调优原则**：

  - **合理设置Survivor区的大小，避免内存浪费**：因为Survivor区的内存利用率不高，如果设置得过大，则会导致内存浪费严重。
  - **让GC尽量发生在Minor GC级别，尽量减少Full GC的发生**。

| JVM参数                        | 默认值 | 说明                                                         |
| ------------------------------ | ------ | ------------------------------------------------------------ |
| -XX：+NewRatio=？              | 2      | 老年代：新生代的内存大小比值                                 |
| -XX：SurvivorRatio=？          | 8      | Eden区：Survivor区的内存大小比值                             |
| -XX：PretenureSizeThreshold=？ | 0      | 分配到老年代的对象大小阈值，为0表示不做限制，所有对象都优先在Eden区分配 |
| -Xms                           | -      | 最小堆内存                                                   |
| -Xmx                           | -      | 最大堆内存                                                   |
| -Xmn                           | -      | 新生代大小                                                   |
| -XX：+DisableExplicitGC        | 开启   | 忽略掉System.gc（）的调用                                    |
| -XX：NewSize=？                | -      | 新生代初始内存大小                                           |
| -XX：MaxNewSize=？             | -      | 新生代最大内存                                               |

#### 综合 - 增量算法

每次只收集一小片区域内存的垃圾，从而减少系统的停顿时间，见G1收集器的实现。

### 3.1. JVM垃圾收集器？

#### 相关概念

- **垃圾回收算法**：为实现垃圾回收提供理论支持。
- **垃圾收集器**：利用垃圾回收算法，实现垃圾回收的实践落地。
- **Stop The World**：**简写为STW，也叫全局停顿**，处于该状态时，Java代码将停止运行，而native代码可以继续运行，但无法与JVM进行交互。
  - **原因**：多半由于垃圾回收导致，也有可能由Dump线程、Dump堆、死锁检查等操作导致。
  - **危害**：服务会停止，没有响应；STW时间过长，可能会导致主从发生切换，影响生产环境。
- **并行收集**：指多个垃圾收集线程同时并行工作，但在收集过程中，用户线程处于等待状态。
- **并发收集**：指用户线程与垃圾收集线程同时工作。
- **应用吞吐量**：指的是CPU用于运行业务代码的时间，与CPU总消耗时间的比值。
  - **计算公式**：应用吞吐量 = 运行业务代码时间 / （运行用户代码时间 + 垃圾收集时间）* 100%，垃圾收集时间越长，应用吞吐量越小。

 ![1626495749202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626495749202.png)

#### 新生代 - Serial收集器

- **背景**：最基本的、发展历史最悠久的收集器。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **单线程、简单、相对高效**：由于是单线程实现的，不存在与其他线程的交互开销，可以专心做垃圾回收。
  - **收集过程全程Stop The World**。
- **适用场景**：
  - **用于客户端程序**：如果应用以java -client -jar方式启动时，默认使用的就是Serial收集器。
  - **用于单核机器上**：常见于一些嵌入式低性能的机器上运行。
- **执行过程**：
  - **Safepoint**：当发生GC时，用户线程必须全部停下来，才可以进行垃圾回收，这个状态可以认为JVM 是安全的（safe），整个堆的状态是稳定的。如果在GC前，有线程迟迟进入不了safepoint状态，那么整个 JVM都在等待这个线程，从而造成了GC整体时间变长。

![1626496514434](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626496514434.png)

#### 新生代 - ParNew收集器

- **背景**：Serial收集器的多线程版本，除了使用多线程不同以外，其他都和Serial收集器一样，包括JVM参数、Stop The World别的表现和垃圾收集算法。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **多线程、收集过程全程Stop The World**。
  - 可使用**-XX：ParallelGCThreads**设置垃圾收集的线程数，一般设置为CPU核心数就可以了。
- **适用场景**：主要用来和CMS收集器配合使用。
- **执行过程**：

![1626505507768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505507768.png)

#### 新生代 - Parallel  Scavenge收集器

- **背景**：也叫吞吐量优先收集器，也是并行的多线程收集器（多线程的方式与ParNew收集器类似）。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **可以达到一个可控制的吞吐量**：
    - -XX：MaxGCPauseMillis，设置阈值后，JVM将**尽力控制**最大的垃圾收集停顿时间为该阈值。
    - -XX：GCTimeRatio，设置吞吐量的大小，取值0~100，设置后JVM将花费不超过1 + / （1+n）的时间用于垃圾收集。
  - **自适应GC策略**：可用-XX：+UseAdptiveSizePolicy启用，启用后无需手动设置-Xmn、-XX：SurvivorRatio等参数，虚拟机会根据系统的运行状况收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。因此Parallel  Scavenge收集器存在着一定的智能性。
- **适用场景**：比较注重吞吐量的场景。
- **执行过程**：

![1626505950316](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505950316.png)

#### 老年代 - Serial Old收集器

- **背景**：也叫串行老年代收集器，可以认为是Serial收集器的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：除了算法采用标记整理算法与Serial收集器不同之外，其他都是一样的。
- **适用场景**：
  - 可以和Serial、ParNew、Parallel Scavenge三个新生代收集器配合使用。
  - CMS收集器在出现故障时，会使用Serial Old收集器作为备用。
- **执行过程**：

![1626506526709](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506526709.png)

#### 老年代 - Parallel Old收集器

- **背景**：可以认为是Parallel Scavenge的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：只能和Parallel Scavenge新生代收集器使用。
- **适用场景**：关注吞吐量的场景。
- **执行过程**：

![1626506871826](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506871826.png)

#### 老年代 - CMS收集器

- **背景**：CMS，Concurrent Mark Sweep，并发标记清除，是一个并发收集器，可以与用户线程同时工作。
- **垃圾回收算法**：标记清除算法。Serial Old与Parallel Scavenge采用的是标记整理算法。
- **特点**：
  - **优点**：
    - **Stop The World时间比较短，大多过程都是并发执行的**：只有1. 初始标记和5. 重新标记阶段存在Stop The World，其他阶段都是并发执行的）。
  - **缺点**：
    - **CPU资源比较敏感，并发执行的阶段会导致应用吞吐量的降低**：由于垃圾收集线程也需要占用一定的CPU资源，与业务线程一起去争抢CPU时间片，导致影响业务线程的执行效率，降低应用吞吐量。
    - **无法处理浮动垃圾**：由于并发清除阶段用户线程仍在并发执行，其可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而CMS无法在本次GC清理掉这些浮动垃圾，需要留到下次GC才能清理掉。
    - **不能等到老年代几乎满了才开始收集**：因为用户线程并发执行，必须为老年代预留足够的内存给用户线程使用。如果CMS执行期间预留的内存不能满足用户程序的需要，则会出现一次Concurrent Mode  Failure异常，这将会导致JVM**改用备用的Serial Old收集器**去收集老年代的垃圾，从而导致Stop The World时间加长。
      - 可使用CMSInitiatingOccupancyFraction，设置老年代占比达到多少后（默认68%），就会触发CMS垃圾收集。
    - **存在内存碎片（最令人诟病的地方）**：标记清除算法会导致内存碎片的产生。
      - 可使用UseCMSCompactAtFullCollection，在完成Full GC后是否要进行内存碎片的整理（默认打开）。
      - 也可使用CMSFullGCsBeforeCompaction，在进行几次Full GC后就进行一次内存碎片的整理（默认为0）。
  - **其他**：对于CMS收集器，Major GC和Full GC并不约等于，因为CMS是作用在老年代的垃圾回收，这里讲的Major GC并不是之前讲的Full GC。
- **适用场景**：
  - **希望系统停顿时间短，响应速度快的场景**：比如各种服务端应用场景。
- **执行过程**：

1. **初始标记**： 
   - initial  mark，标记根对象（GC Roots）能直接关联到的对象，因此能够标记到的对象会比较少。
   - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
2. **并发标记**：
   - concurrent mark，找出所有根对象（GC Roots）能够关联到的对象。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
3. **并发预清理**：
   - concurrent-preclean，**不一定会执行的阶段**，可用-XX：-CMSPrecleaningEnabled，关闭并发预清理阶段，默认是打开的。
   - 重新标记那些在并发标记阶段，引用被更新了的对象（比如新晋升到老年代的对象），从而减少后面重新标记阶段的工作量。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
4. **并发可中止的预清理阶段**：
   - concurrent-abortable-preclean，**不一定会执行的阶段**，使用该阶段的前提条件是：当Eden区使用量大于CMSScheduleRemarkEdenSizeThreshold的阈值（默认2M）时，才会执行该阶段。
   - 与并发预清理阶段所工作的事情是一样的。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 该阶段的主要作用是：允许用户能够控制预清理阶段的结束时机。
     - 比如，扫描多长时间：可用CMSMaxAbortablePrecleanTime进行设置，默认为5秒。
     - 再如，当Eden区使用占比达到多大阈值就结束本阶段：可用CMSScheduleRemarkEdenPenetration进行设置，默认为50%。
5. **重新标记**：
   - remark，修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
     - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
     - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
   - 存在Stop The World，一般来说（经验之谈），重新标记所花费的时间会比初始标记阶段的要长一些，但会比并发标记阶段的段一些。
6. **并发清理**：
   - concurrent sweep，或者叫**并发清除**，会基于标记结果，清除掉要前面标记出来需要清除的垃圾（会存在内存碎片）。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 为什么是并发清除，而不是并发整理？
     - 由于本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     - 试想一下如果既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，保证业务程序没有问题，这实现起来会变得非常困难，还容易出错。
     - 而采用并发清除就变得容易了许多，因此这里是并发清除而不是并发整理。
7. **并发重置**：
   - concurrent reset，清理本次CMS GC的上下文信息，为下一次GC做准备。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

#### 新生代&老年代 - G1收集器

- **背景**：Garbge First，是一款面向服务器端应用的垃圾收集器，既可以用在新生代，又可以用在老年代，即整个堆内存，会优先处理那些垃圾多的Region（First是价值优先的意思）。

- **垃圾回收算法**：复制算法。

- **革命性变化**：

  - **堆内存布局上的变化**：G1将整个堆划分成了若干个大小相等的区域，每个区域叫一个Region。
    - Region的大小可通过-XX：G1HeapRegionSize来指定，取值范围为1M~32M，必须为2的N次幂。
    - 在G1收集器里，同一代的对象可能是不连续的：一共分为4类Region，分别为Eden Region（伊甸园）、Survivor Region（存活区）、Old Region（老年代）、 Humongous Region（用于存储大对象，即超过Region大小一半的对象，而特大对象会分配到连续的Humongous Region里面）。

  ![1626511732234](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626511732234.png)

  - **设计思想上的变化**：**化整为零，分而治之**，本质上是应用了**增量算法**的思想。
    - 将堆内存按照Region分成多个块。
    - 然后会去跟踪每个Region里面的垃圾堆积的价值大小（即回收一个Region能够获取到多大的剩余空间）。
    - 最后构建一个优先列表，根据允许的收集时间，**优先回收价值高的Region**（回收后能够得到大的空间），以获得更高的垃圾收集效率。

- **特点**：

  - 可以作用在整个堆，既可以作用在新生代，又可以作用在老年代。
  - 垃圾回收时的停顿时间是可控的。
    - 可用MaxGCPauseMillis=？去控制。
  - 回收Region使用的是复制算法，无内存碎片的问题。

- **适用场景**：

  - 占用内存较大的应用（比如6G以上）。
  - 用于替换CMS垃圾收集器。
    - 对于JDK 8，G1和CMS的性能差异并不大，都可以使用。（经验之谈）如果内存<=6G，建议使用CMS；如果内存>6G，可以考虑使用G1。
    - 对于> JDK 8，则使用G1，因为CMS从JDK 9就已经被废弃了。

- **垃圾收集机制**：

  - **Young GC**：过程上与之前的Minor GC差不多（**复制算法**），只不过回收的单位是Region。

    - 所有Eden Region都满了时，会触发Young GC。
    - 所有Eden Region里面存活的对象，都会转移到Survivor Region里面去。
    - 而原先在Survivor Region中存活的对象，则会转移到新的Survivor Region中，或者晋升到Old Region中。
    - 其中，回收后空闲的Region会被放入空闲的列表中，等待下次被使用。

  - **Mixed GC**：最能体现G1的设计思想，与CMS有类似之处，但也有许多差异，比如使用的是复制算法。

    - 老年代大小占整个堆的百分比达到一定阈值时，则会触发Mixed GC。
      - 可用-XX：InitiatingHeapOccupancyPercent指定，默认为45%。
    - Mixed GC会回收所有Young Region，同时回收**部分**Old Region，回收那些根据收集时间与回收价值而选择的Old Region。
    - **执行过程**：除2. 并发标记是并发执行，其他阶段都是需要Stop The World的，但由于每次只回收部分Region，所以**Stop The World的时间是可控的**。

    1. **初始标记**：
       - Initial Marking，与CMS的初始标记类似，都是标记根对象（GC Roots）能直接关联到的对象。
       - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
    2. **并发标记**：
       - Concurrent Marking，与CMS的并发标记类似，用于找出所有根对象（GC Roots）能够关联到的对象。
       - 垃圾收集线程和用户线程并发执行，没有Stop The World。
    3. **最终标记**：
       - Final Marking，与CMS的重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
         - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
         - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
       - 存在Stop The World。
    4. **筛选回收**：
       - Live Data Counting and Evaluation，会对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间（MaxGCPauseMillis）来制定回收计划，并选择一些Region进行回收。
       - **回收过程：复制算法，无内存碎片**。
         - 选择一系列Region构成一个回收集。
         - 接着把决定要回收的Region中的存活对象复制空的 Region中。
         - 最后删除掉需要回收的Region。
       - 存在Stop The World。

  ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

  - **Full  GC**：
    - 当G1在复制对象时发现内存不够，或者无法分配足够内存（比如特大对象没有足够的连续Humongous Region可分配）时，则会触发Full GC。
    - 一旦触发Full GC，在Full GC模式下使用的是Serial Old模式的垃圾回收，将会出现长时间的Stop The World。

- **G1调优原则**：

  - 尽量减少Full GC的发生，尽量只停留在Young GC或者Mixed GC的模式上进行垃圾回收。
  - **减少Full GC的思路**？
    - **增加预留的内存**：可用过加大-XX：G1ReserveRercent来实现，默认为堆的10%。
    - **更早地回收垃圾，可降低老年代大小占整个堆的百分比的阈值，提早触发Mixed GC**：可通过减少-XX：InitiatingHeapOccupancyPercent来实现，默认为45%。
    - **增加并发阶段使用的线程数**：可增大-XX：ConcGCThreads，这样就可以有更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

#### 其他垃圾收集器

Shenandoah、ZGC、Epsilon，JDK 14处于实验状态，不建议在生产环境中使用。

#### 如何选择垃圾收集器？

不能纸上谈兵，要根据实际情况选择。

- 应用系统所关注的最主要的矛盾点？
  - 响应快、吞吐量高：Parallel Scaveng。
  - Web应用，低延迟：CMS或者G1。
  - 桌面端应用，启动慢：Serial & -Xverify：none参数。
- 应用系统的基础设施？
  - 单核：Serial。
  - Windows + JDK11：应用不了ZGC，需要升级到JDK14才支持。
- 应用系统的JDK的版本？
  - JDK6用不了G1。
  - Oracle JDK用不了Shenandoah。

#### 垃圾收集器相关JVM参数

详细见《JVM参数选型-高级选型-常用高级垃圾收集选项》一栏。

### 3.2. JVM性能调优工具？

详细见《JVM调优工具集锦》：基于JDK 11编写。

#### JDK内置 - 监控类工具

##### jps

Java Virtual Machine Process Status Tool，实验性工具，用于查看所有Java进程，比ps -ef  | grep java方便。

```java
eg：
jps -q：只查看进程号。
jps -m：查看传递给main方法的参数。
jps -l：查看启动类的全限定名。
jps -v：查看JVM启动时的参数。


```

##### jstat

JVM Statistics Monitoring Tool，实验性工具，⽤于监控JVM的各种运⾏状态息，包括**内存状态**和**垃圾回收**。

```java
命令格式：jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]
  -<option> ：指定参数，取值可⽤jstat -options查看
  -t        ：⽤来展示每次采样花费的时间
  <lines>   ：每抽样⼏次就列⼀个标题，默认0，显示数据第⼀⾏的列标题
  <interval>：抽样的周期，格式使⽤:<n>["ms"|"s"]，n是数字，ms/s是时间单位，默认是ms
  <count>   ：采样多少次停⽌，默认是一直打印

option参数解释：
-class    :：显示类加载器的统计信息
-gcutil    ：垃圾回收统计概述
-gc        ：垃圾回收堆的行为统计
-gcnew     ：新生代行为统计
-gcold     ：年老代和永生代行为统计
-gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计


```

#### JDK内置 - 故障排查类工具

##### jinfo

Java Configuration Info，实验性参数，主要⽤来查看以及调整JVM参数。

```java
命令格式：jinfo <option> <pid>

1）查看能力:
jinfo 11666：查看11666进程的Java System Properties、VM Flags、VM Arguments
jinfo -sysprops 11666          ：只查看11666进程的Java System Properties
jinfo -flags 11666             ：只查看11666进程的VM Flags
jinfo -flag 11666 Xmx          ：只查看11666进程的Xmx参数（最大堆内存大小）
jinfo -flag 11666 Xms          ：只查看11666进程的Xms参数（初始堆内存大小）
jinfo -flag 11666 Xmn          ：只查看11666进程的Xmn参数（新生代内存大小）
jinfo -flag 11666 MetaspaceSize：只查看11666进程的MetaspaceSize参数（元空间内存大小）

2）动态修改能力：不用重启JVM就可以生效，但能力比较有限
java -XX:+PrintFlagsInitial | grep manageable：只有显示出来的结果才能被动态修改。
开关类（打开/关闭）：jinfo -flag +HeapDumpAfterFullGC 11666
赋值类（更新为60） ：jinfo -flag MinHeapFreeRatio=60 11666


```

##### jmap

Java Memory Map，实验性工具，⽤来展示对象内存映射或者堆内存详细信息。

- **生成堆dump的8种方式**：
  - **jmap**：jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆Dump文件为mydump.hprof。
  - **jcmd**：jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）。
  - **jhsdb jmap**：jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件。
  - **Visual VM**：Monitor界面的Heap Dump按钮Dump堆，相当于jmap dump命令。
  - **OOM异常自动后生成**：使用-XX：+HeapDumpOnOutOf  MemeoryError，使JVM在OOM异常出现后自动生成堆Dump文件。
  - **Ctrl + （Pause）Break生成**：使用-XX：+HeapDumpOnCtrBreak，开启后可使用Ctrl + （Pause）Break，让虚拟机生成堆Dump文件。
  - **kill -3命令**：在Linux操作系统下，发送kill -3 pid命令生成堆Dump文件。
  - **借助SpringBoot Actuator生成**：对于SpringBoot应⽤，可以使⽤SpringBoot Actuator提供的/actuator/heapdump来实现堆Dump的生成。

```java
命令格式：jmap [option] <pid>

option参数解释：
-heap             ：打印java heap摘要
-clstats          ：打印Java堆的类加载器统计信息
-finalizerinfo    ：打印等待finalization的对象的信息
-histo[:live]     ：打印Java堆的直⽅图。如果指定了live⼦选项，则仅统计活动对象
-dump:dump_options：生成java堆的dump文件。其中，dump_options的取值为：
              live：指定时，仅Dump活动对象；如果未指定，则转储堆中的所有对象
          format=b：以hprof格式Dump堆
     file=filename：将堆Dump到filename

eg:
jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆dump文件为mydump.hprof


```

##### jstack

Stack Trace for Java，实验性工具，⽤于打印当前虚拟机的线程快照（线程快照也叫Thread Dump或者javacore⽂件，包含展示每个线程正在做什么、执行到了哪里等信息），常用于定位线程出现长时间卡顿的原因，比如死锁、死循环等。

- **生成线程dump的4种方式**：
  - **jstack**：jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息。
  - **jcmd**：jcmd 11666 Thread.print -l：打印11666进程所有线程以及线程持有锁的额外信息。
  - **jhsdb jstack**：jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息。
  - **VisualVM**：Threads界面的Thread Dump按钮Dump线程，相当于jstack。

```java
命令格式：jstack [-l][-e] <pid>
  
option参数解释：
-l：显示有关线程持有的锁的额外信息
-e：展示有关线程的额外信息（⽐如分配了多少内存、定义了多少个类等等）

eg：
jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息


```

##### jhat

JVM Heap Analysis Tool，实验性工具，⽤来分析jmap⽣成的堆Dump，能力比较弱，有非常多的替代品（比如VisualVM、Eclipse Memory Analyzer），且在JDK 11已被废弃（可在JDK 8中使用），对于学习不太重要了。

```java
命令格式：jhat [options] heap-dump-file

option参数解释：
-stack false | true   ：开启或关闭跟踪对象分配调⽤栈，默认true
-refs false | true    ：开启或关闭对对象引⽤的跟踪，默认true
-port port-number     ：指定jhat HTTP Server的端⼝，默认7000
-exclude exclude-file ：指定⼀个⽂件，该⽂件列出了应从可达对象查询中排除的数据成员
-baseline exclude-file：指定基线堆Dump⽂件。两个堆Dunmp中，对于⽐较两个不同的堆转储很有⽤
-debug intSets        ：指定该⼯具的debug级别。设置为0，则不会有debug输出。数值越⾼，⽇志越详细
-version              ：显示版本


```

##### jcmd

JVM Command，⽤于将诊断命令请求发送到正在运⾏的Java虚拟机，从JDK 7开始提供。

```java
命令格式：jcmd <pid | main class> <command ...|PerfCounter.print|-f file>

命令参数解释：
pid              ：接收诊断命令请求的进程ID
main class      :：接收诊断命令请求的main类的所有进程
command          ：command必须是⼀个有效的jcmd命令
PerfCounter.print：打印指定Java进程上可⽤的性能计数器
-f filename      ：从指定⽂件中读取命令并执⾏
-l               ：查看所有的JVM进程。jcmd不使⽤参数与jcmd -l效果相同

eg：
jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）
jcmd 11666 GC.run						 ：调⽤一次java.lang.System.gc()
jcmd 11666 Thread.print -l		         ：打印11666进程所有线程以及线程持有锁的额外信息


```

##### jhsdb

Java Hotspot Debugger，Hotspot进程调试器，可⽤于从崩溃的JVM附加到Java进程或核⼼转储，从JDK 9开始引入，JDK 9前使用sa-jdi.jar（jhsdb的原型）也是可以的。

```java
1）jhsdb clhsdb --pid 11666：进入11666进程的jhsdb的交互界面
eg：（交互界面下）
	flags          ：展示所有以-XX开头的JVM参数的值
	g1regiondetails：查看G1每个Region的起始指针、结束指针、是哪一个分代的信息

2）jhsdb hsdb --pid 11666：进入11666进程的图形化界面

3）jhsdb jinfo --flags --pid 11666：打印11666进程的VM标志

4）jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件

5）jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息

6）jhsdb jsnap --all -pid 11666：打印11666进程所有性能计数器的信息=jcmd的PerfCounter.print


```

#### JDK内置 - 可视化工具

##### jhsdb

jhsdb hsdb --pid 11666：进入11666进程的图形化界面，其菜单功能包括：

- Inspect Thread：这个线程的诊断信息，包含对象头和指向对象元数据的指针（Java类型的名字、继承关系、实现接⼝关系，字段信息、⽅法信息、运⾏时常量池的指针、内嵌的虚⽅法表（vtable）以及接⼝⽅法表（itable）等）。
- Stack Memory：这个线程栈的内存数据信息。
  - 第⼀列：内存地址（虚拟地址，⾮物理内存地址）。
  - 第⼆列：该地址上存储的数据，以字宽为单位。
  - 第三列是：对数据的注释，竖线表示范围，横线或斜线连接范围与注释⽂字。
- Show Java stack trace：这个线程的线程栈信息。
- Show Thread Information：这个线程的其他信息。
- Find Crashes：可找出这个线程崩溃的原因。
- Windows Console：可输⼊诊断命令，也就是jhsdb clhsdb命令交互页面。

![1626576342750](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576342750.png)

##### jconsole

- Java Monitoring and Management Console，是⼀款基于JMX（Java Manage-ment Extensions）的可视化监控、管理⼯具，主要是通过JMX的MBean（Managed Bean）对系统进⾏信息收集和参数动态调整。
  - JMX是⼀种开放性的技术，它既可以⽤在虚拟机本身的管理上，也可以⽤于运⾏在虚拟机之上的软件中。⽬前很多软件都⽀持基于JMX进⾏管理与监控。
- 执行jconsole命令打开界面，然后输入线程号即可。

![1626576867182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576867182.png)

##### VisualVM

- 也叫JVisualVM，是⼀个All-in-One Java Troubleshooting Tool，即多合一的故障排查工具，从JDK 6开始提供，是⽬前最强⼤的监控及故障处理程序之⼀。
- JDK 8输入jvisualvm启动即可，JDK 9输入独自安装，其界面菜单功能包括：
  - Overview：展示应⽤的概要信息，相当于可视化的jps、jinfo。
  - Monitor：展示一些监控信息，包括CPU、内存、类、线程等曲线图，Perform GC按钮通知JVM执⾏垃圾回收，Heap Dump按钮Dump堆，相当于jmap dump命令。
  - Threads：展示查看线程状态，以及Thread Dump按钮Dump线程，相当于jstack。
  - Sampler：抽样器，可⽤于实时性能分析，支持CPU抽样以及内存抽样。
  - Profiler：性能分析，提供了程序运⾏期⽅法级的处理器执⾏时间分析及内存分析。
    - 执⾏该性能分析，会对程序运⾏性能有⽐较⼤的影响，⼀般不建议在⽣产环境使⽤这项功能，建议使用JMC来代替。
    - 开启类共享（⼀种共享类，从⽽提升加载速度、节省内存的技术）可能会导致执⾏Profiler的应⽤崩
      溃，建议在执⾏Profiler的应⽤上添加-Xshare:off，关闭掉类共享。
  - 分析堆dump文件：File -> Load -> 选择hprof -> 打开 -> 分析。
  - 其他插件：VisualVM还支持安装插件来扩展功能，比如Visual CC来实时分析垃圾回收的情况。

![1626577315983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626577315983.png)

##### JDK Mission Control

- 也叫Java Mission Control，简称JMC，是一款监控、定义线上问题以及性能调优的神器。
  - 它是⼀款商业授权⼯具（例如在JDK 8中），需要商业授权才能在⽣产环境中使⽤，现已开源，在JDK 11（哪怕是OpenJDK）中，任何⼈都可以使⽤JFR + JMC（需遵循 UPL协议 ）。
- JMC的两大功能：
  - 作为JMX控制台，监控虚拟机MBean提供的数据。
  - 可持续收集数据的JFR，并可作为JFR的可视化分析⼯具。
    - JFR：Java Flight Recorder，是⼀种⽤于收集有关运⾏中的Java应⽤的诊断信息和性能数据的⼯具。它⼏乎没有性能开销，因此，即使在负载很⼤的⽣产环境中也可以使⽤。
    - 主要用于性能分析、性能分析、⽀持与调试的场景。
- MBean服务器菜单功能介绍：
  - 概览：各种概要信息。
  - MBean浏览器：展示应⽤被JMX管理的Bean。
  - 触发器：配置触发规则，当规则满⾜时，就触发某个操作（在操作⼀栏配置）。
  - 系统：查看系统相关信息。
  - 内存：查看内存相关信息。
  - 线程：查看线程相关信息。
  - 诊断命令：可视化使⽤诊断命令，相当于可视化的jcmd。
- 飞行记录性菜单功能介绍：
  - 如果应用JDK版本 < JDK11，则启动项目时需要添加-XX:+UnlockCommercialFeatures -XX:+FlightRecorder。
  - ⾃动分析结果：JMC⾃动给出的优化提议。
  - Java应⽤程序：展示应⽤的各种执⾏情况。
  - JVM内部：展示JVM层⾯的执⾏情况。
  - 环境：展示操作系统层⾯的执⾏情况。
  - 事件：展示录制期间发⽣的事件。
- JMC优点：
  - JFR在⽣产环境中对吞吐量的影响⼀般不会⾼于1%。
  - JFR监控过程是可动态的，⽆需重启。
  - JFR监控过程对应⽤完全透明，⽆需修改应⽤的代码，也⽆需安装额外的插件或代理。
  - JFR提供的数据质量⾮常⾼，对监控、排查的参考价值更⼤。
- JMC缺点：
  - JFR并不完全向后兼容。⽐如，在JDK 11⾥⾯⽣成的JFR⽂件，⽤早期的JMC（例如JMC 5.5）⽆法打开。
  - JMC 7.0.1⽆法分析堆dump⽂件（hprof格式），但 官⽅Wiki 宣称⽀持分析堆dump⽂件。

![1626578206459](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626578206459.png)

#### 第三方工具

##### Memory Analyzer Tool

- Memory Analyzer Tool，简称MAT，可以作为独⽴软件，也可作为Eclipse插件存在，是⼀个快
  速且功能丰富的Java堆内存分析器，可帮助您查找内存泄漏并减少内存消耗。

- MAT主要功能：

  - 找出内存泄漏的原因。
  - 找出重复引⽤的类和jar。
  - 分析集合的使⽤。
  - 分析类加载器。

- 相关概念：

  - **浅堆**：一个对象E自身所消耗的内存，根据堆转储格式，对象⼤⼩可能会被调整（例如，对⻬为8bit），从⽽更好地模拟VM的实际消耗量。⼀般来说，对象的浅堆是对象在堆中的⼤⼩，⽽同⼀对象的保留⼤⼩是在垃圾回收对象时将释放的堆内存量。
  - **X的保留集**：Retained set，当E被垃圾回收时，由GC删除的对象集E和G。同理，如果E没有被回收，那么该集合中的对象E和G都会“保留下来”。
  - **X的保留堆**：Retained heap，指的是对象E的保留集E和G的内存⼤⼩，即由于它的存活导致多⼤的内存没有被回收。
  - **前导对象集的保留集**：前导对象E不可达时，被释放的那些对象E和G，所以这里前导对象集E的保留集为E和G。

  ![1626581295844](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626581295844.png)

  - **支配树**：MAT提供了对象图的⽀配树，通过将对象参考图转换为⽀配树，可以轻松地识别最⼤的保留内存块以及对象之间的依赖关系。⽀配树是在对象图的基础上建⽴的，在⽀配树中，每个节点都是其⼦节点的直接⽀配者。因此，基于⽀配树可以轻松看出对象之间的依赖关系。其具有以下属性：
    - 对象从属于X的⼦树（例如对象被X⽀配）就是X的Retained set。
      - **X⽀配Y**：如果对象图中从起始（或Root）节点到Y的每条路径都必须经过X，那么就说对象X⽀配对象Y。
      - **直接⽀配者**：某个对象路径最短的⽀配者。
      - **间接支配者**：一个对象X支配了该对象Y，但又不是Y的直接支配者，则称X为Y的间接支配者。
    - 如果X是Y的直接⽀配节点，那么⽀配X的节点也可以⽀配Y。
    - ⽀配树中的边并不直接对应于对象图中的对象引⽤。

  ![1626582280791](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582280791.png)

- MAT菜单功能介绍：

  - inspector：透视图，⽤于展示⼀个对象的详细信息，例如内存地址、加载器名称、包名、对象名称、对象所属的类的⽗类、对象所属的类的加载器对象、该对象的堆内存⼤⼩和保留⼤⼩，gc root信息。下半部分展示类的静态属性和值、对象的实例属性和值、对象所属的类的继承结构。
  - Heap Dump History：列出最近分析过的⽂件。
  - 功能选择栏：从左到右依次是：概览、类直⽅图、⽀配树、OQL查询、线程视图、报告相关、详细功能。其中概览就是上图的这个⻚⾯，其他则提供了⼀些更细致的分析能⼒。总的来说，功能上和VisualVM⼤同⼩异，但分析得更加细致。
  - 饼图：展示retained size对象占⽤⽐例。
  - Actions：常⽤的内存分析动作。
    - Histogram：列出内存中的对象，对象的个数及其⼤⼩。点击后⽣成的报表：
      - Class Name ： 类名称，java类名。
      - Objects ： 类的对象的数量，这个对象被创建了多少个。
      - Shallow Heap ：⼀个对象内存的消耗⼤⼩，不包含对其他对象的引⽤。
      - Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和。
    - Dominator Tree：列出最⼤的那些对象，以及他们为什么存活。
    - Top Consumers：打印最昂贵的对象，以内和包分组。
    - Duplicate Classes：检测被多个classloader加载的类。
  - Reports：报表功能，包括：
    - Leak Suspects：⾃动分析内存泄漏的原因，并能直接定位到Class，找到可能导致内存泄露的代码⾏数。
    - Top Components：列出占⽤超过1%的组件的报告信息。
  - Step by Step：
    - Top Components：分析从属于指定包或者class loader的对象。

![1626582745483](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582745483.png)

##### JITWatch

- JITWatch是JIT编译器的⽇志分析器与可视化⼯具，可⽤来检查内联决策、热点⽅法、字节码以及汇编的各种细节，经常和HSDIS配合使⽤，实际中用的也不是特别多。
  - HSDIS是⼀个HotSpot虚拟机即时编译代码的反汇编插件，它包含在HotSpot虚拟机的源码当中，在OpenJDK的⽹站也可以找到单独的源码下载，但并没有提供编译后的程序。
- 安装HSDIS后，启动应用，添加以下参数，用于收集反汇编日志，执行完后将会⽣成⼀个  /Users/itmuch.com/logfile.log ⽂件，⾥⾯包括了各种类编辑以及汇编信息。
  - UnlockDiagnosticVMOptions：开启诊断信息。
  - PrintAssembly：输出反汇编内容。
  - Xcomp：以编译模式启动，这样，⽆执⾏⾜够次数来预热即可触发即时编译。
  - LogCompilation：打印编译相关信息。
  - LogFile：指定⽇志⽂件。
  - TraceClassLoading：是否跟踪类的加载。

```java
java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp -XX:+LogCompilation -XX:LogFile=/Users/itmuch.com
/logfile.log -XX:+TraceClassLoading -jar xxx.jar


```

- 最后使用JITWatch可视化阅读⽇志，使用以下命令启动JITWatch，选择反汇编日志，点击start即可可视化地分析了。

```java
mvn clean compile exec:java


```

![1626583188575](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626583188575.png)

### 3.3. JVM参数选项？

笔记时间：2021-07-18。

#### 标准选项

- 用于**执行常见操作**（比如检查JRE版本、设置类路径、启动详细输出等），各种厂牌的虚拟机都会支持。
- **格式不统一**，以java -help的结果为准。
- **常见的标准选项有**：

| JVM参数                          | 作用                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| -class-path \| -classpath \|- cp | 指定JVM类搜索路径，多个路径之间以分号隔开。如果指定了-classpath，则JVM就忽略系统变量CLASSPATH中指定的路径。如果-classpath和CLASSPATH都没有指定，则JVM会从当前路径寻找class |
| -server                          | 以server模式启动JVM，与client模式恰好相反。适合生产环境，适用于服务器。64位的JVM自动以server模式启动 |
| -client                          | 以client模式启动JVM，这种方式启动速度快，但运行时性能和内存管理效率不高，适合客户端程序或者开发调试。64位的JVM不支持client模式 |
| -Dproperty=value                 | 设置系统属性值。其中， property是属性名称，value是属性值，如果value有空格，则需要使用双引号，比如-Dfoo=“foo bar” |
| -javaagent：jarpath[=options]    | 加载指定的Java编程语言代理                                   |
| -verbose：class                  | 显示类加载相关的信息，当报找不到类或者类冲突时，可用此参数来诊断 |
| -verbose：gc                     | 显示垃圾收集事件的相关信息                                   |
| -verbose：jni                    | 显示本机方法和其他Java本机接口（JNI）的相关信息              |
| -version                         | 展示JDK版本                                                  |

#### 附加选项

- JDK 11文档中称为**额外参数**，JDK 8文档中称为**非标准参数**，是**Hotspot虚拟机的通用选项**，其他厂牌的JVM不一定会支持，并且未来可能会发生变化。
- 附加选项都以**-X开头**，具体以java -x的结果为准。
- **常见的附加选项有**：

| JVM参数                  | 默认值                                                       | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| -Xcomp                   | 默认情况下，client模式下会解释执行10000次（< JDK 11），server模式下会解释执行10000次，并收集信息，此后才可能编译运行。 | 在第一次调用时强制编译方法。指定该选项将禁用解释方法调用。此外，还可使用-XX：CompileThreshold选项更改在编译之前解释执行方法的调用次数 |
| -Xint                    | -                                                            | 以解释模式运行                                               |
| -Xmixed                  | -                                                            | 热点方法以编译模式运行，其他方法以解释模式运行               |
| -Xloggc：option          | -                                                            | 将GC事件的相关信息记录到文件中                               |
| -Xnoclassgc              | -                                                            | 禁用类的垃圾收集。使用该参数可节省一些GC时间，缩短应用程序运行期间的停顿。但一旦使用该参数，那么应用程序中的类对象就会始终被视为活动对象，从而导致这块内存被永久占用。如果使用不当，将会导致内存溢出 |
| -Xshare：mode            | auto：尽可能使用CDS，是32位的Hotspot JVM的默认值；on：开启CDS。如果CDS无法被开启，将会打印错误信息；off：不适用CDS | 设置类数据共享模式（class data sharing，即CDS）。注意，此选项只应用于测试目的，并且可能由于操作系统使用地址空间布局随机化而导致间歇性故障，不应在生产环境中使用 |
| -XshowSettings：category | all：默认值，展示所有设置；locale：展示语言环境相关的设置；properties：展示系统属性相关的设置；vm：展示JVM的设置；system：展示Linux主机系统或者容器的配置 | 展示设置                                                     |
| -Xmn                     | -                                                            | 设置年轻代的初始值以及最大值，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节，例如-Xmn256m。此外，还可用-XX：NewSize设置年轻代初始大小，-XX：MaxNewSize设置年轻代最大大小 |
| -Xms                     | -                                                            | 设置堆内存的初始大小，以字节为单位。此值必须是1024的倍数且大于1MB。如果未设置此选项，则将堆内存初始大小设置为老年代和年轻代分配的大小之和。设置格式同-Xmn，例如-Xms6144K |
| -Xmx                     | -                                                            | 设置堆内存的最大大小，以字节为单位。此值必须是1024的倍数且大于2MB。等效于-XX：MaxHeapSize |
| -Xss                     | 默认值取决于平台，64位Linux：1024KB；64位 MacOS：1024KB；64位Oracle Solaris：1024KB；Windows：默认值取决于虚拟内存 | 设置线程栈大小，以字节为单位                                 |

#### 高级选项

- 高级选项是**为开发人员提供的选项**，用于调整Java **HotSpot虚拟机**操作的特定区域（这些区域通常具有特定的系统要求，并且可能需要对系统配置参数的特权访问），其他厂牌的JVM不一定会支持，并且未来可能会发生变化。
- 高级选项都以**-XX开头**，可以使用以下方法查看所支持的选项：

```java
1）解锁参数并打印：java -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsInitial

2）jhsdb clhsdb --pid 11666，进入交互页面后使用flags查看


```

- **使用格式**：
  - **boolean类型**：格式为-XX：（+/-），+表示将选项设置为true，-表示将选项设置为false。
  - **非boolean类型**：格式为-XX：选项=值。
- **常见的高级选项有**：

##### 常用高级运行时选项

用于控制HotSpot VM的运行时的各种行为。

| JVM参数                               | 默认值或者取值方式 | 作用                                                         |
| ------------------------------------- | ------------------ | ------------------------------------------------------------ |
| -XX：ActiveProcessorCount=n           | -                  | JVM使用多少个CPU核心，去计算用于执行垃圾收集或者ForkJoinPool线程池的大小 |
| -XX：InitiatingHeapOccupancyPercent=n | 45                 | 老年代大小到达该阈值，会触发G1 Mixed GC                      |
| -XX：LargePageSizeInBytes=n           | -                  | 设置用于Java堆的大页面尺寸，以字节为单位，其数值必须是2的幂次，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxDirectMemorySize=n            | -                  | 设置java.nio包的直接缓存区分配的最大总大小，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxGCPauseMillis=n               | 200ms              | 期望的最大停顿时间                                           |
| -XX：OnError=string                   | -                  | 发生错误的时候做某事，string是一个或者多个命令，多个命令使用分号分隔，如果字符串包含空格，则必须将其用引号引起来。比如“gcore %p；dbx - %p”，表示当发生错误时，使用gcore命令创建核心dump文件 |
| -XX：OnOutOfMemoryError=string        | -                  | 当发生OOM异常时做模式，配置格式同-XX：OnError                |
| -XX：ParallelGCThreads=n              | -                  | 设置GC并行阶段的线程数                                       |
| -XX：+PrintCommandLineFlags           | 关闭               | 打印命令行标记                                               |
| -XX：ThreadStackSize=size             | -                  | 设置线程栈的大小，和-Xss等价                                 |
| -XX：-UseBiasedLocking                | -                  | 禁用偏向锁                                                   |
| -XX：-UseCompressedOops               | 启用               | 禁用压缩指针。此选项仅适用于64位JVM，当Java堆大小小于32GB时，将使用压缩指针。启用此选项后，对象引用将表示为32位偏移量，而非64位指针，这通常会在运行Java堆大小小于32GB的应用程序时提高性能。当Java堆大小大于32GB时，可使用-XX：ObjectAlignmentInBytes选项 |
| -XX：GCLogFileSize=n                  | 512KB              | 处理大型日志文件                                             |
| -XX：+UseLargePages                   | 关闭               | 启用大页面内存的使用                                         |
| -XX： VMOptionsFile=filename          | -                  | 允许用户在文件中指定VM选项。比如java -XX：VMOptionsFile=/var/my_vm_options_HelloWorld |
|                                       |                    |                                                              |
| 元空间参数                            |                    |                                                              |
| -XX：MetaspaceSize                    | 20.8MB             | 元空间的初始值，元空间占用达到该值就会触发垃圾回收，进行类的卸载，同时收集器会自动调整该值。如果能够释放空间，则会自动降低该值（减少空间浪费）；如果释放空间很少，则在不超过-XX：MaxMetaspaceSize的情况下，适当提高该值（保证有足够空间） |
| -XX：MaxMetaspaceSize                 | 受限于本地内存大小 | 元空间大小的最大值                                           |
| -XX：MinMetaspaceFreeRatio            | 40%                | 垃圾收集后，计算当前元空间的空闲百分比，如果小于该值，则增加元空间的大小（保证有足够空间） |
| -XX：MaxMetaspaceFreeRatio            | 70%                | 垃圾收集后，计算当前元空间的空闲百分比，如果大于该值，则减少元空间的大小（减少空间浪费） |
| -XX：MinMetaspaceExpansion            | 332.8KB            | 元空间增长时的最小幅度                                       |
| -XX：MaxMetaspaceExpansion            | 5.2MB              | 元空间增长时的最大幅度                                       |
|                                       |                    |                                                              |
| 直接内存参数                          |                    |                                                              |
| -XX：MaxDirectMemorySize              | -                  | 设置最大直接内存大小，对Unsafe不起作用，但对ByteBuffer有效   |
|                                       |                    |                                                              |
| TLAB参数（不建议修改）                |                    |                                                              |
| -XX：+UseTLAB                         | 开启               | 是否启用线程私有分配缓存区（Thread-Local Allocation Buffer） |
| -XX：MinTLABSize                      | 2048B              | 最小TLAB大小，单位字节                                       |
| -XX：+ResizeTLAB                      | 是                 | 是否动态调整TLAB的大小                                       |
| -XX：TLABRefillWasteFraction          | 64                 | 由于TLAB空间比较小，因此很容易装满。比如TLAB 100KB，已使用80KB，当需要再分配一个30KB的对象时，就无法分配到这个TLAB了。这时虚拟机会有两种选择，第一，废弃当前TLAB，这样就会浪费20KB的空间；第二，保留当前的TLAB并将这30KB的对象直接分配在堆上，这样将来有小于20KB的对象时，仍可以使用这块空间。实际上，JVM内部维护了一个叫做refill_waste的值，当请求对象大于refill_waste时，会在堆中分配；若小于该值，则会废弃当前TLAB，新建TLAB分配对象。可以用TLABRefillWasteFraction来调整该阈值，表示TLAB中允许产生这种浪费的比例，默认为64，即允许使用1/64的TLAB空间作为refill_waste。默认情况下，TLAB和refill_waste都会在运行时不断地调整，使系统的运行状态达到最优。如果想要禁用自动调整TLAB的大小，可以使用-XX：-ResizeTLAB禁用ResizeTLAB，并使用-XX：TLABSize手工指定一个TLAB的大小 |
| -XX：+TLABStats                       | 是                 | 是否提供详细的TLAB的统计信息                                 |
| -XX：TLABSize                         | 0                  | 设置TLAB的初始大小，如果设置为0，JVM会自动设置TLAB的初始大小 |
| -XX：TLABWasteTargetPercent           | 1                  | 允许TLAB占用Eden空间的百分比                                 |

##### 常用高级JIT编译器选项

用于控制HotSpot VM如果执行的JIT编译。

| JVM参数                                       | 默认值                                                   | 作用                                                         |
| --------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| -XX：+BackgroundCompilation                   | 开启                                                     | 启用JIT后台编译                                              |
| -XX：CompileCommand=command，method[，option] | -                                                        | 在指定方法上执行指定command。command可选项为：break：在调试JVM时设置一个断点，以便在指定方法编译开始时停止； compileonly：排除所有未指定的所有方法；dontinline：防止内联指定方法；exclude：排除指定的方法；help：打印-XX： CompileCommand选项的帮助信息；inline：尝试内联指定的方法；log：排除指定方法以外的所有方法的编译日志记录（用-XX：+Log Compilation打印编译日志），默认情况下将对所有编译方法执行日志记录；option：将JIT编译选项传递给指定的方法，以代替最后一个参数（option）。编译选项设置在方法名称之后，且可指定多个编译选项，以逗号或者空格分隔；print：在编译指定的方法后打印生成的汇编代码；quiet：不打印编译命令，默认情况下，将显示使用-XX：CompileCommand选项指定的命令 |
| -XX：+DoEscapeAnalysis                        | 开启                                                     | 启用逃逸分析                                                 |
| -XX：+Inline                                  | 开启                                                     | 启用方法内敛                                                 |
| -XX：InlineSmallCode=n                        | 1000B                                                    | 指定内联的以编译的方法的最大代码大小，以字节为单位           |
| -XX：+LogCompliation                          | 关闭                                                     | 将编译活动记录到当前工作目录的hotspot.log文件中，也可用+XX：LogFile选项来指定其他日志文件路径和名称。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：MaxInlineSize=n                          | -                                                        | 设置要内联的方法的最大字节码大小，以字节为单位               |
| -XX：+PrintAssembly                           | 关闭                                                     | 打印字节码和本地方法的汇编代码，需要HSDIS的支持。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：+PrintCompaction                         | 关闭                                                     | 打印哪些方法被内联。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
|                                               |                                                          |                                                              |
| CodeCache参数                                 |                                                          |                                                              |
| -XX：ReservedCodeCacheSize=n                  | 不同版本不同，JDK 8 + 64位以及JDK 11 + 64位都是240MB     | 设置 JIT编译的代码的最大代码缓存大小，以字节为单位，最大不超过2GB，否则会产生错误。该配置不应小于-XX： InitialCodeCacheSize的值，以java -XX：PrintFlagsFianl \| grep ReservedCodeCacheSize的结果为准 |
| -XX：InitialCodeCacheSize=n                   | 不同的操作系统，以及不同的编译器的值也会不同，一般为48MB | 设置代码缓存区的初始大小，以java -XX：PrintFlagsFianl \| grep InitialCodeCacheSize的结果为准 |
| -XX：-PrintCodeCache                          | 关闭                                                     | 在JVM停止时打印代码缓存的使用情况                            |
| -XX：-PrintCodeCacheOnCompilation             | 关闭                                                     | 每当方法被编译后，就打印一下代码缓存区的使用情况             |
| -XX：+UseCodeCacheFlushing                    | 打开                                                     | 代码缓存区即将耗尽时，尝试回收一些早期编译但又很久没有被调用的方法 |
| -XX：-SegementedCodeCache                     | 关闭，表示使用整体的代码缓存区                           | 是否使用分段的代码缓存区                                     |

##### 常用高级可服务性选项

用于控制系统信息收集与调试支持。

| JVM参数                                  | 默认值                                | 作用                                                         |
| ---------------------------------------- | ------------------------------------- | ------------------------------------------------------------ |
| -XX：HeapDumpPath=path                   | -                                     | 指定堆Dump的文件路径，经常和-XX：+HeapDumpOnOutOf MemoryError选项配合使用 |
| -XX：LogFile=path                        | 在当前工作目录中创建，名为hotspot.log | 指定日志文件的路径，经常和-XX：+LogCompilation配合使用       |
| -XX：+Unlock ExperimentalVMOptions       | 关闭                                  | 用于解锁JVM实验性参数                                        |
| -XX：+UnlockDiagnosticVMOptions          | 关闭                                  | 用于解锁JVM诊断性参数                                        |
|                                          |                                       |                                                              |
| JDK 8日志参数                            |                                       |                                                              |
| -XX：+PrintFlagsInitial                  | 关闭                                  | 打印支持的高级选项，并展示默认值                             |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |
| -XX：+PrintGCCause                       | 打开                                  | 是否在GC日志中打印造成GC的原因                               |
| -XX：+PrintGCID                          | 关闭                                  | 打印垃圾GC的唯一标识                                         |
| -XX：+PrintGCDateStamps                  | 关闭                                  | 以日期的格式输出GC的时间戳，如2013-05-04T21：53：59.234+0800 |
| -XX：+PrintGCTimeStamps                  | 关闭                                  | 以基准时间的格式，打印GC时间戳                               |
| -XX：+PrintHeapAtGC                      | 关闭                                  | 在GC前后打印堆信息                                           |
| -XX：+PrintHeapAtGCExtended              | 关闭                                  | 在开启PrintHeapAtGC的前提下，额外打印更多堆的相关信息        |
| -XX：+PrintGCApplicationStoppedTime      | 关闭                                  | 打印垃圾回收期间程序暂定的时间                               |
| -XX：+PrintGCApplicationConcurrentTime   | 关闭                                  | 打印每次垃圾回收前，程序未中断的执行时间，可与PrintGCApplicationStoppedTime配合使用 |
| -XX：+PrintClassHistogramAfterFullGC     | 关闭                                  | Full GC之后打印堆的直方图                                    |
| -XX：+PrintClassHistogramBeforeFullGC    | 关闭                                  | Full GC之前打印堆的直方图                                    |
| -XX：+PrintReferenceGC                   | 关闭                                  | 打印处理引用对象的时间消耗，需开启PrintGCDetails才有效       |
| -XX：+PrintTLAB                          | 关闭                                  | 查看TLAB空间的使用情况                                       |
| -XX：-UseGCLogFileRotation               | 关闭                                  | 轮换文件，日志文件达到一定大小后，就创建一个新的日志文件。需指定-Xloggc：时才有效 |
| -XX：GCLogFileSize                       | 8KB                                   | 设置单个日志文件的大小，需开启UseGCLogFileRotation才有效     |
| -XX：NumberOfGCLogFiles                  | 0，表示保留所有日志                   | 日志轮换时，保留几个日志文件                                 |
| -Xloggc：path                            | -                                     | 指定GC日志文件路径                                           |
| -XX：+PrintAdaptiveSizePolicy            | 关闭                                  | 某些GC收集器有自适应策略，自适应调整策略会动态调整Eden、Survivor、老年代的大小。使用该标记，可打印自适应调节策略的相关信息 |
| -XX：+PrintTenuringDistribution          | 关闭                                  | 查看每次Minor GC后新的存活周期的阈值                         |
| -XX：G1PrintRegionLivenessInfo           | -                                     | 标记阶段结束后打印所有Region的存活情况，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+G1PrintHeapRegions                 | -                                     | 打印堆的区域上的分配和释放的信息，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+PrintStringDeduplicationStatistics | -                                     | JDK 8u20开始，使用G1垃圾收集器，可支持-XX：+UseStringDeduplication开启字符串去重。可用-XX：+PrintStringDeduplicationStatistics打印字符串去重的统计信息 |
|                                          |                                       |                                                              |
| JDK 11统一日志管理（只剩下两个）         |                                       |                                                              |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |

##### 常用高级垃圾收集选项

用于控制HotSpot VM如何执行垃圾收集

| 收集器                | 参数以及默认值                             | 备注                                                         |
| --------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| Serial                | -XX：+UseSerialGC                          | 虚拟机在Client模式下的默认值，开启后，使用Serial + Serial Old的组合 |
| ParNew                | -XX：+UseParNewGC                          | 开启后，使用ParNew + Serial Old的组合                        |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
| Parallel Scavenge     | -XX：+UseParallelGC                        | 虚拟机在Server模式下的默认值，开启后，使用Parallel Scavenge + Serial Old的组合 |
|                       | -XX：MaxGCPauseMillis=n                    | 收集器尽可能保证单次内存回收停顿的时间不超过这个值，但是并不保证不超过该值，只是尽可能 |
|                       | -XX：GCTimeRatio=n                         | 设置吞吐量的大小，取值范围为0~100，假设GCTimeRatio的值为n，那么系统将花费不超过1 / （1 + n）的时间用于垃圾收集 |
|                       | -XX：+UseAdaptiveSizePolicy                | 开启后，无需人工指定新生代的大小（-Xmn）、Eden和Survivor的比例（-XX：SurvivorRatio）以及晋升老年代对象的年龄（-XX：PretenureSizeThreshold）等参数，收集器会根据当前系统的运行情况自动调整 |
| Serial Old            | 无                                         | Serial Old是Serial的老年代版本，主要用于Client模式下的老年代收集，同时也是CMS在发生Concurrent Mode Failure时的后备方案 |
| Parallel Old          | -XX：+UseParallelOldGC                     | 开启后，使用Parallel Scavenge + Parallel Old的组合。Parallel Old是Parallel Scavenge的老年代版本，在注重吞吐量和CPU资源敏感的场合，可以优先考虑这个组合 |
| CMS                   | -XX：+UseConcMarkSweepGC                   | 开启后，使用ParNew + CMS的组合，Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后备收集器使用 |
|                       | -XX：CMSInitiatingOccupancyFraction=68     | CMS收集器在老年代空间被使用多少后触发垃圾收集，默认68%       |
|                       | -XX：+UseCMSCompactAtFullCollection        | 在完成垃圾收集后是否要进行一次内存碎片整理，默认开启         |
|                       | -XX：CMSFullGCsBeforeCompaction=0          | 在进行若干次Full GC后就进行一次内存碎片整理，默认为0         |
|                       | -XX：+UseCMSInitiatingOccupancyOnly        | 允许使用占用值作为启动CMS收集器的唯一标准，一般和CMSFullGCsBeforeCompaction配合使用。如果开启，那么当CMSFullGCsBeforeCompaction达到阈值就开始GC，如果关闭，那么JVM仅在第一次使用CMSFullGCsBeforeCompaction的值，后续则自动调整，默认关闭 |
|                       | -XX：+CMSParallelRemarkEnabled             | 重新标记阶段会并行执行，使用此参数可降低标记停顿，默认打开（仅适用于CMS + ParNew的GC） |
|                       | -XX：+CMSScavengeBeforeRemark              | 开启或关闭在CMS重新标记阶段之前的清除Young GC的尝试。新生代里一部分对象会作为GC Roots，让CMS在重新标记之前，做一次Young GC，而YGC能够回收掉新生代里大多数对象，这样就可以减少GC Roots的开销。因此，打开此开关，可在一定程度上降低CMS重新标记阶段的扫描时间，当然，开启此开关后，Young GC也会消耗一些时间。PS：开启此开关并不保证在标记阶段前一定会进行清除操作，生产环境建议开启，默认关闭 |
| CMS-Precleaning       | -XX：+CMSPrecleaningEnabled                | 是否启用并发预清理，默认开启                                 |
| CMS-AbortablePreclean | -XX：CMSScheduleRemarkEdenSizeThreshold=2M | 如果Eden区的内存使用超过该值，才可能进入并发可中止的预清理阶段 |
| CMS-AbortablePreclean | -XX：+CMSMaxAbortablePrecleanTime=5000     | 并发可终止的预清理阶段持续的最大时间                         |
| CMS                   | -XX：+CMSClassUnloadingEnabled             | 使用CMS时，是否启用类卸载，默认开启                          |
|                       | -XX：+ExplicitGCInvokesConcurrent          | 显示调用System.gc（）会触发Full GC，会有Stop The World，开启此参数后，可让System.gc（）触发的垃圾回收变成一次普通的CMS GC |
| G1                    | -XX：+UseG1GC                              | 使用G1收集器                                                 |
|                       | -XX：G1HeapRegionSize=n                    | 设置每个 Region的大小，该值必须为2的幂次，范围为1M到32M，如果不指定G1会根据堆的大小自动决定 |
|                       | -XX：MaxGCPauseMillis=200                  | 设置最大停顿时间，默认值为200毫秒                            |
|                       | -XX：G1NewSizePercent=5                    | 设置年轻代占整个堆的最小百分比，默认值为5，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1MaxNewSizePercent=60                | 设置年轻代占整个堆的最大百分比，默认值为60，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
|                       | -XX：ConcGCThreads=n                       | 设置垃圾收集器并发阶段使用的线程数量，设置n大约为ParallelGCThreads的1/4 |
|                       | -XX：InitiatingHeapOccupancyPercent=45     | 老年代大小达到该阈值，则会触发Mixed GC，默认值为45           |
|                       | -XX：G1MixedGCLiveThresholdPercent=85      | Region中的对象，活跃度低于该阈值，才可能被包含在Mixed GC收集周期中，默认值为85，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1HeapWastePercent=5                  | 设置浪费的堆内存百分比，当可回收百分比小于浪费百分比时，JVM就不会启动Mixed GC，从而避免昂贵的GC开销。此参数相当于用来设置允许垃圾对象占用内存的最大百分比。 |
|                       | -XX：G1MixedGCCountTarget=8                | 设置在标记周期完成之后，最多执行多少个Mixed GC，默认值为8，启动多个Mixed GC可以缩短老年代的收集时间 |
|                       | -XX：G1OldCSetRegionThresholdPercent=10    | 设置在一次Mixed GC中被收集的老年代的比例上限，默认值为Java堆的10%，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1ReservePercent=10                   | 设置预留空闲内存百分比，虚拟机会保证Java堆有这么多空间可用，从而防止对象晋升时无空间可用而失败，默认值为Java堆的10% |
|                       | -XX：G1PrintHeapRegions                    | 输出Region被分配和回收的信息，默认为false                    |
|                       | -XX：G1PrintRegionLivenessInfo             | 在清理阶段的并发标记环节，输出堆中的所有Regions的活跃度信息，默认为fasle |
| Shenandoah            | -XX：+UseShenandoahGC                      | 使用Shenandoah收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| ZGC                   | -XX：+UseZGC                               | 使用ZGC收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| Epsilon               | -XX：+UseEpsilonGC                         | 使用Epsilon收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |

### 3.4. JVM线上故障排查？

#### 如何打印JVM日志？

- JDK 8垃圾收集日志打印参数：

打印GC明细、日期、系统相对时间戳、GC的原因、GC日志存储的位置。

```java
-Xms50m -Xmx50m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -Xloggc:/Users/itmuch.com/gclog.log
```

- JDK 11垃圾收集日志打印参数：

打印GC详情、GC日志存储的位置，使用-Xlog进行统一日志管理。

```java
-Xms50m -Xmx50m -Xlog:gc*=trace:file=/Users/itmuch.com/xloggc.log
```

- JDK 8运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志。

```java
-XX:+TraceClassLoading -XX:+TraceBiasedLocking
```

- JDK 11运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志，使用-Xlog进行统一日志管理。

```java
-Xlog:class+load=debug,biasedlocking=debug:file=/Users/itmuch.com/trace.log

```

#### 如果分析GC日志？

- **自动分析GC日志工具**：

  - **GCEasy（在线）**：<https://www.gceasy.io/>。

  ![1626740104774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740104774.png)

  - **GC Viewer（老牌）**：<https://github.com/chewiebug/GCViewer>。

  ![1626740032908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740032908.png)

  - **GCPlot（很久没维护了）**：<https://github.com/GCPlot/gcplot>。

- **手工分析，格式如下**：

##### Serial GC日志

除CMS、G1 GC日志与Serial GC（Serial + Serial Old）日志不太一样外，其他的格式都是类似的。

###### JDK 8 Serial GC日志

```java
# Serial GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseSerialGC -Xmx50m -Xloggc:./gc_analysis.log

# JDK相关信息
Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)

# 内存相关信息
Memory: 4k page, physical 8266332k(2973848k free), swap 16532664k(9866032k free)

# 展示当前应用使用的JVM参数
CommandLine flags:
    -XX:-BytecodeVerificationLocal
    -XX:-BytecodeVerificationRemote
    -XX:InitialHeapSize=52428800
    -XX:+ManagementServer
    -XX:MaxHeapSize=52428800
    -XX:+PrintGC
    -XX:+PrintGCDateStamps
    -XX:+PrintGCDetails
    -XX:+PrintGCTimeStamps
    -XX:TieredStopAtLevel=1
    -XX:+UseCompressedClassPointers
    -XX:+UseCompressedOops
    -XX:-UseLargePagesIndividualAllocation
    -XX:+UseSerialGC

# 年轻代GC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:08.848+0800:
# 相对时间戳(PrintGCTimeStamps):
    3.708:
# 造成GC的原因(PrintGCCause):...:
    [GC (Allocation Failure) 2021-04-15T20:36:08.849+0800: 3.709:
# 展示DefaultNew的回收前后的内存以及年轻代总内存大小(Serial DefNew)
    [DefNew: 13696K->1663K(15360K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0099516 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13696K->2410K(49536K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0111863 secs]
# 用户、系统、实际耗时
    [Times: user=0.00 sys=0.00, real=0.01 secs]

# FullGC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:20.608+0800:
# 相对时间戳(PrintGCTimeStamps):
    15.466:
# 造成GC的原因(PrintGCCause):...:
    [Full GC (Metadata GC Threshold) 2021-04-15T20:36:20.608+0800: 15.466:
# 老年代回收之前和回收之后的内存大小以及老年代总内存大小
    [Tenured: 5749K->6890K(34176K),
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0256217 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13665K->6890K(49536K),
# 元空间回收之前和回收之后的内存大小以及元空间总内存大小
    [Metaspace: 20533K->20533K(1067008K)],
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0257088 secs]
# 用户、系统、实际耗时
    [Times: user=0.01 sys=0.00, real=0.02 secs]

```

###### JDK 11 Serial GC日志

```java
# JDK11 Serial GC收集器日志分析:

[0.104s][info][gc] Using Serial
# 内存概览: 堆内存地址、堆内存总大小、、压缩指针模式
[0.105s][info][gc,heap,coops] Heap address: 0x00000000fe200000, size: 30 MB, Compressed Oops mode: 32-bit
# 年轻代GC, 第1次回收为GC(0)
[1.846s][info][gc,start     ] GC(0) Pause Young (Allocation Failure)
# 年轻代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) DefNew: 8192K->1024K(9216K)
# 老年代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) Tenured: 0K->4482K(20480K)
# 元空间回收前后的内存以及总内存大小
[1.862s][info][gc,metaspace ] GC(0) Metaspace: 6131K->6131K(1056768K)
# 整个堆回收前后的内存以及总内存大小
[1.862s][info][gc           ] GC(0) Pause Young (Allocation Failure) 8M->5M(29M) 16.267ms
# 用户、系统、实际耗时
[1.862s][info][gc,cpu       ] GC(0) User=0.00s Sys=0.00s Real=0.02s
[4.813s][info][gc,start     ] GC(1) Pause Young (Allocation Failure)
[4.824s][info][gc,heap      ] GC(1) DefNew: 9216K->1024K(9216K)
[4.824s][info][gc,heap      ] GC(1) Tenured: 4482K->6236K(20480K)
[4.824s][info][gc,metaspace ] GC(1) Metaspace: 11473K->11473K(1060864K)
[4.824s][info][gc           ] GC(1) Pause Young (Allocation Failure) 13M->7M(29M) 11.722ms

```

##### CMS GC日志

使用ParNew + CMS的组合，Serial Old作为后备。

```java
# CMS GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -Xmx50m -Xloggc:./GC_CMS.log
# 结论: => 日志格式大体上与GC_Serial.log一致, 但增加了一些CMS的步骤描述

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3336640k free), swap 16532664k(9654484k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:MaxNewSize=17477632 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC 
2021-04-15T21:04:10.842+0800: 2.650: [GC (Allocation Failure) 2021-04-15T21:04:10.842+0800: 2.650: [ParNew: 13696K->1664K(15360K), 0.0128738 secs] 13696K->2445K(49536K), 0.0131776 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]

# 1、初始标记
2021-04-15T21:04:22.827+0800: 14.635: [GC (CMS Initial Mark) [1 CMS-initial-mark: 7035K(34176K)] 8820K(49536K), 0.0007531 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:22.827+0800: 14.636: [CMS-concurrent-mark-start]
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-mark: 0.019/0.019 secs] [Times: user=0.06 sys=0.03, real=0.02 secs]
# 3、并发预清理 -> (4、并发可中止清理)
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-preclean-start]
2021-04-15T21:04:22.848+0800: 14.656: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 5、重新标记
2021-04-15T21:04:22.848+0800: 14.656: [GC (CMS Final Remark) [YG occupancy: 2776 K (15360 K)]2021-04-15T21:04:22.848+0800: 14.656: [Rescan (parallel) , 0.0009519 secs]2021-04-15T21:04:22.849+0800: 14.657: [weak refs processing, 0.0000363 secs]2021-04-15T21:04:22.849+0800: 14.657: [class unloading, 0.0032038 secs]2021-04-15T21:04:22.853+0800: 14.660: [scrub symbol table, 0.0038571 secs]2021-04-15T21:04:22.856+0800: 14.664: [scrub string table, 0.0003238 secs][1 CMS-remark: 7035K(34176K)] 9811K(49536K), 0.0087240 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]
# 6、并发清除
2021-04-15T21:04:22.857+0800: 14.665: [CMS-concurrent-sweep-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-sweep: 0.003/0.003 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 7、并发重置
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]

# 1、初始标记
2021-04-15T21:04:27.076+0800: 18.884: [GC (CMS Initial Mark) [1 CMS-initial-mark: 21029K(34176K)] 22587K(49536K), 0.0011465 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:27.077+0800: 18.885: [CMS-concurrent-mark-start]
2021-04-15T21:04:27.113+0800: 18.921: [CMS-concurrent-mark: 0.036/0.036 secs] [Times: user=0.08 sys=0.01, real=0.04 secs]
# 3、并发预清理
2021-04-15T21:04:27.114+0800: 18.922: [CMS-concurrent-preclean-start]
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、并发可中止清理
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-abortable-preclean-start]
2021-04-15T21:04:27.282+0800: 19.090: [GC (Allocation Failure) 2021-04-15T21:04:27.282+0800: 19.090: [ParNew: 14979K->1443K(15360K), 0.0043541 secs] 36009K->22692K(49536K), 0.0044774 secs] [Times: user=0.06 sys=0.00, real=0.00 secs] 
2021-04-15T21:04:27.418+0800: 19.226: [CMS-concurrent-abortable-preclean: 0.050/0.303 secs] [Times: user=0.47 sys=0.00, real=0.30 secs]
# 5、重新标记
2021-04-15T21:04:27.418+0800: 19.226: [GC (CMS Final Remark) [YG occupancy: 8840 K (15360 K)]2021-04-15T21:04:27.418+0800: 19.226: [Rescan (parallel) , 0.0028890 secs]2021-04-15T21:04:27.421+0800: 19.229: [weak refs processing, 0.0000623 secs]2021-04-15T21:04:27.421+0800: 19.229: [class unloading, 0.0035473 secs]2021-04-15T21:04:27.425+0800: 19.233: [scrub symbol table, 0.0088034 secs]2021-04-15T21:04:27.434+0800: 19.242: [scrub string table, 0.0005316 secs][1 CMS-remark: 21248K(34176K)] 30088K(49536K), 0.0162688 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]
# 6、并发清除
2021-04-15T21:04:27.435+0800: 19.243: [CMS-concurrent-sweep-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-sweep: 0.012/0.012 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
# 7、并发重置
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]


```

##### G1 GC日志

与Serial GC、CMS GC格式差异非常大。

```java
# G1 GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseG1GC -Xmx50m -Xloggc:./GC_G1.log

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3458332k free), swap 16532664k(9495268k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:-UseLargePagesIndividualAllocation

# 年轻代G1 GC: 下面的缩进表示日志的子任务
2021-04-15T21:12:09.426+0800: 2.494: [GC pause (G1 Evacuation Pause) (young), 0.0052693 secs]
   # 并发任务解释
   [Parallel Time: 4.1 ms, GC Workers: 4]
      # GC统计
      [GC Worker Start (ms): Min: 2493.6, Avg: 2493.6, Max: 2493.6, Diff: 0.0]
      # GC扫描对象统计
      [Ext Root Scanning (ms): Min: 0.0, Avg: 0.7, Max: 1.1, Diff: 1.1, Sum: 2.7]
      # Update Remembered Sets(指保存到堆中的区域跟踪引用 -> 保存到Update Buffers更新缓存中)
      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Update Buffers数量统计
         [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0]
      # Remembered Sets扫描统计
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Code Root扫描统计
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.3]
      # 拷贝存活对象统计
      [Object Copy (ms): Min: 0.0, Avg: 2.2, Max: 3.1, Diff: 3.1, Sum: 8.6]
      # 中断统计
      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 0.6]
         # 尝试中断统计
         [Termination Attempts: Min: 1, Avg: 1.3, Max: 2, Diff: 1, Sum: 5]
      # GC线程其他工作统计
      [GC Worker Other (ms): Min: 0.0, Avg: 1.0, Max: 4.0, Diff: 3.9, Sum: 4.1]
      # GC线程总工作统计
      [GC Worker Total (ms): Min: 4.0, Avg: 4.1, Max: 4.1, Diff: 0.1, Sum: 16.3]
      # GC线程结束时间
      [GC Worker End (ms): Min: 2497.6, Avg: 2497.7, Max: 2497.7, Diff: 0.1]
   # 串行任务, 修复Code Root耗时统计
   [Code Root Fixup: 0.1 ms]
   # 串行任务, 清除Code Root耗时统计
   [Code Root Purge: 0.0 ms]
   # 清除Card Table中的Dirty Card耗时统计
   [Clear CT: 0.0 ms]
   # 其他任务
   [Other: 1.0 ms]
      # Collection Set选择区域耗时统计
      [Choose CSet: 0.0 ms]
      # 对象引用处理耗时统计
      [Ref Proc: 0.8 ms]
      # 引用队列ReferenceQueue耗时统计
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.0 ms]
      # 处理超大对象耗时统计
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      # 释放Collection Set耗时统计
      [Free CSet: 0.0 ms]
      # 各区域内存变化统计
   [Eden: 14.0M(14.0M)->0.0B(18.0M) Survivors: 0.0B->2048.0K Heap: 14.0M(50.0M)->2555.5K(50.0M)]
 # 用户、系统、实际耗时
 [Times: user=0.00 sys=0.00, real=0.01 secs]

# 最重要, 体现了G1 GC的过程
# 并发回收日志: 1、初始标记(stop the world)
2021-04-15T21:12:11.327+0800: 4.394: [GC pause (Metadata GC Threshold) (young) (initial-mark), 0.0047654 secs]
   [Parallel Time: 4.3 ms, GC Workers: 4]
      [GC Worker Start (ms): Min: 4394.3, Avg: 4394.3, Max: 4394.3, Diff: 0.0]
      [Ext Root Scanning (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.2, Sum: 4.1]
      [Update RS (ms): Min: 0.6, Avg: 0.7, Max: 0.8, Diff: 0.2, Sum: 2.7]
         [Processed Buffers: Min: 2, Avg: 3.8, Max: 7, Diff: 5, Sum: 15]
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]
      [Object Copy (ms): Min: 2.4, Avg: 2.5, Max: 2.5, Diff: 0.1, Sum: 9.9]
      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4]
      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [GC Worker Total (ms): Min: 4.2, Avg: 4.2, Max: 4.2, Diff: 0.0, Sum: 16.8]
      [GC Worker End (ms): Min: 4398.5, Avg: 4398.5, Max: 4398.5, Diff: 0.0]
   [Code Root Fixup: 0.0 ms]
   [Code Root Purge: 0.0 ms]
   [Clear CT: 0.1 ms]
   [Other: 0.4 ms]
      [Choose CSet: 0.0 ms]
      [Ref Proc: 0.2 ms]
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.1 ms]
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      [Free CSet: 0.0 ms]
   [Eden: 5120.0K(26.0M)->0.0B(26.0M) Survivors: 4096.0K->4096.0K Heap: 14.9M(50.0M)->11.3M(50.0M)]
 [Times: user=0.06 sys=0.00, real=0.01 secs]
# 开始扫描初始标记阶段Survivor区的Root Region
2021-04-15T21:12:11.332+0800: 4.399: [GC concurrent-root-region-scan-start]
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-root-region-scan-end, 0.0055232 secs]
# 2、并发标记
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-mark-start]
2021-04-15T21:12:11.352+0800: 4.419: [GC concurrent-mark-end, 0.0143048 secs]
# 3、最终标记(stop the world)
2021-04-15T21:12:11.355+0800: 4.422: [GC remark 2021-04-15T21:12:11.355+0800: 4.422: [Finalize Marking, 0.0001519 secs] 2021-04-15T21:12:11.355+0800: 4.422: [GC ref-proc, 0.0006391 secs] 2021-04-15T21:12:11.356+0800: 4.423: [Unloading, 0.0037653 secs], 0.0048311 secs]
 [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、筛选回收(stop the world)
2021-04-15T21:12:11.360+0800: 4.427: [GC cleanup 12M->12M(50M), 0.0005645 secs]
 [Times: user=0.00 sys=0.02, real=0.00 secs] 
```

#### 如何定位CPU过高的地方？

- **定位问题代码的方法**：
  - 可以使用JMC MBean服务器实时查看：但需要应用开启JMX连接。
  - **也可以使用top + jstack配合查看**：

1. top查看当前CPU占用率最高的进程，拿到占用率最高的进程号36032：

   ```java
   top
   ```

2. top -Hp查看该进程线程的运行信息，拿到占用率最高的线程号36044：

   ```java
   top -Hp 36032
   ```

3. printf得到该线程号36044的16进制数8ccc，用于搜索dump文件：

   ```java
   printf %x 36044
   ```

4. jstack dump出进程36032所有的线程栈，得到文件1.txt：

   ```java
   jstack -l 36032 > 1.txt
   ```

5. cat搜索线程栈文件1.txt，找到16进制为8ccc（即线程号为36044），并往后再搜索30行的内容：

   ```java
   cat 1.txt | grep -A 30 8ccc
   ```

6. 定位该线程中的出问题代码，并分析原因：原来是有个for循环，导致CPU过高。

```java
@Override
public void run() {
    while (true) {
        double a = Math.random() * Math.random();
        System.out.println(a);
    }
}
```

- **CPU过高的场景与解决方案**？
  - **无限while循环**：
    - 尽量避免无限循环。
    - 也可以让循环执行得慢点，比如sleep（）或者yeild（）。
  - **频繁GC**：
    - 尽量降低GC频率。
  - **频繁创建新的对象**：
    - 合理使用单例，避免频繁创建对象。
  - **频繁的线程上下文切换**：
    - 降低切换的频率，不过需要结合业务进行业务改造，而改造的难度取决于业务的复杂度。
  - 序列化和反序列化：
    - 原因：大多都是由于使用了不合理的类库导致的，比如XStream反序列化大对象，改用ObjectInputStream来解决问题。
    - 解决方案：使用合理的API来实现，选择好用的序列化与反序列化的类库。
  - 正则表达式：
    - 原因：由于正则表达式使用NFA自动机的引擎，在进行字符串匹配时会发生回溯，一旦发生回溯可能会导致CPU过高的问题。
    - 解决方案：改写正则表达式，降低回溯的发生。

#### 如何解决内存溢出问题？

##### 堆内存溢出

- **相关概念**：**堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
- **定位问题代码的方法**：

1. 指定OOM溢出后转储堆Dump：

   真实环境下，堆内存溢出很可能会导致进程直接挂掉，根本不会打印堆栈日志，所以需要JVM发生异常时自动转储出堆Dump文件，以便出现问题后能够进行分析。

   ```java
   --XX:+HeapDumpOnOutOfMemoryError
   
   
   ```

2. 在项目根目录，找到堆Dump文件，使用MAT打开堆Dump文件：

   ![1626605721295](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605721295.png)

3. 点击Leak Suspects，分析内存泄露：

   ![1626605971298](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605971298.png)

4. 查看问题对象Object[]的details，分析with incoming references，即问题对象被引用的情况：

   此外，如果Leak Suspects有堆栈信息，也可以从堆栈信息中分析问题所在。

   ![1626606234660](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626606234660.png)

5. 原来是因为无限循环插入了一堆随机String对象：

   ```java
   public class HeapOOMTest {
       private List<String> oomList = new ArrayList<>();
   
       public static void main(String[] args) {
           HeapOOMTest oomTest = new HeapOOMTest();
           while (true) {
               oomTest.oomList.add(UUID.randomUUID().toString());
           }
       }
   }
   
   ```

- **堆内存溢出的场景**？
  - **内存泄露**：
    - 可以借助MAT或者VisualVM，去查看泄露对象到对象的引用链，分析这个泄露的对象是通过哪个路径跟哪个对象关联，从而导致没有被回收掉。最后找到内存泄露对象的创建位置，优化相关的代码。
  - **存在生命周期或者数据结构不合理的对象**：
    - 更换不合理对象的生命周期或者数据结构。
  - **机器的堆内存大小设置得过小**：
    - 根据实际情况适当增大-Xms、-Xmn的值。

##### 栈内存溢出

- **相关概念**：在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。
- **定位的方法**：栈溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
- **栈内存溢出的场景**？
  - **递归调用深度过大**：
    - 原因：每递归调用一次，就会创建一个栈帧压入栈中，在栈容量有限的情况下，当容纳不了足够多的栈帧时，则会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **方法内创建过多的局部变量**：
    - 原因：局部变量存放在局部变量表中，当栈中容纳不了这么多变量时也会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **创建了过多的线程**：
    - 原因：栈是线程独享的，每个线程会创建自己的栈，当创建新线程的时候没有足够的内存去创建对应的栈，则会抛出**OutOfMemoryError**异常。
    - 解决方法：优化问题代码。
- **如何保证创建足够多的线程**？
  - **减少-Xss配置**：由于栈是线程独享的，每个线程会创建自己的栈，对于相同的内存总量，减少每个栈的大小，就可以创建更多的栈，在OOM之前就可以创建更多的线程了。
  - **增大栈能分配的内存**：尽量减少除了栈以外的内存占用，增大栈内存占用。其中公式为：
    - 栈内存 = 机器总内存 - 操作系统内存 - 堆内存 - 方法区内存 - 程序计数器内存 - 直接内存。 
  - **尽量杀死其他应用程序**：这样可以为目标应用腾出更多的内存。
  - **增大操作系统对线程数量的限制**：
    - sysctl -w kernel.threads-max：增大Linux系统支持的最大线程数（表示物理内存决定的理论系统进程数上限，一般会很大）。
    - sysctl -w kernel.pid_max：增大Linux系统限制某用户下最多可以运行多少进程或线程数。
    - sysctl -w vm.max_map_count：增大限制一个进程可以拥有的VMA(虚拟内存区域)的数量。
      - 虚拟内存区域是一个连续的虚拟地址空间区域。在进程的生命周期中，每当程序尝试在内存中映射文件，链接到共享内存段，或者分配堆空间的时候，这些区域将被创建。
    - ulimit -u：增大用户最多可启动的进程数目。

##### 方法区溢出

- **相关概念**：

  - Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。

- **定位的方法**：方法区溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。

- **方法区内存溢出分类**：

  不同的JDK版本，方法区存放的结构不同，所以相同的代码导致的内存溢出抛出的异常信息也可能不同。

  - **永久代溢出 & 堆内存溢出**：
    - 对于小于JDK 7的版本，采用的是**永久代**存储符号引用、字符串以及类的静态变量，所以小于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 7把符号引用（native heap）、字符串常量池以及类的静态变量移动到了**堆**中，所以大于等于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**堆的大小**。
  - **永久代溢出 & 元空间溢出**：
    - 对于小于JDK 8的版本，采用的是**永久代**存储类信息，所以小于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 8中使用了**元空间**替代永久代，采用运行时常量池存储已加载的类的元数据信息，所以大于等于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**元空间**的大小，而元空间是放在**本地内存**上的，只要**机器内存**足够大，理论上是很难发生溢出的。

- **方法区内存溢出的场景**？

  - **常量池对象太大**：
    - **原因**：比如字符串过多。
    - **解决方案**：根据JDK版本，为（字符串）常量池预留足够的空间。
      - < JDK 7：增大PermSize、MaxPermSize。
      - 》= JDK7：增大-Xms、-Xmx。
  - **加载的类过多**：
    - **原因**：
      - **动态代理的操作库生成了大量的动态类**：比如CXF、XSource、CGLIB等动态代理的框架，因为增强的类越多，就需要更多的空间来存储类的定义信息。
      - **JSP过多**：因为JSP是在第一次被访问的时候，才会被编译成Java类，在极端场景下，访问过多的JSP页面，可能会打满方法区导致内存溢出。
      - 脚本语言动态类加载：比如Grovy脚本出现的动态类加载导致的元空间溢出的问题。
    - **解决方案**：
      - < JDK 8：增大PermSize、MaxPermSize。
      - 》= JDK 8：可以留空元空间相关的配置（本地内存实现，不配置时JVM会动态去分配），或者设置合理的元空间大小。

##### 直接内存溢出

- **相关概念**：
  - **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，但这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。
- **定位的方法**：直接溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
  - java.lang.OutOfMemoryError：Unsafe导致直接内存溢出报错没有小尾巴。
  - java.lang.OutOfMemoryError: Direct buffer memory：ByteBuffer直接内存溢出报错是有小尾巴的。
  - **（经验之谈）如果堆Dump文件看不出问题或者太小，可考虑是直接内存溢出的问题**。
- **直接内存溢出的场景**？
  - **内存泄露多导致的内存溢出**：
    - **原因**：分配对象到直接内存后，不使用时不释放内存，然后继续分配对象，时间久了就会出现溢出问题。
    - **解决方案**：设置最大直接内存大小-XX：MaxDirectMemorySize，**对Unsafe不起作用**，但对ByteBuffer有效（会先设置long maxMemory = VM.maxDirectMemory（））。

##### 代码缓存区溢出

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。
- **定位的方法**：
  - 使用jconsole连接进程观察CodeCache。
  - 日志打印出VM warning：CodeCache is full. Compiler has been disabled信息。
  - 项目平常性能OK，但突然出现性能下降，业务又没有问题时，可排查是否由代码缓存区溢出所导致。
- **代码缓存区溢出的场景**：
  - **单体项目过于庞大但CodeCache又设置得过小**。
    - **解决方案**：
      - 可以对照jconsole设置合理的-XX：ReservedCodeCacheSize（代码缓存区的最大大小）。
      - 而对于微服务等代码量不多的小应用来说，240MB默认的CodeCache一般都是够用的了。

#### 项目越跑越慢如何定位与解决？

可能的场景有：

- **Stop The World时间过长、GC频繁**：

  - **定位方法**：检查GC日志。
  - 解决方案？：增加-XX：ParallelGCThreads并行收集的线程数、根据实际情况更换垃圾收集器。

- **项目依赖的资源导致变慢**：

  - **定位方法**：检查数据库、网络等资源是否被其他程序占用了很多。
  - 解决方案？：释放调用问题的资源。

- **CodeCache满了**：会导致JIT从编译执行退化成了解释执行。

  - **定位方法**：使用jconsole检查CodeCache大小。

- **线程争抢过于激烈**：会导致目标线程抢不到CPU片。

  - **定位方法**：使用VisualVM检查目标进程中的线程运行情况、分析ThreadDump（比如可以使用FastThread、PerfMa进行可视化分析）。
    - 结果发现：在循环中创建了一堆线程池，且使用完了又没关闭掉，导致线程池争抢激烈，消耗CPU资源严重。
    - 解决方案：使用完线程池后，在finally代码块把线程池关闭掉；同时根据业务规则命名线程（new ThreadFactoryBuilder().setNameFormat("my-thread-pool-%d")），方便以后定位问题。

- 服务器问题（了解就好）：操作系统问题、其他进程争抢资源。

  如果一个实例发生了问题，根据情况选择，要不要着急去重启。如果出现的CPU、内存飙高或者日志里出现了OOM异常**第一步是隔离**，第二步是**保留现场**，第三步才是**问题排查**。

  - **隔离**：就是把你机器从请求列表里摘除，比如把nginx相关的权重设成零。

  - **保留现场**：

    1. **系统当前网络连接**：使用 ss 命令而不是netstat的原因是：netstat 在网络连接非常多的情况下，执行非常缓慢。后续的处理，可通过查看各种网络连接状态的梳理，排查 TIME_WAIT或者CLOSE_WAIT，或者其他连接过高的问题，非常有用。

       ```shell
       ss -antp > $DUMP_DIR/ss.dump 2>&1
       ```

    2. **网络状态统计**：

       ```shell
       # 它能够按照各个协议进行统计输出，对把握当时整个网络状态，有非常大的作用。
       netstat -s > $DUMP_DIR/netstat-s.dump 2>&1
       
       # 在一些速度非常高的模块上，比如 Redis、Kafka，就经常发生跑满网卡的情况。表现形式就是网络通信非常缓慢。
       sar -n DEV 1 2 > $DUMP_DIR/sar-traffic.dump 2>&1
       ```

    3. **进程资源**：通过查看进程，能看到打开了哪些文件，可以以进程的维度来查看整个资源的使用情况，包括每条网络连接、每个打开的文件句柄。同时，也可以很容易的看到连接到了哪些服务器、使用了哪些资源。这个命令在资源非常多的情况下，输出稍慢，请耐心等待。

       ```shell
       lsof -p $PID > $DUMP_DIR/lsof-$PID.dump
       ```

    4. **CPU 资源**：主要用于输出当前系统的 CPU 和负载，便于事后排查。

       ```shell
       mpstat > $DUMP_DIR/mpstat.dump 2>&1
       vmstat 1 3 > $DUMP_DIR/vmstat.dump 2>&1
       sar -p ALL  > $DUMP_DIR/sar-cpu.dump  2>&1
       uptime > $DUMP_DIR/uptime.dump 2>&1
       ```

    5. **I/O 资源**：一般，以计算为主的服务节点，I/O 资源会比较正常，但有时也会发生问题，比如**日志输出过多，或者磁盘问题**等。此命令可以输出每块磁盘的基本性能信息，用来排查 I/O 问题。在第 8 课时介绍的 GC 日志分磁盘问题，就可以使用这个命令去发现。

       ```shell
       iostat -x > $DUMP_DIR/iostat.dump 2>&1
       ```

    6. **内存问题**：free 命令能够大体展现操作系统的内存概况，这是故障排查中一个非常重要的点，比如 SWAP 影响了 GC，SLAB 区挤占了 JVM 的内存。

       ```shell
       free -h > $DUMP_DIR/free.dump 2>&1
       ```

    7. **其他全局**：dmesg 是许多静悄悄死掉的服务留下的最后一点线索。当然，ps 作为执行频率最高的一个命令，由于内核的配置参数，会对系统和 JVM 产生影响，所以我们也输出了一份。

       ```shell
       ps -ef > $DUMP_DIR/ps.dump 2>&1
       dmesg > $DUMP_DIR/dmesg.dump 2>&1
       sysctl -a > $DUMP_DIR/sysctl.dump 2>&1
       ```

    8. **进程快照**：此命令将输出 Java 的基本进程信息，包括**环境变量和参数配置**，可以查看是否因为一些错误的配置造成了 JVM 问题。

       ```shell
       ${JDK_BIN}jinfo $PID > $DUMP_DIR/jinfo.dump 2>&1
       ```

    9. **dump堆信息**：jstat 将输出当前的 gc 信息。一般，基本能大体看出一个端倪，如果不能，可将借助 jmap 来进行分析。

       ```shell
       ${JDK_BIN}jstat -gcutil $PID > $DUMP_DIR/jstat-gcutil.dump 2>&1
       ${JDK_BIN}jstat -gccapacity $PID > $DUMP_DIR/jstat-gccapacity.dump 2>&1
       ```

    10. **堆信息**：jmap 将会得到当前 Java 进程的 dump 信息。如上所示，其实最有用的就是第 4 个命令，但是前面三个能够让你初步对系统概况进行大体判断。因为，第 4 个命令产生的文件，一般都非常的大。而且，需要下载下来，导入 MAT 这样的工具进行深入分析，才能获取结果。这是分析内存泄漏一个必经的过程。

        ```shell
        ${JDK_BIN}jmap $PID > $DUMP_DIR/jmap.dump 2>&1
        ${JDK_BIN}jmap -heap $PID > $DUMP_DIR/jmap-heap.dump 2>&1
        ${JDK_BIN}jmap -histo $PID > $DUMP_DIR/jmap-histo.dump 2>&1
        ${JDK_BIN}jmap -dump:format=b,file=$DUMP_DIR/heap.bin $PID > /dev/null  2>&1
        ```

    11. **JVM 执行栈**：

        ```shell
        # jstack 将会获取当时的执行栈。一般会多次取值，我们这里取一次即可。这些信息非常有用，能够还原 Java 进程中的线程情况。
        ${JDK_BIN}jstack $PID > $DUMP_DIR/jstack.dump 2>&1
        
        # 为了能够得到更加精细的信息，我们使用 top 命令，来获取进程中所有线程的 CPU 信息，这样，就可以看到资源到底耗费在什么地方了。
        top -Hp $PID -b -n 1 -c >  $DUMP_DIR/top-$PID.dump 2>&1
        ```

    12. **高级替补**：

        ```shell
        # 有时候，jstack 并不能够运行，有很多原因，比如 Java 进程几乎不响应了等之类的情况。我们会尝试向进程发送 kill -3 信号，这个信号将会打印 jstack 的 trace 信息到日志文件中，是 jstack 的一个替补方案。
        kill -3 $PID
        
        # 对于 jmap 无法执行的问题，也有替补，那就是 GDB 组件中的 gcore，将会生成一个 core 文件。我们可以使用如下的命令去生成 dump：
        gcore -o $DUMP_DIR/core $PID
        ${JDK_BIN}jhsdb jmap --exe ${JDK}java  --core $DUMP_DIR/core --binaryheap
        ```

    13. **内存泄漏的现象**：稍微提一下 jmap 命令，它在 9 版本里被干掉了，取而代之的是 jhsdb，你可以像下面的命令一样使用。一般内存溢出，表现形式就是 Old 区的占用持续上升，即使经过了多轮 GC 也没有明显改善。比如ThreadLocal里面的GC Roots，内存泄漏的根本就是，这些对象并没有切断和 GC Roots 的关系，可通过一些工具，能够看到它们的联系。

        ```shell
        jhsdb jmap  --heap --pid  37340
        jhsdb jmap  --pid  37288
        jhsdb jmap  --histo --pid  37340
        jhsdb jmap  --binaryheap --pid  37340
        ```

# 三、并发篇 

### 1.1. CPU、内存、外存、操作系统、应用程序、进程、线程、协程、管程、超线程？

在计算机中：

- **CPU**：是核心的硬件资源，承担所有的计算任务。
- **内存**：承担运行时数据的保存任务。
- **外存**：承担数据外部永久存储的任务，如硬盘等。
- **操作系统**：统领计算任务的调度、资源的分配。
- **应用程序**：是存放在硬盘中的可执行文件，主要包括代码指令和数据，以进程的形式运行于操作系统之上，享受操作系统提供的服务。
- **进程**：是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。
- **线程**：指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。
- **协程**：是一种比线程更加轻量级的存在，一个线程可以拥有多个协程，协程没有增加线程数量，只是在线程的
  基础之上通过**分用复用**的方式运行多个协程。
- **管程**：是管理共享变量以及对共享变量的操作过程，以让它们支持并发，是一种**进程同步互斥工具**。
- **超线程**：指**在单核CPU上可以并发AB两个线程**，如果AB资源不冲突，则AB两个线程就可以并发执行；而如果AB都在访问同一个资源，那么只能等前一个线程执行完，后一个线程才能执行。

### 1.2. 详细介绍进程的结构？

进程是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。

一般来说，一个进程由**程序段**、**数据段**和**进程控制块**三部分组成。在进程内部，代码段和数据段有自己的独立地址空间，不同进程的地址空间是相互隔离的。

- **程序段**：一般称为代码段，是进程的程序指令在内存中的位置，包含需要执行的指令集合。
- **数据段**：是进程操作数据在内存中的位置，包含需要操作的数据集合。
- **程序控制块**：Program Control Block，PCB，包含进程的描述信息和控制信息，是进程存在的唯一标志。
  - **进程的描述信息**：主要包括：
    - **进程ID**：是唯一的，代表进程的身份。
    - **进程状态**：比如运行、就绪、阻塞；
    - **进程优先级**：是进程调度的重要依据。
  - **进程的调度信息**：主要包括：
    - **程序起始地址**：即程序第一行指令的内存地址，是从这里开始程序的执行。
    - **通信信息**：进程间通信时的消息队列。
  - **进程的资源信息**：主要包括：
    - **内存信息**：内存占用情况和内存管理所用的数据结构。
    - **I/O设备信息**：所用的I/O设备编号及相应的数据结构。
    - **文件句柄**：所打开文件的信息。
  - **进程上下文**：
    - 即**进程的环境**，主要包括**执行时各种CPU寄存器的值**、**当前程序计数器（PC）的值**以及**各种栈的值**等。
    - 在操作系统切换进程时，当前进程被迫让出CPU，当前进程的上下文就保存在PCB结构中，供下次恢复运行时使用。

![1629615113218](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615113218.png)

### 1.3. 详细介绍线程的结构？

为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，进程内部演进出了并发调度的诉求，于是就发明了线程。

线程指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。

一个标准的线程主要由**线程描述信息**、**程序计数器（ProgramCounter，PC）**和**栈内存**三部分组成。

- **线程描述信息**：也即线程的基本信息，主要包括：
  - **线程ID**：Thread ID，线程标识符，是线程的唯一标识，同一个进程内不同线程的ID不会重复。
  - **线程名称**：主要是方便用户识别，用户可以指定线程的名字，如果没有指定，系统就会自动分配一个名称。
  - **线程优先级**：表示线程调度的优先级，优先级越高，获得CPU的执行机会就越大。
  - **线程状态**：表示当前线程的执行状态，为新建、就绪、运行、阻塞、结束等状态中的一种。
  - **其他信息**：比如是否为守护线程等。
- **程序计数器**：记录着线程下一条指令的代码段内存地址。
- **栈内存**：
  - 是代码段中局部变量的存储空间，为线程所独立拥有，在线程之间不共享。
  - 在JDK 1.8中，每个线程在创建时默认被分配**1MB**大小的栈内存，其中栈内存和堆内存不同，栈内存不受垃圾回收器管理。
    - 在Java中，执行程序流程的重要单位是“**方法**”，而栈内存的分配单位是“**栈帧**”（或者叫“方法帧”）。
    - 方法的每一次执行都需要为其分配一个栈帧（方法帧），栈帧主要保存该方法中的局部变量、方法的返回地址以及其他方法的相关信息。
    - 当线程的执行流程进入方法时，JVM就会为方法分配一个对应的栈帧压入栈内存；当线程的执行流程跳出方法时，JVM就从栈内存弹出该方法的栈帧，此时方法帧的局部变量的内存空间就会被回收。
    - 由于栈帧（方法帧）的操作是后进先出的模式，这也是标准的栈操作模式，因此**存放方法帧的内存也被叫作栈内存**。

![1629615141818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615141818.png)

### 1.4. 线程上下文切换？

- **线程上下文**：是指某一时刻**CPU寄存器**和**程序计数器**的内容，CPU通过时间片分配算法来循环执行线程，由于CPU时间片非常短，因此CPU需要通过不停地切换上下文以执行不同的线程。
- **上下文切换**：在当前任务执行完CPU时间片切换到另一个任务之前，操作系统会先保存该任务的状态（包括程序计数器、虚拟机栈中每个栈帧的信息），以便下次再切换回这个任务时，可以再加载这个任务的状态。这种**任务从保存到再加载的过程就是一次上下文切换**。
- **线程上下文切换的开销**：
  - **直接消耗**：指CPU寄存器需要保存和加载、系统调度器的代码需要执行、TLB实例需要重新加载等。
  - **间接消耗**：指多核的CPU高速缓存之间需要共享数据，间接对程序造成影响。
- **线程上线文切换的场景**：
  - **抢占式**：一般跟锁竞争有关，可以减少锁争用，来减少线程上下文切换。
    - **线程的CPU时间片已用完**：当前执行线程（任务）的**CPU时间片用完**之后，CPU会调度下一个线程。
  - **时间片轮转**：一般跟时间片有关，可以减少线程数，来减少线程上下文切换。
    - **线程被挂起**：比如调用了Thread#sleep、Thread#yield、Object#wait、LockSupport#park、synchronized、lock、阻塞式I/O等方法后。
- **如何减少线程上下文切换**：
  - **合理使用线程**：合理设置线程数目，避免创建不必要的线程，既可以最大化利用CPU，又可以减少线程切换的开销。
    - **高并发，低耗时的情况，**建议减少线程数。
    - **低并发，高耗时的情况**，建议增加线程数。
    - **高并发高耗时，**需要分析任务类型、增加排队、加大线程数等。
  - **减少锁争用**：通过设计算法来减少争抢锁的概率，比如JDK 7 ConcurrentHashMap中的**分段锁**，将ConcurrentHashMap分为多个段，每个段有自己的哈希表，线程只需要获取某段的分段锁，就可以操作该段的哈希表。这样保证线程安全的同时，还可以减少锁的争用，从而减少线程的上下文切换。
  - **无锁并发编程**：如CAS算法，通过自旋+CAS，不需要加锁也可以实现线程安全，其实现有Atomic包下的原子类、JDK 8 ConcurrentHashMap等。
  - 使用协程：通过线程的分用复用，在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

### 1.5. 进程与线程的区别？

|              | 线程                                                         | 进程                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 目的不同     | 为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，满足进程内部并发调度的诉求 | 用于将程序装入内存，运行程序的指令                           |
| 概念不同     | 线程是“进程代码段”的一次顺序执行流程，是CPU调度的最小单位    | 进程是程序的一次启动执行，是操作系统分配资源的最小单位，一个进程由一个或多个线程组成，一个进程至少有一个线程 |
| 共享空间不同 | 各线程之间共享进程的方法区内存、堆内存、系统资源（文件句柄、系统信号等） | 进程之间是相互独立的，但进程内部的各个线程之间并不完全独立   |
| 切换速度不同 | 线程上下文切换快                                             | 进程上下文切换慢                                             |

### 1.6. 进程的状态？

- **背景**：进程是程序的一次执行，在这个执行过程中，有时进程正在被CPU处理，有时又需要等待CPU服务，其状态会有各种变化。**为了方便对各个进程的管理**，操作系统需要将进程合理地划分为几种状态。
- **进程的几种状态**：
  - **创建态**：New，进程正在被创建，操作系统为进程分配资源、初始化PCB。
  - **就绪态**：Ready，进程已经具备运行条件，但由于没有空闲CPU，而暂时不能运行。
    - 进程处于就绪态，代表已经拥有了除处理机之外所有需要的资源，一旦获得处理机，即可立即进入运行态开始运行，即**万事俱备，只欠CPU**。
  - **运行态**：Running，进程占有CPU，并在CPU上运行。
    - 注意，单机处理机环境下，每时刻最多只有一个进程处于运行态；而双核环境下，可以同时有两个进程处于运行态。
  - **阻塞态**：Waiting/Blocked，又称等待态，进程因申请某一资源没有被分配，或者等待某一事件而暂时不能运行。
    - 比如等待操作系统分配打印机、等待读磁盘操作的结果。CPU是计算机中最昂贵的部件，为了提高CPU的利用率，需要先将其他进程需要的资源分配到位，才能得到CPU的服务。
  - **终止态**：Terminated，进程运行结束，或者由于bug导致进程无法继续执行下去（比如数组越界错误，此时需要撤销进程），此时进程需要从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。

### 1.7. 进程状态的转换？

- **创建态 -> 就绪态**：系统完成创建进程相关的工作。
- **就绪态 -> 运行态**：进程被CPU调度。
- **运行态 -> 就绪态**：进程被分配的CPU时间片到了，或者CPU被其他高优先级进程抢占了。
- **运行态 -> 阻塞态**：等待系统资源分配，或者等待某事件的发生，属于进程的**主动行为**。
- **阻塞态 -> 就绪态**：系统资源已分配到位，或者等待的事件已发生，属于进程的**被动行为**。
  - 注意，不能由阻塞态直接转换为运行态，因为需要等待CPU的调度。
  - 也不能由就绪态直接转换为阻塞态，因为进入阻塞态是进程的主动请求，必然需要进程在运行时才能发出这种请求。
- **运行态 -> 终止态**：进程运行结束，或者运行过程中遇到不可修复的错误。

![1629536288202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629536288202.png)

### 1.8. Java线程状态与状态切换？

Java线程的生命周期，即Java线程状态，线程在某时刻只能处于一种状态。注意！这些状态只为JVM虚拟机状态，不代表任何操作系统的线程状态。

- **NEW**：新建状态**（对应进程创建态）**，处于该状态的线程尚未启动。
  - new Thread（...）创建了线程，但未调用start（）启动线程时。
- **RUNNABLE**：可执行状态，该状态包含操作系统进程的就绪、运行两种状态。
  - **Ready**：就绪状态**（对应进程就绪态）**，仅仅代表当前线程具备运行的资格，如果线程没有被操作系统的调度程序挑选中，则会永远处于就绪状态。
    - Thread#start（）、线程的CPU时间片用完、Thread#sleep（long）、线程抢到对象锁（Object Monitor）、Thread#yield（）。
  - **Running**：运行状态**（对应进程运行态）**，调用Thread#run（）方法不一定会马上被并发执行，在线程获取了CPU时间片之后，才真正启动并发执行，此时线程进入运行状态。
- **BLOCKED**：阻塞状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且在线程抢到锁或者等待事件发生后，会回到就绪状态。
  - 线程阻塞等待锁、阻塞式I/O操作。
- **WAITING**：等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且需要被其他线程**显式地唤醒**，才会回到就绪状态。
  - 调用无时限的Object#wait（）、Thread#join（）、LockSupport#park（）时。
- **TIMED_WAITING**：限时等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且如果指定时间内没有被唤醒，限时等待的线程会被**系统自动唤醒**，会回到就绪状态。
  - Thread#sleep（long）、Object#wait（long）、LockSupport#park Nanos（long）、LockSupport#parkUntil（long）、Thread#join（long）。
  - 因此，对应进程状态可得出结论：进入BLOCKED状态、WAITING状态、TIMED_WAITING状态的线程，都会让出CPU的使用权，在处于等待或者阻塞状态的线程被唤醒后，才会回到就绪状态，然后需要重新获取CPU时间片才能接着运行。
- **TERMINATED**：
  - 终止状态**（对应进程终止态）**，也叫死亡状态，处于RUNNABLE状态的线程，在**Thread#run（）方法执行完成之后**，就会变成该状态。
  - 当然，如果在Thread#run（）方法执行过程中，发生了**运行时异常**而没有被捕获，Thread#run（）方法将被异常终止，线程也会变成该状态。

![1629615205233](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615205233.png)

### 1.9. 线程切换相关方法？

| 方法                            | 作用                                                         | 状态转换（JVM线程）                                          | 状态转换（进程）                    |
| ------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------- |
| Thread#start（）                | 被synchronized修饰，开始执行Thread线程，然后JVM会调用run方法 | NEW -> RUNNABLE                                              | NEW -> READY                        |
| Thread#run（）                  | 如果运行的目标任务不为null，则调用Runnable#run方法           | RUNNABLE -> TERMINATED                                       | READY -> RUNNING -> TERMINATED      |
| Thread#yiled（）                | 让步CPU，向调度程序提示，当前线程愿意放弃其当前对处理器的使用 | RUNNABLE                                                     | RUNNING -> READY                    |
| Thread#sleep（long）            | 使当前正在执行的线程休眠（暂时停止执行），且当前线程不会失去任何监视器的所有权 | RUNNABLE -> TIMED_WAITING -> RUNNABLE                        | RUNNING -> Waiting/Blocked -> READY |
| Object#wait（）                 | 需要被synchronized修饰，当前线程阻塞等待该对象调用notify、notifyAll、中断 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待锁) -> RUNNABLE    | RUNNING -> Waiting/Blocked -> READY |
| Object#wait（long）             | 需要被synchronized修饰，当前线程阻塞等待该对象调用notify、notifyAll、中断或者指定时间过去(为0时需要一直等待) | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Thread#join（）                 | 被synchronized修饰，无限等待调用线程的死亡，实质上是调用当前Thread实例的wait方法进行阻塞等待 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待锁) -> RUNNABLE    | RUNNING -> Waiting/Blocked -> READY |
| Thread#join（long）             | 被synchronized修饰，等待调用线程的死亡，实质上是调用当前Thread实例的wait方法进行阻塞等待 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#park                | 基于Linux#mutex和condition实现，无限阻塞当前线程，直到当前线程unpark被调用、被中断 | *RUNNABLE -> WAITING(唤醒后不需要等待对象锁) ->RUNNABLE*     | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#parkNanos           | 基于Linux#mutex和condition实现，在指定的等待时间内阻塞当前线程，直到当前线程unpark被调用、被中断、time时间过去 | *RUNNABLE -> TIMED_WAITING(唤醒后不需要等待对象锁) ->RUNNABLE* | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#parkUntil           | 基于Linux#mutex和condition实现，在绝对时间前阻塞当前线程, 直到当前线程unpark被调用、被中断、time时间过去 | *RUNNABLE -> TIMED_WAITING(唤醒后不需要等待对象锁) -> RUNNABLE* | RUNNING -> Waiting/Blocked -> READY |
| Condiction#await                | 基于LockSupport#park实现，当前线程阻塞等待, 直到收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待Lock锁) -> RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitUninterruptibly | 基于LockSupport#park实现，当前线程阻塞等待, 直到收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待Lock锁) -> RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#await(long)          | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitNanos           | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitUntil           | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |

### 2.0. 线程通信？

线程的通信，指当多个线程共同操作共享的资源时，线程间通过某种方式互相告知自己的状态，以避免无效的资源争夺。

- 等待 - 通知：Java中使用普遍的线程间通信方式，指的是一个线程A调用了同步对象的wait()方法进入等待状态，而另一线程B调用了同步对象的notify()或者notifyAll()方法通知等待线程，当线程A收到通知后，重新进入就绪状态，准备开始执行。
  - 线程间的通信需要借助同步对象（Object）的监视器来完成，Object对象的wait()、notify()方法就如开关信号，用于完成等待方和通知方之间的通信。
- 共享内存：见进程通信。
- 管道流：见进程通信。

### 2.1. Object#wait核心原理？

在调用同步对象的wait()和notify()系列方法时，“当前线程”必须拥有该对象的**同步锁**。

1. 当线程调用了locko（某个同步锁对象）的wait()方法后，JVM会将当前线程加入locko监视器的WaitSet（等待集），等待被其他线程唤醒。
2. 当前线程会释放locko对象监视器的Owner权利，让其他线程可以抢夺locko对象的监视器。
3. 让当前线程等待，其状态变成WAITING。

![1629677601364](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629677601364.png)

### 2.2. Object#notify核心原理？

在调用同步对象的wait()和notify()系列方法时，“当前线程”必须拥有该对象的**同步锁**。

1. 当线程调用了locko（某个同步锁对象）的notify()方法后，JVM会唤醒locko监视器WaitSet中的第一条等待线程。
2. 当线程调用了locko的notifyAll()方法后，JVM会唤醒locko监视器WaitSet中的所有等待线程。
3. 等待线程被唤醒后，会从监视器的WaitSet移动到EntryList，线程具备了排队抢夺监视器Owner权利的资格，其状态从WAITING变成BLOCKED。
4. EntryList中的线程抢夺到监视器的Owner权利之后，线程的状态从BLOCKED变成Runnable，具备重新执行的资格。

![1629677703149](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629677703149.png)

### 2.3. Object#wait与Thread#sleep的区别？

1. wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。
2. wait 方法会主动释放 monitor 锁，在同步代码中执行 sleep 方法时，并不会释放 monitor 锁。
3. wait 方法意味着永久等待（因为没带时间参数），直到被中断或被唤醒才能恢复，不会主动恢复，sleep 方法中会定义一个时间，时间到期后会主动恢复。
4. wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。

### 2.4. LockSupport#park与Thread#sleep的区别？

LockSupport.park()和Thread.sleep()方法，进入阻塞的线程**不会释放持有的锁**，因此在持有锁的时候调用该方法需要谨慎。

1. Thread.sleep()没法从外部唤醒，只能自己醒过来；而被LockSupport.park()方法阻塞的线程可以通过调用LockSupport.unpark()方法去唤醒。
2. Thread.sleep()方法声明了InterruptedException中断异常，这是一个受检异常，调用者需要捕获这个异常或者再抛出；而调用LockSupport.park()方法时不需要捕获中断异常。
3. 被LockSupport.park()方法、Thread.sleep()方法所阻塞的线程有一个特点，当被阻塞线程的Thread.interrupt()方法被调用时，被阻塞线程的中断标志将被设置，该线程将被唤醒。不同的是，二者对中断信号的响应方式不同：LockSupport.park()方法不会抛出InterruptedException异常，仅仅设置了线程的中断标志；而Thread.sleep()方法会抛出InterruptedException异常。
4. 与Thread.sleep()相比，调用LockSupport.park()能更精准、更加灵活地阻塞、唤醒指定线程。
5. Thread.sleep()本身就是一个Native方法；LockSupport.park()并不是一个Native方法，只是调用了一个Unsafe类的Native方法（名字也叫park）去实现。
6. LockSupport.park()方法还允许设置一个Blocker对象，主要用来供监视工具或诊断工具确定线程受阻塞的原因。

### 2.5. LockSupport#park与Object#wait的区别？

1. Object.wait()方法需要在synchronized块中执行；而LockSupport.park()可以在任意地方执行。
2. Object.wait()方法，进入阻塞的线程**会释放持有的锁**；而LockSupport.park()可以在任意地方执行，进入阻塞的线程**不会释放持有的锁**。
3. 当被阻塞线程被中断时，Object.wait()方法抛出了中断异常，调用者需要捕获或者再抛出；当被阻塞线程被中断时，LockSupport.park()不会抛出异常，调用时不需要处理中断异常。
4. 如果线程在没有被Object.wait()阻塞之前被Object.notify()唤醒，也就是说在Object.wait()执行之前去执行Object.notify()，就会抛出IllegalMonitorStateException异常，是不被允许的；而线程在没有被LockSupport.park()阻塞之前被LockSupport.unPark()唤醒，也就是说在LockSupport.park()执行之前去执行LockSupport.unPark()，不会抛出任何异常，是被允许的。

### 2.6. 线程中断的相关方法？

| 方法                                | 作用                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| public void interrupt()             | 1. 中断实例线程（注意！实例线程不⼀定是当前线程，⽽是指调⽤该⽅法的Thread实例所代表的线程）。2. 如果实例线程处于阻塞状态（比如调用了wait方法或者io等待时），则会立马退出阻塞，并抛出InterruptedException异常，线程就可以通过捕获InterruptedException来做一定的处理，然后线程退出。3. 如果实例线程正在运行中，实际上只是给线程设置⼀个中断标志，线程仍会继续运⾏，线程自己要在适当的位置通过调用isInterrupted方法来查看自己是否被中断，并做退出操作。4. 如果线程的interrupt方法先被调用，然后线程调用阻塞方法进入阻塞状态，InterruptedException异常依旧会抛出。5. 如果线程捕获InterruptedException异常后，继续调用阻塞方法，将不再触发InterruptedException异常。 |
| public static boolean interrupted() | 测试当前线程是否已经被中断（检查中断标志），返回⼀个boolean并清除中断状态，第⼆次再调⽤时中断状态已经被清除，将返回⼀个false。 |
| public boolean isInterrupted()      | 只测试实例线程是否被中断 ，不清除中断状态。                  |

### 2.7. 创建线程的方式？

#### 实现Runnable接口

- 优先使用。

```java
public class RunnableThread implements Runnable {
    @Override
    public void run() {System.out.println('用实现Runnable接口实现线程');}
}
```

#### 实现Callable接口

- 有返回值、可抛出异常。

```java
class CallableTask implements Callable<Integer> {
    @Override
    public Integer call() throws Exception { return new Random().nextInt();}
}
```

#### 继承Thread类

- 在不修改Thread方法情况下，不建议使用。

```java
public class ExtendsThread extends Thread {
    @Override
    public void run() {System.out.println('用Thread类实现线程');}
}
```

#### 使用线程池

- 底层都是实现Runable#run方法。

```java
static class DefaultThreadFactory implements ThreadFactory {
    
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null) ? 
            s.getThreadGroup() : Thread.currentThread().getThreadGroup();
        namePrefix = "pool-" + poolNumber.getAndIncrement() +"-thread-";
    }
    
    public Thread newThread(Runnable r) {
        Thread t = 
            new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0);
        
        if (t.isDaemon()) t.setDaemon(false);// 是否守护线程
        if (t.getPriority() != Thread.NORM_PRIORITY) 
            t.setPriority(Thread.NORM_PRIORITY);// 线程优先级
        
        return t;
    }
}
```

### 2.8. 详细介绍线程池？

#### 特点

- ThreadPoolExecutor，继承AbstractExecutorService，实现ExecutorService、Executor接口，**使用多个线程之一来执行每个提交的任务**，通常使用 {@link Executors} 工厂方法进行配置。
- **线程池优点**：
  - **降低资源消耗**：线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，通过**重复利用已创建的线程**可以降低线程创建和销毁造成的消耗。
  - **提高响应速度**：当任务到达时，可以不需要等待线程创建就能**立即执行**。
  - **提高线程的可管理性**：线程池提供了一种限制、管理资源的策略，维护一些基本的线程统计信息，如已完成任务的数量等。通过线程池可以**对线程资源进行统一的分配、监控和调优**。

#### 原理记忆图

![1629770131750](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629770131750.png)

#### 构造方法 

```java
// 线程池构造函数7大参数
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler) {
    
}
```

| 参数                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| corePoolSize             | 核心线程数                                                   |
| maximumPoolSize          | 最大线程数                                                   |
| keepAliveTime            | 空闲线程的保活时间，线程池中超过corePoolSize数目的空闲线程最大存活时间（等待任务的最长时间） |
| TimeUnit                 | 空闲线程的保活时间单位                                       |
| workQueue                | 任务阻塞队列                                                 |
| threadFactory            | 线程工厂                                                     |
| RejectedExecutionHandler | 拒绝策略处理程序，当提交任务数超过maxmumPoolSize+workQueue容量之和，或者线程池已关闭时，任务会交给拒绝策略处理程序来处理 |

#### 线程池状态

![1629772009056](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629772009056.png)

- **线程池控制状态ctl**，是一个原子整数，封装了两个概念字段：
  - workerCount，低29位，表示**有效线程数**（当前活动的线程数）。
  - runState，高3位，表示**线程池状态**，比如是否正在运行、正在关闭等。
- runState提供主要的**生命周期控制**，提供5种取值，这些值之间的数字顺序很重要，以允许进行有序比较。
  - runState取值有：
    - **RUNNING**：接受新任务并处理排队任务。
    - **SHUTDOWN**：不接受新任务，但处理排队任务。
    - **STOP**：不接受新任务，不处理排队任务，并中断正在进行的任务。
    - **TIDYING**：所有任务都已终止，workerCount 为0，转换到状态 TIDYING 的线程将运行 terminate()
      钩子方法。
    - **TERMINATED**： terminate() 钩子方法已完成.
  - runState 会随时间单调增加，但**可以不用命中每个状态**。转换有：
    - **RUNNING -> SHUTDOWN**：在调用 **shutdown()** 时，可能隐含在 finalize() 中。
    - **（RUNNING 或 SHUTDOWN）-> STOP**：在调用 **shutdownNow()** 时。
    - **SHUTDOWN -> TIDYING**：当**队列为空**且**工作线程数量为0**时。
    - **STOP -> TIDYING**：当**工作线程数量为0**时。
    - **TIDYING -> TERMINATED**：当 terminate() 钩子方法完成时。

```java
public class ThreadPoolExecutor extends AbstractExecutorService {
	// 线程池控制状态ctl, 高3位表示线程池状态, 低29位表示有效线程数, 初始为(1110, 0000, 0000, 0000, 0000, 0000, 0000, 0000) < 0
    private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
    
    // 29位
    private static final int COUNT_BITS = Integer.SIZE - 3;
    
    // 低29位存储有效线程数(约5亿个线程)
    private static final int CAPACITY   = (1 << COUNT_BITS) - 1;
    
    private static final int RUNNING    = -1 << COUNT_BITS;// 运行状态, 高3位: 111
    private static final int SHUTDOWN   =  0 << COUNT_BITS;// 关闭状态, 高3位: 000
    private static final int STOP       =  1 << COUNT_BITS;// 停止状态, 高3位: 001
    private static final int TIDYING    =  2 << COUNT_BITS;// 整理状态, 高3位: 010
    private static final int TERMINATED =  3 << COUNT_BITS;// 终止状态, 高3位: 011
}
```

#### 线程复用原理

![1629788027448](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629788027448.png)

- 线程工人类Worker：
  - 继承AQS抽象类，以实现轻量级的独占锁，用于**记录独占线程**。
  - **持有Thread引用**，在构造Worker时设置，在ThreadPoolExecutor#runWorker（）或者ThreadPoolExecutor#addWorker（）中，用于执行任务或者启动线程。
  - 持有firstTask引用，**作为第一个任务执行**，之后便从任务队列中获取任务执行了。
  - 实现Runnable接口，在线程工厂工造线程时，把**本身当做一个执行任务传入**，使其能够在ThreadPoolExecutor#addWorker（）方法中，执行完firstTask后Thread#start（）启动Worker引用的线程实例时，从而调用Worker#run（）方法。
  - Worker#run（）方法调用ThreadPoolExecutor#runWorker（）方法，在ThreadPoolExecutor#runWorker（）方法中，清空firstTask（此时firstTask肯定被执行过了），接着ThreadPoolExecutor#getTask（）**轮训获取**任务队列中的任务，然后调用Runnable#run（）方法执行任务，其中如果检测到STOP状态时，还会中断Worker持有的实例线程。
- **空闲线程淘汰原理**：
  - 在ThreadPoolExecutor#getTask（）方法中，如果线程池为SHUTDOWN状态且队列为空，或者线程池为STOP状态，或者空闲线程获取任务超时，则都会扣减ctl低29位的有效工人数量，并返回null的任务。否则阻塞获取任务。
  - 返回null的任务，在ThreadPoolExecutor#runWorker（）方法轮训被检测到，则会调用ThreadPoolExecutor#processWorkerExit（）来真实移除工人集合中的指定Worker，接着调用tryTerminate（）尝试清空线程，最后根据ctl获取当前工作线程数、核心线程数、最大核心线程数、是否允许核心线程空闲，来决定是否需要增加Worker，如果不需要则直接返回即可，如果需要则重新调用ThreadPoolExecutor#addWorker（）增加非核心线程（允许核心线程空闲也代表只有非核心线程）。
  - tryTerminate（）在线程池为STOP状态 或者 为SHUTDOWN状态且队列为空时, 如果工作线程数不为0, 则需要中断一个工作线程，如果为TIDYING状态还会调用钩子terminated()方法 ，代表线程池已终止。

```java
// 线程工人, 实现Runnable本身可以作为一个任务, 实现AQS以简化获取和释放围绕每个任务执行的锁, 实现了一个简单的不可重入互斥锁
private final class Worker extends AbstractQueuedSynchronizer implements Runnable {
    
    final Thread thread;// 该工人正在运行的线程, 如果工厂生产线程失败, 则为null
    Runnable firstTask;// 该工人要运行的初始任务, 可能会为空
    volatile long completedTasks;// worker已完成任务计数器
    
    // 注意! 在构造Worker时, 使用了当前worker实例作为Thread#Runnable实例变量, 如果运行的目标任务不为null, 则调用Runnable#run方法
    Worker(Runnable firstTask) {
        setState(-1); // inhibit interrupts until runWorker 禁止中断直到 runWorker
        this.firstTask = firstTask;
    
     // 注意! 在构造Worker时, 使用了当前worker实例作为Thread#Runnable实例变量, 如果运行的目标任务不为null, 则调用Runnable#run方法
        this.thread = getThreadFactory().newThread(this);
    }

    // 指定当前工人来运行任务: 先获取firstTask -> 从任务队列中获取任务 -> beforeExecute -> 运行获取到的任务 -> afterExecute -> 线程运行后的清理工作processWorkerExit
    public void run() {
        runWorker(this);
    }
}
```

#### 任务处理过程

![1629786785786](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629786785786.png)

1. 首先获取线程池控制位ctl，根据ctl获取当前工作线程数，如果工作线程数小于核心线程数，则使用当前任务作为firstTask创建核心线程。
2. 如果核心线程创建成功，则直接返回即可；如果核心线程创建失败，说明线程池可能是状态发生了变化，或者线程数超过了核心线程数，则需要重新获取线程池控制位ctl，再次判断。
3. 如果判断到线程池状态仍然为RUNNING，说明只是发生了线程数超过了核心线程数，这时只需要把任务追加到任务队列即可。
   1. 如果任务追加成功，为了稳重起见，重新获取线程池控制位ctl，再次判断线程池状态是否为RUNNING。
   2. 如果线程池确认仍然为RUNNING，为了保证能够有线程拉取任务，则再判断当前工作线程数是否为0，如果没有则不适用firstTask创建非核心线程；如果有则直接返回即可，代表线程池任务投递成功。
   3. 如果线程池确实不为RUNNING，则移除刚才追加的任务，然后履行拒绝策略，代表无论是SHUTDOWN还是STOP或者其他，都不接收任何新的任务了。
4. 如果判断到线程池状态不为RUNNING，或者任务追加失败，则尝试使用当前任务作为firstTask创建非核心线程。
5. 如果非核心线程创建失败，则履行拒绝策略；如果非核心线程创建成功，则直接返回即可（因为非核心线程执启动后会执行firstTask）。

```java
// 在未来的某个时间执行给定的任务, 任务可以在新线程或现有池线程中执行, 如果任务无法提交执行, 则该任务由当前 {@code RejectedExecutionHandler} 来处理
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();

    // 获取ctl控制位c
    int c = ctl.get();

    // 根据控制位ctl获取工作线程数, 如果工作线程数小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        // 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
        if (addWorker(command, true))
            // 如果启动工作线程成功, 则直接返回
            return;

        // 如果启动工作线程失败, 则重新获取ctl控制位c
        c = ctl.get();
    }

    // 如果线程池仍为运行状态, 则往任务队列填充任务command
    if (isRunning(c) && workQueue.offer(command)) {
        // 如果任务填充成功, 则再获取ctl控制位recheck
        int recheck = ctl.get();

        // 如果此时线程池不为运行状态, 则从执行程序的内部队列中删除该任务，从而导致它在尚未启动时无法运行
        if (!isRunning(recheck) && remove(command))
            // 如果删除成功, 则履行任务command和当前任务执行者executor的拒绝策略
            reject(command);
        // 如果此时线程池仍为运行状态, 但工作线程数为0, 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 如果线程池不为运行状态, 或者往任务队列填充任务command失败, 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
    else if (!addWorker(command, false))
        // 如果worker添加失败, 则履行任务command和当前任务执行者executor的拒绝策略
        reject(command);
}
```

#### 线程工厂

| 实现类                  | 特性                                                         |
| ----------------------- | ------------------------------------------------------------ |
| DefaultThreadFactory    | 默认线程工厂，创建的线程都在同一个 {@link ThreadGroup} 中，并且具有相同的 {@code NORM_PRIORITY} 优先级和非守护进程状态。 |
| PrivilegedThreadFactory | 能够继承权限的线程工厂, 创建的线程具有相同的线程上下文和类加载器 |

#### 阻塞队列

![1629788141222](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629788141222.png)

##### BlockingQueue接口实现

| 实现类                | 界限性 | 特性                                                         |
| --------------------- | ------ | ------------------------------------------------------------ |
| ArrayBlockingQueue    | 有界   | 1. 基于数组实现的有界阻塞队列。2. 初始化时必须指定容量大小。3. 一旦指定容量大小，其容量就不能修改了。 |
| LinkedBlockingQueue   | 有界   | 1. 基于单向链表实现的有界阻塞队列。2. 容量可选，空参构造时为Integer.MAX_VALUE，相当于无界队列。 |
| LinkedBlockingDeque   | 有界   | 1. 基于双向链表实现的阻塞双端队列。2. 容量可选，空参构造时为Integer.MAX_VALUE，相当于无界队列。 |
| PriorityBlockingQueue | 无界   | 1. 基于优先级堆实现的无界优先级阻塞队列。2. 允许插入NULL元素。3. 元素必须实现 Comparable接口，用于队列排队。 |
| DelayQueue            | 无界   | 1. Delayed元素（标记了给定延迟后应作用的对象）、底层依赖PriorityQueue的无界优先级队列。2. 元素必须实现Delayed接口，同时需要实现Comparable接口，一般情况下按照过期时间的优先级排序。3. 使用场景：定时关闭连接、缓存对象、超时处理 |
| DelayedWorkQueue      | 无界   | 1. ScheduledThreadPoolExecutor延迟线程池的内部类、基于小顶堆的数据结构的、专门的延迟任务队列。2. 元素需要实现RunnableScheduledFuture接口。 |
| SynchronousQueue      | 有界   | 1. 同步队列，其容量为0，不存储任何元素，每个插入操作都会阻塞等待另一个线程进行相应的删除操作才会恢复，take和put需要配对使用。2. 利用自旋 + LockSupport方式阻塞 + CAS乐观锁方式实现栈或者队列结构实现，全程没有使用悲观锁也能保证同步，吞吐量高。 |

| LinkedTransferQueue   | 无界   | 1. 基于链表实现的无界消息阻塞队列，一个新增的元素会与一个删除的空元
素配对。2. 比其他队列多了 transfer（）和tryTransfer（）方法，用于数据交换。3. 既有同步队列中生产者与消费者的特性，也包含了对高并发无锁CAS + 自旋的优化，通过跳过2个结点才更新head指针，减少一半线程的CPU自旋损耗，又利用LockSupport.park（）来实现BlockingQueue的阻塞特性，还提供了异步非阻塞、延迟消费消息的方法。 |

##### BlockingQueue接口方法

|          | 抛出异常                   | 特殊值（null或者false，取决于具体实现） | 阻塞                 | 超时                                                        |
| -------- | -------------------------- | --------------------------------------- | -------------------- | ----------------------------------------------------------- |
| **插入** | {@link #add add(e)}        | {@link #offer offer(e)}                 | {@link #put put(e)}  | {@link #offer(Object, long, TimeUnit) offer(e, time, unit)} |
| **删除** | {@link #remove remove()}   | {@link #poll poll()}                    | {@link #take take()} | {@link #poll(long, TimeUnit) poll(time, unit)}              |
| **检索** | {@link #element element()} | {@link #peek peek()}                    | 不适用               | 不适用                                                      |

#### 拒绝策略

![1629794826356](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629794826356.png)

- 当Executor已经关闭，或者当Executor对最大线程数和工作队列容量已经饱和时，在
  {@link #execute(Runnable)} 方法中提交的新任务将被 {@link RejectedExecutionHandler} 的{@link
  RejectedExecutionHandler#rejectedExecution(Runnable, ThreadPoolExecutor)} 拒绝。

| 实现类              | 特性                                                         | 优点                                                         |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| AbortPolicy         | 默认的拒绝策略，在任务被拒绝时，会抛出运行时异常             | 可以阻止系统正常运行                                         |
| CallerRunsPolicy    | 调用execute时，线程自己会去运行任务，提供了一个简单的反馈控制机制，可以减慢提交新任务的速度 | 不会造成任务丢失，同时减缓提交任务的速度，给执行任务缓冲时间 |
| DiscardPolicy       | 被拒绝时，任务会被简单地丢弃                                 | 如果允许任务丢失，这是最好的一种方案                         |
| DiscardOldestPolicy | 如果Executor没有关闭，工作队列头部的任务被丢弃，然后重试执行，但可能会再次失败，导致重复执行 | 丢弃最老的一个请求，也就是**即将被执行的任务**，并尝试再次提交当前任务 |

#### 线程池调优

##### 线程池大小设置

需要先确认任务的类型，分为CPU密集型任务、IO密集型任务、混合型任务，以下都是经验公式以及通过工具粗略计算得出的范围，而最优的参数还是需要在实际环境中**不断压测、调优**才能得到的。

- **CPU密集型任务**：
  - **概念**：CPU密集型指定的是，任务需要大量的运算，没有阻塞，CPU一直全速运行。
  - **目的**：需要尽可能少的线程数量，以减少线程上下文切换的次数，提高CPU的利用率，一般此时合理的目标线程数为（CPU核数 + 1）。
  - **经验公式**：N + 1。
- **IO密集型任务**：
  - **概念**：IO密集型指的是，任务大量时间都花在IO的阻塞上，希望的是CPU尽可能去调度其他任务，而不是等待线程，浪费CPU资源，因此需要更多的线程数以供CPU调度。
  - **目的**：需要尽可能多的线程数，但过多的线程数会带来过多的上下文切换，因此要适度，一般此时合理的目标线程数为（CPU核数 * 2）。
  - **经验公式**：2 * N。
- **混合型任务**：
  - **概念**：既有CPU密集型任务，又有IO密集型任务。
  - **经验公式**：N * U * （1 + WT / ST） = CPU核心数 * 目标CPU利用率 * （1 + 平均线程等待时间 / 平均线程运行时间），当**目标CPU利用率为100%**时，等于 CPU核心数 * （1 + 平均线程等待时间 / 平均线程运行时间）。
    - N为CPU核心数，U为目标CPU利用率，WT为线程等待时间，ST为线程运行时间。
    - 观察公式可得，**如果平均线程等待时间越长，则需要的线程数越多；如果平均线程运行时间越短，则需要的线程越少**。
  - **相关工具**：使用VisualVM观察、继承PoolSizeCalculator工具类粗略计算。

##### 阻塞队列设置

- **内存上**：估算单个任务占用内存，以及线程池计划占用内存。
- **排队策略上**：
  - **直接交接**：
    - **实现举例**：工作队列的一个很好的默认选择是 {@link SynchronousQueue}，它将任务交给线程而不用其他方式保留它们。在这里，如果没有线程可立即运行，则将任务排队的尝试将失败，因此将构
      建一个新线程。 
    - **适用场景**：在处理可能具有内部依赖性的请求集时，**可避免锁定**。
    - **缺点**：直接切换通常需要无限的maximumPoolSizes以避免拒绝新提交的任务，所以局限在于，当命
      令平均持续到达速度快于它们可以处理的速度时，可能会出现**无限线程的增长问题**。
  - **无界队列**：
    - **实现举例**：使用无界队列（如没有预定义容量的 {@link LinkedBlockingQueue}）将导致新任务在所有 corePoolSize 线程都忙时在队列中等待。因此，不会创建超过 corePoolSize 的线程，也即设置的maximumPoolSize没有任何作用。
    - **适用场景**：当**每个任务完全独立于其他任务**时，这可能是合适的，因此任务不会影响彼此的执行。例如，在网页服务器中。
    - **缺点**：虽然这种排队方式在平滑请求的**瞬时爆发**方面很有用，但局限在于，当命令的平均到达速度超
      过它们的处理速度时，**工作队列可能会无限增长**。
  - **有界队列**：
    - **实现举例**：有界队列（如{@link ArrayBlockingQueue}）在与有限的 maximumPoolSizes 一起使用。
    - **优点**：有助于**防止资源耗尽**。
    - **缺点**：可能更难以调整和控制。

##### 池大小与队列调优总结

- 当使用**有界队列**来构造**有界线程池**时，队列大小和最大池大小会**相互制衡**：
  - **使用大队列和小池**：
    - 可以最大限度地减少CPU使用率、操作系统资源和上下文切换开销。
    - 但可能会导致人为地降低吞吐量，如果任务频繁阻塞，则任务可能需要更长的响应时间。
  - **使用小队列和大池**：
    - 这会使CPU更忙，可能会遇到不可接受的线程调度开销，降低吞吐量。

#### Executors便捷构造方法

![1629794884916](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629794884916.png)

- **Executors便捷构造方法的弊端**：
  - FixedThreadPool、SingleThreadExecutor、ScheduledThreadPool、ScheduledThreadPoolExecutor：使用无界的任务队列，有可能会导致OOM。
  - CachedThreadPool、ScheduledThreadPool、ScheduledThreadPoolExecutor：使用无界的线程池，允许创建最大线程数为 Integer.MAX_VALUE，可能会导致OOM。
- **解决方案**：不建议使用Executors便捷构造，建议专门指定参数来创建线程池，底层使用有界队列以及创建有界线程池，以防止OOM。

| 方法                           | 参数                                                         | 线程池实例类型              | 特性                                                         |
| ------------------------------ | ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| newCachedThreadPool            | 0核心线程数，MAX最大线程数，60秒保活时间，同步队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 缓存型、无界线程池，会先查看线程能否复用，有就复用，没有就新建，且具有自动回收线程的功能。2. 适用于生存周期很短的异步任务，或者负载较轻的服务。 |
| newFixedThreadPool             | n核心线程数，n最大线程数，0秒保活时间，无界阻塞队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 固定大小线程池，任意时间最多只有固定数目的活动线程存在。2. 适用于线程数比较稳定的并发场景，或者执行长期的任务。 |
| newSingleThreadExecutor        | 1核心线程数，1最大线程数，0秒保活时间，无界阻塞队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 单后台线程池，任意时间最多只有一个活动线程存在，可以保证任务按照提交顺序执行。2. 适用于需要严格控制执行顺序的场景。 |
| newScheduledThreadPool         | n核心线程数，MAX最大线程数，0秒保活时间，延迟任务无界队列，默认线程工厂，拒绝时抛出异常 | ScheduledThreadPoolExecutor | 1. 调度型线程池，拥有调度能力。2. 适用于执行定时任务或者延期任务。 |
| newScheduledThreadPoolExecutor | 1核心线程数，MAX最大线程数，0秒保活时间，延迟任务无界队列，默认线程工厂，拒绝时抛出异常 | ScheduledThreadPoolExecutor | 1. 调度型线程池，拥有调度能力，但核心线程只有一个。2. 适用于执行定时任务或者延期任务。 |
| newWorkStealingPool            | 等于CPU核数的并发线程数， 默认ForkJoin线程工厂，异步模式     | ForkJoinPool                | 1. 创建一个ForkJoinPool。2. 适用于分而治之、递归计算的CPU密集型场景 |

#### 如何优雅地关闭线程池？

优雅地关闭线程池，指的是允许任务丢弃，**保证所有线程被中断退出**。

1. 使用Runtime.getRuntime（）.**addShutdownHook**（ ShutdownHookThread, Callable）注册线程池关闭任务，其任务逻辑为：
2. 先调用**shutdown（）**拒绝接收新任务，结合**awaitTermination（long）**指定估计等待时间（比如60s），同步等待线程处理任务完毕。
3. 如果awaitTermination（）返回true，可以提前返回；如果awaitTermination（）返回false，说明预估的时间到了仍然没处理完，或者抛出中断异常，说明当前等待线程中用户中断了，则调用**shutdownNow（）**拒绝处理任务队列任务。
4. 最后模仿Dubbo框架中线程池关闭源码的部分代码，补充检测线程池状态是否为TERMINATED，如果仍然没关闭，则1000次**循环awaitTermination（）等待 +  shutdownNow（）**中断所有线程，如果抛出异常则记录日志。

#### 线程池其中一个线程异常会发生什么？

##### execute调用

1. 当异常线程是被execute调用时，在ThreadPoolExecutor#runWorker（）中，如果没有实现钩子方法处理异常，则**会抛出Throwable异常**。

2. 接着调用finally块的processWorkerExit(w, completedAbruptly)方法，由于completedAbruptly为true，所以会先从工作线程集合中移除这个异常的Worker，然后重新生成一个新的Worker加入到工人集合中，**以实现替换**。

   ```java
   // 使用指定工人运行任务: 先获取firstTask -> 从任务队列中获取任务 -> beforeExecute -> 运行获取到的任务 -> afterExecute -> 线程运行后的清理工作processWorkerExit
   final void runWorker(Worker w) {
       // 获取当前线程wt， 用于运行beforeExecute方法
       Thread wt = Thread.currentThread();
   
       // 获取要运行的初始任务task
       Runnable task = w.firstTask;
       w.firstTask = null;
   
       // 先释放锁, 同步器状态从-1更改为0, 允许中断当前线程
       w.unlock(); // allow interrupts 允许中断
   
       // worker需要突然死亡
       boolean completedAbruptly = true;
       try {
           // 执行阻塞或定时等待任务, 如果需要淘汰线程, 则使用存活时间定时获取任务, 在获取不到时则标记超时等待下一轮清空多余线程; 如果不需要淘汰线程, 则阻塞获取任务
           // 通过worker里的线程启动后, 自旋获取任务队列中的任务, 实现线程复用!!! 通过存活时间、核心线程与任务队列, 控制资源消耗
           while (task != null || (task = getTask()) != null) {
               // 如果任务不为空, 则获取worker锁, 设置当前线程为独占线程
               w.lock();
   
               // 如果运行状态为停止(不接受新任务)、整理(任务终止)、终止状态(已完成), 且线程已被中断, 但当前线程中断标记位不为true, 则中断当前线程
               if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted())
                   // 中断当前线程, 如果从Thread其他实例方法调用该方法, 则会清除中断状态, 然后会收到一个{@link InterruptedException}
                   wt.interrupt();
               try {
                   // 执行任务前的钩子方法, 用于给子类实现回调
                   beforeExecute(wt, task);
   
                   // 运行任务
                   Throwable thrown = null;
                   try {
                       task.run();
                   } catch (RuntimeException x) {
                       thrown = x; throw x;
                   } catch (Error x) {
                       thrown = x; throw x;
                   } catch (Throwable x) {
                       thrown = x; throw new Error(x);
                   } finally {
                       // 执行任务后的钩子方法, 用于给子类实现回调, 该方法由执行任务的线程调用, t为执行任务期间抛出的Throwable
                       afterExecute(task, thrown);
                   }
               } finally {
                   task = null;
   
                   // 更新worker的任务完成数
                   w.completedTasks++;
   
                   // 释放锁, 同步器状态从1更改为0
                   w.unlock();
               }
           }
   
           // worker需要不突然死亡
           completedAbruptly = false;
       } finally {
           // 从工作线程集中删除线程, 并且可能会终止池或替换工作线程, 当指定的completedAbruptly为true时, 会先减少ctl工作线程数并替换工作线程
           processWorkerExit(w, completedAbruptly);
       }
   }
   
   ```

3. 此后由于没有任何程序捕获这个异常，将在ThreadGroup#uncaughtException（）中捕获到，并**打印出异常堆栈信息**。

   ```java
   // 当此线程组中的线程由于未捕获的异常而停止，并且该线程没有安装特定的 {@link Thread.UncaughtExceptionHandler} 时，由Java虚拟机调用
   public void uncaughtException(Thread t, Throwable e) {
       if (parent != null) {
           parent.uncaughtException(t, e);
       } else {
           Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler();
           if (ueh != null) {
               ueh.uncaughtException(t, e);
           } else if (!(e instanceof ThreadDeath)) {
               System.err.print("Exception in thread \"" + t.getName() + "\" ");
               e.printStackTrace(System.err);
           }
       }
   }
   
   ```

##### submit调用

1. 当异常线程是被submit调用时，同样在ThreadPoolExecutor#runWorker（）中，如果没有实现钩子方法处理异常，则**会抛出Throwable异常**。

2. 接着调用finally块的processWorkerExit(w, completedAbruptly)方法，由于completedAbruptly为true，所以会先从工作线程集合中移除这个异常的Worker，然后重新生成一个新的Worker加入到工人集合中，以**实现替换**。

3. 但在FutureTask#run（）程序中捕获到Throwable异常，并设置到Future#outcome结果中，因此并**不会打印异常堆栈信息**。

   ```java
   try {
       result = c.call();
       ran = true;
   } catch (Throwable ex) {
       result = null;
       ran = false;
   
       // 如果计算时发生异常, 则为异步计算结果设置异常结果, 并更新任务状态为已发生异常状态, 最后遍历等待线程堆栈结点, 并清空唤醒每个结点的线程, 并在完成前调用done方法触发子类的回调, 以及清空运行的任务
       setException(ex);
   }
   
   ```

### 2.9. Java对象结构？

Java对象（Object实例）结构包括三部分：**对象头、对象体和对齐字节**：

- **对象头**：
  - **Mark Word**：
    - 标记字，用于存储自身运行时的数据，例如GC标志位、哈希码、锁状态等信息。
    - 主要用于表示对象的线程锁状态，另外还可以用来配合GC存放该对象的HashCode。
  - **Class Pointer**：类对象指针，用于存放方法区Class对象的地址，虚拟机通过这个指针来确定这个对象是哪个类的实例。
  - **Array Length**：数组长度，是一个可选的字段。
    - 如果对象是一个Java数组，那么此字段必须有，用于记录数组的长度。
    - 如果对象不是一个Java数组，那么此字段不存在。
- **对象体**：
  - 包含对象的成员变量，包括父类的成员变量，其内存按4字节对齐。
- **对齐字节**：
  - 也叫填充对齐，用来保证Java对象所占内存字节数为8的倍数。
  - HotSpot VM的内存管理要求对象起始地址必须是8字节的整数倍，由于对象头本身是8的倍数，当对象的成员变量数据不是8的倍数时，则需要填充数据来保证8字节的对齐。

![1629615319144](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615319144.png)

#### Oop对象指针压缩

- Mark Word、Class Pointer、Array Length与JVM位数有关。
  - 在32位JVM中，它们为32位。
  - 在64位JVM中，它们为64位。
- 如果JVM中对象数量过多，想要节约内存，可以使用**+UseCompressedOops**开启指针压缩，开启后，以下类型的指针将会从64位压缩到32位：
  - Class对象的属性指针，即静态变量。
  - Object对象的属性指针，成员变量。
  - 普通对象数组的元素指针。
- 当然，也不是所有的指针都会压缩，一些特殊类型的指针不会被压缩，比如：
  - 指向PermGen（永久代）的Class对象指针，而在JDK 8的是指向元空间的Class对象指针。
  - 本地变量、堆栈元素、入参、返回值和NULL指针等。
- 在堆内存小于32GB的情况下，64位JVM的UseCompressedOops选项是默认开启的，表示会将原来64位的Oop对象指针压缩为32位。

### 3.0. Java内置锁原理？

#### 内置锁的Mark Word结构信息

- Java内置锁（synchronized）涉及很多重要信息，它们都存放在对象结构的对象头Mark Word字段中，其中Mark Word的位结构不会受到Oop对象指针压缩选项的影响。
- Java内置锁状态一共有4种，级别由低到高分别为：**无锁、偏向锁、轻量级锁和重量级锁**。
  - 在JDK 1.6之前，Java内置锁是一个重量级锁，效率比较低下。
  - 在JDK 1.6之后，为了提高锁的获取和释放的效率，JVM对synchronized的实现进行了优化，引入了偏向锁和轻量级锁。
  - 从此Java内置锁就有了以上4种状态，并且它们会随着竞争的情况逐渐升级，但不可降级。
  - Java内置锁的状态与Mark Word字段的结构强相关，为了让Mark Word字段存储更多的信息，JVM将Mark Word**最低两位**设置为Java内置锁状态位，不同锁状态对应着不同的Mark Word结构。
- 64位Mark Word与32位Mark Word类似，它们的结构信息如下图：
  - **lock**：锁状态标记位，2bit，占2个字节。由于Mark Word希望用尽可能少的二进制位表示尽可能多的信息，因此设置了lock标记，该值的不同则整个Mark Word表示的含义也不同。
  - **biased_lock**：对象是否启用偏向锁标记，1bit，占1个字节。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。
    - 因此，【lock，biased_lock】两个标记位组合在一起，共同表示Object实例处于什么样的锁状态。
    - 【01，0】表示无锁，【01，1】表示偏向锁，【00，无】表示轻量级锁，【10，无】表示重量级锁，【11，无】表示GC标记。
  - **age**：Java对象的分代年龄，4bit，占4个字节。在GC中，对象在Survivor区复制一次，年龄就增加1，当对象达到设定的阈值时，将会晋升到老年代。
    - 由于age只有4位，因此-XX：MaxTenuringThreshold选项最大值为15，即对象的年龄阈值为15。
  - **identity_hashcode**：hashcode，对象标识，哈希码，31bit，占31位字节。
    - 采用延迟加载技术，当调用Object.hashCode（）方法，或者System.identityHashCode（）方法，来计算对象的HashCode后，其结果将被写到该对象头中。
    - 当对象被锁定时，该值会移动到 Monitor监视器中。
  - **thread**：线程ID值，54bit，占54个字节，持有偏向锁的线程ID。
  - **epoch**：偏向时间戳，2bit，占2个字节。
  - **ptr_to_lock_record**：在轻量级锁的状态下，指向栈帧中锁记录的指针，62bit，占62个字节。
  - **ptr_to_heavyweight_monitor**：在重量级锁的状态下，指向对象监视器的指针，62bit，占62个字节。

![1629596133871](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629596133871.png)

![1629596155693](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629596155693.png)

#### 无锁

![1629597556442](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597556442.png)

无锁，即无线程竞争，在Java对象刚创建时，还没有任何线程来竞争，此时对象处于无锁状态。

- 此时，偏向标志位为0，锁状态标志位为01。

#### 偏向锁

![1629597869808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597869808.png)

偏向锁，是指一段同步代码一直被同一个线程所访问，偏向锁状态下的Mark Word会记录内置锁偏爱的线程ID，从而让内置锁认定该线程为“熟人”，从而该线程可以自动获取锁，降低获取锁的代价。

- **主要解决无竞争下的锁性能问题**：由于线程ID被记录在锁对象的Mark Word中（CAS设置），以后该线程获取锁时，只需要判断一下线程ID和标志位，就可以直接进入同步块，连CAS操作都不需要，省去了大量有关锁申请的操作，消除了无锁竞争情况下的同步原语，从而提高了程序的性能。
- **偏向锁的膨胀**：
  1. 如果偏向锁已经被A占据，一旦有第二个线程B来争抢这个对象，由于偏向锁不会主动释放，所以B看到的内置锁是偏向状态，表明已经存在了竞争，则JVM会去检查原来持有该对象锁的占有线程A是否依然存活。
  2. 如果发现A已经挂了，则将锁对象变为无锁状态，然后重新偏向B线程。
  3. 如果发现A依然存活，则会进一步检查A的调用堆栈是否有锁记录持有该偏向锁。如果存在锁记录，表明原来的线程A仍然在使用该偏向锁，即A和B此时发生了锁竞争，JVM则会撤销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。
- **偏向锁的撤销**：如果锁对象经常被多个线程竞争，那么偏向锁就是多余的，并且撤销偏向锁的过程也会带来一些性能开销。
  1. 在一个安全点停止拥有锁的线程。
  2. 遍历线程的栈帧，检查是否存在锁记录，如果存在，则需要清空**锁记录**（锁记录是线程私有的，每个线程都有自己的一份锁记录），使其变为无锁状态，并修复锁记录指向的Mark Word，清除其线程ID。
  3. 将当前锁升级为轻量级锁。
  4. 唤醒当前线程。
- **偏向锁的撤销条件**：
  - 多个线程竞争偏向锁。
  - 调用偏向锁对象的hashCode（）方法，或者System.identityHashCode（）方法，计算对象的**HashCode**之后，将哈希码放置到了Mark Word中，内置锁变成无锁状态，偏向锁会被撤销。
- 经验表明，大部分情况下一个同步代码块的线程都是同一个线程，总体来说，**使用偏向锁带来的好处大于偏向锁撤销和膨胀带来的代价**。
  - 如果某些临界区存在两个或者两个以上的线程竞争，偏向锁反而会降低性能，此时可以在启动JVM时把偏向锁的默认功能关闭。

#### 轻量级锁

![1629598045639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629598045639.png)

轻量级锁，也被成为**非阻塞同步锁、乐观锁**，是指当锁处于偏向锁，又被另一个线程企图抢占时，偏向锁就会升级为轻量级锁，而企图抢占的线程会通过**自旋**的形式尝试获取锁，不会阻塞抢锁线程，以提高性能。其中，哪个线程先占有锁对象，锁对象的Mark Word就指向哪个线程栈帧中的锁记录。

- **引入轻量级锁的主要目的**：在多线程竞争不激烈的情况下，通过CAS机制竞争锁，减少重量级锁产生的性能损耗，尽可能不动用操作系统层面的互斥锁，在应用层面上通过**自旋**来解决线程同步的问题。

  - **自旋原理**：如果持有锁的线程能在很短时间内释放锁资源，竞争等待锁的线程则不需要进行内核态和用户态的切换进入阻塞状态，它们只需要CPU自旋，等待持有锁的线程释放锁后即可立即获取锁，避免了用户线程和内核切换的消耗，从而提高性能。
  - **自旋锁分类**：
    - **普通自旋锁**：指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。
      - JDK 1.6的轻量级锁使用的是普通自旋锁，需要使用-XX：+UseSpinning选项手工开启。
      - 默认情况下，自旋次数为10次，可以通过-XX：PreBlockSpin选项来进行更改。
      - 然而，线程自旋需要消耗CPU，如果一直获取不到锁，那么线程也不能一直占用CPU自旋做无用功，因此需要设定一个自旋等待的最大时间。
    - **适应性自旋锁**：
      - JVM对于自旋周期的选择，JDK 1.7引入了**适应性自旋锁**（自动开启），指的是自旋的时间不是固定式的，而是由前一次在同一个锁上的自旋时间，以及锁的拥有者状态来决定的，解决的是**锁竞争时间不确定**的问题，使得**竞争程度趋于稳定**。
      - **自旋成功了则下次自旋的次数就会更多**：如果抢锁线程在同一个锁对象上之前成功获得过锁（竞争力强，适合竞争），JVM则会认为这次自旋很可能再次成功，此次允许自旋等待持续相对更长的时间。
      - **自旋失败了则下次自旋的次数就会减少**：如果对于某个锁，抢锁线程很少成功获得过（竞争力弱，不适合竞争），JVM则减少自旋时间甚至省略自旋过程，以避免浪费CPU资源。

- **轻量级锁的抢占过程**：

  1. 在抢锁线程进入临界区之前，如果该内置锁没有被锁定，JVM首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前Mark Word的拷贝。

     ![1629601733727](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629601733727.png)

  2. 然后，抢锁线程将使用CAS自旋操作，尝试将内置锁对象头的Mark Word的ptr_to_lock_record（锁记录指针）更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，**这个线程就拥有了对象锁**。

  3. 接着，JVM将Mark Word中的lock标记位改为00，代表该内置锁对象处于轻量级锁状态。

  4. 抢锁成功之后，JVM会将Mark Word中原来的锁对象信息（如哈希码等），保存在抢锁线程锁记录中的Displaced Mark Word字段中，再将抢锁线程中锁记录的owner指针指向锁对象。

     ![1629602512221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629602512221.png)

- **轻量级锁的膨胀**：

  - 如果临界区代码执行耗时较长，在其执行期间，其他线程都在原地CAS+自旋等待替换ptr_to_lock_record，导致一直空耗CPU，带来很大的性能损耗。
  - 而轻量级锁的本意，是**为了减少多线程进入操作系统层面互斥锁的概率**，并不是要替代其互斥锁。
  - 因此，在内置锁争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁实现的重量级锁。

#### 重量级锁

![1629599089661](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629599089661.png)

重量级锁，也称为**同步锁**，是指当锁处于轻量级锁，如果持有锁的线程执行的时间，超过了自旋等待的最大时间仍然没有释放锁，自旋等待锁的线程不会一直自旋下去，而是会进入阻塞状态，该锁也膨胀为重量级锁。

- 锁对象的Mark Word会再次发生变化，指向一个**监视器对象**，该监视器对象会用集合的形式来登记和管理排队的线程。

  - **监视器**：是一个同步工具，相当于一个许可证，拿到许可证的线程即可进入临界区进行操作，没有拿到的则需要阻塞等待。在JVM中，每个对象都关联一个监视器，监视器和对象一起创建、销毁，保证同一时间只有一个线程可以访问被保护的临界区代码。监视器也可以说是同步机制，主要特点是：
    - **同步**：监视器所保护的临界区代码互斥地执行，一个监视器是一个运行许可，任一线程进入临界区代码都需要获得这个许可，离开时会把许可归还。
    - **协作**：监视器提供Signal机制，允许正持有许可的线程暂时放弃许可进入阻塞等待状态，等待其他线程发送Signal去唤醒；其他拥有许可的线程可以发送Signal，唤醒正在阻塞等待的线程，让它可以重新获得许可并启动执行。

- 重量级锁通过**监视器**的方式，保障了任何时间只允许一个线程通过受到监视器保护的临界区代码。在Hotspot虚拟机中，监视器由C++类**ObjectMonitor**实现：

  - **_recursions**：线程的重入次数。
  - **_owner**：标识拥有该Monitor的线程，即获得锁的线程。
  - **cxq**：竞争队列，所有请求锁的线程首先会被放入这个竞争队列中。cxq由Node及其next指针逻辑构成（单向链表），并不存在一个队列的数据结构，只是一个虚拟队列：
    1. 在线程进入cxq前，抢锁线程会先尝试通过CAS自旋获取锁，如果获取不到，则会进入cxq队列，显然抢锁操作这对于那些已经进入了cxq队列的线程是不公平的，因此**synchronized同步块所使用的重量级锁是非公平锁**。
    2. 每次新加入的Node会在cxq的队头进行，通过CAS改变第一个结点的指针为新增结点，同时设置新增结点的next指向后续结点。
    3. 从cxq取出元素时，会从队尾获取。由于只有owner线程才能从队尾取出元素，即线程出列操作无争用，因此cxq是**无锁结构**。
  - **_EntryList**： 候选竞争队列，由于cxq会被线程并发访问，为了降低对cxq队尾的争用，在owner线程释放锁时，JVM会从cxq中迁移线程到EntryList中，并会指定EntryList中某个线程（一般为Head）为OnDeck Thread（Ready Thread），因此EntryList中的线程是作为候选竞争线程而存在的。
    - **OnDeck Thread**：
      - JVM不直接把锁传递给Owner Thread，而是把锁竞争的权利交给OnDeck Thread，On Deck需要重新竞争锁，这种行为称为**竞争切换**，虽然牺牲了一些公平性，但极大提升了系统的吞吐量。
      - OnDeck Thread获取到锁资源后将会变为Owner Thread，无法获得锁的OnDeck Thread则会依然留在EntryList中。
      - 另外，在OnDeck Thread成为Owner的过程中，还要一个**不公平**的事情：后来的新抢锁线程可能会直接通过CAS自旋成为Owner而获得锁。
  - **_WaitSet**：等待队列，某个拥有ObjectMonitor的线程（owner线程）在调用Object.wait（）方法之后将被阻塞，然后该线程将被放置在 _WaitSet链表中，直到某个时刻通过Object.notify（）或者Object.notifyAll（）唤醒后，该线程才会重新进入EntryList中继续候选竞争锁。

  ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

- **重量级锁性能低**：重量级锁使用了操作系统底层的互斥锁（Mutex Lock），会导致线程在**用户态和内核态之间的频繁切换**，从而带来较大的性能损耗。

  - 处于cxq、EntryList、WaitSet中的线程都处于阻塞状态，线程的阻塞或者唤醒，都需要操作系统来帮忙。比如在Linux内核中采用pthread_mutex_lock系统调用（互斥锁）来实现，因此，进程需要从用户态切换到内核态。
  - 进程从用户态切换到内核态，这种切换需要消耗很多时间，有可能比用户执行代码的时间还要长，而由于轻量级锁使用CAS进行自旋抢锁，都处于用户态下，进程不存在用户态和内核态之间的切换，因此轻量级锁开销较小，而重量级锁使用了Linux内核态下的互斥锁，会造成较大的性能开销。

#### 执行过程总结

![1629617805708](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617805708.png)

![1629617826584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617826584.png)

synchronized执行过程总结：

1. **确认是否为可偏向状态**：线程抢锁时，JVM首先检测内置锁对象Mark Word中的biased_lock（偏向锁标识）是否设置成1，lock（锁标志位）是否为01，如果都满足，则确认内置锁对象为**可偏向状态**。
2. **确认线程ID**：在内置锁对象确认为可偏向状态后， JVM会检查Mark Word中的线程ID是否为抢锁线程的ID。
3. **同线程ID，直接执行临界区代码**：如果是，则表示抢锁线程处于偏向锁状态，然后抢锁线程快速获得锁，开始执行临界区代码。
4. **竞争锁成功，升级为偏向锁**：如果Mark Word中的线程ID并未指向抢锁线程，则通过CAS操作去竞争锁。
   - 如果竞争成功，则将Mark Word中的线程ID设置为抢锁线程，偏向标志位设置为1，锁标志位设置为01，然后执行临界区代码，此时内置锁对象为**偏向锁状态**。
5. **发生锁竞争失败，偏向锁升级为轻量级锁**：如果CAS操作竞争失败，说明发生了竞争，此时JVM会去检查原先持有锁的线程是否存活。
   - 如果原线程已经死亡，则设置Mark Word为抢到锁的线程ID，内置锁继续保持为偏向锁。
   - 如果原线程没有死亡，且其堆栈中存在该内置锁的所记录，则需要撤销偏向锁，进而升级为**轻量级锁**（继续由原持有锁线程持有）。
6. **其他线程继续CAS竞争，以获取轻量级锁**：如果仍然有其他线程继续竞争轻量级锁，则在JVM将在替换锁对象Mark Word中的ptr_to_lock_record过程中，使用**CAS替换**为抢锁线程的锁记录指针。
   - 如果替换成功，则代表抢锁线程获得了**轻量级锁**。
   - 如果替换失败，表明存在其他线程竞争锁，则JVM接着尝试使用**CAS+自旋**方式来替换。
     - 如果替换成功，代表抢锁成功，则锁对象继续保持为**轻量级锁状态**。
7. **CAS+自旋失败，轻量级锁升级为重量级锁**：如果CAS+自旋替换失败，即超过了最大自旋次数，轻量级锁则升级为重量级锁，此后等待锁的线程都需要进入**阻塞状态**。

**总的来说**：

1. **偏向锁**是在没有发生锁争用的情况下使用的。
2. 一旦有了第二个线程争用锁，偏向锁则会升级为**轻量级锁**。
3. 如果锁争用很激烈，轻量级锁的CAS+自旋到达自旋阈值后，轻量级锁则会升级为**重量级锁**。

#### 适用场景总结

| 锁       | 优点                                                         | 缺点                                           | 适用场景                                 |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ---------------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比，仅存在纳秒级的差距 | 如果线程间存在锁竞争，则会带来额外的锁撤销消耗 | 适用于只有一个线程访问临界区的场景       |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 抢不到锁竞争的线程会使用CAS自旋等待，会消耗CPU | 锁占用时间很短，追求响应时间，但吞吐量低 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU                              | 使用系统互斥锁，线程阻塞，响应时间缓慢         | 吞吐量高，追求吞吐量，但锁占用时间较长   |

#### 锁消除

锁消除是指，JVM在 JIT编译时，通过对运行上下文的扫描，经过逃逸分析，去除不可能存在共享资源竞争的锁（没发生逃逸的变量作为内置锁对象时），消除没有必要的锁，节省毫无意义的锁请求时间，以提高性能。

#### 锁粗化

锁粗化是指，将多个连续的加锁和解锁操作连接在一起，扩展成一个范围更大的锁，避免频繁的加锁和解锁操作。

- **JVM默认是开启锁消除和锁粗化的**。
- 也可以通过-server -XX：-DoEscapeAnalysis -XX：-EliminateLocks来关闭锁消除和锁粗化。

### 3.1. Java锁分类？

- 显示锁分类有：可重入锁和不可重入锁、悲观锁和乐观锁、公平锁和非公平锁、可中断锁和不可中断锁、共享锁和独占锁。
- 其他锁概念有：互斥锁和读写锁、分段锁、自旋锁、偏向锁、轻量级锁、重量级锁。

#### 可重入锁和不可重入锁

- 从**同一个线程是否可以重复占有同一个锁对象**的角度来分：
  - **可重入锁**：也叫作递归锁，指的是一个线程可以**多次**抢占同一个锁。
  - **不可重入锁**：与可重入锁相反，指的是一个线程只能抢占**一次**同一个锁。
- JUC的ReentrantLock类是可重入锁的一个标准实现类，而synchronized内置锁逻辑上也是可重入的。

#### 悲观锁和乐观锁

- 从**线程进入临界区前是否锁住同步资源**的角度来分：
  - **悲观锁**：先锁再用。
    - 就是悲观思想，每次进入临界区操作数据的时候都认为别的线程会修改，所以线程每次在读写数据时都会**上锁**，锁住同步资源，这样其他线程需要读写这个数据时就会**阻塞**，一直等到拿到锁。
    - 总体来说，悲观锁适用于**写多读少**的场景，遇到**高并发写时性能高**。
  - **乐观锁**：用时检查。
    - 是一种乐观思想，每次去拿数据的时候都认为别的线程不会修改，所以**不会上锁**，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复**读-比较-写**的操作。
    - 总体来说，乐观锁适用于**读多写少**的场景，遇到**高并发写时性能低**。
    - Java中的乐观锁基本都是通过CAS自旋操作实现的，但在争用激烈的场景下，CAS自旋会出现大量的**空自旋**，会导致乐观锁性能大大降低。
- Java的synchronized轻量级锁是一种乐观锁，synchronized重量级锁、ReentrantLock是一种悲观锁。

#### 公平锁和非公平锁

- 从**线程抢占锁的机会是否公平、平等**的角度来分：
  - **公平锁**：指不同的线程抢占锁的机会是公平的、平等的，从抢占时间上来说，先对锁进行抢占的线程**一定**被先满足，抢锁成功的**次序体现为FIFO（先进先出）顺序**。简单来说，公平锁就是保障各个线程获取锁都是按照顺序来的，**先到的线程先获取锁**。
    - **优点**：所有的线程都能得到资源，不会饿死在队列中，适合大任务使用。
    - **缺点**：**吞吐量会下降**，队列里面除了第一个线程，其他的线程都会阻塞，CPU唤醒阻塞线程的开销大。
  - **非公平锁**：指不同的线程抢占锁的机会是非公平的、不平等的，从抢占时间上来说，先对锁进行抢占的线程**不一定**被先满足，抢锁成功的**次序不会体现为FIFO（先进先出）顺序**。
    - **优点**：非公平锁由于线程有机会提前插队抢锁，减少了线程挂起的概率，从而减少了一些唤醒线程的开销，**因此整体的吞吐量会比公平锁的高点**。
    - **缺点**：可能会导致线程饥饿问题，即队列中的线程可能会一直获取不到锁，或者长时间获取不到锁。
- 默认情况下，ReentrantLock实例是非公平锁，但是，如果在实例构造时传入了参数true，所得到的锁就是公平锁。另外，ReentrantLock的tryLock（）是一个特例，无论ReentrantLock实例是公平的还是非公平的，都会进行非公平的方式抢锁，即一旦有线程释放了锁，正在tryLock的线程就能优先取到锁，即使已经有其他线程在等待队列中。
- **公平锁效率低原因**：
  - 公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在等待，如果有，则要将当前线程挂起，并加到队列，由于没有抢锁机制，导致每次都要唤醒队列最前面线程，这样相比较非公平锁就多了一次**线程的挂起和唤醒**。
  - 而对于非公平锁，后来的线程**有一定几率**逃离被挂起的开销，因此减少了线程挂起和唤醒的几率，整体上提高了吞吐量。**因此整体的吞吐量会比公平锁的高点**。

#### 可中断锁和不可中断锁

- 从**线程抢锁等待时是否会响应中断**的角度来分：
  - **可中断锁**：如果某一线程A正占有锁在执行临界区代码，另一线程B正在阻塞式抢占锁，可能由于**等待时间过长**，线程B不想等待了，想先处理其他事情，我们可以让它**中断自己的阻塞等待**，这种就是可中断锁。
  - **不可中断锁**：一旦这个锁被其他线程占有，如果自己还想抢占，**只能选择等待或者阻塞**，直到别的线程释放这个锁，如果别的线程永远不释放锁，那么自己只能**永远等下去**，并且没有办法终止等待或阻塞。
- Java的synchronized内置锁就是一个不可中断锁，而JUC的显式锁（如ReentrantLock）是一个可中断锁。

#### 共享锁和独占锁

- 从**每次是否只有一个线程能持有锁**的角度来分：
  - **独占锁**：
    - 指每次**只有一个线程**能持有的锁。独占锁是一种悲观保守的加锁策略，它不必要地限制了读读竞争，如果某个只读线程获取锁，那么其他的读线程都只能等待，这种情况下就**限制了读操作的并发性**，因为读操作并不会影响数据的一致性。
    - JUC的ReentrantLock类是一个标准的独占锁实现类。
  - **共享锁**：
    - 允许**多个线程**同时获取锁，容许线程并发进入临界区。与独占锁不同，共享锁是一种乐观锁，它放宽了加锁策略，并**不限制读读竞争**，允许多个执行读操作的线程**同时访问共享资源**。
    - JUC的ReentrantReadWriteLock（读写锁）类是一个共享锁实现类。使用该读写锁时，读操作可以有很多线程一起读，但是写操作只能有一个线程去写，而且在写入的时候，别的线程也不能进行读的操作。

#### 互斥锁和读写锁

- 上面讲的共享锁和独享锁是一种广义的说法，而互斥锁与读写锁是指**具体的实现**。
- **JDK中的互斥锁和读写锁实现有**：
  - **互斥锁**：ReentrantLock。
  - **读写锁**：ReadWriteLock。
- 用ReentrantLock锁替代ReentrantReadWriteLock锁虽然可以保证线程安全，但是也会浪费一部分资源，因为多个读操作并没有线程安全问题，所以在读的地方使用ReentrantReadWriteLock读锁，在写的地方使用ReentrantReadWriteLock写锁，可以**提高程序执行效率**。

#### 偏向锁、轻量级锁和重量级锁

- 这些锁指的是**Synchronized的锁状态**，在Java 5通过引入锁升级的机制来实现高效Synchronized，详细介绍如上。
- **偏向锁**：
  - 是指一段同步代码**一直被一个线程所访问**，那么该线程会自动获取锁，从而降低获取锁的代价。
- **轻量级锁**：
  - 是指当锁是偏向锁的时候，**被另一个线程所访问**，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
- **重量级锁**：
  - 是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当**自旋一定次数**的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。
  - 重量级锁会让其他申请的线程进入阻塞，性能降低。

#### 分段锁

- 分段锁，是一种**锁的设计思想**，并不是具体的一种锁，目的是**细化锁的粒度**，对于ConcurrentHashMap而言，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作，通过分段锁的形式来实现高效的并发操作。
- ConcurrentHashMap中的分段锁称为Segment， 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的**并行插入**。

#### 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是**采用循环的方式去尝试获取锁**。

- **优点**：减少线程上下文切换的消耗。
- **缺点**：循环会消耗CPU，如果出现大量的空自旋，可能还会导致总线风暴。

##### CLH自旋锁

- CLH锁，是一种基于队列排队（单向链表）的自旋锁，由于是Craig、Landin和Hagersten三人一起发明的，因此被命名为CLH锁，也叫CLH队列锁，能够确保无饥饿性、提供先来先服务的公平性。

  - 申请线程只在本地变量上**普通自旋**，不断**轮询前驱的状态**，如果发现前驱释放了锁就结束自旋，成功获取锁。
  - 因此，在节点加入队列之后，抢锁线程不需要进行CAS自旋，只需普通自旋即可，在争用激烈的场景下，**可以大大减少CAS操作的数量，以避免CPU的总线风暴**。

- **CLH自旋锁的大致流程**：

  1. 初始状态队列尾部属性tail，指向一个EMPTY节点。
  2. 线程在抢锁时，会创建一个新的Node加入等待队列尾部，此时tail指向该Node，同时该Node的preNode属性指向tail之前指向的节点（第一个时为EMPTY节点），并且该操作是通过CAS自旋完成的，以确保操作成功。
  3. 线程加入抢锁队列之后，如果不为头结点，则会在前驱节点上自旋，循环判断前驱节点的locked属性是否为false。如果为false就表示前驱节点释放了锁，当前线程抢占到锁，当线程抢到锁之后，**其locked属性一直为true，代表正在使用锁**。
  4. 等到该线程临界区代码执行完，然后调用unlock（）方法释放锁，设置node的前驱引用为null，更新locked属性才为false，代表成功释放了锁。

  ![1630134819633](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630134819633.png)

  ![1630134919788](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630134919788.png)

- **CLH自旋锁的优缺点**：

  - **优点**：空间复杂度低，如果有N个线程、L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O(L+N)，N个线程有N个Node，L个锁有L个Tail。
  - **缺点**：在NUMA架构的CPU平台上性能很差，如果在NUMA架构上使用CLH自旋锁，每个CPU内核有自己的内存，如果前驱节点在不同的CPU内核上，且其内存位置比较远，在CLH自旋判断前驱节点的locked属性时，性能将大打折扣。而CLH锁在SMP架构的CPU平台上则不存在这个问题，性能还是挺高的。
  - **解决方案**：使用MCS队列锁来提升NUMA架构下自旋锁的性能。

##### MCS自旋锁

与CLH自旋锁最大的不同是**线程自旋的规则不同**，CLH是在前驱结点的locked域上自旋等待，而MCS是在**自己的结点的locked域上自旋等待**，从而解决了CLH在NUMA系统架构中，获取locked域状态内存过远的问题。

- **MCS自旋锁的大致流程**：

  1. 队列初始化时没有结点，tail=null。
  2. 线程A想要获取锁，于是将自己置于队尾，由于它是第一个结点，**其locked域为false，表示获得了锁**。
  3. 线程B和C相继加入队列，此时a -> next=b, b -> next=c，尾指针指向线程C对应的结点。由于B和C现在没有获取锁，处于等待状态，所以它们的locked域为true。
  4. 线程A释放锁后，顺着它的next指针找到了线程B，并把B的locked域设置为false，触发线程B获取锁。

  ![1630136366948](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630136366948.png)

### 3.2. Java锁优化？

- **系统层面上**：偏向锁、轻量级锁、重量级锁、适应性自旋锁、CLH自旋锁、MCS自旋锁、锁消除、锁粗化。
- **使用层面上**：
  - **减少锁的时间**：不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放。
  - **减少锁的粒度**：将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间，java中很多数据结构都是采用这种方法提高并发操作的效率，比如分段锁。
  - **锁粗化**：大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度，比如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的。
  - **锁分离**：使用读写锁，ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写。
  - **无锁**：使用CAS，如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用CAS效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+CAS操作会是非常高效的选择。

### 3.3. 并发编程三大问题？

要想并发程序正确地执行，必须要保证**原子性、可见性以及有序性**。只要有一个没有得到保证，就有可能会导致程序运行不正确。而由于需要尽可能释放CPU的能力，因此在CPU上不断增加内核和缓存，而随着**CPU内核和缓存的增加**，导致了并发编程的**可见性**和**有序性**问题。

#### 原子性问题

所谓原子操作，就是**不可中断的一个或一系列操作**，是指不会被线程调度机制打断的操作。这种操作一旦开始，就一直运行到结束，中间不会有任何线程的切换。

- **问题发生原因**：线程并发操作时，发生了意想不到的调度或者中断。
- **解决方案**：互斥锁、乐观锁（CAS）。
- **场景举例**：比如i++操作。

#### 可见性问题

一个线程对共享变量的修改，另一个线程能够立刻可见，我们称该共享变量具备**内存可见性**。

- **问题发生原因**：线程并发执行，**某些线程读到了没及时刷到主内存的值**，导致最后并发操作后刷回主存的值发生错误。

  - JMM（Java Memory Model，**Java内存模型**）规定，将所有的变量都存放在公共主存中，当线程使用变量时会把主存中的变量复制到自己的工作空间（或者叫私有内存）中，线程对变量的读写操作，是自己工作内存中的变量副本。

- **解决方案**：

  - 所有线程都将共享变量**刷新到主存**，比如使用Java提供的关键字volatile修饰共享变量。
  - 硬件层面可由**MESI协议**来解决。

- **场景举例**：

  1. 主存中有变量sum，初始值为0。
  2. 线程A计划将sum加1，先将sum=0复制到自己的私有内存中，然后更新sum的值。线程A操作完成之后其私有内存中sum的值为1，然而线程A将更新后的sum值回刷到主存的时间是**不固定**的。
  3. 在线程A没有回刷sum到主存前，刚好线程B同样从主存中读取sum，此时值为0，和线程A进行同样的操作，最后期盼的sum=2目标没有达成，最终sum=1。
  4. 最终导致，虽然发生了两次+1操作，但结果只增加了1，导致结果不对，原因为线程A的修改还在其工作内存中，还没有刷入主存，**对线程B不可见**，此时线程B读取到了主内存中的值并发执行了+1操作。

  ![1629965063896](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629965063896.png)

#### 有序性问题

所谓程序的有序性，是指程序**按照代码的先后顺序执行**。如果程序执行的顺序与代码的先后顺序不同，并导致了错误的结果，即发生了有序性问题。

- **问题发生原因**：发生了**指令级重排序**，虽然不会影响单个线程的执行，但是会影响多个线程并发执行的正确性。

- **解决方案**：Java中使用**volatile**关键字可以解决指令重排序的问题。

- **场景举例**：x、y赋值操作发生在a、b赋值操作之前，导致出现（0，0）的结果。

  ![1629966035812](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629966035812.png)

### 3.4. 字节序列大小端问题？

- **背景**：
  - 第一大阵营是PowerPC系列CPU，采用**大端模式**存放数据。
  - 第二大阵营是X86系列CPU，采用**小端模式**存放数据。
- **大端模式**：
  - 是指数据的**高字节保存在内存的低地址**中，而数据的**低字节保存在内存的高地址**中。
  - 大端存放模式有点类似于把数据当作字符串顺序处理：**地址由小向大增加，而数据从高位往低位放**。
  - **适用场景**：由于所有网络协议都是采用大端模式来传输数据的，因此有时也会把大端模式称为**“网络字节序”**。当两台采用不同字节存放模式的主机通信时，在发送数据之前，都必须经过字节次序转换，转成“网络字节序”（大端模式）后再进行传输。
- **小端模式**：
  - 是指数据的**高字节保存在内存的高地址**中，而数据的**低字节保存在内存的低地址**中。
  - 这种存储模式将地址的高低和数据位权有效地结合起来，**高地址部分权值高，低地址部分权值低**，此模式和日常的数字计算在方向上是一致的。
  - **适用场景**：在处理器（即CPU）的计算过程中，因为使用小端模式在数据类型转换的时候（尤其是指针转换）不用考虑地址问题，所以小端模式是**处理器的主流字节存放模式**。**JVM所采用的字节存放模式是小端模式**。

![1629896683986](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629896683986.png)

![1629896701845](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629896701845.png)

### 3.5. CPU三大架构？

- **多处理器结构**：Symmetric Multi-Processor，SMP，对称多处理器，服务器中多个CPU对称工作，每个CPU访问内存地址所需时间相同，主要特征是**共享**，包含对CPU，内存，I/O等进行共享。所有的CPU会共享一条总线，靠此总线连接主存，每个核都有自己的高速缓存，各核相对于BUS对称分布，因此，这种结构称为对称多处理器。

  - **优点**：常见的PC、手机、老式服务器都是SMP架构，其**架构简单**，但**拓展性能非常差**。
  - **缺点**：SMP能够保证内存一致性，但这些**共享的资源很可能成为性能瓶颈**，随着CPU数量的增加，每个CPU都要访问相同的内存资源，可能导致内存访问冲突，可能会导致CPU资源的浪费。

  ![1630129986362](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630129986362.png)

- **非一致存储访问结构**：Non-Uniform Memory Access，NUMA，非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个CPU组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，访问本地内存的速度将远远高于访问远地内存（系统内其它节点的内存）的速度，这也是非一致存储访问的由来。

  - **优点**：NUMA较好地解决SMP的扩展问题。
  - **缺点**：当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。

  ![1630201447035](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201447035.png)

- **海量并行处理结构**：Massive Parallel Processing，MPP，大规模并行处理，由多个 SMP 服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。

  - **优点**：每个节点只访问自己的本地资源（如内存、存储等），是一种**完全无共享**结构（节点之间数据不共享，只有通过网络连接实现的协同），因而**扩展能力最好**，理论上其扩展无限制，目前的技术可实现512个节点互联，数千个 CPU。
  - **缺点**：数据按某种规则散布到了各个节点上，**很难做高可用**；每个客户端同时连接所有节点通信，**很影响网络**。

  ![1630201176460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201176460.png)

### 3.6. CPU物理缓存架构？

- **背景**：由于CPU的运算速度比主存（物理内存）的存取速度快很多，**为了提高处理速度**，现代CPU不直接和主存进行通信，而是在CPU和主存之间设计了多层的Cache（**高速缓存**），越靠近CPU的高速缓存越快，容量也越小。
- **CPU高速缓存结构**：
  - L1高速缓存和L2高速缓存只能被一个单独的CPU内核使用，容量最小，速度最快。
    - L1高速缓存最接近CPU，容量最小（如32KB、64KB等）、存取速度最快，每个核上都有一个L1高速缓存。
    - ·L2高速缓存容量更大（如256KB）、速度低些，在一般情况下，每个内核上都有一个独立的L2高速缓存。
  - L3高速缓存被同一个CPU芯片上的所有CPU内核共享。
    - L3高速缓存最接近主存，容量最大（如12MB）、速度最低，由在同一个CPU芯片板上的不同CPU内核共享。
  - 主存由系统中的所有CPU共享，容量最大，速度最慢。

![1629962629036](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629962629036.png)

- **缓存命中过程**：
  1. CPU内核读取数据时，先从L1高速缓存中读取。
  2. 如果没有命中，再到L2、L3高速缓存中读取。
  3. 假如这些高速缓存都没有命中，则会到主存中读取所需要的数据。
- **CPU处理过程**：
  1. 先将计算需要用到的数据缓存在CPU的高速缓存中。
  2. 在CPU进行计算时，直接从高速缓存中读取数据。
  3. 在计算完成之后写回高速缓存中。
  4. 在整个运算过程完成后，再把高速缓存中的数据同步到主存。
- **高速缓存优点**：
  - 写缓冲区可以保证指令流水线持续运行，可以避免由于CPU停顿下来等待向内存**写入数据而产生的延迟**。
  - 通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，**减少对内存总线的占用**。

### 3.7. MESI缓存一致性协议？

硬件层的MESI协议是一种用于解决内存可见性问题的手段，其中，CPU主要提供了两种解决办法：**总线锁和缓存锁**。

#### 总线锁

- **背景**：操作系统提供了总线锁机制。线程总线（也叫CPU总线）是所有CPU与芯片组连接的主干道，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送控制信号，通过地址总线发送地址信号指定其要访问的部件，通过数据总线实现双向传输。

- **概念**：总线锁的意思是，在线程总线中加入一把锁，当不同的CPU内核访问同一个缓存行时，只允许一个CPU内核进行读取，该CPU内核将**独享共享内存**。

  1. 在CPU内核1要对a执行访问操作的时候，将在总线上发出一个LOCK#信号，使得其他CPU无法通过总线来访问共享主存中的数据，把CPU和主存之间的通信锁住，从而锁住变量a所在的缓存行。
  2. 这样其他CPU内核就不能操作缓存，从而阻塞其他CPU内核，使CPU内核1可以独享此共享内存，即总线被锁住，得等CPU内核1访问完，CPU内核2才能访问b。

  ![1629969079553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629969079553.png)

- **缺点**：某一个CPU**访问主存**时，总线锁把CPU和主存的通信给锁住了，其他CPU不能操作其他主存地址的数据，使得**效率低下，开销较大**。

#### 缓存锁

- **背景**：总线锁的粒度太大了，最好的方法就是**控制锁的保护粒度**，只需要保证被多个CPU缓存的同一份数据一致即可。所以引入了缓存锁（如缓存一致性机制），后来的CPU都提供了缓存一致性机制，Intel 486之后的处理器就提供了这种优化。
- **概念**：
  - 相比总线锁，**缓存锁降低了锁的粒度**，实现对共享内存的独占性访问，缓存锁（缓存一致性协议）会阻止两个CPU同时修改共享内存的数据。
  - 为了达到数据访问的一致，需要各个CPU在访问高速缓存时遵循一些协议，在存取数据时根据协议来操作，常见的协议有**MSI、MESI、MOSI**等，最常见的就是MESI协议。

#### 缓存一致性机制

缓存一致性机制就是，当某CPU对高速缓存中的数据进行操作之后，通知其他CPU将放弃存储在它们内部的缓存数据，或者从主存中重新读取。

#### 缓存一致性协议

- **背景**：在多CPU的系统中，为了保证各个CPU的高速缓存中数据的一致性，会实现缓存一致性协议，每个CPU通过嗅探在总线上传播的数据来检查自己的高速缓存中的值是否过期，当CPU发现自己缓存行对应的主存地址被修改时，就会将当前CPU的缓存行设置成**无效状态**，当CPU对这个数据执行修改操作时，会重新从系统主存中把数据读到CPU的高速缓存中。
- **高速缓存副本一致性写入模式**：
  - **直写模式**：Write-Through，在数据更新时，同时写入低一级的高速缓存和主存。
    - **优点**：操作简单，因为所有的数据都会更新到主存，所以其他CPU读取主存时都是最新值。
    - **缺点**：数据写入速度较慢，因为数据修改之后需要同时写入低一级的高速缓存和主存。
  - **回写模式**：Write-Back，数据的更新并不会立即反映到主存，而是只写入高速缓存，只在数据被**替换出高速缓存或者变成共享（S）状态**时，如果发现数据有变动，才会将最新的数据更新到主存。
    - **优点**：数据写入速度快，因为发生数据变动时不需要写入主存，所以这种模式占用总线少，**大多数CPU的高速缓存采用这种模式**。
    - **缺点**：实现一致性协议比较复杂，因为最新值可能存放在私有高速缓存中，而不是存放在共享的高速缓存或者主存中。
- **主要实现**：MSI协议、MESI协议等。

##### MSI协议

MSI协议，也叫作**写入失效协议**，采用的是**缓存回写模式**，是缓存一致性协议的基础版本。

1. c1和c2先后读取主存中的同一变量m值0。
2. c1更新m值为1后，并不会更新主存，而是通知c2使其高速缓存中的变量m失效。
3. 在c2第二次读取m时，c1会将m的最新值返回给c2，并且更新主存中m值，此时c1和c2的m值会变成共享状态，且等于主存中的m值。

![1629978291010](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629978291010.png)

##### MESI协议

MESI协议，是MSI协议的扩展，要求在每个**缓存行**（64字节，高速缓存操作的基本单位）维护两个状态位（2bit），使得每个数据位可能处于**M、E、S和I**这4种状态之一，是一种基于过期机制的高速缓存一致性保障协议。

- **MESI状态**：

  - **M：Modified**，被修改，处于Modified状态的缓存行数据只在本CPU中有缓存，且其数据与主存中的数据不一致，数据被修改过。
    1. 该缓存行的数据只在本CPU的私有高速缓存中进行了缓存，而**其他CPU中没有**，是被修改过的（Dirty），即**与主存中的数据不一致**，且没有更新到内存中。
    2. 该缓存行中的内存需要在未来的某个时间点（允许其他CPU读取主存中相应的数据之前）写回（Write Back）主存，当被写回主存之后，该缓存行的状态会变成**独享状态**。
  - **E：Exclusive**，独享的，处于Exclusive状态的缓存行数据只在本CPU中有缓存，且其数据与内存中一致，没有被修改过。
    1. 该缓存行的数据只在本CPU的私有高速缓存中进行了缓存，而**其他CPU中没有**，缓存行的数据是未被修改过的（Clean），并且**与主存中的数据一致**。
    2. 该状态下的缓存行在任何时刻被其他CPU读取之后，其状态将变成**共享状态**。
    3. 在本CPU修改了缓存行中的数据后，该缓存行的状态可以变成**Modified状态**。
  - **S：Shared**，共享的，处于Shared状态的缓存行的数据在多个CPU中都有缓存，且与主存一致。
    1. 该缓存行的数据可能在**本CPU以及其他CPU**的私有高速缓存中进行了缓存，并且各CPU私有高速缓存中的数据**与主存数据一致**（Clean）。
    2. 当有一个CPU修改该缓存行时，其他CPU中该缓存行将被作废，变成**无效状态**。
  - **I：Invalid**，无效的，该缓存行是**无效的**，可能有其他CPU修改了该缓存行。

- **MESI状态转换过程**：

  1. **初始阶段**：开始时，缓存行没有加载任何数据，所以它处于“**I状态**”。
  2. **本地写阶段**：Local Write，如果CPU内核写数据到处于“I状态”的缓存行，缓存行的状态就变成“**M状态**”。
     - 注意：处于“M状态”的缓存行，再由本地CPU写入或者读出，状态是不会改变的。
  3. **本地读阶段**：Local Read，如果本地CPU读取处于“I状态”的缓存行，很明显此缓存没有数据给它。此时分两种情况：
     - ①其他CPU的高速缓存中也没有此行数据，那么从内存加载数据到此缓存行后，将它设成“**E状态**”，表示只有本CPU有此行数据，其他CPU都没有；
     - ②其他CPU的高速缓存有此行数据，就将此缓存行的状态设为“**S状态**”。
  4. **远程读阶段**：Remote Read，假设我们有两个CPU c1和c2，如果c2需要读c1的缓存行内容，c1需要把它的缓存行内容通过主存控制器（MemoryController）发送给c2，c2接收到后将相应的缓存行状态设为“**S状态**”。在设置之前，**主存要从总线上得到这份数据并保存**。
  5. **远程写阶段**：Remote Write，其实确切地说不是远程写，而是c2得到c1的数据后，不是为了读，而是为了写，**也算是本地写**。此时由于本来数据就是从c1那里拷贝过来的，此时c2需要发出一个**RFO（Request For Owner）请求**，说明它需要拥有这行数据的权限，此后其他CPU的相应缓存行设为“**I状态**”，从而保证了数据的安全，但处理RFO请求以及设置“I状态”的过程将给写操作带来**很大的性能消耗**。

  ![1629980427644](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629980427644.png)

#### 总线风暴

CPU会通过MESI协议保障变量的缓存一致性，为了保障“缓存一致性”，不同的内核需要通过总线**来回通信**，因而所产生的流量一般被称为“**缓存一致性流量**”，而由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将成为瓶颈，这就是所谓的**总线风暴**。

- 总线风暴与CPU的架构和设计有关，并不是所有的CPU都会产生总线风暴，由于使用lock前缀指令的Java操作（包括CAS、volatile）恰恰会产生缓存一致性流量，**当有很多线程同时执行lock前缀指令操作时，在SMP架构的CPU平台上必然会导致总线风暴**。

### 3.8. 详细介绍Unsafe？

- Unsafe是位于sun.misc包下的一个类，主要提供一些用于**执行低级别、不安全的底层操作**，如**直接访问系统内存资源、自主管理内存资源**等。

- Unsafe类的全限定名为sun.misc.Unsafe，从名字中可以看出这个类对普通程序员来说是“危险”的，一般的应用开发都不会涉及此类，**Java官方也不建议直接在应用程序中使用这些类**。

  - 由于使用Unsafe类可以像C语言一样使用**指针操作内存空间**，这无疑增加了指针相关问题、内存泄漏问题出现的概率。

  - 总之，在程序中过度使用Unsafe类会使得程序出错的概率变大，使得安全的语言Java变得**不再安全**，因此对Unsafe的使用一定要慎重。

  - **Unsafe实例获取方式**：

    ```java
    // 不受信任的代码, 只能通过反射获取Unsafe类并通过其分配直接内存
    Field unsafeField = Unsafe.class.getDeclaredFields()[0];
    unsafeField.setAccessible(true);
    Unsafe unsafe = (Unsafe) unsafeField.get(null);
    
    ```

- Unsafe大量的方法都是native方法，基于C++语言实现，这些方法在**提升Java运行效率、增强Java语言底层资源操作能力**方面起到了很大的作用。

#### 操作Java变量方法

- **getObject(Object o, long offset)**：根据对象和64位地址偏移量, 获取某个Object类型Java变量的值。
- **putObject(Object o, long offset, Object x)**：根据对象和64位地址偏移量, 将x值存储到Java变量中, 其字段类型必须为Object类型。
- **staticFieldOffset(Field f)**：返回给定静态字段的位置, 任何给定的字段将始终具有相同的偏移量, 并且同一类的两个不同字段永远不会具有相同的偏移量和基数。
- **objectFieldOffset(Field f)**：返回给定字段在其类的存储分配中的位置, 任何给定的字段将始终具有相同的偏移量, 并且同一类的两个不同字段永远不会具有相同的偏移量和基数。
- **staticFieldBase(Field f)**：获取给定静态字段的基本“对象”(可能引用一个对象, 它是一个“cookie”, 不能保证是一个真正的对象, 它不应该以任何方式使用, 除了作为此类中get和put例程的参数), 如果有的话,可以通过 {@link #getInt(Object, long)} 之类的方法访问给定类的静态字段。
- **arrayBaseOffset(Class<?> arrayClass)**：返回给定数组Class的存储分配中第一个元素的偏移量。

#### 操作类和对象方法

- **defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain)**：告诉VM定义一个类。
- **allocateInstance(Class<?> cls)**：分配一个实例，但不运行任何构造函数。如果尚未初始化类，则初始化该类。

#### 操作C堆方法

- **getByte(long address)**：从给定的内存地址获取一个值。
- **putByte(long address, byte x)**：将值存储到给定的内存地址中。
- **getAddress(long address)**：从给定的内存地址获取本地指针。
- **putAddress(long address, long x)**：将本地指针存储到给定的内存地址。

#### 分配内存方法

- **allocateMemory(long bytes)**：分配一个新的本地内存块，以字节为单位给定大小。
- **reallocateMemory(long address, long bytes)**：重新分配一个新的本地内存块，以字节为单位给定大小。
- **setMemory(Object o, long offset, long bytes, byte value)**：将给定内存块中的所有字节设置为固定值(通常为零), 当对象引用为空时, 偏移量提供一个绝对基地址。
- **copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes)**：将给定内存块中的所有字节设置为另一个块的副本, 当对象引用为空时, 偏移量提供一个绝对基地址。
- **freeMemory(long address)**：释放本地内存块。

#### 系统属性方法

- **addressSize()**：获取本地指针的字节大小。
- **pageSize()**：获取本地内存页面的字节大小。

#### 多线程同步方法

- **compareAndSwapObject(Object o, long offset, Object expected, Object x)**：如果当前保持预期状态，则将Java变量原子更新为x。
- **getAndAddInt(Object o, long offset, int delta)**：以原子方式将给定值添加到给定对象o中给定偏移量处的字段或数组元素的当前值。
- **getAndSetInt(Object o, long offset, int newValue)**：在给定的偏移量处以原子方式将给定值与给定对象 o 内的字段或数组元素的当前值进行交换。
- **getObjectVolatile(Object o, long offset)**：从给定具有 volatile 加载语义的Java变量中获取引用值, 否则等同于 {@link #getObject(Object, long)}。
- **putObjectVolatile(Object o, long offset, Object x)**：使用volatile存储语义将引用值存储到给定的Java变量中。否则等同于{@link #putObject(Object, long, Object)}, 该方法会保证存储对其他线程的立即可见性。
- **putOrderedObject(Object o, long offset, Object x)**：使用volatile存储语义将引用值存储到给定的Java变量中，否则等同于{@link #putObject(Object, long, Object)}, 该方法不保证存储对其他线程的立即可见性。

#### 挂起与恢复方法

- **unpark(Object thread)**：唤醒在park上阻塞的指定线程, 如果该线程并未阻塞, 则它在后续调用park时不会被阻塞。
- **park(boolean isAbsolute, long time)**：阻塞当前线程, 直到当前线程unpark被调用、被中断、time时间过去(非绝对时为纳秒, 绝对时为毫秒, 为0时代表无限阻塞)。

#### 内存屏障方法

- **loadFence()**：确保在栅栏之前不会对loads重排序, 在栅栏后不会对loads或stores重排序。
- **storeFence()**：确保栅栏前不会对stores重排序, 在栅栏后不会对loads或stores重排序。
- **fullFence()**：确保在栅栏之前不会对loads或stores进行重新排序，而在栅栏之后则不会对stores或loads进行重新排序。

### 3.9. 详细介绍CAS？

#### 概念

- CAS，**CompareAndSwap**，比较并交换，是乐观锁的一种实现方式，是一种**无锁算法**，该算法关键依赖两个值——期望值（旧值）和新值，底层CPU利用原子操作判断内存原值与期望值是否相等，如果相等就给内存地址赋新值，否则不做任何操作。
- 操作系统层面的CAS是一条**CPU的原子指令（cmpxchg指令）**，正是由于该指令具备**原子性**，因此使用CAS操作数据时不会造成数据不一致的问题，Unsafe提供的CAS方法直接通过native方式（封装C++代码）调用了底层的CPU指令cmpxchg。
- 当CAS将内存地址的值与预期值进行比较时，如果相等，就证明内存地址的值没有被修改，可以替换成新值，然后继续往下运行；如果不相等，就说明内存地址的值已经被修改，放弃替换操作，然后重新自旋。
- **使用CAS进行无锁编程的步骤大致如下**：
  1. 获得字段的期望值（oldValue）。
  2. 计算出需要替换的新值（newValue）。
  3. 通过CAS将新值（newValue）放在字段的内存地址上，如果CAS失败就重复第（1）步到第（2）步，一直到CAS成功，这种重复俗称**CAS自旋**。
- **CAS对象字段偏移量参数概念**：可见，**对象字段偏移量**，指的是从对象结构的对象头中开始算起，落在对象体中的字节数。

![1629897755808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629897755808.png)

#### 优点

CAS是处于用户态下的CPU指令级的原子操作，在用于线程同步时，可以不使用锁机制实现，线程也无需进入阻塞状态，没有用户态与内核态之间的切换，**性能开销较小**。

- **JDK应用场景**：
  - java.util.concurrent.atomic包中的原子类、Java AQS、显式锁以及CurrentHashMap等。
  - synchronized重量级锁涉及操作系统内核态下互斥锁的使用，其线程阻塞和唤醒需要进程在用户态到内核态的频繁切换，导致**重量级锁开销大、性能低**；synchronized轻量级锁使用CAS进行自旋抢锁，**CAS是CPU指令级的原子操作**，并处于用户态下，所以**轻量级锁的开销较小**。

#### 缺点

##### 只能保证单个变量原子性

当对一个共享变量执行操作时，可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，CAS就无法保证操作的原子性。

- **解决方案**：把多个共享变量**合并**成一个共享变量来操作。

##### 空耗CPU资源

在高并发、线程争用激烈的场景下，大量的CAS**空自旋**会浪费大量的CPU资源，大大降低了程序的性能。

- **优化思路**：当并发修改的线程少，冲突出现的机会少时，自旋的次数也会很少，CAS的性能会很高；当并发修改的线程多，冲突出现的机会多时，自旋的次数也会很多，CAS的性能会大大降低。所以，**提升CAS无锁编程效率的关键在于减少冲突的机会**，其有效方式之一是**以空间换时间**。

- **解决方案**：

  - **分散操作热点**：LongAdder，其核心思想是**热点分离**，将value值分离成一个数组，当多线程访问时，通过Hash算法将线程映射到数组的一个元素进行操作，在获取最终的value结果时，则将数组的元素求和即可。可见，LongAdder通过**以空间换时间**的方式，将原始的一个value值拆分为分布式的value值，减少了CAS时线程之间的冲突，以提升性能。

    ![1629957184893](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629957184893.png)

  - **使用队列削峰**：将发生CAS争用的线程加入一个队列中排队，降低CAS争用的激烈程度，比如JUC中非常重要的基础类抽象队列同步器AQS。

##### ABA问题

指线程A进行CAS操作，但是线程A发现M位置的数据仍然是V1，然后线程A操作成功。尽管线程A的CAS操作成功，但是不代表这个过程是没有问题的，线程A操作的数据V1可能已经不是之前的V1，而是**被线程B替换过的V1**，这就是ABA问题。

- **场景举例**：如果使用得不合理，CAS原子操作就会存在ABA问题：

  1. 现有一个LIFO（后进先出）堆栈，该堆栈使用单向链表实现，元素的插入和删除都发生在单向链表的头部。

     ![1629950310341](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629950310341.png)

  2. 假设线程A和线程B是两个在堆栈上进行并发操作的线程，其中线程A计划从Head位置通过CAS进行元素E2的弹出操作。

  3. 在线程A刚好启动CAS的执行，但是没有开始之前，线程B抢在前面从Head位置中弹出元素E2、E1，并压入了一个新元素E3，再压入了E2，线程B完成操作之后，栈帧的Head位置的数据仍然是E2，此时head -> E2 -> E3。

  4. 但线程A认为的是head -> E2 -> E1，此时CAS将E2出栈并设置E1为头结点后，会出现head -> E1，而E3却成为了一个游离的NULL -> E3 -> NULL结点。因此，也就是在线程A执行完毕后，线程B之前压入的E3元素处于游离状态，不再存在于堆栈中，平白无故被丢掉了，这就是ABA问题引发的不正常状态。

- **解决方案**：

  - 可以使用**版本号（Version）**方式来解决。每次在执行数据的修改操作时都会带上一个版本号，版本号和数据的版本号一致就可以执行修改操作并对版本号执行加1操作，否则执行失败。
  - 由于每次操作的版本号都会随之增加，因此不会出现ABA问题，因为版本号只会增加，不会减少。

  ```java
  // 1、使用AtomicStampedReference解决ABA问题
  public class AtomicStampedReference<V> {
      // 使用原始数量、初始版本号构造
      public AtomicStampedReference(V initialRef, int initialStamp) {
          pair = Pair.of(initialRef, initialStamp);
      }
      
      // CAS+版本号更新为newReference和newStamp
      public boolean compareAndSet(V   expectedReference,
                                   V   newReference,
                                   int expectedStamp,
                                   int newStamp) {
          Pair<V> current = pair;
          return
              expectedReference == current.reference &&
              expectedStamp == current.stamp &&
              ((newReference == current.reference &&
                newStamp == current.stamp) ||
               casPair(current, Pair.of(newReference, newStamp)));
      }
  }
  
  // 2、或者使用AtomicMarkableReference解决ABA问题
  public class AtomicMarkableReference<V> {
      // 使用原始数量、初始标记构造
      public AtomicMarkableReference(V initialRef, boolean initialMark) {
          pair = Pair.of(initialRef, initialMark);
      }
  
      // CAS+标记更新为newReference和newMark
      public boolean compareAndSet(V       expectedReference,
                                   V       newReference,
                                   boolean expectedMark,
                                   boolean newMark) {
          Pair<V> current = pair;
          return
              expectedReference == current.reference &&
              expectedMark == current.mark &&
              ((newReference == current.reference &&
                newMark == current.mark) ||
               casPair(current, Pair.of(newReference, newMark)));
      }
  }
  
  ```

##### 总线风暴

在**SMP架构**的CPU平台上，大量的CAS操作可能会导致**总线风暴**。

- sun.misc.Unsafe#compareAndSwapInt（），会根据当前CPU的类型**是否为多核CPU**，来决定是否为cmpxchg指令**添加lock前缀**。
  - 如果程序在多核CPU上运行，就为cmpxchg指令加上lock前缀（lockcmpxchg）。反之，如果程序在单核CPU上运行，就省略lock前缀，因为单核CPU不需要lock前缀提供的内存屏障效果。
  - 在Intel X86平台下，CAS的汇编指令lock cmpxchg是一个l**ock前缀指令**，因此CAS操作和volatile一样，也需要CPU保障变量的**缓存一致性**。
- CPU会通过MESI协议保障变量的缓存一致性，为了保障“缓存一致性”，不同的内核需要通过总线**来回通信**，因而所产生的流量一般被称为“**缓存一致性流量**”，而由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将成为瓶颈，这就是所谓的**总线风暴**。
  - 总线风暴与CPU的架构和设计有关，并不是所有的CPU都会产生总线风暴，由于使用lock前缀指令的Java操作（包括CAS、volatile）恰恰会产生缓存一致性流量，**当有很多线程同时执行lock前缀指令操作时，在SMP架构的CPU平台上必然会导致总线风暴**。
- **解决方法**：分散热点、使用队列削峰（比如AQS的对抢锁线程进行排队），从而最大程度上减少了CAS操作数量。

### 4.0. 什么是重排序？

- 重排序是单核时代非常优秀的优化手段，有足够多的措施保证其在单核下的正确性，而在多核时代，如果工作线程之间不共享数据或仅共享不可变数据，重排序也是性能优化的利器。
- 但如果工作线程之间共享了可变数据，由于两种重排序的结果都不是固定的，因此会导致工作线程似乎表现出了**随机行为**。
- 编译器和CPU常常会对指令进行重排序，因此重排序主要分为两类：**编译器重排序**和**CPU重排序**。

![1630031189798](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630031189798.png)

#### 编译器重排序

- 编译器重排序指的是，在代码编译阶段进行指令重排，不改变程序执行结果的情况下，为了提升效率，编译器对指令进行乱序的编译。
  - 其目的在于，与其等待阻塞指令（如等待缓存刷入）完成，不如先去执行其他指令。
  - 其优点在于，与CPU重排序相比，编译器重排序能够完成**更大范围、效果更好**的乱序优化。

#### CPU重排序

- CPU重排序指的是，为了CPU的执行效率，流水线都是并行处理的，在不影响语义的情况下，处理次序和程序次序是允许不一致的，只要满足**As-if-Serial规则**即可。
  - **处理次序**：Process Ordering，机器指令在CPU实际执行时的顺序。
  - **程序次序**：Program Ordering，程序代码的逻辑执行顺序。
- 一般来说，CPU为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行顺序同代码中的先后顺序一致，但是它会保证程序**最终的执行结果**和代码顺序执行的结果是一致的。
- CPU重排序包括两类：**指令级重排序**和**内存系统重排序**。

##### 指令级重排序

- 指令级重排序指的是，在不影响程序执行结果的情况下，为了提升效率，CPU内核采用ILP（Instruction-Level Parallelism，指令级并行运算）技术来将多条指令重叠执行。
- 如果指令之间**不存在数据依赖性**，CPU就可以改变语句的对应机器指令的执行顺序。

##### 内存系统重排序

- 内存系统重排序指的是，对于现代的CPU来说，在CPU内核和主存之间都具备一个**高速缓存**，其主要作用是减少CPU内核和主存的交互。在CPU内核进行读操作时，如果缓存没有的话就从主存取，而对于写操作都是先写在缓存中，最后再一次性写入主存，从而提升性能，但可能会导致一个**数据不一致**的问题。
- 内存系统重排序和指令级重排序不同，内存系统重排序为**伪重排序**，也就是说只是**看起来**像在乱序执行而已。

### 4.1. As-if-Serial规则？

- As-if-Serial规则指的是，无论如何重排序，都必须保证代码在单线程下运行正确。
  - 为了遵守As-if-Serial规则，编译器和CPU不会对存在数据依赖关系的操作进行重排序，因为这种重排序会改变执行结果。
    - 为了保证As-if-Serial规则，Java异常处理机制也会为指令重排序做一些特殊处理：JIT在重排序时会在catch语句中插入错误补偿代码，补偿执行语句，将程序恢复到发生异常时应有的状态。
    - 这种做法会将异常捕捉的和处理的底层逻辑变得非常复杂，但是JIT的优化原则是，尽力保障正确的运行逻辑，哪怕以catch块逻辑变得复杂为代价。
  - 但是，如果指令之间不存在数据依赖关系，这些指令可能被编译器和CPU重排序。
- 虽然编译器和CPU遵守了As-if-Serial规则，保证在单CPU执行的情况下保证结果的正确性，在多核CPU并发执行的场景下，由于CPU的一个内核无法清晰分辨其他内核上指令序列中的数据依赖关系，因此可能出现乱序执行，从而导致程序运行结果错误。
- 因此，As-if-Serial规则只能保障**单内核**指令重排序之后的执行结果正确，不能保障多内核以及跨CPU指令重排序之后的执行结果正确。

### 4.2. 硬件层内存屏障？

- 内存屏障（Memory Barrier），又称内存栅栏（Memory Fences），是一系列的CPU指令，是一项让**CPU高速缓存内存可见**的技术，也是一项**保障跨CPU内核有序执行指令**的技术。
- **硬件层内存屏障**分为三种：读屏障、写屏障和全屏障。
  - **读屏障**：Load Barrier，在指令前插入读屏障，可以在指令执行时，**让高速缓存中的数据失效**，强制重新从主存加载数据，并且读屏障会告诉CPU和编译器，**先于这个屏障的指令必须先执行**。
    - 读屏障既使得指令执行时，当前CPU内核对共享变量的更改对所有CPU内核可见，又阻止了一些可能导致读取无效数据的指令重排。
    - 读屏障对应着X86处理器上的lfence指令，将强制**所有读操作都在lfence指令执行之后**被执行，并且强制本地高速缓冲区的值**全部失效**，以便从主存中重新读取共享变量的值。
  - **写屏障**：Store Barrier，在指令后插入写屏障，可以在指令执行时，**让高速缓存中的最新数据更新到主存**，让其他线程可见，并且写屏障会告诉CPU和编译器，**后于这个屏障的指令必须后执行**。
    - 写屏障对应X86处理器上的sfence指令，会保证**所有写操作都在sfence指令执行之前**被完成，并把高速缓冲区的数据都**刷新到主存**中，使得当前CPU对共享变量的更改对所有CPU可见。
  - **全屏障**：Full Barrier，又称为StoreLoad Barriers，是一种全能型的屏障，具备读屏障和写屏障的能力
    - X86处理器平台上mfence指令综合了sfence指令与lfence指令的作用，强制所有在mfence之前的store/load指令都在mfence执行之前被执行，所有在mfence之后的store/load指令都在该mfence执行之后被执行。简单来说，**X86处理器禁止对mfence指令前后的store/load指令进行重排序**。
    - X86处理器上的**lock前缀指令**也具有内存全屏障的功能。
- **硬件层内存屏障的作用**：
  - **强制让高速缓存的数据失效**：硬件层的内存屏障强制把高速缓存中的最新数据写回主存，让高速缓存中相应的脏数据失效，一旦完成写入，任何访问这个变量的线程将会得到最新的值。
  - **阻止屏障两侧的指令重排序**：编译器和CPU可能为了使性能得到优化而对指令重排序，但是插入一个硬件层的内存屏障，相当于告诉CPU和编译器先于这个屏障的指令必须先执行，后于这个屏障的指令必须后执行。
- **volatile与硬件层内存屏障**：
  - volatile在X86处理器上被JVM编译之后，它的汇编代码中会被插入一条**lock前缀指令**（lock ADD），从而实现**全屏障**目的。
  - 由于不同的物理CPU硬件所提供的内存屏障指令的差异非常大，因此**JMM**定义了自己的一套相对独立的内存屏障指令，用于屏蔽不同硬件的差异性。
  - 很多Java关键字（如volatile）在语义中包含JMM内存屏障指令，在不同的硬件平台上，这些**JMM内存屏障指令**会要求JVM为不同的平台生成相应的硬件层的内存屏障指令。

### 4.3. Java内存模型JMM？

![1630043244494](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630043244494.png)

#### JMM概念

- JMM，Java Memory Model，Java内存模型，并不像JVM内存结构一样是真实存在的运行实体，而是体现为一种规范和规则，该规范定义了一个线程对共享变量写入时，**如何确保对另一个线程是可见的**。
  - 为此，JMM提供了合理的禁用缓存以及禁止重排序的方法，用于解决**可见性和有序性**。
  - 同时，JMM还能**屏蔽各种硬件和操作系统的访问差异**，保证Java程序在各种平台下对内存的访问最终都是一致的。
- **Java内存模型规定**，所有的变量都存储在主存中（类似于物理内存），每个线程都有自己的工作内存（类似于CPU中的高速缓存）。工作内存保存了线程使用到的变量的拷贝副本，线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行，不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主存来传递。
- **JMM两个重要概念**：
  - **主存**：堆内存。
    - 主要存储的是**Java实例对象**，所有线程创建的实例对象都存放在主存中，包括成员变量对象、方法中的局部变量对象，以及共享的类信息、常量、静态变量等。
    - 由于是共享数据区域，因此多条线程对同一个变量进行访问可能**会发现线程安全问题**。
  - **工作内存**：线程私有数据区域。
    - 主要存储**当前方法的所有本地变量信息**，工作内存中存储着主存中的变量副本，每个线程只能访问自己的工作内存，即线程中的本地变量对其他线程是不可见的，即使两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，包括字节码行号指示器、相关Native方法的信息。
    - 注意，由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据**不存在线程安全问题**。
- **JMM场景举例**：以Java为例，一个i++方法编译成字节码后，在JVM中是分成以下三个步骤运行：
  1. 从主存中复制i的值到CPU的工作内存中。
  2. CPU取工作内存中的值，然后执行i++操作，完成后刷新到工作内存。
  3. 将工作内存中的值更新到主存。

#### JMM与JVM物理内存的区别

|        | JMM                                                          | JVM                                                          |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 模型上 | 属于概念和规范维度的模型，是一个参考性质的模型，是一组规则，并不实际存在 | 虽然也是一个概念和规范维度的模型，但是大家常常将JVM理解为实体的、实现维度的虚拟机，通常是指HotSpot VM |
| 规定上 | 规定所有的变量都存储在主存中（类似于系统内存，但有区别），还能包含部分共享缓存，而每个Java线程都有自己的工作内存（类似于CPU高速缓存，但也有区别）。 | 定义了一个指令集、一个虚拟计算机架构和一个执行模型，具体的JVM实现需要遵循JVM的模型 |
| 作用上 | 确保了在不同的编译器和不同的CPU平台上，为Java程序员提供了一致的内存可见性和指令并发执行的有序性 | 能够运行根据JVM模型指令集编写的代码，就像真机可以运行机器代码一样 |

#### JMM与硬件内存架构的关系

多线程的执行最终都会映射到CPU上执行，但是Java内存模型和硬件内存架构并不完全一致。总体上来说，JMM和计算机硬件内存架构是**相互交叉**的关系，是一种**抽象概念划分与真实物理硬件的交叉**：

- 对于硬件内存来说只有寄存器、缓存内存、主存的概念，并没有工作内存（线程私有数据区域）和主存（堆内存）之分，也就是说JMM对内存的划分对硬件内存并没有任何影响。
- 而JMM只是一种抽象的概念，是一组规则，并不实际存在，无论是工作内存的数据还是主存的数据，对于计算机硬件来说都会存储在计算机主存中，当然也有可能存储到CPU高速缓存或者寄存器中。

![1630044892085](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630044892085.png)

#### JMM 8个操作

JMM定义了一套自己的主存与工作内存之间的交互协议，即**一个变量如何从主存拷贝到工作内存，又如何从工作内存写入主存**，该协议包含8种操作，并且要求JVM具体实现必须保证其中每一种操作都是**原子的、不可再分的**。

- 如果要把一个变量从主存复制到工作内存，就要按**顺序执行Read和Load操作**；如果要把变量从工作内存同步回主存，就要**按顺序执行Store和Write操作**。
- JMM规定，执行上述8种基本操作时必须满足如下规则：
  1. 不允许read和load、store和write操作之一单独出现，以上两个操作**必须按顺序执行，但没有保证必须连续执行**，也就是说，read与load之间、store与write之间是可插入其他指令的。
  2. 不允许一个线程丢弃它最近的assign操作，也就是说当线程使用assign操作对私有内存的变量副本进行变更时，它必须使用write操作将其同步到主存中。
  3. 不允许一个线程无原因地（比如没有发生过任何assign操作）把数据从线程的工作内存同步回主存中。
  4. 一个新的变量只能从主存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，也就是说对一个变量实施use和store操作之前，必须先执行assign和load操作。
  5. 一个变量在同一个时刻只允许一个线程对其执行lock操作，但lock操作可以被同一个线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
  6. 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。
  7. 如果一个变量实现没有被lock操作锁定，就不允许对它执行unlock操作，也不允许unlock一个被其他线程锁定的变量。
  8. 对一个变量执行unlock操作之前，必须先把此变量同步回主存（执行store和write操作）。

![1630045226983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630045226983.png)

| 操作   | 作用对象 | 说明                                                         |
| ------ | -------- | ------------------------------------------------------------ |
| Read   | 主存     | 读取。把一个变量的值从主存传输到工作内存中，以便随后的Load操作使用。 |
| Load   | 工作内存 | 载入。把Read操作从主存中得到的变量值，载入到工作内存的变量副本中（可以简单理解为CPU的高速缓存）。 |
| Use    | 工作内存 | 使用。每当JVM遇到一个需要使用变量值的字节码指令时，都会执行Use操作，会把工作内存中的一个变量值传递给执行引擎。 |
| Assign | 工作内存 | 赋值。每当JVM遇到一个给变量赋值的字节码指令时，都会执行Assign操作，操作引擎通过Assign操作给工作内存的变量赋值。 |
| Store  | 工作内存 | 存储。把工作内存的一个变量值传递到主存中，以便随后的Write操作使用。 |
| Write  | 主存     | 写入。把Store操作从工作内存中得到的变量值，写入到主存的变量中。 |
| Lock   | 主存     | 锁定。把一个变量标识为某个线程独占的状态。                   |
| Unlock | 主存     | 解锁。把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 |

#### JMM内存屏障

由于不同CPU硬件实现内存屏障的方式不同，**JMM屏蔽了这种底层CPU硬件平台的差异，定义了不对应任何CPU的JMM逻辑层内存屏障，提供了自己的内存屏障指令**，要求JVM编译器实现这些指令，由JVM在不同的硬件平台生成对应的内存屏障机器码，禁止特定类型的编译器（不是所有的编译器重排序都要禁止）和CPU重排序，解决**有序性问题**。

- JMM内存屏障主要有**Load和Store**两类：

  - **Load Barrier**：读屏障，在读指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，重新从主存加载数据。
  - **Store Barrier**：写屏障，在写指令后插入写屏障，可以在指令执行时，让写入缓存的最新数据写回主存。

- 在实际使用时，JMM会对Load Barrier和Store Barrier两类屏障进行组合，用于**禁止特定类型的CPU重排序**：

  - **LoadLoad**：LL屏障。

    - 在执行预加载或者支持乱序处理的指令序列中，需要显示地声明LoadLoad屏障。
    - 在Load2要读取的数据被访问前，使用LoadLoad屏障，能保证Load1要读取的数据被读取完毕。

    ```java
    // LoadLoad屏障伪代码
    Load1；LoadLoad；Load2
    
    ```

  - **StoreStore**：SS屏障。

    - 如果CPU刷新数据时，不能保证按顺序从高速缓冲向主存（或其他CPU），则需要使用StoreStore屏障。
    - 在Store2以及后续写入操作执行前，使用StoreStore屏障，能保证Store1的写入结果对其他CPU可见。

    ```java
    // StoreStore屏障伪代码
    Store1；StoreStore；Store2
    
    ```

  - **LoadStore**：LS屏障。

    - LoadStore屏障，用于在数据写入操作执行前，确保完成数据的读取。
    - 在Store2以及后续写入操作执行前，使用LoadStore屏障，能保证Load1要读取的数据被读取完毕。

    ```java
    // LoadStore屏障伪代码
    Load1；LoadStore；Store2
    
    ```

  - **StoreLoad**：SL屏障。

    - StoreLoad屏障，用于在数据读取操作执行前，确保完成数据的写入。该屏障是一个**全能型屏障**，其开销是4种屏障中最大的，因为兼具其他3个屏障的效果，现代的多核CPU大多支持该屏障。
    - 在Load2以及后续所有读取操作执行前，使用StoreLoad屏障，能保证Store1的写入对所有CPU可见。

    ```java
    // StoreLoad屏障伪代码
    Store1；StoreLoad；Load2
    
    ```

### 4.4. volatile原理？

#### 保证内存可见性

使用volatile修饰的变量，在变量值发生改变时，会立刻同步到主存，并使其他线程的变量副本失效，即一个线程修改了某个volatile变量的值，该值对其他线程立即可见。

- 在正常情况下，系统操作并不会校验共享变量的缓存一致性，只有当共享变量用**volatile**关键字修饰后，才可以保证共享变量的**内存可见性**，也就是将共享变量的改动值立即刷新回主存，该变量所在的缓存行才会被要求进行**缓存一致性的校验**。
- 分析volatile关键字对应的汇编指令，可知在操作volatile变量之前，多出了一个 lock前缀指令**lock addl（lock ADD）**。
- **lock前缀指令具有以下功能**：
  - **将当前CPU缓存行数据立即写回主存**：在执行指令期间，CPU可以**独占共享内存**（即主存）。
    - 对共享内存的独占，老的CPU（如Intel 486）通过**总线锁**方式实现。
    - 由于总线锁开销比较大，因此新版CPU（如IA-32、Intel 64）通过**缓存锁**实现对共享内存的独占性访问，缓存锁（缓存一致性协议）会阻止两个CPU同时修改共享内存的数据。
  - **失效其他CPU中相同地址的缓存行**：
    1. 写回操作时要**经过总线传播数据**，而每个CPU通过嗅探在总线上传播的数据来检查自己缓存的值是否过期。
    2. 当CPU发现自己缓存行对应的内存地址被修改时，就会将当前CPU的缓存行设置为**无效状态**。
    3. 当CPU要对这个值进行修改的时候，会强制重新从主存中把数据读到CPU缓存。
  - **禁止指令级重排序**：lock前缀指令还可以作为**内存屏障**，禁止指令重排序，避免多线程环境下程序出现乱序执行的现象。

#### 禁止指令重排序

##### 硬件层面上

用volatile修饰的变量，在硬件层面上，会通过在指令前后加入**内存屏障指令**（lock前缀指令）来实现，以保证执行的有序性。

- 为了实现volatile关键字语义的有序性，JVM编译器在生成字节码时，会在指令序列中插入**内存屏障**来禁止特定类型的处理器重排序。

- JMM建议JVM volatile采取**保守策略**严格禁止重排序：

  - 在每个volatile读操作的后面插入一个**LoadLoad屏障**，以及一个**LoadStore屏障**，禁止后面的普通读、普通写和前面的volatile读操作之间发生重排序。
    - LoadLoad屏障：在Load2要读取的数据被访问前，使用LoadLoad屏障，能保证Load1要读取的数据被读取完毕。
    - LoadStore屏障：在Store2以及后续写入操作执行前，使用LoadStore屏障，能保证Load1要读取的数据被读取完毕。

  ![1630053036307](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630053036307.png)

  - 在每个volatile写操作前插入一个StoreStore屏障，在写操作后面插入一个StoreLoad屏障，禁止前面的普通写和后面的volatile写操作之间发生重排序，同时禁止后面的普通读和前面的volatile写操作之间发生重排序。
    - StoreStore屏障：在Store2以及后续写入操作执行前，使用StoreStore屏障，能保证Store1的写入结果对其他CPU可见。
    - StoreLoad屏障：在Load2以及后续所有读取操作执行前，使用StoreLoad屏障，能保证Store1的写入对所有CPU可见。

  ![1630052862174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630052862174.png)

- 由于上述JMM建议的volatile写和volatile读的内存屏障插入策略，是针对任意处理器平台的，所以非常保守。不同的处理器有不同“松紧度”的处理器内存模型，只要不改变volatile读写操作的内存语义，不同JVM编译器可以根据具体情况省略不必要的JMM屏障。

  - 以X86处理器为例，该平台的JVM实现仅仅在volatile写操作后面插入一个StoreLoad屏障，其他的JMM屏障都会被省略。
  - 由于StoreLoad屏障的开销大，因此在X86处理器中，volatile写操作比volatile读操作的开销会大很多。

##### JMM层面上

用volatile修饰的变量，在JMM层面上，是通过对volatile有着特殊约束来实现的，以保证执行的有序性。

- 使用volatile修饰的变量其**read、load、use都是连续出现的**，所以每次使用变量的时候都要从主存读取最新的变量值，替换私有内存的变量副本值（如果不同的话）。
- 其对同一变量的**assign、store、write操作都是连续出现的**，所以每次对变量的改变都会立马同步到主存中。

#### 复合操作不具备原子性

虽然volatile修饰的变量，其要求对变量的（read、load、use）以及（assign、store、write）必须是连续出现的，每次读取的变量可以是最新值，且可以强制刷新回主存，但是在不同CPU内核上并发执行的线程，还是有可能出现读取脏数据的时候，因此volatile变量的复合操作并不具备原子性。

- **场景举例**：

  1. 假设有两个线程A、B分别运行在Core1、Core2上，并假设此时的value为0，线程A、B也都读取了value值到自己的工作内存。
  2. 现在线程A将value变成1之后，完成了assign、store的操作，假设在执行write指令之前，线程A的CPU时间片用完，线程A被空闲，**但是线程A的write操作没有到达主存**。
  3. 由于线程A的store指令触发了写的信号，线程B缓存过期，**重新从主存读取到value值**，但是线程A的写入没有最终完成，线程B读到的value值还是0。
  4. 线程B执行完成所有的操作之后，将value变成1写入主存。
  5. 线程A的时间片重新拿到，重新执行store操作，将过期了的1写入主存。

  => 可见，虽然A、B两线程执行了两次+1操作，但是最终结果只是增加了1而不是2，因此，volatile变量的复合操作不具备原子性。

- **解决方法**：对于复合操作，volatile变量无法保障其原子性，如果要保证复合操作的原子性，就需要使用**锁**。

![1630118559462](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630118559462.png)

### 4.5. Happens-Before规则？

JMM定义了一套Happens-Before规则（先行发生规则），确保只要两个Java语句之间存在Happens-Before关系，JMM需要尽量确保这两个Java语句之间的**内存可见性和指令有序性**。

Happens-Before规则的主要内容包括以下几个方面：

1. **程序顺序执行规则**：即as-if-serial规则，在同一个线程中，有依赖关系的操作按照先后顺序，前一个操作必须**先行发生于**后一个操作，换句话说就是，单个线程中的代码顺序无论怎么重排序，对于结果来说是不变的。
   - As-if-Serial规则，仅仅用来保证程序在单线程执行结果的正确性，但是无法保证程序在多线程执行结果的正确性。
2. **volatile变量规则**：对volatile变量的写操作必须**先行发生于**对volatile变量的读操作。
   - 如果第二个操作为volatile写，无论第一个操作是什么都不能重排序。
   - 如果第一个操作为volatile读，无论第二个操作是什么都不能重排序。
3. **传递性规则**：如果A操作先于B操作，而B操作又先行发生于C操作，那么A操作**先行发生于**C操作。
4. **监视锁规则**：对一个监视锁的解锁操作**先行发生于**后续对这个监视锁的加锁操作。
   - 即无论在单线程还是多线程中，同一个锁如果处于被锁定状态，那么必须先对锁进行释放操作，后面才能继续执行lock操作，先获取锁的线程，对x赋值之后释放锁，另一个再获取锁时，一定能看到前一个加锁线程对x赋值的改动。
   - 由于监视器互斥执行的特性，监视锁规则不会对临界区内的代码进行约束，临界区内的代码可以重排序，其他线程根本无法“观察”到该线程在临界区内的重排序，这种重排序既提高了执行效率，又没有改变程序的执行结果。但JMM不允许临界区内的代码“逸出”到临界区之外，因为那样会破坏监视器的语义。
5. **start规则**：对线程的start操作**先行发生于**这个线程内部的其他任何操作，具体来说就是，如果线程A执行B.start()启动线程B，那么线程A的B.start()操作先行发生于线程B中的任意操作。
   - 即如果主线程A启动子线程B后，线程B能看到线程A在start（）操作前的任何操作。
6. **join规则**：如果线程A执行了B.join()操作并成功返回，那么线程B中的任意操作**先行发生于**线程A所执行的ThreadB.join()操作。
   - 即线程A等待子线程B完成后，线程B的所有赋值操作，线程A都能够看到。

### 4.6. 详细介绍AQS？

![1630209591346](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209591346.png)

#### 背景

- **CAS自旋的两大性能问题**：
  - CAS恶性空自旋会浪费大量的CPU资源。
  - 在SMP架构的CPU上会导致“总线风暴”。
- 解决CAS恶性空自旋的有效方式之一是**以空间换时间**，较为常见的方案有两种：**分散操作热点和使用队列削峰**。
  - JUC并发包使用的是**队列削峰**的方案解决CAS的性能问题，并提供了一个基于双向队列的削峰基类——抽象基础类**AbstractQueuedSynchronizer**。

#### 特点

- AbstractQueuedSychronizer，**简称AQS**，抽象队列同步器，提供一个构建锁和同步器的框架，能够简单且⾼效地构造出应⽤⼴泛的⼤量的同步器，可以用于实现**依赖先进先出 (FIFO) 等待队列**的阻塞锁和相关同步器（信号量、事件等），旨在成为大多数依赖**单个原子 {@code int} 值来表示状态**的同步器的有用基础。
- AQS支持**独占模式（默认）和共享模式**，在不同模式下等待的线程**共享同一个 FIFO 队列**。
  - 当以独占模式获取时，其他线程尝试获取不会成功。
  - 当以共享模式获取时， 多个线程尝试获取可能会成功。当共享模式获取成功时，下一个等待线程（如果存在）也必须确定它自己是否也可以获取（前驱通过调用setHeadAndPropagate方法传播告知）。
- AQS定义了一个嵌套的 {@link ConditionObject} 类，{@link ConditionObject}可以被支持独占模式的子类用作 **{@link Condition} 实现**，而{@link ConditionObject} 的行为当然取决于其同步器实现的语义。
- AQS还为内部队列提供检查、检测和监视方法，同时也为ConditionObject提供类似方法。

#### 实现原理

##### AQS核⼼思想

1. 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
2. 如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，而这个机制AQS是通过CLH队列（自旋锁）实现的，即将暂时获取不到锁的线程加⼊到队列中。
3. 每当线程通过AQS获取锁失败时，线程将被封装成一个Node节点，通过CAS原子操作插入队列尾部。
4. 当有线程释放锁时，AQS会尝试让队头的后继节点占用锁。

![1630209724753](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209724753.png)

##### AQS主等待队列

AQS主等待队列，是CLH队列（自旋锁）的一个变种，AQS将它们改为用于阻塞同步器：

- 主等待队列的每个节点都充当一个**特定的通知式监视器**，持有一个**等待线程**（用于保存后继有关控制信息），一个**状态字段**（用于跟踪线程是否应该阻塞）。
- 在前驱结点Release时，当前结点将会收到信号，从而可能会尝试获取成为在队列中的head结点，但并不保证成功，只是给予当前结点参与竞争的权利。
- 而要加入CLH队列，需要原子地将其拼接为新的尾部，要出列则需要设置该结点成为head结点。
- “prev”前驱指针（原始CLH锁中没有前驱指针），用于处理取消结点：如果一个结点被取消，则它的后继会重新链接到一个未取消的前驱；以及判断是否为头结点，方便后继执行一次尝试抢占锁的操作。
- “next”后继指针，用于实现阻塞与通知机制：每个节点的线程id保存在它自己的节点中，因此前驱通过遍历下一个链接来确定它是哪个线程来通知下一个节点唤醒。
- 此外，AQS主等待队列还需要一个**虚拟头结点**来启动，但是AQS不会在构建时创建它们，因为如果从不存在争用，那将是浪费精力。因此，AQS只会在第一次争用时，才构造结点并设置头指针和尾指针。
- 即使AQS内部基于FIFO队列，但它也不会自动执行FIFO采集策略，因为在入队之前会先调用获取的检查，所以新的获取线程可能会抢在其他被阻塞和排队的线程之前。
  - 虽然该策略无法保证公平或者无饥饿，但允许较早的排队线程在较晚的排队线程之前竞争，从而能够保持**最高的吞吐量和可扩展性**。
  - 如果需要可以定义{@code tryAcquire} 或者 {@code tryAcquireShared} ，通过内部调用一种或多种检查方法来禁用插入，从而提供公平的 FIFO 获取顺序。比如{@link #**hasQueuedPredecessors**}（一种专门设计用于公平同步器使用的方法）返回 {@code true}时不允许插入，因此大多数公平同步器可以基于该方法，从而定义 {@code tryAcquire} 返回 {@code false}，代表不允许提前插入。

![1630238528789](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630238528789.png)

##### AQS条件队列

- Condition，是JUC用来替代传统Object的wait()/notify()线程间通信与协作机制的新组件，相比调用Object的wait()/notify()，调用Condition的await()/signal()这种方式实现**线程间协作更加高效**。
  - Condition与Object的wait()/notify()作用是相似的，都是使得一个线程等待某个条件，只有当该条件具备signal()或者signalAll()方法被调用时等待线程才会被唤醒，从而重新争夺锁。
  - 不同的是，Object的wait()/notify()由JVM底层实现，而Condition接口与实现类完全使用Java代码实现。当需要进行线程间的通信时，建议结合使用ReetrantLock与Condition，通过Condition的await()和signal()方法进行线程间的阻塞与唤醒。
- ConditionObject类是实现条件队列的关键，每个ConditionObject对象都维护一个单独的条件等待队列。每个ConditionObject对应一个条件队列，它记录该队列的头节点和尾节点。
  - 在一个显式锁上，我们可以创建多个等待任务队列，这点和内置锁不同，Java内置锁上只有唯一的一个等待队列。
  - Condition条件队列是单向的，而AQS同步队列是双向的，AQS节点会有前驱指针。一个AQS实例可以有多个**条件队列，是聚合关系**；但是一个AQS实例只有一个**同步队列，是逻辑上的组合关系**。
- AQS条件队列，也使用了相同的Node队列结点，但额外维护了一个nextWaiter指针，在调用Condition#await时，会把一个Condition结点插入到条件队列中，然后根据Condition#signal信号，该结点将会被转移到主队列中，去参与AQS竞争，竞争失败的会重新阻塞，阻塞后依赖于AQS的CLH机制实现唤醒。

![1630238750935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630238750935.png)

##### 队列结点数据结构

![1630208598316](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630208598316.png)

- **waitStatus**：
  - **waitStatus为0**：表示当前节点处于初始状态。
  - **CANCELLED = 1**：表示线程因为中断或者等待超时，需要从等待队列中取消等待，其节点不会参与竞争，且会一直保持取消状态。
  - **SIGNAL = -1**：表示其后继的节点处于等待状态，当前节点对应的线程如果释放了同步状态或者被取消，就会通知后继节点，使后继节点的线程得以运行。
  - **CONDITION = -2**：表示该线程在条件队列中阻塞，当持有锁的线程调用了CONDITION的signal（）方法之后，节点会从条件队列转移到AQS主等待队列上，去竞争锁。
  - **PROPAGATE = -3**：表示下一个线程获取共享锁后，自己的共享状态会被无条件地传播下去，因为共享锁可能出现同时有N个锁可以用，这时直接让后面的N个节点都来工作，这样就不会让其他等待的线程等很久，这种向后传播的目的也是**通知其他等待的线程尽快获取锁**。
- **thread**：存放进入AQS队列中的线程引用。
- **nextWaiter**：如果当前结点为条件等待结点，则说明该结点处于某个Condition的等待队列上，指向该条件队列的后继等待结点；如果当前结点为普通结点，则只作为独占（null）/共享（new Node）模式的标记。
  - **SHARED**：new Node（），共享模式的标记，表示线程是因为获取共享资源时阻塞而被添加到队列中的。
  - **EXCLUSIVE**：null，独占模式的标记，表示线程是因为获取独占资源时阻塞而被添加到队列中的。
- **prev**：前驱结点，当前结点会在前驱结点上自旋，循环检查前驱结点的waitStatus状态。用于处理取消结点，如果一个结点被取消，则它的后继会重新链接到一个未取消的前驱；以及判断是否为头结点，方便后继执行一次尝试抢占锁的操作。
- **next**：后继结点，用于实现阻塞与通知机制，每个节点的线程id保存在它自己的节点中，因此前驱通过遍历下一个链接来确定它是哪个线程来通知下一个节点唤醒。

#### 同步状态

AQS中维持了一个单一的volatile修饰的状态信息state，使用int类型的state标示锁的状态，可以理解为锁的同步状态。

#### 钩子方法

AQS钩子方法，默认实现是抛出UnsupportedOperationException异常，而AQS其他方法都是final类型的方法，无法被子类重写。

- **tryAcquire(int)**：独占锁钩子，尝试获取资源，若成功则返回true，若失败则返回false。
- **tryRelease(int)**：独占锁钩子，尝试释放资源，若成功则返回true，若失败则返回false。
- **tryAcquireShared(int)**：共享锁钩子，尝试获取资源。
  - 负数，表示失败。
  - 正数，表示成功，且有剩余资源。
  - 0，也表示成功，但没有剩余可用资源。
- **tryReleaseShared(int)**：共享锁钩子，尝试释放资源，若成功则返回true，若失败则返回false。
- **isHeldExclusively()**：独占锁钩子，判断该线程是否正在独占资源，只有用到condition条件队列时才需要去实现它。

#### 独占模式

![1630209980487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209980487.png)

![1630210001133](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210001133.png)

- 独占模式下，tryAcquire返回的是boolean值，其含义取决于实现类定义的语义。
  - 经过推算，要实现独占就要保证：如果想要获取同步器，则当已存在独占线程时，则要返回false，当没存在独占线程时，则要返回true。
- 每个结点尝试获取同步器，获取失败的生成Node结点，并加入AQS主队列参与竞争，竞争失败的则会将前驱结点设置为SINGAL状态，然后阻塞。
- 每个结点（此时作为后继的前驱）释放同步器时，由于当前为SINGAL状态，所以会唤醒后继结点，重新参与AQS竞争。

##### 获取资源

1. 尝试以独占模式获取同步器，如果获取成功，则直接返回即可。
2. 如果获取失败，则使用当前线程构建独占模式的Node结点，并CAS+自旋直至入队成功。
3. 入队成功后，则调用acquireQueued方法，自旋判断前驱是否为头结点，如果是则执行一次抢占锁的操作，抢占成功则更新头结点，并返回中断标记interrupted（该方法唯一返回入口）。
4. 如果检测到前驱不为头结点，或者抢占锁失败，则使用LockSupport.park（this）来阻塞当前线程。
5. 直到LockSupport.unpark（当前线程的实例）调用后，当前线程被唤醒，会先检查线程中断状态，然后才会重新自旋检查前驱状态、抢占锁或者继续阻塞。

##### 可抛中断异常原理

对比普通独占获取资源方法，可抛中断异常获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会**提前抛出中断异常**，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireInterruptibly方法来添加入队结点。
3. 接着自旋判断到前驱为头结点，并成功抢占锁后，不会返回任何值。
4. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会**立马抛出中断异常**。

##### 定时获取原理

对比普通独占获取资源方法，定时获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会提前抛出中断异常，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireNanos方法来添加入队结点，并且根据当前系统纳秒时间，来**计算剩余过期时间**。
3. 接着自旋判断到前驱为头结点，并成功抢占锁后，会**返回true**，代表在规定时间内成功获取到了锁。
4. 如果前驱不为头结点，或者抢锁失败，则会继续根据当前系统纳秒时间，来**计算剩余过期时间**，并且如果发现超过了定时时间，则会**返回false**，代表未能在规定时间内获取到锁，抢锁失败。
5. 如果没超过定时时间，则调用的是LockSupport.parkNanos(this, nanosTimeout)来**定时阻塞当前线程**。
6. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

##### 释放资源

1. 尝试以独占模式释放同步器，如果释放失败，则直接返回false即可，代表释放失败。

2. 如果释放成功，则需要继续判断头结点，如果头结点为空，或者为初始的普通结点，则返回true，代表释放成功。

3. 如果头结点为业务结点，则还需要调用**unparkSuccessor（head）**方法来唤醒后续排队的结点，唤醒后则返回true，代表释放成功。

   - 调用释放方法并不会重新设置头结点，而仅仅是更新头结点的waitStatus以及唤醒后继结点。
   - 而重新设置头结点和清空头结点，将留到其后继获取同步状态成功后进行更新，这样可以保证后继线程自己来确保成为头结点，比放在释放方法里由非头线程设置头结点要严谨一些。

   4. unparkSuccessor（head）方法，会先更新头结点的waitStatus为0，然后获取后继结点s，使用LockSupport.unpark(s.thread)来唤醒s结点的排队线程，代表当前结点出队成功。

#### 共享模式

- 共享模式下，tryAcquireShared返回的是int值，其含义取决于实现类定义的语义。
- PROPAGATE相当于启动一个**占位的作用**：
  - 获取到的资源非最后一个资源的结点，状态为PROPAGATE。
  - 获取到的资源最后一个资源的结点，状态一开始为0，不过很快就会在下一个结点阻塞前，设置为SINGAL；
  - 当它们释放共享锁时，如果为PROPAGATE结点释放，则无任何唤醒后继结点的操作，而如果为SINGAL结点释放，则会唤醒后继结点，接着又会重复出现PROPAGATE和SINGAL结点，然后往复之前的操作。

##### 获取资源

对比普通独占获取资源方法，共享获取资源方式，**主要不同的地方在于**：

1. 在尝试获取共享资源时，如果获取到的数量大于等于0，说明获取成功，此时直接返回即可。
2. 但在获取到的数量小于0时，说明获取失败，此时需要调用doAcquireShared方法来添加入队结点，但此时设置的结点的nextWaiter不在是默认的null，而是SHARED，代表为共享模式的结点。
3. 接着自旋判断到前驱为头结点，会进行一次尝试获取共享资源，如果获取的数量大于等于0，说明获取成功，则**调用setHeadAndPropagate方法**更新当前结点为头结点，**调用doReleaseShared方法**设置头结点为PROPAGATE，表示下一个线程获取共享锁后，自己的共享状态会被无条件地传播下去，**通知其他等待的线程尽快获取锁**。传播完毕后，返回之前需要判断当前线程是否有被中断，如果是的话则调用一次中断方法，重新设置线程中断标志再返回。
4. 如果获取的数量小于0，说明获取失败，则在调用shouldParkAfterFailedAcquire方法时，由于此时该前驱为最后一个成功获取资源的结点，所以会更新前驱为SINGAL，代表在前驱释放锁成功后，需要唤醒当前线程，接着使用LockSupport.park（this）来阻塞当前线程。
5. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，不会抛出中断异常，而是更新代码中断标志位为true。

##### 可中断式获取

对比普通共享获取资源方法，可抛中断异常获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会**提前抛出中断异常**，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireInterruptibly方法来添加入队结点。
3. 接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是**直接返回**。
4. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会**立马抛出中断异常**。

##### 定时式获取

对比普通共享获取资源方法，定时获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会提前抛出中断异常，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireSharedNanos方法来添加入队结点，并且根据当前系统纳秒时间，来**计算剩余过期时间**，如果定时时间小于等于0，则**返回false**，表未能在规定时间内获取到锁，抢锁失败。
3. 接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是**返回true**，代表在规定时间内成功获取到了锁。
4. 如果前驱不为头结点，或者抢锁失败，则会继续根据当前系统纳秒时间，来**计算剩余过期时间**，并且如果发现超过了定时时间，则会**返回false**，代表未能在规定时间内获取到锁，抢锁失败。
5. 如果没超过定时时间，则调用的是LockSupport.parkNanos(this, nanosTimeout)来**定时阻塞当前线程**。
6. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

##### 释放资源

1. 尝试以共享模式释放同步器，如果释放失败，则直接返回false即可，代表释放失败。
2. 如果释放成功，则需要继续判断头结点，如果头结点为SIGNAL结点，则需要调用unparkSuccessor（head）方法来唤醒后续排队的结点，唤醒后则返回true，代表释放成功。
   - unparkSuccessor（head）方法，会先更新头结点的waitStatus为0，然后获取后继结点s，使用LockSupport.unpark(s.thread)来唤醒s结点的排队线程，代表当前结点出队成功。
3. 如果头结点是waitStatus为0的普通结点（在并发设置传播特性时走到这里），则需要CAS更新waitStatus为PROPAGATE，然后返回true，代表释放成功。
   - 调用释放方法并不会重新设置头结点，而仅仅是更新头结点的waitStatus以及唤醒后继结点。
   - 而重新设置头结点和清空头结点，将留到其后继获取同步状态成功后进行更新，这样可以保证后继线程自己来确保成为头结点，比放在释放方法里由非头线程设置头结点要严谨一些。

#### 条件同步

![1630210049637](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210049637.png)

![1630210030025](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210030025.png)

- **ConditionObject数据结构**：
  - **firstWaiter**：条件队列的第一个节点。
  - **lastWaiter**：条件队列的最后一个节点。
- **ConditionObject构造方法**：
  - 由ReentrantLock.Sync#newCondition()方法调用，从而创建一个ConditionObject实例对象。

##### 条件阻塞等待

1. 首先会创建一个**Condition结点**，并放入Condition条件队列的队尾。
2. 然后获取全部的同步状态来释放锁，其中会调用**unparkSuccessor方法**唤醒AQS主等待队列中头结点的后继线程。
   - 这里执行的一次AQS释放锁操作，类似于执行一次synchronized重量级锁的【指定EntryList头结点线程为OnDeck Thread】一样，用于从**候选竞争队列EntryList**中选取就绪线程。
   - 由于要触发一次AQS抢锁操作，需要一定的资源次数来获取，为了不影响其他结点的使用，先获取了全部的同步器状态，然后马上全部释放掉，保证同步器状态不变，但是如果发生了并发问题，释放失败的话则会抛出IllegalMonitorStateException监视器异常。
3. 接着判断当前结点是否已经在AQS主等待队列中，如果还没有进入主等待队列，则执行while循环，将当前线程阻塞，直到该结点被调用**doSignal方法**离开等待队列，重新回到同步队列成为同步节点后，线程才退出while循环。如果期间发生了虚假唤醒，则需要检查线程中断状态，如果已发生了中断，则需要退出while循环。
   - 条件队列，相当于synchronized重量级锁的**cxq队列**，所有请求等待线程都是被放入这个队列中，在调用到结点的doSignal方法时，会将结点waitStatus更新为0，放入AQS主等待队列中参与AQS主等待队列的排队，在成功抢占锁后会退出Object#await那里的while循环。
   - 而这里的AQS主等待队列，则相当于synchronized重量级锁的**EntryList队列**，用于管理等待队列竞争锁的问题，同理，这里把条件队列结点转移到AQS主等待队列结点中等待，是因为需要把竞争锁的工作，交由更加专业的AQS主等待队列去完成。
4. 退出while循环后，代表结点肯定在AQS主等待队列中了，则开始调用acquireQueued方法尝试抢锁，如果没抢到锁，则使用LockSupport.part（this）进入阻塞，**根据AQS机制来实现唤醒**。
5. 当从acquireQueued方法中返回，说明当前线程已经抢到锁了，则先检查返回值，如果为true，说明抢锁期间发生了中断，则更新代码的中断模式为THROW_IE或者REINTERRUPT，然后继续运行。
6. 最后在void返回前，清空Condition条件队列中被取消的节点，响应代码更新到的中断模式。
   - REINTERRUPT，代表在退出等待时重新标记线程为已中断状态。
   - THROW_IE，代表在退出等待时要抛出nterruptedException。

##### 定时式等待

对比普通条件阻塞等待方法，定时等待的方式，**主要不同的地方在于**：

1. 在会创建Condition结点前，会先**校验线程是否已中断**，如果是则会提前抛出中断异常，阻止继续往下执行。
2. 接着进入判断是否在主等待队列+while阻塞循环前，会先根据系统纳秒时间，计算出超时时间，然后调用LockSupport.parkNanos(this, nanosTimeout)方法，来**定时阻塞当前线程**。
3. 当在while循环中发生了虚假唤醒，则重新计算超时时间，继续判断+循环，如果发现**已经超时了**，则取消Condition结点，交由AQS主等待队列去管理和释放。
4. 最后，在清空Condition条件队列中被取消的节点，且响应代码更新到的中断模式完毕后，不再是void返回了，而是返回是否发生了超时，**如果为true代表没有发生超时，如果为false代表发生了超时**。

##### 条件唤醒

1. 先更新指定的条件队列结点的waitStatus为0，然后enq方法自旋入队，返回其前驱结点p。
2. 如果前驱结点p的状态是取消状态，或者设置p为Signal状态失败，则唤醒当前线程，让其退出Condition#await中的while循环，进行一次抢占锁的操作，抢占失败则需要AQS机制来唤醒，从而保证必定能被AQS管理到。
3. 如果结点顺利入队，则参与AQS主等待队列的排队，交由AQS机制来管理和释放。

#### 典型实现

![1630201659838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201659838.png)

##### CountDownLatch

- CountDownLatch，一种同步辅助，**它允许一个或多个线程等待，直到执行的一组操作完成才唤醒这些线程**。
- {@code CountDownLatch} 使用给定的计数进行初始化，{@link #await await} 方法阻塞，直到当前计数由于 {@link #countDown} 方法的调用而达到零，之后所有等待线程都被释放，并且 {@link #await await} 的任何后续调用立即返回。这是一种**一次性现象**（即计数无法重置），如果需要重置计数的版本，请考虑使用 {@link CyclicBarrier}。
- {@code CountDownLatch} 是一种**多功能同步工具**，可用于多种用途。 
  - 计数初始化为1的 {@code CountDownLatch} 用作简单的开关锁存器或门闩。所有调用 {@link #await await} 的线程在门处等待，直到它被调用 {@link # countDown}。
  - 计数初始化为 N 的 {@code CountDownLatch} 可用于使一个线程等待，直到 N 个线程完成某个操作，或者某个操作已完成 N 次。

###### Sync

- **tryAcquireShared**：实现钩子方法，尝试获取共享资源。
  1. 如果计数为0，则返回1，代表获取资源成功，此时在共享模式下，会唤醒一个又一个的线程，实现**释放全部等待线程**的功能。
  2. 如果计数不为0，则返回-1，代表获取资源失败，此时在共享模式下，会**阻塞所有排队线程**。
- **tryReleaseShared**：实现钩子方法，尝试释放共享资源。这里的共享释放，做的是**传播，而非许可的累加**。
  1. 开始自旋，如果计数为0，则返回false，代表门闩资源释放失败，因为计数已经为0，不能再减了。
  2. 如果计数不为0，则计数-1，然后使用CAS更新，最后返回更新后是否为0。
     - 如果为0，则返回true，代表当前线程为最后一个到达门闩的线程，需要**释放资源**。
     - 如果不为0，则返回false，代表当前线程不是最后一个到达的线程，需要继续**阻塞等待**。

###### await

1. 由“主线程”调用，传入的参数为1，代表需要获取1个资源。
2. 由于实现了tryAcquireShared钩子方法，1又不等于0，所以每次都会返回-1，代表获取资源失败，导致**主线程入队+阻塞**。

###### countDown

1. 由"子线程"调用，传入的参数为1，代表需要释放1个资源。
2. 由于实现了tryReleaseShared钩子方法，该方法每次都会减少1，如果没减到0，则返回false，代表当前线程还不是最后一个到达的线程，因此不会做任何唤醒操作。
3. 而如果减到了0，则返回true，代表当前线程为**最后一个到达的线程**，因此会调用doReleaseShared方法，唤醒头结点后继线程，由于资源为0，所以该后继线程能够获取资源成功，进而继续唤醒后继线程，实现唤醒等待线程的功能。

##### ReentrantLock

- ReentrantLock，**{@link Lock}接口的可重入、互斥锁实现**，与使用{@code synchronized}方法和语句访问的隐式监视器锁具有相同的基本行为和语义，但具有扩展功能，由上次成功lock但尚未unlock的线程拥有：
  - 当锁不属于另一个线程时，调用 {@code lock} 的线程将返回并成功获取锁。
  - 如果当前线程已经拥有锁，该方法将立即返回。 可以使用方法 {@link #isHeldByCurrentThread} 和 {@link #getHoldCount} 进行检查。
- ReentrantLock的构造函数接受一个可选的公平参数，当设置{@code true}时，在争用情况下，锁倾向于授予对**等待时间最长的线程**的访问权限，否则这个锁不能保证这个特定的访问顺序。与使用默认设置的程序相比，使用由多个线程访问的公平锁的程序可能会显示出较低的总体吞吐量（即更慢，通常慢得多），但是能避免线程饥饿问题。
  - 请注意，**锁的公平性并不能保证线程调度的公平性**。因此，使用公平锁的许多线程之一可能会连续多次获得它，而其他活动线程没有进行并且当前没有持有该锁。
  - 另请注意，**未计时的 {@link #tryLock()} 方法不符合公平性设置**。 即使其他线程正在等待，如果锁可用，它也会成功。
- ReentrantLock，建议的做法是，在lock成功获取锁后需要try-finally或try-catch的保护，以确保在必要时unlock。

###### Sync

- **nonfairTryAcquire**：非钩子方法，用于提供公共的**非公平、非阻塞**获取独占资源的方法。
  1. 先获取当前锁次数，如果锁次数为0，则CAS更新锁次数为需要获取的次数，更新成功后设置当前线程为独占线程，然后返回true，代表获取独占资源成功。
  2. 如果锁次数不为0，但当前独占线程为当前线程，则累加需要获取的次数为锁次数，代表**锁重入**，然后返回true，代表获取独占资源成功。
  3. 如果锁次数不为0，当前独占线程也不为当前线程，则返回false，代表获取锁失败，需要等待独占线程释放锁。
- **tryRelease**：实现钩子方法，**作为公共的锁释放方法**，尝试释放独占资源。
  1. 计算剩余锁次数 = 当前锁次数 - 需要释放的锁次数。
  2. 如果当前独占的线程不为当前线程，则抛出IllegalMonitorStateException监视器异常。
  3. 如果当前独占的线程确实为当前线程，如果剩余锁次数为0，则**清空当前独占的线程**、更新锁次数，并返回true，代表锁已经被释放了。
  4. 如果剩余锁次数不为0，则只更新锁次数，然后返回false，代表锁仍然被持有。

###### NonfairSync

- **lock**：实现Lock#lock方法。
  1. CAS更新锁次数为1，只有锁次数为0，才会更新成功，更新成功后设置当前线程为独占线程，实现**非公平提前抢锁成功**的功能。
  2. 如果锁次数不为0，则会更新失败，此时调用AQS#acquire方法非公平+入队+阻塞，实现**非公平、阻塞获取锁**的功能。
- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 调用Sync公共的非钩子方法，用于提供公共的**非公平、非阻塞**获取独占资源的方法。

###### FairSync

- **lock**：实现Lock#lock方法，阻塞获取锁。
  1. 直接调用AQS#acquire方法公平抢锁+入队+阻塞，实现**公平、阻塞获取锁**的功能。
- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 先获取当前锁次数，如果锁次数为0，且AQS主等待队列中不存在任何排队线程，才会使用CAS更新锁次数为需要获取的次数，更新成功后设置当前线程为独占线程，然后返回true，代表获取独占资源成功，实现**公平按排队顺序抢锁**的功能。
  2. 如果锁次数不为0，但当前独占线程为当前线程，则累加需要获取的次数为锁次数，代表**锁重入**，然后返回true，代表获取独占资源成功。
  3. 如果锁次数不为0，当前独占线程也不为当前线程，则返回false，代表获取锁失败，需要等待独占线程释放锁。

###### 阻塞式获取锁

```java
// 阻塞方式获取锁
public void lock() {
    sync.lock();
}

```

###### 可中断式获取锁

```java
// 以阻塞、独占可中断模式获取同步器
public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

```

###### 快速失败式获取锁

```java
// 非公平方式尝试获取锁, 如果可用则获取锁并立即返回值{@code true}; 如果锁不可用, 则立即返回值{@code false}
public boolean tryLock() {
    return sync.nonfairTryAcquire(1);
}

```

###### 定时式获取锁

```java
// 定时可中断式尝试获取锁, 获得则返回true, 否则返回false
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

```

###### 释放锁

```java
// 释放锁
public void unlock() {
    sync.release(1);
}

```

##### ReentrantReadWriteLock

- ReentrantReadWriteLock，{@link ReadWriteLock} 的实现，支持与 {@link ReentrantLock} 类似的语义。
- ReentrantReadWriteLock具有一下属性：
  - **非公平模式（默认）**: 
    - 当构造为**非公平（参数为false）**时，读写锁的进入顺序是未指定的，受重入约束。
    - 持续竞争的非公平锁，可能会无限期推迟一个或多个读或写线程（线程饥饿），但通常比公平锁具有更高的吞吐量。
  - **公平模式**：
    - 当构造为**公平（参数为true）**时，线程使用近似到达顺序策略竞争进入。只有当前持有的锁被释放时，等待时间最长的写线程才会被分配写锁。或者如果有一组读线程等待的时间比所有等待写入器线程都长，则该组将被分配读取锁。
    - 如果写锁被持有，如果有一个试图获取**公平读锁（非可重入）**的线程将被阻塞，那么它将会直到当前等待的最老的写线程获得并释放写锁之后，该线程才会获得读锁。
    - 同理，如果一个等待的写线程放弃等待，留下一个或多个读线程作为队列中最长的等待者，并且写入锁空闲，那么这些读取器将被分配读取锁。
    - 除非读锁和写锁都是空闲的（这意味着没有等待线程），否则尝试获取公平写锁（非可重入）的线程将阻塞。
    - 请注意，非阻塞 {@link ReadLock#tryLock()} 和 {@link WriteLock#tryLock()} 方法不遵守此公平设置，如果可能将会立即获取锁，而不管等待线程。
  - **可重入性**：
    - ReentrantReadWriteLock，允许读和写以 {@link ReentrantLock} 接口的样式重新获取读或写锁。 
    - 但在写线程持有的所有写锁都被释放之前，不允许非可重入读锁。
    - 此外，写线程可以获取读锁，但反之则不行。基于这点，当调用或回调在读锁下，执行读取的方法期间持有写锁时，可重入可能很有用。
    - 而如果读线程试图获取写锁，它将永远不会成功。
  - **锁降级**：
    - 根据可重入性，ReentrantReadWriteLock允许从写锁降级到读锁，通过获取写锁，然后获取读锁，然后释放写锁，此时仍然持有读锁。
    - 但是，无法从读锁升级到写锁，即**只支持锁降级，不支持锁升级**。
  - **锁获取中断**：读锁和写锁，都允许线程在获取锁期间发生中断。
  - **Condition支持**：
    - 写锁提供了一个 {@link Condition} 实现，它的行为方式与写锁相同，就像 {@link ReentrantLock#newCondition} 为 {@link ReentrantLock} 提供的{@link Condition} 实现一样。因此， **该{@link Condition} 只能与写锁一起使用**。
    - **读锁不支持 {@link Condition}**， 并且 {@code readLock().newCondition()} 抛出 {@code UnsupportedOperationException}。
  - **仪表监控**：
    - ReentrantReadWriteLock，支持确定是持有锁还是争用锁的方法。
    - 这些方法设计用于监视系统状态，而不是用于同步控制。
- ReentrantReadWriteLock，可用于在某些类型的集合的某些用途中**提高并发性**。这通常只有在**预期集合很大**、**访问的读取线程比写入线程多**、**读取时需要的开销超过同步的开销**时才有意义。

###### Sync

- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 先获取当前锁状态，根据锁状态获取独占线程的个数（int的低16位）。
  2. 如果锁状态不为0，且独占线程个数为0或者当前独占线程不为当前线程，则返回false，代表存在**读线程不允许获取写锁**。
  3. 如果锁状态不为0，且当前独占线程为当前线程，说明是当前线程获取到了写锁，则累加低16位累加锁次数，然后返回true，代表**写锁重入**。
  4. 否则锁状态为0，如果**获取写锁需要等待**，或者CAS更新累加后的锁状态失败，则返回false，代表**写锁获取失败**。
  5. 如果写锁不需要等待，且CAS更新累加后的锁状态成功后，则设置当前独占线程为当前线程，然后返回true，代表**写锁获取成功**。
- **tryRelease**：实现钩子方法，尝试释放独占资源。
  1. 判断当前独占线程是否为当前线程，如果不是，则抛出监视器异常IllegalMonitorStateException。
  2. 如果当前独占线程为当前线程，则获取锁次数**低16位扣减**需要的锁次数，然后根据扣减后的锁次数，获取写锁次数，如果写锁次数为0，说明**写锁被释放了**，则清空当前独占线程。
  3. 如果写锁仍未释放，或者被释放且清空了独占线程，则更新锁状态，然后返回写锁释放结果，**如果为true，代表写锁释放成功，如果为false，代表写锁仍未释放**。
- **tryAcquireShared**：实现钩子方法，尝试获取共享资源。
  1. 先获取锁状态，根据锁状态获取写锁次数，如果写锁次数不为0，且当前独占线程不为当前线程，则返回-1，代表共享资源获取失败。
  2. 如果写锁次数为0，或者当前独占线程为当前线程，说明没有写线程，或者当前线程已经持有了写锁，则根据锁状态获取读锁次数，如果**获取读锁不需要被阻塞**，则CAS更新**高16位读锁次数**，更新成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），最后返回1，代表读锁获取成功。
  3. 如果**获取读锁需要等待**，或者CAS更新**高16位读锁次数**失败，则开始自旋，如果自旋先判断到独占线程存在，且不为当前线程，则返回-1，代表读锁获取失败，因为**其他线程持有了写锁**。
  4. 否则写锁没被持有，或者写锁被当前线程持有，如果确实在**获取读锁需要等待**（需要在缓存读锁计数失效时返回false），如果缓存中的读锁次数为0（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），说明当前线程的读锁已经释放了，不可继续重入，则返回-1，代表读锁获取失败，因为当前线程不为第一个获得读锁的线程，所以需要重新排队，从而实现**排队获取读锁**。
  5. 如果判断过了独占线程，以及缓存读锁次数后依然没问题，说明当前线程可以继续重入，则CAS更新**高16位读锁次数**，更新成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），最后返回1，代表读锁获取成功；如果CAS更新失败，在继续自旋判断+重新更新。
- **tryReleaseShared**：实现钩子方法，尝试释放共享资源。
  1. 判断当前线程是否命中一级缓存，缓存读锁次数为1，说明当前线程为最后一个释放读锁的线程，则清空f一级缓存，使得该线程下次能够继续获取读锁；如果读锁次数不为1，说明当前线程还可以继续重入，则减少读锁次数。
  2. 如果当前线程没有命中二级缓存，则更新缓存的读锁次数-1（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存）。
  3. 缓存的读锁次数更新完毕后，则开始自旋，**高16位减少一单位的锁状态**，然后CAS更新，如果CAS更新失败则继续自旋计算+更新。
  4. 否则，CAS更新成功，如果剩余锁状态为0，则返回true，代表读锁释放成功；如果剩余锁状态不为0，则返回false，代表读锁仍未释放成功。
- **tryWriteLock**：尝试以非公平、非阻塞方式获取独占资源（写锁），相比tryAcquire少了writerShouldBlock的调用，即在锁状态为0时，CAS更新累加后的锁状态前，**不需要校验写锁是否需要等待**。
  1. 先获取当前锁状态，根据锁状态获取独占线程的个数（int的低16位）。
  2. 如果锁状态不为0，且独占线程个数为0或者当前独占线程不为当前线程，则返回false，代表存在**读线程不允许获取写锁**。
  3. 如果锁状态不为0，且当前独占线程为当前线程，说明是当前线程获取到了写锁，则累加低16位累加锁次数，然后返回true，代表**写锁重入**。
  4. 否则锁状态为0，如果CAS更新累加后的锁状态失败，则返回false，代表**写锁获取失败**。
  5. 如果CAS更新累加后的锁状态成功后，则设置当前独占线程为当前线程，然后返回true，代表**写锁获取成功**。
- **tryReadLock**：尝试以非公平、非阻塞方式获取共享资源（读锁），相比tryAcquireShared少了对readerShouldBlock的调用，即无需在缓存读锁计数失效时返回false，这些缓存是用于**获取当前线程的读锁重入次数**，以及在控制公平获取读锁时，用于判断线程是可以重入，还是已经释放过了再获取则需要**重新排队**。
  1. 先获取锁状态，根据锁状态获取写锁次数，如果写锁次数不为0，且当前独占线程不为当前线程，则返回-1，代表共享资源获取失败。
  2. 如果写锁次数为0，或者当前独占线程为当前线程，说明没有写线程，或者当前线程已经持有了写锁，则根据锁状态获取读锁次数，如果CAS更新**高16位读锁次数**成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则累加一级缓存，如果命中二级缓存则累加二级缓存），最后返回1，代表读锁获取成功。
  3. 如果CAS更新**高16位读锁次数**失败，则继续自旋判断+更新。

###### NonfairSync

- **writerShouldBlock**：获取写锁时是否需要等待。
  - 由于为非公平抢锁，所以返回false，代表**永远不需要等待写锁**，实现**非公平抢锁**的功能。
- **readerShouldBlock**：获取读锁时是否需要等待。
  - 如果AQS主等待队列中头结点后继为独占结点，则返回true，说明第一个线程为独占线程，此时获取读锁需要等待。
  - 如果AQS主等待队列中头结点后继为共享结点，则返回false，说明第一个线程不为独占线程，此时获取读锁不需要等待，实现**非公平抢锁**的功能。

###### FairSync

- **writerShouldBlock**：获取写锁时是否需要等待。
  - 由于为公平抢锁，所以需要判断AQS主等待队列头结点后继的线程实例是否存在，如果存在则返回true，代表需要**公平排队获取写锁**。
- **readerShouldBlock**：获取读锁时是否需要等待。
  - 由于为公平抢锁，所以需要判断AQS主等待队列头结点后继的线程实例是否存在，如果存在则返回true，代表需要**公平排队获取读锁**。

###### 阻塞式获取读锁

```java
// 共享方式获取读锁, 如果写锁未被另一个线程持有，则获取读锁并立即返回; 如果写锁被另一个线程持有, 则当前线程会阻塞
public void lock() {
    sync.acquireShared(1);
}

```

###### 可中断式获取读锁

```java
// 可中断共享方式获取读锁, 如果写锁未被另一个线程持有，则获取读锁并立即返回; 如果写锁被另一个线程持有, 则当前线程会阻塞
public void lockInterruptibly() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

```

###### 快速失败获取读锁

```java
// 非公平、共享方式尝试获取锁, 如果写锁未被另一个线程持有, 则获取读锁并立即返回值 {@code true}; 如果写锁被另一个线程持有，则此方法将立即返回值 {@code false}
public boolean tryLock() {
    return sync.tryReadLock();
}

```

###### 定时式获取读锁

```java
// 非公平、定时、可中断、共享方式尝试获取锁, 如果写锁未被另一个线程持有, 则获取读锁并立即返回值 {@code true}; 如果写锁被另一个线程持有，则此方法将立即返回值 {@code false}
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

```

###### 释放读锁

```java
// 共享方式释放锁, 如果读锁同步器状态现在为0, 则会尝试共享方式释放读锁
public void unlock() {
    sync.releaseShared(1);
}

```

###### 阻塞式获取写锁

```java
// 独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public void lock() {
    sync.acquire(1);
}

```

###### 可中断式获取写锁

```java
// 独占、可中断方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

```

###### 快速失败式获取写锁

```java
// 非公平、独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public boolean tryLock( ) {
    return sync.tryWriteLock();
}

```

###### 定时式获取写锁

```java
// 非公平、定时、可中断、独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

```

###### 释放写锁

```java
// 独占方式释放锁, 如果当前线程是此锁的持有者, 则持有计数递减; 如果保持计数现在为零, 则锁定被释放; 如果当前线程不是此锁的持有者, 则抛出 {@link IllegalMonitorStateException}
public void unlock() {
    sync.release(1);
}

```

##### Semaphore

- Semaphore，计数信号量，从概念上讲，**信号量维护一组许可**。
  - 每个{@link#acquire}会直到许可证是可用的，然后获取。
  - 每个{@link#RELEASE}添加一个许可，释放阻塞的获取线程。
  - 实际上{@code Semaphore}有维护许可对象，它只是让计数可用，从而采取相应的行动。
- 信号量通常用于限制可以访问某些（物理或逻辑）资源的线程数。 
- Semaphore，可以初始化为 1 的信号量，并且使用时最多只有一个许可可用，用作互斥锁。 这通常被称为**二元信号量**，因为它只有两种状态：一个许可可用，或零个许可可用。以这种方式使用时，二进制信号量具有属性（与许多 {@link java.util.concurrent.locks.Lock} 实现不同），即“锁”可以由所有者以外的线程释放（因为**信号量具有没有所有权的概念**），这在某些特定上下文中很有用，例如**死锁恢复**。
- Semaphore的构造函数可以选择接受公平参数：
  - 当公平性设置为 false 时，为非公平模式，则不保证线程获取许可的顺序。特别是，允许插入，即调用 {@link #acquire} 的线程可以在一直等待的线程之前，分配一个许可（逻辑上，新线程将自己置于等待线程队列的头部）。
  - 当公平性设置为true时，为公平模式，信号量保证调用任何 {@link #acquire()acquire} 方法的线程被选择以按照它们对这些方法的调用的处理顺序（先进先出）获得许可。
  - 请注意，未计时的 {@link #tryAcquire() tryAcquire} 方法**不遵守公平设置**，但会采用任何可用的许可。
  - 通常，**用于控制资源访问的信号量应初始化为公平的**，以确保没有线程因访问资源而饿死。 当使用信号量进行其他类型的同步控制时，**非公平排序的吞吐量大于公平性排序的吞吐量**。

###### Sync

- **tryReleaseShared**：实现钩子方法，自旋尝试释放共享资源，直到释放到许可则返回true。这里的共享释放，做的是**许可的累加，而非传播**。
  1. 开始自旋，获取最新的许可数量，计算累加需要释放的许可数量，如果累加后的结果反而还小了，则抛出错误，因为**不能释放负数的许可**。
  2. 否则CAS更新许数量为累加后的结果，如果CAS成功，则返回true，代表获取许可成功，否则继续自旋。
- **nonfairTryAcquireShared**：非钩子方法，非公平自旋方式获取共享资源，直到获取到才返回剩余许可。
  1. 开始自旋，获取最新的许可数量，扣减需要获取的许可数量，如果扣减后的剩余许可数量小于0，则返回负数，代表资源获取失败。
  2. 如果剩余许可数量大于等于0，则CAS更新许可数量，更新成功则**返回剩余许可数量**，否则继续自旋。

###### NonfairSync

- **tryAcquireShared**：实现钩子方法，底层调用Sync#nonfairTryAcquireShared方法，会非公平自旋方式获取共享资源。

###### FairSync

- **tryAcquireShared**：实现钩子方法，对比Sync#nonfairTryAcquireShared方法，扣减许可前会先判断AQS主队列头结点后继线程是否已经存在，如果是则返回-1，代表获取共享资源失败，需要去排队。

###### 可中断阻塞式获取许可

```java
// 以阻塞、共享可中断模式获取同步器状态
public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

```

###### 不可中断阻塞式获取许可

```java
// 以阻塞、不可中断、共享模式获取同步器状态
public void acquireUninterruptibly() {
    sync.acquireShared(1);
}

```

###### 快速失败式获取许可

```java
// 非公平快速失败方式获取同步器状态
public boolean tryAcquire() {
    return sync.nonfairTryAcquireShared(1) >= 0;
}

```

###### 定时式获取许可

```java
// 以阻塞、共享、定时、可中断模式获取同步器状态
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

```

###### 释放许可

```java
// 尝试释放共享模式的同步器状态, 如果释放成功, 则返回true; 如果释放失败, 则返回false
public void release() {
    sync.releaseShared(1);
}

```

##### ThreadPoolExecutor

###### Worker

线程工人类，实现Runnable本身可以作为一个任务，实现AQS以简化获取和释放围绕每个任务执行的锁，实现了一个简单的**不可重入的、互斥的任务锁**。

- **tryAcquire**：实现钩子方法，尝试获取独占资源，如果更新锁计数为1，则设置当前线程为独占线程，然后返回true，代表获取独占锁成功；否则返回false，代表获取独占锁失败。
- **tryRelease**：实现钩子方法，尝试释放独占资源，清空独占线程，并重置锁计数为0，永远返回true，代表独占锁释放成功。

###### 阻塞式获取锁

```java
// 阻塞式获取锁, 快速失败失败还会进去AQS队列中排队
public void lock()        { acquire(1); }

```

###### 快速失败式获取锁

```java
// 快速失败式获取锁, 只会将0 CAS更新为1(unused没用), CAS成功则设置当前线程为独占线程, 并返回true, 代表获取成功, 否则返回false, 代表获取失败
public boolean tryLock()  { return tryAcquire(1); }

```

###### 释放锁

```java
// 释放锁, 只会将同步状态设置为0, 并清空独占线程以及返回true, 代表释放成功
public void unlock()      { release(1); }

```

##### CyclicBarrier

- CyclicBarrier，一种同步辅助工具，它允许一组线程全部等待彼此到达公共屏障点，在涉及固定大小的线程组的程序中很有用。
- CyclicBarrier屏障之所以被称为Cyclic循环的，因为它可以在等待线程被释放后**重新使用**。
- {@code CyclicBarrier} 支持一个可选的 {@link Runnable} 命令，该命令在每个屏障点运行一次，在参与者中的最后一个线程到达之前，其他参与者线程都会被阻塞。此屏障操作对于在任何一方继续之前更新共享状态很有用，为方便起见，每次调用 {@link #await}（被唤醒后） 都会返回该线程在屏障处的**到达索引**。
- {@code CyclicBarrier}的每次使用都表示为一个生成Generation实例，每当障碍物被触发或重置时，Generation都会发生变化，因此可以有许多Generation与使用{@code CyclicBarrier}的线程相关联。
  - 由于锁以不确定的方式分配给等待线程，但一次只能激活Generation其中之一，因此其余的Generation要么坏了要么被绊倒了。
  - 另外，如果有中断但没有后续复位，则该Generation将损坏。

###### await

1. 先阻塞式获取栅栏入口的ReentrantLock，获取到后则获取分代实例Generation，如果发现Generation已经损坏，则抛出BrokenBarrierException异常。
2. 如果Generation还没损坏，则再检验当前线程的中断状态，如果已中断，则破坏当前Generation，重置栅栏参与线程数，并唤醒所有等待的线程。
3. 如果Generation还没损坏，且当前线程没被中断，说明当前线程达到了栅栏，因此参与数-1。
4. 如果减少到了0，说明当前线程为最后一个到达栅栏的线程，则还需要运行栅栏任务（如果有），生成下一代Generation，重置栅栏参与线程数，并唤醒所有等待的线程，并返回0，代表最后一个到达栅栏的索引。
5. 如果还没减少到0，则开始自旋，如果不需要超时，则调用Condiction#await阻塞当前线程，如果还没发生超时，则调用Condiction#awaitNanos定时阻塞当前线程。
6. 当最后一个线程达到栅栏，或者等待期间任意一个线程发生了中断，会破坏当前Generation，唤醒所有线程，如果唤醒后判断到当前Generation已损坏，则抛出BrokenBarrierException异常。
7. 如果Generation没损坏，但已被更新，说明最后一个线程确实到达了栅栏，则返回当前线程达到索引（越接近0，说明越完到达）。
8. 如果Generation没损坏，但没被更新，说明当前线程发生了等待超时，则破坏当前Generation，唤醒所有线程，并抛出超时异常TimeoutException。
9. 最后释放栅栏入口的ReentrantLock。

### 4.7. synchronized与ReentrantLock与的区别？

| 区别点   | Synchronized                   | ReentrantLock                    |
| -------- | ------------------------------ | -------------------------------- |
| 使用方式 | 是一个关键字                   | 是一个实现类                     |
| 实现方式 | 由JVM实现控制                  | 由AQS实现控制                    |
| 锁的获取 | 如果资源被锁，会一直等待       | 如果资源被锁，可以有多种处理方式 |
| 锁的释放 | 被锁的代码执行完，或者发生异常 | 需要在finally中，手动编程释放    |
| 锁的状态 | 无法判断                       | 可以判断，isLocked（）           |
| 锁的特性 | 可重入、不可中断、非公平锁     | 可重入、可中断、公平锁、非公平锁 |

```java
【ReentrantLock可中断锁】
ReentrantLock中的lockInterruptibly()方法使得线程可以在被阻塞时响应中断，比如一个线程t1通过lockInterruptibly()方法获取到一个可重入锁，并执行一个长时间的任务，另一个线程通过interrupt()方法就可以立刻打断t1线程的执行，来获取t1持有的那个可重入锁。
而通过ReentrantLock的lock()方法或者Synchronized持有锁的线程是不会响应其他线程的interrupt()方法的，直到该方法主动释放锁之后才会响应interrupt()方法。

```

### 4.8. 内存泄露与内存溢出？

#### 内存泄露

内存泄漏，memory leak，指不再用到的内存没有及时释放。

- 对于持续运行的服务进程必须及时释放内存，否则系统可用的内存会越来越小，内存占用率越来越高，轻则影响系统性能，重则导致内存不足、进程崩溃甚至操作系统崩溃。

#### 内存溢出

内存溢出，out of memory，指应用所需要的内存超过了系统所能分配的内存，从而导致应用没法正常工作，直接后果是导致应用程序崩溃，严重了还会导致系统安全问题。

- 内存溢出无法根本解决，只能尽可能避免，比如说在应用程序申请内存之前对可用内存进行检查、增大分配给应用的内存、优化程序代码、减少应用中的大数据复杂操作等。

### 4.9. 详细介绍ThreadLocal？

#### 背景

- 为了保证多个线程对变量的安全访问，将变量放到某个对象中，使变量在每个线程中都有独立值，不会出现一个线程读取变量时，被另一个线程修改的现象，JDK设计了ThreadLocal类，通常被翻译为“**线程本地变量**”类或者“**线程局部变量**”类。
  1. 如果程序创建了一个ThreadLocal实例，那么在访问这个变量的值时，每个线程都会拥有一个独立的、自己的本地值。
  2. “线程本地变量”可以看成专属于线程的变量，不受其他线程干扰，保存着线程的专属数据。
  3. 当线程结束后，每个线程所拥有的那个本地值会被释放。在多线程并发操作“线程本地变量”的时候，线程各自操作的是自己的本地值，从而规避了线程安全问题。

#### 特点

- ThreadLocal，**提供线程局部变量**，依赖于附加到每个线程的Map中，即Thread.threadLocals 和inheritableThreadLocals，使得每个访问的线程都有**自己的、独立的变量副本**。
  - 在该Map中**ThreadLocal 对象充当键**，通过threadLocalHashCode进行搜索，这是一个自定义哈希代码（仅在 ThreadLocalMaps 中有用），它消除了在相同线程使用连续构造的 ThreadLocals 的常见情况下的冲突，同时在不太常见的情况下保持良好行为。
  - 只要线程处于活动状态，并且 {@code ThreadLocal} 实例可访问，每个线程都持有对其线程局部变量副本的**隐式引用**；线程消失后，它的所有线程本地实例副本都将进行**垃圾回收**（除非存在对这些副本的其他引用）。
- ThreadLocal是**解决线程安全问题**的一个较好的方案，通过为每个线程提供一个独立的本地值去解决并发访问的冲突问题。在很多情况下，使用ThreadLocal比直接使用同步机制（如synchronized）解决线程安全问题更简单、更方便，且结果程序**拥有更高的并发性**。其使用场景大致可以分为以下两类：
  - **线程隔离**：
    - ThreadLocal的主要价值在于线程隔离，ThreadLocal中的数据只属于当前线程，其本地值对别的线程是不可见的，在多线程环境下，可以防止自己的变量被其他线程篡改。
    - 另外，由于各个线程之间的数据相互隔离，**避免了同步加锁**带来的性能损失，大大提升了并发性的性能。
    - 常见的案例有：数据库连接独享、Session数据管理等，由于每个线程绑定一个数据库连接，使得这个数据库连接为线程所独享，从而避免数据库连接被混用而导致操作异常问题。
  - **跨函数传递数据**：
    - 因为ThreadLocal的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到，线程执行过程中所执行到的函数，都能读写ThreadLocal变量的线程本地值，从而可以方便地实现跨函数的数据传递。
    - 使用ThreadLocal保存函数之间需要传递的数据，在需要的地方直接获取，也能**避免通过参数传递数据带来的高耦合**。
    - 常见的案例有：用来传递请求过程中的用户ID、请求过程中的Session、HTTP的用户请求实例HttpRequest，以及其他在函数之间频繁传递的数据等。

#### 实现原理

##### 早期实现

- 早期版本的ThreadLocal是这样设计的，一个ThreadLocal实例可以形象地理解为一个Map，当工作线程Thread实例向本地变量保持某个值时，会以“Key-Value对"的形式保存在ThreadLocal内部的Map中。
- 其中Key为线程**Thread实例**，Value为待保存的值，当工作线程Thread实例从ThreadLocal本地变量取值时，会以Thread实例为Key，获取其绑定的Value。

![1630407029053](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630407029053.png)

##### 优化后的实现

- 经过后来的优化后（下面的源码都以优化后的数据结构为准），ThreadLocal的内部结构发生了演进，虽然还是使用了Map结构，但是Map结构的拥有者已经发生了变化，其拥有者为Thread实例，**每一个Thread实例拥有一个Map实例**，且Key值也发生了变化，由之前的Thread实例更改为了**ThreadLocal实例**。
- 每一个Thread线程内部都有一个ThreadLocalMap，如果给一个Thread创建多个ThreadLocal实例，然后放置本地数据，那么当前线程的ThreadLocalMap中就会有多个“Key-Value对”，其中ThreadLocal实例为Key，本地数据为Value。
- 每一个线程在获取本地值时，都会将ThreadLocal实例作为Key从自己拥有的ThreadLocalMap中获取值，别的线程无法访问自己的ThreadLocalMap实例，自己也无法访问别人的ThreadLocalMap实例，达到相**互隔离，互不干扰**。

![1630411048268](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630411048268.png)

##### 变化点

| 变化点                         | 早期实现            | 优化后的实现    |
| ------------------------------ | ------------------- | --------------- |
| Key发生了变化                  | Thread实例          | ThreadLocal实例 |
| ThreadLocalMap拥有者发生了变化 | 拥有者为ThreadLocal | 拥有者为Thread  |

##### 优化的好处

- **每个ThreadLocalMap存储的“Key-Value对”数量变少**，早期版本的“Key-Value对”数量与线程个数强关联，如果线程数量多，则ThreadLocalMap存储的“Key-Value对”数量也多，而新版本的ThreadLocalMap的Key为ThreadLocal实例，多线程情况下ThreadLocal实例比线程数少。
- 早期版本ThreadLocalMap的拥有者为ThreadLocal，在Thread实例销毁后，ThreadLocalMap还是存在的；而新版本的ThreadLocalMap的拥有者为Thread，在当Thread实例销毁后，ThreadLocalMap也会随之销毁，**在一定程度上能减少内存的消耗**。

#### 线程本地变量

```java
public class Thread implements Runnable {
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
    ...
}

// ThreadLocal.ThreadLocalMap
public class ThreadLocal<T> {
    static class ThreadLocalMap {
        private static final int INITIAL_CAPACITY = 16;// 初始容量，必须是2的幂
        private Entry[] table;// 散列表，table.length必须始终是2的幂
        private int size = 0;// 散列表实际大小
        private int threshold;// 散列表阈值

        // 条目对象
        static class Entry extends WeakReference<ThreadLocal<?>> {
            Object value;

            // Entry#Key 强引用=> WeakReference 弱引用-> ThreadLocal:v
            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
    }
}

```

##### 设置原理

**Thread#set**：设置当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果获取到的ThreadLocalMap实例为空，说明本地变量还没初始化，则调用setInitialValue方法设置初始值，先获取初始值, 如果ThreadLocal.ThreadLocalMap threadLocals已被初始化, 则为其赋初值, 否则**惰性构造**默认容量16、默认负载因子16 * 2/3、当前ThreadLocal实例作为第一个Entry#Key的ThreadLocalMap。
3. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则直接返回即可。
4. 如果获取到的Entry弱键为空，说明存在弱键已失效，则清空该槽设置一个弱键包装后的key-value条目，然后向后清空所有弱键为空的槽。
5. 如果获取到的Entry为null，则新增一个key-value条目，更新实际大小，向后清除清空所有弱键为空的槽。
6. 接着判断**是否需要扩容**，如果当前实际大小大于等于阈值（len *  1/2），说明需要扩容，则调用resize方法进行扩容，否则直接返回即可。
   - **ThreadLocalMap#resize**：ThreadLocalMap扩容方法，创建两倍容量的新散列表 -> 遍历旧表，重新计算该元素在新表上的索引，转移结点到新表 -> 根据新表容量设置阈值（len * 2/3）-> 更新新表、更新实际大小 -> 最后返回。

##### 删除原理

**Thread#remove**：删除当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则清空WeakReference.referent（即清空弱键，会导致e.get()返回null），然后清空该槽，并且向后清空所有弱键为空的槽，最后返回。

##### 获取原理

**Thread#get**：获取当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果获取到的ThreadLocalMap实例为空，说明本地变量还没初始化，则调用setInitialValue方法设置初始值，先获取初始值, 如果ThreadLocal.ThreadLocalMap threadLocals已被初始化, 则为其赋初值, 否则**惰性构造**默认容量16、默认负载因子16 * 2/3、当前ThreadLocal实例作为第一个Entry#Key的ThreadLocalMap。
3. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则直接返回即可。
4. 如果根据计算出来的索引获取不到Entry，则调用getEntryAfterMiss查找：如果弱键为空，说明存在弱键已失效，则清空该槽，并且向后清空所有弱键为空的槽；否则向后线性探测下一个Entry，继续遍历；如果**线程探测+清空缓存**后，仍然找不到key匹配的Entry，则返回null。

#### 内存泄露

##### ThreadLocal实例内存泄露

- **场景举例**：线程tn调用funcA()方法新建了一个ThreadLocal实例，使用local局部变量指向这个实例，接着set方法设置100后，调用get方法获取一次。

  ```java
  public void funcA() {
      ThreadLocal<Integer> local = new ThreadLocal<>();
      local.set(100);
      local.get();
  }
  
  ```

- **弱键的好处**：

  1. local是强引用，在set方法设置后，线程tn的ThreadLocalMap成员内部会新建一个Entry实例，其Key以**弱引用包装**的方式指向ThreadLocal实例。
  2. 当线程tn执行完funcA()方法后，funcA()的方法栈帧将被销毁，栈帧中的强引用local会被回收，而由于线程tn仍在继续，导致Thread#ThreadLocalMap中对应的Entry.Key引用还指向ThreadLocal实例。
  3. **如果Entry的Key引用是强引用**，则会导致Key引用指向的ThreadLocal实例及其Value值，都不能被GC回收，这将造成严重的**内存泄漏**问题。
  4. **如果Entry的Key引用是弱引用**，由于ThreadLocalMap中Entry的Key使用了弱引用，在下次GC发生时，就可以使那些没有被其他强引用指向、仅被Entry的Key所指向的**ThreadLocal实例能被顺利回收**，在Entry的Key引用被回收之后，其Entry的Key值变为null，后续当ThreadLocal的get()、set()或remove()被调用时，ThreadLocalMap的内部代码会**清除这些Key为null的Entry**，从而完成相应的内存释放，**避免ThreadLocal内存泄露**。

  ![1630466341260](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630466341260.png)

##### Entry.value内存泄露

ThreadLocal虽然使用了弱键，但仍导致内存泄漏，发生条件如下（同时满足）：

1. **线程长时间运行而没有被销毁**。

   - 在线程池中的Thread实例很容易满足此条件。

2. ThreadLocal引用被设置为null，且后续在同一Thread实例执行期间，没有发生对其他ThreadLocal实例的**get()、set()或remove()**操作。

   - 如果后续没有调用过任何get()、set()或remove()操作，弱键的ThreadLocal实例被回收后，key为null，但Entry没有被回收，出现了Entry.value的内存泄露。
   - 只要存在一个针对任何ThreadLocal实例的get()、set()或remove()操作，就会触发Thread实例拥有的ThreadLocalMap的Key为null的**Entry清理工作**，释放掉ThreadLocal弱引用为null的Entry，避免**Entry.value的内存泄露**。

   ![1630483124536](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630483124536.png)

##### static & final内存泄露

- **使用static、final的好处**：
  - ThreadLocal实例作为ThreadLocalMap的Key，针对一个线程内的所有操作是共享的，所以建议设置static修饰符，以便被所有的对象共享。由于静态变量会在类第一次被使用时装载，只会分配一次存储空间，此类的所有实例都会共享这个存储空间，所以**使用static修饰ThreadLocal就会节约内存空间**。
  - 为了**确保ThreadLocal实例的唯一性**，除了使用static修饰之外，还会使用final进行加强修饰，以防止其在使用过程中发生动态变更。
  - 此外，ThreadLocal实例常常添加private修饰呢，主要目的是**缩小使用的范围**，尽可能不让他人引用。
- **static、final导致内存泄露的原因**：
  - 使用static、final修饰ThreadLoacl实例，ThreadLoacl实例会以单例形式存在，导致指向该ThreadLoacl实例的ThreadLocalMap#Entry.Key在Thread实例的生命期内始终保持为非null，从而导致Key所在的Entry不会被自动清空，这就会让Entry中的Value指向的对象一直被Entry强引用，于是Value指向的对象在线程生命期内不会被释放，导致发生内存泄漏。
  - 因此，在使用完static、final修饰的ThreadLocal实例之后，必须**调用remove()**来进行显式的释放操作。

##### 避免内存泄露总结

可见，使用ThreadLocal容易发生内存泄漏，如果能保证使用完ThreadLocal**及时调用remove方法**，则可以简单、有效地避免内存泄漏的发生。

# 四、MySQL篇

### 1.1. 为什么使用数据库？

使用数据库保存数据，**既能保证数据永久保存，又能兼顾查询效率**。

| 数据保存位置 | 内存中           | 文件中                                                      | 数据库中                                                     |
| ------------ | ---------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| 优点         | 存取速度快       | 数据永久保存                                                | 1）数据永久保存；2）使用SQL语句，查询方便效率高；3）管理数据方便 |
| 缺点         | 数据不能永久保存 | 1）速度比内存操作慢；2）需要频繁的IO操作；3）查询数据不方便 | -                                                            |

### 1.2. 数据库OLTP与OLAP的区别？

数据处理大致可以分成两大类：OLTP和OLAP。

- **OLTP**：
  - Online Transaction Processing，**联机事务处理系统**，表示事务性非常高的系统，一般都是高可用的在线系统，以小的事务以及小的查询为主，评估其系统的时候，一般看其每秒执行的Transaction以及Execute SQL的数量。
  - 在OLTP系统中，单个数据库每秒处理的Transaction往往超过几百个，或者是几千个，Select 语句的执行量每秒几千甚至几万个，典型系统有电子商务系统、银行、证券等。
  - OLTP 系统，是一个数据块变化非常频繁、SQL 语句提交非常频繁的系统，因此出现瓶颈的地方就是CPU与磁盘子系统。
    - 对于数据块来说，应尽可能让数据块保存在内存当中；对于SQL来说，尽可能使用变量绑定技术来达到SQL 重用，减少物理I/O 和重复的SQL 解析，从而极大的改善数据库的性能。 
- **OLAP**：
  - Online Analytical Processing，**联机分析处理系统**，也叫DSS决策支持系统，就是大家所说的数据仓库。
  - 在OLAP系统中，语句的执行量不是考核标准，因为一条语句的执行时间可能会非常长，读取的数据也非常多，所以，考核的标准往往是磁盘子系统的吞吐量（带宽），如能达到多少MB/s的流量。
    - 磁盘子系统的吞吐量往往取决于磁盘的个数，应尽量采用个数比较多的磁盘以及比较大的带宽，如4Gb的光纤接口。

|          | OLTP                                 | OLAP                             |
| -------- | ------------------------------------ | -------------------------------- |
| 定位     | 基本日常的事务处理                   | 复杂分析、决策支持               |
| 强调指标 | 内存命中率、SQL变量绑定、SQL并发执行 | SQL执行时长、磁盘I/O、带宽吞吐量 |
| 数据     | 当前的、最新的、细节的               | 历史的、聚集的、统一的           |
| 读写方式 | 每次读写数十条记录                   | 每次读上百万条记录               |
| 工作单位 | 简单的事务                           | 复杂的查询                       |
| DB大小   | 100MB-GB                             | 100GB-TB                         |

### 1.3. 数据库产品对比？

| 产品           | 优点                                                        | 缺点                                             | 备份                                      | 高可用                                         | 适用场景                                   |
| -------------- | ----------------------------------------------------------- | ------------------------------------------------ | ----------------------------------------- | ---------------------------------------------- | ------------------------------------------ |
| 关系型数据库   |                                                             |                                                  |                                           |                                                |                                            |
| MySQL          | 支持事务、开源免费                                          | 数据量大时，需要进行水平拆分                     | mysqldump逻辑备份，xtrabackup工具物理备份 | 主从（读写分离）、分片集群                     | 中小型LAMP                                 |
| Oracle         | 支持事务、支持大字段、性能最高                              | 管理维护麻烦、价格昂贵                           | exp逻辑备份，RMAN工具物理备份             | 双机热备、Oracle Dataguard主从、Oracle RAC集群 | 大部分事业单位                             |
| SQL Server     | 方便易用                                                    | 只能运行在windows平台、性能不够稳定              | -                                         | -                                              | windows平台OLTP                            |
| PostgreSQL     | 支持事务、稳定性强、性能高                                  | 扩容麻烦、MVCC并发版本需定期清理                 | COPY命令逻辑备份，pgdump物理备份          | 主从、Slony-I第三方组件做数据同步、集群有bug   | 地理位置信息处理                           |
| SQLite         | 自给自足、无需服务器、开源免费                              | 只能本地嵌入，无法远程访问                       | -                                         | -                                              | 嵌入式设备、本地应用程序                   |
| DB2            | 并行性高、适合海量数据                                      | -                                                | -                                         | -                                              | 数据仓库、数据挖掘                         |
| 非关系型数据库 |                                                             |                                                  |                                           |                                                |                                            |
| Redis          | 单线程、支持K-V以及多种数据结构存储、支持持久化，适合热数据 | 容量受内存限制，不便于海量数据读写，不适合冷数据 | RDB、AOF                                  | 主从、哨兵、集群                               | 缓存、最新回复、点赞数、共同好友、排行榜   |
| MemCache       | 多线程、性能高、速度快，用于减轻数据库负载                  | 不支持持久化、只能存储K-V数据                    | 不支持                                    | 集群没有同步复制机制                           | 前端缓存、用户信息、好友信息、文章信息     |
| MongoDB        | 文档结存存储、海量数据性能优越                              | 不支持事务、占用空间大、无法关联查询             | mongoexport逻辑备份、mongodump物理备份    | 主从、1.6 ReplicaSets复制集故障时自动切换      | Json文件、日志分析、敏捷开发、地理位置信息 |

### 1.4. MySQL与Oracle的使用区别？

#### MySQL

- MySQL是一个**关系型数据库管理系统**，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品，是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的关系数据库管理系统之一。
  - **关系数据库**：指将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。
- MySQL所使用的SQL语言，是用于访问数据库的最常用标准化语言，采用了双授权政策，分为社区版和商业版，由于其**体积小、速度快、总体拥有成本低**，尤其是**开放源码**这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。
  - **SQL**：Structured Query Language，结构化查询语言，是一种数据库查询语言，用于**存取数据、查询、更新和管理**关系数据库系统。

#### Oracle

Oracle Database，又名Oracle RDBMS，简称Oracle，是甲骨文公司的一款关系数据库管理系统，系统可移植性好、使用方便、功能强，适用于各类大、中、小微机环境，是一种**高效率的、可靠性好的、适应高吞吐量**的数据库方案。

| 区别         | Oracle                                                       | MySQL                                                        |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 开源免费与否 | 收费                                                         | **开源免费**                                                 |
| 超长文本处理 | 使用CLOB类型                                                 | 使用text和longtext类型                                       |
| 日期字段查询 | select * from tb1 where dt>to_date('2020-09-13 12:15:01', 'yyyy-MM-dd hi24:mi:ss'); | select * from tb1 where dt>'2020-09-13 12:15:01';            |
| 分页实现     | select * from (select t.*,rownum num from tb1 t where rownum<=100 ) where num>50; | select username from tb1 limit 50, 100;                      |
| group by     | 不允许返回group by外的其他字段                               | 可以任意返回一个字段值                                       |
| 修改字段类型 | 空字段直接改，不允许更改字段名称，改类型必须保证正确         | alter table tb1 change column f1_old f1_new int(11) comment 'xxx'; |
| 表字段注释   | 只能在创建字段之后指定                                       | 可以在建表时指定，也可以在建表完成后修改                     |
| 字段移位     | 建表后不能移位                                               | 建表之后可以修改字段顺序                                     |
| 创建索引     | 只能在建表完成后添加                                         | 可以在建表时添加，也可以在建表完成后添加                     |
| 查询建表语句 | select  dbms_metadata.get_ddl(table, 'tb1') from dual;       | show create table tb1;                                       |
| 查询执行计划 | explain plan for select + select * from table(dbms_xplan.display()); | explain select                                               |

### 1.5. MySQL数据类型？

- **整数类型**：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。
  - 任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。
  - 整数类型可以被指定长度，但在大多数场景是没有意义的，不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。
    - 比如，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。
- **实数类型**：FLOAT、DOUBLE、DECIMAL。
  - **DECIMAL**：可以用于存储比BIGINT还大的整型，能存储精确的小数。
  - **FLOAT和DOUBLE**：有取值范围，并支持使用标准的浮点进行近似计算。
    - 计算时，FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL可以理解成是用字符串进行处理。
- **字符串类型**：VARCHAR、CHAR、TEXT、BLOB。
  - **尽量避免使用TEXT/BLOB类型**，查询时会使用临时表，导致严重的性能开销。
  - 使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。
  - **varchar与char**：对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR**不容易产生碎片**；对于非常短的列，CHAR比VARCHAR在**存储空间上更有效率**。
    - **varchar**：使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示，当存储的内容超出设置的长度时，内容会被截断。
      - 用于存储可变长字符串，它比定长类型更节省空间。
    - **char**：字段定长，根据定义的字符串长度分配足够的空间，会根据需要使用空格进行填充，当存储的内容超出设置的长度时，内容会被截断。
      - 适合存储很短的字符串，或者所有值都接近同一个长度。
- **日期类型**：timestamp、datetime。
  - **尽量使用timestamp**，空间效率高于datetime。
  - 如果需要存储微妙，可以使用bigint存储。

### 1.6. MySQL存储引擎？

存储引擎，Storage engine，是**MySQL的一套文件系统实现**，使用各种不同的技术将数据存储在文件或内存中，通过使用不同的存储机制、索引技巧、锁定水平，来提供不同的能力，以使得能够获得额外的速度或者功能，从而改善应用的整体功能。

- **Innodb**：提供对事务的支持，还提供了行、表锁以及外键的约束，索引与数据同一文件。
  - 适合更新和删除操作频率高，要保证数据的完整性的、并发量高的场景，比如OA自动化办公系统。如果没有特别的需求，使用默认的InnoDB即可。
- **MyIASM**：不提供事务的支持，不支持行锁和外键，索引与数据在不同的文件。
  - 适合以读写插入为主的应用程序，比如博客系统、新闻门户网站。
- **MEMORY**：所有的数据都在内存中，数据的处理速度快，但是安全性不高。

### 1.7. MySQL锁分类？

当数据库发生**并发事务**时，需要**锁机制**来保证访问的次序，以满足事务的**隔离性**，最终保证**数据的一致性**。

#### 悲观锁和乐观锁

从**事务进入临界区前是否锁住同步资源的角度**来分：

- **悲观锁**：先锁再用。
  - 就是悲观思想，事务每次进入临界区操作数据的时候都认为别的事务会修改，所以事务每次在读写数据时都会**上锁**，锁住同步资源，这样其他事务需要读写这个数据时就会**阻塞**，一直等到拿到锁。
  - 适用于**写多读少**的场景，遇到**高并发写时性能高**，比如MySQL的**排他锁**。
- **乐观锁**：用时检查。
  - 是一种乐观思想，事务每次去拿数据的时候都认为别的事务不会修改，所以**不会上锁**，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复**读-比较-写**的操作。
  - 适用于**读多写少**的场景，遇到**高并发写时性能低**，MySQL的乐观锁可以通过**Version+SQL判断**实现。

#### 排他锁和共享锁

按照**锁定资源的方式**来分：

- **共享锁**：Shared lock，简称S锁，允许持有锁读取行的事务，即读锁，加锁时将自己和子节点全加S锁，父节点直到表头全加IS锁。
  - **兼容性**：读写互斥，加了S锁的记录，允许其他事务再加S锁，不允许其他事务再加X锁。
  - **加锁方式**：select … lock in share mode。
- **排他锁**：Exclusive lock，简称X锁，允许持有锁修改行的事务，即写锁， 加锁时将自己和子节点全加X锁，父节点直到表头全加IX锁 。
  - **兼容性**：写读互斥，写写互斥，加了X锁的记录，不允许其他事务再加S锁或者X锁。
  - **加锁方式**：select … for update。

#### 表锁和行锁

按照**锁定资源的粒度**来分：

##### 表锁

Mysql中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，**MyISAM和 InnoDB引擎都支持表级锁**。

###### 意向锁

Intention Locks，表明某个事务正在某些行持有了锁，或该事务准备去持有锁，其存在是为了**协调行锁和表锁**的关系，支持多粒度的锁（表锁与行锁）并存。

- **意向共享锁**：Intention shared lock，IS，事务有意向对表中的某些行加S锁，在请求S锁前，要先获得IS锁。
- **意向排他锁**：Intention exclusive lock，IX，事务有意向对表中的某些行加X锁，在请求X锁前，要先获得IX锁。
- **意向锁举例**：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞，因此意向锁通过这种**锁叠加的方式**实现了行锁和表锁共存，并且满足了事务隔离性的要求。
- **为什么意向锁是表级锁**：当需要加一个排他锁时，需要根据意向锁去判断表中**有没有数据行被锁定**，此时如果意向锁是行锁，则需要遍历每一行数据去确认，性能低下；而如果意向锁是表锁，则只需要**判断一次**即可知道有没数据行被锁定，**性能较高**。
- **意向锁兼容性**：指当事务A对某个数据范围（行或表）上了“某锁”后，另一个事务B是否能在这个数据范围上“某锁”，可见，意向锁之间、读锁与意向锁之间互相兼容，写锁与其他锁之间都不兼容。

| 互斥性       | 共享锁（S） | 排它锁（X） | 意向共享锁IS | 意向排他锁IX |
| ------------ | ----------- | ----------- | ------------ | ------------ |
| 共享锁（S）  | ✅           | ❌           | ✅            | ❌            |
| 排它锁（X）  | ❌           | ❌           | ❌            | ❌            |
| 意向共享锁IS | ✅           | ❌           | ✅            | ✅            |
| 意向排他锁IX | ❌           | ❌           | ✅            | ✅            |

###### 自增锁

AUTO-INC Locks，是一种特殊的表级锁，发生涉及**AUTO_INCREMENT**列的事务性插入操作时产生。

##### 行锁

Mysql中锁定粒度最小的一种锁，只针对当前操作的行进行加锁，能大大减少数据库操作的冲突，其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。**InnoDB默认使用行锁**，按**锁算法**的角度来分，InnoDB支持的行锁包括如下几种：

###### 记录锁

Record Lock，对**索引项**加锁，锁定**符合条件的行**，其他事务不能修改和删除加锁项。

- 如果该表上没有任何索引，那么InnoDB会在后台创建一个隐藏的聚蔟主键索引，那么锁住的就是这个隐藏的**聚蔟主键索引**。

###### 间隙锁

Gap Lock，对索引项之间的间隙加锁，锁定**记录的范围，不包含索引项本身**，其他事务不能在锁范围内插入数据。

- 比如在 1、2、3中，间隙锁的可能值有 (∞, 1)，(1, 2)，(2, ∞)。
- 可用于**防止幻读**，保证索引间的不会被插入数据。

###### 临建锁

Next-key Lock，锁定索引项本身和索引范围，**左开右闭区间**，即Record Lock+Gap Lock的结合，可解决幻读问题。

- 默认情况下，InnoDB select … for update使用Next-Key Lock来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock会进行优化，**降级为Record Lock**，即仅锁住索引本身，不是范围。
- 另外，Next-Key Lock在不同的场景中会退化：

| 场景                                        | 退化后的锁类型                   |
| ------------------------------------------- | -------------------------------- |
| 使用unique index精确匹配（=），且记录存在   | Record Lock                      |
| 使用unique index精确匹配（=），但记录不存在 | Gap Lock                         |
| 使用unique index范围匹配（< 或 >）          | Record Lock + Gap Lock，左开右闭 |

##### 页锁

MySQL中锁定粒度介于行级锁和表级锁中间的一种锁，表级锁速度快，但冲突多；行级冲突少，但速度慢，因此取了折衷的页级，**一次锁定相邻的一组记录**，其开销和加锁时间界于表锁和行锁之间、会出现死锁、锁定粒度界于表锁和行锁之间、并发度一般。

##### 锁的选择

比如执行，update test set name=“hello” where name=“world”，精确匹配时：

1. 如果更新条件没有走索引，则会进行全表扫描，扫表时会阻止其他任何的更新操作，**上升为表锁**。
2. 如果更新条件为索引字段，但是为非唯一索引，则会**使用Next-Key Lock**，保证在符合条件的记录上加上排他锁，锁定当前非唯一索引以及其对应的主键索引的值，同时，还要保证锁定的区间不能插入新的数据。
3. 如果更新条件为唯一索引，则会使用**Record Lock**。

#### MySQL死锁排查

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

常见的解决死锁的方法

1. InnoDB目前处理死锁的方法是，将持有最少行级排他锁事务进行**回滚**，这是相对比较简单的死锁回滚算法。
2. **相同的访问顺序**，如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。
3. 在同一个事务中，尽可能做到**一次锁定所需要的所有资源**，减少死锁产生概率；
4. 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过**表级锁**定来减少死锁产生的概率；

```mysql
show engine innodb status\G
-- TABLE LOCK：表锁
-- lock mode IX：意向锁
-- RECORD LOCK：行锁
-- index GEN_CLUST_INDEX：聚蔟索引，InnoDB加锁是给索引加的锁
-- lock_mode X：写锁，间隙锁
-- lock_mode X locks rec but not gap：行锁，非间隙锁
-- lock_mode X locks rec but not gap waiting：行锁等待
-- LATEST DETECTED DEADLOCK：最近探测到的死锁，排查到发生死锁
```

### 1.8. MVCC多版本并发控制？

#### 概念

MVCC，Multi-Version Concurrency Control，即**多版本并发控制**，实现对数据库的并发访问，实现读写冲突时的无锁并发控制。

- 可以在并发读写数据库时，做到在**读操作时不用阻塞写操作，写操作也不用阻塞读操作**，提高了数据库并发读写的性能。
- 同时还可以解决**脏读、不可重复读、幻读**等事务隔离问题，但不能解决更新丢失问题。
- MVCC手段只适用于Msyql **RC读已提交和 RR可重复读** 的事务隔离级别，RU读未提交由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC。

#### 当前读和快照读

- **当前读**：非MVCC实现，读取的是记录的最新版本，读取时要保证其他并发事务不能修改当前记录，会对读取的记录进行**加锁**。当前读就是悲观锁的具体功能实现
  - **举例**：select lock in share mode（共享锁）, select for update（拍他锁），update、insert、delete（排他锁）、串行化事务隔离级别。
- **快照读**：MySQL实现MVCC理想模型的中一个具体的**非阻塞读功能**，避免了加锁的操作，可以降低开销、提高并发性能，但快照读可能读到的不一定是数据的最新版本，而可能是之前的**历史版本**。
  - **前提**：快照读的前提是，事务使用**非串行化**的隔离级别，因为串行化级别下的快照读会**退化成当前读**。
  - **举例**：不加锁的select。

#### MySQL实现MVCC

![1630673126935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630673126935.png)

##### 版本链

InnoDB中，每次修改版本都会在版本链中记录，通过**undo log + roll_pointer**实现：

- **trx_id**：当前版本的事务ID，用来存储的每次对某条记录进行修改的时候的**事务ID**。当每个事务开启时，都会被分配一个ID，而这个ID是递增的，因此越新的事务其ID值越大。
- **roll_pointer**：回滚指针，由于每次对记录修改时，都会把老版本写入到undo日志中，使用回滚指针来指向这条记录**上一个版本**的位置，通过它来获得上一个版本的记录信息。
  - 注意，插入操作的undo日志没有roll_pointer，因为它没有老版本。

##### undo log

undo log是用于记录旧版本的链表，链首为最新的旧记录，链尾为最早的旧记录，主要分为两种：

- **insert undo log**：
  - 代表事务在insert新记录时产生的undo log，只在事务回滚时需要，并且在**事务提交后可以被立即丢弃**。
- **update undo log**：
  - 对MVCC其实质性的帮助，事务在进行update或delete时产生的undo log，不仅在事务回滚时需要，**在快照读时也需要**，所以不能随便删除。
  - 只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程（InnoDB专门的记录清理线程）统一清除。

##### Read View

![1630674963257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630674963257.png)

Read View，是事务进行快照读操作时产生的**读视图**，是数据库当前的一个快照，记录了系统当前**活跃事务ID**，用于做**可见性判断**。

- **活跃事务ID**：即还没有commit的事务ID。

- **可见性判断**：当某个事务执行快照读时，会对该记录创建一个Read View读视图， 并把它作为条件，来**判断当前事务能够看到哪个版本的数据**，其中可能是当前版本的数据，也有可能是该行记录的undo log里面的某个版本的老数据。

  1. **trx_id == creator_trx_id**：可以访问这个版本，这个版本的事务ID等于当前事务ID（创建Read View的事务ID），即**自己能够读到自己的版本**。
     - creator_trx_id用来标记当前生成Read View的事务，使得能够让该事务读取到自己未提交的版本。
  2. **trx_id < min_trx_id**：可以访问这个版本，这个版本的事务ID小于最小活跃事务ID，说明这个版本**已经提交过了**，对于当前做可见性判断的事务来说，**是可以看见的**。
     - min_trx_id用来标记最早未提交的事务A，对比版本记录中的事务B，从而判断出B是否已经提交。
  3. **trx_id > max_trx_id**：不可以访问这个版本，这个版本的事务ID大于下一个事务ID，说明这个版本记录是在该Read View生成之后产生的，已经超出了版本链范围，而快照读只能读取版本链中的版本，因此该版本对于当前做可见性判断的事务来说，**是不应该看见的**。
     - max_trx_id用来标记下一个将要生成的事务A，对比版本记录中的事务B，从而判断出B是否超出版本链范围。
  4. **min_trx_id <= trx_id <= max_trx_id**：
     - 如果这个版本的事务ID为m_ids中的某个值，则不可以访问这个版本的，因为m_ids都是活跃的、还没提交的事务，说明该版本记录还没有提交，对于当前做可见性判断的事务来说，**是不应该看见的**。
     - 如果这个版本的事务ID不为m_ids中的某个值，则可以访问这个版本，因为没在m_ids里，又小于等于max_trx_id，说明该版本记录已提交了，对于当前做可见性判断的事务来说，**是可以看见的**。

  => 因此，如果可见性判断到要读取的版本记录为**自己创建的或者已经提交的**，则说明对于当前做可见性判断的事务来说，**该版本记录是可以看见的**。

### 1.9. 事务四大特性ACID？

事务，Transaction，是指**访问、更新数据库数据一个程序执行单元**，是逻辑上的一组操作，要么都执行，要么都不执行，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。

> ACID 则是衡量事务的四个特性，按照严格的 SQL 标准，只有同时满足 ACID 特性的才算是事务，但在各大数据库厂商的实现中，真正能严格满足 ACID 事务的少之又少。
>
> 比如 MySQL NDB Cluster 事务不满足持久性和隔离性，InnoDB RR 不满足严格的隔离性，Oracle RC 也不满足严格的隔离性等等。
>
> 所以，与其说 ACID 是事务必须满足的条件，不如说它们是衡量事务的四个维度而已。

- **原⼦性**： Atomicity， 事务是最小的执行单位，不允许分割，整个事务中所有的操作，要么全部提交成功，要么全部失败回滚，强调的是**事务操作原子不可分割**。

  - **undo log**：回滚日志，属于逻辑日志，记录的是 sql 执行相关的信息，是 MySQL 中事务**原子性**和**隔离性**实现的基础。
  - **实现原理**：在 MySQL InnoDB 中，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log。如果事务执行失败或调用了 rollback，导致事务需要回滚时，就可以根据 undo log 的内容做与之前**相反**的工作，把数据回滚到修改之前的样子，以实现事务原子性操作。
    1. 对于每个 insert，回滚时会执行 delete。
    2. 对于每个 delete，回滚时会执行 insert。
    3. 对于每个 update，回滚时会执行一个相反的 update，把数据改回去。

- **一致性**：Consistency， 指事务执行结束后，数据库的完整性约束没有被破坏，都是合法的数据状态，强调的是**数据状态事务前后的一致**。

  - **数据库的完整性约束包括但不限于**：
    - **实体完整性**：比如，行的主键存在且唯一。
    - **列完整性**：比如，字段的类型、大小、长度都要符合要求。
    - **外键约束**：比如，主键所在的表是主表，外键所在的表是从表。
    - **用户自定义完整性**：比如，转账前后，两个账户余额的和应该保持不变。
  - **实现原理**：可以说，**一致性是事务追求的最终目标**，原子性、持久性和隔离性都是为了保证数据库状态的一致性。其中，实现一致性的措施包括：
    - **数据库层面的保障**：原子性、持久性和隔离性的保证，以及一些其他约束，比如不允许向整型列插入字符串值，或者字符串长度不能超过列的限制等等。
    - **应用层面的保障**：比如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。

- **隔离性**： Isolation，并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的，一个事务所做的修改在最终提交之前，对其他事务是不可见的，强调的是**事务间的数据操作互不影响**。

  - **实现原理**：
    - **写写操作**：使用**锁机制**来保证隔离性。
    - **写读操作**：
      - **快照读**：使用**MVCC**来保证隔离性。
      - **当前读**：使用**锁机制**保证隔离性。

- **持久性**：Durability， ⼀个事务被提交之后，它对数据库中数据的改变是持久的，即使数据库发⽣故障，也不应该对其有任何影响，强调的是**事务后的数据会永久保存**。

  - **Buffer Pool**：为减少每次读写数据的磁盘I/O，InnoDB 提供了 Buffer Pool 缓存，其中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲。当从数据库读取数据时，InnoDB 会先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool；当向数据库写入数据时，同样 InnoDB 也会先写入 Buffer Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中，这一过程称为**刷脏**。

    - **优点**：大大提高了读写数据的效率。
    - **缺点**：如果 MySQL 宕机，而此时 Buffer Pool 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，**无法保证事务的持久性**。

  - **实现原理**：InnoDB 引入 redo log 来解决 Buffer Pool 的问题， 以保证事务的持久性。

    1. 当数据修改时，修改 Buffer Pool 中的数据前，会先在把这次操作**写入** redo log 缓冲区。
    2. 写入 redo log缓冲区后，根据innodb_flush_log_at_trx_commit属性来决定**刷盘机制**：
       - **0**：表示当事务提交时，不会把 redo log 缓冲区的日志**同步**到磁盘 redo log 文件中，而是等待线程每秒的刷新，不能完全保证全部写入成功。
       - **1**：表示当事务提交时，把 redo log 缓存区的日志**同步**到磁盘 redo log 文件中，且会保证全部写入成功。
       - **2**：表示当事务提交时，异步把 redo log 缓存区的日志**同步**到磁盘 redo log 文件中，不能完全保证全部写入成功。
    3. 如果 MySQL 宕机，重启时可以**读取** redo log 中的数据，对数据库进行**恢复**。

    ![1632132586785](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632132586785.png)

  - **redo log**：重做日志，属于物理日志，用于保证事务的持久性。

    - **WAL**：Write-ahead logging，预写式日志，redo log 采用 WAL ，所有修改先**写入**日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。

    - **写入 redo log 性能高于 Buffer Pool 刷脏**：因此，写入 redo log 是可以用在 Buffer Pool 刷脏之前来保证事务持久性的。

      | 写入 redo log 缓冲区                 | Buffer Pool刷脏                                              |
      | ------------------------------------ | ------------------------------------------------------------ |
      | 是追加操作，属于顺序 I/O             | 每次修改的数据位置都是随机的，属于随机 I/O                   |
      | 只需要修改的部分，大大减少了无效 I/O | 以数据页 Page 为单位（MySQL默认为16 KB），一个 Page上只出现一个小修改，需要将整页写入磁盘，存在大量的无效 I/O |

    - **redo log vs binlog**：

      | 不同点   | redo log                         | bin log                      |
      | -------- | -------------------------------- | ---------------------------- |
      | 日志名称 | 重做日志                         | 二进制日志                   |
      | 日志作用 | 用于崩溃恢复，保证事务的持久性   | 用于时间点恢复，保证主从复制 |
      | 存储内容 | 属于物理日志，内容基于磁盘数据页 | 逻辑日志，内容为一条条SQL    |
      | 实现层面 | InnoDB存储引擎实现               | MySQL服务器层实现            |
      | 写入时机 | 事务提交时、每秒一次             | 事务提交时写入               |

### 2.0. 事务并发问题？

- **脏读**：Drity Read，指两个事务并发执行，事务A已更新某一份数据，事务B读取同一份数据，出于某种原因，事务A回滚了更新的操作，导致事务B读取的数据不正确。
  - **产生原因**：事务A读取了事务B中**未提交的数据**。
  - **特点**：违背了隔离性。
- **不可重复读**：Non-repeatable read，指两个事务并发执行，事务A前后两次查询的结果不一样（**行内容发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**修改并提交了事务**。
  - **特点**：相比脏读的区别是，不可重复读是读取另一事务提交的数据。这种现象是正常的，是由于事务的隔离级造成的，但是在在某些特别的情况下也是不允许的。 
- **幻读**：Phantom Read，指两个事务并发执行，事务A前后两次查询的结果不一样（**出现了幻行，导致行数量发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**新增数据并提交了事务**，比如事务A查询了几行数据，而事务B并发插入了新的几行数据，事务A在接下来的查询中，会发现有几行数据是它先前所没有的。
  - **特点**：和不可重复读一样，都是读取了另外一个事务的数据，不同的是不可重复读查询的是同一条数据，而幻读则是针对批量的数据，或者说**不可重复读是A读取了B的更新数据，幻读是A读取了B的新增数据**。

### 2.1. 事务隔离级别？

| 事务隔离级别 | 存在的事务并发问题     |
| ------------ | ---------------------- |
| 读未提交     | 脏读、幻读、不可重复读 |
| 读已提交     | 幻读、不可重复读       |
| 可重复读     | 幻读                   |
| 串行化       | 没有事务并发问题       |

- **读未提交**：READ UNCOMMITTED，是最低的事务隔离级别，事务可以读取到其他事务未提交的数据，可能会导致脏读、不可重复读和幻读。

  - **当前读**：读取数据**不需要加共享锁**，这样就不会与修改的数据上的排他锁冲突了。

- **读已提交**：RC，READ COMMITTED，也叫不可重复读，事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的，是大多数据库的默认事务隔离级别（**比如Oracle**），可以阻⽌脏读，但还是可能会导致不可重复读和幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在语句执行完以后释放共享锁**。
  - **快照读**：MVCC
    - **Read View以select为单位**，每次select都会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **不可重复读的原因**：由于Read View以select为单位，每次select都会生成一个Read View，两者的可见性判断的结果可能不一样，能看到的版本也就不一样，从而可能导致事务前后两次的**查询别人版本的结果**不一致，产生不可重复读。

- **可重复读**：RR，REPEATABLE READ，事务对同⼀字段的**多次读取的结果都是⼀致的**，除⾮数据是被事务本身所修改，是**MySQL的默认事务隔离级别**，可以阻⽌脏读和不可重复读，但还是可能会导致幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在事务提交之前并不释放共享锁**，也就是必须等待事务执行完毕以后，才释放共享锁。
    - **解决幻读的方式**：
      - **使用间隙锁**：MySQL默认开启间隙锁，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。
      - **使用MVCC快照读**：快照读基于Read View来实现，每个事务对应一个Read View，解决了幻读的问题。
      - **升级到串行化隔离级别**：把隔离级别设置成SERIALIZABLE，但这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多，实际中很少用到。
  - **快照读**：MVCC
    - **Read View以事务为单位**，每个事务只会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **解决不可重复读、幻读的问题**：由于Read View以事务为单位，每个事务只会生成一个Read View，事务前后的快照读只对应同一份Read View，可见性判断一致，能看到的版本一致，因此整个事务过程中**查询别人版本的结果**一致，避免了不可重复读、幻读的发生，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。

  |        | RC                                   | RR                         |
  | ------ | ------------------------------------ | -------------------------- |
  | 实现   | 多条查询语句会创建多个不同的ReadView | 仅需要一个版本的ReadView   |
  | 粒度   | 语句级读一致性                       | 事务级读一致性             |
  | 准确性 | 每次语句执行时间点的数据             | 第一条语句执行时间点的数据 |

- **串行化**：SERIALIZABLE，是最高的隔离级别，通过强制事务串行执行，所有的事务依次逐个执⾏，事务之间完全不存在互相⼲扰，解决了幻读的问题，即阻止了所有的事务并发问题，包括脏读、不可重复读和幻读。

  - **当前读**：**锁定整个范围的键**，并一直持有锁，直到事务完成，可能导致大量的超时和锁争用的问题，实际中很少使用。

### 2.2. MySQL慢SQL与慢查询日志？

#### 慢SQL

- **危害**：
  - **从数据库角度看**：
    - 每个SQL执行都需要消耗一定I/O资源，SQL执行的快慢，决定资源被占用时间的长短。
    - 假设总资源是100，如果有一条慢SQL占用了30的资源共计1分钟，那么在这1分钟时间内，其他SQL能够分配的资源总量就是70，如此循环，当资源分配完的时候，会**导致所有新的执行SQL进行排队等待**。
  - **从应用的角度看**：SQL执行时间长，意味着应用需要等待，导致用户的体验较差。
- **治理原则**：
  - **优先治理写库的慢SQL**：目前数据库基本上都是读写分离架构，读在从库上执行，写在主库上执行，而由于从库的数据都是从主库上复制过去的，如果主库等待较多，则会**加大与从库的复制时延**。
  - **执行次数多的慢SQL优先治理**：如果有一类SQL高并发集中访问某一张表，应当优先治理。

#### 慢查询日志

慢查询日志，是MySQL内置的一项功能，可以记录执行超过指定时间的SQL语句，即**记录慢SQL**。

- **参数设置方式**：

  - **修改my.cof配置文件**：

    ```sh
    [mysqld]
    # ...
    log_output = 'FILE,TABLE';
    show_query_log = ON
    
    # 表示0.001s，即默认值为1ms，表示任何SQL都会记录起来，对于实际业务没任何意义
    long_query_time = 0.001
    ```

  - **set global设置全局变量**：

    ```sql
    set global log_output = 'FILE,TABLE';
    set global slow_query_log = 'ON';
    
    -- 表示0.001s，即默认值为1ms，表示任何SQL都会记录起来，对于实际业务没任何意义
    set global long_query_time = 0.001;
    ```

- **慢查询日志分析**：

  - **log_output = TABLE**：select * from `mysql`.slow_log。
  - **log_output = FILE**：使用show variables like '%slow_query_log_file%'获取日志路径，使用mysqldumpslow分析日志。

  ![1630805035402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630805035402.png)

  ```mysql
  -- mysqldumpslow：
  -- -s：排序方式，默认为at
  --		1) al：平均时间
  --		2）ar：平均返回记录
  --		3）at：平均查询时间
  --		4） c：访问计数
  --		5） l：锁定时间
  --		6） r：返回记录
  --		7） t：查询时间
  -- -r：将-s的排序倒序
  -- -t：top n的意思，展示最前面的几条
  -- -g：正则匹配，只有符合正则的行才会展示
  -- -a：展示原始SQL
  
  -- eg: 得到返回记录集中最多的10条SQL
  mysqldumpslow -s -r -t 10 /var/lib/mysql/894503c23e0-slow.log
  
  -- eg: 得到按照查询时间排序，并且带有left join的10条SQL
  mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/894503c23e0-slow.log
  ```

| 慢查询日志参数                         | 作用                                                         | 默认值    |
| -------------------------------------- | ------------------------------------------------------------ | --------- |
| log_output                             | 日志输出的类型，可以设置多种格式，比如FILE，TABLE；默认为FILE，表示文件；设置成TABLE，则将日志记录到mysql.slow_log中； | FILE      |
| long_query_time                        | 执行时间超过指定阈值，才记录到慢查询日志，单位为秒，可使用小数表示小于秒的时间 | 10        |
| log_queries_not_using_indexs           | 是否要将未使用索引的SQL，都记录到慢查询日志中，此配置会无视long_query_time的配置，生产配置建议关闭，开发环境建议开启 | OFF       |
| log_throttle_queries_not_using_indexes | 和log_queries_not_using_indexs配置使用，如果log_queries_not_using_indexs打开，则该参数将限制每分钟写入的、未使用索引的SQL数量 | 0         |
| min_examined_row_limit                 | 扫描行数至少达到指定阈值，才记录到慢查询日志                 | 0         |
| log_show_admin_statements              | 是否要记录管理语句，默认关闭，管理语句包括ALTER、ANALYZE、CHECK、CREATE、DROP、OPTIMIZE、REPAIR | OFF       |
| slow_query_log_file                    | 指定慢查询日志的文件路径                                     | /var/路径 |
| log_slow_slave_statements              | 该参数在从库上设置，决定是否记录在复制过程中超过long_query_time的SQL，如果binlog格式是row，则该参数无效 | OFF       |
| log_show_extra                         | 当log_output=FILE时，是否要记录额外信息（>= MySQL 8.0.14开始提供），对log_output=TABLE的结果无影响 | OFF       |

### 2.3. 详细介绍MySQL EXPLAIN？

- 使用EXPLAIN关键字可以**模拟优化器执行SQL语句**，分析查询语句或是结构的性能瓶颈。
- 在select语句之前增加explain关键字，MySQL会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行SQL。

#### 总结

基于MySQL 8.0编写，理论上支持MySQL 5.0以及更高版本。

| Explain结果字段   | json名称      | 含义                         |
| ----------------- | ------------- | ---------------------------- |
| id                | select_id     | 该语句的唯一标识             |
| select_type       | 无            | 查询类型                     |
| table             | table_name    | 表名                         |
| partitions        | partitions    | 匹配的分区                   |
| **type**          | access_tpye   | 联接类型                     |
| **possible_keys** | possible_keys | 可能的索引选择               |
| **key**           | key           | 实际选择的索引               |
| **key_len**       | key_length    | 索引的长度                   |
| ref               | ref           | 索引的哪一列被引用了         |
| **rows**          | rows          | 估计要扫描的行               |
| **filtered**      | filtered      | 表示符合查询条件的数据百分比 |
| **Extra**         | 没有          | 附件信息                     |

#### id

该语句的唯一标识：

- 如果结果包含多个id值，则**数字越大，越先执行**。
- 而相同id的，则**从上往下依次执行**。

#### select type

查询类型，有以下几种取值：

| 查询类型             | 作用                                                         |
| -------------------- | ------------------------------------------------------------ |
| SIMPLE               | 简单查询（未使用UNION或者子查询）                            |
| PRIMARY              | 最外层的查询                                                 |
| UNION                | 在UNION中的第二个和随后的SELECT被标记为UNION，如果UNION被FROM子句中的子查询包含，则它的第一个SELECT会被标记为DERIVED（派生表）。 |
| DEPENDENT UNION      | UNION中的第二个或后面的查询，依赖了外面的查询                |
| UNION RESULT         | UNION的结果                                                  |
| SUBQUERY             | 子查询中的第一个SELECT                                       |
| DEPENDENT SUBQUERY   | 子查询中的第一个SELECT，依赖了外面的查询                     |
| DERIVED              | 用来表示包含在FROM子句的子查询中的SELECT，MySQL会递归执行并将结果放入到一个临时表中，内部称其为Derived table（派生表），因为该临时表是从子查询派生出来的 |
| DEPENDEDNT DERIVED   | 派生表，依赖了其他的表                                       |
| MATERIALIZED         | 物化子查询                                                   |
| UNCACHEABLE SUBQUERY | 子查询，结果无法缓存，必须针对外部查询的每一行重新评估       |
| UNCACHEABLE UNION    | UNION属于UNCACHEABLE SUBQUERY的第二个或后面的查询            |

#### table

表示当前这一行正在访问哪张表，如果SQL定义了表名，则展示表的别名。

#### partitions

当前查询匹配记录的分区，对于未分区的表，返回null。

#### type

**重点**，连接类型，有如下几种取值，性能从好到坏排序：

| 连接类型        | 含义                                                         | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| system          | 该表只有一行，相当于系统表                                   | system是const的特例                                          |
| const           | 针对主键或者唯一索引的等值查询，最多返回一行数据             | 查询速度非常快                                               |
| eq_ref          | 当使用了索引的全部组成部分，并且索引是**主键或者非空唯一索引**才会发生 | 性能仅次于system和const                                      |
| ref             | 当满足索引的最左前缀规则，或者索引**不是主键也不是唯一索引**时才会发生 | 如果索引只匹配到少量的行，则性能也是不错的                   |
| fulltext        | 全文索引                                                     | 使用MyISAM存储引擎才有                                       |
| ref_or_null     | 该类型类似于ref，但MySQL会额外搜索哪些行包含NULL，           | SELECT * FROM ref_table WHERE key_col = expr OR key_col IS NULL； |
| index_merge     | 该类型表示使用了索引合并优化，表示一个查询里面用到了多个索引 | -                                                            |
| unique_subquery | 该类型和eq_ref类型，但使用了**IN查询**，且**子查询是主键或者唯一索引** | value IN (SLECT id FROM single_talbe WHERE expr)             |
| index_subquery  | 和unique_subquery类型，只是**子查询使用的是非唯一索引**      | value IN (SELECT key_col FROM single_table WHERE other_expr) |
| range           | 范围扫描，表示检索了指定范围的行，主要用于有限制的索引扫描   | 常见的有，BETWEEN、>、>=、<、<=、IS NULL、<=>、LIKE、IN      |
| index           | 全索引扫描，和ALL类型，只不过index是全盘扫描了索引的数据     | 当查询仅使用索引中的一部分列时，会使用该类型，有两种触发场景：1）覆盖索引，比ALL快，此时只扫描索引数，Extra列为Using Index；2）全表扫描，同ALL，此时会回表查询数据，Extra列不会出现Using Index； |
| ALL             | 全表扫描                                                     | 性能最差                                                     |

#### possible_keys

展示当前查询可以使用哪些索引，由于这一列的数据是在SQL优化过程早期创建的，因此，有些索引可能对于SQL后续优化过程是没用到的。

#### key

表示MySQL实际选择的索引。

#### key_len

索引使用的字节数，由于存储格式，当字段允许为NULL时，key_len比不允许为NULL的大1个字节，计算公式为：

- **varchar（10）+ 允许为NULL**：2（varchar变长字段） + 10 \* ( Character Set）+ 1（允许为NULL）。
  - **varchar变长字段**：使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用**1字节**表示，否则使用**2字节**表示，当存储的内容超出设置的长度时，内容会被截断。
  - **Character Set**：UTF8 = 3字节, GBK = 2字节, LATIN = 1字节。
  - **允许为NULL** = 1字节。
- **varchar（10）+ 不允许为NULL**：2（varchar变长字段） + 10 \* ( Character Set）。
- **char（10）+ 允许为NULL**：10 \* ( Character Set） + 1（允许为NULL）。
- **char（10）+ 不允许为NULL**：10 \* ( Character Set） 。

#### ref

表示索引的哪一列被引用了，将哪个字段或者常量，和key列所使用的字段进行比较。

- 如果ref是一个函数，则使用的值是函数的结果。
  - 要想查看是哪个函数，可在Explain语句之后紧跟一个SHOW WARNING语句。

#### rows

MySQL估算会扫描的行数，数值越小，性能越高。

#### filtered

表示符合查询条件的数据百分比，最大100，用rows * filtered可获得和下一张表连接的行数。

#### Extra

展示有关本次查询的附件信息，取值如下：

| 附件信息                                                     | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Child of 'table' pushed join@1                               | 此值只会在NDB CLUSTER下出现                                  |
| const row not found                                          | 查询的表是空的                                               |
| Deleting all rows                                            | 对于DELETE语句，某些引擎（比如MyISAM）支持以一种简单而快速的方式删除所有数据，如果使用了这种优化，则会显示此值 |
| Distinct                                                     | 查找Distinct值，当找到第一个匹配的行后，将停止为当前行组合搜索更多的行 |
| FirstMatch(table_name)                                       | 当前使用了半连接FirstMatch策略                               |
| Full Scan on NULL key                                        | 子查询中的一种优化方式，在无法通过索引访问NULL值时会使用     |
| Impossible HAVING                                            | HAVING子句始终为false，不会命中任何行                        |
| Impossible WHERE                                             | WHERE子句始终为false，不会命中任何行                         |
| Impossible WHERE noticed after reading const tables          | MySQL已经读取了所有const（或者system）表，并发现WHERE子句始终为false |
| LooseScan（m...n）                                           | 当前使用了半连接LooseScan策略                                |
| No  matching min/max row                                     | MIN、MAX语句中，没有任何能满足WHERE条件的行                  |
| No matching row in const table                               | 对于关联查询，存在一个空表，或者没有行能够满足唯一索引条件   |
| No matching rows after partition pruning                     | 对于DELETE或者UPDATE语句，优化器在partition pruning（分区修剪）之后，找不到要DELETE或者UPDATE的内容 |
| No tables used                                               | 当此查询没有FROM子句或者拥有FROM DUAL子句时出现              |
| Not exists                                                   | MySQL能对LEFT JOIN优化，在找到符合LEFT JOIN的行后，不会为上一行组合中检查此表中的更多行，只查找一次 |
| Plan isn't ready yet                                         | 使用了EXPLAIN FOR CONNECTION，当优化器尚未完成为在指定连接中执行的语句创建执行计划时，就会出现此值 |
| Range checked  for each record（index map：N）               | MySQL没有找到合适的索引去使用，但是去检查是否可以使用range或者index_merge来检索行时，会出现此提示 |
| Recursive                                                    | 出现了递归查询                                               |
| Rematerialize                                                | 用得很少                                                     |
| Scanned N databases                                          | 表示在处理INFOMATION_SCHEMA表的查询时，扫描了几个目录，N的取值可以是0、1或者all |
| Select tables optimized away                                 | 优化器确定最多返回1行时会出现此提示，一般在用某些聚合函数访问存在索引的某个字段时，优化器会通过索引直接一次定位到所需要的数据行完成整个查询时，会展示该值 |
| Skip_open_table，Open_firm_only，Open_full_table             | 表示适用于INFORMATION_SCHEMA表查询的文件打开优化，Skip_open_table表示无需打开表文件，信息已经通过扫描数据字典获得；Open_firm_only表示仅需要读取数据字典以获取表信息；Open_full_table表示未优化的信息查找，表信息必须从数据字典以及表文件中获取 |
| Start temporary，End temporary                               | 表示临时表使用Duplicate Weedout策略                          |
| unique row not found                                         | 对于形如select ... from tab_name的查询，但没有行能够满足唯一索引或者主键查询的条件时出现 |
| **Using filesort**                                           | 当Query中包含ORDER BY操作，而且无法利用索引完成排序操作时，MySQL Query Optimizer不得不选择相应的排序算法来实现。在数据较少时，从内存排序，否则从磁盘排序。 其中，Explain不会显式地告诉客户端用哪种排序。 |
| **Using Index**                                              | 仅使用索引树中的检索列信息，不必进行其他查找以读取实际行，当查询仅使用属于单个索引的列时，会使用此策略 |
| **Using index condition**                                    | 使用索引下推时出现，表示先按条件过滤索引，过滤完索引后，找到符合索引条件的数据行，随后用WHERE子句中的其他非索引条件，去过滤这些数据行。 |
| **Using index for group-by**                                 | 数据访问和Using Index一样，所需数据只需要读取索引，当Query中使用GROUP BY或者DISTINCT子句时，如果所有分组字段也在索引中，该信息就会出现 |
| Using index for skip scan                                    | 表示使用了Skip Scan                                          |
| Using join buffer（Block Nested Loop），Using join Buffer（Batched Key  Access） | 使用Block Nested Loop或者Batched Key  Access算法来提高join的性能 |
| Using MRR                                                    | 使用了Muti-Range Read优化策略                                |
| Using sort_union（..），Using union（..），Using intersect（..） | 这些提示索引扫描如何合并为index_merge连接类型                |
| **Using temporary**                                          | 为了解决该查询，MySQL创建了一个临时表来保存结果，如果查询包含不同列的GROUP BY和ORDER BY子句，通常会发生这种情况。 |
| **Using Where**                                              | 如果不是读取表的所有数据，或者不仅仅通过索引就可以获取所有需要的数据时，则会出现该值 |
| Using where with pushed condiction                           | 仅用于NDB                                                    |
| Zero limit                                                   | 该查询有一个limit 0子句，不能选择任何行                      |

### 2.4. MySQL SQL性能分析？

除了使用EXPLAIN分析模拟优化器执行SQL语句外，还可以深入SQL内部来分析性能瓶颈，包括三种形式：

#### SHOW PROFILE

SHOW PROFILES，是MySQL的一个性能分析命令，可以跟踪SQL各种资源消耗情况，但官方文档声明SHOW PROFILES已被废弃，建议使用Performance Schema作为替代品。

- **使用步骤如下**：

  ```sql
  -- 1. 查看是否支持SHOW PROFILES功能，yes表示支持
  select @@have_profiling;
  
  -- 2. 查看是否启用了SHOW PROFILES功能，0表示未启动，1表示已启动
  select @@profiling;
  
  -- 3. 开启SHOW PROFILES功能
  set profiling = 1;
  
  -- 4. 使用SHOW PROFILES功能，默认展示15条，可通过set profiling_history_size来设置
  SHOW PROFILES;
  
  -- 5. 关闭SHOW PROFILES功能
  set profiling = 0;
  ```

  ![1630814806087](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630814806087.png)

- 默认情况下，SHOW PROFILES只展示Status和Duration两列，如果想展示更多信息，还可以**指定type**。

| type             | 含义                                         |
| ---------------- | -------------------------------------------- |
| ALL              | 显示所有信息                                 |
| BLOCK IO         | 显示阻塞I/O次数                              |
| CONTEXT SWITCHES | 显示自愿及非自愿的上下文切换次数             |
| CPU              | 显示用户与系统CPU使用时间                    |
| IPC              | 显示消息发送与接收的次数                     |
| MEMORY           | 显示内存相关的开销                           |
| PAGE FAULTS      | 显示页错误相关的开销                         |
| SOURCE           | 列出相应操作对应的函数名及其在源码中的行位置 |
| SWAPS            | 显示swap交换次数                             |

#### INFORMATION_SCHEMA.PROFILING

SHOW PROFILES本质上读的就是INFORMATION_SCHEMA.PROFILING表，因此除了使用SHOW PROFILES做性能分析，也可以直接查询INFORMATION_SCHEMA.PROFILING，除非设置set profiling = 1，否则该表不会有任何数据。 

```sql
SHOW PROFILE FOR QUERY 2;

-- 等价于
SELECT STATE, FORMAT(DURATION, 6) AS DURATION
FROM INFORMATION_SCHEMA.PROFILING
WHERE QUERY_ID = 2
ORDER BY SEQ;
```

| INFORMATION_SCHEMA.PROFILING字段          | 含义                                         |
| ----------------------------------------- | -------------------------------------------- |
| QUERY_ID                                  | SQL语句的唯一标识                            |
| SEQ                                       | 一个序号，展示具有相同QUERY_ID值的行显示顺序 |
| STATE                                     | 分析状态                                     |
| DURATION                                  | 在这个状态下持续了多久时间（秒）             |
| CPU_USER，CPU_SYSTEM                      | 用户和系统CPU使用情况（秒）                  |
| CONTEXT_VOLUNTARY，CONTEXT_INVOLUNTARY    | 发生了多少次自愿和非自愿的上下文切换         |
| BLOCK_OPS_IN，BLOCK_OPS_OUT               | 块输入和输出操作的数量                       |
| PAGE_FAULTS_MAJOR，PAGE_FAULTS_MINOR      | 主要和次要的页错误信息                       |
| SWAPS                                     | 发生了多少次SWAP                             |
| SOURCE_FUNCTION，SOURCE_FILE，SOURCE_LINE | 当前状态是在源码的哪里执行的                 |

#### PERFOMANCE_SCHEMA

PERFORMANCE_SCHEMA是MySQL建议的性能分析方式，未来SHOW PROFILES、INFORMATION_SCHEMA.PROFILING都会被废弃。

```sql
-- 1. 查看是否开启性能监控，默认是开启的（>= MySQL 5.6）
mysql> SELECT * FROM performance_schema.setup_actors;
+------+------+------+---------+---------+
| HOST | USER | ROLE | ENABLED | HISTORY |
+------+------+------+---------+---------+
| %    | %    | %    | YES     | YES     |
+------+------+------+---------+---------+

-- 2. 开启相关监控
mysql> UPDATE performance_schema.setup_instruments
       SET ENABLED = 'YES', TIMED = 'YES'
       WHERE NAME LIKE '%statement/%';

mysql> UPDATE performance_schema.setup_instruments
       SET ENABLED = 'YES', TIMED = 'YES'
       WHERE NAME LIKE '%stage/%';
       
mysql> UPDATE performance_schema.setup_consumers
       SET ENABLED = 'YES'
       WHERE NAME LIKE '%events_statements_%';

mysql> UPDATE performance_schema.setup_consumers
       SET ENABLED = 'YES'
       WHERE NAME LIKE '%events_stages_%';

-- 3. 执行业务SQL后，获取EVENT_ID
mysql> SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT
       FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%10001%';
+----------+----------+--------------------------------------------------------+
| event_id | duration | sql_text                                               |
+----------+----------+--------------------------------------------------------+
|       31 | 0.028310 | SELECT * FROM employees.employees WHERE emp_no = 10001 |
+----------+----------+--------------------------------------------------------+

-- 4. 根据EVENT_ID获取SQL性能分析信息
mysql> SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration
       FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=31;
+--------------------------------+----------+
| Stage                          | Duration |
+--------------------------------+----------+
| stage/sql/starting             | 0.000080 |
| stage/sql/checking permissions | 0.000005 |
| stage/sql/Opening tables       | 0.027759 |
| stage/sql/init                 | 0.000052 |
| stage/sql/System lock          | 0.000009 |
| stage/sql/optimizing           | 0.000006 |
| stage/sql/statistics           | 0.000082 |
| stage/sql/preparing            | 0.000008 |
| stage/sql/executing            | 0.000000 |
| stage/sql/Sending data         | 0.000017 |
| stage/sql/end                  | 0.000001 |
| stage/sql/query end            | 0.000004 |
| stage/sql/closing tables       | 0.000006 |
| stage/sql/freeing items        | 0.000272 |
| stage/sql/cleaning up          | 0.000001 |
+--------------------------------+----------+
```

### 2.5. MySQL OPTIMIZER_TRACE优化器跟踪？

OPTIMIZER_TRACE是MySQL 5.6引入的一项跟踪功能，可以跟踪优化器做出的各种决策，比如访问表的方法、各种开销的计算、各种的转换等，并将跟踪结果记录到INFORMATION_SCHEMA.OPTIMIZER_TRACE表中。

- 默认关闭，在开启后可分析SELECT、INSERT、REPLACE、UPDATE、EXPLAIN、SET、DECLARE、IF、RETURN、CALL。

- **使用步骤**：

  ```sql
  -- 1. 开启OPTIMIZER_TRACE
  SET OPTIMIZER_TRACE="enabled=on",END_MARKERS_IN_JSON=on;
  SET optimizer_trace_offset=-30, optimizer_trace_limit=30;
  
  -- 2. 执行业务SQL
  select *
  from salaries
  where from_date = '1986-06-26' and to_date = '1987-06-26';
  
  -- 3. 查看跟踪信息
  SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE limit 30;
  
  -- 4. 关闭OPTIMIZER_TRACE
  SET optimizer_trace="enabled=off";
  ```

- **OPTIMIZER_TRACE字段含义**：

  | 字段                              | 含义                                                         |
  | --------------------------------- | ------------------------------------------------------------ |
  | QUERY                             | 查询的SQL语句                                                |
  | TRACE                             | QUERY字段对应语句的跟踪信息                                  |
  | MISSING_BYTES_BEYOND_MAX_MEM_SIZE | 跟踪信息过长时，被截断的跟踪信息字节数                       |
  | INSUFFICIENT_PRIVILEGES           | 执行跟踪语句的用户是否有查看对象的权限，当不具有权限时，该列信息为1且TRACE字段为空，一般在调用带有SQL SECURITY DEFINER的视图，或者存储过程的情况下，会出现此问题 |

- **TRACE字段内容**：

  ```java
  # 跟踪结果展示
  TRACE: {
  	"steps": [{
  			# 1. 准备阶段的执行过程
  			"join_preparation": {
  				"select#": 1,
  				"steps": [{
  					"expanded_query": "/* select#1 */ select `salaries`.`emp_no` AS `emp_no`,`salaries`.`salary` AS `salary`,`salaries`.`from_date` AS `from_date`,`salaries`.`to_date` AS `to_date` from `salaries` where ((`salaries`.`from_date` = '1986-06-26') and (`salaries`.`to_date` = '1987-06-26'))"
  				}] /* steps */
  			} /* join_preparation */
  		},
  		{
  			# 2. 优化阶段的执行过程，是分析OPTIMIZER_TRACE的重点
  			"join_optimization": {
  				"select#": 1,
  				"steps": [{
  						# 2.1. 条件处理，主要对WHERE条件进行优化处理
  						"condition_processing": {
  							# 优化的对象类型，比如WHERE 或者 HAVING
  							"condition": "WHERE",
  							# 优化前的原始语句
  							"original_condition": "((`salaries`.`from_date` = '1986-06-26') and (`salaries`.`to_date` = '1987-06-26'))",
  							# 主要包括三步，分别是quality_propagation（）、constant_propagation（）、trivial_condition_removal（）
  							"steps": [
  							    # 等值条件句转换
  							    {
  									# 转换类型句
  									"transformation": "equality_propagation",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal('1986-06-26', `salaries`.`from_date`) and multiple equal('1987-06-26', `salaries`.`to_date`))"
  								},
  								# 常量条件句转换
  								{
  									# 转换类型句
  									"transformation": "constant_propagation",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal('1986-06-26', `salaries`.`from_date`) and multiple equal('1987-06-26', `salaries`.`to_date`))"
  								},
  								# 无效条件移除的转换
  								{
  									# 转换类型句
  									"transformation": "trivial_condition_removal",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal(DATE'1986-06-26', `salaries`.`from_date`) and multiple equal(DATE'1987-06-26', `salaries`.`to_date`))"
  								}
  							] /* steps */
  						} /* condition_processing */
  					},
  					{
  						# 2.2. 用于替换虚拟生成列
  						"substitute_generated_columns": {} /* substitute_generated_columns */
  					},
  					{
  						# 2.3. 分析表之间的依赖关系
  						"table_dependencies": [{
  							# 涉及的表名，如果有别名，也会展示出来
  							"table": "`salaries`",
  							# 行是否可能为NULL，这里指JOIN操作之后，这张表里的数据是不是可能为NULL。如果语句中使用了LEFT JOIN，则后一张表row_may_be_null会显示为true
  							"row_may_be_null": false,
  							# 表的映射编号，从0开始递增
  							"map_bit": 0,
  							# 依赖的映射表，当使用STRAIGHT JOIN强行控制连接顺序或者LEFT JOIN/RIGHT JOIN有顺序差别时，会在depends_on_map_bits中展示前置表的map_bit值
  							"depends_on_map_bits": [] /* depends_on_map_bits */
  						}] /* table_dependencies */
  					},
  					{
  						# 2.4. 列出所有可用的ref类型的索引，如果使用了组合索引的多个部分，则会在ref_optimizer_key_uses下列出多个元素，每个元素中会列出ref使用的索引及对应值
  						"ref_optimizer_key_uses": [{
  								"table": "`salaries`",
  								"field": "from_date",
  								"equals": "DATE'1986-06-26'",
  								"null_rejecting": false
  							},
  							{
  								"table": "`salaries`",
  								"field": "to_date",
  								"equals": "DATE'1987-06-26'",
  								"null_rejecting": false
  							}
  						] /* ref_optimizer_key_uses */
  					},
  					{
  						# 2.5. 估算需要扫描的记录数
  						"rows_estimation": [{
  							# 表名
  							"table": "`salaries`",
  							"range_analysis": {
  								# 如果全表扫描的话，需要扫描多少行，以及需要的代价
  								"table_scan": {
  									"rows": 2838216,
  									"cost": 286799
  								} /* table_scan */ ,
  								# 列出表中所有的索引，并分析其是否可用。如果不可用的话，会列出不可用的原因是什么，如果可用会列出索引中可用的字段
  								"potential_range_indexes": [{
  										"index": "PRIMARY",
  										"usable": false,
  										"cause": "not_applicable"
  									},
  									{
  										"index": "salaries_from_date_to_date_index",
  										"usable": true,
  										"key_parts": [
  											"from_date",
  											"to_date",
  											"emp_no"
  										] /* key_parts */
  									}
  								] /* potential_range_indexes */ ,
  								# 如果有下推的条件，则带条件考虑范围查询
  								"setup_range_conditions": [] /* setup_range_conditions */ ,
  								# 当使用了GROUP BY或者DISTINCT时，是否有合适的索引可用。当未使用GROUP BY或者DISTINCT时，会显示chosen=false，cause=not_group_by_or_distinct；如果使用了GROUP或者DISTINCT，但为多表查询时，则会显示chosen=false，cause=not_single_table。其他情况下会尝试分析索引（potential_group_range_indexes）并计算对应的扫描行数及其所需代价
  								"group_index_range": {
  									"chosen": false,
  									"cause": "not_group_by_or_distinct"
  								} /* group_index_range */ ,
  								# 是否使用了skip scan，skip scan是MySQL 8.0的新特性
  								"skip_scan_range": {
  									"potential_skip_scan_indexes": [{
  										"index": "salaries_from_date_to_date_index",
  										"usable": false,
  										"cause": "query_references_nonkey_column"
  									}] /* potential_skip_scan_indexes */
  								} /* skip_scan_range */ ,
  								# 分析各个索引的使用成本
  								"analyzing_range_alternatives": {
  									# range扫描分析
  									"range_scan_alternatives": [{
  										# 索引名
  										"index": "salaries_from_date_to_date_index",
  										# range扫描的条件范围
  										"ranges": [
  											"0xda840f <= from_date <= 0xda840f AND 0xda860f <= to_date <= 0xda860f"
  										] /* ranges */ ,
  										# 是否使用了index dive，该值会被参数eq_range_index_dive_limit变量值影响
  										"index_dives_for_eq_ranges": true,
  										# 该range扫描的结果集是否根据主键值进行排序
  										"rowid_ordered": true,
  										# 是否使用了MRR
  										"using_mrr": false,
  										# 表示是否使用了覆盖索引
  										"index_only": false,
  										# 扫描的行数
  										"rows": 86,
  										# 索引的使用成本
  										"cost": 50.909,
  										# 表示是否使用了索引
  										"chosen": true
  									}] /* range_scan_alternatives */ ,
  									# 分析是否使用了索引合并(index merge)，如果未使用，会在cause中展示原因；如果使用了索引合并，会在该部分展示索引合并的代价
  									"analyzing_roworder_intersect": {
  										"usable": false,
  										"cause": "too_few_roworder_scans"
  									} /* analyzing_roworder_intersect */
  								} /* analyzing_range_alternatives */ ,
  								# 在前一个步骤中分析了各类索引使用的方法及代价，得出了一定的中间结果之后，在summary阶段汇总前一阶段的中间结果确认最后的方案
  								"chosen_range_access_summary": {
  									# range扫描最终选择的执行计划
  									"range_access_plan": {
  										# 展示执行计划的type，如果使用了索引合并，则会展示index_roworder_intersect
  										"type": "range_scan",
  										# 索引名
  										"index": "salaries_from_date_to_date_index",
  										# 扫描的行数
  										"rows": 86,
  										# range扫描的条件范围
  										"ranges": [
  											"0xda840f <= from_date <= 0xda840f AND 0xda860f <= to_date <= 0xda860f"
  										] /* ranges */
  									} /* range_access_plan */ ,
  									# 该执行计划的扫描行数
  									"rows_for_plan": 86,
  									# 该执行计划的执行代价
  									"cost_for_plan": 50.909,
  									# 是否选择该执行计划
  									"chosen": true
  								} /* chosen_range_access_summary */
  							} /* range_analysis */
  						}] /* rows_estimation */
  					},
  					{
  						# 2.6. 负责对比各可行计划的开销，并选择相对最优的执行计划
  						"considered_execution_plans": [{
  							# 当前计划的前置执行计划
  							"plan_prefix": [] /* plan_prefix */ ,
  							# 涉及的表名，如果有别名，也会展示出来
  							"table": "`salaries`",
  							# 通过对比considered_access_paths，选择一个最优的访问路径
  							"best_access_path": {
  								# 当前考虑的访问路径
  								"considered_access_paths": [{
  										# 使用索引的方式
  										"access_type": "ref",
  										# 索引
  										"index": "salaries_from_date_to_date_index",
  										# 行数
  										"rows": 86,
  										# 开销
  										"cost": 50.412,
  										# 是否选用这种执行路径
  										"chosen": true
  									},
  									{
  										"access_type": "range",
  										"range_details": {
  											"used_index": "salaries_from_date_to_date_index"
  										} /* range_details */ ,
  										"chosen": false,
  										"cause": "heuristic_index_cheaper"
  									}
  								] /* considered_access_paths */
  							} /* best_access_path */ ,
  							# 类似于explain的filtered列，是一个估算值
  							"condition_filtering_pct": 100,
  							# 执行计划最终的扫描行数，由considered_access_paths.rows * condition_filtering_pct计算获得
  							"rows_for_plan": 86,
  							# 执行计划的代价，由considered_access_paths.cost相加获得
  							"cost_for_plan": 50.412,
  							# 是否选择了该执行计划
  							"chosen": true
  						}] /* considered_execution_plans */
  					},
  					{
  						# 2.7. 基于considered_execution_plans中选择的执行计划，改造原有的where条件，并针对表增加适当的附加条件，以便于单表数据的筛选，主要是为了便于索引条件下推（ICP），但ICP是否开启并不影响这部分内容的构造
  						"attaching_conditions_to_tables": {
  							# 原始的条件语句
  							"original_condition": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))",
  							# 使用启发式算法计算已使用的索引，如果已使用的索引的访问类型是ref，则计算用range能否使用组合索引中更多的列，如果可以，则用range的方式替换ref
  							"attached_conditions_computation": [] /* attached_conditions_computation */ ,
  							# 附加之后的情况汇总
  							"attached_conditions_summary": [{
  								# 表名
  								"table": "`salaries`",
  								# 附加的条件或原语句中能直接下推给单表筛选的条件
  								"attached": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))"
  							}] /* attached_conditions_summary */
  						} /* attaching_conditions_to_tables */
  					},
  					{
  						# 2.8. 最终的、经过优化后的表条件
  						"finalizing_table_conditions": [{
  							"table": "`salaries`",
  							"original_table_condition": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))",
  							"final_table_condition   ": null
  						}] /* finalizing_table_conditions */
  					},
  					{
  						# 2.9. 改善执行计划
  						"refine_plan": [{
  							"table": "`salaries`"
  						}] /* refine_plan */
  					}
  				] /* steps */
  			} /* join_optimization */
  		},
  		{
  			# 3. 执行阶段的执行过程
  			"join_execution": {
  				"select#": 1,
  				"steps": [] /* steps */
  			} /* join_execution */
  		}
  	] /* steps */
  }
  
  ```

### 2.6. MySQL数据库诊断命令？

MySQL数据库诊断命令，可以帮助了解数据库的运行情况。

| 命令                 | 作用                                                         |
| -------------------- | ------------------------------------------------------------ |
| SHOW PROCESSLIST     | 查看当前正在运行的线程，如果执行此命令的用户拥有PROCESS权限，则可看到所有线程；否则只能看到自己的线程。等价于select * from information_schema.PROCESSLIST; |
| SHOW STATUS          | 查看服务器相关信息                                           |
| SHOW VARIABLES       | 查看MySQL的变量                                              |
| SHOW TABLE           | 查看表以及视图的状态                                         |
| SHOW INDEX           | 查看索引相关信息                                             |
| SHOW ENGINE          | 查看有关存储引擎的相关信息                                   |
| SHOW MASTER STATUS   | 查看有关master binlog文件的相关信息                          |
| SHOW SLAVE STATUS    | 查看slave线程的相关信息                                      |
| SHOW PROCEDURE       | 查看存储过程相关信息                                         |
| SHOW FUNCTION STATUS | 查看函数相关信息                                             |
| SHOW TRIGGERS        | 查看触发器相关信息                                           |
| SHOW WARNINGS        | 查看error、waring、note级别的诊断信息                        |
| SHOW ERRORS          | 查看error级别的诊断信息，和show warnings类似                 |
| SHOW BINARY LOGS     | 查看服务器上所有的binary log                                 |
| SHOW BINLOG EVENTS   | 查看binary log中的事件                                       |
| SHOW RELAYLOG EVENTS | 查看复制从库的relay log事件相关信息                          |

### 2.7. MySQL索引分类？

- 索引，是按照特定的数据结构，把数据表中的数据放在索引文件中，以便于快速查找。
- 索引存在于磁盘中，会占据物理空间。

| 存储内容   | InnoDB           | MyISAM             |
| ---------- | ---------------- | ------------------ |
| 表结构文件 | .frm             | .frm               |
| 表数据文件 | .idb（聚蔟索引） | .myd               |
| 索引文件   | .idb（聚蔟索引） | .myi（非聚蔟索引） |

#### 按数据结构角度分

##### B-Tree索引

###### BST

- **特点**：
  - Binary Sort Tree，二叉树查找树，左边的结点比右边的结点小，右边的结点比左边的结点大。
  - 查找效率取决于树的高度。
- **查找流程**：
  1. 从根结点出发比较要查找的关键字key。
  2. 如果根结点关键字等于key，则返回根结点。
  3. 如果根结点关键字比key小，则继续查找左子树。
  4. 如果根结点关键字比key大，则继续查找右子树。
- **缺点**：有可能会退化成链表，查询的时间复杂度也从O(logn)退化成O(n)。

![1630832978045](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630832978045.png)

###### AVL

- **特点**：
  - Self-balancing binary search tree，平衡二叉搜索树，每个结点的左子树和右子树的高度差不能超过1。
  - 对于n个结点，树的高度是logn，查询的时间复杂度为O(logn)。
- **缺点**：结点过多时，数的高度也会越来越大，最终导致查询效率较低。

###### B-Tree

- **特点**：
  - Balance Tree，平衡多路搜索树，根结点的子结点个数为 2 <= x <= m，m是树的阶。
    - 假设m=3，则根结点可以有2~3个孩子。
  - 中间结点的子结点个数为m/2 <= y <= m。
    - 假设m=3，中间结点至少有2个孩子，最多3个孩子。
  - 每个中间结点包含n个关键字，n为子结点个数-1，且按升序排序。
    - 如果中间结点有3个子结点，则中间结点里面会有**2个关键字，且按升序排序**。
  - Pi（i=1，...，n+1）为指向子树根结点的指针，其中P[1]指向关键字小于Key[1]的子树，P[i]指向关键字属于（Key[i-1]，Key[i]）的子树，P[n+1]指向关键字大于Key[n]的子树。
    - 如果中间结点有3个子结点，则中间结点里面会有3个指针，2个关键字。
    - P1、P2、P3为指向子树根结点的指针，P1指向关键字小于Key1的树，P2指向Key1~Key2之间的子树，P3指向大于Key2的树。
- **优点**：可以有效地降低树的高度，树的阶m越大，树的高度就越低，查询次数就越少，性能就越高。
  - 在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**，而造成磁盘IO读写过于频繁，进而导致效率低下的情况，此时，只要通过某种较好的树结构减少树的结构尽量减少树的高度，而B树与B+树每个结点可以有多个关键字，由于多路子树的存在，可以大大降低降低树的高度。
- **缺点**：范围查询时，需要多次从头遍历树，性能较低。

![1630833491913](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630833491913.png)

###### B+Tree

- **特点**：
  - B+Tree中，有n个子结点的结点，会含有n个关键字。
    - 而B-Tree中的是n-1个关键字。
  - B+Tree中，所有的叶子结点中包含了全部的关键字信息（会冗余父结点的关键字），且叶子结点按照关键字大小， 自小而大地顺序链接，构成一个有序链表。
    - 而B-Tree中的叶子结点不会包括全部的关键字。
  - B+Tree中，非叶子结点仅用于存放索引（即关键字），不保存数据记录（即data），记录都存放在叶子结点中。
    - 而B-Tree中的非叶子结点既保存索引，也保存数据记录。
- **优点**：
  - B+树是B树的升级版，B+树只有叶节点存放数据，其余节点用来索引，其索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而**提高范围查找的效率，增加的索引的范围**。
  - B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描。

![1630834501421](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630834501421.png)

- **磁盘预读原理**：将**一个节点的大小设为等于一个页**，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：
  - 每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。
- **页存储**：
  - 自mysql5.7后，提供了一个设定page大小的参数innodb_page_size，默认值是16K，可以通过来改变page的大小来**间接改变m阶**，来改变B+树的m的大小。
  - 比如要存20G大小的数据，那么page=16K和page=4K，树的高度是不一样的，也就是说，树的高度是根据要存下的数据是多少来决定的。

![1630915960707](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630915960707.png)

###### B+Tree VS B-Tree

| 场景     | B+Tree                                                    | B-Tree                             |
| -------- | --------------------------------------------------------- | ---------------------------------- |
| 等值查询 | 中间结点存储的索引多，树整体更加矮胖，磁盘I/O次数比较稳定 | 中间结点会存放数据，查询效率不稳定 |
| 范围查询 | 只需要遍历叶子结点的有序链表即可，性能较高                | 需要多次从根结点开始遍历，性能较低 |

###### InnoDB VS MyISAM

|                                      | InnoDB                                 | MyISAM                                           |
| ------------------------------------ | -------------------------------------- | ------------------------------------------------ |
| 索引数据结构                         | B+Tree                                 | B+Tree                                           |
| 主键索引                             | 叶子结点存储主键及数据记录（聚蔟索引） | 叶子结点存储的是指向数据记录的指针（非聚蔟索引） |
| 非主键索引（即二级索引或者辅助索引） | 叶子结点存储索引以及主键（非聚蔟索引） | 叶子结点存储的是指向数据记录的指针（非聚蔟索引） |

##### Hash索引

- **特点**：
  - 基于哈希表来实现，用索引列的值来计算hashCode，根据hashCode组成一个哈希表，同时在哈希表中存储了指向每个数据行的物理位置。
  - 由于使用哈希算法，因此时间复杂度为O（1），访问速度非常快，而当产生哈希冲突时，需要遍历指针数组或者指针链表，性能会下降一些，因此使用哈希索引需要尽量避免哈希冲突的发生。
- **缺点**：
  - 由于一个值只能对应一个hashCode，且根据哈希算法进行散列，哈希后的值不再具有比较意义，因此hash索引**不支持范围查找和排序，只支持等值匹配**，因此Hash索引只适合特殊场景下才使用。

![1630836502073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630836502073.png)

###### InnoDB VS MyISAM

| InnoDB                                                       | MyISAM                 |
| ------------------------------------------------------------ | ---------------------- |
| 1）自适应的hash索引，不支持显示创建Hash索引，当InnoDB发现某个索引值使用非常频繁，它会在B+Tree的基础上再建立一个哈希索引。2）可以使用show variables like 'innodb_adaptive_hash_index'查看开关是否打开。3）以及使用set global innodb_adaptive_hash_index = ‘OFF’，来关闭该功能（默认是打开的） | 支持显示地创建Hash索引 |

##### 空间索引

- **特点**：
  - 基于R-Tree构建，也叫R-Tree索引，用来存储GIS数据（地图数据）。
  - 在早期只有MyISAM引擎支持空间索引，在MySQL 5.7开始，InnoDB也开始支持空间索引了。

##### 全文索引

- **特点**：
  - 用于适应全文搜索的需求。
  - 在MySQL 5.7之前，全文索引不支持中文，经常搭配Sphinx的使用，而从5.7开始MySQL内置了ngram，支持中文。
  - 但是目前一般使用搜索引擎来解决全文搜索的需求，比如ES。

#### 按功能逻辑角度分

##### 普通索引

普通索引，是基础的索引，没有任何约束，主要用于提高查询效率。

```sql
CREATE INDEX index_name ON table(column(length))

```

##### 唯一索引

- 唯一索引，是在普通索引的基础上，增加了数据唯一性的约束，其索引列的值必须唯一，且允许为NULL值。
- 如果一个为唯一索引同时还是组合索引，那么表示列值组合必须唯一。
- 在一张数据表里可以有多个唯一索引。

```sql
CREATE UNIQUE INDEX indexName ON table(column(length))

```

##### 主键索引

主键索引，是一种特殊的唯一索引，其索引列不允许有NULL值，并且一张表最多只有一个主键索引。

##### 组合索引

组合索引，指多个字段上创建的索引，使用组合索引时需要遵循**最左前缀原则**。

```sql
CREATE index index_name ON table (column1, column2);

```

##### 全文索引

全文索引，用来检索文本中的关键字，用得很少，一般应对这种需求用ES或者Solr之类的全文搜索引擎比较好。

```sql
CREATE FULLTEXT INDEX ...

```

#### 按物理存储角度分

![1630845876331](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630845876331.png)

##### 聚蔟索引

聚蔟索引，**叶子结点就是数据结点**，将表数据和主键一起存储，其数据的物理存放顺序与索引顺序是一致的，即只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上，而由于无法同时把数据行同时存放在两个不同的地方，因此一张表只有一个聚蔟索引。

- InnoDB的主键索引使用的是聚蔟索引，如果创建的表没有主键，InnoDB则会隐式定义一个主键来作为聚蔟索引。
- **聚蔟索引的二级索引**：叶子结点不会保存引用行数据，而是保存行的主键值，然后根据主键值获取到数据，比如InnoDB的普通索引、联合索引。
- **优点**：
  - 查找效率理论上比非聚蔟索引的要高，因为数据就存放在索引上，且数据存储顺序就是索引的顺序。
  - 范围查询方便，因为只需要遍历索引的叶子结点即可。
- **缺点**：
  - 插入、修改、删除操作的性能比非聚蔟索引的要低，因为非聚蔟索引在更新时，数据行在表中的位置不会发生变化，而聚蔟索引的数据行需要重新移动位置。
  - **插入速度严重依赖于插入顺序**，因为按照主键顺序插入数据是InnoDB表中速度最快的插入方式，如果不是按照主键顺序插入数据，那么在插入完成后，最好使用**optimize table**命令重新组织一下表，因此，对于聚集索引，一般都会定义一个自增的ID列为主键。
  - **更新主键的代价很高**，因为会导致InnoDB移动被更新的行。
  - 另外，插入新行或者更新主键导致数据行被移动时，还有可能面临**页分裂**的问题，当行的主键值被要求必须插入行数据到某个已满的页中，InnoDB会将页分裂为两个页面来容纳这行，产生一次页分裂操作，这会**导致表占用更多的磁盘空间。**
  - 而由于页分裂导致数据存储不连续，或者本身行数据就存储得比较稀疏时，聚蔟索引可能导致**全表扫描变得更慢**。

##### 非聚蔟索引

非聚蔟索引，**叶子结点不存储数据**，而是指向对应数据块的指针，表数据和索引分开存储，查询时先找到索引，再根据索引找到对应的数据行。

- MyISAM的主键索引使用的是非聚蔟索引。

##### 聚蔟索引与自增主键？

1. **随机主键给聚蔟索引的坏处**：

   - 如果主键不是自增ID（比如UUID），会使得聚簇索引的插入变得随机，使得数据没有任何聚集特性。
   - 性能上，由于插入的随机性产生乱序写入，为了给新行分配空间，InnoDB不得不频繁做页分裂操作，导致需要移动大量数据，不断地调整数据的物理地址和分页，**影响写入的性能**。
   - 而由于**页分裂**导致数据存储不连续，或者本身行数据就存储得比较稀疏时，聚蔟索引可能导致**全表扫描变得更慢**。

   => 因此随机主键在插入完成后，最好使用**optimize table**命令，来重建表并优化页的填充。

2. **自增主键对聚蔟索引的好处**：对于聚蔟索引，叶子结点就是数据结点，将表数据和主键一起存储，其数据的物理存放顺序与索引顺序是一致的，即只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上。

   - 对于这种数据结构，如果按主键自增的顺序写入数据，InnoDB只需要一页一页地写，**索引结构相对紧凑，磁盘碎片少，效率也高**。

3. **自增主键对聚蔟索引的坏处**：对于高并发场景下，如果在InnoDB中按主键顺序插入，**可能会造成明显的锁争用**。这是因为：

   - **主键的上界（左边）会成为热点**：由于所有插入都发生在这里，所以并发插入可能会导致**间隙锁竞争**。
   - **另一个热点是自增锁机制**：如果遇到这个问题，则可能需要考虑重新设计表或者应用，比如应用层面生成单调递增的主键ID，插表不使用auto_increment机制。

### 2.8. MySQL创建索引的原则？

**创建索引的原则**：目的是让索引过滤更多的行，**快速定位记录，或者利用索引的有序性**。

- **where条件、分组、排序、去重、联表、唯一的字段**，一般建议创建索引。
- **更新多、查询少、表数据少、列重复数据多、不是where频繁使用的字段**，一般不建议创建索引。

#### 创建索引

```sql
CREATE [UNIQUE | FULLTEXT]  INDEX 索引名 ON 表名(字段名) [USING 索引方法]；
-- eg: CREATE index index_name ON table (column1, column2);

-- 说明：
-- UNIQUE: 可选。表示索引为唯一性索引。
-- FULLTEXT: 可选。表示索引为全文索引。
-- INDEX: 用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。
-- 索引名: 可选。给创建的索引取一个新名称。
-- 字段名: 指定索引对应的字段的名称，该字段必须是前面定义好的字段。
-- 注： 索引方法默认使用B+TREE。

```

#### 哪些场景建议创建索引

1. **select语句中，频繁作为where条件的字段**，建议创建索引，可以快速定位行记录。
2. **update和delete语句中，where条件的字段**，建议创建索引，可以快速定位行记录。
3. **需要分组、排序的字段**，建议创建索引，可以利用索引的有序性，避免文件内排序和建立临时表。
4. **distinct所使用的字段**，建议创建索引，可以快速定位行记录。
5. **字段的值有唯一性约束**，可以创建主键或者唯一索引。
6. **对于多表查询，联接字段应创建索引**，且**类型务必保持一致**，因为如果不一致可能会出现**类型的隐式转换**，导致索引失效。

#### 哪些场景不建议创建索引

1. **where子句里用不到的字段**，不建议创建索引，索引作用是用来定位记录，如果查询条件里不需要这个字段，那么这个字段也不需要创建索引。
2. **表的记录非常少时**，不建议创建索引，因为这种情况下（比如100条数据），建立索引的作用并不大，没有必要创建索引。
3. **列里有大量重复数据时**，不建议创建索引，因为此时索引的选择性低，建立索引作用不大。
   - **唯一索引比普通索引效率高的原因**：索引选择性越高，查询的效率就越好，因为可以在查找时过滤掉更多的行，如果索引列重复的值过多，索引的选择性就低，查询能过滤掉的行就少，此时效率自然就不高。
4. **频繁更新的字段，想要建立要考虑索引维护的开销**，如果该字段查询得少，则没必要为它创建索引。

#### 索引性能评估公式

多数情况下，可以通过计算磁盘的搜索次数来估算查询性能。

- **对于比较小的表**：可以在一次磁盘搜索中找到，因为索引可能已经被缓存了。
- **对于更大的表**：可以使用B-Tree索引来进行估算，估算公式为：

```mysql
磁盘I/O次数 = log(row_count) / log(
          	index_block_length / 3 * 2 / (index_length + data_pointer_length)
           ) + 1
          
-- 其中，index_block_length=1024字节，data_pointer_length=4字节，则公式等于
磁盘I/O次数 = log(row_count) / log(
          	1024 / 3 * 2 / (index_length + 4)
           ) + 1 
           = log（row_count） / [ log(683 / (index_length + 4) ) ]
           = log（row_count） / [log683 - log(index_length + 4)]

-- => 可见，当row_count越大，index_length越大，内存中存放的索引就越少，需要的磁盘I/O次数就越多，性能就越差。

```

### 2.9. MySQL索引失效与解决方案？

#### 索引列不独立

- **独立**：是指列不能是**表达式**的一部分，也不能是**函数**的参数。
- **解决方案**：
  - 事先计算好结果，再传到SQL，避免在where条件等号左侧做表达式和函数运算。
  - 或者用等价的SQL去替代。

```sql
-- 示例1：索引字段不独立(索引字段进行了表达式计算)
explain
select *
from employees
where emp_no + 1 = 10003;
-- 解决方案：事先计算好表达式的值，再传过来，避免在SQLwhere条件 = 的左侧做计算

-- 示例2：索引字段不独立(索引字段是函数的参数)
explain
select *
from employees
where SUBSTRING(first_name, 1, 3) = 'Geo';
-- 解决方案：预先计算好结果，再传过来，在where条件的左侧，不要使用函数；或者使用等价的SQL去实现
explain
select *
from employees
where first_name like 'Geo%';

```

#### 使用了左模糊

- **解决方案**：尽量避免使用左模糊，如果避免不了，可以考虑使用搜索引擎去解决。

```sql
-- 示例3：使用了左模糊
explain
select *
from employees
where first_name like '%Geo%';
-- 解决方案：尽量避免使用左模糊，如果避免不了，可以考虑使用搜索引擎去解决
explain
select *
from employees
where first_name like 'Geo%';

```

#### 使用OR查询的部分字段没有索引

- **解决方案**：额外添加索引，使得or的两侧字段都走索引。
  - 添加后，explain#type会变成index_merge，表示索引合并（mysql的内部优化机制），合并了or两侧字段的索引。

```sql
-- 示例4：使用OR查询的部分字段没有索引
explain
select *
from employees
where first_name = 'Georgi'
   or last_name = 'Georgi';
-- 解决方案：分别为first_name以及last_name字段创建索引

```

#### 字符串条件未使用''引起来

- **解决方案**：实质上发生了类型的隐式转换，因此需要规范地编写SQL。

```sql
-- 示例5：字符串条件未使用''引起来
explain
select *
from dept_emp
where dept_no = 3;
-- 解决方案：规范地编写SQL
explain
select *
from dept_emp
where dept_no = '3';

```

#### 不符合最左前缀原则的查询

- **解决方案**：调整索引的顺序，使其满足最左前缀原则。

```sql
-- 示例6：不符合最左前缀原则的查询
-- 存在index(last_name, first_name)
explain select *
        from employees
        where first_name = 'Facello';
-- 解决方案：调整索引的顺序，变成index(first_name,last_name)/index(first_name)

```

#### 索引字段建议添加NOT NULL约束

- **原因**：**单列索引无法储null值，复合索引无法储全为null的值**，因此查询时，如果采用is null条件，则不能利用到索引，只能全表扫描。
- **解决方案**：索引字段设置成NOT NULL，甚至可以把所有字段都设置成NOT NULL并为字段设置默认值。

```sql
-- 示例7：索引字段建议添加NOT NULL约束
-- 单列索引无法储null值，复合索引无法储全为null的值
-- 查询时，采用is null条件时，不能利用到索引，只能全表扫描
-- MySQL官方建议尽量把字段定义为NOT NULL：https://dev.mysql.com/doc/refman/8.0/en/data-size.html
explain
select *
from `foodie-shop-dev`.users
where mobile is null;
-- 解决方案：把索引字段设置成NOT NULL，甚至可以把所有字段都设置成NOT NULL并为字段设置默认值

```

#### 隐式转换导致索引失效

- **解决方案**：在创建表的时候尽量规范一点，比如统一用int，或者bigint。

```sql
-- 示例8：隐式转换导致索引失效
-- 目前没这样的表，演示不了，同学们可以试试把de.emp_no的字段类型改成varchar
select emp.*, d.dept_name
from employees emp
         left join dept_emp de
                   on emp.emp_no = de.emp_no
         left join departments d
                   on de.dept_no = d.dept_no
where de.emp_no = '100001';
-- 解决方案：在创建表的时候尽量规范一点，比如统一用int，或者bigint

```

### 3.0. MySQL最左前缀原则与原理？

- **概念**：最左前缀原则，指的是索引按照**最左优先**的方式匹配索引，主要使用在**联合索引**中，其索引的数据结构在InnoDB中是B+Tree，它会按照第一个关键字、第二个关键字...**顺序进行索引排列**。
- **原理**：如果查询条件遵循最左前缀原则，那么MySQL会：
  1. 先根据第一个关键字查找联合索引树。
  2. 定位到索引树的叶子结点后，找出所有满足第一个关键字的叶子结点。
  3. 第一个关键字选择的叶子结点确定后，如果这些叶子结点对于**第二个关键字是存在且顺序**的，则MySQL会使用二分查找的方式查找这些叶子结点，接着该索引继续匹配下一个关键字。
  4. 如果这些叶子结点对于第二个关键字**不存在或者乱序**，此时则会在关键字上出现**索引失效**，导致后面的条件无法继续走上索引，而是根据之前选择的叶子结点上的**主键回表查找**。
- **联合索引失效场景**：这些场景都是因为匹配到某个关键字的叶子结点时，**不满足存在以及顺序性**。
  - 如果不是从索引的最左列开始查找，则无法使用索引。
  - 不能在中间跳过索引中的某个列，这样的查询只能使用到索引的前几列。
  - 如果查询中有某个列的范围查询，则该列右边的所有列都无法使用索引优化查找。

![1630924286192](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630924286192.png)

### 3.1. MySQL索引调优？

#### 长字段调优

- **背景**：

  - 索引字段类型范围过长，比如varchar(300)，会导致占用的空间大。
  - 而根据性能公式`磁盘I/O次数 = log（row_count） / [log683 - log(index_length + 4)]`可知，索引长度越大，一次磁盘I/O读取到的索引就越少，磁盘I/O次数就越多，性能就越差。

- **解决方案**：

  - **使用Hash算法减少B-Tree索引长度**：根据原索引字段建立一个新的字段，使用Hash算法计算原字段的Hash值，并在其上建立B-Tree索引，因此本质上依然是B-Tree索引，是"伪Hash索引"，并不是真正的哈希索引。另外还需要注意：

    - **Hash后的长度应该比较小**：SHA1/MD5是不合适的，因为它们Hash出来的值也是比较长的。
    - **应尽量避免hash冲突**：就目前来说，流行的Hash算法有CRC32（）和FNV64（）。

    ```sql
    -- Hash索引使用案例：
    -- 1) 如果直接使用B-Tree索引存储URL，由于URL一般都比较长，存储的内容就会很大。
    -- 2) 此时可以在表中新建一个列url_crc，把crc32(url)计算后的hashCode存到这个列，并在url_crc列上建立一个Hash索引，这样只需要很小的索引就可以为超长的列建立索引，性能会提高很多。
    -- 3) 但要注意，因为有可能会有哈希冲突，所以还要对url进行等值比较。
    
    ```

  - **使用前缀索引**：alter table employees add key (first_name(n))，其中n应调试到**最佳的索引选择性**，以提高索引的效益。

    - **索引选择性 = 不重复的索引值 / 数据表的总记录数**，结果越大，表示选择性越高，性能也越好。
    - 另外，翻转字符串存储 + 前缀索引，可以实现**后缀索引**。
    - **优点**：能节省空间，提高索引性能；优化对上层应用透明，落地成本小。
    - **缺点**：无法做order by和group by；也无法使用覆盖索引。

#### 单列索引调优

如果使用两个**单列索引**作为查询条件，则会导致MySQL合并索引，对两索引列匹配的结果求交集，导致产生额外的开销。

- 如果出现索引合并，往往说明存在的索引不够合理。
- 调优的目的是为了解决性能问题，如果SQL暂时没有性能问题，可以先放一边暂时不管。
- 必要时，可以将两列索引组合成为一个**组合索引**，可以节省额外的开销，但使用时需要注意**最左前缀原则**。

#### 覆盖索引调优

覆盖索引指的是，对于索引X，**SELECT的字段直接出现在从索引树上**，而无需回表数据里获取，换句话说就是，当SELECT的字段被使用的索引字段覆盖时，这种用法就是覆盖索引。

- **特点**：使用覆盖索引时，Explain#Extra结果会展示Using Index。
- **原理**：
  1. 如果索引是非主键索引，则索引树上只有对应数据行的主键，此后还需要根据主键，然后在主键索引树上定位到叶子结点后，才能返回对应的数据行（**回表查询**）。
     - **回表查询**，就是对于二级索引，需要先定位到主键值，然后再定位行记录，其性能比覆盖索引扫一遍索引树的低。
  2. 如果该索引满足覆盖索引，则在索引树上就找到需要的数据行的字段，此时直接返回即可，无需回表查询。
- **优点**：可以直接在索引树上获取到想要的数据，而无需回表查询，减少了回表的开销，提升性能。
  - 因此，编写SQL时，**尽量只返回想要的字段**，一来可以使用上覆盖索引，二来可以减少网络传输的开销，从而提升SQL的性能。

#### 重复索引调优

重复索引指的是，在相同的列上，按照相同的顺序创建的索引。

- 由于索引在增删改时是有开销的，所以**尽量避免重复索引**，如果发现则应该删除。

```sql
-- 重复索引
create table test_table
(
    id int not null primary key auto_increment,
    a  int not null,
    b  int not null,
    UNIQUE (id),
    INDEX (id)
) ENGINE = InnoDB;
-- 发生了重复索引，改进方案： 删掉唯一索引和普通索引

```

#### 冗余索引调优

冗余索引指的是，如果已经存在索引index（A，B），又创建了index（A），那么index（A）就是index（A，B）的冗余索引。

- 冗余索引针对的是联合索引，不是Hash索引和其他索引。
- 但冗余索引也有特例，特别是与**where + order by / group by主键**时。
  - 这种情况下，是利用了复合索引来定位叶子主键，然后order by / group by利用了主键索引的排序特性，来避免文件内排序。
  - 如果误删某个冗余索引，可能会出现问题。

```sql
-- 冗余索引: index(a)是index(a, b)的冗余索引
-- 冗余索引特例:
explain
select *
from salaries
where from_date = '1986-06-26'
order by emp_no;

-- 创建from_date索引: salaries_from_date_index
-- index(from_date): type=ref, extra=null，使用了索引
-- index(from_date) 某种意义上来说就相当于index(from_date, emp_no) => 因为emp_no是主键索引, 所以order by子句可以使用索引

-- 而index(from_date, to_date): type=ref, extra=Using filesort，order by子句无法使用索引
-- index(from_date, to_date)某种意义上来说就相当于index(from_date, to_date, emp_no) 
-- => 该复合索引跳过了to_date, 导致from_date定位到叶子主键时, 顺序是乱序的, 对于后面的order by就没办法利用上索引了, 所以出现了文件内排序Using filesort
-- 因此, 这种特例下: 在有了index(from_date, to_date)复合索引, 为了保证order by能走索引, 还需要创建冗余索引index(from_date)

```

#### 未使用的索引调优

未使用的索引指的是，某个索引根本未被使用。

- 这种索引就是累赘，应当删除。

### 3.2. MySQL索引条件下推优化？

- **概念**：索引条件下推， Index Condition PushDown，ICP，是针对MySQL**使用索引从表中检索行**情况的优化，其目标是**减少全行读取的次数，从而减少 I/O 操作**。

  - 在没有 ICP 的情况下，存储引擎遍历索引，以定位基表中的行，并将它们返回给 MySQL 服务器，该服务器评估`WHERE`行的条件。
    - 步骤⑥从存储引擎返回查找到的**多条元组**给MySQL Server，MySQL Server在⑦得到较多的元组。
    - 步骤⑦到⑧，MySQL Server依据WHERE子句条件进行过滤，得到满足条件的元组。
    - 因此，在无ICP方式下，是在MySQL Server层得到较多元组，然后才过滤，最终得到的是少量的、符合条件的元组。

  ![1630976765074](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630976765074.png)

  - 启用ICP后，如果`WHERE`可以仅使用索引中的列来评估部分条件，则MySQL服务器会推送这部分**`WHERE`条件下降到存储引擎**。然后，存储引擎使用索引条目评估推送的索引条件，并且仅当满足该条件时才从表中读取行。
    - 步骤③，不仅要在索引行进行索引读取，还要在该阶段依据MySQL Server下推过来的条件进行**条件判断**，不满足条件的则不去读取表中的数据，直接在索引树上进行下一个索引项的判断，直到有满足条件的，才进行步骤④。
    - 步骤⑥从存储引擎返回查找到的**少量元组**给MySQL Server，MySQL Server在⑦得到少量的元组。
    - 因此，在对比无ICP的方式，ICP方式返回给MySQL Server层的是**少量的、符合条件的元组**。

  ![1630976784073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630976784073.png)

- **特点**：当使用Explain进行分析时，如果使用了索引条件下推，Extra会显示**Using index condition**。

- **作用**：索引条件下推优化ICP，可以减少**存储引擎访问基表的次数**和**MySQL服务器访问存储引擎的次数**。

- **适用条件**：

  - **当需要全表扫描时**，比如range、ref、eq_ref、ref_or_null，适用于InnoDB引擎和MyISAM引擎的查询。
  - 对于InnoDB引擎，**只适用于二级索引**，因为其聚簇索引会将整行数据读到InnoDB缓冲区中，此时数据已经在内存中了，存储已经不再需要去I/O读取了，使得ICP减少I/O的目的失去意义，因此**ICP不适合聚蔟索引**。
  - 不能下推引用**子查询、存储函数、触发器函数**的条件。

```sql
-- 关闭索引下推条件优化
SET optimizer_switch = 'index_condition_pushdown=off';

-- 开启索引下推条件优化
SET optimizer_switch = 'index_condition_pushdown=on';

```

### 3.3. MySQL SQL生命周期？

![1630983427049](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630983427049.png)

① 通过客户端/服务器通信协议与MySQL建立连接，并查询是否有权限。

② MySQL8.0之前需要先查看是否开启缓存，如果开启了Query Cache且命中完全相同的SQL语句，则将查询结果直接返回给客户端。

③ 由解析器进行语法语义解析，并生成解析树，如查询是select、表名tb_student、条件是id='1'等。

④ 由查询优化器生成执行计划，根据索引看看是否可以优化。

⑤ 由执行引擎执行SQL语句对应的执行计划，并根据存储引擎类型得到查询结果，如果开启了Query Cache，则还要把结果缓存起来，否则直接返回。

### 3.4. MySQL SQL执行顺序？

1. **FROM**：将数据从硬盘加载到数据缓冲区，方便对接下来的数据进行操作。
2. **WHERE**：从基表或视图中选择满足条件的元组。
3. **JOIN**：比如right left右连接，此时从右边表中读取某个元组，并且找到该元组在左边表中对应的元组或元组集。
4. **ON**：join on实现多表连接查询，**推荐该种方式进行多表查询，不使用子查询**。
5. **GROUP BY**：对满足条件的元组进行分组，一般与聚合函数一起使用。
6. **HAVING**：在以上元组的基础上进行筛选，选出符合条件的元组，一般与GROUP BY进行连用。
7. **SELECT**：从查询到得的所有元组中，获取需要展示的列。
8. **DISTINCT**：对查询得到的所有元组进行去重。
9. **UNION**：将多个查询结果合并，默认去掉重复的记录。
10. **ORDER BY**：对以上的元组结果进行相应的排序。
11. **LIMIT 1**：显示输出一条元组数据记录。

### 3.5. MySQL SQL语句调优？

#### JOIN优化 

##### 用法

![1631013588400](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631013588400.png)

从左到右，从上到下：

1. **A LEFT JOIN B**：左连接，返回A的全集。
2. **A RIGHT JOIN B**：右连接，返回B的全集。
3. **A INNER JOIN B**：内连接，返回A和B的交集。
4. **A LEFT JOIN B WHERE B.Key IS NULL**：返回A的独有集合。
5. **A RIGHT JOIN B WHERE A.Key IS NULL**：返回B的独有集合。
6. **A FULL OUTER JOIN B**：全连接，返回A和B的并集。
7. **A FULL OUTER JOIN B WHERE A.Key IS NULL OR B.Key IS NULL**：返回A和B独有集合的并集。
8. 另外，还有一种**A CROSS JOIN B**：笛卡尔连接，返回A和B的笛卡尔集，结果行数为 A *  B，如果有ON连接条件，则等于内连接。

##### 原理

联接操作的本质就是，把各个联接表中的记录都取出来，依次匹配的组合会加入结果集并返回给用户。

- 如果没有任何限制条件的话，多表联接起来产生的笛卡尔积可能是非常巨大的。比方说3个100行记录的表联接起来产生的笛卡尔积就有100×100×100=1000000行数据！

- 所以在联接的时候过滤掉特定记录组合是有必要的，在联接查询中的过滤条件可以分成两种，下面以一个JOIN查询为例：

  - **涉及单表的条件**：WHERE条件也可以称为搜索过滤条件，比如t1.m1 > 1是只针对t1表的过滤条件，t2.n2 < ‘d’是只针对t2表的过滤条件。
  - **涉及两表的条件**：比如t1.m1 = t2.m2、t1.n1 > t2.n2等。

  ```sql
  SELECT * FROM t1, t2 WHERE t1.m1 > 1 AND t1.m1 = t2.m2 AND t2.n2 < 'd';
  
  -- 查询结果
  +------+------+------+------+
  | m1   | n1   | m2   | n2   |
  +------+------+------+------+
  |    2 | b    |    2 | b    |
  |    3 | c    |    3 | c    |
  +------+------+------+------+
  
  ```

  - **联接过程**：
    1. 首先确定第一个需要查询的表，这个表称之为**驱动表**，这里使用t1作为驱动表，那么就需要到t1表中找满足t1.m1 > 1的记录，由于这里没有给t1字段添加索引，所以查询t1表的访问方法为all，也就是采用全表扫描的方式执行单表查询。
    2. 从驱动表t1产生的结果集中的每一条记录，分别需要到t2表中，查找符合过滤条件的记录。由于是根据t1表中的记录去找t2表中的记录，所以t2表也可以被称之为**被驱动表**。比如上一步骤从驱动表中得到了2条记录，所以需要查询2次t2表，此时涉及两个表的列的过滤条件t1.m1 = t2.m2就派上用场了。
    3. 当t1.m1 = 2时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 2，所以此时t2表相当于有了t1.m1 = 2、t2.n2 < ‘d’这两个过滤条件，然后到t2表中执行**单表查询**。
    4. 当t1.m1 = 3时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 3，所以此时t2表相当于有了t1.m1 = 3、t2.n2 < ‘d’这两个过滤条件，然后到t2表中执行**单表查询**。

  ![1631149759571](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631149759571.png)

  - **结论**：
    - 因此，这个两表联接查询共需要查询1次t1表，2次t2表，如果把t1.m1 > 1这个条件去掉，那么从t1表中查出的记录就有3条，就需要查询3次t2表了。
    - 也就是说在两表联接查询中，**驱动表只需要访问一次，被驱动表可能被访问多次**，这种方式在MySQL中有一个专有名词，叫**Nested-Loops Join**（嵌套循环联接）。

##### 算法

###### Nested-Loops Join

- **概念**：
  - 联接算法是，MySQL数据库用于处理联接的物理策略，当联接的表上有索引时，Nested-Loops Join是非常高效的算法。
  - 根据B+树的特性，其联接的时间复杂度为O（logn * logn），若没有索引，则可视为最坏的情况，时间复杂度为O(N²)。
  - MySQL数据库根据不同的使用场合，支持两种Nested-Loops Join算法实现，一种是**Simple Nested-Loops Join（SNLJ）**算法，另一种是**Block Nested-Loops Join（BNLJ）**算法。
- **算法思想**：
  1. **Join阶段**：
     - Join阶段是指，驱动表row scan过滤后的结果集中的每一条记录，需要分别到被驱动表中匹配关联条件的过程。
  2. **Fetch阶段**：
     - Fetch阶段是指，被驱动表根据过滤条件以及匹配的关联条件，进行回表查询数据的过程。
     - 如果关联条件的列是二级索引时，需要再访问主键索引才能得到表中数据（回表），其中MyISAM由于其二级索引存放的是指向记录的指针，所以回表速度要快点；而InnoDB是索引组织表，需要再次通过主键查找才能定位数据。
     - 然而，Fetch阶段也不是必须存在的，如果是覆盖索引联接，那么可以直接得到数据，无需回表，也就没有Fetch这个阶段。

![1631151245915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631151245915.png)

- **性能评估**：评判一个Join算法是否优劣，需要**Join开销成本**是否比较小、**I/O访问方式**是顺序还是随机等。

  | 开销统计                      | 含义                                            |
  | ----------------------------- | ----------------------------------------------- |
  | 驱动表的扫描次数（O）         | 通常都是1，即Join时扫描一次驱动表的数据即可     |
  | 被驱动表的扫描次数（I）       | 使用不同的Join算法，该值可能会不同              |
  | 联接过程读取的总记录数（R）   | 使用不同的Join算法，该值可能会不同              |
  | Join时的比较次数（M）         | 使用不同的Join算法，该值可能会不同              |
  | 被驱动表回表读取的记录数（F） | 如果Fetch为非覆盖索引，被驱动表可能需要回表查询 |

###### Simple Nested-Loops Join

Simple Nested-Loops Join，SNLJ，**简单直接的嵌套循环联接**，即驱动表中的**每一条记录**与被驱动表中的记录都需要进行比较判断，对于两表联接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍，具体访问几遍取决于对驱动表执行单表查询后的结果集中的记录条数。

- **执行过程**：

  ```sql
  For each row r in R do                         -- 扫描R表（驱动表）
      For each row s in S do                     -- 扫描S表（被驱动表）,全表扫描
          If r and s satisfy the join condition  -- 如果r和s满足join条件
              Then output the tuple <r, s>       -- 返回结果集
  
  ```

  ![1631152538991](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631152538991.png)

- **优点**：**算法最简单**。

- **缺点**：由于联接过程需要多次全表扫描被驱动表，所以**性能开销最大**。

  - 联接过程读取的总记录数的成本，和Join时的比较次数的成本都是SN*RN，也就是笛卡儿积。假设外表内表都是1万条记录，那么其读取的记录数量和Join的比较次数都需要上亿，因此实际上MySQL并不会使用到SNLJ算法。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         |
  | ----------------------------- | ------------ |
  | 驱动表的扫描次数（O）         | 1            |
  | 被驱动表的扫描次数（I）       | RN           |
  | 联接过程读取的总记录数（R）   | RN + RN * SN |
  | Join时的比较次数（M）         | RN * SN      |
  | 被驱动表回表读取的记录数（F） | 0            |

###### Index Nested-Loops Join

Index Nested-Loops Join，INLJ，**基于索引的嵌套循环联接**，为了降低SNLJ联接过程中多次全表扫描被驱动表的成本开销，可以在被驱动表中建立索引，减少被驱动表读取的记录数，其中MySQL中使用较多的是这种算法。

- **执行过程**：

  ```sql
  For each row r in R do                     -- 扫描R表
      lookup s in S index                    -- 查询S表的索引（固定3~4次IO，B+树高度）
          If find s == r                     -- 如果r匹配了索引s
              Then output the tuple <r, s>   -- 返回结果集
  
  ```

  ![1631157411686](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631157411686.png)

- **优点**：由于内表上有索引，所以Join比较时不再需要一条条记录进行比较，而可以通过索引来减少比较次数，从而加快查询速度。

  - 由于驱动表中每条记录会通过被驱动表的索引进行**二分查找匹配**，所以每次被驱动表的比较次数为**索引树的高度**。
  - 而一般B+树的高度为3~4层，也就是说匹配一次的I/O消耗也就3~4次，所以索引查询的成本是比较固定的，因此MySQL优化器会倾向于**使用记录数少的表作为驱动表**。

- **缺点**：

  - 如果被驱动表进行Join时，关联列使用的是**主键索引**，在大数据量的情况下，由于主键索引查找的开销非常小，且此时的访问模式也是比较顺序的，INLJ的效率也是相当不错的。
  - 如果被驱动表进行Join时，关联列使用的是**非覆盖的二级索引**，在大数据量的情况下，由于访问的是非覆盖的二级索引，需要通过主键索引进行回表查询，此时会产生**大量的随机I/O**，对比顺序I/O性能低下。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ                         |
  | ----------------------------- | ------------ | ---------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            |
  | 被驱动表的扫描次数（I）       | RN           | RN                           |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） |

###### Block Nested-Loops Join

Block Nested-Loops Join，BNLJ，**基于块的嵌套循环联接**，为了减少SNLJ联接过程中访问被驱动表的次数，使用一次性把多条驱动表中的记录去和被驱动表做匹配，可以大大减少重复从磁盘上加载被驱动表的代价。

- **Join Buffer使用原则**：

  - 每次联接使用一个Join Buffer，因此多表的联接可以使用多个Join Buffer。
  - Join Buffer在联接发生之前进行分配，在SQL语句执行完后进行释放。
  - Join Buffer只存储要进行查询操作的相关列数据，而不是整行的记录。
  - Join Buffer可被用于被驱动表的关联列为**ALL、index、和range**类型的联接查询。
  - 系统变量**Join_buffer_size**决定了Join Buffer的大小。
    - 当MySQL的Join有使用到Block Nested-Loop Join，调大后可以避免多次的内表扫描，从而提高性能；如果是Index Nested-Loop Join使用索引进行Join，那么调大这个变量则毫无意义。
    - Join_buffer_size默认值是256K，显然对于稍复杂的SQL是不够用的。
    - 建议在会话级别进行设置，但如果设置不好，则会容易导致因无法分配内存而宕机的问题。

- **执行过程**：

  ```sql
  For each tuple r in R do                             -- 扫描外表R
      store used columns as p from R in Join Buffer    -- 将部分或者全部R的记录保存到Join Buffer中，记为p
      For each tuple s in S do                         -- 扫描内表S
          If p and s satisfy the join condition        -- p与s满足join条件
              Then output the tuple                    -- 返回为结果集
  
  ```

  ![1631159874694](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631159874694.png)

- **优点**：

  - BNLJ算法较SNLJ算法的改进就在于，可以**减少被驱动表的扫描次数**，甚至可以和Hash Join算法一样，仅需扫描内表一次。
  - 可以使用增大**Join Buffer**（联接缓冲），或者只需要把驱动表关心的列放到查询列表，以支持一次性匹配更多的驱动表记录，来减少循环读取被驱动表的次数，从而提升Join的性能。

- **缺点**：仍然有可能会多次全表扫描被驱动表，占用磁盘 IO 资源。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ                         | BNLJ                                      |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         |

- **算法使用标记**：在BNLJ算法使用后，在SQL Explain#Extra中会提示 Using join buffer (Block Nested Loop)。

  - 在有索引的情况下，MySQL会尝试去使用Index Nested-Loop Join算法。
  - 但在Join列没有索引的情况下，MySQL不会去使用最简单的Simple Nested-Loop Join算法，而是使用Block Nested-Loop Join算法。

###### Batched Key Access Join

Batched Key Access Join，BKA，**批量键访问联接**，为了优化INLJ存在的大量随机I/O操作，在MySQL 5.6开始支持BKA算法，它是通过常见的空间换时间方式，将随机I/O转换为顺序I/O，以此来极大地提升Join的性能。

- **MRR**：Multi Range Read，**多范围读取**，MySQL 5.6的新特性，是BKA的重要支柱，目的是**为了减少磁盘的随机访问**。

  1. InnoDB由于索引组织表的特性，如果查询是使用非覆盖二级索引，则需要回表读取数据做后续处理，虽然二级索引是有序的，但对应的主键索引很可能是无效的，因此该程会随机的回表，并伴随着大量的随机I/O。

  2. 而MRR的优化在于，并不是每次都会通过二级索引直接回表读取记录，而是在范围扫描（Range Access）中，MySQL将扫描到的数据存入由**read_rnd_buffer_size**变量定义的内存大小中，默认256K。

  3. 然后对其按照**Primary Key（RowID）**排序，然后使用排序好的数据进行**顺序回表**，由于InnoDB中叶子节点数据，是按照PRIMARY KEY（ROWID）进行顺序排列的，所以可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，是能够提升读性能的，为SQL查询语句带来极大的性能提升。

  4. MRR能够提升性能的核心在于，这条查询语句在索引上做的是一个**范围查询**，可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出**顺序性**的优势，所以MRR优化可用于被驱动表关联列为**range，ref，eq_ref**类型的查询。

  5. **开启mrr的参数**：optimizer_switch#mrr和optimizer_switch#mrr_cost_based选项。

     - **optimizer_switch#mrr选项**：表示是否开启MRR优化，默认为on。
     - **optimizer_switch#mrr_cost_based**：表示通过基于成本的算法，来确定是否需要开启MRR特性，默认为off。然而，在MySQL当前版本中，基于成本的算法过于保守，导致大部分情况下优化器都不会选择MRR特性。因为如果强制开启MRR，由于MRR需要排序，在某些SQL语句下，假如排序的时间超过直接扫描的时间，那么性能可能会变差。

     ```sql
     set optimizer_switch='mrr=on,mrr_cost_based=off';
     
     ```

     

  ![1631178784100](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631178784100.png)

- **执行过程**：

  1. 将驱动表中相关的列放入Join Buffer中。
  2. 批量地将Key（索引键值）发送到MRR接口。
  3. MRR接口通过收到的Key，**根据其对应的主键ID进行排序**，然后再进行数据的读取操作。
  4. 最后返回结果集给客户端。

  ![1631176759460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631176759460.png)

- **优点**：

  - 与INLJ不同的地方在于，BKA不是从驱动表一行一行地取出 Join条件值，再到被驱动表去做Join，而是从驱动表里**一次性拿出多行存到join_buffer**，然后再一起传给被驱动表。
  - 而这个join_buffer，在BNLJ算法里的作用是暂存驱动表的数据，但在NLJ算法里并没有用，而此时刚好可以**复用join_buffer**到BKA算法中。
  - 如果扫描被驱动表的是主键，那么被驱动表中的记录访问都是比较有序的；如果扫描被驱动表的是非覆盖二级索引，那么对于被驱动表中记录的访问可能就是非常离散的。
  - 因此，对于非覆盖二级索引的join联接，BKA算法会调用MRR接口，通过**对索引对应的主键ID进行排序**，使得该索引能够以**顺序的I/O**读取数据，而不是以随机I/O读取，从而提高Join的执行效率。

- **缺点**：

  - 由于BKA算法本质上是通过MRR接口，将非覆盖二级索引对于记录的访问，转化为根据主键ID排序的较为有序地获取记录，所以要想通过BKA算法来提高性能，需要确保联接列为被驱动表的**非覆盖二级索引**。

  - **BKA参数**：optimizer_switch#batched_key_access选项。

    - 由于BKA使用MRR，因此MRR标志也必须打开，但目前MRR的成本估算过于悲观，必须关闭mrr_cost_based才能使用BKA。

    ```sql
    SET optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
    
    ```

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ/BKA                     | BNLJ                                      |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         |

- **算法使用标记**：EXPLAIN#Extra值包含Using join buffer（Batched Key Access），且类型值为**ref或eq_ref**时，表示使用了BKA。

###### Classic Hash Join

Classic Hash Join，CHJ，Hash Join不需要任何索引，而是在Join Buffer中**创建散列表**，然后被驱动表通过哈希算法进行查找，使得能够在BNLJ算法的基础上，**进一步减少了被驱动表的比较次数**，从而提升JOIN的查询性能。

- **执行过程**：
  1. build阶段：CHJ的第一个阶段，先将驱动表中的数据放入Join Buffer中，然后根据键值产生一张散列表。
  2. probe阶段：CHJ的第二个阶段，随后读取被驱动表中的一条记录，对其应用散列函数，将其和散列表中的数据进行比较。

![1631179295488](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631179295488.png)

- **优点**：

  - 如果Join Buffer能够缓存所有驱动表的查询列，那么驱动表和被驱动表的扫描次数都将只有1次，并且比较的次数也只是被驱动表的记录数（假设哈希算法冲突为0时）；反之则需要扫描多次内部表。因此，为了使Classic Hash Join更有效果，应该规划好Join Buffer的大小。

  - 要使用Classic Hash Join算法，需要将join_cache_level设置为大于等于4的值，并显示地打开优化器的选项，设置过程如下：

    ```sql
    set join_cache_join=4;
    set optimizer_switch='join_cache_hashed=on';
    
    ```

- **缺点**：

  - Classic Hash Join算法虽好，但是仅能用于**等值联接**，对于非等值联接的JOIN查询，就会显得无能为力了。
  - **创建散列表也是费时的工作**，不过一旦建立完成后，就能大幅提升JOIN的速度，因此，在通常情况下，大表之间的JOIN，Hash Join算法会比较有优势；小表通过索引查询，利用BKA Join就已经能很好的完成查询。
  - 此外，Hash Join需要在MySQL 8.0.18才会有支持，业界中使用该版本的公司还是比较少的，所以在生产应用得可能并不多。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ/BKA                     | BNLJ                                      | CHJ                                       |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   | SN / I                                    |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         | 0                                         |

- **算法使用标记**：如果将Hash Join应用于Simple Nested-Loops Join中，则Explain#Extra列会显示BNLH；如果将Hash Join应用于Batched Key Access Join中，则Explain#Extra列会显示BKAH。

##### 优化方案

根据JOIN原理和每种JOIN的算法分析可得出，JOIN联接查询的成本开销占大头的是，**驱动表记录数 * 单次访问被驱动表的成本**，因此优化重点应该为这两个部分：

- **尽量减少驱动表的记录数**。
  - **小表驱动大表**：一般无需人工考虑，MySQL优化器会自动选择最优的执行方式，另外可以使用STRAIGHT_JOIN可以指定左右表顺序，使其不被优化器优化。
  - **尽量使用过滤条件先减少驱动表的记录数**：如果有where条件，应当要能够使用索引，并尽可能地减少驱动表的数据量。
- **对被驱动表的访问成本尽可能降低**。
  - **尽量在被驱动表的联接列上建立索引**：主键、唯一索引最优，其次是非唯一的二级索引，这样就可以使用eq_ref或ref的索引匹配类型来访问被驱动表，从而降低访问被驱动表的成本。
    - 注意，join字段的类型需要保持一致，以**避免索引失效**。
  - **合理设置join_buffer大小**：如果被驱动表的join字段用不了索引，且内存较为充足，可以考虑把join_buffer设置得大一些，以**减少被驱动表的扫描次数**，提高查询性能。
  - **尽量减少联接过程读取的总记录数**：经验之谈，如果能控制扫描驱动表和被驱动表的行数在**百万条以内**，效率还是可以接受的。
- **参与Join的表不要太多**：
  - 对于NLJ的算法实现，参与Join的驱动表越多，**循环嵌套也就越多**，导致访问被驱动表的次数也越多，性能自然就不会太高。
  - 再者，参与Join的表过多，会导致SQL变得复杂和臃肿，**不利于后期调优和维护**。
  - 在阿里变成规约中建议，**参与Join的表不能超过3张**，如果业务确实需要关联这么多表，可以抽取到应用层去实现，避免在SQL中Join过多的表。

#### GROUP BY优化

##### 执行过程分析

1. 如果group by和select字段都建立了索引，但不做任何优化，则会先扫描emp_no索引树上的每一个索引键。
2. 确定好emp_no后，再去扫描salary索引树的上每一个索引键，然后得出当前emp_no最小的salary。
3. 最后遍历每个emp_no的salary，得出最小的salary并返回。
4. 其中，如果group by和select字段没建立索引，则扫描的不是索引树，而是全表扫描。

```sql
/*
 * 分析这条SQL如何执行：
 * [emp_no, salary] 组合索引
 * [10001,50000]
 * [10001,51000]
 * ...
 * [10002,30000]
 * [10002,32000]
 * ...
 * 1. 先扫描emp_no = 10001的数据，并计算出最小的salary是多少，[10001,50000]
 * 2. 扫描emp_no = 10002，并计算出最小的salary是多少，[10002,30000]
 * 3. 遍历出每个员工的最小薪资，并返回
 */
 -- 查询每个员工拿到过的最少的工资是多少[比惨大会]
-- CREATE INDEX salaries_emp_no_salary_index ON salaries (emp_no, salary);
explain
select emp_no, min(salary)
from salaries
group by emp_no

```

##### 扫描模式

###### Loose Index Scan（松散索引扫描）

松散索引扫描，**无需扫描所有满足条件的索引键**，即可返回结果。

- **执行过程**：

  1. 在确定好emp_no后，由于此时salary索引是有序的，所以第一个salary正式当前emp_no最小的salary，因此，会直接返回第一个salary，跳过后面的salary索引树扫描。
  2. 接着继续遍历下一个emp_no，同样也是取第一个salary...
  3. 最后遍历每个emp_no的salary，得出最小的salary并返回。

- **特点**：

  - **性能最好**：由于索引树是有序的，获取MIN（）时，只需返回第一个索引即可，无需扫描所有满足条件的索引键，**性能最好**。
  - **标志**：Explain#Extra会显示Using index for group-by。

- **使用条件**：

  1. **查询作用在单张表上**：
     - 因为如果作用在多张表上，可能需要扫描整个索引树。
  2. **GROUP BY关键字都要符合最左前缀原则**：
     - 因为如果不符合最左前缀原则，会导致复合索引的索引失效，此时可能会全表扫描。
  3. **聚合函数只支持MIN（）和MAX（）**：
     - 由于其他聚合函数需要扫描所有索引键，因此只支持MIN（）和MAX（）。
     - 且如果MIN（）和MAX（）同时在一条SQL中使用，则必须作用在同一个字段，才能走松散索引扫描。
     - 且MIN（）和MAX（）的字段必须也符合最左前缀原则，保证索引不失效。
     - 另外，当查询中不存在GROUP BY和DISTINCT语句时，AVG（DISTINCT 单个参数）、SUM（DISTINCT 单个参数）、COUNT（DISTINCT 多个参数） 也可以使用松散索引扫描。
  4. **SELECT字段必须为GROUP BY关键字或者常量**：
     - 因为如果SELECT字段为非GROUP BY关键字、非常量，可能会导致回表查询（最左前缀索引等值查询除外），不符合松散索引扫描原则。
  5. **索引不能为前缀索引**：
     - 因为使用前缀索引无法让GROUP BY正常工作。

- **适用场景举例**：假设index（c1，c2，c3）作用在t1（c1，c2，c3，c4）表上。

  ```sql
  -- 符合最左前缀原则
  SELECT c1，c2 FROM t1 GROUP BY c1，c2；
  
  -- 等价与GROUP BY c1，c2，只不过DISTINCT取的是分组后的一条数据
  SELECT DISTINCT c1，c2 FROM t1；
  
  -- 聚合函数 + DISTINCT + 非GROUP BY和DISTINCT条件时，也可以走松散索引扫描
  SELECT COUNT(DISTINCT c1)，SUM(DISTINCT) FROM t1；
  SELECT COUNT(DISTINCT c1，c2)，COUNT(DISTINCT c2，c1) FROM t1；
  
  -- 符合最左前缀原则 + MIN（）
  SELECT c1，MIN（c2） FROM t1 GROUP BY c1；
  
  -- 范围查询 + 符合最左前缀原则
  SELECT c1，c2 FROM t1 WHERE c1 < const GROUP BY c1，c2；
  
  -- 范围查询 + 符合最左前缀原则
  SELECT c2 FROM t1 WHERE c1 < const GROUP BY c1，c2；
  
  -- 范围查询 + 符合最左前缀原则 + MIN（）& MAX（）作用在同一个字段上
  SELECT MAX（c3），MIN（c3），c1，c2 FROM t1 WHERE c2 > const GROUP BY c1，c2；
  
  -- 符合最左前缀原则 + 最左前缀索引等值查询
  SELECT c1，c2 FROM t1 WHERE c3 = const GROUP BY c1，c2；
  
  ```

- **不适用场景举例**：假设index（c1，c2，c3）作用在t1（c1，c2，c3，c4）表上。

  ```sql
  -- 聚合函数不是MIN（）或MAX（）
  SELECT c1，SUM（c2） FROM t1 GROUP BY c1；
  
  -- 不符合最左前缀原则
  SELECT c1，c2 FROM t1 GROUP BY c2，c3；
  
  -- SELECT查询了非GROUP BY关键字、非常量，且c3最左前缀索引没作等值查询
  SELECT c1，c3 FROM t1 GROUP BY c1，c2；
  -- => 改成下面语句，则可以走松散索引扫描
  -- 符合最左前缀原则 + 最左前缀索引等值查询
  -- SELECT c1，c2 FROM t1 WHERE c3 = const GROUP BY c1，c2；
  
  ```

###### Tight index Scan（紧凑索引扫描）

紧凑索引扫描，**需要扫描所有满足条件的索引键**，才可返回结果，如果一条SQL无法使用松散索引扫描，则会尝试使用紧凑索引扫描。

- **特点**：

  - **性能次好**：由于需要扫描整个索引树，因此，性能会比松散索引扫描差一些，不过还是可以接受的。
  - **标志**：Explain#Extra会显示Using index，表示覆盖索引，扫描了整个索引树。

- **适用场景举例**：

  ```sql
  -- 紧凑索引扫描，虽然emp_no和salary有索引，但使用了SUM聚合函数，需要遍历整个salary索引树
  -- CREATE INDEX salaries_emp_no_salary_index ON salaries (emp_no, salary);
  explain
  select emp_no, sum(salary)
  from salaries
  group by emp_no;
  
  ```

###### Temporary table（临时表）

当紧凑索引扫描也无法使用的话，MySQL会读取需要的数据，**创建一个临时表**，用临时表实现GROUP BY操作。

- **特点**：

  - **性能最差**：因为走了全表扫描以及创建了一个临时表。
  - **标志**：Explain#Extra会显示Using temporary，表示使用了临时表。

- **场景举例**：

  ```sql
  -- 出现临时表，hire_date没有索引
  explain
  select max(hire_date)
  from employees
  group by hire_date;
  
  ```

###### 扫描模式总结

| 扫描模式                         | 使用规则                             | Extra标识                | 性能 |
| -------------------------------- | ------------------------------------ | ------------------------ | ---- |
| Loose Index Scan（松散索引扫描） | 优先尝试使用                         | Using index for group-by | 最好 |
| Tight index Scan（紧凑索引扫描） | 使用不了松散索引扫描时，才会尝试使用 | Using index              | 次好 |
| Temporary table（临时表）        | 使用不了紧凑索引扫描时，才会使用     | Using temporary          | 最差 |

##### 优化方案

如果GROUP BY使用了临时表，则要想办法**走上索引**，即用上松散索引扫描，或者紧凑索引扫描，尽量避免临时表。

#### DISTINCT优化

- **原理**：DSITINCT本质上是在GROUP BY操作之后，**每组只取1条数据**。
- **优化方案**：和GROUP BY思路一样，如果使用了临时表，则要想办法**走上索引**，即用上松散索引扫描，或者紧凑索引扫描，尽量避免临时表。

#### ORDER BY优化

##### 索引使用规律

###### 全表扫描 VS 索引排序

|          | 场景                                | 标志                                   |
| -------- | ----------------------------------- | -------------------------------------- |
| 全表扫描 | 当MySQL优化器发现全表扫描开销更低时 | 此时Explain#Extra会显示Using File Sort |
| 索引排序 | 当MySQL优化器发现走索引开销更低时   | 此时Explain#Extra没有Using File Sort   |

###### 单列索引+范围查询

- **排序情况**：可以使用索引避免排序。
- **原理**：单列索引first_name是有序的，即使做了范围查询，也是可以利用索引避免排序的。

```sql
explain
select *
from employees
where first_name < 'Bader'
order by first_name;

```

###### 联合索引+等值查询

- **排序情况**：可以使用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name等值结果中的last_name是有序的，因此可以利用索引的有序性。

```sql
explain
select *
from employees
where first_name = 'Bader'
order by last_name;

```

###### 联合索引+范围查询

- **排序情况**：无法利用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name非等值结果集中，last_name是无序的，因此无法利用索引避免排序。

```sql
explain
select *
from employees
where first_name < 'Bader'
order by first_name;

```

###### 升降序不一致

- **排序情况**：无法利用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name等值结果中的last_name只是顺序的，如果再对last_name做反向排序，则利用不了last_name的有序性，因此无法利用索引避免排序。

```sql
explain
select *
from employees
order by first_name desc, last_name asc
limit 10;

```

###### 排序字段存在多个索引中

- **排序情况**：无法利用索引避免排序。
- **原理**：
  1. 虽然first_name和emp_no分别是普通索引和主键索引，它们都是有序的。
  2. 但如果先对first_name做排序再对主键做排序，由于普通索引是非聚蔟索引，会先去找主键，然后把找到的主键集做排序。
  3. 而在这种情况下，是不能保证这些主键集的有序性的，因此无法利用索引避免排序。

```sql
-- emp_no为主键
explain
select *
from employees
order by first_name, emp_no
limit 10;

```

##### 排序模式

Using File Sort，共有三种排序模式：

###### rowid排序（常规排序）

- **执行过程**：
  1. 从表中获取满足WHERE条件的记录。
  2. 对于每条记录，将记录的主键及排序键（id，order_column）取出来，放入sort buffer（排序缓存，由**sort_buffer_size**控制）。
  3. 如果sort  buffer能存放所有满足条件的（id，order_column），则直接在sort buffer内存中进行排序；否则，会进行多次sort buffer排序，并在每次在sort buffer满后，把排序后的结果写到**临时文件**中。
     - 这里sort buffer排序算法用的是，**快速排序**算法，O（n * logn）。
  4. 如果sort buffer排序后，产生了临时文件，则还需要对其使用**归并排序算法**，来保证记录是有序的。
  5. 循环执行上述过程，直到所有满足条件的路基全部参与排序。
  6. 扫描排好序的（id，order_column），并**使用id**去获得SELECT语句中其他需要返回的字段。
  7. 返回结果集。
- **特点**：
  - **可能会产生临时文件**：需要看sort buffer能否存放WHERE里面的所有（id，order_column），如果不满足，则会产生临时文件。
  - **一次排序需要两次I/O**：
    1. 第一次I/O发生在第2步，将（id，order_column）读取出来放入sort buffer中，且如果sort buffer满后，还会写出到临时文件中
    2. 第二次I/O发生在第6步，当（id，order_column）排序好后，需要根据主键ID获取其他字段，由于其结果是按照order_column进行排序的，只能保证order_column是顺序的，并不能保证主键ID的有序性，因此会存在随机I/O的问题。
       - **解决方案**：MySQL内部针对这种情况做了优化，在使用主键ID去获取数据之前，先对主键ID排好序并放入一个缓存里面，其大小由**read_md_buffer_size**控制（即MRR接口），默认256K，接着再去获取记录，从而把随机I/O转换为顺序I/O。

###### additional_fields排序（全字段排序）

- **执行过程**：
  1. 与rowid排序（常规排序）执行过程类似，不过排序的字段不仅仅只有（id，order_column），而是该SQL中**所有需要的字段都**会放入到sort buffer中参与排序。
  2. 由于sort buffer已经包含了查询需要的所有字段，因此，在sort buffer中排序完成后，即可直接返回。
- **优点**：排序完成后即可直接返回，无需两次I/O，从而获得了性能的提升。
- **缺点**：
  - 由于所有字段都参与排序，所以一行数据占用的空间会比rowid排序的多。
  - 如果sort buffer设置的比较小（默认256K），由于排序的字段多，在排序时会容易占满sort buffer，从而导致产生临时文件，而发生了写临时文件+归并排序，性能下降。
- **使用场景**：当order by中出现的**字段总长度小于max_length_for_sort_data**时，MySQL会使用全字段排序；否则，MySQL会使用rowid排序。

###### packed_additional_fields排序（打包字段排序）

- **执行过程**：
  1. 与全字段排序的工作原理一样，也是将所有需要的字段都放入到sort buffer中参与排序。
  2. 不同的地方在于，打包字段排序，会将**字段紧密地排列**在一起，而不是使用固定长度空间（字段总长度）。
     - 比如VARCHAR（255）"yes"字段，使用全字段排序会占用255字节的sort buffer，而使用打包字段排序则只占用2+3字节的sort buffer。
- **优点**：由于字段会紧密排列，一个sort buffer可以容纳下更多的字节，从而减少写临时文件的发生，减少性能下降的概率。

###### 排序与OPTIMIZER_TRACE

```json
    {
      # 3. 执行阶段的执行过程
      "join_execution": {
        "select#": 1,
        "steps": [
          {
            # 排序后特有的内容
            "sorting_table": "employees",
            "filesort_information": [
              {
                "direction": "asc",
                "expression": "`employees`.`last_name`"
              }
            ] /* filesort_information */,
            "filesort_priority_queue_optimization": {
              "limit": 502,
              "chosen": true
            } /* filesort_priority_queue_optimization */,
            "filesort_execution": [
            ] /* filesort_execution */,
            # 重点关注 filesort_summary
            "filesort_summary": {
              # 可用内存, 其实就是sort_buffer_size => 默认256k
              "memory_available": 262144,
              "key_size": 264,
              "row_size": 401,
              "max_rows_per_buffer": 503,
              "num_rows_estimate": 45208,
              # 本次排序一共参与排序的行数
              "num_rows_found": 22287,
              # 本次排序产生了几个临时文件, 0则代表是完全基于内存排序
              "num_initial_chunks_spilled_to_disk": 0,
              "peak_memory_used": 205727,
              "sort_algorithm": "std::sort",
              "unpacked_addon_fields": "using_priority_queue",
              # 使用的排序模式: 这里全字段排序 => rowid、additional_fields、packed_additional_fields
              "sort_mode": "<varlen_sort_key, additional_fields>"
            } /* filesort_summary */
          }
        ] /* steps */
      } /* join_execution */
    }

```

###### 排序模式总结

| 变量                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| sort_buffer_size         | 指定sort_buffer的大小                                        |
| read_rnd_buffer_size     | 默认256K，MRR接口主键ID排序后的缓存区大小                    |
| max_sort_length          | 指定排序时，排序字段最多取多少字节                           |
| max_length_for_sort_data | 当order by中出现的**字段总长度小于max_length_for_sort_data**时，MySQL会使用全字段排序；否则，MySQL会使用rowid排序。 |

##### 优化方案

- **使用索引**：最好的做法是，利用索引的有序性，让MySQL跳过filesort排序过程，以避免排序。
- **优化filesort**：如果发生了filesort，并且没有办法避免时，则需要想办法优化filesort。
  - **调大sort_buffer_size**：设置较大的sort buffer，可以减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
    - 当OPTIMIZER_TRACE#filesort_summary#**num_initial_chunks_spilled_to_disk**过大时，说明产生的临时文件过多，归并次数也就越多，此时可以调大sort buffer，以减少临时文件的产生，提升性能。
  - **调大read_rnd_buffer_size**：设置较大的MRR排序缓存区，可以接收更多来自MRR接口排序好的主键ID，从而让一次顺序I/O返回更多的结果。
  - **调小max_sort_length**：如果排序字段超长，减少取值的字段长度，可以减少sort buffer的占用，减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
  - **设置合理的max_length_for_sort_data**：一般不建议随意调整。
    - 如果设置得过大，MySQL则会认为有足够的缓存容纳全部字段，使得各种排序SQL都走上全字段排序，从而导致**大量的内存占用**，当还发生写临时文件时，又会**占用大量的硬盘**。
    - 如果设置得太小，MySQL则会认为没有足够的缓存容纳全部字段，使得各种排序SQL都走上rowid排序，由于rowid排序需要走上两次I/O，并且会有随机I/O的发生，所以导致**各种排序SQL性能都比较低下**。

#### LIMIT优化

##### 用法

limit offset, size：

- **offset**：返回结果第一行的偏移量，即想要跳过多少行。
- **size**：指定返回多少条记录。

##### 优化需求

当offset过大时，会导致MySQL先扫描offset条行数据，从而可能使MySQL走向**全表扫描**。

```sql
-- 查询第30001页的时候，花费174ms
explain
select *
from employees
limit 300000,10;

```

##### 优化方案

###### 使用覆盖索引

可在只返回索引字段的场合下，让全表扫描ALL提升到**全索引树扫描Index**。

- **缺点**：只能返回单个字段。

```sql
-- 方案1：覆盖索引 (108ms)
explain
select emp_no
from employees
limit 300000,10;

```

###### 使用覆盖索引+Join

这种方式会先走一次方案1，不过由于方案一为全索引数扫描Index，满足了BNLJ的使用场景，因此可以使用覆盖索引 + Join的方式，来获取深度分页的**全字段查询结果**。

- **分析**：此时联接算法为**BNLJ**，由于t比较小，MySQL会使用t为驱动表，然后把t的查询结果存进join_buffer，接着e表一次性将join_buffer的结果进行匹配，由于联接字段是e的覆盖索引，可以在索引树上直接返回，不会产生大量的随机I/O，因此这种优化方式还是可以接受的。

```sql
-- 方案2：覆盖索引+join(109ms)
select *
from employees e
         inner join
     (select emp_no from employees limit 300000,10) t
     using (emp_no);

```

###### 覆盖索引+子查询

这种方式也是先需要走一次方案1，先查询达到深度分页最小的emp_no，再利用索引的有序性，往后再找10条记录。

- **分析**：利用了索引的有序性。

```sql
-- 方案3：覆盖索引+子查询（126ms）
select *
from employees
where emp_no >=
      (select emp_no from employees limit 300000,1)
limit 10;

```

###### 范围查询

- **优点**：扫描的行数永远只有10行，性能次优。
- **缺点**：需要先获取上一页最大的emp_no。

```sql
select *
from employees
where emp_no > #{last_max_emp_no}
limit 10;

```

###### 起始主键值 + 结束主键值

- **优点**：扫描的行数永远只有10行，且只在主键索引上查询，性能最优。
- **缺点**：需要先获取上一页最后一行的主键值。

```sql
-- 方案5：如果能获得起始主键值 & 结束主键值
select *
from employees
where emp_no between 20000 and 20010;

```

###### 禁止传入过大的页码

从业务的角度解决深度分页问题，比如百度搜索最多只显示76页的结果。

- **缺点**：需要业务的妥协。

#### COUNT优化

##### MySQL#count（？）区别

如果没有特殊要求，一般建议使用count（*）就好。

| 形式              | 性能上的区别                                                 | 业务上的区别                                   |
| ----------------- | ------------------------------------------------------------ | ---------------------------------------------- |
| count（业务字段） | 如果该字段存在索引，则会走上索引；否则只能全表扫描           | 只会对该字段进行统计，会排除字段值为NULL的行   |
| count（*）        | 与count（1）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键；InnDB >= 8.0.13，对于无条件count（*）做了优化 | 与count（1）没有区别，不会排除字段值为NULL的行 |
| count（1）        | 与count（*）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键 | 与count（*）没有区别，不会排除字段值为NULL的行 |

##### MySQL#count（*）索引选择规律

1. 当没有非主键索引时，会使用主键索引。eg：PRIMARY => ken_len: 4。
2. 如果存在非主键索引的话，会使用非主键索引。eg：user_test_count_email_index => ken_len: 243。
3. 如果存在多个非主键索引，会使用一个最小的非主键索引。eg：user_test_count_birthday_index => ken_len: 4。

##### MySQL#count（*）索引选择原理

1. InnoDB的非主键索引叶子结点存储的是索引 + 主键，而主键索引存储的是主键+表数据。
2. 在MySQL#count时，如果使用非主键索引，可以比使用主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。
3. 同理，在MySQL#count时，如果使用key_len小的非主键索引，可以比使用key_len大的非主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。

##### 优化方案

目的是减少count查询的性能开销。

###### 升级MySQL版本

InnDB >= 8.0.13，对于无条件count（*）做了优化，性能提升比较大。

- **缺点**：实际项目用的很少，一般不会升级MySQL版本。

###### 更换MyISAM引擎

把数据库引擎换成MyISAM，由于MyISAM引擎的表数据不存在索引树上，在遇到没有条件的count查询会直接返回结果。

- **缺点**：实际项目用的很少，一般不会修改数据库引擎。

###### 创建更小的非主键索引

- **缺点**：提升并不大。

###### 建立汇总表

分别记录每张业务表的表名以及表数量，当业务表发生变化时，更新汇总表，也可以使用触发器去维护汇总表。

- **优点**：结果比较准确、用法比较灵活。
- **缺点**：增加了维护的成本。

###### 使用sql_calc_found_rows

在做完limit语句后，紧跟found_rows()语句获取分页时sql_calc_found_rows统计的结果。

- **缺点**：需要分页；mysql 8.0.17已经废弃这种用法，且未来会被删除。
- **注意点**：需要在MYSQL终端执行，IDEA无法正常返回结果。

```sql
-- 在做完本条查询之后，自动地去执行COUNT
select sql_calc_found_rows * from salaries limit 0,10;
select found_rows() as salary_count;

```

###### 缓存+定时更新

使用定时器定时统计结果到缓存中。

- **优点**：性能比较高；结果比较准确，有误差但是比较小，除非在缓存更新的期间，新增或者删除了大量数据，这时无差才会比较大。
- **缺点**：引入了额外的组件，增加了架构的复杂度。

###### information_schema.tables

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
-- 方案6：information_schema.tables
select *
from `information_schema`.TABLES
where TABLE_SCHEMA = 'employees' and TABLE_NAME = 'salaries';

```

###### show table status

优缺点同information_schema.tables。

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
show table status where Name = 'salaries';

```

###### explain

优缺点同information_schema.tables。

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
explain select * from salaries;

```

###### 反向查询

如果反向查询能够减少扫描的行数的话，可以考虑进行反向查询。

- **缺点**：针对的只是**特殊场合**下的范围统计查询。

```sql
select count(*) from salaries where emp_no > 10010;
-- 等价于 => 逆向查询
select count(*) - (select count(*) from salaries where emp_no <= 10010) from salaries;

```

#### 表结构优化

##### 数据库三范式

###### 第一范式（1NF）

- **概念**：
  - 字段具有**原子性**，即数据库表的每一个字段都是不可分割的原子数据项，不能是集合、数组、记录等非原子数据项。
  - 当实体中的某个属性有多个值时，必须拆分为不同的属性。
- **好处**：在统计比如address字段时，如果满足1NF的话，更加容易统计出省、市和具体地址的个数，粒度更细，字段具有原子性。
- **解决方案**：如果需要让表符合1NF，可以通过**拆字段**的方式来实现。

![1631344696874](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631344696874.png)

###### 第二范式（2NF）

- **概念**：在满足1NF的基础上，要求表中每一行数据具有**唯一性**，并且非主键字段完全依赖主键字段。
- **好处**：消除了部分依赖，每个非主键属性必须完全依赖于主键。
- **解决方案**：如果需要让表符合2NF，可以通过**垂直拆表**的方式来实现。

![1631345460201](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345460201.png)

![1631345039416](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345039416.png)

###### 第三范式（3NF）

- **概念**：在满足2NF的基础上，表中字段不能存在传递依赖。
- **好处**：消除了传递依赖。
- **解决方案**：如果需要让表符合3NF，可以通过**垂直拆表**的方式来实现。

![1631345416769](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345416769.png)

![1631345387480](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345387480.png)

###### 反模式设计

- **概念**：出于性能的考虑，可以打破三范式的约束，将某些字段冗余起来，减少表之间的关联以提升查询效率。
- **好处**：灵活、不需要联表、性能较好。

![1631346021073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631346021073.png)

##### 表设计原则

1. **字段应少而精**，建议20个以内（经验之谈） ，超过后可以拆分出去。
   - 把常用的字段放到一起。
   - 把不常用的字段独立出去。
   - 大字段（TEXT/BLOB/CLOB等）独立出去。
2. **尽量使用小型字段**。
   - 比如ip可以用int类型存储，而不是varchar类型，这样可以节省空间和提高性能。
3. **避免使用允许为NULL的字段**。
   - MySQL官方建议把字段设置为非NULL，因为允许为NULL的字段很难做查询优化，且索引需要额外的空间。
4. **合理平衡范式和冗余**。
   - 一般情况下都是要遵守三范式的，但必要时可以进行反模式设计，以提高查询效率。
5. 如果表数据量非常大，可以考虑**分库分表**。
6. 其他的量化建议：
   - 单表不超过40列。
   - 单表索引不超过5个。
   - 单表不超过500w数据。
   - 单库不超过200张表。

#### SQL语句优化建议总结

##### 避免使用子查询

```sql
-- 子查询在MySQL5.5版本里，内部执行计划器是先查外表再匹配内表，而不是先查内表t2，所以，当外表的数据很大时，查询速度会非常慢。
SELECT * FROM t1 WHERE id (SELECT id FROM t2 WHERE name='hechunyang');

-- 而在MariaDB10/MySQL5.6版本里，采用了Join关联方式对其进行了优化，该SQL会自动转换为：
-- SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id；
-- 而JOIN语句会被MySQL优化器使用对应的Join算法优化，此时，相对于原本的子查询来说，有了一定的性能提升

-- 但还要注意的是：这种优化只针对SELECT有效，对UPDATE/DELETE的子查询是无效的，因此，生产环境应避免使用子查询！

```

##### 避免函数索引

```sql
-- 低效查询，MySQL不像Oracle那样支持函数索引，即使d字段有索引，也会直接全表扫描
SELECT * FROM t WHERE YEAR(d) >= 2016;

-- 高效查询，MySQL索引项不适用函数，避免索引失效
SELECT * FROM t WHERE d >= '2016-01-01'；

```

##### 使用IN来替换OR

```sql
-- 低效查询，回表3次
SELECT * FROM t WHERE LOC_ID = 10 OR LOC_ID = 20 OR LOC_ID = 30;

-- 高效查询，MRR接口优化
SELECT * FROM t WHERE LOC_IN IN (10,20,30);

```

##### LIKE双百分号无法使用到索引

```sql
-- 低效查询，索引失效
SELECT * FROM t WHERE name LIKE '%de%';

-- 高效查询，索引不失效
SELECT * FROM t WHERE name LIKE 'de%';

```

##### 使用LIMIT读取适当的记录

```sql
-- 低效查询，查询所有记录
SELECT * FROM t WHERE 1;

-- 低效查询，只查询10条记录
SELECT * FROM t WHERE 1 LIMIT 10;

```

##### 避免数据类型不一致

```sql
-- 低效查询，索引失效
SELECT * FROM t WHERE id = '19';

-- 高效查询，索引不失效
SELECT * FROM t WHERE id = 19;

```

##### 减少GROUP BY多余的排序

```sql
-- 低效查询，GROUP BY会对goods_id进行排序，因为只是想看统计结果而已，没必要排序
SELECT goods_id,count(*) FROM t GROUP BY goods_id;

-- 高效查询，使用ORDER BY NULL来禁止GROUP BY排序，避免排序结果的消耗
SELECT goods_id,count(*) FROM t GROUP BY goods_id ORDER BY NULL;

```

##### 禁止不必要的ORDER BY排序

```sql
-- 低效查询，因为只是想看统计结果而已，没必要排序
SELECT count(1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id WHERE 1 = 1 
ORDER BY u.create_time DESC;

-- 高效查询，禁止不必要的ORDER BY排序
SELECT count(1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id;

```

### 3.6. MySQL主从复制？

#### 概念

- **原理**：把主节点的binlog日志，复制到从节点上执行一遍，从而达到主从数据一致的状态。

- **过程**：

  1. 主节点**binlog线程**，在每个事务更新数据完成之前，将该操作记录串行地写入到自己的binlog文件中。
     - **bin log**：主库的二进制日志。
  2. 在start slave开启主从同步后，从节点**I/O线程**，负责从master上拉取binlog内容，放在自己的relay log（中继日志）中，如果从节点读取的进度已经跟上了master，则会进入睡眠状态，并等待master产生新的事件。
     - **relay log**：从库的中继日志。
  3. 从节点另外开启一个**SQL线程**，把relay log中的语句，在自身机器上执行一遍，从而达到主从数据一致的状态。

  ![1631410904850](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631410904850.png)

- **优点**：

  - **数据分布**：可以作为**备用数据库**，避免单点故障。
  - **负载均衡**：可以做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证**数据的一致性**。

- **开启主从配置**：

  ```sql
  -- 1. 修改主节点的/etc/my.cnf
  log-bin=imooc_mysql
  server-id=1
  
  -- 2. 编辑从节点的/etc/my.cnf
  server-id=2
  
  -- 3. 主节点创建备份账号
  mysql> CREATE USER 'repl'@'%' IDENTIFIED BY 'password'; 
  mysql> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
  
  -- 4. 主节点表加读锁，阻止写入
  mysql> FLUSH TABLES WITH READ LOCK;
  
  -- 5. 主节点查看bin-log状态
  mysql > SHOW MASTER STATUS;
  
  -- 6. 主节点dump所有数据，用于初始化从节点
  mysqldump --all-databases --master-data > dbdump.db -uroot -p
  
  -- 7. 主节点解锁，允许写入
  mysql> UNLOCK TABLES;
  
  -- 8. 从节点导入主节点dump出来的数据
  mysql < aa.db -uroot -p
  
  -- 9. 从节点配置主从连接信息
  mysql> CHANGE MASTER TO
      -- 主节点地址
  	-> MASTER_HOST='master_host_name',
  	-- 主节点端口
  	-> MASTER_PORT=port_num
      -- 备份账户用户名
  	-> MASTER_USER='replication_user_name', 
  	-- 备份账户密码
  	-> MASTER_PASSWORD='replication_password', 	
      -- bin-log文件名
  	-> MASTER_LOG_FILE='recorded_log_file_name',
      -- bin-log位置
      -> MASTER_LOG_POS=recorded_log_position;
  
  -- 10. 从节点开启主从同步
  mysql> START SLAVE;
  
  -- 11. 主节点查看从节点状态
  show slave status;
  
  ```

#### bin log日志格式

- **三种日志格式**：statement、row、mixed。

  - **statement**：基于SQL语句的复制模式，每一条会修改数据的SQL都会记录在binlog中。
    - **优点**：不需要记录每一行的变化，减少了binlog日志量，**节约IO**，提高性能。
    - **缺点**：
      - 由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此，还必须记录每条语句在执行的时候的**一些相关信息**，以保证所有语句能让slave执行出**在master端执行时相同的结果**。
      - 像一些特定函数功能，slave可与master上要保持一致，则会有很多相关问题，比如sleep()， last_insert_id()，user-defined functions(udf)等，都可能会出现问题，**导致数据不一致**。
  - **row**：基于行的复制模式，不记录sql语句上下文相关信息，仅保存哪条记录被修改。
    - **优点**：**更能保证主从库数据的一致性**，因为row level的日志内容会非常清楚的记录下每一行数据修改的细节，而且不会出现某些特定情况下的存储过程、function、trigger的调用以及触发无法等无法被正确复制的问题。
    - **缺点**：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生**大量日志内容**，从而导致**从库延迟变大**。
  - **mixed**：基于SQL语句和行的混合复制模式，根据语句来选用是statement还是row模式。
    - 一般的语句修改使用statment格式保存binlog。
    - 而对于一些函数，statement无法完成主从复制的操作时，则采用row格式保存binlog。

- **应用场景**：

  - Mysql默认是使用statement日志格式，推荐使用mixed。
  - 而对于一些特殊使用，可以考虑使用row，比如自己通过binlog日志来同步数据的修改，使用row会节省很多相关操作。

- **配置方式**：

  ```sql
  -- 修改主节点的/etc/my.cnf
  -- binlog日志名称
  log_bin = mysql-bin.log
  -- binlog日志格式
  binlog_format = MIXED
  -- binlog过期时间
  expire_logs_days = 7
  -- binlog文件大小
  max_binlog_size = 100m
  
  ```

#### 主从复制模式

- **异步复制**：Asynchronous replication，MySQL默认的复制即是异步，主库在执行完客户端提交的事务后会**立即将结果返回**给给客户端，并不关心从库是否已经接收并处理。
  - **缺点**：主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时强行将从提升为主，可能导致新主上的数据不完整，从而导致数据的不一致。
- **全同步复制**：Fully synchronous replication，指当主库执行完一个事务，**所有的从库**都执行了该事务才返回给客户端。
  - **缺点**：由于需要等待所有从库执行完该事务才能返回，所以全同步复制的**性能必然会收到严重的影响**。
- **半同步复制**：Semisynchronous replication，介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待**至少一个**从库接收到并写到relay log中才返回给客户端。
  - **优点**：相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间，所以，半同步复制最好在**低延时**的网络中使用。

#### 数据一致性问题

- **原因**：
  1. **人为**：人为地在从库写入，导致从库与主库的数据不一致。
  2. **bin log格式**：使用了statement的bin log格式，某些特定函数功能在复制过程中出现问题，导致数据的不一致。
  3. **异常**：主从复制过程中，主库异常宕机了，数据还没及时同步到从库，主从切换导致的数据不一致。
  4. **延时**：主从复制有延时，如果在这个延时期间，应用程序读取从库，可能读到与主库不一致的数据。
- **解决方案**：
  1. **从库只读**：设置从库为只读模式。
  2. **row/mixed**：使用row或者mixed的复制模式。
  3. **非异步复制**：使用全同步复制，或者MySQL 5.7半同步复制。
  4. **缓存写key法**：在缓存中记录哪些行发生过写的操作，来路由到底读主库，还是读从库。
  5. **定期校验**：引入定期的主从数据校验，保证数据一致性。
- **数据强一致架构方案**：

##### SAN共享存储

![1631430708683](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430708683.png)

- **特点**：使用共享存储，MySQL服务器能够正常挂载文件系统并操作，如果主库发生宕机，备库可以挂载相同的文件系统，保证主库和备库使用相同的数据。
- **优点**：保证数据的强一致性，不会因为MySQL的逻辑错误发生数据不一致的情况。
- **缺点**：价格昂贵，且需要考虑共享存储的高可用。

##### DRBD磁盘复制

![1631430728718](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430728718.png)

- **特点**：当本地主机出现问题，远程主机上还保留着一份相同的数据，可以继续使用，保证了数据的安全。
  - DRBD是一种**基于软件、基于网络**的块复制存储解决方案，是linux内核模块实现的快级别的同步复制技术，可以与SAN达到相同的共享存储效果，主要用于对服务器之间的磁盘、分区、逻辑卷等进行数据镜像。当用户将数据写入本地磁盘时，还会将数据发送到网络中另一台主机的磁盘上，这样的本地主机(主节点)与远程主机(备节点)的数据就可以保证实时同步。
- **优点**：保证数据的强一致性，且相比于SAN储存网络，价格低廉。
- **缺点**：对io性能影响较大，且从库不提供读操作，造成服务器资源浪费。

##### 分布式协议方案 - MySQL Cluster

分布式协议可以很好解决**数据一致性**问题，比如Paxos、Raft、2PC算法等等，一系列成熟的产品如PhxSQL、MariaDB Galera Cluster、Percona XtraDB Cluster等越来越多的被大规模使用。

![1631430373534](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430373534.png)

- **特点**：MySQL Cluster是官方集群的部署方案，通过使用**NDB存储引擎**实时备份冗余数据，实现数据库的高可用性和数据一致性。
- **优点**：保证数据的强一致性，且全部使用官方组件，不依赖于第三方软件。
- **缺点**：配置较复杂，需要使用NDB储存引擎，与MySQL常规引擎存在一定差异，且**国内使用的较少**。

##### 分布式协议方案 - Galera

![1631430780963](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430780963.png)

- **特点**：基于Galera的MySQL高可用集群，是多主数据同步的MySQL集群解决方案，使用简单，没有单点故障，可用性高。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性。
  - 有自动故障转移功能，能够自动添加、剔除节点。
  - 有成熟的社区，有互联网公司在大规模的使用。
- **缺点**：需要为原生MySQL节点打wsrep补丁，且只支持InnoDB储存引擎。

##### 分布式协议方案 - PAXOS

![1631430935520](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430935520.png)

- **特点**：Paxos算法解决的问题是一个分布式系统如何就某个值（决议）达成一致，被认为是同类算法中**最有效**的，与MySQL相结合可以实现在分布式的MySQL数据的强一致性。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性；
  - 有自动故障转移功能，能够自动添加、剔除节点。
  - 也有成熟理论基础。
- **缺点**：只支持InnoDB储存引擎。

#### 高可用架构

在考虑MySQL数据库的高可用架构时，主要考虑以下方面：

- **可用性**：如果数据库发生了宕机或者意外中断等故障，能尽快恢复数据库的可用性，尽可能的减少停机时间，保证业务不会因为数据库的故障而中断。
- **数据一致性**：
  - 用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。
  - 当业务发生数据库切换时，切换前后的数据库内容应当一致，不会因为数据缺失或者数据不一致而影响业务。

常见的MySQL高可用方案有：

##### 双机高可用 | 主备

![1631430437735](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430437735.png)

- **特点**：
  1. A作为主库，负责读和写，B库作为备用库。
  2. A库故障后，B升级为主库，负责读写，A库作为备用库。
- **开发说明**：
  - 数据源配置中的数据库IP地址，采用虚拟的VIP地址，VIP由两台数据库机器上的keepalive配置，并互相检测心跳，当其中一台故障后，VIP自动漂移到另外一台正常的库上。
  - 数据库的主备配置、故障排除和数据补全，需要DBA和运维人员来维护，而程序代码或配置并不需要修改。
- **优点**：
  - 双节点，需求资源少，部署简单。
  - 架构比较简单，使用原生**半同步复制**作为数据同步的依据。
  - 保证可用性，一个机器故障了可以自动切换，没有主机宕机后的选主问题，直接切换即可。
- **缺点**：
  - 需要额外考虑haproxy、keepalived的高可用机制。
  - 完全依赖于**半同步复制**，如果半同步复制退化为异步复制，**数据一致性无法得到保证**。
    - 半同步复制机制是可靠的，如果半同步复制一直是生效的，那么便可以认为数据是一致的。
    - 但是如果由于**网络波动**等一些客观原因，导致半同步复制发生超时而切换为异步复制，那么这时便不能保证数据的一致性。
    - 所以尽可能的保证半同步复制，便可提高数据的一致性。
  - 只有一个库在工作，读写并未分离，并发有限制，且无故障时浪费服务器资源。
- **适用场景**：读和写都不高的场景（单表数据低于**500万**），双机高可用。

##### 一主一从 | 读写分离

![1631430468863](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430468863.png)

- **特点**： 
  1. A作为主库，负责写，B库作为从库，负责读。
  2. A库故障后，B负责读写。
  3. A库恢复后，B作为主库，负责写，A作为从库，负责读。
- **开发说明**：
  - 数据库的主主配置、故障排除和数据补全，依然需要DBA和运维人员来维护。
  - 而程序代码需要借助数据库中间件Mycat来实现，配置Mycat数据源，并实现对Mycat数据源的数据操作，数据库A和数据库B应该互为主从。
- **优点**：读写分离，并发有了很大的提升。
- **缺点**：
  - 完全依赖于**半同步复制**，如果半同步复制退化为异步复制，**数据一致性无法得到保证**。
  - 需要额外考虑Mycat的高可用机制，常规的解决方案是引入haproxy和keepalive对mycat做集群。
- **适合场景**：读和写都不是非常高的场景（单表数据低于**1000万**），但比方案一并发要高很多。

##### 一主多从 | 读写分离

![1631430498326](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430498326.png)

- **特点**： 
  1. A作为主库，负责写，BCD库作为从库，负责读。
  2. A库故障后，选举B为主库，负责写，CD负责读。
  3. A库恢复后，B仍然作为主库，负责写，CD负责读，A加入从库，负责读。
- **开发说明**：
  - 主库A故障后，Mycat会自动把从B提升为写库，而C、D从库，则可以通过**MHA**等工具，自动修改其主库为B，进而实现自动切换的目地。
    - **MHA Manager**：可以单独部署在一台独立的机器上**管理多个MHA master-slave集群**，也可以部署在一台MHA slave节点上。
    - **MHA Node**：运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将**最新数据的slave**提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。
- **优点**：
  - 相比于双节点的MySQL复制，三节点/多节点的MySQL发生不可用的概率更低。
  - 由于配置了多个读节点，读并发的能力有了质的提高，理论上来说，读节点可以多个，可以负载很高级别的读并发。
  - 可扩展性较好，可以根据需要扩展MySQL的节点数量和结构。
- **缺点**：
  - 至少需要三节点，相对于双节点需要更多的资源，还有可能因为网络分区发生脑裂现象。
  - 数据一致性仍然靠原生半同步复制保证，仍然存在**数据不一致**的风险。
  - 需要额外考虑配置MHA集群保证MHA的高可用。
- **适合场景**：适合写并发不大，但是读并发大的很的场景。

##### MariaDB Galera Cluster

![1631431756775](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631431756775.png)

- **特点**：
  - 多个数据库，在负载均衡作用下，可同时进行写入和读取操作。
  - 各个库之间以Galera Replication的方法进行数据同步，即每个库理论上来说，数据是**完全一致**的。
- **开发说明**：
  - 应用程序做数据库读写时，只需要修改数据库读写IP为keepalive的虚拟节点即可。
  - 数据库配置方面相对比较复杂，需要引入haproxy、keepalive、Galaera等各种插件和配置。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性，可以在任意节点上进行读。
  - 有自动故障转移功能，能够自动添加、剔除节点。
- **缺点**：
  - 只支持InnoDB储存引擎，在处理事务时，会运行一个协调认证程序来保证事务的全局一致性，若该事务长时间运行，就会锁死节点中所有的相关表，导致插入卡住。
  - 整个集群的写入吞吐量是由最弱的节点限制，如果有一个节点变得缓慢，那么整个集群将是缓慢的，所以为了稳定的高性能要求，需要保证所有的节点使用统一的硬件。
  - Mysql数据库5.7.6及之后的版本才支持此种方案。
- **适合场景**：适合读写并发较大，但数据量不是非常大的场景。

##### 数据库分片 | 一主多从集群

![1631432218392](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631432218392.png)

- **特点**：
  - 采用Mycat进行分片存储，可以解决写负载均衡和**数据量过大**问题。
  - 每个分片配置多个读从库，可以减少单个库的读压力。
- **开发说明**： 配置和维护量都比较大，需要配置Haproxy、keepalive和mycat集群，每个分片上又需要配置一主多从的集群。
- **优点**：可以解决高并发高数据量的问题。
- **缺点**： 
  - 配置和维护都比较麻烦，需要的软硬件设备资源大。
  - 每个分片至少需要三节点，相对于双节点需要更多的资源，还有可能因为网络分区发生脑裂现象。
  - 数据一致性仍然靠原生半同步复制保证，仍然存在**数据不一致**的风险。
- **适用场景**：读写并发都很大，并且数据量非常大的场景。

##### 高可用架构总结

- 一些对数据**实时性要求不高**的业务场景，可以考虑使用读写分离。
  - 经验之谈，如果网络延迟在5ms以内，此时做读写分离是没有问题的，数据几乎是实时同步到读库，根本感觉不到延迟。
- 但是对数据**实时性要求比较高**的业务场景，比如订单支付状态场景，则不建议采用读写分离的方案，或者也可以在写程序时指定去写库读取数据。

### 3.7. MySQL分库分表？

- **背景**：
  - 关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到**1000W或100G**以后，由于查询维度较多，即使添加从库、优化索引，很多操作性下降严重。
  - 此时就要考虑对其进行切分了，切分的目的就在于**减少数据库的负担，缩短查询时间**。
- **概念**：
  - 数据库分库分表的核心内容是**数据切分**，以及切分后对**数据的定位和整合**。
    - **分库**：可以根据业务场景和地域分库，每个库并发量不超过2000。
    - **分表**：比如根据用户ID进行分表，每个表控制在300万数据。
  - **数据切分**：Sharding，指将数据分散存储到多个数据库中，使得单一数据库中的**数据量变小**，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。数据切分可以分为两种方式：**垂直切分**和**水平切分**。

#### 垂直切分

垂直切分，分为**垂直分库以及垂直分表**，由于垂直分表切分后，提升的只是表级性能，仍然存在单库并发瓶颈问题，所以，垂直切分一般指的是垂直分库。

##### 垂直分库

垂直分库，指根据业务耦合性，将关联度低的不同表，存储在不同的数据库中。从按照业务进行独立划分的角度来看，其做法与大系统拆分为多个小系统类似；从单独使用一个数据库的角度来看，其做法与微服务治理的做法类似。

- **优点**：
  - 解决业务系统层面的耦合，业务清晰。
  - 与微服务的治理类似，能对不同业务的数据进行分级管理、维护、监控、扩展等。
  - 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈。
- **缺点**：
  - 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度。
  - 分布式事务处理复杂。
  - 依然存在单表数据量过大的问题，此时需要水平切分。

![1631512512432](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631512512432.png)

##### 垂直分表

垂直分表，指基于数据库中的列进行切分，如果某个表字段较多，此时可以新建一张扩展表，将不经常用
的或者字段长度较大的字段，拆分到扩展表中。

- **优点**：
  - 在字段很多的情况下（比如一个大表有100多个字段），通过"大表拆小表"，更**便于开发与维护**，也能**避免MySQL跨页问题**。
    - MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。
  - 另外，数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，**减少了磁盘IO**，从而提升了数据库性能。
- **缺点**：
  - 对于应用层来说增加了开发成本，比如查询所有数据时，需要所有的表做Join操作。
  - 依然存在单库并发瓶颈问题，此时需要垂直分库。

![1631512742958](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631512742958.png)

#### 水平切分

- **背景**：当一个应用难以再细粒度的垂直切分，或切分后数据量行数仍然十分巨大，存在单库读写、存储性能瓶颈时，就需要进行水平切分了。
- **概念**：水平切分是指，根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。水平切分可以分为**库内分表**和**异库分表**。

![1631513461176](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631513461176.png)

##### 库内分表

库内分表，是指当数据库中的某张表由于数据库过大时，可以对该表按行进行拆分，由于拆分数据后的表数据量回到了正常水平，所以在一定程度上能够解决单表的性能问题。

- **特点**：
  - 虽然解决了单一表数据量过大的问题，但是并没有将表分布到不同机器的库上。
  - 而对于减轻MySQL数据库的压力来说，帮助不是很大，因为查询请求还是竞争同一个物理机的CPU、内存和网络IO，因此，水平切分最好还是通过**异库分表**来解决。

##### 异库分表

水平切分进行异库分表后，同一张表会出现在多个数据库/表中，每个库/表的内容不同，其中典型的数据分片规则为**根据数值范围**和**根据数值取模**。

- **优点**：
  - 不存在单库数据量过大、高并发的性能瓶颈，提升了系统稳定性和负载能力。
  - 应用端改造较小，不需要拆分业务模块。
- **缺点**：
  - 跨库的join关联查询性能较差。
  - 跨分片的事务一致性难以保证。
  - 数据多次扩展难度和维护量极大。

###### 根据数值范围切分

- **概念**：可以按照时间区间，或者按ID区间来切分。
  - 比如，按日期将不同月甚至是日的数据分散到不同的库中；将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。
  - 另外，某些系统中使用的**冷热数据分离**，其原理是将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。
- **优点**：
  - 单表大小可控。
  - **天然便于水平扩展**，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。
  - 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，**有效避免跨分片查询的问题**。
- **缺点**：容易出现**某分片过热**的问题，即切分后热点数据可能都落在同一分片上，成为系统性能的瓶颈。
  - 比如按时间字段分片时，有些分片存储了最近时间段内的数据，可能会被频繁的读写，为热点数据；而有些分片存储的历史数据，则很少被查询。

![1631514616880](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631514616880.png)

###### 根据数值取模切分

- **概念**：一般采用hash取模mod的切分方式。
  - 比如，将Customer表根据cusno字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。
- **优点**：分片相对比较均匀，不容易出现热点和并发访问的瓶颈。
- **缺点**：
  - 后期分片集群扩容时，需要迁移旧的数据。
    - 此时，使用**一致性hash算法**可以较好的避免这个问题。
  - 容易面临跨分片查询的复杂问题。
    - 比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。

![1631514925416](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631514925416.png)

#### 分库分表问题

##### 事务一致性问题

- **描述**：
  1. 数据切分前，一个事务处于一个数据库实例中，提交和回滚都能保持原子性。
  2. 但数据切分后，原本同一个事务的代码逻辑，可能需要被拆分成请求多个数据库实例，导致一个事务割裂成多个事务，从而失去了本来单个事务的原子性，出现事务一致性问题。
- **解决方案**：分布式事务和最终一致性。

###### 分布式事务

- **背景**：
  - 当更新内容同时分布在不同库中，不可避免地带来跨库事务问题。
  - 跨分片事务也是分布式事务，没有简单的方案，一般可使用**XA协议**和**两阶段提交**处理。
- **优点**：分布式事务能最大限度保证了数据库操作的原子性。
- **缺点**：
  - 但在提交事务时需要协调多个节点，延后了提交事务的时间点，延长了事务的执行时间，导致事务在访问共享资源时发生冲突或死锁的概率增高。
  - 随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。

###### 最终一致性

- **背景**：
  - 对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要
    在允许的时间段内达到最终一致性即可，可采用**事务补偿**的方式。
- **特点**：与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种**事后检查补救**的措施。
  - 事务补偿需要结合业务系统来考虑，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。

##### 跨节点关联查询Join问题

- **描述**：
  1. 数据切分前，系统中很多列表和详情页所需的数据可以通过SQL Join来完成。
  2. 而数据切分后，数据可能分布在不同的节点上，此时Join带来的问题就比较麻烦了，考虑到性能，应尽量避免使用Join查询。
- **解决方案**：全局表、字段冗余、数据组装以及ER分片。

###### 全局表

- 全局表，也可看做是**数据字典表**，指系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。
  - 由于这些数据通常很少会进行修改，所以也不担心一致性的问题。

###### 字段冗余

- 字段冗余，指一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。
  - 比如，订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询"买家user表"了。
- **缺点**：
  - 适用场景也有限，比较适用于依赖字段比较少的情况。
  - 而且，冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了userName后，是否需要在历史订单中同步更新呢？因此，这种方案要结合实际业务场景进行考虑。

###### 数据组装

数据组装，指在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次
请求得到关联数据，最后将获得到的数据进行字段拼装。

###### ER分片

- ER分片，指在关系型数据库中，如果可以先确定表之间的关联关系（ER关系），则可以将那些存在关联关系的表记录，按照ER关系存放在同一个分片上，这样能较好的避免跨分片join问题。
  - 在1:1或1:n的情况下，通常按照**主表的主键ID**切分。
  - 如下图，Data Node1上面的order订单表与orderdetail订单详情表，就可以通过orderId
    进行局部的关联查询了，而无需跨分片join了。同理，Data Node2上也一样。

![1631518097468](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631518097468.png)

##### 跨节点分页、排序、函数问题

- **描述**：

  - 跨节点多库进行查询时，会出现limit分页、order by排序等问题。
  - 比如，分页时需要按照指定字段进行排序：当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片。当排序字段非分片字段时，就变得比较复杂了，此时需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。
    - 如果只是取第一页的数据，对性能影响还不是很大。
    - 但是如果取得页数很大，情况则变得复杂很多，因为各分片节点中的数据可能是随机的，为了排序的准确性，需要将所有节点的前N页数据都排序好做合并，最后再进行整体的排序，这样的操作时很耗费CPU和内存资源的，所以，页数越大，系统的性能也会越差。
  - 另外，在使用Max、Min、Sum、Count之类的函数进行计算的时候，也需要先在每个分片上执行
    相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。

  ![1631520513150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631520513150.png)

- **解决方案**：全局表、缓存统计、应用内统计等。

##### 全局主键避重问题

- **描述**：
  - 在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，因为某个分区数据库自生成的ID无法保证全局唯一。
  - 因此，需要单独设计全局主键，以避免跨库主键重复问题。
- **解决方案**：UUID、MyISAM ID表、高可用ID服务器、Snowflake分布式自增ID算法。

###### UUID

UUID标准形式包含32个16进制数字，分为5段，形式为8­4­4­4­12的36个字符，例如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：UUID主键，是最简单的方案，且本地生成，性能高，没有网络耗时。
- **缺点**：
  - 由于UUID非常长，会占用大量的存储空间。
  - UUID作为主键，建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。

###### MyISAM ID表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();

```

- **概念**：
  - stub字段（存根）设置为**唯一索引**，同一stub值在sequence表中只有一条记录，可以同时为多张表生成全局ID。
  - 使用MyISAM存储引擎而不是 InnoDB，以获取更高的性能，因为MyISAM使用的是**表级锁**，对表的读写是串行的，所以不用担心在并发时两次读取同一个ID值。
  - 使用REPLACE INTO + SELECT获取自增ID，但必须保证两操作在同一事务内，其中REPLACE INTO会先删除旧数据再生成新数据，从而实现主键自增。
- **优点**：简单。
- **缺点**：
  - 存在单点问题，强依赖DB，当DB异常时，整个系统都不可用。
  - 虽然配置主从可以增加可用性，但当主库挂了，主从切换时，数据一致性在特殊情况下难以保证。
  - 另外，整个系统性能瓶颈限制在单台MySQL的读写性能上。

###### 高可用ID服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：flickr团队使用的一种主键生成策略，与上面的sequence表方案类似，但更好的解决了单点和性能瓶颈的问题。

- **思想**：

  - 建立2个以上的全局ID生成的服务器，每个服务器上只部署一个数据库，每个库有一张sequence表用于记录当前全局ID。
  - 表中ID增长的步长相同，等于库的数量，**起始值依次错开**，这样能将ID的生成散列到各个数据库上。
    - 比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...），可见ID是错开的。

- **优点**：生成ID的压力能够均匀分布在两台机器上，同时提供了系统容错，当第一台出现了错误，可以自动切换到第二台机器上获取ID。

- **缺点**：

  - 系统添加机器水平扩展时，需要停止原本正在运行的ID服务器，以修改步长。
  - 每次获取ID都要读写一次DB，DB的压力还是很大，只能靠堆机器来提升性能。

- **优化方案  **：批量获取ID。

  - 使用批量的方式降低数据库的写压力，每次获取一段区间的ID号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    1. 比如，还是使用两台DB保证可用性，数据库中只存储当前的最大ID。
    2. ID生成服务每次批量拉取6个ID，先将max_id修改为5，当应用访问ID生成服务时，就不需要访问数据库，从号段缓存中依次派发0~5的ID。
    3. 当这些ID发完后，再将max_id修改为11，下次就能派发6~11的ID。
    4. 可见，数据库的压力降低为原来的1/6。
  - **缺点**：ID生成服务需要维护最大ID值，再下次生成ID时，需要告诉DB M1、DB M2各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

###### Snowflake分布式自增ID算法

Twitter的snowflake算法，解决了分布式系统生成全局ID的需求，可以生成64位的Long型数字。

- **概念**：1 + 41 + 10 + 12  = 64位。
  - 第一位未使用。
  - 接下来41位是毫秒级时间，41位的长度可以表示**69年**的时间。
  - 5位datacenterId，5位workerId，这10位的长度最多支持部署**1024个节点**。
  - 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生**4096个ID序列**。
- **优点**：
  - 毫秒数在高位，生成的ID整体上按时间趋势**递增**。
  - 不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞。
  - 可根据自身业务灵活分配bit位。
- **缺点**：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

###### 美团点评分布式ID生成系统 - Leaf

Leaf，在美团点评公司内部服务包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在4C8G的机器上QPS能压测到近5w/s，TP999 1ms，已经能够满足大部分的业务的需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

- **Leaf-segment ID服务器方案**：

  - **思想**：
    1. 利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。
    2. 用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。
  - **实现**：
    1. biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。
       - 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。
       - 如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。
    2. 原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000，那么只有当1000个号被消耗完了之后才会去重新读写一次数据库，此时读写数据库的频率从1减小到了1/step。
    3. 比如，test_tag在第一台Leaf机器上是1~1000的号段，当这个号段用完时，会去加载另一个长度为step=1000的号段。如果另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是3001~4000，同时，数据库对应的biz_tag这条数据的max_id会从3000被更新成4000。
  - **优点**：
    - Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
    - ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
    - 容灾性高，Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
    - 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。
  - **缺点**：
    - TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，TP999数据会出现偶尔的尖刺。
    - DB宕机会造成整个系统不可用。
    - ID号码不够随机，能够泄露发号数量的信息，不太安全。

- **双buffer优化**：优化第一个缺点，当TP999号段使用完，线程取号时阻塞的问题。

  - **背景**：

    - Leaf 取号段的时机是在**号段消耗完**的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致**线程阻塞**。
    - 如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。

  - **思想**：

    - 为了让DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到**某个点时**就异步的把下一个号段加载到内存中，而不需要等到号段用尽的时候才去更新号段。

  - **实现**：

    1. 采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。
    2. 当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。
    3. 当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。

    ![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **高可用容灾**：解决第二个缺点，DB宕机会造成整个系统不可用的问题。

  - **DB高可用方案**：
    - 采用一主两从的方式，同时分机房部署，Master和Slave之间采用**半同步复制**方式同步数据。同时使用公司DBProxy（原Atlas）数据库中间件做主从切换。
    - 当然，这种方案在一些情况会退化成异步模式，甚至在**非常极端**情况下仍然会造成数据不一致的情况，但是出现的概率非常小。
    - 如果系统要保证100%的数据强一致，可以选择使用**类Paxos算法**实现的强一致MySQL方案，但是运维成本和精力都会相应的增加，应该根据实际情况进行选型。
  - **应用高可用方案**：
    - Leaf服务分IDC部署，内部的服务化框架是“MTthrift RPC”。
    - 服务调用的时候，根据负载均衡算法会优先调用同机房的Leaf服务。
    - 如果该IDC内Leaf服务不可用时，会选择其他机房的Leaf服务。
    - 同时，服务治理平台OCTO还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措施。

  ![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

- **Leaf-snowflake方案**：优化第三个缺点，ID号码不够随机，能够泄露发号数量的信息，不太安全。

  ![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

  - Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。

    - 对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置；当Leaf服务规模较大，动手配置成本太高，此时使用Zookeeper持久顺序节点的特性自动对snowflake节点**配置wokerID**。

  - Leaf-snowflake是按照下面几个步骤启动的：

    1. 启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。
    2. 如果有注册过，则直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。
    3. 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。
    4. 除了每次会去ZK拿数据以外，也会在本机文件系统上**缓存一个workerID文件**，当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对Zookeeper的**弱依赖**。一定程度上提高了SLA。

    ![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

  - **解决snowflake时钟回退问题**：由于snowflake依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。

    1. 服务启动时首先检查自己是否写过ZooKeeper leaf_forever节点，若写过，则用自身系统时间与leaf_forever/#{self}节点记录时间做比较。
    2. 若小于leaf_forever/​#{self}时间则认为机器时间发生了**大步长回拨**，服务启动失败并报警；若未写过，证明是新服务节点，直接创建持久节点leaf_forever/#{self}并写入自身系统时间。
    3. 接下来综合对比其余Leaf节点的系统时间来判断自身系统时间是否准确，具体做法是取leaf_temporary下的所有临时节点（所有运行中的Leaf-snowflake节点）的服务IP：Port。
    4. 然后通过RPC请求得到所有节点的系统时间，计算sum(time)/nodeSize。
    5. 若abs( 系统时间-sum(time)/nodeSize ) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点leaf_temporary/#{self} 维持租约；否则认为本机系统时间发生大步长偏移，启动失败并报警。
    6. 其中，leaf_temporary临时结点会每隔一段时间(3s)上报自身系统时间，并写入到leaf_forever/#{self}。

##### 数据迁移、扩容问题

当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。

- 一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。
  - 如果采用**数值范围分片**，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。
  - 如果采用的是**数值取模分片**，则考虑后期的扩容问题就相对比较麻烦。
- 此外，还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过**1000W**）。

#### 分库分表原则

能不切分尽量不要切分，不到万不得已不用轻易使用分库分表这个大招，**避免过度设计和过早优化**。

- 因为并不是所有表都需要进行切分，主要还是看数据的增长速度，切分后会在某种程度上提升业务的复杂度，数据库除了承载数据的存储和查询外，协助业务更好的实现需求也是其重要工作之一。
- 分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等，只有当数据量达到单表的瓶颈时候，才考虑分库分表。

#### 分库分表时机

##### 影响正常运维和业务访问时

数据量过大，影响到正常运维和业务访问时，需要进行分库分表，原因有：

- **备份风险高**：对数据库备份，如果单表太大，备份时需要大量的磁盘IO和网络IO，比如1T的数据，网络传输占50MB时候，需要20000秒才能传输完毕，整个过程的风险都是比较高的。
- **DDL修改锁表时间长**：对一个很大的表进行DDL修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大，在此操作过程中，都算为风险时间。此时，如果将数据表拆分，总量减少，则有助于降低这个风险。
- **访问压力高**：大表会经常访问与更新，就更有可能出现锁等待，如果将数据切分，用空间换时间，可以降低访问压力。

##### 业务快速发展，查询效益不高时

```sql
-- 项目初始阶段的user表
id                   bigint             #用户的ID 
name                 varchar            #用户的名字 
last_login_time      datetime           #最近登录时间 
personal_info        text               #私人信息 
.....                                   #其他信息字段

```

1. 在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。
2. 而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新last_login_name字段，使得user表被不断update，压力很大，而其他字段：id, name, personal_info 是不变的或很少更新的，
3. 此时，在业务角度，就需要将last_login_time拆分出去，新建一个user_time表。
4. 而由于personal_info 属性是更新和查询频率较低的，并且text字段占据了太多的空间，此时，也要垂直拆分出 user_ext 表了。

##### 数据量快速增长，性能出现瓶颈时

- 随着业务的快速发展，单表中的数据量会持续增长，当性能接近瓶颈时，就需要考虑水平切分，做分库分表了。
  - 经验数值参考，每个表控制在300万数据，每个库并发不超过2000。
- 此时，一定要选择合适的切分规则，提前预估好数据容量。

##### 出于安全性和可用性考虑时

鸡蛋不要放在一个篮子里。

- 在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。
- 利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。

#### 分库分表实现

##### MyCAT

- MyCAT，是一个开源的分布式数据库系统，是一个实现了MySQL协议的的Server，是基于**服务端代理模式**的分库分表实现。
- 前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问；而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信。
- 可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。

```xml
<!-- mycat/conf/schema.xml -->
<schema>:   表示的是在mycat中的逻辑库配置，逻辑库名称为:TESTDB
<table>:    表示在mycat中的逻辑表配置，逻辑表名称为:user,映射到两个数据库节点dataNode中,切分规则为:rule1(在rule.xml配置)
<dataNode>: 表示数据库节点,这个节点不一定是单节点，可以配置成读写分离.
<dataHost>: 真实的数据库的地址配置
<heartbeat>:用户心跳检测
<writeHost>:写库的配置
    
<!-- mycat/conf/rule.xml -->
<property name="count">2</property>: 配置有拆分了多个库(表)，需要和前面配置中的dataNode个数一致，否则会出错.
    
<!-- 至于Java应用层配置无需做任何变化，只需要连接MyCAT的逻辑库和逻辑名就好 -->

```

##### Sharding-JDBC

- Sharding-JDBC，是一个开源的分布式关系型数据库中间件，是基于**客户端代理模式**的分库分表实现。
- 可以定位为轻量级的Java框架，通过Jar包提供服务；可以理解为增强版的JDBC驱动，完全兼容各种ORM框架。

![1631587631799](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631587631799.png)

###### 配置实际数据源

```xml
<!-- 实际数据源1 -->
<bean id="ds0" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.142/sharding_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 实际从数据源1.1 -->
<bean id="slave0" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.141/sharding_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 实际数据源2 -->
<bean id="ms1" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.143/shard_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 配置读写分离负载规则 -->
<master-slave:load-balance-algorithm id="msStrategy" type="RANDOM"/>

```

###### 配置实例分片规则

```xml
<!-- 配置Sharding JDBC数据源 以及 逻辑表与分片规则 -->
<sharding:data-source id="sharding-data-source">
    <sharding:sharding-rule data-source-names="ds0,slave0,ms1" default-data-source-name="ms0">
        <!-- 读写分离配置 -->
        <sharding:master-slave-rules>
            <sharding:master-slave-rule id="ms0" master-data-source-name="ds0" slave-data-source-names="slave0" strategy-ref="msStrategy"/>
        </sharding:master-slave-rules>

        <!-- 配置普通分片表 -->
        <sharding:table-rules>
            <sharding:table-rule logic-table="t_order" actual-data-nodes="ms$->{0..1}.t_order_$->{1..2}"
                                 database-strategy-ref="databaseStrategy" table-strategy-ref="tableStrategy" key-generator-ref="snowflake"/>

            <!-- 配置绑定表的分片表 -->
            <sharding:table-rule logic-table="t_order_item" actual-data-nodes="ms$->{0..1}.t_order_item_$->{1..2}"
                                 database-strategy-ref="databaseStrategy" table-strategy-ref="tableOrderItemStrategy" key-generator-ref="snowflake"/>
        </sharding:table-rules>

        <!-- 配置广播表(全局表) -->
        <sharding:broadcast-table-rules>
            <sharding:broadcast-table-rule table="area"/>
        </sharding:broadcast-table-rules>

        <!-- 配置绑定表(子表): 4.0.0-RC2版本会抛出空指针bug: 原因是源码中先创建了绑定表规则然后才是获取广播表 -->
        <sharding:binding-table-rules>
            <sharding:binding-table-rule logic-tables="t_order,t_order_item"/>
        </sharding:binding-table-rules>
    </sharding:sharding-rule>
</sharding:data-source>

```

###### 配置散列规则

```xml
<!-- 数据库分片规则: 根据user_id取模 -->
<sharding:inline-strategy id="databaseStrategy" sharding-column="user_id" algorithm-expression="ms$->{user_id % 2}"/>

```

###### 配置主键ID生成规则

```xml
<!-- 配置主键Key生成规则 -->
<!--<sharding:key-generator id="uuid" column="order_id" type="UUID"/>-->
<sharding:key-generator id="snowflake" column="order_id" type="SNOWFLAKE" props-ref="snow"/>
<bean:properties id="snow">
    <!-- DataCenterId + MachineId => 10bit -->
    <prop key="worker.id">678</prop>
    <!-- 最大容忍回调时间 -->
    <prop key="max.tolerate.time.difference.milliseconds">10</prop>
</bean:properties>

```

##### 总结

|      | MyCAT                                          | Sharding-JDBC                                            |
| ---- | ---------------------------------------------- | -------------------------------------------------------- |
| 区别 | 是服务端代理；不支持库内分表，只支持分异库分表 | 是客户端代理；既支持库内分表，也支持异库分表             |
| 优点 | 对于各个项目透明，应用层无需关心               | 不用部署，运维成本低；不需要服务代理层的二次转发，性能高 |
| 缺点 | 需要部署，运维成本高                           | 各个系统耦合Sharding-JDBC，给以后升级带来麻烦            |

#### 分库分表案例

比如，用户中心，是一个非常常见的业务，主要提供用户注册、登录、查询/修改等功能，其核心表为用户表。

```sql
-- 用户表
User(uid, login_name, passwd, sex, age, nickname)

```

1. 任何脱离业务的架构设计都是耍流氓，在进行分库分表前，需要对**业务场景**需求进行梳理：

   - **用户侧**：前台访问，访问量较大，需要保证高可用和高一致性。主要有两类需求：
     - **用户登录**：通过login_name/phone/email查询用户信息，1%请求属于这种类型。
     - **用户信息查询**：登录之后，通过uid来查询用户信息，99%请求属这种类型。
   - **运营侧**：后台访问，支持运营需求，按照年龄、性别、登陆时间、注册时间等进行分页的查询，是内部系统，访问量较低，对可用性、一致性的要求不高。

2. 水平切分方法，当数据量越来越大时，需要对数据库进行水平切分，切分方法有**根据数值范围**和**根据数值取模**：

   - **根据数值范围**：以主键uid为划分依据，按uid的范围将数据水平切分到多个数据库上。
     - **例如**：user­db1存储uid范围为0~1000w的数据，user­db2存储uid范围为1000w~2000w uid数据。
     - **优点**：扩容简单，如果容量不够，只要增加新db即可。
     - **缺点**：请求量不均匀，一般新注册的用户活跃度会比较高，所以新的user­ db2会比user­ db1负载高，导致**服务器利用率不平衡**。
   - **根据数值取模**：也是以主键uid为划分依据，按uid取模的值将数据水平切分到多个数据库上。
     - **例如**：user­ db1存储uid取模得1的数据，user­ db2存储uid取模得0的uid数据。
     - **优点**：数据量和请求量分布均均匀。
     - **不足**：扩容麻烦，当容量不够时，新增加db，需要rehash，同时需要考虑对数据进行平滑的迁移。

3. 水平切分后，对于按uid查询的需求能很好的满足，可以直接路由到具体数据库，但对于按**非uid**的查询，例如login_name，就不知道具体该访问哪个库了，此时需要**遍历所有库**，性能会降低很多。

   - **用户侧解决方案**：可以采用**建立非uid属性到uid的映射关系**的方案。

     - **非uid需求**：主要需求以单行查询为主，需要建立login_name/phone/email到uid的映射关系，可以解决这些字段的查询问题。

     - **映射关系**：

       1. 比如，login_name不能直接定位到数据库，可以建立**login_name→uid**的映射关系，用索引表或缓存来存储。
       2. 当访问login_name时，先通过映射表查询出login_name对应的uid，再通过uid定位到具体的库。
       3. 由于映射表只有两列，因此可以承载很多数据，当数据量过大时，还可以对映射表再做水平切分。同时，这类kv格式的索引结构，可以很好的使用cache来优化查询性能，而且映射关系不会频繁变更，缓存命中率会很高。

     - **分库基因优化**：上面的映射关系的方法需要额外存储映射表，按非uid字段查询时，还需要多一次数据库或cache的访问。

       ![1631583587908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631583587908.png)

       1. 假如通过uid分库，分为8个库，采用uid%8的方式进行路由，此时是由uid的最后3bit来决定这行User数据具体落到哪个库上，那么这3bit可以看为分**库基因**。
       2. 如果想要消除多余的存储和查询，可以通过**f函数取login_name的基因作为uid的分库基因**。
       3. 而生成uid可以参考分布式唯一ID的生成方案，来生成61big的全局唯一ID，再加上最后3位bit值=f(login_name)当做分库基金。
       4. 这样，当查询login_name时，只需计算f(login_name)%8的值，就可以定位到具体的库。
       5. 不过这样需要提前做好容量规划，预估未来几年的数据量需要分多少库，要预留一定bit的分库基因。

   - **运营侧解决方案**：可以采用**前台与后台分离**的方案。

     - **非uid需求**：很多批量分页且条件多样的查询，这类查询计算量大，返回数据量大，对数据库的性能消耗较高。此时，如果和用户侧公用同一批服务或数据库，可能因为后台的少量请求，占用大量数据库资源，而导致用户侧访问性能降低或超时。
     - **前台与后台分离**：
       1. 运营侧后台业务抽取**独立的service和db**，解决和前台业务系统的耦合。
       2. 由于运营侧对可用性、一致性的要求不高，可以不访问实时库，而是通过binlog异步同步数据到**运营库**进行访问。
       3. 另外，在数据量很大的情况下，还可以使用**ES搜索引擎或Hive**来满足后台复杂的查询方式。

#### 老数据迁移

双写（新老写库）不中断迁移：

1. 线上系统里所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改（**双写**）。
2. 系统部署以后，还需要跑程序**读老库数据写新库**，写的时候需要判断updateTime。
3. 循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码即可。

#### 系统性能评估与扩容

- **场景**：和家亲目前有1亿用户：场景 10万写并发，100万读并发，60亿数据量。
- **设计思路**：考虑极限情况，32库*32表~64个表，一共1000 ~ 2000张表。
  - 支持**3万**的写并发，配合MQ可以实现每秒**10万**的写入速度。
  - 读写分离**6万**读并发，配合分布式缓存可以实现每秒**100万**读并发。
  - 2000张表每张**300万**，可以最多写入**60亿**的数据。
  - 64张用户表，支撑**亿级**用户，后续最多也就扩容一次。
- **动态扩容步骤**：
  1. 推荐是32 库 * 32 表，对于我们公司来说，可能几年都够了。
  2. 配置路由的规则，uid % 32 = 库，uid / 32 % 32 = 表。
  3. 扩容的时候，申请增加更多的数据库服务器，呈倍数扩容。
  4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去。
  5. 修改一下配置，重新发布系统，上线，原先的路由规则变都不用变。
  6. 直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

### 3.8. 线上故障及优化？

#### 更新失败 | 主从同步延时

1. 以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。
2. 是这个么场景，有个同学是这样写代码逻辑的：先插入一条数据，再把它查出来，然后更新这条数据。
3. 在生产环境高峰期，写并发达到了 2000/s，这个时候，**主从复制延时**大概是在小几十毫秒，此时，线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。
4. 接着用户跟客服反馈，而客服就会反馈给我们。
5. 我们通过 MySQL 命令：`show slave status`，查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。一般来说，如果主从延迟较为严重，有以下解决方案：
   - **分库**：拆分为多个主库，每个主库的写并发就减少了几倍，主从延迟可以忽略不计。
   - **重写代码**：由于插入数据时立马查询可能查不到，如果确实需要立马要求就查询到，可以对这个查询**设置直连主库**或者**延迟查询**（主从复制延迟一般不会超过50ms）。

#### **应用崩溃 | 分库分表优化**

1. 我们有一个线上通行记录的表，由于数据量过大，进行了分库分表，当时分库分表初期经常产生一些问题。典型的就是通行记录查询中使用了深分页，通过一些工具如MAT、Jstack追踪到，是由于sharding-jdbc内部引用造成的。
2. 通行记录数据被存放在两个库中，如果没有提供**切分键**，查询语句就会被分发到所有的数据库中，比如查询语句是 limit 10、offset 1000，最终结果只需要返回 10 条记录，但是数据库中间件要完成这种计算，则需要 （1000+10）* 2 = 2020条记录来完成这个计算过程。
3. 如果 offset 的值过大，使用的内存就会暴涨，虽然sharding-jdbc使用归并算法进行了一些优化，但在实际场景中，深分页仍然引起了**内存和性能**问题。
4. 这种在中间节点进行**归并聚合**的操作，在分布式框架中非常常见，比如，在ElasticSearch中，就存在相似的数据获取逻辑，**不加限制的深分页**，同样会造成ES的内存问题。
5. **业界解决方案**：
   - **方法一 - 全局视野法**：
     - 将order by time offset X limit Y，改写成order by time offset 0 limit X + Y，直接返回X + Y条数据，然后服务层对得到的N *（X + Y）条数据后，N为数据库实例的数量，再在服务层进行内存排序，内存排序后再取偏移量X后的Y条记录。
     - **缺点**：随着翻页的进行，性能会越来越低。
   - **方法二 - 业务折衷法-禁止跳页查询**：
     - 用正常的方法取得第一页数据，并得到第一页记录的time_max，然后每次翻页，将order by time offset X limit Y，改写成order by time where time > #time_max limit Y以保证每次只返回一页数据。
     - **优点**：性能为常量。
     - **缺点**：由于每次记录上一页的time_max，所以不能跳页查询。
   - **方法三 - 业务折衷法-允许模糊数据**：将order by time offset X limit Y，改写成order by time offset X/N limit Y/N，N为数据库实例的数量，这样视所有数据库实例为一个整体，每个实例平均查询X/N偏移，Y/N数据量，汇总后可以达到X偏移量以及Y数据量。
     - **优点**：由于每个数据库实例平摊掉成本，所以查询性能较好。
     - **缺点**：由于每个数据库实例查询的都是平均偏移量和平均数据量，可能并不是真实想要的数据，所以需要业务允许这样模糊查询。

#### 查询异常 | SQL 调优

1. 分库分表前，有一段用用户名来查询某个用户的 SQL 语句：select * from user where name = "xxx" and community="other";
2. 为了达到动态拼接的效果，这句SQL语句被一位同事进行了如下修改select * from user where 1=1，他的本意是，当name 或者community 传入为空的时候，动态去掉这些查询条件，这种写法在 MyBaits 的配置文件中，也非常常见，在大多数情况下，这种写法是没有问题的，因为结果集合是可以控制的。
3. 但随着系统的运行，用户表的记录越来越多，当传入的 name 和 community 全部为空时，悲剧的事情发生了：数据库中的所有记录，都会被查询出来，载入到 JVM 的内存中。由于数据库记录实在太多，直接把内存给撑爆了。
4. 由于这种原因引起的内存溢出，发生的频率非常高，比如导入Excel文件时，通常的解决方式是**强行加入分页功能**，或者对一些**必填的参数进行校验**：
   - **Controller层优化**：
     - 现在很多项目都采用前后端分离架构，所以 Controller 层的方法，一般使用@ResponseBody 注解，把查询的结果，解析成 JSON 数据返回。这在数据集非常大的情况下，会**占用很多内存资源**。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用20M或者更多的内存。
     - 因此，**保持结果集的精简**，是非常有必要的，这也是 DTO（Data Transfer Object）存在的必要，互联网环境不怕小结果集的高并发请求，却非常恐惧大结果集的耗时请求，这是其中一方面的原因。
   - **Service层优化**：
     - Service 层用于处理具体的业务，更加贴合业务的功能需求，一个 Service可能会被多个 Controller 层所使用，也可能会使用多个dao结构的查询结果进行计算、拼装。
     - 比如List< User > users = dao.getAllUser();会导致全询user表全部的数据，在数据量达到一定程度后，才会暴露问题。
   - **ORM层优化**：
     - 比如使用Mybatis时，有一个批量导入服务，在 MyBatis 执行**批量插入**的时候，竟然产生了内存溢出，按道理这种插入操作是不会引起额外内存占用的，最后通过源码追踪到了问题。
     - 这是因为 MyBatis 循环处理batch的时候，操作对象是数组，而我们在接口定义的时候，使用的是 List；当传入一个非常大的 List 时，它需要调用 List 的 toArray 方法将列表转换成数组（浅拷贝）；在最后的拼装阶段，又使用了**StringBuilder**来拼接最终的 SQL，所以实际使用的内存要比 List 多很多。
     - 事实证明，不论是插入操作还是查询动作，只要涉及的数据集非常大，就容易出现问题，由于项目中众多框架的引入，想要分析这些具体的内存占用，就变得非常困难。因此，**保持小批量操作和结果集的干净**，是一个非常好的习惯。

# 五、Redis篇

### 1.1. 缓存原理与分类？

#### 概念

通过开辟一个新的数据交换缓冲区，来解决**原始数据获取代价太大**的问题，以让数据得到更快的访问。

- **狭义缓存**：缓存最初的含义，是指用于**加速 CPU 数据交换**的 RAM，即随机存取存储器，通常这种存储器使用更昂贵。
- **广义缓存**：其定义则更宽泛，任何用于**数据高速交换**的存储介质都可以是缓存，可以是硬件也可以是软件。

#### 原理

通过利用**时间局限性原理**，通过**空间换时间**来达到加速数据获取的目的。

1. **时间局限性原理**：被获取过一次的数据，在未来也可能会被多次引用。
   - 比如一条微博被一个人感兴趣并阅读后，它大概率还会被更多人阅读，当然如果变成热门微博后，会被数以百万/千万计算的更多用户查看。
2. **以空间换时间**：因为原始数据获取太慢，所以开辟了一块高速独立空间，提供高效访问，从而达到数据获取加速的目的。

#### 优势

1. **提升访问速度**：缓存存储了 DB 关键数据，数据存在缓存时，无需从 DB 获取，大大提升了访问速度。
   - 一般来讲，服务系统的全量原始数据存储在 DB 中（如 MySQL、HBase 等），所有数据的读写都可以通过 DB 操作来获取。
   - 但 DB 读写性能低、延迟高，如 MySQL 单实例的读写 QPS 通常只有千级别（线上可以到 **3000～6000**），读写平均耗时 **10～100ms** 级别，如果一个用户请求需要查 20 个不同的数据来聚合，仅仅 DB 请求就需要数百毫秒甚至数秒。
   - 而缓存读写性能高的特点，正好可以弥补 DB 的不足，比如 Memcached 的读写 QPS 可以达到 **10～100 万**级别，读写平均耗时在 **1ms** 以下，Redis 读写 QPS 也可以达到 **10万** 级别，结合并发访问技术，单个请求即便查上百条数据，也可以轻松应对。
2. **降低网络拥堵**：由于减少了频繁访问数据库的网络流量，降低了网络拥堵。
3. **减轻服务负载**：由于减少了解析和计算，调用方和存储服务的负载也可以大幅降低。
4. **增强可扩展性**：缓存的读写性能很高，预热快，在数据访问存在性能瓶颈或遇到突发流量，系统读写压力大增时，可以快速部署上线，同时在流量稳定后，也可以随时下线，从而使系统的可扩展性大大增强。

#### 代价

1. **增加了系统复杂度**：服务系统中引入缓存，会增加系统的复杂度。

2. **存在数据不一致**：由于一份数据同时存在缓存和 DB 中，甚至缓存内部也会有多个数据副本，多份数据就会存在一致性问题，同时，缓存体系本身也会存在可用性问题和分区的问题。

3. **缓存容量小**：只能存储部分访问频繁的热数据。

4. **部署成本比 DB 高**：由于缓存相比原始 DB 存储的成本更高，所以系统部署及运行的费用也会更高。

   - 由于缓存空间的成本较高，在实际设计架构中，还要考虑访问**读写延迟和成本**的权衡问题。

     - 系统的访问性能越高越好，访问延迟越低小越好，但要维持相同数据规模的存储及访问，性能越高延迟越小，成本也会越高，所以，在系统架构设计时，需要在系统性能和开发运行成本之间做取舍。
     - 比如相同成本的容量，SSD 硬盘容量会比内存大 10～30 倍以上，但读写延迟却高 50～100 倍。

     ![1631789780363](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631789780363.png)

#### 分类

##### 按宿主层次分类

- **浏览器缓存**：指客户端把服务器请求或响应资源缓存在本地，以加速用户访问，提升单个用户的体验。
  - **浏览器本地内存缓存：**专题活动，一旦上线，在活动期间是不会随意变更的。
  - **浏览器本地磁盘缓存：**Logo缓存，大图片懒加载。
- **CDN缓存**：CDN，Content Delivery Network，即内容分发网络，而CDN缓存指的是，CDN边缘节点将数据缓存起来，使得用户能够**就近获取**所需内容，降低网络拥塞，提高用户访问响应速度和命中率。
- **反向代理缓存**：比如Nginx缓存，可以提升访问上游服务器的速度。
- **本地缓存**：指服务器把数据缓存到本地，性能非常高，但会占用堆内存，影响垃圾回收、影响系统性能，且由于由于没有被持久化，重启后必定会被穿透。
  - 为什么不使用服务器本地磁盘做缓存？是因为当系统处理大量磁盘 I/O 操作的时候，由于 CPU 和内存的速度远高于磁盘，可能导致 CPU 耗费太多时间，来等待磁盘返回处理的结果，对于这部分 CPU 在 I/O 上的开销，称为 **I/O Wait**。
- **分布式缓存**：跨服务器建立通用的缓存系统，可以减轻数据库压力、提升响应速度和分布式处理数据。
  - 比如 Redis 等，针对穿透的情况，可以继续做缓存分层，必须保证数据库不被压垮。

##### 按存储介质分类

- **内存型缓存**：将数据存储在内存，读写性能很高，但缓存系统重启或 Crash 后，内存数据会丢失。
- **可持久化型缓存**：将数据存储到硬盘中，在相同成本下，这种缓存的容量会比内存型缓存大 1 个数量级以上，而且数据会持久化落地，重启不丢失，但读写性能相对低 1～2 个数量级。
  - 比如 Memcached 就是典型的内存型缓存，而 Redis 则属于可持久化型缓存。

### 1.2. 为什么使用Redis？

Redis，是开源的，数据结构存储于内存中，被用来作为数据库，缓存和消息代理。

- 支持多种数据结构，例如字符串（string）、哈希（hash）、列表（list）、集合（set）、带范围查询的排序集合（zset）、位图（bitmap）、hyperloglog、带有半径查询和流的地理空间索引。
- 具有内置的复制、Lua脚本、LRU逐出、事务和不同级别的磁盘持久性。
- 通过Redis Sentinel和Redis Cluster自动分区提供高可用性。

#### 读写速度快（Redis为什么这么快？）

1. **完全基于内存操作**：数据存在内存中，机器访问内存的速度远远大于访问磁盘的速度。

2. **采用单线程架构**：避免了多线程不必要的上下文切换和竞争条件，不存在加锁释放锁操作，减少了因为锁竞争导致的性能消耗。

   - **线程上下文切换场景**：

     - **抢占式**：一般跟锁竞争有关，可以减少锁争用，来减少线程上下文切换。
     - **时间片轮转**：一般跟时间片有关，可以减少线程数，来减少线程上下文切换。

   - **Redis 6.0版本支持多线程**：仍然使用单线程处理命令，但是读写网络数据使和协议解析使用了多线程。

     - **背景**：从 Redis 自身角度来说，因为读写网络的 Read/Write 系统调用占用了 Redis 执行期间大部分 CPU 时间，瓶颈主要在于**网络的 IO 消耗**。

     - **目的**：支持多线程可以充分利用服务器 CPU 资源，分摊 Redis 同步 IO 读写负荷。

     - **使用**：默认关闭，可以在 `io-threads-do-reads` 配置中打开，建议线程数一定要小于CPU核数。

     - **效果**：不严谨测试结论为，对比单线程性能提升**翻倍**。

     - **实现机制**：IO 线程只负责读写 Socket 解析命令，不负责命令处理，而是把命令交给主线程执行。

       1. 主线程负责接收建立连接请求，获取 Socket 放入到全局等待读处理队列。
       2. 主线程处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。
       3. 主线程阻塞，等待 IO 线程读取 Socket 完毕。
       4. 主线程通过单线程的方式，执行请求命令，请求数据读取并解析完成，但并不回写。
       5. 主线程阻塞，等待 IO 线程将数据回写 Socket 完毕。
       6. 解除绑定，清空等待队列。

       => 可以看到，Redis 6.0 多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行，因此无需去考虑控制 Key、Lua、事务、LPUSH/LPOP 等等的并发线程安全问题。

       ![1632104148793](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632104148793.png)

3. **使用I/O多路复用模型**：

   - **I/O交互方式**：
     - **BIO**：同步阻塞，早期传统的阻塞模型，一个连接对应一个线程，开销非常大。
     - **NIO**：同步非阻塞，在一个连接被创建时，Kernel会创建一个socket文件描述符fd，并提供非阻塞的select、poll、epoll多路复用器。
       - **select**：每次都会返回所有的fd，需要用户程序遍历全部的fd，然后找到有数据的fd进行读写，效率较低，最多只能监听1024个连接。
       - **poll**：实现和select基本一样，不过poll突破了1024个连接的监听限制。
       - **epoll**：epoll会返回有读写状态的fd，不再需要用户程序去全量遍历查找，epoll_create创建socket文件描述符fd，epoll_ctl注册事件，epoll_wait等待事件的fd。
     - **AIO**：异步非阻塞，无需一个线程去轮询所有I/O操作的状态改变，在I/O状态发生改变后，操作系统会通知对应的线程来处理。
   - **多路复用执行过程**：文件事件处理器是单线程的，采用多路复用的方式，来监听系统上多个socket，将socket上产生的事件压入队列中，由文件事件分派器从队列中取出一个socket，并根据事件类型发给相应的事件处理器。
     1. 客户端发起请求，向redis的server socket请求连接，这里命名为socket01。
     2. server socket产生一个**AE_READABLE事件**，IO多路复用程序监听到事件后，将这个socket01压入队列。
     3. 文件事件分派器从队列中取出socket01，交给连接应答处理器，连接应答处理器会将socket01的AE_READABLE事件与命令请求处理器相关联，然后压入队列中。
     4. 客户端执行set操作，此时命令请求处理器会从socket01读取key value，并在内存中完成key value的设置，接着在内存中完成设置后，会将socket01的**AE_WRITEABLE事件**与命令回复处理器相关联，然后压入队列中。
     5. 事件分派器拿到socket01后，交给命令回复处理器，由命令回复处理器向socket01写入本次操作的结果，比如OK，之后解除事件关联。

   ![1631793891157](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631793891157.png)

4. **基于C语言开发**：直接跟操作系统交互，命令执行飞快。

5. **使用专门设计的数据结构**：对string、list、set、zset、hash都专门设计了数据结构，使得某些操作的性能有所提升，比如获取string的长度，使用sds的时间复杂度为O（1），而c字符串的为O（n）。

#### 数据结构丰富

Redis不仅仅支持简单的key-value类型的数据结构，同时还提供了list，set，zset，hash等数据结构。

#### 支持持久化

Redis提供了RDB和AOF两种持久化策略，能最大限度地保证Redis服务器宕机重启后数据不会丢失。

#### 支持高可用

Redis可以使用主从模式、哨兵模式以及集群模式，来保证服务器的高可用。

#### 客户端语言多

由于Redis受到社区和各大公司的广泛认可，所以客户端语言涵盖了所有的主流编程语言，比如Java，C，C++，PHP，NodeJS等等。

#### 竞品对比

| 产品               | 优点                                                        | 缺点                                                         | 持久化        | 高可用               | 使用场景                                 |
| ------------------ | ----------------------------------------------------------- | ------------------------------------------------------------ | ------------- | -------------------- | ---------------------------------------- |
| Redis              | 单线程、支持K-V以及多种数据结构存储、支持持久化，适合热数据 | 容量受内存限制，不便于海量数据读写，不适合冷数据             | RDB、AOF      | 主从、哨兵、集群     | 缓存、最新回复、点赞数、共同好友、排行榜 |
| Memcahe            | 多线程、性能高、速度快，用于减轻数据库负载                  | 不支持持久化、只能存储K-V数据                                | 不支持        | 集群没有同步复制机制 | 前端缓存、用户信息、好友信息、文章信息   |
| Tair               | 淘宝开源，多线程、支持K-V以及多种数据结构存储、支持持久化   | -                                                            | MDB、RDB、LDB | 集群可以灵活配置     | 适合作为大数据量缓存                     |
| EvCache            | Netflix基于Memcached 实现的缓存方案，性能很高               | -                                                            | 支持          | 支持                 | 适合对强一致性没有必须要求的场合         |
| Google Guava Cache | 本地缓存，性能非常高                                        | 会占用堆内存，影响垃圾回收、影响系统性能；每台JVM都有自己的本地缓存，没有分布式一致性可言 | -             | -                    | 本地缓存                                 |

##### Memcache

Memcache，是一个高性能的分布式内存对象缓存系统，通过在内存里维护一个统一的**巨大的hash表**，用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等，数据存储在内存中，然后直接从内存中读取，从而大大提高读取速度。

- **使用场景**：
  1. 如果有持久方面的需求，或对数据类型和处理有要求的，应该选择redis。 
  2. 如果简单的key-value存储的，应该选择memcached。	

| redis                                 | Memcached                    |
| ------------------------------------- | ---------------------------- |
| 内存高速数据库                        | 高性能、分布式内存缓存数据库 |
| 支持hash、list、set、zset、string结构 | 只支持key-value结构          |
| 将大部分数据放到内存                  | 全部数据放到内存中           |
| 支持持久化、主从复制备份              | 不支持数据持久化及数据备份   |
| 数据丢失可通过AOF恢复                 | 挂掉后，数据不可恢复         |
| 单线程（2~4万TPS）                    | 多线程（20-40万TPS）         |

##### Tair

Tair，Taobao Pair，是淘宝开发的分布式Key-Value存储引擎，默认支持基于内存和文件的两种存储方式，分别与缓存和持久化存储对应，既可以做缓存，也可以做数据源。

- **三种引擎切换**：
  - **MDB**：基于Memcache，，属于内存型产品，支持KV和类HashMap结构，性能最优，不支持持久化存储。
  - **RDB**：基于Redis，支持List、Set、Zset等复杂的数据结构，性能次之，可提供缓存以及持久化存储两种模式。
  - **LDB**： 基于Google LevelDB，属于持久化产品，支持KV和类Hashmap结构，性能稍低，但持久化可靠性最高。
- **痛点**：在Redis集群中，如果程序想借用缓存资源，则必须得指明redis服务器地址去获取，增加了程序维护的复杂度，因为Redis服务器很可能是频繁变动的。
  - **中心化管理**：Tair使用中心节点代理缓存集群，借用Tair资源的程序只需要跟该中心节点交互，无需频繁更改服务器地址。同时，Tair还有服务器配置的功能，使得在改集群配置文件时，不需要一个个机器地去修改。

##### EVCache

EVCache，Ephemeral Volatile Cache，短暂易失缓存，是一个Netflflix开源的，基于Memcached实现的分布式缓存，用以构建超大容量、高性能、低延时、跨区域全球可用的缓存数据层，适合对**强一致性没有必须要求**的场合。

- **特性**：分布式键值存储、AWS跨域复制存储数据、注册和自动发现新节点或者新服务。

##### Google Guava Cache

- **Google Guva**：是google开源的一个公共java库，类似于Apache Commons，它提供了集合，反射，缓存，科学计算，xml，io等一些工具类库，而cache只是其中的一个模块，使用Guva cache能够方便快速的构建本地缓存。
- **Google Guava Cache**：是一种非常优秀本地缓存解决方案，提供了基于容量，时间和引用的缓存回收方式。
  - 缓存核心类LocalCache里面的内部类Segment，与jdk1.7及以前的ConcurrentHashMap非常相似，都继承于ReetrantLock，还有六个队列，以实现丰富的本地缓存方案。
- **优点**：
  - 作用在LocalCache上，相对于IO操作速度快，性能非常高效。
  - 对于Redis等分布式缓存，它们受限于网络IO、吞吐率以及缓存的数据大小等原因，远水救不了近火，而DB + Redis + LocalCache可以实现高效存储、高效访问。
- **缺点**：
  - 会占用堆内存，影响垃圾回收、影响系统性能。
  - 对于缓存一致性方面，每台JVM都有自己的本地缓存，没有分布式一致性可言；而使用分布式缓存则更好一点，因为集群环境下的节点都使用同一份缓存。
- **使用场景**：
  - 对性能有非常高的要求时。
  - 缓存数据需要不经常变化，且占用内存不能太大时。
  - 整个集合都需要被访问时。
  - 数据允许不实时一致时。
- **使用方法**：

```java
// 5. 构造LocalCache
private final LoadingCache<String,List<SysDictItem>> vendorDictItemCache = CacheBuilder.newBuilder()
    // 1. 设置缓存容量
    .maximumSize(1000)
    // 2. 设置超时时间
    .expireAfterWrite(10, TimeUnit.SECONDS)
    // 3. 设置缓存Key失效监听器
    .removalListener((RemovalListener<String, List<SysDictItem>>) notification -> {
        LOGGER.warn(notification.getKey() + "缓存已失效, 失效原因为: " + notification.getCause().name());
    })
    // 4. 提供缓存加载器 -> 缓存不存在时，会去查找数据库来设置缓存
    .build(new CacheLoader<String, List<SysDictItem>>() {
        @Override
        public List<SysDictItem> load(String code) {
            return getDictItemsByCodeAndTypeInDB(code);
        }
    });

// 6. 获取缓存
sysDictItems = vendorDictItemCache.get(dictCode);
```

- **自己设计本地缓存痛点：**
  - **并发处理能力差**：针对并发可以使用CurrentHashMap，但缓存的其他功能需要自行实现。
  - **缓存处理**：需要根据一定的规则进行淘汰数据，比如LRU、LFU、FIFO等，缓存加载和刷新都需要手工实现。
  - **回调通知实现**：清除数据时，需要触发回调通知，同样需要自己实现。
- **使用Google Guava Cache的优势**：
  - **并发处理能力**：
    - Google  Guava Cache类似CurrentHashMap，是线程安全的，提供了设置并发级别的API，使得缓存支持并发的写入和读取，采用分段锁机制，以减小锁力度，提升并发能力。
  - **缓存过期和淘汰机制**：在Google  Guava Cache中，可以设置Key的过期时间，包括访问过期和创建过期，会在缓存容量达到指定大小时，采用LRU的方式，将不常使用的键值从缓存中删除。
  - **防止缓存击穿**： Google  Guava Cache可以在CacheLoader#load方法中加以控制，对同一个key，只让一个请求去读源数据并回填缓存，其他请求阻塞等待，相当于集成了数据源，方便用户使用。
  - **监控统计能力**：另外，还提供了缓存加载以及命中情况统计信息的API。

##### 总结

| 对比               | Redis优势                             |
| ------------------ | ------------------------------------- |
| Memcache           | Redis支持多种数据结构存储、支持持久化 |
| Tair               | 业务量不大时，Redis简单高效、实用性好 |
| EvCache            | Redis社区活跃、使用最多               |
| Google Guava Cache | Redis缓存统一存储，分布式一致性好点   |

### 1.3. Redis数据类型与底层实现？

Redis，是一个Key-Value型的内存数据库，它所有的key都是字符串，而value常见的数据类型有五种：**String、Hash、List、Set、Zset**。

![1631850908728](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631850908728.png)

#### 基本类型API总结

http://redisdoc.com/、https://redis.io/topics/streams-intro

| String                    | Hash                  | List                     | Set                 | Zset                                    | Stream（5.0版本）        |
| ------------------------- | --------------------- | ------------------------ | ------------------- | --------------------------------------- | ------------------------ |
| SET、GET、GETSET          | HSET、HSETNX          | LPUSH、LPUSHHX、LPOP     | SADD                | ZADD                                    | XADD                     |
| SETNX、SETEX、PSETEX      | HGET、HGETALL         | RPUSH、RPUSHX、RPOP      | SISMEMBER           | ZINCRBY、ZSCORE                         | XLEN                     |
| APPEND                    | HEXSITS               | RPOPLPUSH                | SPOP、SRANDMEMBER   | ZCARD、ZCOUNT                           | XRANGE、XREVRANGE        |
| STRLEN                    | HDEL                  | LREM、LINSERT            | SREM、SMOVE         | ZRANGE、ZREVRANGE                       | XREAD、XREAD BLOCK       |
| SETRANGE、GETRANGE        | HLEN                  | LINDEX、LSET             | SCARD               | ZRANGEBYSCORE、ZREVRANGEBYSCORE         | XGROUP、XREADGROUP、XACK |
| INCR、INCRBY、INCRBYFLOAT | HSTRLEN               | LRANGE、LTRIM            | SMEMBERS            | ZRANK、ZREVRANK                         | XPENDING                 |
| DECR、DECBY               | HINCRBY、HINCRBYFLOAT | BLPOP、BRPOP、BRPOPLPUSH | SINTER、SINTERSTORE | ZREM、ZREMRANGEBYRANK、ZREMRANGEBYSCORE | XCLAIM、XAUTOCLAIM       |
| MSET、MSETNX、MGET        | HMSET、HMGET          |                          | SUNION、SUNIONSTORE | ZRANGEBYLEX、ZLEXCOUNT、ZREMRANGEBYLEX  | XINFO                    |
|                           | HKEYS、HVALS          |                          | SDIFF、SDIFFSTORE   | ZINTERSTORE、ZUNIONSTORE                | XTRIM、XDEL              |

#### 基本类型使用场景总结

| 类型              | 说明     | 使用场景                                       |
| ----------------- | -------- | ---------------------------------------------- |
| String            | 字符串   | 帖子、评论、热点数据、输入缓冲                 |
| Hash              | 哈希表   | 结构化数据，比如存储对象                       |
| List              | 列表     | 评论列表、商品列表、发布与订阅、慢查询、监视器 |
| Set               | 集合     | 交集、并集、差集，比如朋友关系                 |
| Zset              | 有序集合 | 去重后排序，适合排名场景                       |
| Stream（5.0版本） | 流       | 消息队列                                       |

#### Redis对象

```c
// Redis对象
typedef struct redisObjet {
    // 对象类型，取值范围有：REDIS_STRING、REDIS_HASH、REDIS_LIST、REDIS_SET、REDIS_ZSET
    unsigned type:4;
    // 对象编码，取值范围有：REDIS_ENCODING_INT、REDIS_ENCODING_EMBSTR、REDIS_ENCODING_RAW、REDIS_ENCODING_HT、REDIS_ENCODING_LINKEDLIST、REDIS_ENCODING_ZIPLIST、REDIS_ENCODING_INTSET、REDIS_ENCODING_SKIPLIST
    unsigned encoding:4;
    // 指向底层实现的数据结构的指针
    void *ptr;
    ...
}
```

使用Redis对象来表示key和Value，即每新建一个键值对，至少会创建有两个对象，而使用对象具有以下**好处**：

- **命令是否可执行判断**：在执行命令前，可以根据对象的类型来判断，一个对象是否可以执行该命令。
- **优化不同场景下的使用效率**：针对不同的使用场景，为对象设置不同的数据结构实现，从而优化对象的不同场景下的使用效率。
- **基于引用计数的内存回收**：可以基于引用计数的内存回收机制，自动释放对象所占用的内存。
- **对象内存共享**：可以让多个Key共享同一个对象，从而节约内存。
- **根据空转时长淘汰对象**：对象带有访问的时间记录信息，使用该信息可以进行优化空转时长较大的Key，从而进行删除。

#### Redis数据结构

Redis对象的**ptr指针**，指向对象底层实现数据结构，而这些数据结构由对象的**encoding属性**来决定，其**对应关系**为：

| RedisObject#encoding      | ptr指向的数据结构               | RedisObject#type                   |
| ------------------------- | ------------------------------- | ---------------------------------- |
| REDIS_ENCODING_INT        | redisObject + long型整数        | REDIS_STRING                       |
| REDIS_ENCODING_EMBSTR     | embstr（redisObject+优化的sds） | REDIS_STRING                       |
| REDIS_ENCODING_RAW        | raw（redisObject+sds）          | REDIS_STRING                       |
| REDIS_ENCODING_HT         | dict                            | REDIS_HASH、REDIS_SET              |
| REDIS_ENCODING_LINKEDLIST | linkedlist                      | REDIS_LIST                         |
| REDIS_ENCODING_ZIPLIST    | ziplist                         | REDIS_HASH、REDIS_LIST、REDIS_ZSET |
| REDIS_ENCODING_INTSET     | intset                          | REDIS_SET                          |
| REDIS_ENCODING_SKIPLIST   | skiplist+dict                   | REDIS_ZSET                         |

##### sds

```java
// 简单动态字符串
struct sdshdr{ 
  // 记录buf数组中已使用字节的数量，即实际使用的字节数 
  int len;
  // 记录buf数组中未使用字节的数量
  int free;
  // 字符数组，用于保存字符串
  char buf[];
}
```

![1631870815998](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631870815998.png)

- **概念**：sds，simple dynamic String，**简单动态字符串**，是Redis自己实现的一个字符串数据结构，在Redis中所有场景中，出现的字符串基本都是由SDS来实现的，包括所有的Key、非数字值、字符串类型的值。

- **特点**：

  - **空间预分配**：在进行修改之后，sds会对接下来可能需要的空间进行预分配，使用free属性来记录当前预分配了多少空间，来减少修改字符串带来的内存重分配次数，其分配策略如下：
    - 如果当前sds的长度小于1M，则分配等于len长的free空间。
    - 如果当前sds的长度大于1M，则分配1M的free空间。
  - **惰性释放内存**：为避免缩短字符串时的内存重分配操作，sds在数据减少时，并不会立刻释放空间，而是暂时留着，以备下次进行增长时使用。
    - 对于内存紧张的机器，sds也提供了对应的API，可以在需要的时候，来释放掉多余的未使用空间。
  - **SSD限制512M**：由于sds大小限制512M，所以Redis的Key以及字符串数据结构的值，最大大小也为 512M。

- **对比C字符串**：

  | SSD函数                | C字符串                                                      | SDS                                                  |
  | ---------------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
  | 高性能获取字符串长度   | 由于需要遍历整个字符数组，所以获取字符串长度需要O（N）       | 由于记录了len，所以获取字符串长度只需要O（1）        |
  | 杜绝字符数组缓冲区溢出 | 字符数组空间不会自动扩展，容易造成缓冲区溢出                 | 会先检查free是否足够，来自动扩展空间，避免缓冲区溢出 |
  | 减少内存重分配次数     | 每次修改字符串长度，都需要内存重新分配                       | 空间预分配、惰性释放内存，但最坏情况下，同C字符串    |
  | 二进制安全             | 由于使用空间符'0'来判断一个字符串的结尾，所以只能保存纯文本，非二进制安全 | 二进制安全，可以保存任意格式的二进制数据             |
  | 部分兼容C库函数        | 可以无缝使用所有C库函数                                      | 只兼容部分的C库函数                                  |

##### int

![1631878723017](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878723017.png)

long类型的整数，占8个字节。

##### embstr

![1631878253168](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878253168.png)

embstr，embstr编码的简单动态字符串，是对sds的一个小优化，将redisObject对象头和sds对象连续存在一起，一旦两者整体大小大于64字节时，Redis则认为是一个大字符串（即字符串为44字节时，3.2版本前是39字节），然后将会将字符串转为raw进行存储。

- 当使用sds时，程序需要调用两次内存分配，redisObject和sds各自分配一块空间；而由于embstr需要的空间很少，可以采用**连续的空间保存**，只需要一次内存分配，将sds的值和字符串对象的值放在一块连续的内存空间上，由于内存是连续的，减少了很多内存碎片和指针内存的占用，进而节约了内存，提高短字符串的内存分配效率和空间利用率。
- 另外，embstr是只读的形式，Redis并未对其提供任何修改的方式，因此，embstr需要转换为RAW才能进行修改。

##### raw

![1631878637658](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878637658.png)

raw，简单动态字符串，以sds形式存储，主要为了解决长度计算和追加字符效率的问题。

##### dict

```c
// 字典，持有两个哈希表，只是对hashtable做了一层封装
typedef struct dict{
  // 类型特定函数，配合*private以实现字典多态
  dictType *type;
  // 私有数据，配合*type以实现字典多态
  void *private;
  // 哈希表
  dictht ht[2];
  // rehash索引，当当前的字典不在rehash时，值为-1
  int trehashidx;
}

// 哈希表，是字典条目的数组
typedef struct dictht{
  // 哈希表的数组
  dictEntry **table;
  // 哈希表的大小
  unsigned long size;
  // 哈希表的大小的掩码，用于计算索引值，总是等于 size-1
  unsigned long sizemasky;
  // 哈希表中已有的节点数量
  unsigned long used;
}

// 字典条目，持有Key和Value
typedef struct dictEntry{
  // 键
  void *key;
  // 值
  union {
    void *val;
    uint64_tu64;
    int64_ts64;
  } v;

  // 指向下一个节点的指针
  struct dictEntry *next;
} dictEntry;
```

![1631878774943](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878774943.png)

dict，字典，一种能够存储键值对的数据结构，在Redis中的字典实现中，它持有两张哈希表，一个为null，另一个存储实际键值对，在rehash时允许同时存在键值对。

- **hash算法**：在哈希表添加一个元素时，需要计算该键值的hash值，之后根据其hash值来定位被放入的槽，为了减少哈希冲突的发生，需要将key值打散的足够均匀，此时hash算法的选择尤其重要。Redis 选用了业内计算性能好的算法来实现hash过程：
  - **Redis 5.0 & 4.0版本**：siphash哈希算法，可以在输入的Key值很小的情况下，产生随机性比较好的输出。
  - **Redis 3.2、3.0 & 2.8版本**：Murmurhash2哈希算法，可以在输入值是有规律时，也能给出比较好的随机分布。
- **hash冲突**：hash算法计算结束之后，会根据当前哈希表的长度，来确定当前键值所在的index，而由于长度有限，迟早会产生两个键值要放到同一个位置的问题，即产生hash冲突。
  - **解决方案**：Redis的哈希表处理Hash冲突的方式，和Java中的HashMap一样，即链地址法，Hash表有两维，第一维度是个数组，第二维度是个链表，当发生了hash冲突的时，会将冲突的节点使用链表连接起来，放在同一个桶内。
    - **缺点**：由于第二维度是链表，如果hash冲突比较严重，导致单个链表过长，那么此时hash表的查询效率就会急速下降。
- **扩容与缩容**：当哈希表过于拥挤，查找效率就会下降，需要进行扩容操作；当哈希表过于稀疏，对内存就有点太浪费了，需要进行缩容操作。
  - **负载因子**：用于描述哈希表当前被填充的程度，计算公式是：`负载因子= 哈希表已保存的节点数量 / 哈希表的大小`，在Redis实现里，扩容缩容有三条规则：
    1. 当没有正在执行的`BGSAVE`和`BGREWRITEAOF`指令时，且**负载因子 >= 1**，才会对哈希表进行扩容。
    2. 当存在正在执行`BGSAVE`和`BGREWRITEAOF`指令时，且**负载因子 >= 5**，才会对哈希表进行扩容。
       - 这是因为在进行BGSAVE操作时，会存在**子进程**，Redis会尽量避免在存在子进程时进行扩容，以节省内存。
    3. 无论存不存`BGSAVE`和`BGREWRITEAOF`指令，只要**负载因子 < 0.1**时，会自动开始对哈希表进行缩容。
       - 而缩容过程中，由于申请的内存比较小，同时还会释放掉一些已经使用的内存，不会增大系统的压力，因此不需要在缩容时考虑是否正在进行`BGSAVE`和`BGREWRITEAOF`操作。
  - **扩容的目标数量**：第一个大于等于`ht[0].used * 2`的`2^n`，初始为4。
  - **缩容的目标数量**：第一个大于等于`ht[0].used`的`2^n`。
- **渐进式rehash**：在扩缩容期间，需要将当前哈希表中的所有节点，重新进行一次hash，即rehash。
  - **对比Java rehash**：
    - 在 Java的HashMap中，实现方式是，新建一个哈希表，一次性的将当前所有节点rehash完成，之后释放掉原有的 hash表，再持有新表。
    - 而Redis不是，由于rehash需要重新定位所有的元素，对数据量很大的字典执行此操作将比较耗时，这对于单线程的Redis说，是很难接受这种延时的，因此，Redis选择使用**一点一点搬的渐进式rehash**策略。
  - **渐进式rehash过程**：
    1. 如果当前数据在ht[0]中，则会首先为ht[1]分配足够的空间。
    2. 在字典中维护一个rehashindex变量，并更新rehashindex = 0，表示当前开始rehash操作。
    3. 在rehash期间，客户端每次对字典进行增删改查操作，在完成实际操作之后，redis都会对该字典进行一次rehash操作，将ht[0]在rehashindex对应位置上的值rehash到ht[1]上，然后把rehashindex 递增一位。
       - 为了让该字典在持有两个哈希表期间，仍然可以对外提供服务，对于添加操作，需要直接添加到 ht[1]上，让ht[0]的数量只会减少不会增加，保证rehash过程可以完结。
       - 而对于删除、修改以及查询操作，可以在ht[0]上进行，如果得不到结果，则会去ht[1]再执行一遍，保证rehash过程的推进。
    4. 随着字典不断被增删改查，原来的ht[0]上的数值会全部rehash完成，此时会将rehashindex置为-1，代表rehash结束。
    5. 而如果服务器很空闲，中间几小时没有被请求过，则Redis定时函数会加入帮助rehash的操作，从而加快rehash的过程。
  - **优点**：采用了分而治之的思想，将rehash操作，分散到每一个对该字典的操作上以及定时函数上，避免了集中式rehash带来的性能压力。
  - **缺点**：在 rehash 的时间内，需要同时持有两个哈希表，对服务器内存的占用稍大，如果此时服务器本来内存就不足时，突然进行的rehash，会使得Redis执行缓存淘汰策略，造成大量的Key被抛弃。

##### linkedlist

```c
// 双向链表
typedef struct list {
  // 表头结点
  listNode *head;
  // 表尾节点
  listNode *tail;
  // 链表所包含的节点数量
  unsigned long len;
  // 其他函数
  ...
} list;

// 双向链表结点
typedef struct listNode{
  // 前置节点
  struct listNode *prev;
  // 后置节点
  struct listNode *next;
  // 节点值
  void *value;
} listNode
```

![1631882244485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631882244485.png)

linkedlist，双向链表，由于经常需要使用，Redis自己实现了一个双向链表。

- **双向**：包含了头结点、尾结点，同时每个结点都有自己的前驱和后继，可以很方便地进行正向和反向的遍历。
- **无环**：头结点的prev指针和尾结点的next指针都指向null，是一个无环链表。
- **持有长度计数器**：len记录着当前链表的长度，获取的时间复杂度是O（1）。

##### ziplist

```c
// 压缩链表，底层是个结点数组
struct ziplist<T>{
    // 整个压缩列表占用字节数
    int32 zlbytes;
    // 最后一个节点到压缩列表起始位置的偏移量，可以用来快速定位到压缩列表中的最后一个元素
    int32 zltail_offset;
    // 压缩列表包含的元素个数
    int16 zllength;
    // 元素内容列表，用数组存储，内存上紧挨着
    T[] entries;
    // 压缩列表的结束标志位，值永远为0xFF.
    int8 zlend;
}

// 压缩链表结点
struct entry{
    // 前一个entry的长度，当其在254字节以内时，该值为1字节；否则为5字节
    int<var> prevlous_entry_length;
    // 编码方式，记录着结点content属性所保存数据的类型以及长度
    int<vat> encoding;
    // 内容，真正要保存的数据，类型和长度由encoding决定
    optional bute[] content;
}
```

![1631926865240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631926865240.png)

压缩列表，是由一系列连续内存块组成的顺序型数据结构，由于内存是连续的，减少了很多内存碎片和指针内存的占用，进而节约了内存。

- **prevlous_entry_length取值逻辑**：
  - 当前一个节点的长度小于254字节时，`previous_entry_length`长度为1字节。
  - 当前一个节点的长度大于等于254字节时，`previous_entry_length`长度为5字节。
- **遍历列表**：
  - **顺序遍历**：按顺序遍历`entries`数组。
  - **反向遍历**：首先拿到尾部节点的偏移量，找到最尾部的节点，然后调用`prevlous_entry_length`属性，就可以拿到前一个节点，接着不断向前遍历即可。
- **新增结点**：ziplist 是连续存储的数据结构，内存是没有冗余的（SDS中就有冗余空间）, 所以，每一次新增节点，都需要进行内存申请。
  - 如果当前ziplist所在的内存连续块够用，则将新节点添加即可。
  - 但如果申请到的是另外一块连续的内存空间，则需要将所有的内容拷贝到新的地址，当ziplist中存储的值太多，这样的内存拷贝将是一个很大的消耗。
  - 因此，Redis只在一些数据量小的场景下使用ziplist。
- **级联更新问题**：
  - **发生场景**：
    1. 假设有一个极端的场景，在这个ziplist内部，所有的节点的长度都是 253 字节，也就意味着所有节点的`prevlous_entry_length`属性都是一个字节。
    2. 此时，给压缩列表**最前端**插入一个大于 254 字节的节点，那么原来的第一个节点的`prevlous_entry_length`属性会从 1 个字节变成 5 个字节，这个节点的总长度也就来到了 257 字节，大于了254 字节，那么它的下一个节点（原来的第二个节点）的`prevlous_entry_length`属性也需要变成 5 个字节，这又会导致下一个节点的变化... 从而引起了连锁的变化，所有节点的`prevlous_entry_length`值都需要更新一遍。
    3. 同理，删除节点也有可能会造成级联更新的发生。
  - **缺点**：级联更新的时间复杂度很差，最多需要进行N次空间的重分配，每次空间的重分配最差也需要 O（N）, 所以，级联更新的时间复杂度最差是 O（N^2）。
    - 级联更新问题造成Redis性能压力的**概率极其低**：因为级联更新需要大范围连续的节点大小为250-253字节之间，出现的概率非常小，而且当只出现了3~5个结点的级联更新时，对Redis也不会造成性能压力。

##### quicklist（3.2版本）

```c
// 快速列表
struct quicklist{
    // 头结点
    quicklistNode* head;
    // 尾节点
    quicklistNode* tail;
    // 元素总数
    long count;
    // ziplist 节点的个数
    int nodes;
    // LZF 算法压缩深度
    int compressDepth;
}

// 快速列表结点
struct quicklistNode {
    // 快速列表前驱
    quicklistNode* prev;
    // 快速列表后继
    quicklistNode* next;
    // 指向压缩列表 ziplist
    ziplist* zi; 
    // ziplist 的字节总数
    int32 size;
    // ziplist 的元素总数
    int 16 count;
    // 存储形式，是原生的字节数组，还是 LZF 压缩存储
    // 为了进一步节约内存，quicklist 可使用 LZF 算法对 ziplist 进行压缩存储
    int2 encoding;
}
```

![1631929051582](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631929051582.png)

quicklist，快速列表，是 Redis 3.2 列表的底层实现，是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。（在 Redis 3.2 之前，Redis 采用双向链表 linkedlist 和压缩列表 ziplist 实现）

- **linkedlist缺点**：
  - **指针内存浪费**：每个节点都有自己的前后指针，指针所占用的内存有点多，太浪费了。
  - **内存碎片多**：每个节点单独的进行内存分配，当节点过多，造成的内存碎片太多了，影响内存管理的效率。
- **quicklist优点**：将 linkedlist 和 ziplist 结合起来，通过前后指针，互相连接多个 ziplist，可以在一定程度上缓解 linkedlist 指针内存浪费和内存碎片多的问题，同时解决 ziplist 数据量太大导致的性能变差问题。
- **ziplist切割大小**：
  - ziplist 太小的话（比如为1个元素时），quicklist 退化成了普通的链表，起不到应有的作用；ziplist 太大的话（比如 quicklist 只用一个 ziplist），quicklist 退化成了 ziplist，性能太差。
  - 因此，quicklist 内部默认定义的单个 ziplist 的大小为 `8k 字节`，可以由参数`list-max-ziplist-size`来控制，其作用是，如果分配结点时，发现 ziplist 超过了这个大小，则会重新分配一个 ziplist。
- **压缩深度**：
  - 为了进一步节约内存，quicklist 可使用 LZF 算法对 ziplist 进行压缩存储，同时可以指定压缩深度，由`list-compress-depth`参数决定，默认的压缩深度为 0，表示所有的节点都不进行压缩。
    - 当压缩深度为 1 时：quicklist 两端的第一个 ziplist 不进行压缩。
    - 当压缩深度为 2 时：quicklist 两端的各自2个 ziplist 不进行压缩。
  - 之所以只压缩两端的结点，是因为需要支持列表快速的 push/pop 操作：
    - 如果对两端的 ziplist 压缩了，那么要从列表里面读取值时，必然需要先解压，从而导致性能变差。
    - 因此可以将两端即将被操作的节点不压缩，其他的选择压缩。

##### listpack（5.0版本）

```c
// 紧凑列表类似于ziplist压缩链表，以下是它结点的一些属性：

// 编码方式，记录着结点content属性所保存数据的类型以及长度
int<vat> encoding;
// 内容，真正要保存的数据，类型和长度由encoding决定
optional bute[] content;
// 结点自身长度
int<var> length;
```

![1631943890480](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631943890480.png)

listpack，紧凑列表，是Redis 5.0 版本中新引入的一个数据结构，和 ziplist 极其相似，列表结点不再记录前一个结点的长度，而是记录自身的长度，从而解决ziplist的痛点问题。（在极小的概率下有可能发生级联更新，当连续规模较大的级联更新发生时，会对 Redis 的性能有比较大的影响）

- **优点**：
  - 不再需要 zltail_offset 属性也可以快速定位到最后一个节点，而是用`listpac总长度 - 最后一个结点的长度`。
  - 每个节点记录自己的长度，当本节点的值发生了改变，只需要更改自己的长度即可，不再需要更改别的节点的属性，彻底解决掉了级联更新的问题。
- **局限**：由于 ziplist 在 Reids 5.0版本前，内部使用得过于广泛，有一些兼容问题，listpack 替代 ziplist 需要一个逐步替换的过程，所以，在5.0版本中，listpack 只被 Stream 数据结构使用。

##### intset

```c
// 整数集合
typedef struct intset{
    // 编码方法，指定当前存储的是16位，还是32位，还是64位的整数数组
    int32 encoding;
    // 集合中的元素数量
    int32 length;
    // 保存元素的数组，具体是多少位整数的数组，取决encoding的值
    int<T> contents;
}
```

![1631932631768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631932631768.png)

intset，整数集合，用于保存整数值集合的抽象数据结构，可以保存16、32、64位的整数且保证不重复。

- **整数集合升级**：每当一个整数被添加到整数集合时，都需要先去判断 `这个整数 是否大于 当前编码方式所能容放的最大整数`，如果大于，则需要对当前的整数集合进行升级（16 -> 32 -> 64位），同时，将原来的所有整数转换成新的编码。
  - **好处**：
    - **节约内存**：用能容纳数字的最小编码进行存储，可以有效的节约内存。
    - **提升操作的灵活性**：整数集合封装了对三种整数之间的转换，使得不用考虑类型错误，可以不断的向整数集合内添加整数，提升了操作的灵活性。
  - **不能降级**：与升级相对应的，当大的数字被删除之后，整数集合不会进行降级。

##### skiplist

```c
// 跳表
typedef struct zskiplist{
    // 表头结点和尾节点
    struct zskiplistNode *header, *tail;
    // 表中节点的数量
    unsigned int length;
    // 表中层数最大的节点的层数
    int level;
} zskiplist;

// 跳表结点
typedef struct zskiplistNode{
    struct zskiplistLevel{
        // 前进指针
        struct zskiplistNode *forward;
        // 跨度
        unsigned int span;
    } level[];
    // 后退指针
    struct zskiplistNode *backward;
    // 分值
    double score;
    // 成员对象
    robj *obj;
} zskiplistNode;
```

![1631933408583](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631933408583.png)

skiplsit，跳跃表，是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问元素的目的，支持平均`O(log N)`、最坏`O(N)`的节点查找，大部分情况下查找效率可以和红黑树媲美，并且相比红黑树可以更方便地实现并发操作（例如Java中的`ConcurrentSkipListMap`）。

- **跳表结点**：
  - **forward**： 前进指针，可以在当前层，继续向右走。
  - **span**：跨度，可以累加查找路径中的所有跨度，计算出当前结点在跳跃表中的一个排名，比如zset提供查看排名的功能。
  - **backward**：后退指针，如果在向右走的太多了，可以用后退指针来向反向操作。
  - **score & obj**：用于保存当前结点的value值以及分值。
- **层级问题**：
  - **计算方式**：
    - 在 Java 的`ConcurrentSkipListMap`的实现中，索引每一次向上升级或者不升级，都是随机的，一个结点是否是一级索引的概率是 50%，是否是二级索引的概率是 25%...
    - 而在 Redis 中，每新添加一个结点，都会给结点随机一个索引层数，而且概率是 25%，之后将该结点的各层索引与左右的索引相链接，即结点为level 1的概率为 1 - 0.25 = 0.75，level 2的概率为 0.75 * 0.25...
  - 由于level + 1的概率都是25%，Redis跳跃表相对于Java中的跳跃表，结构更加扁平一些，因此：
    - **优点**：Redis索引的数量并不是完全的等同于节点数，额外的内存只占用了50%，可以**节省内存**。
    - **缺点**：Redis在查找的时候，可能需要在同级上**多查询几个索引**。
- **顺序问题**：Redis 除了按照score分值排序之外，还会按照value值的字符串字典顺序来排序。
- **排名问题**：可以累加查找路径中的所有跨度，计算出当前结点在跳跃表中的一个排名，比如zset提供查看排名的功能。

###### skiplist vs 平衡树 vs 哈希表

| 比较点         | skiplist                                                     | 平衡树                                                       | 哈希表                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------- |
| 元素有序性     | 有序                                                         | 有序                                                         | 无序                                           |
| 单值查找       | O（logn）                                                    | O（logn）                                                    | 无哈希冲突时为O(1)                             |
| 范围查找       | 实现简单，只需要 O（logn）定位头尾结点，然后遍历链表即可，缓存局部性比平衡树的要好 | 实现困难，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]    | 只能做单值查找，不适合做范围查找               |
| 插入与删除操作 | 只需要修改相邻结点的指针，简单又快速，并发场景下需要使用volatile修饰指针，效果比平衡树的好 | 可能会引发子树的调整，逻辑复杂，并发场景下需要对根结点进行加锁 | 存在哈希冲突，并发场景下需要对桶头结点进行加锁 |
| 内存占用       | 每个结点平均包含`1/(1-p)`个指针，当p为25%概率时为**1.33**个指针，比平衡树少 | 每个结点平均包含左右子树，共2个指针                          | 无冲突时只有散列表数组                         |
| 缓存友好性     | 由于新结点插入的level是随机的，导致查找路径可能会发生变化，缓存友好性不如平衡树 | 插入新结点后，大部分老结点仍然处于原查找路径上               | 哈希冲突和扩容后，查找路径可能会发生变化       |
| 算法实现难度   | 比平衡树简单                                                 | 典型的有红黑树，实现麻烦                                     | 最简单，不过需要处理哈希冲突                   |

###### 为什么Redis使用skiplist？

- **范围查找效率高**：
  1. 对于 `ZRANGE` 和 `ZREVRANGE` 命令的范围查找，如果使用哈希表，则只能做单值查找，不适合做范围查找。
  2. 如果使用红黑树，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]，效率低且实现复杂。
  3. 而使用 skiplilst 只需要 O（logn）定位头尾结点，然后遍历链表即可，简单又高效，缓存局部性比红黑树的要好。
- **内存占用少**：Redis skiplist 索引的默认生成概率为 25%，即每个结点平均只包含1.33个指针，内存占用比红黑树的 2 个指针要少。
- **实现与调试容易**：使用 skiplist 比红黑树更容易实现与调试。

##### radix tree（5.0版本）

```c
// rax树
typedef struct rax {
    // rax树头节点
    raxNode *head;
    // 元素数量
    uint64_t numele;
    // rax树节点数量
    uint64_t numnodes;
} rax;

// rax树结点
typedef struct raxNode {
    // 表示这个节点是否包含key，0：没有，1:完整路径存储了key
    uint32_t iskey:1;
    // 是否有存储value值，比如存储元数据就只有key，没有value值，value值也是存储在data中
    uint32_t isnull:1;
    // 是否有前缀压缩，决定了data存储的数据结构，0:非压缩模式，1:压缩模式
    uint32_t iscompr:1;
    // 该节点存储的字符个数
    uint32_t size:29;
    // 存储子节点的信息
    unsigned char data[];
} raxNode;
```

![1631944112996](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631944112996.png)

raxid tree，Rax树，即基数树，是一棵有序字典树 ，按照 key 的字典序排列，可以快速地定位、插入和删除操作。

#### 基本类型底层实现

Redis自定义了一个Object系统，其中包含5种Object，每种至少有2种不同的编码，其**对应关系**：

| RedisObject#type | RedisObject#encoding      | 值保存条件                                                   |
| ---------------- | ------------------------- | ------------------------------------------------------------ |
| 字符串类型       |                           |                                                              |
| REDIS_STRING     | REDIS_ENCODING_INT        | long范围内的整数值                                           |
| REDIS_STRING     | REDIS_ENCODING_EMBSTR     | <= 39字节字符串值（3.2版本），<= 44字节字符串值（4.0版本）   |
| REDIS_STRING     | REDIS_ENCODING_RAW        | > 39字节字符串值（3.2版本），> 44字节字符串值（4.0版本）     |
| 哈希类型         |                           |                                                              |
| REDIS_HASH       | REDIS_ENCODING_ZIPLIST    | 键和值的长度都 < 64字节，且键值对个数 < 512个时              |
| REDIS_HASH       | REDIS_ENCODING_HT         | 存在键和值的长度 >= 64字节，或者键值对个数 >= 512个时        |
| 列表类型         |                           |                                                              |
| REDIS_LIST       | REDIS_ENCODING_ZIPLIST    | Redis 3.2版本前，所有元素长度都 < 64字节，且列表元素个数 < 512个时 |
| REDIS_LIST       | REDIS_ENCODING_LINKEDLIST | Redis 3.2版本前，存在元素长度 >= 64字节，或者列表元素个数 >= 512个时 |
| REDIS_LIST       | REDIS_ENCODING_QUICKLIST  | Redis 3.2版本后，列表使用统一格式                            |
| 集合类型         |                           |                                                              |
| REDIS_SET        | REDIS_ENCODING_INTSET     | long范围内的整数值，且集合元素数量 < 512个时                 |
| REDIS_SET        | REDIS_ENCODING_HT         | 存在long范围内的整数值元素，或者集合元素数量 >= 512个时      |
| 有序集合类型     |                           |                                                              |
| REDIS_ZSET       | REDIS_ENCODING_ZIPLIST    | 所有元素长度都 < 64字节，且有序集合元素个数 < 128个时        |
| REDIS_ZSET       | REDIS_ENCODING_SKIPLIST   | 存在元素长度 >= 64字节，或者有序集合元素个数 >= 128个时      |

##### String

| 命令        | 使用                                                  | 作用                                                         |
| ----------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| SET         | set key value [ex seconds] [px milliseconds] [nx\|xx] | 设置value，ex代表设置秒TTL，px代表设置毫秒TTL，nx代表只有键不存在时才设置，xx代表只有键存在时才设置 |
| GET         | get key                                               | 获取value                                                    |
| GETSET      | getset key value                                      | 设置value，并返回旧值                                        |
| SETNX       | setnx key value                                       | 如果key不存在，才新增key和value                              |
| SETEX       | setex key seconds value                               | 设置value，并原子设置TTL为seconds                            |
| PSETEX      | psetex key milliseconds value                         | 设置value，并原子设置TTL为milliseconds                       |
| APPEND      | append key value                                      | 在key值后面追加value                                         |
| STRLEN      | strlen key                                            | 返回key值的字符串长度                                        |
| SETRANGE    | setrange key offset value                             | value覆盖从offset开始的字符串                                |
| GETRANGE    | getrange key start end                                | 返回[start，end]部分的字符串                                 |
| INCR        | incr key                                              | value + 1                                                    |
| INCRBY      | incrby key increment                                  | value + increment                                            |
| INCRBYFLOAT | incrbyfloat key increment                             | value + increment                                            |
| DECR        | decr                                                  | value - 1                                                    |
| DECRBY      | decrby key decrement                                  | value - decrement                                            |
| MGET        | mget key[key...]                                      | 批量获取多个键的值                                           |
| MSET        | mset key value[key value...]                          | 批量设置多个键的值                                           |
| MSETNX      | msetnx key value[key value...]                        | 批量设置多个键的值，仅当所有键都不存在时，才会设置成功       |

###### int

- **值保存条件**：long范围内的整数值。
- **对应编码**：REDIS_ENCODING_INT。

![1631946982581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631946982581.png)

###### embstr

- **值保存条件**：<= 39字节字符串值（3.2版本），<= 44字节字符串值（4.0版本）。
- **对应编码**：REDIS_ENCODING_EMBSTR。

###### raw

- **值保存条件**：> 39字节字符串值（3.2版本），> 44字节字符串值（4.0版本）。
- **对应编码**：REDIS_ENCODING_RAW。

![1631947051873](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631947051873.png)

##### Hash

| 命令         | 使用                                   | 作用                                                         |
| ------------ | -------------------------------------- | ------------------------------------------------------------ |
| HSET         | hset hash field value                  | 把hash#field设置为value                                      |
| HSETNX       | hsetnx hash field value                | 把hash#field设置为value，仅当hash#field不存在时，才会设置成功 |
| HGET         | hget hash field                        | 获取hash#field的value                                        |
| HGETALL      | hgetall hash                           | 获取hash中所有的field和value                                 |
| HEXSITS      | hexists hash field                     | 检查hash#field是否存在                                       |
| HDEL         | hdel hash field[field..]               | 删除hash中一个或者多个field                                  |
| HLEN         | hlen hash                              | 获取hash中field的数量                                        |
| HSTRLEN      | hstrlen hash field                     | 获取hash#field的value长度                                    |
| HINCRBY      | hincrby hash field increment           | 把hash#field设置为value+increment                            |
| HINCRBYFLOAT | hincrbyfloat hash field increment      | 把hash#field设置为value+increment                            |
| HMSET        | hmset hash field value[field value...] | 批量把hash#field设置为对应的value                            |
| HMGET        | hmget hash field[field...]             | 批量获取hash#field的value                                    |
| HKEYS        | hkeys hash                             | 获取hash中所有的field                                        |
| HVALS        | hvals key                              | 获取hash中所有的和value                                      |

###### ziplist

- **值保存条件**：键和值的长度都 < 64字节，且键值对个数 < 512个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631950146881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950146881.png)

###### dict

- **值保存条件**：存在键和值的长度 >= 64字节，或者键值对个数 >= 512个时。
- **对应编码**：REDIS_ENCODING_HT。

![1631950298985](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950298985.png)

##### List

| 命令       | 使用                                  | 作用                                                         |
| ---------- | ------------------------------------- | ------------------------------------------------------------ |
| LPUSH      | lpush key value[value...]             | 把一个或者多个value从表头插入，当key不存在时，会先创建列表再插入元素 |
| LPUSHX     | lpushx key value                      | 把value从表头插入，当key不存在时，则什么也不做               |
| LPOP       | lpop key                              | 移除并返回表头元素                                           |
| RPUSH      | rpush key value[value...]             | 把一个或者多个value从表尾插入，当key不存在时，会先创建列表再插入元素 |
| RPUSHHX    | rpushx key value                      | 把value从表尾插入，当key不存在时，则什么也不做               |
| RPOP       | rpop key                              | 移除并返回表尾元素                                           |
| RPOPLPUSH  | rpoplpush source destination          | 弹出source表尾元素，插入到destination表头，并返回该元素      |
| LREM       | lrem key count value                  | 移除列表count个与value相等的元素，count=0代表移除所有相等的元素；count<0代表从表头开始查找；count>0代表从表尾开始查找 |
| LINSERT    | linsert key before\|after pivot value | 把value插入到pivot前面或者后面，如果没找到pivot，则什么也不做 |
| LINDEX     | lindex key index                      | 获取下标为index的元素（-1代表最后一个元素）                  |
| LSET       | lset key index value                  | 设置index元素为value（-1代表最后一个元素）                   |
| LRANGE     | lrange key start stop                 | 获取列表中[start，stop]区间内的元素                          |
| LTRIM      | ltrim key start stop                  | 剪裁并保留列表中[start，stop]区间内的元素                    |
| BLPOP      | blpop key [key...] timeout            | 阻塞式移除并返回表头元素                                     |
| BRPOP      | brpop key [key...] timeout            | 阻塞式移除并返回表尾元素                                     |
| BRPOPLPUSH | brpoplpush source destination timeout | 阻塞式弹出source表尾元素，插入到destination表头，并返回该元素 |

###### ziplist

- **值保存条件**：Redis 3.2版本前，所有元素长度都 < 64字节，且列表元素个数 < 512个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631952569099](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952569099.png)

###### linkedlist

- **值保存条件**：Redis 3.2版本前，存在元素长度 >= 64字节，或者列表元素个数 >= 512个时。
- **对应编码**：REDIS_ENCODING_LINKEDLIST。

![1631952812216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952812216.png)

###### quicklist

- **值保存条件**：Redis 3.2版本后，列表使用统一格式。
- **对应编码**：REDIS_ENCODING_QUICKLIST。

![1631953074136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631953074136.png)

##### Set

| 命令        | 使用                                 | 作用                                                         |
| ----------- | ------------------------------------ | ------------------------------------------------------------ |
| SADD        | sadd key member [member...]          | 把一个或者多个member加入到集合中，当key不存在时，会先创建列表再添加元素 |
| SISMEMBER   | sismember key member                 | 判断member元素是否为集合的成员                               |
| SPOP        | spop key                             | 移除并返回集合中的一个随机元素                               |
| SRANDMEMBER | srandmember key [count]              | 返回集合中的一个随机元素，count>0，返回集合的子集数组，其元素不重复；count<0，返回含重复元素的数组 |
| SREM        | srem key member [member...]          | 移除集合中一个或者多个member元素，不存在的member元素会被忽略 |
| SMOVE       | smove source destination member      | 把member元素从source集合移动到destination集合中，如果member元素不存在，则什么也不做 |
| SCARD       | scard key                            | 获取集合中元素的数量                                         |
| SMEMBERS    | smembers key                         | 获取集合中所有的成员                                         |
| SINTER      | sinter key [key...]                  | 获取所有给定集合的交集                                       |
| SINTERSTORE | sinterstore destination key [key...] | 获取所有给定集合的交集，并覆盖到destination中                |
| SUNION      | sunion key [key...]                  | 获取所有给定集合的并集                                       |
| SUNIONSTORE | sunionstore destination key [key...] | 获取所有给定集合的并集，并覆盖到destination中                |
| SDIFF       | sdiff key [key...]                   | 获取所有给定集合的差集                                       |
| SDIFFSTORE  | sdiffstore destination key [key...]  | 获取所有给定集合的差集，并覆盖到destination中                |

###### intset

- **值保存条件**：long范围内的整数值，且集合元素数量 < 512个时。
- **对应编码**：REDIS_ENCODING_INTSET。

![1631954240528](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954240528.png)

###### dict

- **值保存条件**：存在long范围内的整数值元素，或者集合元素数量 >= 512个时。
- **对应编码**：REDIS_ENCODING_HT。

![1631954355626](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954355626.png)

##### Zset

| 命令             | 使用                                                         | 作用                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ZADD             | zadd key score member [[score member] [score member] ..]     | 把一个或者多个member及其score加入有序集合中，如果key不存在，则会先创建有序集合再添加元素 |
| ZINCRBY          | zincrby key increment member                                 | 把member#score值+increment                                   |
| ZSCORE           | zscore key member                                            | 获取member#score值                                           |
| ZCARD            | zcard key                                                    | 获取有序集合中元素的个数                                     |
| ZCOUNT           | zcount key min max                                           | 获取有序集合中score在[min，max]之间的元素个数                |
| ZRANGE           | zrange key start stop [withscores]                           | 获取有序集合[start，stop]区间的元素，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序 |
| ZREVRANGE        | zrevrange key start stop [withscores]                        | 获取有序集合[start，stop]区间的元素，返回的元素会按score从大到小进行排序，相等时则再按字典逆序进行排序 |
| ZRANGEBYSCORE    | zrangebyscore key min max [withscores] [limit offset count]  | 获取有序集合中score在[min，max]之间的元素个数，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZREVRANGEBYSCORE | zrevrangebyscore key min max [withscores] [limit offset count] | 获取有序集合中score在[min，max]之间的元素个数，返回的元素会按score从大到小进行排序，相等时则再按字典逆序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZRANK            | zrank key member                                             | 获取member在有序集合中从大到小的排名                         |
| ZREVRANK         | zrevrank key member                                          | 获取member在有序集合中从小到大的排名                         |
| ZREM             | zrem key member [member...]                                  | 移除一个或者多个member，如果member不存在，则会被忽略         |
| ZREMRANGEBYRANK  | zremrangebyrank key start stop                               | 移除有序集合[start，stop]区间的元素，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序 |
| ZREMRANGEBYSCORE | zremrangebyscore key min max                                 | 移除有序集合中score在[min，max]之间的元素个数，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZRANGEBYLEX      | zrangebylex key min max [limit offset count]                 | 获取有序集合[start，stop]区间的元素，仅当有序集合中的元素分数都相同时才有效；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZLEXCOUNT        | zlexcount key min max                                        | 获取有序集合中score在[min，max]之间的元素个数，仅当有序集合中的元素分数都相同时才有效；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZREMRANGEBYLEX   | zremrangebylex key min max                                   | 移除有序集合中score在[min，max]之间的元素个数；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZINTERSTORE      | zinterstore destination numkeys key [key...] [weights weight [weight...]] [aggregate sum | 计算一个或者多个有序集合的交集，再把结果集覆盖到destination中，默认使用sum；sum会统计所有相同成员的score之和，min会取相同成员的最小score，max会取相同成员的最大score，作为该成员结果score |
| ZUNIONSTORE      | zunionstore destination numkeys key [key...] [weights weight [weight...]] [aggregate sum\|min\|max] | 计算一个或者多个有序集合的并集，再把结果集覆盖到destination中，默认使用sum；sum会统计所有相同成员的score之和，min会取相同成员的最小score，max会取相同成员的最大score，作为该成员结果score |

###### ziplist

- **值保存条件**：所有元素长度都 < 64字节，且有序集合元素个数 < 128个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631954526032](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954526032.png)

###### skiplist+dict

- **值保存条件**：存在元素长度 >= 64字节，或者有序集合元素个数 >= 128个时。
- **对应编码**：REDIS_ENCODING_SKIPLIST。

![1631955510770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955510770.png)

##### Stream（5.0版本）

（非网上资料，自己理解可能有差错）

| 命令        | 使用                                                   | 作用                                                         |
| ----------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| XADD        | xadd stream 0-1 field value                            | 添加field-value消息到stream中，0-1为指定的消息id，可以使用*，代表使用redis自增消息ID |
| XLEN        | xlen stream                                            | 获取stream中的消息个数                                       |
| XRANGE      | xrange stream min max                                  | 获取消息ID在[min，max]区间的消息，返回的消息按ID顺序排列；min/max语句中，-表示最x小的消息ID，+表示最大的消息ID |
| XREVRANGE   | xrevrange stream min max                               | 获取消息ID在[min，max]区间的消息，返回的消息按ID逆序排列；min/max语句中，-表示最x小的消息ID，+表示最大的消息ID |
| XREAD       | xread count n streams stream                           | 非阻塞式从stream获取n个消息                                  |
| XREAD BLOCK | xread block count n STREAMS stream                     | 阻塞式从stream获取n个消息                                    |
| XGROUP      | xgroup create stream group $                           | 为stream创建消费组group                                      |
| XREADGROUP  | xreadgroup GROUP group cousumer COUNT n STREAMS stream | consumer消费者从group消费组读取stream消费消息                |
| XACK        | xack stream group id                                   | 确认stream队列group消费组中序号为id的消息                    |
| XPENDING    | xpending stream group min max count                    | 获取stream队列group消费组中ID在[min，max]区间的消息总量      |
| XCLAIM      | xclaim stream group consumer id [id...]                | stream队列group消费组中consumer认领指定id消息的所有权        |
| XAUTOCLAIM  | xautoclaim stream group consumer id[id...]             | stream队列group消费组中consumer自动认领指定id消息的所有权    |
| XINFO       | xinfo STREAM stream                                    | 获取stream状态以及所有消费组的信息                           |
| XTRIM       | xtrim stream MAXLEN\|MINID n                           | MAXLEN，表示剪裁stream并最大保存10个消息；MINID，表示剪裁stream并只保留大于等于ID的消息 |
| XDEL        | xdel stream id                                         | 删除stream队列中指定id的消息                                 |

Redis Stream，消息流类型，底层主要使用了紧凑列表（listpack）和基数树（Rax树）。

- listpack，表示一个字符串列表的序列化，用于存储stream的消息内容。
- raxid tree，Rax树，即基数树，是一棵有序字典树 ，按照 key 的字典序排列，可以快速地定位、插入和删除操作。

![1631955983886](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955983886.png)

### 1.4. Redis Bitmap与布隆过滤器？

#### BitMap

| 命令     | 使用                                                         | 作用                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SETBIT   | set key offset value                                         | 设置offset位置为value（0或1），如果offset不存在，则字符串会自动扩展，空白位置以0填充；如果key不存在，则会先创建一个字符串再设置；时间复杂度为O（1），就跟操作数组一样 |
| GETBIT   | getbit key offset                                            | 获取offset位置的value（0或1），如果offset或者key不存在，则会返回0；时间复杂度为O（1），就跟操作数组一样 |
| BITCOUNT | bitcount key [start] [end]                                   | 计算[start，end]区间内为1的数量，默认计算整个字符串          |
| BITPOS   | bitpos key bit [start] [end]                                 | 获取[start，end]区间内value为bit的位置，默认比较整个字符串   |
| BITOP    | bitop operation destkey key [key...]                         | 对一个或者多个bitmap key进行位操作，最后把结果保存到destkey上；operation为AND代表与，OR代表或，NOT代表非，XOR代表异或 |
| BITFIELD | bitfield key get type offset] [set type offset value] [incrby type offset increment] [overflow wrap\|sat\|fail] | 把整个bitmap看作是一个二进制位数组，可以对指定偏移量的bit进行其他命令操作 |

![1632039188474](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632039188474.png)

Bitmap，位图，基本思想是，用一个bit位来标记某个元素对应的value，而key即是该元素。

##### 优点

由于采用了bit为单位来存储数据，因此，可以**大大节省存储空间**。比如，1G大约只可以存储1.34亿个int数值，但可以存储10.74亿个bit。

##### 使用场景

主要用于**检索大数据量关键字的状态**，比如大数据量的排序、查找、去重，以及登录表等实际场景。

- **大数据量计数排序**：把序列中所有的元素，一个一个等于自身数值的offset中，然后遍历一次bitmap即可拿出所有顺序的序列；如果序列中有重复的元素，则bitmap中元素需要更多bit来存储，以记录该元素一共出现多少次，在后续顺序遍历中，对于这种元素需要重复取多次。
  - **优点**：非比较排序算法，运算效率高；占用内存少。
- **大数据量快速去重**：使用2 bit 来表示元素的3种状态，00代表不存在，01代表出现1次，11代表出现了多次，接着把每个元素放入等于自身数值的offset中（2bit一个单位），最后遍历出每单位为01的数字即可。
- **大数据量快速查找**：把每个元素的2进制值对应存进bitmap中，最后根据bitmap长度对元素长度取余即可，比如int类型的数值，占4个字节，则应该对32取余 n % 32。
- **登录表**：用于记录用户每天的登录情况，可以一个用户一个bitmap，然后当前有登录则在对应天数offset上记为1，否则记为0，最后遍历bitmap，即可拿到该用户每天的登录情况了。

#### 布隆过滤器

Bloom filter，布隆过滤器，基础数据结构是一个bitmap 位图，可以用来判断集合中一个元**素一定不存在**，或者**可能存在**。

##### 优点

运行快速、内存占用小。

##### 缺点

- 对于元素的存在结果有误判，并且随着系统的不断运行，误判率会越来越高，此时可以**定期重建**布隆过滤器。
- 元素一旦存进布隆过滤器中，删除则十分困难，因为可能会删掉其他元素的 bit 结果，此时可以使用额外的删除标记变量进行**逻辑删除**。

##### 实现原理

1. 当一个元素被加入集合时，通过K个散列函数该元素映射成位图中的K个点，同时把这些点都置为1。
2. 在检索时，只要看看这些点是不是都为1，就可以知道该元素是否在集合中。
3. 如果这些点有任何一个为0，则该元素一定不在。
4. 如果这些点都为1，则该元素很可能在，因为散列函数存在哈希冲突，所以布隆过滤器存在对结果的误判。

![1632042655580](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632042655580.png)

##### 使用方式

| 实现方式      | 存储位置 | 优点                                   | 缺点                                                         |
| ------------- | -------- | -------------------------------------- | ------------------------------------------------------------ |
| Guava 实现    | JVM      | 可以减轻 Redis 内存与 I/O 的压力       | 应用有状态，水平复制麻烦，布隆过滤器重启即失效，也不支持大数据量的存储；本地缓存无分布式一致性可言，所以无法应用于分布式场景。 |
| Redisson 实现 | Redis    | 支持分布式场景、可以继续保持无状态应用 | 大量的布隆过滤器查询请求，会增加 Redis 的 I/O 压力，同时布隆过滤器还占用一定的 Redis 内存。 |

###### Guava实现

```java
// 构造布隆过滤器
BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01);
// 将号码10086插入到布隆过滤器中
bloomFilter.put("10086");
// 使用布隆过滤器进行判断
System.out.println(bloomFilter.mightContain("123456"));
System.out.println(bloomFilter.mightContain("10086"));
```

###### Redisson实现

```java
// 构造Redisson
RedissonClient redisson = Redisson.create(config);
// 构造布隆过滤器
RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
// 初始化布隆过滤器：预计元素为100000000L,误差率为3%
bloomFilter.tryInit(100000000L,0.03);
// 将号码10086插入到布隆过滤器中
bloomFilter.add("10086");
// 使用布隆过滤器进行判断
System.out.println(bloomFilter.contains("123456"));// false
System.out.println(bloomFilter.mightContain("10086"));// true
```

##### 使用场景

主要应用于大规模数据下，**不需要精确过滤**的场景，如检查垃圾邮件地址，爬虫URL地址去重，以及解决**缓存穿透**等问题：

###### 白名单 | 解决缓存穿透、开放转载权限

由于布隆过滤器的存在，可以拦截大部分非白名单内的key，基本解决**缓存穿透**问题。

- **执行过程**：

  1. 服务器启动时，会先把所有key加载到布隆过滤器中，然后客户端请求服务器，会先根据key查询布隆过滤器。
  2. 如果布隆过滤器查询结果为true，代表key可能存在白名单中，则查询Redis。
  3. 如果Redis查询结果不为null，说明该key存在缓存中，则直接返回缓存数据，不需要查询数据库了。
  4. 如果Redis查询结果为null，说明该key不存在缓存中，则继续查询数据库。
  5. 如果数据库查询结果不为null，说明该key是合法，且布隆过滤器没有误判，则把数据查询结果存进Redis中，更新缓存后再返回数据。
  6. 如果数据库查询结果为null，说明这个key是个非法的key（根据业务而定），此时按理应该把key从布隆过滤器删掉，但布隆过滤器存在误判，且删除困难，所以这里对其不做处理（业务允许时），最后返回null。

  ![1632043975276](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632043975276.png)

- **注意点**：服务器启动时，需要把所有key都存到布隆过滤器里，不然所有请求都会返回空数据。

- **局限**：布隆过滤器存在误判，会有少量请求穿透到数据库中。

  - **解决方案**：误判的几率很小，问题不大无需处理。

###### 黑名单 | 视频不重复推送

由于布隆过滤器的存在，可以拦截大部分黑名单内的key，而初次不能拦截，因为需要初始化。

- **执行过程**：与白名单类似，但不同的地方在于：

  1. 服务器启动后，布隆过滤器一开始为空，没有任何的key，需要判断到黑名单才会填充进来，而白名单的是必须在服务器启动前全部key都设置完成。
  2. 如果布隆过滤器判断到key不存在时，才允许查询Redis和数据库，而白名单的是存在才允许查询。
  3. 如果数据库查询结果为null，说明这个key是个非法的key（根据业务而定），这时需要填充回布隆过滤器中，待下次布隆过滤器判断时使用，而白名单的是不做任何处理。

  ![1632044944582](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632044944582.png)

- **局限**：

  - 黑名单要很全，不然一开始会存在大量的缓存穿透请求。
    - **解决方案**：在判断为非法key时，加入布隆过滤器的黑名单中。
  - 布隆过滤器存在误判，会有少量正常请求被意外拦截掉，返回空的数据。
    - **解决方案**：业务允许则无需处理，比如视频推送。

### 1.5. Redis事务？

#### 概念

- Redis事务，本质上是一组命令的集合，可以一次执行多个命令，在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会被插入到事务执行命令序列中。
- 总结来说就是，Redis事务是**一次性、顺序性、排他性地执行**一个队列中的一系列命令，整个操作是一个原子操作，事务中的命令要么全部被执行，要么全部都不执行。

#### 事务特性

- **隔离性**：
  - Redis的事务总是具有ACID中的**一致性和隔离性**。
  - 事务是一个单独的隔离操作，事务期间所有命令都会序列化、按顺序地执行，并且在执行的过程中，不会被其他客户端发送来的命令请求所打断。
- **一致性**：Redis的事务总是具有ACID中的**一致性和隔离性**。
- **持久性**：当服务器运行在AOF持久化模式下，并且 `appendfsync` 选项的值为 `always` 时，事务也具有持久性。
  - 如果Redis服务器因为某些原因被管理员杀死，或者遇上某种硬件故障，那么可能只有部分事务命令会被成功写入到磁盘中，这种情况下，Redis在重新启动时发现 AOF 文件出了这样的问题，那么它会退出，并汇报一个错误。
  - 可以使用 `redis-check-aof` 程序可以修复这一问题：它会移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。
- **不保证原子性**：虽然Redis事务操作是一个原子操作，但 EXEC执行过程中，如果有一条命令执行失败，其后的命令仍然会被执行，不会进行回滚，因此不保证事务的原子性。

事务命令

Redis事务功能是通过 `MULTI`、`EXEC`、`DISCARD` 和 `WATCH` 四个原语实现的。

- **MULTI**：用于开启一个事务，它总是返回OK，在 `MULTI` 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当 `EXEC`命令被调用时，所有队列中的命令才会被执行。
- **EXEC**：执行所有事务块内的命令，返回事务块内所有命令的返回值，按命令执行的先后顺序排列；当操作被打断时，返回空值 `nil` 。
- **WATCH** ：是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为，监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控会一直持续到 `EXEC` | `DISCARD` | `UNWATCH` 命令。
- **DISCARD**：调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。
- **UNWATCH**：命令可以取消 `WATCH` 命令对所有key的监控。

| 命令    | 使用               | 作用                                                         |
| ------- | ------------------ | ------------------------------------------------------------ |
| MULTI   | multi              | 开启事务，标记一个事务的开始                                 |
| EXEC    | exec               | 执行事务，一次执行事务内的所有命令，如果事务被打断，则返回nil，否则按顺序返回命令执行结果 |
| DISCARD | discard            | 取消事务，放弃执行事务块内的所有命令                         |
| WATCH   | watch key [key...] | 监视一个或者多个key，如果事务执行前，这些key被其他命令改动，那么事务将会被打断 |
| UNWATCH | unwatch            | 取消watch命令对key的监视，如果该事务执行了exec或者discard命令，则无需unwatch了 |

#### 事务中的错误

- **命令入队前出错**：事务在执行 `EXEC` 命令前，入队的命令可能会出错，比如命令可能会产生语法错误等，或者其他更严重的错误，比如内存不足等。
  - **Redis应对措施**：
    1. 在 Redis 2.6.5 以前， 客户端的做法是，检查命令入队所得的返回值：如果命令入队时返回`QUEUED` ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会**停止并取消**这个事务。
    2. 从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 `EXEC` 命令时，**拒绝执行**并自动放弃这个事务。
- **命令入队后出错**：命令可能在 EXEC 调用之后出错，比如事务中的命令可能处理了错误类型的键：列表命令用在了字符串键上面等等。
  - **Redis应对措施**：在事务中某些命令在 `EXEC` 执行时产生了错误，Redis并不会对它们进行特别处理，而是让其他命令**继续执行**，因而无法保证事务的原子性。

#### 为什么Redis事务不支持回滚？

- **描述**：当事务执行过程中，遇到入队后出错的命令，Redis 并不会进行回滚，而是继续执行其他命令。
- **原因**：
  - **从实用性的角度来说**：入队后出错的命令都是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。
  - **从回滚功能的角度来说**：回滚并不能解决编程错误带来的问题，比如程序员本来想通过 `INCR key` 命令将键的值加上 `1` ， 却不小心调用了两次加上了 `2`，或者对错误类型的键执行了`INCR key`，回滚是没有办法处理这些情况的。
  - 因此，鉴于没有任何机制能避免程序员**自己造成的错误**， 并且这类错误通常不会在生产环境中出现，所以，Redis 选择了更简单、更快速的无回滚方式来处理事务。
- **优点**：由于无需对回滚进行支持，所以 Redis 内部可以保持简单且快速。

### 1.6. Redis key过期机制？

- **永久 key**：在没有指定过期时间的情况下创建，这种 key 将永远存在，除非以明确的方式将其删除，比如使用 `DEL` 命令。

- **可过期 key**：`EXPIRE` 命令，通过增加一些额外的内存成本，为 key 指定一个过期时间，当一个 key 设置了过期时间后，Redis 将确保在指定的时间段过去后，删除这个 key。

- Redis 同时使用 2 种 **key 过期机制**：

  - **被动方式**：当客户端尝试访问某个 key 时，如果发现该 key 已超时，则该 key 才会被动地过期与删除。

    - **对内存不友好**：虽然存在 key 超时后，如果永远没有被访问，那么它就不会被删除，永远地占用着服务器的内存。

  - **主动方式**：Redis 默认每秒 10 次（可在 `hz 10` 中配置），进行以下随机测试：

    1. 在可过期 key 集合中，随机测试 20 个 key。
    2. 删除所有发现已过期的 key。
    3. 如果超过 25% 的 key 都已过期，则继续以上循环。

    => 这意味着在任何时刻，过期 key 所能占用的最大内存 = 每秒新写入 key 所占用的内存之和 / 4，即过期 key 最多只会占用 1/4 的内存。

### 1.7. Redis内存淘汰策略？

- **内存淘汰机制**：使用 Redis，可以方便地在客户端添加新数据时，自动淘汰旧数据。其中，LRU 是 Redis 支持的淘汰方法之一，从 Redis 4.0 版本开始，引入了新的 LFU 淘汰方法。

  - **LRU**：Least Recently Used，最近最少使用淘汰算法，用于淘汰**最长时间没有被访问**的旧数据。
  - **LFU**：Least Frequently Used，最不经常使用淘汰算法，用于淘汰**在一段时间内访问次数最少**的旧数据。

- **内存淘汰策略**：指当达到指定的 `maxmemory` （默认为 0，代表没有限制）内存量时，可以在不同的行为中进行选择需要淘汰的旧数据。

  - 当 `maxmemory` 达到限制时，发生的内存淘汰策略是根据 `maxmemory-policy` 配置来指定的。

  | 策略                     | 作用对象   | 客户端请求发现内存不足时                                     | 适用场景                                            |
  | ------------------------ | ---------- | ------------------------------------------------------------ | --------------------------------------------------- |
  | noeviction               | 全局 key   | 会返回错误                                                   | 常量字典，不能淘汰任何 key 时                       |
  | allkeys-lru              | 全局 key   | 会先尝试删除 LRU key                                         | 热点缓存，需要淘汰非热点 key 时                     |
  | volatile-lru             | 可过期 key | 会先尝试删除 LRU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 热点缓存，需要淘汰非热点 key，又需要保护永久 key 时 |
  | allkeys-random           | 全局 key   | 会随机淘汰 key                                               | 需要以相同概率去淘汰 key 时                         |
  | volatile-random          | 可过期 key | 会随机淘汰 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要以相同概率去淘汰 key ，又需要保护永久 key 时    |
  | volatile-ttl             | 可过期 key | 会先尝试删除剩余 TTL 最短的 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要根据过期时间去淘汰 key 时                       |
  | allkeys-lfu（4.0 版本）  | 全局  key  | 会先尝试删除 LFU key                                         | 需要淘汰访问次数少的 key 时                         |
  | volatile-lfu（4.0 版本） | 可过期 key | 会先尝试删除 LFU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要淘汰访问次数少的 key，又需要保护永久 key 时     |

### 1.8. Redis分布式锁？

当发生高并发访问量激增时，虽然在系统会通过限流、异步、排队等方式优化，但整体的并发还是平时的数倍以上，为了避免并发问题，**防止库存超卖**，给用户提供一个良好的购物体验，这些系统中都会用到锁的机制。

- **背景**：

  - 对于单进程的并发场景，可以使用编程语言及相应的类库提供的锁，如 Java 中的 synchronized 语法以及 ReentrantLock 类等，来避免并发问题。

  ![1632658813782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632658813782.png)

  - 而如果在分布式场景中，实现**不同客户端**的线程对代码和资源的同步访问，保证在多线程下处理共享数据的安全性，就需要用到分布式锁技术。

  ![1632658861088](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632658861088.png)

- **概念**：分布式锁是指，控制分布式系统或者不同系统之间，**共同访问共享资源**的一种锁实现，在不同的系统或者同一个系统的不同主机之间共享了某个资源时，可以用来互斥地防止彼此干扰保证一致性。

- **特性**：

  - **互斥性**：互斥是锁的基本特征，同一时刻锁只能被一个线程持有，执行临界区操作。
  - **超时释放**：通过超时释放，可以避免死锁，防止不必要的线程等待和资源浪费。
  - **可重入性**：一个线程在持有锁的情况下，可以对其再次请求加锁。
  - **高性能和高可用**：加锁和释放锁的过程性能开销要尽可能的低，同时也要保证高可用，防止分布式锁意外失效。

- **实现方式**：

  - **通过数据库方式实现**：基于乐观锁和唯一索引实现。
  - **基于分布式缓存实现**： 基于 Memcached、Redis 单机、Redisson 和 Redis RedLock 实现。
  - **基于分布式一致性算法实现**：基于ZooKeeper、Chubby（google闭源实现）和 Etcd 实现。

#### 基于数据库实现 | 负担大

##### 基于乐观锁实现

- **原理**：根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。

##### 基于唯一索引实现

- **原理**：数据库建立唯一索引，当想要获得锁时，向数据库中插入一条记录，释放锁时则删除这条记录。
- **存在的问题**：
  1. 锁没有失效时间，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
  2. 只能是非阻塞锁，insert 失败直接就报错了，无法进入队列进行重试。
  3. 不可重入，同一线程在没有释放锁之前无法再获取到锁。

#### 基于分布式缓存实现 | 锁失效

##### 基于 Memcached 实现

- **原理**：利用 Memcached 的 `add` 命令，由于该命令原子性操作，只有在 key 不存在的情况下，才能 add 成功，也就意味着同一时刻只有一个线程获得锁。

##### 基于 Redis 单机实现

###### 1、使用 setnx 指令

- **原理**：

  ```shell
  setnx key value
  	do do something
  del key
  ```

- **存在的问题**：do something 有问题，锁一直不会释放，因此需要增加锁的过期时间。

###### 2、使用 setnx+expire 指令

- **原理**：

  ```shell
  setnx key value
  expire key 10
  	do do something
  del key
  ```

- **存在的问题**：`setnx` 与 `expire` 不是一个原子操作，如果在执行 `setnx` 和 `expire`  之间发生异常，`setnx` 执行成功，但 `expire` 没有执行，则会导致这把锁在长期存在，导致其他进程无法正常获取锁。

###### 3、使用 set 扩展指令

- **原理**：

  ```shell
  set key value NX EX 10
  	do something
  del key
  ```

- **存在的问题**：如果 do something 耗时过长，会出现锁被提前释放，甚至被别的进程误删。

- **解决方案**：

  1. do something 部分不要做过长时间的处理，但还是可能存在 STW 的停顿风险。
  2. 释放锁时，需要验证锁的持有者是否是自己。

###### 4、释放前判断值是否改变

- **原理**：

  ```shell
  set key random_value nx ex 10 # 加锁
  	do something
  if random_value == key.value  # 判断 value
  	del key 			      # 删除 key
  ```

- **存在的问题**：判断 value 和删除 key 两个操作不能保证原子性。

- **解决方案**：需要使用 Lua 脚本进行处理，因为 Lua 脚本可以保证连续多个指令的原子性执行。

###### 5、使用 lua 脚本

- **原理**：

  ```lua
  if redis.call("get", KEY[1]) === ARGV[1] then
      return redis.call("del", KEY[1])
  else 
      return 0
  end
  ```

- **存在的问题**：还是会出现，由于时钟漂移 或者 do something 耗时过长，导致的锁被提前释放，甚至被别的进程误删的问题。

- **解决方案**：锁租期续约。

##### 基于 Redisson 实现

Redisson，是一个在 Redis 的基础上实现的 Java 驻内存数据网格，是一个分布式、可扩展的 Java 数据结构。

- **原理**：
  1. 让获得锁的线程开启一个定时器的守护线程，每 expireTime/3 执行一次，去检查该线程的锁是否存在。
  2. 如果存在，则对锁的过期时间重新设置为 expireTime，即利用守护线程对锁进行**续约**，防止锁由于过期提前释放。
  3. 对于Redis 多机环境的分布式锁，Redisson 也提供了 Red Lock的算法实现。

##### 基于 Redis RedLock 实现

- **背景**：基于 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 的复制是异步的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下发生故障转移，此时其他客户端上的线程依然可以获取到锁，因此会丧失锁的安全性。
- **原理**：
  1. 获取当前 Unix 时间 `t1`，以毫秒为单位。
  2. 按顺序依次尝试从 5 个实例使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁自动失效时间 `expire`，客户端还应该设置响应超时时间 `timeout`，且这个超时时间 < 锁的失效时间 `expire` 。
     1. 比如锁自动失效时间 `expire` 为10秒，则超时时间 `timeout` 应该在5-50毫秒之间。
     2. 这样可以避免服务器端 Redis 已经挂掉的情况下，客户端还在一直等待响应结果，使得在服务器端没有在规定时间内响应时，客户端可以尽快尝试去另外一个 Redis 实例请求获取锁。
  3. 客户端使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从大多数（N/2+1，这里是3个节点）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` < 锁失效时间 `expire`时，锁才算获取成功。
  4. 如果取到了锁，key 的真正有效时间 `real_expire` 等于锁失效时间 `expire  `减去锁花费的总时间 `T`。
  5. 如果因为某些原因，获取锁失败（没有在至少N/2+1个 Redis 实例取到锁，或者取锁时间已经超过了锁失效时间 `expire），客户端应该在所有的 Redis 实例上使用 Redis Lua 脚本进行解锁。
     1. 原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端向服务器通信是正常的，但反方向却是有问题的。
     2. 虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功。
     3. 因此，释放锁的时候，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起请求。
     4. 除此之外，为了避免 Redis 节点发生崩溃重启后造成锁丢失，从而影响锁的安全性，Redis 官方还提出了**延时重启**的概念，即一个节点崩溃后不要立即重启，而是等待一段时间后再进行重启，这段时间应该大于锁失效时间 `expire  `。
- **局限**：
  - **性能过重**：使用 RedLock 维护那么多的Redis实例，提升了系统的维护成本。
  - **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生错误，会导致它持有的锁提前过期然后被释放，因此，RedLock 还是不能保证锁的安全性。

##### Redis 分布式锁总结

- **存在的问题**：
  - **客户端长时间阻塞导致锁失效问题**：比如执行业务时间过长，或者发生了 STW。
    - **解决方案**：锁租期续约，在锁有效时间内，异步启动另外一个线程去检查的问题，判断这个 key 是否超时，如果锁超时时间快到期且逻辑未执行完，则延长锁超时时间。
  - **服务器时钟漂移问题导致同时加锁**：由于 Redis 的过期时间是依赖系统时钟的，如果时钟漂移过大时，理论上是可能出现的会影响到过期时间的计算。
    - **解决方案**：根据时间来自动释放的分布式锁，都没办解决这个问题。
  - **单点实例故障，锁未及时同步导致锁丢失**：
    1. 虽然使用 RedLock 算法，可以通过多节点来防止 Redis 的单点故障，但效果一般，且仍然无法防止在**主从切换**导致的两个客户端同时持有锁的发生。
    2. 但在大部分情况下，主从切换持续时间极短，RedLock 会在切换的瞬间获取到节点的锁，虽然也是有问题发生的可能，但这已经是极低的概率了，无法避免。
    3. 因此，Redis 分布式锁适合**幂等性**事务，如果一定要保证安全，应该使用 Zookeeper、ETCD 或者 DB，但是，锁的性能会急剧下降。

#### 基于分布式一致性算法实现 | 强一致

##### 基于 Zookeeper 实现

Zookeeper，是一个为分布式应用提供一致性服务的软件，它内部是一个分层的文件系统目录树结构，规定统一个目录下**只能有一个唯一文件名**。

- **概念**：
  - **数据模型**：
    - **永久结点**：结点创建后，不会因为会话失效而消失。
    - **临时结点**：与永久结点相反，如果客户端连接失效，则立即删除结点。
    - **顺序结点**：与上述两个结点特性类似，如果指定创建这类结点时，ZK 会自动在结点名后加一个数字后缀，并且是有序的。
  - **监视器**：watcher，当创建一个节点时，可以注册一个该结点的监视器，当节点状态发生改变时，watcher 被触发时，ZooKeeper 会向客户端发送且仅发送一条通知（因为 watcher 只能被触发一次）。
- **原理**：
  1. 创建一个锁目录 lock。
  2. 希望获得锁的线程 A 就在 lock 目录下，创建**临时顺序结点**。
  3. 先获取锁目录下所有的子结点，再获取比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则 线程 A 获得锁。
  4. 接着，线程 B 获取所有结点，判断自己不是最小的结点，此时发现存在有更小的线程 A 的结点，则设置监听器 watcher，只监听比自己次小的结点 A（为了防止发生**羊群效应**）。
     - **分布式中的羊群效应**：也称惊群效应，指在分布式系统中，比如Zokeeper集群中，当某一结点 A 被大量 Client 进行Watch 时，当结点 A 发生变化时，可能只会对某一个 Client 有影响，但是由于所有 Client 都对该结点进行了 watch，其他没有影响的 Client 也会受到通知，因此，对于产生了这种**不必要的通知**就是分布式中的羊群效应。
  5. 当线程 A 处理完业务，会删除结点 A，释放掉，然后线程 B 监听到变更事件，判断到自己是最小的结点，成功获得锁。

##### 基于 Chubby 实现

- **原理**：Google 公司实现的**粗粒度**分布式锁服务，有点类似于 ZooKeeper，但也存在很多差异，通过 sequencer 机制解决了**请求延迟**造成的锁失效的问题。

##### 基于 Etcd 实现

- **概念**：
  - **Lease 机制**：租约机制，Etcd 可以为存储的 KV 对设置租约，当租约到期，KV 将失效删除，同时支持续约，即 KeepAlive。
  - **Revision 机制**：
    1. 每个 key 带有一个 Revision 属性值，Etcd 每进行一次事务对应的全局 Revision 值都会加 1。
    2. 因此，每个 key 对应的 Revision 属性值都是全局唯一的，通过比较 Revision 的大小就可以知道进行写操作的顺序。
    3. 在实现分布式锁时，多个程序同时抢锁，根据 **Revision 值大小**依次获得锁，可以避免**羊群效应**，实现公平锁。
  - **Prefix 机制**：前缀机制，也称目录机制，可以根据前缀（目录），来获取该目录下所有的 key 及对应的属性（包括 key, value 以及 revision 等）。
  - **Watch 机制**：监听机制，Watch 机制支持 Watch 某个固定的 key，也支持 Watch 一个前缀（目录），当被 Watch 的 key 或目录发生变化，客户端将收到通知。
- **原理**：
  1. **准备 key**：客户端连接 Etcd，以 `/lock/mylock` 为前缀创建**全局唯一**的 key。
     - 假设第一个客户端对应的 key="/lock/mylock/UUID1"，第二个为 key="/lock/mylock/UUID2"，客户端分别为自己的 key 创建租约 Lease，租约的长度根据业务耗时确定，假设为 15s；
  2. **写入 key**：进行 put 操作，将步骤 1 中创建的 key 绑定租约写入 Etcd，根据 Etcd 的 Revision 机制，假设两个客户端 put 操作返回的 Revision 分别为 1、2，客户端需记录 **Revision** 用以接下来判断自己是否获得锁。
  3. **获取锁**：
     1. 客户端以前缀 `/lock/mylock` 读取 keyValue 列表，其中 keyValue 中会带有 key 对应的 Revision。
     2. 接着判断自己 key 的 Revision 是否为当前列表中**最小**的，如果是则认为获得锁。
     3. 否则，需要监听列表中前一个 Revision 比自己小的 key 的**删除事件**，一旦监听到删除事件，或者因租约失效而删除的事件，则自己获得锁。
  4. **执行业务**：获得锁后，操作共享资源，执行业务代码。
  5. **心跳续约**：
     1. 当一个客户端持有锁期间，其它客户端只能等待，为了避免等待期间租约失效，持有锁的客户端需创建一个定时任务，作为**心跳**进行续约。
     2. 如果持有锁期间客户端崩溃，心跳停止，key 将因**租约到期**而被删除，从而锁释放，**避免死锁**。
  6. **释放锁**：完成业务流程后，删除对应的key释放锁。

#### 分布式锁总结

- **数据库锁**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：分布式系统大多数瓶颈都在数据库，使用数据库锁会增加数据库负担。
- **分布式缓存锁**：
  - **优点**：性能高，实现起来较为方便，在**允许偶发的锁失效**情况，不影响系统正常使用，建议采用分布式缓存锁。
  - **缺点**：通过锁超时机制不是十分可靠，当线程获得锁后，处理时间过长导致锁超时，就失去了锁的作用。
    - 当业务必须要数据的强一致性，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下请不要使用分布式缓存锁，此时可以使用 CP 模型实现，比如Zookeeper 和 Etcd。
- **分布式一致性算法锁**：
  - **优点**：不依靠超时时间释放锁，可靠性高，当系统要求高可靠性时，建议采用分布式一致性算法锁。
  - **缺点**：性能比不上分布式缓存锁，因为无论是 Zookeeper 还是 Etcd，都需要频繁的创建和删除结点。

|            | Redis    | Zookeeper                       | Etcd                            |
| ---------- | -------- | ------------------------------- | ------------------------------- |
| 一致性算法 | 弱一致性 | Paxos（ZAB）                    | Raft                            |
| CAP        | AP       | CP                              | CP                              |
| 高可用     | 主从集群 | n+1（保证奇数，过半存活即可用） | n+1（保证奇数，过半存活即可用） |
| 实现       | setnx    | createNode                      | restfulAPI                      |

### 1.9. Redis持久化？

持久化，就是把内存中的数据，持久化到本地磁盘中，防止服务器宕机了内存数据丢失。

- Redis 提供两种持久化机制 **RDB（默认）** 和 **AOF**，Redis 4.0 以后采用混合持久化，用 AOF 来**保证数据不丢失**，作为数据恢复的第一选择，用 RDB 来做不同程度的**冷备**。

#### RDB

RDB，Redis DataBase，是Redis**默认**的持久化方式，Redis 会按照一定的时间间隔，将内存的数据以**时间点快照、二进制**的形式保存到磁盘中。

##### 特点

- 只会产生一个数据文件，为dump.rdb。
- 可以通过配置文件中的 `save` 参数，来定义快照生成周期。

##### 生成方式

- **`SAVE` 命令**：会阻塞当前 Redis 主线程，直到持久化完成。线上应该禁止使用，要使用也需要先明确时间点，再关机维护。
- **`BGSAVE` 命令**：
  1. Redis 调用 `fork（） `一个子进程，同时拥有父进程和子进程。
  2. 父进程继续处理其他命令，子进程负责持久化过程，将数据集写入到一个临时 RDB 文件中。
     - **写时复制**：Copy On Write，COW，指的是，为了节约物理内存，操作系统在调用 `fork()` 生成子进程时，子进程与父进程会**共享同一内存区域**，只有当其中父子中任意一个进程进行写操作时，操作系统才会为其另外分配内存页面。其中，子进程与父进程是两个独立的进程，在父进程结束后，子进程并不会结束，而是会被 `init` 进程托管。**原理如下**：
       1. 当进程 A 使用系统调用 `fork()` 创建一个子进程 B 时，由于子进程 B 实际上是父进程A的一个拷贝，因此会拥有与父进程相同的物理页面。
       2. 为了节约内存和加快创建速度的目标，`fork()` 函数会让子进程 B 以**只读方式**共享父进程A的物理页面，同时，也将父进程 A 对这些物理页面的访问权限设置成**只读**。
       3. 这样，当父进程 A 或子进程 B 任何一方对这些已共享的物理页面执行写操作时，都会产生页面出错异常 `page_fault int14` 中断，此时 CPU 会执行系统提供的异常处理函数`do_wp_page()` 来解决这个异常。
       4. `do_wp_page()` 会对这块导致写入异常中断的物理页面进行**取消共享操作**，为写进程复制一新的物理页面，使父进程 A 和子进程 B 各自拥有一块内容相同的物理页面。
       5. 最后，在从异常处理函数中返回后，CPU会重新执行刚才导致异常的写入操作指令，使陷入异常的进程继续执行下去。
     - **Redis 与写时复制**：根据 Copy On Write 技术可知， `fork()` 操作并不会导致生成 RDB 时内存的暴涨。
       1. 因为只有父进程发生写操作修改内存数据时，才会真正去给子进程分配内存空间，并只是复制父进程中被修改过的内存页中的数据，并不是全部的内存数据。
       2. 对于那些没有写操作的数据，子进程会共享父进程同一段内存。
       3. 因此，`fork()` 操作是不会导致内存暴涨的。
  3. 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。

##### 生成周期配置

save参数。

```shell
# 900秒（15分钟）内数据集至少有1个改动
save 900 1
# 300秒（5分钟）内数据集至少有10个改动
save 300 10
# 60秒（1分钟）内数据集至少有10000个改动
save 60 10000
```

##### 其他参数

```shell
# save、bgsave期间，如果出错，是否停止继续生成RDB
# yes：停止
# no：不停止，但可能会造成数据不一致
stop-writes-on-bgsave-error

# 是否压缩RDB文件
# yes：开启
# no：关闭，可以节省CPU消耗，但可以减小RDB大小
rdbcompression

# 是否校验RDB文件
# yes：使用CRC 64算法对RDB数据进行校验，但会有10%左右的性能损耗
# no：不校验
rdbchecksum
```

##### 优点

- **适合备份**：RDB 保存了 Redis 在某个时间点上的数据集，非常适合用于备份。
- **适合灾备**：RDB 只有一个文件，并且内容都非常紧凑，可以远程传输到别的数据中心，灾备简单，非常适用于灾难恢复。
- **影响 Redis 性能小**：RDB 可以最大化减少对 Redis 性能的影响，在保存 RDB 文件时，父进程唯一要做的就是 `fork` 出一个子进程，然后交由子进程处理接下来所有的保存工作，父进程无须执行任何磁盘 I/O 操作，从而可以保证主进程继续处理命令，RDB 时只存在毫秒级不响应请求。
- **恢复速度快**：RDB 相对 AOF 来说，在恢复大数据集时，速度比 AOF 的恢复速度要快。

##### 缺点

**数据安全性低**，RDB 是间隔一段时间进行持久化，如果间隔前进，Redis 发生故障，则会发生数据丢失。

#### AOF

AOF，Append Only File，记录 Redis 服务器执行的所有**写操作命令**，并在服务器启动时，通过重新执行这些命令来还原数据集。

##### 特点

- AOF 文件中的命令，会全部以 Redis 协议的格式来保存，新命令会被**追加**到文件的末尾。 
- 可以在后台对 AOF 文件进行**重写**，使得 AOF 文件的体积，不会超出保存数据集状态所需的实际大小。

##### 写入与同步参数

```shell
# AOF默认关闭，yes可以开启
appendonly no
# AOF的文件名
appendfilename "appendonly.aof"

#appendfsync always
appendfsync everysec
#appendfsync no
```

- **appendfsync always**：命令写入 aof_buf 后，直接调用系统的 `fsync` 操作同步到 AOF 文件中，真正的把指令写入了磁盘中。
  - **aof_buf**：AOF 缓冲区，打开 AOF 开关后，每次执行完一个写命令后，都会把写命令以 Redis 协议的格式保存到 aof_buf 缓冲区中。
  - **特点**：由于 AOF 每次都会同步落盘，所以优点是**数据不会丢失**，缺点是**效率低**。
- **appendfsync everysec**：命令写入aof_buf 后，调用系统的 `write` 操作，把 aof_buf 缓冲区的内容写入到 AOF 文件中， 然后在`write` 操作完成后返回；而`fsync` 同步 AOF 文件的操作，将由专门的线程每秒调用一次。
  - **特点**：对 always 和 no 方案，在**数据安全性**和**性能**上做了折衷。
- **appendfsync no**：命令写入 aof_buf 后，调用系统的 `write` 操作，把 aof_buf 缓冲区的内容写入到 AOF 文件中，然后在`write` 操作完成后返回；不对 AOF 文件做 `fsync` 同步操作，交由操作系统负责。
  - **操作系统同步条件**：缓冲区被填满，或者，超过了同步周期限制，通常同步周期限制最长为30秒。
  - **特点**：与 always方案相反，是另一个极端，这种方案由于 Redis 不保证 AOF 的落盘，所以保证不了数据安全性。

![1632132586785](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632132586785.png)

##### 备份流程

1. 处理客户端**写命令**请求，处理完毕后，响应客户端请求。
2. 接着处理时间事件，Redis 将 `serverCron` 作为时间事件运行，定期自动运行一次，比如尝试进行 AOF 或者 RDB 持久化等操作。
3. 然后判断是否打开 `appendonly`，如果为是，则把**写命令**写入 aof_buf 缓冲区，并根据 `appendfsync` 策略同步到磁盘中；如果为否，则结束 AOF 备份流程。

![1632135630382](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632135630382.png)

##### 重写流程

```shell
# AOF重写机制的触发参数：
# 当前AOF文件的大小是上次AOF大小的100%，且文件体积达到64m时，则触发AOF重写
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

```

1. 当前 AOF 文件的大小是上次 AOF 文件大小的100%，且文件体积达到 64m时，则触发 AOF 重写；或者显示调用 `BGREWRITEAOF` 命令，也会触发 AOF 重写。
2. 此时，Redis 执行 `fork()` ，同时拥有父进程和子进程。
3. 子进程开辟 AOF 重写缓冲区，并开始执行 AOF 重写，根据 `fork()`写时复制机制，子进程只能共享 `fork()`时的内存数据，此时子进程会根据内存快照，按照**命令合并规则**把重写后的命令写入到新 AOF 文件。
4. 父进程继续处理其他命令，对于所有新执行的写入命令，父进程一边把这些改动，追加到旧 AOF 文件的末尾，并根据 `appendfsync` 策略同步到磁盘中，一边把它们累积到重写缓冲区中，这样即使在重写的中途发生了停机，旧 AOF 文件也还是安全的。
5. 当子进程完成重写工作时，会给父进程发送一个信号，父进程在接收到信号之后，阻塞服务器进程，拒绝所有命令，同时把重写缓冲区中的所有数据，追加到新 AOF 文件的末尾。
6. 最后原子地用新 AOF 文件替换旧 AOF 文件，再恢复服务器进程，之后所有命令都会追加到新 AOF 文件的末尾，完成一次 AOF 的重写。

![1632138509700](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632138509700.png)

##### 还原流程

1. Redis 服务启动时，会先创建 Fack Client 伪客户端，该客户端不会发送网络请求，只是用来读取 Redis 配置文件。
2. 接着判断 AOF 文件中是否存有数据，如果没有，则结束 AOF 还原流程。
3. 如果有，则分析、读取、执行 AOF 文件中的每一条指令，直到 AOF 中的指令全部被执行完毕后，则结束 AOF 还原流程。
4. Redis 还可以同时使用 AOF 和 RDB 持久化，在这种情况下，会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集，通常比 RDB 文件所保存的数据集更完整。

![1632138046711](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632138046711.png)

##### 优点

- **持久化实时性好**：AOF 可以根据不同的 fsync 策略来持久化，默认为 `always`，表示每秒钟 fsync 一次，Redis 仍然可以保持良好的性能，就算发生故障停机，最多也只是丢失一秒钟的数据。
- **顺序写，写入效率高**：AOF 文件是一个只进行追加操作的日志文件， 对 AOF 文件的写入不需要进行 seek，顺序写即可，所以写入效率高。
- **AOF重写**：Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的**最小命令集合**。 
- **简单易懂**：AOF 文件写入的命令，会以 Redis 协议的格式进行保存， 其内容非常容易被人读懂， 对文件进行分析会比较轻松。 

##### 缺点

- **体积较大，恢复速度慢**：对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积，且恢复速度也会比 RDB 的慢。
- **可能会影响 Redis 性能**：针对不同的同步机制，AOF 会比 RDB 慢，由于 AOF 每秒都会备份做日志写操作，这样相对比 RDB 来说，性能就略低，比如每秒备份 fsync，如果客户端每秒的写入都做一次 fsync 备份的话，那么 Redis 的性能就会下降。

#### RDB & AOF如何选择？

|                        | RDB                                           | AOF                                                  |
| ---------------------- | --------------------------------------------- | ---------------------------------------------------- |
| 文件内容               | 全量的二进制数据                              | 按Redis 协议格式保存的写命令                         |
| 文件体积               | 较小                                          | 较大，同时提供 AOF 重写                              |
| 数据恢复速度           | 快                                            | 慢                                                   |
| 对Redis 性能的影响程度 | 子进程备份时间间隔较远，对 Redis 性能影响较小 | 如果子进程每秒都做 AOF 同步，则对 Redis 性能影响较大 |
| 适用场景               | 按照时间间隔备份，适合冷备                    | 实时性好，适合热备                                   |

##### 仅使用 RDB

如果可以承受一段时间内的数据丢失， 那么可以只使用 RDB 持久化。

##### 仅使用 AOF

**不推荐**，因为定时生成 RDB 快照非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外，使用 RDB 还可以避免之前 AOF 程序的 bug 。

- AOF 在过去曾经发生过这样的 bug： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样，比如阻塞命令 `BRPOPLPUSH` 。
- 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。

##### 同时使用 AOF 和 RDB

如果对实时性数据比较关心，则应该同时使用两种持久化功能。

1. 使用 RDB 和 AOF 结合一起做持久化，**RDB 做冷备**，可以在不同时期对不同版本做恢复， **AOF 做热备**，保证数据仅仅只有1秒的损失。
2. 当 AOF 破损不可用时，那么再用 RDB 恢复，这样就做到了两者的相互结合，也就是说 Redis 恢复会先加载 AOF，当 AOF 有问题时再加载 RDB，从而达到**冷热备份**的目的。
   - **冷备份**：一般发生在数据库已经正常关闭的情况下，当正常关闭时，会提供给我们一个完整的数据库，但冷备份的数据往往不够实时。
   - **热备份**：是在数据库运行的情况下，采用archivelog mode（归档日志模式）方式备份数据库的方法，其备份的数据具有很好的实时性。
   - **冷热备份**：在发生问题时，如果同时存在一个冷备份和不久的热备份文件，那么就可以利用这些资料来恢复更多的信息。

### 2.0. Redis数据分区？

![1632400451957](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632400451957.png)

#### 分区概念

在Redis中，数据分区（分片），是一种在多个 Redis 实例之间拆分数据的技术，将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。

#### 分区优点

- **带宽与算力的提升**：单机 Redis 的网络 I/O 能力和计算资源都是有限的，把请求分散到多台机器，可以充分利用多台机器的计算能力与网络带宽，有助于提高 Redis 总体的服务能力。
- **内存的横向扩展**：即使 Redis 的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的内存，把数据分散到多台机器上存储，使得 Redis 内存可以横向扩展。

#### 分区缺点

- **不支持跨实例的命令与事务**：涉及多个 key 的操作通常不会被支持，比如不能直接使用交集指令来对两个集合求交集，因为这些 key 可能被存储到不同的 Redis 实例中，同理，操作多个key时也不能使用Redis事务。
- **大 Key 数据集无法再分片**：由于是基于 key 进行数据分区的，因此无法使用单个大 key 对数据集进行分区，比如一个很大的排序集或列表，只能作为一个 key 存储进一个 Redis 实例中，而不能对其再分片。
- **备份管理要复杂得多**：数据分区后，如果需要对数据进行备份，则必须从不同的 Redis 实例同时收集 RDB 和 AOF 文件。
- **扩缩容时可能需要对数据再平衡**：数据分区后，在集群运行时增加或者删除 Redis 节点，对于散列分区方式，需要对数据进行再平衡，使用预分片可以较好地解决这个问题。
  - **预分片**：可以在刚开始时就开启多个 Redis 实例，比如 32 或 64 个实例来作为我们的工作集群，当一台物理机器内存不够时，可以把其中一些实例移动到第二台存储更大的物理机上，这样就可以保证在集群Redis 实例数不变的情况下，又达到了扩充机器内存的目的。

#### 分区方案

##### 范围分区

- **特点**：将分片规则对象范围映射到 Redis 实例。
  - 比如，从 ID 0到 ID 10000的用户将进入实例 R0，而从 ID 10001到 ID 20000的用户将进入实例 R1 等。
- **优点**：
  - **简单有效**。
  - **分片可顺序访问**：使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。
- **缺点**：
  - **数据分散度容易倾斜**：容易出现某分片过热的问题，即切分后热点数据可能都落在同一分片上，成为系统性能的瓶颈。
  - **需要管理映射表**：每种分片规则对象都需要管理一个将范围映射到 Redis 实例的表，对比其他分区方案效率低得多，因此，Redis 中的范围分区通常是不可取的。

##### 哈希分区

- **特点**：采用 hash 取模的切分方式。
  1. 获取 Key 并使用散列函数（比如 `crc32` 散列函数）将其转换为数字值。
  2. 对这个数字值使用模运算，将它转换成一个 0 到 3 之间的数字，映射到 4个 Redis 实例的其中一个。
- **优点**：**数据分散度高**：不容易出现热点和并发访问的瓶颈。
- **缺点**：**分片无法顺序访问**：容易面临跨分片查询的复杂问题。

###### 节点取余 | 数据迁移率大

![1632448521969](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632448521969.png)

- **概念**：hash（key）% node。
- **优点**：简单。
- **缺点**：数据迁移率大，当节点数量变化时，数据节点的映射关系需要重新计算，会导致数据的重新迁移。
  - **翻倍扩容**：扩容时通常采用翻倍扩容，可以避免数据映射被全部打乱，导致全量迁移的情况。
  - **一致性哈希**：可以减小影响的范围。
- **适用场景**：常用于数据库的分库分表规则，**不推荐**用于 Redis 数据分区。
  - 一般采用预分区的方式，提前根据数据量规划好分区数，比如提前划分为 512 或 1024 张表，保证可支撑未来一段时间的数据容量，再根据负载情况将表迁移到其他数据库中。

###### 一致性哈希 | 数据不均匀

![1632447059227](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632447059227.png)

- **概念**：hash（key） + 顺时针优化取余。
  1. 一致性 Hash 可以很好的解决稳定问题，可以将所有的存储节点排列在**首尾相接**的 Hash 环上。
  2. 每个key 在计算 Hash 后，会**顺时针**找到遇到的第一组存储节点来存放。
  3. 而当有节点加入或退出时，仅影响该节点在 Hash 环上顺时针相邻的后续节点，将数据从该节点接收或者给予。
- **优点**：加减节点只影响 Hash 环中顺时针方向的相邻节点，对其他节点无影响。
- **局限**：
  - **数据不均匀**：在节点太少时，容易出现节点分布不均匀，从而导致数据倾斜。
  - **数据未命中**：增加节点时，会造成 Hash 环中部分数据无法命中，需要进行手动处理。
  - **数据有迁移**：虽然只影响邻近节点，但仍然有数据迁移。
  - **需翻倍扩容**：在加减节点时，需要增加一倍或者减少一半，才可以保证数据和负载的均衡。
- **适用场景**：当使用少量节点时，节点变化将大范围影响 Hash 环中的数据映射，且容易出现数据倾斜，因此，一致性哈希只适合**数据节点较多**的分布式方案。

###### 虚拟槽分区 | 数据可均匀分配

![1632450278219](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632450278219.png)

- **概念**：使用分散度良好的哈希函数，把所有数据映射到一个**固定范围**的整数集合中，每一个节点负责维护一部分槽以及该槽所映射的数据。
  - 把这个范围的整数定义为**槽**（slot），其范围一般远远大于节点数，比如 Redis Cluster 槽范围是 0 ~ 16383。
- **优点**：
  - **容易扩缩容**：因为解耦了数据和节点之间的关系，降低了节点扩缩容的难度。
    1. 如果增加一个节点 6，就需要从节点 1 ~ 5 获得部分槽分配到节点 6 上。
    2. 如果想移除节点 1，需要将节点 1 中的槽移到节点 2 ~ 5 上，然后将没有任何槽的节点 1 从集群中移除即可。
  - **数据可均匀分配**：由于槽位范围固定，选用合适的算法，可以将数据均匀分配。
- **适用场景**：比如 Redis Cluster。

#### 分区实现

##### 客户端分区

- **概念**：key 在 Redis 客户端就决定了要被存储在哪个 Redis 实例中。
- **实现**：Redis Cluster（客户端分区与查询路由分区的混合体）、Redis-rb、Predis 和 Jedis 等。

![1632451244550](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451244550.png)

##### 代理辅助分区

- **概念**：
  - 客户端将请求发送到能够使用 Redis 协议的代理，而不是直接将请求发送到正确的 Redis 实例。
  - 该代理将确保根据配置的分区模式，把请求转发到正确的 Redis 实例，并将回复发送回客户端。
- **实现**：
  - **Twemproxy**：Twitter 开源，轻量级，是客户端和 Redis 实例之间的中间层，支持在多个 Redis 实例之间自动分区，无法平滑地扩缩容，性能一般，在 Redis Cluster出现后便不再维护。
  - **Codis**：豌豆荚开源，支持水平拓展，运维平台完善，性能较 Twemproxy 快，在国内使用的较多，在 Redis Cluster出现后便不再维护。

![1632451320936](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451320936.png)

##### 查询路由分区

- **概念**：把查询发送到随机 Redis 实例，该实例会确保该查询转发到正确的 Redis 节点。
- **实现**：Redis Cluster（客户端分区与查询路由分区的混合体）。

![1632451413068](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451413068.png)

### 2.1. Redis高可用架构？

#### 主从模式 | 无高可用 & 简单

![1632299571516](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632299571516.png)

##### 概念

Redis 支持简单易用的**主从复制**功能， 使得从服务器成为主服务器的精确复制品。

##### 特点

（>= Redis 2.8）

- 一个 Master 可以有多个 Slave，并且 Slave 也可以有自己的 Slave ， 多级 Slave 之间可以构成一个**图状结构**。
- 复制功能默认使用**异步复制**， Slave 会以每秒 1 次的频率向 Master 报告复制流的处理进度。
- 复制功能**不会阻塞 Master**，即使有一个或多个 Slave 正在进行初次同步， Master 也可以继续处理命令请求。
- 复制功能也**不会阻塞 Slave**，只要启用了 `slave-serve-stale-data` 设置，即使 Slave 正在进行初次同步， 也可以使用旧版本的数据集来处理命令查询，不过在 Slave 删除旧版本数据集并载入新版本数据集的那段时间内， 连接请求会被阻塞。
- 复制功能只是单纯地进行**数据冗余**， 可以通过 `slave-read-only` 配置**读写分离**，让多个 Slave 来处理只读请求来提升扩展性，比说繁重的 `SORT` 命令可以交给 Slave 去运行。
- **禁止**《关闭 Master 持久化 + 自动拉起 Master 服务》：强烈建议打开 Master 的持久化，否则可能会因为延迟等问题，叠加自动拉起 Master 服务的原因，造成数据的丢失：
  1. 比如 Master 节点 A 关闭了持久化，Slave 节点 B 和节点 C 从节点 A 进行复制数据。
  2. 此时，节点 A 崩溃，然后服务被自动拉起，重启了节点 A，由于节点 A 的持久化被关闭了，所以 A 重启之后没有任何数据。
  3. 接着，节点 B 和节点 C 将从节点 A 复制数据，但是 A 的数据是空的，于是 B 和 C就把自身保存的数据副本全部都删除掉。
  4. 这种情况下，即便使用 Sentinel 来实现Redis 高可用也是非常危险的， 因为 Master 可能拉起得非常快，以至于 Sentinel 在配置的心跳时间间隔内，还没有检测到 Master 已被重启，然后 Slave 还是会执行上面数据丢失的流程。

##### 配置参数

```shell
# Slave参数
# 配置主从复制Master的IP+端口
slaveof <masterip> <masterport>
# 如果Master通过requirepass配置密码，则Slave也需要进行相应的配置
masterauth <master-password>
# 默认允许，Slave初次同步未完成时，继续使用旧数据来响应客户端，配置no会阻塞初次同步期间的所有请求
slave-serve-stale-data yes
# 默认开启读写分离，Slave只能读取数据，不能写入数据
slave-read-only yes

# Master参数
# 默认关闭无磁盘化复制，Master磁盘不生成RDB文件，直接通过网络同步给Slave
repl-diskless-sync no
# 默认为3和10，如果至少有3个从服务器，并且这3服务器的延迟值都少于10秒，Master才会执行客户端请求的写操作
# min-slaves-to-write 3
# min-slaves-max-lag 10

```

##### 原理

（>= Redis 2.8）

1. 当建立一个 Slave 时， Slave 会向 Master 发送一个 `PSYNC master_run_id offset` 命令。
2. 如果 Slave 是首次连接，由于 Master 中不存在该 Slave 的复制偏移量，所以会触发一次**完整重同步**操作， 此时，Master 开始执行 `BGSAVE`， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。
   - **部分重同步**：
     1. Master 会为被发送的复制流创建一个缓冲区 `in-memory backlog`， 并且 Master 和所有 Slave 之间都记录一个复制偏移量 `replication offset` 和一个主服务器ID `master run id`，当出现网络连接断开时， Slave 重新连接后会向 Master 请求继续执行原来的复制进程。
     2. 如果 Slave 记录的主服务器ID `master run id` 和当前要连接的主服务器ID `master run id` 相同， 并且 Slave 记录的偏移量 `replication offset` 所指定的数据仍然保存在 Master 的复制流缓冲区 `in-memory backlog` 里面， 那么 Master 会向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
     3. 否则，Slave 就要执行**完整重同步**操作。
3. 当 Master  `BGSAVE` 执行完毕后， Master 将执行保存操作所得的 .rdb 文件发送给 Slave， Slave 接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
4. 之后，Master 会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给 Slave，Slave 则实时同步这些数据。
5. 如果主从复制期间 Slave 断开连接，在自动重连后，会使用 `PSYNC master_run_id offset` 命令来进行同步，Master 会以**增量复制**的形式，向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
   - Slave 会在连接断开后进行自动重连：
     - 在 Redis 2.8 版本之前， 断线之后重连的 Slave 总要执行一次**完整重同步**操作。
     - 从 Redis 2.8 版本开始， Slave 可以根据 Master 的情况来选择执行**完整重同步**还是**部分重同步**。
       1. 如果此时 Master 是 Redis 2.8 之前的版本，那么 Slave 使用 `SYNC` 命令来进行同步。
       2. 如果此时 Master 是 Redis 2.8 或以上版本，那么 Slave 使用 `PSYNC master_run_id offset` 命令来进行同步。

##### 优点

- **部署简单**，仅使用两个节点即可构成主从模式。
- 可以通过**读写分离**，来避免读和写同时不可用。

##### 缺点

- 一旦 Master 节点出现故障，主从节点就**无法自动切换**，直接导致 SLA 服务等级下降。
  - **解决方案**：添加哨兵监控。
- 所有的 Slave 节点数据的复制和同步都由 Master 节点来处理，会造成 Master节点压力过大。
  - **解决方案**：可以使用**主从从结构**，通过引入从从同步，以减少主从同步的次数。

##### 适用场景

一般适合业务**发展初期**，并发量低，运维成本低的情况。

#### 哨兵模式 | 高可用 & 多读

![1632320226337](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632320226337.png)

##### 概念

Sentinel，哨兵，是 Redis 高可用的解决方案，可以监视一个或者多个 Redis Master 服务，以及这些 Master 服务的所有从服务，当某个 Master 服务宕机后，会把这个 Master 下的某个从服务升级为 Master，从而替代已宕机的 Master 继续工作。

##### 特点

- Redis Sentinel 用于管理多个 Redis 服务器实例， 它会执行以下**三个任务**：
  1. **监控**：Monitoring，Sentinel 会不断地检查 Master 和 Slave 是否运作正常。
  2. **提醒**：Notification，当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
  3. **自动故障迁移**：Automatic failover。
     - 当一个 Master 不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效 Master 的其中一个 Slave 升级为新的 Master， 并且让失效 Master 的其他 Slave 改为复制新的 Master。
     - 当客户端试图连接失效的 Master 时， 集群也会向客户端返回新 Master 的地址， 使得集群可以使用新 Master 代替失效 Master。
- Redis Sentinel 是一个分布式系统， 可以在一个架构中运行多个 Sentinel 进程， 这些进程会使用**流言协议**来接收关于 Master 是否下线的信息， 并使用**投票协议**来决定是否执行自动故障迁移， 以及选择哪个 Slave 作为新的 Master。
  - **流言协议**：gossip protocols，是一种计算机对计算机的沟通协议，是一种复制**没有强一致性**需求状态的方式，即使在通讯失败或消息丢失的情形下，更新也可以在期望的时间内传播，通常用来解决其它方式难以解决的分布式问题，比如底层的网络结构非常复杂，或者流言协议是最有效的解决方案等。
  - **投票协议**：agreement protocols，比如 Raft。
- 虽然 Redis Sentinel 释出为一个单独的可执行文件 `redis-sentinel`，但实际上只是一个运行在**特殊模式**下的 Redis 服务器， 可以在启动一个普通 Redis 服务器时通过给定 `--sentinel` 选项来启动 Redis Sentinel 。

##### 配置参数

```shell
# 配置监控 127.0.0.1：6379 的 mymaster 服务器，并且客观下线需要取得2个(quorum)哨兵的同意
# 但是无论该值配置了多少，都需要多数哨兵的选举后，才能发起一次自动故障转移
sentinel monitor mymaster 127.0.0.1 6379 2
# 配置Master服务器密码（如果Master有配置的话）
sentinel auth-pass <master-name> <password>
# 配置判定mymaster主观下线的毫秒数
sentinel down-after-milliseconds mymaster 60000
# 配置主从切换的超时时间，需要自动故障转移时，如果当前哨兵没有去执行，那么在超过这个时间后，会由其他的哨兵来进行处理
sentinel failover-timeout mymaster 180000
# 配置在执行故障转移时，同步新mymaster的最大Slave并行数，如果全部Slave一起对新Master进行同步，由于在Slave载入RDB时会阻塞客户端请求，所以可能会造成所有Slave在短时间内全部不可用的情况出现
sentinel parallel-syncs mymaster 1
```

##### 运行命令

```shell
# 启动命令
# 运行纯Sentinel服务器
redis-sentinel /path/to/sentinel.conf
# 在Redis Server上运行哨兵
redis-server /path/to/sentinel.conf --sentinel

# 运维命令
# 查看imooc-master下的master节点信息
sentinel master imooc-master
# 查看imooc-master下的slaves节点信息
sentinel slaves imooc-master
# 查看imooc-master下的哨兵节点信息
sentinel sentinels imooc-master

```

##### 自动发现原理

###### Sentinel 发现

一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换，通过**发布与订阅**功能，向频道 `__sentinel__:hello` 发送信息，来自动发现正在监视相同 Master 的其他 Sentinel ，无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址。

1. **发布**：每个 Sentinel 会以每两秒一次的频率， 通过发布与订阅功能， 向被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道发送一条信息， 信息中包含了 Sentinel 的 IP、端口和运行 ID `runid`。
   - Sentinel 发送的信息中还包括完整的 Master 当前配置。 如果一个 Sentinel 包含的 Master 配置比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。
2. **订阅**：每个 Sentinel 都订阅了被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道， 查找之前未出现过的 Sentinel，当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了已知的、正在监视同一个 Master 的所有其他 Sentinel 。
   - 在将一个新 Sentinel 添加到监视 Master 的列表上面之前， Sentinel 会先检查列表中是否已经包含了和要添加的 Sentinel 拥有相同运行 ID 或者相同地址（IP+端口）的 Sentinel ， 如果是，则 Sentinel 会先移除列表中已有的那些拥有相同运行 ID 或者相同地址的 Sentinel ， 然后再添加新 Sentinel 。

###### Slave 发现

与此类似，也不必在配置文件中，手动列出 Master 属下的所有 Slave， 因为 Sentinel 可以通过询问 Master 来获得所有 Slave 的信息。

- 在一般情况下， 每个 Sentinel 会以**每10秒1次**的频率向它已知的所有 Master 和 Slave 发送 `INFO [section]` 命令。 
- 当一个 Master 被 Sentinel 标记为客观下线时， Sentinel 向下线 Master 的所有 Slave 发送 `INFO [section]`命令的频率会从每10秒1次改为**每秒1次**。

##### 故障判定原理

###### Sentinel 定期任务

1. 每个 Sentinel 以**每秒1次**的频率向它所知的 Master、Slave 以及其他 Sentinel 实例发送一个 `PING` 命令。
2. 如果一个实例距离最后一次有效回复 `PING` 命令的时间超过 `down-after-milliseconds` 选项所指定的值， 那么这个实例会被 Sentinel 标记为**主观下线**。 
3. 如果一个 Master 被标记为主观下线， 那么正在监视这个 Master 的**所有 Sentinel** 要以每秒1次的频率确认Master 是否的确进入了主观下线状态。
   - 当 Master 重新向 Sentinel 的 `PING` 命令返回有效回复时，Master 的主观下线状态就会**被移除**。
4. 如果一个 Master 被标记为主观下线， 并且有足够数量（>= `quorum` ）的 Sentinel 在指定的时间范围内同意这一判断， 那么这个主服务器被标记为**客观下线**。
   - 当没有足够数量（>= `quorum` ）的 Sentinel 同意主服务器已经下线， Master 的客观下线状态就会**被移除**。

###### 主观下线

主观下线，Subjectively Down， 简称 **SDOWN**，指的是单个 Sentinel 实例对服务器做出的下线判断，如果一个服务器（Master、Slave 和其他 Sentinel）没有在 `master-down-after-milliseconds` 选项所指定的时间内， 对向它发送 `PING` 命令的 Sentinel 一直返回**无效回复**， 那么 Sentinel 就会将这个服务器标记为**主观下线**。

- 服务器对 PING 命令的**有效回复**，可以是以下三种回复的其中一种：
  - 返回 `+PONG` 。
  - 返回 `-LOADING` 错误。
  - 返回 `-MASTERDOWN` 错误。
- 如果服务器返回除以上三种回复之外的其他回复， 又或者在指定时间内**没有回复** `PING` 命令， 那么 Sentinel 认为服务器返回的**回复无效**。
- 只有一个 Sentinel 将服务器标记为**主观下线**，并不一定会引起服务器的自动故障迁移，只有在足够数量（>= `quorum` ）的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为**客观下线**， 这时**自动故障迁移**才会执行。

###### 客观下线

客观下线，Objectively Down， 简称 **ODOWN**，指的是多个 Sentinel 实例在对同一个服务器做出 **SDOWN** 判断， 并且通过  `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务器下线判断。

- 一个 Sentinel 可以通过向另一个 Sentinel 发送 `SENTINEL is-master-down-by-addr` 命令来询问对方是否认为给定的服务器已下线。
- 从主观下线状态切换到**客观下线**状态，并没有使用严格的法定人数算法， 而是使用了**流言协议**：
  - 如果 Sentinel 在给定的时间范围内， 从其他 Sentinel 那里接收到了足够数量（>= `quorum` ）的 Master 下线报告， 那么 Sentinel 就会将 Master 的状态从主观下线改变为**客观下线**。 
  - 如果之后其他 Sentinel 不再报告 Master 已下线， 那么客观下线状态就会**被移除**。
- 客观下线条件只适用于 Master，对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以  Slave 或者其他 Sentinel 永远不会达到客观下线的条件。
- 只要一个 Sentinel 发现某个 Master 进入了客观下线状态， 这个 Sentinel 就可能会被其他 Sentinel 推选出， 并对失效的 Master 执行自动故障迁移操作。

##### 自动故障转移

###### Leader Sentinel 选举

当一个 Master 被判定为**客观下线**后，监视这个 Master 的所有Sentinel会通过 `Raft` 选举算法，选出一个Leader Sentinel 去执行故障转移 `failover` 操作。

- **选举一致性保证**：
  1. 使用 Raft 算法来选举 Leader Sentinel，可以确保在一个给定的 `epoch`（纪元）里， **只有一个** Leader 产生，因为更高的 `epoch` 配置总是优于较低的 `epoch` 配置 ， 每个 Sentinel 都会主动使用更新的 `epoch` 来代替自己的配置。
  2. 当出现网络分区时， 一个 Sentinel 可能会包含了较旧的配置， 而当这个 Sentinel 接到其他 Sentinel 发来的版本更新的配置时， Sentinel 就会对自己的配置进行更新。
  3. 如果想要在出现网络分区时仍然保持一致性，可以使用 `min-slaves-to-write` 选项， 让 Master 在连接的 Slave 实例数**少于给定数量时，停止执行写操作**，并且在每个运行 Redis Master或 Slave 的机器上运行 Redis Sentinel 进程。

###### Raft 算法

http://thesecretlivesofdata.com/raft/#home、https://raft.github.io

![1632381533618](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632381533618.png)

Raft，是一种共识算法，旨在使其易于理解，在容错和性能上与Paxos媲美，不同之处在于它被分解为相对独立的子问题（Leader Election 和 Log Replation），并且清晰明了地解决了分布式系统实际所需的主要部分。

- **Leader Election**：领导者选举，这部分主要就是通过用随机 `election timeout` 的方式，使得能够很快地选出 Leader，并且通过 `heartbeat（AppendEntries RPC，心跳续约）` 周期性地通知 Follower，以维持 Leader 的状态。这大大简化了 Leader 选举的算法，加快了选举速度。**选举流程**为：
  1. 每个 Follower 或者 Candidate 都有一个 election timer，用来计算随机 `election timeout` 时间。
  2. 当 Follower 没有收到 Leader 的 `heartbeat（AppendEntries RPC，心跳续约）` 或者 Candidate 的 `RequestVote RPC（选举发起）`时，则等待 election timer 超时。
  3. 一旦 Follower 超时，则会立刻变为 Candidate 身份，令 `currentTerm++` 发起新一轮 election term 的选举，它会先给自己投票，并重置自己的 election timer，然后广播 `RequestVote RPC（选举发起）` 给所有 server。
  4. 这些 server 如果收到某个 Candidate 的 `RequestVote RPC（选举发起）` 时，会经过一系列规则来判断是否能够进行投票。
  5. 如果在 election timer 超时前，该 Candidate 能收到超过半数 server 的投票，则会立刻变为 Leader，并发送 `heartbeat`，以维持 Leader 身份。
- **Log Replation**：日志复制（自己写的，可能理解会有出入，在分布式章节再补充完整）。
  1. 在客户端请求 Leader 更改集群数据时，Leader 会在数据更改后，先把同步日志发送到它所有的 Follower。
  2. 当超过半数的 Follow 的同步日志写入成功后，Leader 才会对该数据的更改进行提交，并响应客户端。
  3. 最后，Leader 再把提交结果同步到它所有的 Follower，通知他们 Leader 数据的提交。

###### Master 选择

当选举出 Leader Sentinel 后，Leader Sentinel 会根据以下规则，在失效 Master 属下的 Slave 当中，选择出新的 Master：

1. 先淘汰主观下线 | 已断线 | 最后一次回复 `PING` 命令时间大于5秒钟 | 与失效 Master 断开连接时长超过 10 倍主观判断时长 `down-after-milliseconds` 的 Slave 节点。
2. 选择配置 `slave-priority` 最高的 Slave 节点，如果没有，则继续选择。
3. 选择复制偏移量 `replication offset` 最大的 Slave 节点，复制偏移量越大，说明数据复制的越完整。
4. 如果复制偏移量不可用，或者 Slave 的复制偏移量相同， 则选择运行 ID `run_id` 最小的 Slave 节点，`run_id` 越小，说明重启次数越少。

###### 故障转移流程

一次故障转移操作由以下步骤组成：

1. 某个 Sentinel 发现 Master 已经进入**客观下线**状态。
2. 该  Sentinel 对当前 `epoch` （纪元）进行自增， 并尝试在这个 `epoch` 中当选 Leader Sentinel 。
3. 如果 Leader Sentinel 当选失败， 则在设定的故障迁移超时时间 `failover-timeout` 的两倍之后， 会继续重新尝试当选。
4. 如果 Leader Sentinel 当选成功， 则根据Master选择规则，选出一个 Slave，向其发送 `SLAVEOF NO ONE` 命令，让它转变为 Master。
5. 然后， Leader Sentinel 通过**发布与订阅**功能， 将更新后的配置传播给所有其他 Sentinel，让其他 Sentinel 对它们自己的配置进行更新。
   - Sentinel 的状态会被持久化在 Sentinel 的配置文件中，每当 Sentinel 接收到一个新的配置， 或者当Leader Sentinel 为 Master 创建一个新的配置时， 这个配置会与 `epoch` 一起被保存到自己的磁盘里，意味着停止和重启 Sentinel 进程都是安全的。
6. 接着， Leader Sentinel 会向已下线 Master 的其他 Slave 发送 `SLAVEOF host port` 命令， 让它们去复制新的 Master。
   - 当Redis 实例被重新配置，无论是被设置成 Master，或者Slave，或者其他 Master 的 Slave，Sentinel 都会向这个被重新配置的实例发送一个 `CONFIG REWRITE` 命令， 从而确保这些配置会被这个实例持久化在它自己的硬盘里。
7. 最后，当所有 Slave 都已经开始复制新的 Master 时， Leader Sentinel 则结束这次故障迁移操作。

##### 优点

监控、提醒、自动故障转移，从而实现 Redis 的高可用。

##### 缺点

如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

##### 适用场景

适合**读远多于写**的业务场景，比如在秒杀系统中，用来缓存活动信息。

#### 集群模式 | 高可用 & 多写

![1632464692288](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632464692288.png)

##### 概念

Redis Cluster，于 3.0 版本推出，是一个分布式容错的高可用实现。

##### 特点

- 采用**哈希虚拟槽**的数据分区方案，把 key 分布到各个 Master 节点上，每个 Master 后跟若干个 Slave 做主从切换。

- 采用**客户端查询分区+服务端查询路由**的分区实现，客户端可以连接任意 Master 节点，集群内部会按照不同的 key，把请求转发到不同的 Master 节点。

- 可使用的功能只是普通单机 Redis 所有功能的一个**子集**：

  - 不支持同时使用多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的行为。
  - 不支持多数据库功能， 只能使用默认的 `0` 号数据库， 并且不能使用 `SELECT index` 命令。

- Redis Cluster 的设计目标主要为高性能、高可用和高扩展，抛弃了一部分数据一致性，即 **AP**：

  - **数据一致性**：由于 Redis 主从复制使用的是异步复制，在某些情况下，如果 Master 宕机但未同步至 Slave，可能会导致丢失写入，可通过 `WAIT` 命令实现，使丢失写入的可能性大大降低。

    - **`wait` 命令不能保证 Redis 强一致性**：如果写操作已经被传送给一个或多个 Slave节点，当 Master 发生故障，虽然使用 `wait` 命令可以**极大概率**（不保证100%）地提升一个受到写命令的 Slave 节点为Master，但由于其他原因，比如 `slave-priority`， Sentinel 还是有可能去提升其他未同步写命令的 Slave 节点，造成同步写操作的丢失。

    |          | WAIT                                                         |
    | -------- | ------------------------------------------------------------ |
    | 出现版本 | Redis 3.0                                                    |
    | 命令格式 | wait numslaves timeout                                       |
    | 含义     | 阻塞当前客户端 timeout 毫秒，为 0 则代表永远阻塞，直到所有以前的写命令都成功传输并被指定数目的 Slave 确认，命令再返回；或者如果发生 timeout 超时，即使指定数目的 Slave 还没有确认，命令也会返回。 |
    | 返回值   | 返回已处理至该偏移量的 Slave 个数                            |

  - **高可用**：当集群中一部分节点故障后，集群整体依然能响应客户端读写请求。

    - **自动故障转移**：节点间定时互 `Ping` ，当超过一半 Master 判定某节点失败，则标记为 FAIL，然后向集群广播节点下线的消息，如果下线节点是带有哈希槽的 Master，则会在它的 Slave 中挑选出一个来进行主从替换。

  - **高性能**：操作某个 key 时，不会先找到节点再处理，而是直接重定向到目标 Redis 实例，相较代理分片少了 proxy 的连接损耗。

    - 但是在进行 multiple key 操作时，由于 keys 可能会散列到不同的 Redis 实例上，造成操作的非原子性，加之 Redis Cluster 本身就不支持 multiple key 操作，此时可以使用 **hash tags** 哈希标签， 将 keys 散列到同一个 slot 上，以满足进行 multiple key 的需求。
      - **hash tags**：哈希标签，使用 {} 确保两个 key 都在散列到同一个哈希槽，比如 key1 {user1000}.following 和 key2 {user1000}.followers，由于使用了哈希标签，Redis Cluster 在散列时，只会使用 { } 里的字符串进行计算，所以 key1 和 key2 将会落到同一个哈希槽中。

  - **高拓展**：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

##### 配置参数

```shell
# 开启集群模式
cluster-enabled yes
# 每一个节点都需要有这么一个配置文件，3主3从则一共需要6份，用于存储集群模式下的集群状态等信息，由Redis自己维护，而这些信息会相互告知其他所有节点。如果要重新创建集群，只需要把这个文件删除掉就行。
cluster-config-file nodes-201.conf
# 节点超时时限，如果发生超时则会被认定为PFAIL，如果超过半数其他Master认定为PFAIL，则会被集群认定为FIAL，然后会进行主从切换
cluster-node-timeout 5000
# 开启AOF
appendonly yes

```

##### 运行命令

```shell
# Redis3.x旧版集群构建方式，需要使用redis-trib.rb来构建集群，最新版使用C语言来构建了，这个要注意
# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005

# 新版Redis集群构建方式
# 创建集群，主节点和从节点比例为1，1-3为主，4-6为从，1和4，2和5，3和6分别对应为主从关系，这也是最经典用的最多的集群模式
redis-cli --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1

# 集群客户端
redis-cli -c -p 7000

# 检查集群信息
redis-cli --cluster check 127.0.0.1:6379

```

##### 集群节点

###### 节点属性

```shell
# 获取集群所有节点的描述信息
$ redis-cli --cluster nodes
# 结果：节点ID，IP，端口号，节点标志，最后PING发送时间，最后PONG接收时间，连接状态，哈希槽范围
d1861060fe6a534d42d8a19aeb36600e18785e04 :0 myself - 0 1318428930 connected 0-1364
```

- **节点ID**：
  1. 每个节点在集群中都有一个独一无二的 ID，是一个十六进制表示的 160 位随机数，用于标识集群中的每个节点，一个节点可以改变它的 IP 和端口号， 但重启的话不会改变它的节点 ID 。
  2. 节点ID，在节点**第一次启动**时由 `/dev/urandom` 生成，然后保存到配置文件中， 只要这个配置文件不被删除，该节点就会一直沿用这个 ID。 
  3. 集群可以自动识别出 IP + 端口号的变化， 并把这一信息通过 `Gossip` 协议广播让其他节点知道。
- 如果该节点是从节点的话，那么它会记录主节点的节点 ID 。 如果这是一个主节点的话，那么主节点 ID 这一栏的值为 `0000000` 。

###### 节点任务

- **保存数据**：持有键值对数据。
- **状态映射记录**：记录集群的状态，包括键到正确节点的映射。
- **自动发现与选举**：自动发现其他节点，识别工作不正常的节点，并在有需要时，在从节点中选举出新的主节点。

###### 节点通信

集群中的每个节点都会与其他节点建立起**集群连接**， 该连接是一个 TCP 连接， 使用二进制 `Gossip` 协议进行通讯，用于：

- **节点发现**：传播关于集群的信息，以此来发现新的节点。
- **心跳检测**：向其他节点发送 `PING` 数据包，以此来检查目标节点是否正常运作。
  - **集群内互通**：集群节点总是应答来自集群连接端口的连接请求。
  - **非集群内只允许PING**：可以对接收到的 `PING` 数据包进行回复， 即使这个 `PING` 数据包来自不可信的节点，但除了 `PING` 之外， 集群节点会拒绝其他所有非来自集群节点的数据包。
- **事件传播**：在特定事件发生时，发送集群信息。

###### 节点自动发现

如果将一个新节点添加到一个集群中， 只要管理员使用 `CLUSTER MEET` 命令显式地指定了可信关系， 集群就可以自动发现其他节点，最终该节点会与集群中已有的其他所有节点连接起来。

- **握手规则**：
  - A 节点刚加入集群中，B 为集群中的某个节点，此时如果管理员显式地向 A 发送 `CLUSTER MEET ip port` 命令， 那么 A 会向 B 发送 `MEET` 信息， 强制让 B 节点承认 A 属于集群中的一份子。
  - A、B为集群中的某个节点，A 刚承认 C 为集群中的一份子，此时如果 A 向 B 传播第三者 C 的信息， 那么 B 也会把 C 识别为集群中的一份子， 并尝试连接 C 。
- **作用**：可以防止不同的 Redis 集群由于 IP 地址的变更或者其他网络事件的发生，而产生意料之外的问题，从而使得集群更具健壮性。当节点的网络连接断开时， 它会主动连接其他已知的节点。

##### 分区实现原理

###### 虚拟哈希槽模型

Redis 集群的键空间被分割为 `16384` 个槽（slot）， 集群的最大节点数量也是 `16384` 个，但推荐的最大节点数量为 1000 个左右，每个主节点都负责处理 `16384` 个哈希槽的其中一部分，其键的映射算法为：

```shell
# CRC16 算法可以很好地将各种不同类型的键，平稳地分布到 16384 个槽里面
HASH_SLOT = CRC16(key) mod 16384
```

###### 为什么哈希槽数为16384个？

`CRC16` 算法产生的 hash 值有 16 bit，即可产生 2 ^ 16 = 65536 个值，换句话说，值是分布在 0 ~ 65535 之间，那 Redis 在做 `mod` 运算的时候，为什么不 `mod` 65536，而是选择 `mod` 16384 呢？

1. **槽位数不宜过大**：
   1. 如果槽位为 65536，那么节点发送 `PING/PONG` 心跳包消息头所占用的空间会达到 8k （65536 / 8），过于庞大，传输时浪费带宽。
   2. 而使用 16384 个槽位，心跳包消息头所占用的空间仅为 2k（16384 / 8），大小还能接受。
2. **槽位数不宜过小**：
   1. Redis Master 节点数量基本不可能大于 1000 个，因为集群节点越多，心跳数据包消息体携带的数据就越多，就越可能导致网络拥堵。
   2. 同时，Redis Master 的哈希槽配置，是通过一张 bitmap 的形式来保存的，其填充率为 slots / N，N为节点数目，在 N 最大为 1000 的情况下，如果槽位数越小，bitmap 填充率就越小，导致 bitmap 在传输过程中的压缩率就越高，越消耗 CPU 资源。
3. 因此，16384 个插槽可以确保在最大 1000 个 Master 的情况下，仍然有足够的插槽，使得哈希槽配置作为原始 bitmap 进行传播，是综合了心跳包大小、网络带宽、压缩率等方面考虑的结果，16384 个插槽处于**合适的范围**内，能够满足业务需求并且更有优势。

###### 请求路由原理

1. **服务端路由**：集群节点不能代理客户端的命令请求， 客户端应该在节点返回 `-MOVED` 或者 `-ASK` 转向错误时， 自行将命令请求转发至其他节点。
   - 当节点需要让一个客户端**长期地**将针对某个槽的命令请求发送至另一个节点时， 节点会向客户端返回 `-MOVED` 转向。
   - 当节点需要让客户端仅仅在**下一个命令**请求中转向至另一个节点时， 节点会向客户端返回 `-ASK` 转向。
2. **客户端路由**：如果客户端可以将键和节点之间的映射信息保存起来， 可以有效地减少可能出现的转向次数， 籍此提升命令执行的效率。

###### MOVED 转向

1. 一个 Redis 客户端可以向集群中的任意节点（包括从节点）发送 `GET key` 命令请求。

2. 集群节点会对命令请求进行分析， 如果该命令是集群可以执行的命令， 那么节点会查找这个命令所要处理的键所在的哈希槽。

3. 如果要查找的哈希槽正好就处于当前节点中，则接收到的命令由当前节点负责处理。

4. 如果所查找的哈希槽不处于当前节点中，则当前节点会先查看自身内部所保存的哈希槽到节点 ID 的**映射记录**，然后向客户端回复一个 `-MOVED` 转向错误。

   ```shell
   GET x
   # GET命令收到一个 -MOVED 转向错误
   # x真正所在的目标哈希槽，目标节点IP，目标节点端口号
   -MOVED 3999 127.0.0.1:6381
   
   ```

5. 客户端收到 `-MOVED` 转向错误后，根据目标节点 IP 与端口号，会再向目标节点重新发送一次 `GET key`命令请求。

   - 为了让客户端的转向操作**尽可能地简单**， 节点在 `-MOVED` 错误中直接返回了目标节点的 IP 和端口号， 而不是目标节点的 ID 。

6. 如果客户端在重新发送 `GET key` 命令时，集群刚好又更改了 key 的 slot 配置， 此时客户端请求目标哈希槽，会再次收到 `-MOVED` 转向错误， 需要再次向新的目标节点重新发送一次 `GET key`命令请求。

7. 客户端会循环以上操作，直到该命令请求成功，然后记录下该成功请求的哈希槽的目标节点信息，在下次执行相同 key 命令时，加快正确节点的寻找速度。

   - 当集群处于稳定状态时， 所有客户端最终都会保存有一个哈希槽至节点的映射记录，使得集群非常高效，此后客户端可以直接向正确的节点发送命令请求， 而无须转向、代理或者请求其他可能发生单点故障的 Redis 实例。

###### 集群重分片

Redis 集群支持在集群运行的过程中添加或者移除节点，无论是添加还是删除，都需要将哈希槽从一个节点移动到另一个节点，如果添加一个新节点到集群， 则需要将其他已存在节点的槽移动到一个空白的新节点里面；如果从集群中移除一个节点， 则需要将被移除节点的所有槽移动到集群的其他节点上面去。

- **使用 Cluster 子命令**：管理集群节点的哈希槽转换表。

| Cluster子命令                              | 作用                                                         |
| ------------------------------------------ | ------------------------------------------------------------ |
| CLUSTER ADDSLOTS slot1 [slot2] ... [slotN] | 用于添加并指派节点哈希槽，当哈希槽被添加并指派之后， 节点会把这一信息通过 Gossip 协议传播到整个集群，通常在新创建集群时， 作为一种快速地将各个槽指派给各个节点的手段来使用 |
| CLUSTER DELSLOTS slot1 [slot2] ... [slotN] | 用于删除节点哈希槽，当哈希槽被删除之后， 节点会把这一信息通过 Gossip 协议传播到整个集群 |
| CLUSTER SETSLOT slot NODE node             | 可以将指定的哈希槽指派给节点 node                            |
| CLUSTER SETSLOT slot MIGRATING node        | 用于将给定节点 node 中的哈希槽迁移出节点 node。当一个哈希槽被设置为 `MIGRATING` 状态时， 只有当哈希槽的键仍然存在于节点时，该节点才会继续处理关于这个槽的命令请求；如果哈希槽的键不存在于节点， 那么该节点会向客户端返回一个 `-ASK` 转向错误， 以告知客户端要把命令请求发送到 哈希槽迁移后的目标节点 |
| CLUSTER SETSLOT slot IMPORTING node        | 用于将给定哈希槽导入到节点 node 中。当一个槽被设置为 `IMPORTING` 状态时，节点仅在接收到 `ASKING` 命令之后， 才会接受关于这个槽的命令请求；如果客户端没有向节点发送 `ASKING` 命令， 那么节点会使用 `-MOVED` 转向错误，把命令请求转向至真正负责处理这个槽的节点 |

- **使用 redis-trib 客户端**：Redis3.x旧版命令，`./redis-trib.rb reshard <集群中任意结点的IP+端口号>`，不推荐，会阻塞客户端。
  1. 先执行 `CLUSTER GETKEYSINSLOT slot count` 命令，让节点返回 count 个 哈希槽中的键。
  2. 然后对于命令所返回的每个键， redis-trib 会向节点 A 发送一条 `MIGRATE host port key destination-db timeout [COPY] [REPLACE] ` 命令， 把所指定的键**原子地**从节点 A 移动到节点 B，并且在移动键期间，A 和 B两个节点都会处于**阻塞状态**，以免出现竞争条件。
     - `MIGRATE host port key destination-db timeout [COPY] [REPLACE]` ：
       1. 执行该命令的节点会连接到 target 节点， 并将序列化后的 key 数据发送给 target ， 一旦 target 返回 `OK` ， 节点就将自己的 key 从数据库中删除。
       2. 从一个外部客户端的视角来看， 在某个时间点上， 键 key 要么存在于节点 A ， 要么存在于节点 B ， 但不会同时存在于节点 A 和节点 B 。
       3. 由于 Redis 集群只使用 `0` 号数据库， 所以当该命令被用于执行集群操作时， target_database 的值总是 `0` 。
       4. 尽管该命令非常高效， 但对一个键非常多、并且数据量非常大的集群来说，该命令会占用大量的时间， 有可能会导致集群没办法适应那些对于响应时间有严格要求的应用程序。

###### ASK 转向

1. 节点 A 开始迁移 哈希槽8 的键到 节点 B，迁移过程中，客户端对 A 发起了请求。
2. 由于 A 的 哈希槽8 的键被迁移了一部分到 B，导致客户端在节点 A 中没找到某个键，A 节点会向客户端返回一个 `-ASK` 转向错误。
   - 这种转向仅仅会影响**一次命令**查询， 而不是让客户端每次都直接去查找节点 B，并且只针对 16384 个槽中的其中**一个槽**， 所以对集群造成的性能损耗是属于可接受范围的。
3. 客户端接收到 `-ASK` 转向错误后， 则将命令请求的发送对象，调整为转向所指定的节点 B。
4. 接着，客户端会先发送一个 `ASKING` 命令，然后再发送真正的命令请求，否则这个针对带有 `IMPORTING` 状态槽 8 的命令请求将会被节点 B 拒绝执行。
   - **先发送 `ASKING` 命令的好处**：如果客户端出现 Bug ， 过早地将槽8 映射到了节点 B 上面， 只要不先发送 `ASKING` 命令， 后面发送的命令请求就会被 B 返回 `-MOVED` 转向错误， 并将请求转回节点 A，从而保证了在槽8 转移期间，必须先请求节点 A。
5. 节点 B 接收到客户端 `ASKING` 命令后，会将为客户端设置一个一次性的标志， 使得客户端可以执行一次针对 `IMPORTING` 状态槽8 的命令请求。
6. 命令请求成功后，客户端不会去更新所记录的槽8 到节点的映射，此时槽8 仍然是映射到节点 A ， 而不是节点 B。
7. 接下来，在键转移期间，如果客户端继续发起 槽8 的请求，会重复以上操作。
8. 一旦节点 A 的 槽8 转移工作完成，当节点 A 再次收到针对槽8 的命令请求时，就会向客户端返回 `-MOVED` 转向， 把所有关于槽8 的命令请求**长期地**转向到节点 B中。
9. 至此，完成了一次 哈希槽**动态转移**的过程。

##### 高可用原理

###### 节点失效检测

简单来说就是，当一个节点 `PING` 不通另一个节点时，则会把它标记为 `PFAIL`；当一个节点要把另一个节点从 `PFAIL`标记为 `FAIL`时， 则必须得到大部分 Master 的同意才行。

1. 当一个节点 A 向另一个节点 B 发送 `PING` 命令， 但是 B 未能在 `cluster-node-timeout` 配置的节点超时时限内返回该 `PING` 命令的回复时， 那么 A 会将 B 标记为 `PFAIL` （possible failure，代表可能已失效）。
2. 然后下次在节点 A 对 C、D、E... 发送 `PING` 命令时， 都会随机地广播**3个**它所知道的节点的信息，其中一项说明了 B 节点是否已经被 A 标记为 `PFAIL` 或者 `FAIL` 。
3. 当节点 C、D、E... 接收到 A 发来的信息时，会记下那些被 A 标记为失效的节点 B，这操作称为**失效报告**。
4. 如果在Master F 将 B 标记为 `PFAIL` 时， 根据**最近接收到的**失效报告显式， 集群中的大部分其他 Master 都认为 B 已经进入了 `PFAIL` ， 那么 E 会将那个 B 的状态标记为 `FAIL`（failure，代表已失效） 。
5. 一旦 B 被标记为 `FAIL` ，关于它的已失效信息就会被广播到整个集群， 所有接收到这信息的节点都会将 B 标记为 `FAIL` 。
   - **Slave Fail**：当 B 为 Slave 时，在 B 重新上线时， 它的 `FAIL` 标记就会被移除。
     - 由于 Slave 不需要处理任何哈希槽，是否处于 `FAIL` 状态，只决定了它能否在有需要时被提升为 Master，所以保持 Slave 的 `FAIL` 状态是没有意义的。
   - **Master Fail**：当 B 为 Master 时，在 B 经过了 （**4 倍** `cluster-node-timeout` 配置的节点超时时限 +  **10 秒钟**）后，如果 Slave 的故障转移操作仍未完成，且 B 又发生了重新上线，那么 B 的 `FAIL` 标记会被移除，集群继续使用原来的 Master B。

###### 主从复制

为了在一部分节点下线，或者无法与集群的大多数节点进行通讯的情况下， 集群仍然可以正常运作， Redis 集群对节点使用了**主从复制**功能。

1. 集群中的每个节点都有 N 个复制品， 其中 1 个复制品为 Master， 而其余的 N-1 个复制品为 Slave。
2. 比如，在创建集群时，如果为 Master B 添加了 Slave B1 ， 那么当 Master B 下线时， 集群就会将 B1 设置为新的 Master， 并让它代替已下线的 Master B ， 继续处理原来的哈希槽， 这样集群就不会因为 Master B 的下线而无法正常运作了。
3. 但是，对于在这种场景下，如果节点 B 和 B1 都下线的话， 那么 Redis 集群还是会停止运作的。

###### 从节点选举

一旦某个 Master 进入 `FAIL` 状态， 如果这个 Master 有一个或多个 Slave 存在， 那么其中一个 Slave 会被升级为新的 Master， 而其他 Slave 则会开始对这个新的 Master 进行复制。

1. **新 Master 的选举条件**：
   1. 这个节点是已下线 Master 的 Slave。
   2. 已下线 Master 负责处理的槽数量为非空。
   3. Slave 的数据需要是可靠的， 即主从节点之间复制连接的断线时长，不能超过 （`cluster-node-timeout` 配置的节点超时时限 * `REDIS_CLUSTER_SLAVE_VALIDITY_MULT` 常量）得出的积。
2. 如果一个 Slave 满足了所有条件， 那么这个 Slave 将会向集群中的其他 Master **发送授权请求**， 询问它们， 是否允许自己升级为新的 Master。
3. 如果发送授权请求的 Slave 满足以下**授权要求**， 那么其他 Master 将向 Slave 返回 `FAILOVER_AUTH_GRANTED` 授权， 同意 Slave 的升级要求：
   1. 发送授权请求的是一个 Slave， 并且它所属的 Master 处于 `FAIL` 状态。
   2. 在已下线 Master 的所有 Slave 中， 这个 Slave 的节点 ID 在排序中是最小的。
   3. 这个 Slave 处于正常的运行状态，即没有被标记为 `FAIL` 状态， 也没有被标记为 `PFAIL` 状态。
4. 一旦某个 Slave 在给定的时限内得到大部分 Master 的 `FAILOVER_AUTH_GRANTED` 授权， 那么该 Slave 就会开始执行以下**故障转移**操作：显式地向所有节点广播一个 `PONG` 数据包， 加速其他节点识别这个节点的进度， 而不是等待定时的 `PING` / `PONG` 数据包。
   1. 告知其他节点， 自己现在是 Master了。
   2. 告知其他节点， 自己是一个已升级的 `PROMOTED` Slave。
      - 如果一个带有 `PROMOTED` 标识的 Master，由于某些原因又转变成回了 Slave，那么该节点将丢失它所带有的 `PROMOTED` 标识。
   3. 告知其他节点，自己接管了由那个已下线 Master 负责处理所有的哈希槽。
5. 所有其他节点都会根据新的 Master 对进行相应的**配置更新**：
   1. 所有被新的 Master 接管的槽会被更新。
   2. 已下线 Master 的所有 Slave 会察觉到 `PROMOTED` 标志， 并开始对新的 Master 进行复制。
   3. 如果已下线的 Master 重新回到上线状态， 那么它会察觉到 `PROMOTED` 标志， 并将自身调整为现任 Master 的 Slave。

###### 集群状态检测

1. 每当集群发生配置变化时（可能是哈希槽被更新，也可能是某个节点进入了 `FAIL` 状态），集群中的每个节点都会对它们自己所知道的节点进行扫描。
2. 配置扫描处理完毕后， 集群会进入以下两种状态的其中一种：
   - `OK` ： 集群可以正常工作，负责处理全部 `16384` 个槽的节点中， 没有一个节点被标记为 `FAIL` 状态。
   - `FAIL` ： 集群不能正常工作，当集群中有某个节点（该节点的所有主从）进入 `FAIL` 状态时， 集群不能处理任何命令请求， 对于每个命令请求， 集群节点都返回错误回复。
     - 说明即使集群中只有**一部分**哈希槽不能正常使用， 整个集群也会停止处理任何命令。
     - 不过节点从出现问题到被标记为 `FAIL` 状态的这段时间里， 集群仍然会**正常运作**， 所以集群在某些时候， 仍然有可能只能处理针对 `16384` 个槽的其中一个子集的命令请求。
3. 以下是集群进入 `FAIL` 状态的两种情况：
   - **出现至少有一个 哈希槽不可用时**：负责处理某个哈希槽的节点（该节点的所有主从）进入了 `FAIL` 状态。
   - **集群中的大部分 Master 进入了 `PFAIL` 状态时**：此时，集群可以在不请求大部分 Master 的意见下，快速地将某个节点判断为 `FAIL` 状态， 然后集群也会进入 `FAIL` 状态，从而让整个集群停止处理命令请求。

##### 数据弱一致性

Redis 集群**不保证数据的强一致性**，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令，**原因如下**：

- **异步复制**：Master 对命令的复制工作发生在返回客户端命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么 Master 处理命令请求的速度将极大地降低，因此 Redis 在性能和一致性之间做出了权衡，在复制工作上采取了异步复制。
  1. 客户端向 Master B 发送一条写命令。
  2. Master B 执行写命令，并向客户端返回命令回复。
  3. Master B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3。
  4. 如果写命令复制过程中，Master B 发生宕机的话，则会丢失这些被执行过的写命令。
- **集群内出现网络分区**：一个客户端与至少包括一个 Master 在内的少数实例被孤立。
  1. 举个例子，假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点，其中 A 、B 、C 为 Master，而 A1 、B1 、C1 分别为三个 Master 的 Slave，另外还有一个客户端 Z1 。
  2. 假设集群中发生网络分区，那么集群可能会分裂为两方，大多数的一方包含节点 A 、C 、A1 、B1 和 C1，而少数的一方则包含节点 B 和客户端 Z1 。
  3. 在这网络分区期间，主节点 B 仍然会接受 Z1 发送的写命令。
  4. 如果网络分区出现的时间很短，那么集群是可以继续正常运行的。
  5. 如果网络分区出现的时间足够长，使得大多数一方将 Slave B1 设置为新的 Master，那么当网络分区恢复时，原来的 Master B 就会被大多数一方的 Master B1 替代，成为 B1 的 Slave，导致原先 Z1 发送给 Master B 的写命令发生丢失。
     - 不过，在网络分区期间， 客户端 Z1 可以向 Master B 发送写命令的最大时间会被 `cluster-node-timeout` 配置的节点超时时限所限制：
       1. 对于大多数一方来说， 如果一个 Master 未能在 `cluster-node-timeout` 内重新联系上集群， 那么集群会将这个 Master 视为下线， 并使用它的 Slave 来代替自己继续工作。
       2. 对于少数一方来说， 如果一个 Master 未能在 `cluster-node-timeout` 内重新联系上集群， 那么它将停止处理写命令， 并向客户端**报告错误**。

##### 优点

- **高可用**：当集群中的一部分节点失效或者无法进行通讯时， 集群仍然可以继续处理命令请求的能力。
- **高性能**：操作某个 key 时，不会先找到节点再处理，而是直接重定向到目标 Redis 实例，相较代理分片少了 proxy 的连接损耗。
- **高拓展**：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

##### 缺点

- **只可使用普通单机 Redis 所有功能的一个子集**：不支持同时使用多个键的 Redis 命令，不支持多数据库功能， 只能使用默认的 `0` 号数据库。
- **数据弱一致性**：与其他高可用方案一样，Redis 集群也**不保证数据的强一致性**，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。
- **占用带宽**：虽然避免了 Master 单节点的问题，但集群内的数据同步、节点通信会占用一定的带宽。

##### 适用场景

只有在**写操作比较多**的情况下，集群模式才更有优势，相对于其他大多数情况，使用**哨兵模式**都能满足需求。

#### 高可用架构总结

##### AKF 拆分原则

![1632542719978](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542719978.png)

**AKF扩展立方体**，Scalability Cube，是在《The Art of Scalability》一书中被首次提出，旨在提供一个系统化的扩展思路。AKF 把系统扩展分为以下三个维度：

1. **X 轴**：代表无差别的克隆服务和数据，工作可以很均匀的分散在不同的服务实例上。
2. **Y 轴**：关注应用中职责的划分，比如数据类型、交易执行类型的划分。
3. **Z 轴**：关注服务和数据的优先级划分，如分地域划分。

=> X、Y、Z 轴的扩展并不是孤立的，可以同时对这 3 个维度进行扩展系统，分布式系统非常复杂，而 AKF 提供了一种自上而下的方法论，能够让我们针对不同场景下的性能瓶颈，以最低的成本去提升系统性能。

###### X 轴扩展 | 应用负载均衡

![1632542998175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542998175.png)

- **特点**：
  1. 在应用层做 X 轴扩展，需要处理业务的应用进程属于**无状态服务**，用户数据全部放在了关系数据库中。
  2. 此时可以在应用进程前加 1 个负载均衡服务，通过部署更多的应用进程，来获得更大的系统容量。
- **优点**：
  - 成本最低，实施简单：在搭建好负载均衡后，只需要在新的物理机、虚拟机或者微服务上复制程序，就可以让新进程分担请求流量，而且不会影响事务的处理。
  - 解决了**应用程序的单点故障**，提高了系统的可用性。
- **缺点**：只能扩展无状态服务，当有状态的数据库出现性能瓶颈时，应用层的 X 轴扩展就无能为力了。
  1. 当请求用户频率越来越高，这时可以把单实例数据库扩展为主备多实例，在数据库层沿 X 轴**读写分离**提升性能。
  2. 当业务持续发展，数据库的 CPU、网络带宽、内存、磁盘 IO 等某个指标率先达到上限后，系统的吞吐量就达到了瓶颈，这时可以在数据层库层沿 Y 轴`垂直分表` 提升性能。
  3. 当用户数据量持续增长，关系数据库中的表就会达到百万、千万行数据，SQL 语句会越来越慢，这时可以沿着 Z 轴**分库分表**提升性能。
- **适用场景**：发展初期，业务复杂度低，需要增大系统容量时。

###### X 轴扩展 | 读写分离

![1632544601407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632544601407.png)

- **特点**：
  - 把数据库按应用程序的读写操作拆分后，用复制的方式把数据库单机架构扩展为主从架构，让主库支持读写两种 SQL，而从库只支持读 SQL。
  - 如果读库性能达到了瓶颈，还可以继续沿着 X 轴扩展多个从库，提升读 SQL 的性能。
- **优点**：
  - 实现简单，读写分离成本由中间件承担。
  - 实现了**数据库的故障转移**，进一步提高了系统的可用性。
- **缺点**：应用中编写代码的成本有所增加，且主从复制存在数据一致性问题。
- **适用场景**：读频率远大于写频率，影响到系统性能时。

###### Y 轴扩展 | 垂直分表

![1632544928615](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632544928615.png)

- **特点**：当业务持续发展，数据库的 CPU、网络带宽、内存、磁盘 IO 等某个指标率先达到上限后，系统的吞吐量就达到了瓶颈，拆分系统功能，使得各组件的职责、分工更细，从而提升系统的效率。
- **优点**：
  - 每个后端的子应用更加聚焦于细分的功能，使得数据库规模会变小，更容易优化性能。
  - 实现了**数据库的故障隔离**，进一步提高了系统的可用性。
- **缺点**：拆分功能需要重构应用代码，成本对比较沿 X 轴的复制扩展要高得多。
- **适用场景**：业务复杂，代码耦合度高，非数据量导致的单库压力大时。

###### Z 轴扩展 | 分库分表

![1632547686194](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632547686194.png)

- **背景**：当用户数量上亿后，无论怎样基于 Y 轴的功能去垂直拆分表字段，都无法使得关系数据库单个表的行数在千万级以下，这样表字段的 B 树索引非常庞大，难以完全放在内存中，最后大量的磁盘 IO 操作会拖慢 SQL 语句的执行。
- **特点**：沿 Z 轴拆分关系数据库，进行**分库分表**操作。
  - 比如已经含有上亿行数据的 User 用户信息表，可以分成 10 个库，每个库再分成 10 张表，利用固定的哈希函数，就可以把每个用户的数据映射到某个库的某张表中。
  - 这样，单张表的数据量就可以降低到 1 百万行左右，如果每个库部署在不同的服务器上，它们处理的数据量减少了很多，却可以独占服务器的硬件资源，性能自然就有了提升。
- **优点**：
  - 是关系数据库中解决数据增长压力的最有效办法，可以降低数据持续增长的压力，提升系统性能。
  - 还可以从 `用户维度` 拆分系统，基于用户的地理位置获得额外收益。
    - 比如充分利用 IDC 与用户间的网速差，选择不同速度的 IDC，为不同的用户，提供不同性能的服务。
    - 再如将不同的用户分组，免费用户组与付费用户组，在业务上分离用户群体后，然后有针对性地为不同组的用户提供不同水准的服务。
- **缺点**：
  - 导致跨表的查询语句复杂许多，而跨库的事务几乎难以实现，应用程序代码编码成本高。
    - **解决方案**：使用某些厂商提供相应的中间件层，可以降低 Z 轴扩展的代价，同时，分片采用按照 ER 规则进行分片。
  - 当系统需要扩容时，一旦路由规则发生变化，会带来很大的**数据迁移成本**。
    - **解决方案**：使用一致性 hash 算法可以较好的避免这个问题。
  - 跨分片的事务一致性难以保证，当更新内容同时分布在不同库中，不可避免地带来跨库事务问题。
    - **解决方案**：分布式事务和最终一致性。
- **场景**：单表数据过大，影响系统性能时。

##### Redis AKF 拆分

![1632542544732](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542544732.png)

###### X 轴扩展 | 主从复制

- **特点**：
  1. 按照主从设计，Master 负责读写， Slave 负责读。
  2. 再结合哨兵集群，在 Master 故障时，使用 Slave 进行切换，从而实现高可用。
- **优点**：
  1. 主从，解决了读并发压力大的问题。
  2. 哨兵，解决了单点故障问题。
- **缺点**：单机容量会有限制，并且会出现写并发压力大的问题。

###### Y 轴扩展 | 业务拆分

- **特点**：
  - 把 Redis 所有键，按照业务进行拆分，拆分到不同的 Redis 实例上。
  - 可以在 Y 轴的基础上，再进行 X 轴的主从复制的扩展，形成不同业务的 Redis 集群。
- **优点**：从分离不同业务数据的角度，暂时解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：当某个业务的集群达到一定规模后，如果数据量过大，仍然会出现单机容量受限，以及写并发压力大的问题。

###### Z 轴扩展 | 数据分区

- **特点**：
  - 将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。
  - 可以在 Z 轴的基础上，叠加 X 轴的主从复制，集群内进行数据分片，比如 Redis Cluster。
  - 可以再叠加 Y 轴的业务拆分，把整个 Redis 系统划分成多个不同业务的、数据分片过的 Redis Cluster。
- **优点**：增加了整个集群的算力、带宽和内存，从根本上解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：
  - 数据分区后，不支持跨实例的命令与事务。
  - 备份管理要复杂得多。
  - 扩缩容时可能需要对数据再平衡。

### 2.2. Redis经典问题？

#### 缓存击穿

- **概念**：缓存中某一个热点数据，在某一时刻**失效**了，导致大量**并发**请求压垮数据库，就像被击穿了一样。
  - 说白了就是，某个数据在数据库中有，但是在缓存中没有。
- **解决方案**：
  1. **保证缓存一直存在**：以缓存**失效**作为切入点，通过保证缓存一直存在，避免或者减少击穿的发生。
     - **优点**：由于缓存长时间存在，且只在更新时才需要加互斥锁，整体吞吐量高。
     - **缺点**：缓存长期存在内存中，Redis 需要设置内存淘汰策略，淘汰非热点数据。
     - **实现方式**：
       - **不设置过期时间**：设置 key 永远不过期，在修改数据库时，同时更新缓存。
       - **定时任务更新**：后台起一个定时任务，每隔一段时间，在 key 快要失效时，提前将 key 刷新为最新数据。
       - **获取前更新**：每次获取前，检查 key 剩余过期时间，如果发现快过期了，则更新该 key。
       - **Redis 分级缓存**：缓存两份 Redis 数据，第 1 份数据用于被请求命中，第 2 份数据作为备份，生存时间设置得较第 1 份的长一点，如果第 2 份数据被命令则说明第 1 份数据已过期，此时要去查询数据库，更新这两级缓存。
  2. **保证数据库安全**：以**并发**请求数据库作为切入点，虽然保证了缓存一直存在，但在 Redis 发生内存淘汰时，还是可能发生击穿的，此时还需要保证数据库的安全。实现方式有：
     - **分布式锁**：只有获取到互斥锁的线程才能访问数据库，然后在释放锁前重新设置缓存；而其他获取锁失败的线程在唤醒后，不再访问数据库，而是查询缓存。
       - **优点**：可以在缓存更新时，实现互斥访问数据库，保证不被压垮。
       - **缺点**：
         1. 分布式锁本身也存在缺点。
         2. 需要搭配缓存一直存在机制使用，保证吞吐量。
         3. 如果只使用互斥锁来防止击穿，在获取锁失败时，快速返回默认值，也可以保证吞吐量。
     - **分级缓存**：Ehcache、Guava 本地缓存 + Hystrix限流、降级、熔断，避免 MySQL 被打死。
       - **优点**：有多级缓存和限流熔断机制来兜底。
       - **缺点**：增加了系统架构复杂度；本地缓存没有分布式一致性可言。
  3. **缓存预热**：见缓存预热。

#### 缓存雪崩

- **概念**：指大面积的 key 同时**失效**，导致大量**并发**请求压垮数据库。
  - 同样也是，某个数据在数据库中有，但是在缓存中没有。
- **缓存击穿与缓存雪崩**：
  1. 缓存击穿指的是，压垮数据库的所有并发请求都是只查同一条数据。
  2. 而缓存雪崩指的是，大量 key 同时失效，压垮数据库的所有并发请求，等于这些失效 key 的并发请求之和。
  3. 因此，可以把缓存雪崩中这些失效 key，拆成一个一个 key，从而把缓存雪崩看做成一个一个缓存击穿的集合。
- **解决方案**：
  1. **分散过期时间**：以缓存**失效**作为切入点，通过把 key 的过期时间设置成随机的，防止同一时间大量 key 同时失效的发生。
     - **优点**：简单有效。
     - **缺点**：不适合实时性要求比较高的业务，比如游戏的每日两点更新、财报记录等，它们都是需要在一个固定的时间，保证数据刷新，并且不允许出现旧数据。
  2. **分散并发请求**：同缓存击穿。

#### 缓存穿透

- **概念**：指由于请求了数据库也不存在的数据，导致缓存一直没有数据，大量并发绕过了缓存，从而压垮了数据库。
- **缓存击穿与缓存穿透**：
  1. 缓存击穿时，数据库里有请求所需数的据。
  2. 缓存穿透时，数据库里并不存在请求所需的数据。
- **解决方案**：
  1. **使用空 key**：对于这种在缓存获取不到，在数据库也获取不到的数据，可以把 key-null 设置到缓存中，这样下次访问时就可以走上缓存了。
     - **优点**：可以用于防止系统被恶意攻击。
     - **缺点**：只适用于数据能为空的 key；如果空 key 数量多且不重复时，则会造成很多无用 key 的存在。
  2. **使用布隆过滤器**：将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉。
     - **优点**：运行快速、内存占用小。
     - **缺点**：
       1. 对于元素的存在结果有误判，并且随着系统的不断运行，误判率会越来越高，此时可以**定期重建**布隆过滤器。
       2. 元素一旦存进布隆过滤器中，删除则十分困难，因为可能会删掉其他元素的 bit 结果，此时可以使用额外的删除标记变量进行**逻辑删除**。
  3. **后端接口增加校验**：比如用户鉴权校验、ID 基础校验等（ID <= 0的请求则直接拦截掉）。
     - **优点**：属于网关请求过滤，能过滤掉恶意请求。

#### 缓存预热

- **概念**：指在请求被缓存前，提早把相关的数据加载到缓存系统中，避免**初次击穿**问题的发生。
- **实现方式**：
  - **启动时加载**：在系统上线时，把相关可预期（比如排行榜）等热点数据，直接加载到缓存中。
  - **页面手动刷新**：也可以写一个缓存刷新页面，手动操作热点数据上下线（比如广告推广）。
- **优点**：保证了系统一开始就有缓存存在，能够在一定程度上避免**初次击穿**的发生。
- **缺点**：只能保证提前加载能够确定的热点数据，对于运行时的热点数据，还是需要靠以上两种方案。

#### 缓存降级

- **概念**：当访问量剧增、服务出现问题（如响应时间慢、甚至不响应），导致非核心服务影响到了核心流程的性能时，可以根据一些关键数据进行**自动降级**，也可以配置开关实现**人工降级**，从而保证核心服务可用性，即使是可能损害非核心服务。
- **实现方式**：比如基于日志级别实现的方案：
  1. **一般级别**：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以**自动降级**。
  2. **警告级别**：比如有些服务在一段时间内，成功率有所波动（比如在95~100%之间），可以**自动降级或人工降级**，并发送**告警**。
  3. **错误级别**：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阈值时，可以根据情况**自动降级或者人工降级**。
  4. **严重错误级别**：比如因为特殊原因数据错误了，此时需要**紧急人工降级**。
- **优点**：可以防止因非核心业务导致的 Redis 服务故障，从而保证核心服务的高可用，因此，对于**不重要的**缓存数据，可以采取缓存降级的策略。
- **缺点**：在进行降级之前，需要要对系统业务进行梳理，哪些可降级的，哪些是不可降级的（比如核心业务购物车、结算等）。

#### 缓存一致性

##### 一致性保证

- **概念**：在缓存机器的带宽被打满，或者机房网络出现波动时，**缓存更新失败**，新数据没有写入缓存，就会导致**缓存和DB**数据的不一致。
- **解决方案**：
  - **最终一致性保证**：
    1. Cache 更新失败后，可以进行重试，则将重试失败的 key 写入mq。
    2. 待缓存访问恢复后，将这些 key 从缓存**删除**。
    3. 然后 key 在再次被查询时，会重新从 DB 加载，从而保证数据的一致性。
    4. 另外，缓存 key 的过期时间可以适当地调短，让缓存数据及早过期，然后从 DB 重新加载，确保数据不一致的情况不会持续很长时间。
  - **强一致性保证**：读请求和写请求串行化，串到一个内存队列里去。
    - **缺点**：串行化之后，就会导致系统的吞吐量会大幅度的下降，正常情况下，需要多几倍的机器去支撑线上的一个请求。

##### 缓存模式

###### Cache-Aside

![1632829929514](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632829929514.png)

- **概念**：Cache-Aside，旁路缓存，缓存系统不和数据库直接进行交互，而是由应用程序同时和缓存以及数据库打交道，可能是项目中最常见的一种模式，是一种控制逻辑都实现在应用程序中的模式。
- **原理**：
  - **读数据时**：
    1. 应用程序需要判断缓存中是否已经存在数据。
    2. 当缓存中已经存在数据，也就是缓存命中时，则直接从缓存中返回数据。
    3. 当缓存中不存在数据，也就是缓存未命中时，则先从数据库里读取数据，并且存入缓存，然后返回数据。
  - **写数据时**：
    - **策略一**：先更新数据库，再更新缓存。
      - **缺点**：存在线程安全问题，当线程 A 先于 B 写入数据库，却后于 B 才更新缓存时，会导致数据库和缓存的数据不一致。
      - **解决方案**：加锁保证写入数据库和更新缓存操作的原子性。
    - **策略二**：先更新数据库，再删除缓存中的数据，下次在读取缓存时，才从数据库中重新加载。
      - **缺点**：数据最终一致性，在重新加载缓存时，数据库刚好被更新，此时就读到了旧的缓存，相当于发生了**脏读**。
      - **适合场景**：业务允许暂时不一致的场景。
  - **优点**：和 Write-Through 模式相比，避免了任何数据都被写入缓存，导致**缓存频繁更新**的问题。
  - **缺点**：
    - 当发生缓存未命中时，则从请求到成功获取缓存的过程会比较慢，因为需要经过三个步骤，先查询缓存，再数据库读取，最后写入缓存。
    - 复杂的逻辑都在应用程序中，如果实现微服务，多个微服务中会有这些重复的逻辑代码。
  - **使用场景**：适用于**不支持 Read-Through/Write-Through** 的缓存系统。

###### Read-Through/Write-Through

- **概念**：这种模式中，应用程序将**缓存**作为主要的数据源，而数据库对于应用程序是透明的，更新数据库和从数据库的读取的任务，都交给缓存来代理了，因此对于应用程序来说，实现时可以简单很多。

- **原理**：

  - **Read-Through**：

    1. 缓存配置了一个**读模块**，它知道如何将数据库中的数据写入缓存。
    2. 在数据被请求的时候，如果未命中，则将数据从数据库载入缓存。

    ![1632831602956](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632831602956.png)

  - **Write-Through**：

    1. 缓存配置了一个**写模块**，它知道如何将数据写入数据库。
    2. 当应用要写入数据时，缓存会先存储数据，并调用写模块将数据写入数据库。

    ![1632831718553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632831718553.png)

- **优点**：

  - 缓存不存在脏数据，相较于Cache aside而言更适合**缓存一致**的场景。
  - 屏蔽了底层数据库的操作，使得只需要操作缓存，应用程序逻辑相对简单。

- **缺点**：写多读少时，Write-Through 会非常浪费性能，因为数据可能更改了很多次，却没有被读取，白白地每次都写入缓存，造成写入延迟。

- **使用场景**：适用于**写入之后经常被读取**的应用。

###### Write-Behind

![1632832224155](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632832224155.png)

- **概念**：又叫 Write-Back，和 Write-Through 写入的时机不同，Write-Back 将缓存作为可靠的数据源，每次都只写入缓存，而写入数据库则采用异步的方式，比如当数据要被移除出缓存时再存储到数据库，或者在一段时间后批量更新数据库。
- **优点**：
  - 写入和读取数据都非常的快，因为都是从缓存中直接读取和写入。
  - 对于数据库不可用的情况有一定的容忍度，即使数据库暂时不可用，系统也整体可用，在数据库恢复后，再将数据写入数据库。
- **缺点**：有数据丢失的风险，如果缓存挂掉而数据没有及时写到数据库时，则缓存中有些数据会永久的丢失。
- **使用场景**：读写效率都非常好，由于是异步存储到数据库，提升了写的效率，适用于**读写密集**的应用。
  - 比如微博对一些计数业务，一条 Feed 会被点赞 1万 次，如果每次都更新 DB，前后需要更新 1万 次 DB， 代价很大；但如果每次只更新缓存，再合并成一次请求 DB 直接加 1万，则是一个非常轻量的操作。

###### Write-Around

![1632832607368](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632832607368.png)

- **概念**：和 Write-Through 不同，与 Write-Behind 相反，Write Aroud 更新时只写入数据库，不写入缓存。
- **优点**：写效率高，对比 Write-Through，如果数据写入后很少被读取，缓存也不会被没用到的数据占满。
- **缺点**：如果数据被写入多次，则可能导致缓存和数据库的数据不一致。
  - 可以结合 Read-Through 或者 Cache-Aside读 一起使用，只在缓存未命中的情况下写缓存，保证数据的最终一致性。
- **使用场景**：适合于**只写入一次而很少被读取**的应用。

#### Hot Key 问题

- **概念**：指在某个时刻，大量并发请求访问同一个 Key，导致 Redis 服务器压力过大甚至压垮。

  - 明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618 等线上促销活动，都很容易出现 Hot Key 的情况。

- **如何提前发现 Hot Key**？提前找到 Hot Key，可以先进行缓存预热，避免**初次击穿**问题的发生。

  1. **提前评估**：对于重要节假日、线上促销活动这些提前已知的事情，可以**提前评估**出可能的 Hot key 来。
  2. **实时分析**：而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行**实时分析**，及时发现新发布的 Hot Key。而对于之前已发出的事情，逐步发酵成为 Hot Key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频 Hot Key。

- **解决方案**：

  1. **分散 Hot Key**：这 n 个 key 分散存在多个缓存节点，然后 Client 端请求时，随机访问其中某个后缀的 Hot Key，这样就可以把 Hot Key 的请求打散，避免一个缓存节点过载。
  2. **限制逃逸流量**：和缓存击穿一样，通过加锁或者分散的方式，来限制逃逸流量，使得只有一个请求进行数据回源，并刷新本地缓存与 Redis 缓存，其他请求则等待后直接从缓存中的读取。
  3. **水平+垂直扩容**：缓存集群可以单节点进行主从复制和业务拆分（垂直分表）。
  4. **应用本地缓存**：利用应用内的本地缓存，但是需注意需要设置上限。
  5. **定时刷新**：延迟不敏感，定时刷新，实时感知用主动刷新。

  => 无论如何设计，最后都要写一个**兜底逻辑**，千万级流量说来就来。

#### Big Key 问题

- **概念**：指 key 存放的 value 非常大，由于 Redis 是单线程运行的，如果一次操作的 value 很大，则会对 Redis

  服务器长时间进入网络 I/O 拥塞，响应时间增大。

  - 比如互联网系统中需要保存用户最新1万个粉丝的业务，常常会出现 Big Key，因为一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等。
  - 再如，微博的 feed 内容缓存也很容易出现 Big Key，一般用户微博在 140 字以内，但很多用户也会发表 1千字甚至更长的微博内容，这些长微博也就成了 Big Key。

- **解决方案**：将 value 要存的大对象，分拆为多个小对象，然后通过 `multiGet` 来获取，这样可以把单次操作的压力，**平摊**到多个 Redis 实例中，降低对单个 Redis 的 I/O 影响。

### 2.3. Redis调优？

Redis 调优，可以根据缓存架构设计过程中常见的考量点入手：

https://blog.csdn.net/hualaoshuan/article/details/102638188

![1632893948796](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632893948796.png)

#### 缓存读写方式

- **考量内容**：value 读写方式，是选择全部整体读写，还是只部分读写及变更。

  - 比如，用户粉丝数，很多普通用户的粉丝有几千到几万，而大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表肯定不能采用整体读写的方式，**只能部分获取**。
  - 再如，在判断某用户是否关注了另外一个用户时，不需要拉取该用户的全部关注列表，可以直接在关注列表上进行**检查判断**，然后返回 True / False 或 0 / 1 的方式更为高效。

- **调优原则**：

  1. 避免使用 `keys`、`smembers` ，这些命令操作执行期间是阻塞其他客户端的，如果数据量大时，其阻塞的时间是不可接受的。

     - **解决方案**：生产上，可以使用增量式迭代命令 `scan`、`sscan`、`hscan`、`zscan` 命令来替代 `keys` 和 `smembers`，但增量迭代过程中 key 有可能会被修改，所以只能对被返回的元素提供有限的保证。

     | 命令  | 使用                                      | 作用                                                         |
     | ----- | ----------------------------------------- | ------------------------------------------------------------ |
     | SCAN  | SCAN cursor [MATCH pattern] [COUNT count] | 用于迭代当前数据库中的所有 key，返回的每个元素都是一个数据库键。cursor 使用 0，表示开始一次新的迭代，否则代表迭代时返回的游标，直到返回 0，则代表一次完整遍历；count 用于告知迭代命令需要返回的元素个数，默认为 10；pattern 与 `keys` 命令一样。 |
     | SSCAN | 用法同 `SCAN`                             | 用于迭代集合键中的元素，返回的每个元素都是一个集合成员。     |
     | HSCAN | 用法同 `SCAN`                             | 用于迭代哈希键中的键值对，返回的每个元素都是一个键值对，一个键值对由一个键和一个值组成。 |
     | ZSCAN | 用法同 `SCAN`                             | 用于迭代有序集合中的元素，返回的每个元素都是一个有序集合元素，一个有序集合元素由一个成员 member 和一个 score 组成。 |

  2. 批量添加多条数据时尽量选择 `pipline` ，减少发起多次客户端连接。

#### 缓存 KV Size

- **考量内容**：缓存键值对 key-value 所占用的内存。
- **调优原则**：
  1. 对于 key，尽量使用短的 key，有时可以不用刻意追求"见名知意"的目标，而导致拉大了 key 的长度。
  2. 对于 value，尽量也保持精简，比如性别可以用 0、1 表示。
  3. 对象实体可以尽量使用 `hash` 存储，因为如果使用 `string` 存储，每当要修改其中一项时，就需要把整个对象取回，效率低下，而使用 `hash` 可以很好地解决这个问题。
  4. 某些业务场景可以考虑使用 `bitmap` 来减少不必要的内存使用。

#### 缓存 Key 数量

1. 如果 key 数量不大，可以在缓存中存下**全量数据**，把缓存当 DB 存储来用，缓存读取 miss 时，则表明数据不存在，根本不需要再去 DB 查询。
2. 如果 key 数据巨大，则在缓存中尽可能只保留频繁访问的**热数据**，对于**冷数据**直接访问 DB。
3. 选择合适的内存回收策略，让 Redis 内存被填满了之后，尝试回收一部分key。

#### 缓存读写峰值

1. 对缓存数据的读写峰值，如果**小于 10 万**级别，简单分拆到独立 Redis 即可。
2. 而一旦数据的读写峰值**超过 10 万**甚至到达 100 万级的QPS，则可以同时使用 本地缓存 + Redis，甚至 Redis 缓存内部继续分层。

#### 缓存命中率

缓存的命中率，对整个服务体系的性能影响非常大，对于核心高并发访问的业务，需要预留**足够的容量**，减少内存淘汰的发生，确保核心业务缓存维持较高的命中率。

- 比如，微博中的 Feed Vector Cache，常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。

#### 缓存过期策略

1. 可以设置较短的过期时间，让冷 key 自动过期。
2. 也可以让 key 带上时间戳，同时设置较长的过期时间，比如 key_20191019，过了这个时间就可以把缓存删掉。

#### 缓存穿透时间

对于一些缓存穿透后，**加载时间特别长**或者需要**复杂计算**的数据，而且**访问量还比较大**的业务数据，要配置**更多容量**，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。

#### 缓存可运维性

需要考虑 Redis 的集群管理，如何进行一键扩缩容，如何进行 Redis 的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。

#### 缓存安全性

1. 一方面可以限制来源 IP，只允许内网访问。
2. 另一方面，对于一些**关键性指令**，需要增加**访问权限**，避免被攻击或误操作时，导致重大后果。

# 六、消息队列篇

### 1.1. 什么是消息队列？

#### 概念

- **消息**：Message，指在应用间传送的数据，消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。
- **消息队列**：Message Queue，MQ，是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。
  1. 消息发布者只管把消息发布到 MQ 中，而不用管谁来取。
  2. 消息使用者只管从 MQ 中取消息而不管是谁发布的。
  3. 这样发布者和使用者都不用知道对方的存在，解除了上下游调用的依赖关系，实现异步和解耦。
  4. MQ 作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。
  5. 目前主流的消息队列有 ActiveMQ、Kafka、RocketMQ、RabbitMQ 等。

#### 用途

- **异步处理**：把消息写入消息队列，使得**非必要**的业务逻辑能够以异步的方式运行，从而加快响应速度。

  ![1633838988599](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633838988599.png)

- **系统解耦**：解决不同重要程度、不同能力级别系统之间依赖导致一死全死的问题。

  ![1633838915140](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633838915140.png)

- **削峰填谷**：主要解决瞬时写压力大于应用服务能力，把瞬时的大数据量放到后面慢速消费掉，从而导致消息丢失、系统奔溃等问题。

- **蓄流压测**：线上有些链路不好压测，可以通过堆积一定量消息再放开来压测。

- **其他用途**：广播订阅、RPC 调用、日志收集、数据同步、数据采集、分布式事务支持等。

#### 局限

- **系统可用性降低**：本来系统运行好好的，如果加个消息队列进去，那消息队列挂了，系统可用性就可能会降低。
- **系统复杂性增加**：增加消息队列组件，要多考虑很多方面的问题，系统复杂性增大，比如一致性问题、如何保证消息不被重复消费、如何保证保证消息可靠传输等。

#### 技术选型

##### 基础对比

| 比较点     | Kafka                                                        | RocketMQ                                          | RabbitMQ                          |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------- | --------------------------------- |
| 设计定位   | 系统间的数据流管道，实时数据处理                             | 非日志的可靠性传输                                | 可靠消息传输                      |
| 使用场景   | 常规的消息系统、网站活性跟踪、监控数据、日志收集、处理等     | 订单、交易、充值、流计算、消息推送、binlog 分发等 | 类似于RocketMQ                    |
| 成熟度     | 日志领域成熟                                                 | 成熟                                              | 成熟                              |
| 所属社区   | Apache                                                       | Alibaba 开发，现已加入到 Apache下                 | Mozilla Public License            |
| 社区活跃度 | 高                                                           | 中                                                | 高                                |
| API完备性  | 高                                                           | 高                                                | 高                                |
| 文档完备性 | 高                                                           | 高                                                | 高                                |
| 开发语言   | Scala                                                        | Java                                              | Erlang                            |
| 支持协议   | 一套自行设计的基于TCP的二进制协议                            | 自定义的一套非JMS协议                             | AMQP                              |
| 客户端语言 | C/C++、Python、Go、Erlang、.NET、Ruby、Node.js、PHP、Java 等 | Java                                              | Java、C、C++、Python、PHP、Perl等 |

##### 功能对比

|                | Kafka                                        | RocketMQ                                                     | RabbitMQs                                                    |
| -------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 生产端负载均衡 | 可自由指定                                   | 可自由指定                                                   | 需要单独的Load balancer支持                                  |
| 生产端批量发送 | 支持，默认Producer缓存、压缩，然后批量发送   | 不支持                                                       | 不支持                                                       |
| 消费 失败重试  | 支持，offset存储在ZK中                       | 支持，offset存储在broker中                                   | 支持                                                         |
| 消费方式       | Consumer Pull                                | Consumer pull、Broker push                                   | Broker push                                                  |
| 消费并行度     | 消费并行度和分区数一致                       | 顺序消费：消费并行度和分区数一致；乱序消费：消费服务器的消费线程数之和 | 镜像模式下其实等价于从Master消费                             |
| 顺序消费       | 支持，但是一台broker宕机后，就会产生消息乱序 | 支持，在顺序消息场景下，消费失败时消息队列将会暂定           | 支持，但是如果一个消费失败，消息的顺序会被打乱               |
| 消息重新消费   | 支持，通过修改offset来重新消费               | 支持，按照时间重新消费                                       | -                                                            |
| 定时消息       | 不支持                                       | 开源版本仅支持定时Level                                      | 不支持                                                       |
| 事务消息       | 不支持                                       | 支持                                                         | 不支持                                                       |
| 消息过滤       | 不支持                                       | 支持，通过tag过滤，类似于子topic                             | 不支持                                                       |
| 消息查询       | 不支持                                       | 支持，根据MessageId查询，支持根据MessageKey查询信息          | 不支持                                                       |
| 消息清理       | 指定文件保存时间，过期删除                   | 指定文件保存时间，过期删除                                   | 默认可用内存40%触发GC，GC时找到相邻的两个文件，合并right文件到left |

##### 高可用对比

|            | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储方式   | 磁盘文件                                                     | 磁盘文件                                                     | 内存、文件                                                   |
| 部署依赖   | Zookeeper                                                    | NameServer                                                   | Erlang环境                                                   |
| 部署方式   | 单机、集群                                                   | 单机、集群                                                   | 单机、集群                                                   |
| 集群管理   | Zookeeper                                                    | NameServer                                                   | -                                                            |
| 选主方式   | 从 ISR 中自动选举一个 Leader                                 | 不支持自动选主，brokername相同，brokerid = 0时为Master了，其他为Slave | 最早加入集群的broker                                         |
| 主从切换   | 支持，一主多备，Master失效后自动从ISR中选择一个主            | 不支持，Master失效以后不能消费，Consumer默认30s可以感知此事，此后从Slave消费，如果Master无法恢复，异步复制时可能会丢失部分消息 | 支持，最早加入集群的Slave会成为Master，由于新加入的Slave不会同步Master之前的数据，所以可能会丢失部分数据 |
| 复制备份   | 消息写入到Leader的log，Followers从Leader中pull，pull到数据以后先ack Leader，然后写入log中，ISR中维护与Leader同步的列表，落后太多的Follower会被删除掉 | 同步双写、异步复制（Slave启动线程从Master中拉数据）          | 普通模式下不复制；镜像模式下，消息先到Master，然后镜像到Slave上，入集群之前的消息不会被复制到新的Slave上 |
| 可用性     | 非常高，分布式、主从                                         | 非常高，分布式、主从                                         | 高，主从、镜像模式（数据量大时可能产生性能瓶颈）             |
| 数据可靠性 | 很好，支持Producer单条发送、同步复制，但这种场景下性能明显下降 | 很好，Producer单条发送，broker端支持同步刷盘、异步刷盘、同步双写、异步复制 | 好，Producer支持同步、异步ACK，支持队列数据持久化，镜像模式中支持主从同步 |

##### 运维对比

|              | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                 |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------------------------- |
| 系统维护     | Scala语言开发，维护成本高                                    | Java语言开发，维护成本低                                     | Erlang语言开发，维护成本高                               |
| 访问权限控制 | 无                                                           | 无                                                           | 支持配置用户名和密码                                     |
| 管理后台     | 官网不提供，第三方开源管理工具可供使用，不用重新开发         | 官方提供，rocketmq-console                                   | 官方提供，rabbitmqadmin                                  |
| 管理后台功能 | broker、topic、partition、logsize、consumer groups、offset、cluster | cluster、topic、connection、nameserv、message、broker、offset、consumer | overview、connection、channels、exchanges、queues、admin |

#### 技术选型总结

|                  | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                     | Java                      |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------- |
| 开发语言         | Scala                                                        | Java                                                         | Erlang                                                       | Java                      |
| 单机吞吐量       | 10w级别                                                      | 10w级别                                                      | 1w级别                                                       | 1w级别                    |
| 消息写入性能     | 非常好，每条10个字节测试下，100w/s                           | 很好，每条10个字节测试下，单机单broker约7w/s，单机3个broker约12w/s | RAM模式约为RocketMQ的1/2，Disk模式性能约为RAM模式的1/3       | -                         |
| 消息投递实时性   | 毫秒级，具体由Consumer轮询间隔时间决定                       | 毫秒级，支持pull、push两种模式，延时通常在毫秒级             | 毫秒级                                                       | 毫秒级                    |
| 单机支持的队列数 | 单机超过64个队列/分区，Load会发生明显的飙高，队列越多，Load越高，发送消息的响应时间越长 | 单机支持最高5w个队列，并且Load不会发生明显变化               | 依赖于内存                                                   | -                         |
| 堆积能力         | 非常好，消息存储在log中，每个分区一个log文件                 | 非常好，所有消息存储在同一个commit log中                     | 一般，生产者、消费者正常时，性能表现稳定；消费者不消费时，性能不稳定 | -                         |
| 性能稳定性       | 队列/分区多时，性能不稳定、明显下降；消息堆积时，性能稳定    | 队列较多、消息堆积时，性能都稳定                             | 消息堆积时，性能不稳定、明显下降                             | -                         |
| 可用性           | 非常高，分布式、主从                                         | 非常高，分布式、主从                                         | 高，主从、镜像模式                                           | 高，Master-Slave、Network |
| 数据可靠性       | 很好，支持Producer单条发送、同步复制，但这种场景下性能明显下降 | 很好，Producer单条发送，broker端支持同步刷盘、异步刷盘、同步双写、异步复制 | 好，Producer支持同步、异步ACK，支持队列数据持久化，镜像模式中支持主从同步 | 有较低概率丢失数据        |

##### 为什么使用 Kafka？

高可用，几乎所有相关的开源软件都支持，满足大多数的应用场景，尤其是**大数据和流计算**领域。

- **优势**：
  - 高性能，高吞吐，消息持久化，可伸缩，支持分区、副本和容错。
  - 对批处理和异步处理做了大量的设计，因此可以得到非常高的性能，每秒处理几十万异步消息，如果开启了压缩，最终可以达到每秒处理 2000w 消息的级别。
- **局限**：
  - 由于是异步的和批处理的，延迟也会高，不适合电商场景。
  - 不支持事务。
  - 消费集群数目受 Partition 数目限制。
  - 单机 Topic 多时，性能会明显降低。
- **使用建议**：
  1. Kafka 提供的消息中间件的功能明显较少一些，相对上述几款 MQ 中间件要少很多。
  2. 但是 Kafka 优势在于，专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。
  3. 因此，Kafka在大数据领域中配合实时计算技术（比如Spark Streaming、Storm、Flink）使用的较多，在传统的 MQ 中间件使用场景中较少采用。
  4. 如果是大数据领域的**实时计算、日志采集**等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

##### 为什么使用 RocketMQ？

借鉴了Kafka的设计并做了很多改进，几乎具备了消息队列应该具备的**所有特性和功能**。

- **优势**：
  - 主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。
  - 对电商领域的响应延迟做了很多优化，每秒处理**几十万**的消息，同时响应在毫秒级，如果应用很关注响应时间，可以使用RocketMQ，性能比RabbitMQ高一个数量级，同时，经过了历次的双11考验，性能，稳定性可靠性没的说。
  - Java开发，阅读源代码、扩展、二次开发很方便。
- **局限**：
  - 消息堆积、吞吐量上不如Kafka。
  - 不支持主从自动切换，master失效后，消费者需要一定的时间才能感知。
  - 客户端只支持Java，跟周边系统的整合和兼容不是很好。
- **使用建议**：
  1. RocketMQ，是阿里开源的，经过阿里的生产环境的超高并发、高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。
  2. 而且RocketMQ是基于Java语言开发的，适合深入阅读源码，有需要可以站在源码层面解决线上生产问题，包括源码的二次开发和改造。
  3. RocketMQ，确实很不错，但社区活跃度其实不算高，可能有突然黄掉的风险，如果对公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，毕竟 RabbitMQ 有活跃的开源社区，绝对不会黄，所以**大型公司，基础架构研发实力较强**，用 RocketMQ 是很好的选择。

##### 为什么使用 RabbitMQ？

RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款**支持AMQP**协议的产品之一。

- **优势**：
  - 轻量级、低延迟，快速，部署使用方便。
  - 支持灵活的路由配置，在生产者和队列之间有一个交换器模块，根据配置的路由规则，生产者发送的消息可以发送到不同的队列中，路由规则很灵活，还可以自己实现。
  - 客户端支持大多数的编程语言，支持**AMQP**协议。
- **局限**：
  - 消息吞吐能力有限，如果有大量消息堆积在队列中，性能会急剧下降，每秒处理**几万到几十万**的消息，如果应用要求高的性能，注意不要选择 RabbitMQ。
  - 不支持事务。
  - 集群不支持动态扩展，横向扩展能力不是那么好。
  - RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。
- **使用建议**：
  1. 好处在于可以支撑高并发、高吞吐、性能很高，同时有非常完善便捷的后台管理界面可以使用，还支持集群化、高可用部署架构、消息高可靠支持，功能较为完善。
  2. 经过调研，国内各大互联网公司落地大规模 RabbitMQ 集群支撑自身业务的 case 较多，国内各种中小型互联网公司使用 RabbitMQ 的实践也比较多，同时开源社区很活跃，较高频率的迭代版本，来修复发现的bug以及进行各种优化，因此综合考虑过后，可以采取 RabbitMQ。
  3. 但是 RabbitMQ 也有一点缺陷，就是它自身是基于 Erlang 语言开发，导致较为难以分析里面的源码，也较难进行深层次的源码定制和改造，毕竟需要较为扎实的 Erlang 语言功底才可以。
  4. RabbitMQ 的 Erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高，管理功能很丰富，所以**中小型公司，技术实力较为一般，技术挑战不是特别高**，用 RabbitMQ 是不错的选择。

##### 为什么使用 ActiveMQ？

ActiveMQ，是老牌的消息中间件，国内很多公司过去运用的还是非常广泛的，功能很强大。

- **使用建议**：
  1. 由于 ActiveMQ 无法支撑互联网公司的高并发、高负载以及高吞吐的复杂场景，因此，在国内互联网公司落地较少，使用较多的还是一些**传统企业**，用 ActiveMQ 进行异步调用和系统解耦。
  2. 一般的业务系统最早都用 ActiveMQ，但是现在确实用的不多了，而且没经过大规模吞吐量场景的验证，社区也不是很活跃，所以还是算了吧，不推荐使用。

#### 如何设计消息队列？

##### 生产端可靠性投递

如果涉及的是金融相关的业务， 需要保证消息一定不能丢失，做到生产端发出消息时跟数据库操作保持一个原子性操作。

##### 幂等性消费

由于生产者需要做到可靠性投递，可能会出现重复的消息，如果重复的消息被消费者消费了两次或者多次，可能会导致数据的不一致，所以，此时消费端一定要做到一个幂等性的验证。

##### 高可用性

如果MQ一个Broker挂掉了， 应该如何保证服务的高可用？ => HA

##### 低延迟

在MQ面对巨量的流量冲压下，应该如何消息写入的低延迟？是否会给系统带来瓶颈？

##### 可靠性

在消息落到MQ，应该如何保障肯定不会丢失？比如磁盘损坏 => 副本的方式

##### 堆积能力

某个业务场景下，到底有多少的数据量，大体预估消息高峰期会堆积到什么程度？MQ能不能抗住流量的冲击？

##### 可扩展性

MQ能否天然的支持无感知横向扩容？

### 1.2. 什么是 JMS？

#### 概念

- JMS，Java Message Service，Java 消息服务，定义了 Java 中访问消息中间件接口的规范，只是接口并没有给予实现，而实现 JMS 接口的消息中间件称为 JMS Provider。
- 目前知名的MOM（Message Oriented Middleware，消息中间件）包括： ActiveMQ、RocketMQ、Kafka 以及 RabbitMQ，他们都是**基本遵循**或者**参考**JMS规范，都有自己的特点和优势。

| 专业术语          | 释义                                                         |
| ----------------- | ------------------------------------------------------------ |
| JMS               | Java Message Service，实现 JMS 接口的消息中间件              |
| Provider          | Message Provider，消息的生产者                               |
| Consumer          | Message Consumer，消息的消费者                               |
| PTP               | Point to Point，点对点的消息模型                             |
| Pub/Sub           | Publish/Subscribe，发布/订阅模型                             |
| Queue             | 消息队列，一般都是会真正的进行物理存储                       |
| Topic             | 主题目标                                                     |
| ConnectionFactory | 连接工厂，JMS 用它来创建连接                                 |
| Connection        | JMS 客户端到 JMS Provider 的连接                             |
| Destination       | 消息的目的地，指对于生产者来说是消息发送目标，对于消息消费者来说是消息来源 |
| Session           | 会话，一个发送或接收消息的线程，好比Mybatis的Session         |

#### 消息投递模式

##### PTP模式

P2P模式，点对点模式，包含三个角色：消息队列（Queue），发送者（Sender），接收者（Receiver），每个消息都被发送到一个特定的队列，接收者从队列中获取消息，在这期间，队列保留着消息，直到他们被消费或超时。

- **特点**：
  - 每个消息只有一个消费者，即一旦被消费，消息就不再在消息队列中。
  - 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列。
  - 接收者在成功接收消息之后需向队列应答成功。
- **适用场景**：如果希望发送的**每个消息**都会被成功处理的话，那么需要P2P模式。

![1633184806569](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633184806569.png)

##### Pub/Sub模式

Pub/Sub模式，发布订阅模式，包含三个角色：主题（Topic），发布者（Publisher），订阅者（Subscriber） ，多个发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。

- **特点**：
  - 每个消息可以有多个消费者。
  - 发布者和订阅者之间有时间上的依赖性，针对某个主题的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。
  - 为了消费消息，订阅者必须保持运行的状态，另外，为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅，使得即使订阅者没有在运行，它也能接收到发布者的消息。
- **适用场景**：如果希望发送的消息可以**不被做任何处理**、或者**只被一个消息者处理**、或者可**以被多个消费者处理**的话，那么可以采用Pub/Sub模型。

![1633185288754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633185288754.png)

### 1.3. 详细介绍ActiveMQ？

##### 概念

- ActiveMQ，Apache出品，是当前最流行的、能力强劲的开源消息总线。
- ActiveMQ，是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。
- 如果想对大规模、高并发应用服务做消息中间件技术选型，譬如淘宝、京东这种大型的电商网站，尤其是双 11 这种特殊时间，ActiveMQ 可能就显得力不从心了。

##### 特点

1. 多种语言和协议编写客户端。
   - 语言：Java、C、C++、C#、Ruby、Perl、Python、PHP。
   - 应用协议：OpenWire、Stomp REST、WS Notification、XMPP、AMQP.
2. 完全支持 JMS1.1 和 J2EE 1.4 规范 
   - 持久化，XA消息，事务。
3. 对Spring的支持：
   - ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性。
4. 通过了常见 J2EE 服务器（如 Geronimo、JBoss 4、GlassFish、WebLogic）的测试：
   - 其中通过 JCA 1.5 resource adaptors 的配置，可以让 ActiveMQ可以自动的部署到任何兼容 J2EE 1.4 商业服务器上。
5. 支持多种传送协议：
   - in-VM、TCP、SSL、NIO、UDP、JGroups、JXTA。
6. 支持通过 JDBC 和 journal 提供高速的消息持久化。
7. 从设计上保证了高性能的集群：
   - 客户端-服务器，点对点。
8. 支持Ajax。
9. 支持与Axis的整合。
10. 可以很容易得调用内嵌 JMS provider，进行测试。

##### 指标

衡量一个 MOM 消息中间件，主要从三方面考虑即可，即服务性能、存储堆积能力（数据存储）和可扩展性（集群架构）。

- **服务性能**： ActiveMQ 的性能一般，在早期传统行业为王的时代比较流行，但现如今面对高并发、大数据的业务场景，往往力不从心。
- **数据存储**：默认采用 Kahadb（索引文件形式）存储，也可以使用高性能的 google leveldb（内存数据库存储），或者可以使用 MySQL、Oracle 关系型数据库进行消息存储。
- **集群架构**：ActiveMQ 可以与 Zookeeper 构建成主备集群模型，并且多套的主备模型直接可以采用 Network 的方式构建分布式集群。

##### 集群架构模式

ActiveMQ 最经典的两种集群架构模式为：Master-Slave、Network。

- **Master-Slave**：

  - **概念**：顾名思义，即主从，或者主备方式（双机热备机制），是目前 ActiveMQ 推荐的高可靠性和容错的解决方案。
  - **原理**：如果消息被复制到 Slave Broker后，即使 Master Broker 遇到了像硬件故障之类的错误，也可以立即切换到 Slave Broker 而不丢失任何消息。
  - **缺点**：做不到分布式的 topic 和 queue，当消息量巨大时，MQ 集群压力就会过大，没办法满足分布式的需求。

  ![1633244456251](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633244456251.png)

- **Network**：

  - **概念**：可以理解为网络通信方式，也可以叫 Network of Brokers，其消息会进行均衡，真正解决了分布式消息存储、故障转移和 Broker 切换的问题。
  - **原理**：一个 Broker 会相同对待所有的订阅，不管他们是来自本地的客户连接，还是来自远程 Broker，都会递送有关的消息拷贝到每个订阅，远程 Broker 得到这个消息拷贝后，会依次把它递送到其内部的本地连接上。
  - **缺点**：
    1. 部署非常麻烦，需要两套或者多套集群直接相互交叉配置，相互间能够感知到彼此的存在。
    2. 虽然解决了分布式消息队列的问题，但还有许多潜在的问题，比如资源浪费问题。
       - 通常采用 Master-Slave 模型是传统型互联网公司的首选，而互联网公司往往会选择开箱即用的消息中间件，从运维、部署、使用各个方面都要优于 ActiveMQ。

  ![1633244714673](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633244714673.png)

### 1.4. 什么是AMQP？

AMQP，Advanced Message Queuing Protocol，高级消息队列协议，是具有现代特征的二进制协议，是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个**开放标准**，为面向消息的中间件设计。

- **Publisher application**：生产者应用程序，与 Exchage 是多对多的关系。
- **Consumer application**：消费者应用程序，与 Queue 是多对多的关系。
- **Server**：消息队列服务器，物理机。
- **Virtual host**：虚拟主机，用于划分模型域。
- **Exchange**：交换机，类似于主题，是一个逻辑的概念，需要跟 Queue 绑定起来，与 Queue 是多对多的关系。
  - 生产者可以向 Exchange 投递消息，Exchange 会根据一定规则把消息路由到某几个队列中。
- **Message Queue**：消息队列，是一个逻辑的概念，与 Exchange 是多对多的关系。
  - 消费者可以从 Queue 消费消息。

![1633250094430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633250094430.png)

### 1.5. 详细介绍RabbitMQ？

#### 概念

RabbitMQ，是一个开源的、基于Erlang 语言编写的、实现了 AMQP 协议的分布式消息队列系统，采用经典和新颖的消息传递方式，进行跨应用共享数据，其消息路由的强大（广播、直连、主题、首部交换机等）以及容易使用（只需添加和删除消费者即可完成扩展和缩小），使得能够在 MQ 中脱颖而出。

- **通用用途**：异步处理、系统解耦、削峰填谷。
- **特色用途**：广播订阅、RPC 调用。

| 专业术语    | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Server      | 又称 Broker， 指消息队列服务器实体，用于接受客户端的连接     |
| Connection  | 连接，应用程序与 Broker 建立的网络连接                       |
| Channel     | 网络信道，几乎所有的操作都在 Channel 中进行，是进行消息读写的通道（通过 Connection是发送不了消息的），客户端可建立多个 Channel，每个 Channel 代表一个会话任务 |
| Message     | 消息，服务器和应用程序之间传递的数据，由 Properties 和 Body 组成，Properties 可以对消息进行修饰，比如消息的优先级、延迟等高级特性，Body 则是消息体的内容 |
| VHost       | Virtual host，虚拟地址，用于进行**逻辑隔离**，是最上层的消息路由，一个 Vhost 里面可以有若干个 Exchange 和 Queue，但它们的名称不能相同；Vhost 拥有独立的权限系统，可以做到 Vhost 范围的用户控制。 |
| Exchange    | 交换机，接收生产者投递的消息，生产者可以在发送消息时带上 Routing Key，交换机会根据 Routing Key 路由消息到绑定的队列 |
| Binding     | Exchange 和 Queue 之间的虚拟连接，可以包含 Routing Key，把 Exchange 和 Queue按照Routing Key 绑定起来 |
| Routing Key | 路由关键字，一个路由规则，虚拟机可以用来确定如何路由一个消息 |
| Queue       | 又称 Message Queue，消息队列，保存消息并将它们转发给消费者，每个消息可能会被路由到一个或者多个队列 |
| Producer    | 消息生产者，指投递消息的程序                                 |
| Consumer    | 消息消费者，指消费消息的程序                                 |

#### 原理

![1633680788174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633680788174.png)

1. 一方面，生产者向 Exchange 发送消息。
2. Exchange （比如根据 RoutingKey ）把消息路由到 Queue 或者其他 Exchange中。
3. RabbitMQ Broker 在收到消息时，向生产者发送确认。
4. 另一方面，消费者与 RabbitMQ 保持 TCP 长连接，并声明所消费的 Queue。
5. 消息路由到 Queue 后，RabbitMQ 会向消费者**推送消息**。
   - **为什么推而不是拉？**
     1. 推比拉消息分布更均匀，更适合低延迟。
     2. 当某单个队列出现竞争消费者时，如果每个消费者都拉取消息，由于每个消息者拉取的数量不同，消息分布可能会变得非常不均匀。
     3. 消息分布越不均匀，延迟就越多，消费时消息排序的丢失就越严重。
6. 消息消费完毕，消费者会把消费结果（成功或者失败）返回给 RabbitMQ Broker。
7. RabbitMQ Broker 一旦发现消费者消费成功，就会把消息就从 Queue 中移除。

#### API

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>com.rabbitmq</groupId>
    <artifactId>amqp-client</artifactId>
    <version>3.6.5</version>
</dependency>
```

##### 生产者 | HelloWorld

```java
public static void main(String[] args) throws IOException, TimeoutException {
    // 1. 创建ConnectionFactory
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(HOST);
    connectionFactory.setPort(PORT);
    connectionFactory.setVirtualHost(VIRTUAL_HOST);

    // 2. 创建Connection
    Connection connection = connectionFactory.newConnection();

    // 3. 创建Channel
    Channel channel = connection.createChannel();

    // 4. 创建Queue: 一般不在Java中创建, 而是提前维护好队列
    // Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments) throws IOException;
    channel.queueDeclare(ROUTING_KEY, false, false, false, null);

    // 5. 构建消息
    AMQP.BasicProperties props = new AMQP.BasicProperties.Builder()
        .deliveryMode(2)
        .contentEncoding("UTF-8")
        .headers(new HashMap<String, Object>())
        .build();

    // 6. 发送消息到Queue中
    for(int i = 0; i < 5; i++){
        String msg = "Hello World RabbitMQ" + i;
        // 注意, 这里EXCHANGE_NAME为"", 表示采用了默认的交换机(Direct模式), 因此, 表示把消息路由到名称为ROUTING_KEY的Queue上
        // void basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException;
        channel.basicPublish("", ROUTING_KEY, props, msg.getBytes());
        System.out.println("发送消息完毕...");
    }
}
```

##### 消费者 | HelloWorld

```java
public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {
    // 1. 创建ConnectionFactory
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(HOST);
    connectionFactory.setPort(PORT);
    connectionFactory.setVirtualHost(VIRTUAL_HOST);
    connectionFactory.setAutomaticRecoveryEnabled(true);
    connectionFactory.setNetworkRecoveryInterval(3000);

    // 2. 创建Connection
    Connection connection = connectionFactory.newConnection();

    // 3. 创建Channel
    Channel channel = connection.createChannel();

    // 4. 创建Queue: 生产者创建了消费者就不用创建了
    // channel.queueDeclare(ROUTING_KEY, false, false, false, null);

    // 5. 创建Consumer
    QueueingConsumer queueingConsumer = new QueueingConsumer(channel);
    // 由于采用了默认的交换机(Direct模式), 因此ROUTING_KEY的消息会路由到名为ROUTING_KEY的Queue中, 所以消费者去ROUTING_KEY队列中拿消息
    // String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;
    channel.basicConsume(ROUTING_KEY, true, queueingConsumer);

    // 6. 拉取 & 监听消息
    System.out.println("开始监听消息...");
    while (true){
        QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
        String msg = new String(delivery.getBody());
        System.out.println("收到消息: " + msg);
    }
}
```

##### Exchange 属性

Exchange，交换机，接收消息，并根据 ROUTING_KEY 转发消息所绑定的队列。

| 属性        | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Name        | 交换机名称                                                   |
| Type        | 交换机类型， direct、topic、fanout、headers                  |
| Durability  | Exchange 是否需要持久化，true表示需要持久化，一般生产都是需要持久化的 |
| Auto Delete | 当最后一个绑定到 Exchange 上的队列被删除后，是否自动删除该 Exchange，不常用，一般生产都是不需要自动删除的 |
| Internal    | 当前 Exchange 是否用于 RabbitMQ 内部使用，外部无法访问；默认为 False，代表外部使用，外部可以访问 |
| Arguments   | 扩展参数，用于扩展 AMQP 协议，来自动化使用，比如特殊功能、或者带延迟功能的交换机 |

###### Direct Exchange

![1633266272323](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633266272323.png)

Direct Exchange，直连交换机，所有发送到 Direct Exchange 的消息，都会被转发到 RoutingKey 指定的 Queue 中。

- 直连模式下，可以不需要对 Exchange 进行任何绑定 binding 操作，比如此时 Exchange 为 ""，则默认使用 RabbitMQ 自带的 Exchange（**AMQP.default**），此时 RoutingKey 为 Queue 的名称。
- 在其他消息传递时，发送时指定的 RoutingKey 必须和 Queue 名称完全匹配时，该消息才会被 Queue 接收，否则该消息会被抛弃。

```java
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, null, msg.getBytes());

// 消费者 - Queue绑定Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ROUTING_KEY);
// 消费者 - 绑定消费队列
// String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Topic Exchange

![1633329219405](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633329219405.png)

Topic Exchange，主题交换机，所有发送到 Topic Exchange 的消息，都会被转发到所有关心该 RoutingKey #Topic 的 Queue上。

- Queue 通过绑定一个 Topic，如果 Exchange 发现某个 RoutingKe 能够与该 Topic 进行**模糊匹配**，则会把消息投递到该 Queue 中。
  - `#` 表示匹配一个或多个词，比如 "log.info.oa" 能够匹配 `log.#`，则 RoutingKey 为 "log.info.oa" 的消息，将会被 Exchange 投递到 Topic 为 `log.#` 的 Queue 中。
  - `*` 表示只能匹配一个词，比如 "log.erro" 能够匹配 `log.*`，则 RoutingKey 为 "log.erro" 的消息，将会被 Exchange 投递到 Topic 为 `log.*` 的 Queue 中。
- Queue 和 Exchange 是多对多的关系，但如果业务上使用多对多的关系，会导致消息投递逻辑比较乱，建议一类消息只搞一种规则（比如 `test.#`），只投递到一个 Exchange 中，一个 Exchange 绑定多个 Queue，然后消费者从 Queue 消费消息。

```java
// 生产者 - topic类型交换机: 实际Routing_key
String routingKey1 = "user.save";
String routingKey2 = "user.update";
String routingKey3 = "user.delete.abc";
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, routingKey1, null, msg.getBytes());
channel.basicPublish(EXCHANGE_NAME, routingKey2, null, msg.getBytes());
channel.basicPublish(EXCHANGE_NAME, routingKey3, null, msg.getBytes());

// 消费者1 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true, false, false,null);
// 消费者1 - 可以匹配"user.save"、"user.update"、"user.delete.abc"的消息
String routingKey = "user.#"; 
// 消费者1 - Queue绑定Exchange: 表示EXCHANGE匹配"user.*"的消息会路由到QUEUE中
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
// 消费者1 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者1 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();

// 消费者2 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true, false, false,null);
// 消费者2 - 可以匹配"user.save"、"user.update"的消息
String routingKey2 = "user.*"; 
// 消费者2 - Queue绑定Exchange: 表示EXCHANGE匹配"user.*"的消息会路由到QUEUE中
channel.queueBind(QUEUE_NAME_2, EXCHANGE_NAME, routingKey2);
// 消费者2 - 绑定消费队列
channel.basicConsume(QUEUE_NAME_2, true, queueingConsumer);
// 消费者2 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Fanout Exchange

![1633329283915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633329283915.png)

Fanout Exchange，广播交换机，只需要简单的将 Queue 绑定到 Exchange 上，不处理任何 RoutingKey，发送到 Exchange 的消息，都会被转发到与该 Exchange **绑定**的所有 Queue 上，其消息转发效率是**最高**的。

- 从效率来讲，由于 key 匹配速度不同，Fanout Exchange > Direct Exchange > Topic Exchange，所以 Exchange 的选用应该尽量简单，没必要把时间花在 key 的解析和匹配上。

```java
// 生产者 - Fanout类型的交换机不走路由键，所以设不设置Routing_key都不起作用
String routingKey = "";
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, routingKey, null, msg.getBytes());

// 消费者 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "fanout", true, false, false,null);
// 消费者 - Fanout类型的交换机不走路由键，所以设不设置Routing_key都不起作用
String routingKey = "";
// 消费者 - Fanout交换机，只需要Queue绑定到Exchange上即可
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
// 消费者 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Headers Exchange

Headers Exchange，首部模式，不处理任何 RoutingKey，而是根据发送消息内容中的 `headers` 属性进行匹配。

**其工作原理为**：

1. 在绑定 Queue 与 Exchange 时，指定一组 Key-Value 作为 Header，其值可以是任意类型，而不像 fanout，direct，topic 的 RoutingKey 那样只能是字符串形式。
2. 当消息发送到 RabbitMQ 时，会取到该消息的 `headers` 与 Exchange 绑定时指定的 Key-Value 进行匹配。
3. 如果匹配，则消息会路由到该 Queue，否则不会路由到该 Queue，其匹配规则 `x-match` 有下列两种类型：
   - **x-match = all** ：表示所有的 Key-Value 全部匹配，才能接收到消息。
   - **x-match = any** ：表示只要有 Key-Value 存在匹配，就能接收到消息。

```java
// 生产者 - x-match = all，根据用户设置去通知用户，设置email的用户只接收email的消息，设置sms的用户只接收sms的消息，设置两种类型都设置的则两种消息都能收到。
String message = "email inform to user" + i;
Map<String,Object> headers =  new Hashtable<String, Object>();
headers.put("inform_type", "email");// 匹配email消费者绑定的header
// 生产者 -  headers.put("inform_type", "sms");// 匹配sms消费者绑定的header
AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder();
properties.headers(headers);
// 生产者 - email通知
channel.basicPublish(EXCHANGE_NAME, "", properties.build(), message.getBytes());

// 消费者 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS);
// 消费者 - headers.put("inform_type", "sms");// 匹配sms消费者绑定的header
Map<String, Object> headers_email = new Hashtable<String, Object>();
headers_email.put("inform_email", "email");
// 消费者 - Headers交换机，不匹配任何RountingKey，根据Headers进行匹配
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "", headers_email);
// 消费者 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### x-consistent-hash Exchange (>= 3.6.0版本)

![1633699257907](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633699257907.png)

x-consistent-hash Exchange，一致性哈希交换机，根据 RoutingKey 计算出一个 hash 值，然后使用**一致性哈希算法**，根据这个 hash 值，把消息分发到绑定在该交换机下的队列中。因此，如果没有交换机和队列发生绑定更改，具有相同 RoutingKey 的消息，具有相同的 hash 值，将被路由到同一个队列中。

- **背景**：x-consistent-hash Exchange，是在从 RabbitMQ 3.6.0 版本开始，才整合到 RabbitMQ 发布包中的，对于之前的版本，需要手动下载插件去安装。
- **权重**：绑定键 BindingKey 使用一个**数字字符串**，表示所绑定的权重，数字越大，绑定队列的权重就越大，分发消息时能接收到的消息就越多。
  - 绑定键 BindingKey 决定队列的权重。
  - 路由键 RoutingKey 决定消息的分发。
- **局限**：
  - **数据不均匀**：在节点太少时，容易出现节点分布不均匀，从而导致数据倾斜。

##### 常见工作模式

###### Point to Point | 点对点模式

![1633702087552](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702087552.png)

- 实现方法：Direct Exchange 直连交换机 +  Exchange  = "" + RountingKey = Queue_name + 一个消费者消费一个 Queue。

###### Work Queues |  工作队列模式

![1633700659483](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633700659483.png)

- **实现方法**：Direct Exchange 直连交换机 + Exchange  = "" + RountingKey = Queue_name + 多个消费者消费同一个队列 Queue。

###### Publish/Subscribe | 发布订阅模式

![1633700920376](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633700920376.png)

- **实现方法**：Fanout Exchange 广播交换机 + Exchange != "" + RountingKey = "" + 绑定 Exchange & Queue + 多个消费者消费同一个/多个 Queue。

###### Routing | 路由模式

![1633701310453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633701310453.png)

- **实现方法**：Direct Exchange 直连交换机 + Exchange != "" + 多个 RountingKey + 多个 Queue 分别通过 BiningKey = RountingKey 绑定Exchange + 多个消费者分别消费不同的 Queue。

###### Topics | 主题模式

![1633701632932](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633701632932.png)

- **实现方法**：Topic Exchange 主题交换机 + Exchange != "" + 多个 RoutingKey + 多个 Queue 分别通过BiningKey（模糊匹配）绑定Exchange + 多个消费者分别消费不同的 Queue。

###### Headers | 首部模式

![1633702207503](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702207503.png)

- **实现方法**：Headers Exchange 首部交换机 + Exchange != "" + RountingKey = "" + 多个 Queue 分别通过 Headers 绑定Exchange + 多个消费者消费不同的 Queue。

###### RPC 模式

![1633702404965](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702404965.png)

- **实现方法**：RPC 模式，指客户端远程调用服务端的方法 ，使用 MQ 可以实现 RPC 的异步调用，基于 Direct Exchange **直连交换机**实现，流程如下：
  1. 客户端既是生产者也是消费者，它会向 RPC 请求队列发送 RPC 调用消息，同时监听 RPC 响应队列。
  2. 服务端监听 RPC 请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果后，再将 RPC 结果发送到 RPC 响应队列。
  3. 由于客户端（RPC 调用方）监听 RPC 响应队列，所以此时会接收到 RPC 调用结果，完成一次 MQ 的 RPC 异步调用。

###### 工作模式总结

- Exchange 交换机，类似于反向代理用的 Nginx 服务器，不过 Nginx 负责请求的转发， 而 Exchagne 负责消息的转发。
- RabbitMQ 消息的传递，整体流程为『 生产者 -> 交换机 -> 队列 -> 消费者 』的这么一个模式，其中的点对点模式和工作队列模式，可以理解成是一个**匿名的交换机**进行投递队列，此时 RoutingKey = Queue_name。

| 工作模式     | 应用场景                                           |
| ------------ | -------------------------------------------------- |
| 点对点模式   | 把消息固定投放到一个队列，且只需一个消费者         |
| 工作队列模式 | 把消息固定投放到一个队列，但需要多个消费端加快消费 |
| 发布订阅模式 | 把消息投递同时投递到多个队列一起消费               |
| 路由模式     | 把消息固定投放到多个队列                           |
| 主题模式     | 按照一定规则，把消息投递到多个队列                 |
| 首部模式     | 不处理任何 RoutingKey，而是根据 `headers` 进行匹配 |
| RPC 模式     | 发起异步的 RPC 调用                                |

##### Queue 属性

Queue，消息队列，实际存储消息数据。 

| 属性        | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Durability  | Queue 是否需要持久化，Durable：是， Transient：否            |
| Auto Delete | Queue 是否自动删除，yes 代表是，当最后一个监听器被移除之后，该 Queue 会自动被删除 |

##### Message 属性

Message，服务器和应用程序之间传送的数据，本质上是一段数据，由 Properties 和 Payload（相当于 Body）组成。

| 属性               | 释义                                                         |
| ------------------ | ------------------------------------------------------------ |
| Delivery mode      | 1 代表非持久化，2 代表持久，一些客户端库将此属性公开为布尔值或枚举。 |
| Type               | 用于特定应用程序的消息类型，例如“orders.created”             |
| Headers            | Map类型，带有 Name-Value 的自定义映射                        |
| Content type       | 内容类型，例如“application/json”，由应用程序使用，而不是 RabbitMQ |
| Content encoding   | 内容编码，例如“gzip”，由应用程序使用，而不是 RabbitMQ        |
| Message ID         | 消息 ID（唯一 ID）                                           |
| **Correlation ID** | 操作 ID（唯一 ID），用于将请求与响应相关联，消费者可用于进行幂等性校验 |
| Reply To           | 携带响应队列名称，用于 RPC 模式                              |
| **Expiration**     | 每条消息的 TTL 过期时间                                      |
| Timestamp          | 应用程序提供的时间戳                                         |
| User ID            | 用户ID，如果设置则需要验证                                   |
| App ID             | 应用名称                                                     |

##### SpringBoot POM 依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

##### SpringBoot 生产者 | 配置

```properties
# RabbitMQ通用配置
spring.rabbitmq.addresses=192.168.1.111:5672,192.168.1.112:5672,192.168.1.113:5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
spring.rabbitmq.connection-timeout=15000ms

# RabbitMQ生产者配置
# 启动消息Confirm机制, 不需要和mandatory一起使用
spring.rabbitmq.publisher-confirms=true
# 启动消息Return机制, 需要和mandatory一起使用
#spring.rabbitmq.publisher-returns=true
#spring.rabbitmq.template.mandatory=true
```

##### SpringBoot 生产者 | HelloWorld

```java
/**
 * RabbitMQ: Producer
 */
@Component
public class RabbitSender {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    /**
     * 消息Confirm机制
     */
    final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() {
        @Override
        public void confirm(CorrelationData correlationData, boolean ack, String cause) {
            System.out.println("消息ACK结果:" + ack + ", correlationData: " + correlationData.getId());
        }
    };

    /**
     * 对外发送消息
     * @param message
     * @param properties
     */
    public void send(Object message, Map<String, Object> properties){
        // 封装Message
        MessageHeaders messageHeaders = new MessageHeaders(properties);
        Message<Object> msg = MessageBuilder.createMessage(message, messageHeaders);

        // 指定业务唯一ID
        CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());

        // 设置消息发送后置处理器
        MessagePostProcessor messagePostProcessor = new MessagePostProcessor() {
            @Override
            public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message) throws AmqpException {
                System.out.println("post to do: " + message);
                return message;
            }

            @Override
            public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message, Correlation correlation) {
                System.out.println("post to do " + message + " and correlation: " + correlation);
                return message;
            }
        };

        // 设置消息Confirm回调函数
        rabbitTemplate.setConfirmCallback(confirmCallback);

        // 发送消息，"springboot.rabbit"作为RoutingKey，匹配消费者的"springboot.*"
        // 	public void convertAndSend(String exchange, String routingKey, final Object message, final MessagePostProcessor messagePostProcessor, @Nullable CorrelationData correlationData) throws AmqpException
        rabbitTemplate.convertAndSend("exchange-1", "springboot.rabbit", msg, messagePostProcessor, correlationData);
    }
}
```

##### SpringBoot 消费者 | 配置

```properties
# RabbitMQ通用配置
spring.rabbitmq.addresses=192.168.1.111:5672,192.168.1.112:5672,192.168.1.113:5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
spring.rabbitmq.connection-timeout=15000ms

# RabbitMQ消费者配置
spring.rabbitmq.listener.simple.acknowledge-mode=manual
spring.rabbitmq.listener.simple.concurrency=1
spring.rabbitmq.listener.simple.max-concurrency=5
spring.rabbitmq.listener.simple.prefetch=1

```

##### SpringBoot 消费者 | HelloWorld

```java
/**
 * RabbitMQ: Receiver
 */
@Component
public class RabbitReceiver {

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(value = "queue-1", durable = "true"),
            exchange = @Exchange(name = "exchange-1", durable = "true", type = "topic", ignoreDeclarationExceptions = "true"),
            key = "springboot.*"
    ))
    @RabbitHandler
    public void onMessage(Message message, Channel channel) throws IOException {
        // 1. 收到业务以后进行业务端消费处理
        System.out.println("-----------------------");
        System.out.println("消费消息:" + message.getPayload());

        // 2. 处理成功后进行手工ACK
        Long deliveryTag = (Long) message.getHeaders().get(AmqpHeaders.DELIVERY_TAG);
        // void basicAck(long deliveryTag, boolean multiple) throws IOException;
        channel.basicAck(deliveryTag, false);
    }
}

```

#### 高级特性

##### 生产端 Confirm 机制

![1633418219083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633418219083.png)

消息确认，指生产者投递消息后，如果 Broker 收到消息，则会给生产者一个应答，生产者接收应答，可以用于确定该消息是否已经正常地发送到了 Broker，是可靠性投递的核心保障。

- **原理**：

  1. RabbitMQ 不会在收到消息时立马把消息写入磁盘，而是在数百毫秒的范围内，定期写入消息。
  2. 当队列被镜像时，只有在所有镜像都把将消息副本写入磁盘时，才会发送 ACK 给生产者。
  3. 这意味着 Confirm 机制会增加更多延迟，但如果数据需要高可靠性，那么这是必要的。

- **实现方法**：

  1. 在 Channel 上开启确认模式 `channel.confirmSelect()`。
  2. 在 Channel 上添加监听 `addConfirmListener`，去监听消息投递结果（成功和失败），根据具体的结果对消息进行重新发送，或者记录日志等其他后续处理。

  ```java
  // 生产者 - 开启Confirm消息机制
  channel.confirmSelect();
  // 生产者 - 绑定Confirm监听器 => 异步监听
  channel.addConfirmListener(new ConfirmListener() {
      @Override
      public void handleAck(long deliveryTag, boolean multiple) throws IOException {
          System.out.println("------- ok ---------" + deliveryTag);
      }
  
      @Override
      public void handleNack(long deliveryTag, boolean multiple) throws IOException {
          System.err.println("------- error ---------" + deliveryTag);
      }
  });
  // 生产者 - 发送消息msg到EXCHANGE_NAME
  String routingKey1 = "confirm.save";
  channel.basicPublish(EXCHANGE_NAME, routingKey1, null, msg.getBytes());
  
  ```

##### 生产端  Return 机制

![1633419001204](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633419001204.png)

Return Listener，可以用于处理一些**不可路由的消息**，比如 RoutingKey 规则不对不可路由时，如果不做任何监听，RabbitMQ 会默认直接丢弃掉，而此时可以使用 Return Listener 进行监听、处理这些不可达的消息。

- **实现方法**：设置 `Mandatory`，如果为 true，则监听器会接收到路由不可达的消息，然后进行后续处理；如果为 false，则Broker 会自动删除该消息。

  ```java
  // 生产者 - 开启Return消息机制
  channel.addReturnListener(new ReturnListener() {
      @Override
      public void handleReturn(int replyCode,
                               String replyText,
                               String exchange,
                               String routingKey,
                               AMQP.BasicProperties properties,
                               byte[] body) throws IOException {
          System.out.println("**************handleReturn**********");
          System.out.println("replyCode: " + replyCode);
          System.out.println("replyText: " + replyText);
          System.out.println("exchange: " + exchange);
          System.out.println("routingKey: " + routingKey);
          System.out.println("body: " + new String(body));
      }
  });
  // 生产者 - 投递时，routingKey1路由不到任何队列，触发Return机制
  channel.basicPublish(EXCHANGE_NAME, routingKey1, false, null, msg.getBytes());
  
  ```

##### 消费端 QoS 限流

- **背景**：假设有一个场景，RabbitMQ 服务器有上万条未处理的消息堆积，巨量的消息瞬间全部推送过来，单个客户端无法同时处理它们。

- **概念**：RabbitMQ 提供了一种 QoS（Quality of Service，服务质量保证）功能，即在非自动确认消息的前提下，如果一定数目的消息未被 `ACK` 前，则不消费新的消息。

- **参数**：

  - **prefetchSize**：报文大小，RabbitMQ 没有相应的实现。
  - **prefetchCount**：一次性从 Broker 中获取 N 个消息，但不能多于 N 个消息，即消费者一旦有 N 个消息仍未 ACK，则该消费者将不再消费任何消息，直到有消息 ACK 掉。
  - **global**：是否把 QoS 设置应用于 Channel 级别，RabbitMQ 没有相应的实现。
    - **true**：代表应用于 Channel 级别，即 Channel 下面所有的消费者都会使用该配置。
    - **false**：代表应用于 Consumer 级别，即只有当前 Consumer 才有效。

- **原理**：

  1. 首先，`basic.qos` 是通过 Channel 进行设置的，即只有在 Channel 建立之后，才能发送 `basic.qos` 信令。
  2. 在 RabbitMQ 实现中，每个 Channel 对应一个 rabbit_limiter 进程，当收到 `basic.qos` 信令后，会记录信令中 `prefetch_count` 的值，以及该 Channel 未 ACK 的消息个数。
  3. 当 RabbitMQ 要将 Queue 中的一条消息投递给 Consumer 时，会先遍历该 Queue 上的 Consumer 列表，然后选出一个合适的 Consumer，再把消息投递出去。
  4. 其中挑选 Consumer 的一个依据就是，看 Consumer 对应的 Channel 上未 ACK 的消息数是否已经达到了设置的 `prefetch_count` 。
  5. 如果未 ACK 的消息数已经达到了 `prefetch_count` ，则该消费者不符合要求，继续遍历挑选，此时该消费者将不再收到消息的投递，直到它发生了消息 ACK。
  6. 当挑选到合适的消费者后，RabbitMQ 会中断后续的遍历挑选操作，把消息投递到该消费者中去。

- **用途**： 用于控制消息发送给消费者的速度，让 Consumer 能够保持饱和的工作状态。

  1. 如果没有设置 QoS，那么 RabbitMQ 会把队列所有的消息，都按照**网络和客户端允许的速度**，推送给客户端，Consumer 把所有接收到的消息都缓存在自己的内存中，从而导致该 Consumer 内存占用飞速上涨。

  2. 可见，没有设置 Qos 会为 Consumer 提供无限的缓冲区，导致不良行为和不良性能的发生，因此，设置合理的 Qos 对性能的提升十分重要。

     - **目的**：为了让 Consumer 能够保持**饱和的工作状态**，减少 Consumer 缓冲区大小，使得更多消息留在 Queue 而不是 Consumer 内存中，方便在添加新 Consumer 时能够接收到消息推送。

     - **合理的 Qos**：当网络正常时，合理的 Qos 应该等于比值 `q =（消息往返两次所花的时间 + 消息被处理所花的时间） / 消息被处理所花的时间`，以保证在 Qos 最后一个消息被消费完毕时，最早消息的 ACK 已经回到 Broker，并且 Broker 也已经把新消息投递到 Consumer 内存中，使得 Consumer 工作永远饱和，而不至于阻塞等待消息的接收。

       | 异常情况           | 影响                                                         |
       | ------------------ | ------------------------------------------------------------ |
       | 网络正常，Qos 过大 | 会导致堆积在 Consumer 内存中的消息过多，消费出现大量额外的延迟 |
       | 网络正常，Qos 过小 | 会导致 Consumer 出现阻塞等待消息接收的情况，浪费 Consumer 工作时间 |
       | 网络变慢，Qos 正常 | 消息往返时间变长，q 增大，此时 Qos 偏小，会导致 Consumer 出现阻塞等待消息接收的情况，浪费 Consumer 工作时间 |
       | 消费变慢，Qos 正常 | 消息被处理所花时间变长，q 减小，此时 Qos 偏大，会导致堆积在 Consumer 内存中的消息过多，消费出现大量额外的延迟 |

- **实现方法**：

  ```java
  // void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;
  // 消费者 - 开启消费限流 报文大小、限流阈值、是否设置为Channel级别
  channel.basicQos(0, 1, false);
  
  // 消费者 - 消费消息，只有使用手工ACK才可以进行消费流控
  while (true){
      QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
      String msg = new String(delivery.getBody());
      // void basicAck(long deliveryTag, boolean multiple) throws IOException;
      channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
  }
  
  ```

##### 消费端 ACK/NACK 与消息重回队列

消费端进行消费时，如果消费端返回 `NACK`，可以进行日志记录 + 失败补偿，**千万不要把消息重回队列**；而由于服务器宕机等问题，需要消费端进行手工 `ACK`，保证消费成功，一般不会选择自动 `ACK`。

- **消息重回队列**：指把那些没有处理成功的（即返回 `NACK` 的）消息，重新投递给 Broker。

  - **缺点**：如果该消息一直消费失败，会导致无限制地被重新投递、重新消费...，非常浪费性能，甚至可能会搞挂 MQ，所以在使用中，一般都会关闭消息重回队列的功能。

- **实现方法**：

  ```java
  // 消费者 - NACK时开启消息重回队列，一般不采用, 弄不好会搞挂MQ
  // void basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException;
  channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true);
  ```

##### TTL 消息与 TTL 队列

TTL，Time to Live，指消息或者队列的生存时间，即过期时间。

- **TTL 消息**：

  - 指超过过期时间后，消息仍未被消费，则会被 RabbitMQ 删除。
  - RabbitMQ 支持 TTL 消息，通过在消息发送时进行指定。

- **TTL 队列**：

  - 指队列中**所有消息**都为 TTL 消息，且过期时间为指定的队列 TTL。
  - RabbitMQ 支持 TTL 队列，从**消息入队开始**计算，只要超过了队列的超时时间配置，那么消息会自动被删除。

- **实现方法**：

  ```java
  // 生产者 - 设置TTL队列参数
  HashMap<String, Object> queueArguments = new HashMap<>();
  queueArguments.put("x-message-ttl", 6000);// 6s过期时间
  // 生产者 - 声明交换机
  channel.exchangeDeclare(EXCHANGE_NAME, EXCHANGE_TYPE, true, false, false, null);
  // 生产者 - 声明队列（由于有TTL参数，所以为TTL队列）
  channel.queueDeclare(QUEUE_NAME, false, false, false, queueArguments);
  // 生产者 - Queue绑定Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
  String routingKey = ROUTING_KEY;
  channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
  
  // 生产者 - 或者可以通过设置BasicProperties，来设置TTL消息
  AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
      .deliveryMode(2)
      .contentEncoding("UTF-8")
      // TTL消息
      // .expiration("6000")
      .headers(headers)
      .build();
  ```

##### 死信交换机与死信队列

RabbitMQ 中有死信交换机的概念，Dead Letter Exchange，DLX，当一个队列中的消息变成**死信**（Dead Message）之后，它能被重新投递到另一个 Exchange 中，此时这个 Exchange 被称为**死信交换机**，而与死信交换机绑定的队列被称为**死信队列**（Dead Letter Queue，DLQ），

- **死信产生条件**：

  - 消息被拒绝 `basic.rejec` 或者 `basic.nack`，且不重回队列时 `requeue = false`。
  - 消息 TTL 过期时。
  - 队列达到最大长度时。

- **原理**：

  1. DLX 本质上也是一个正常的 Exchange，和一般的 Exchange 没有区别，可以在任何队列上被指定，实际上只是设置了某个队列的属性而已。
  2. 当某个队列中有死信时，RabbitMQ 会自动将死信消息重新投递到设置的 DLX 上，进而被路由到另一个队列（**死信队列**）中。
  3. 通过监听这个死信队列中的消息，进行相应的处理。
     - 死信只能从队头被转发到 DLX，也就是说即是 TTL 消息已过期，如果还没出现在队头，那么该消息还会继续存留在队列中，直到出现在队头才会被转发到 DLX 中。

- **实现方法**：

  ```java
  // 生产者 - QueueArguments声明绑定的死信交换机、对应的RoutingKey、以及TTL队列参数
  HashMap<String, Object> queueArguments = new HashMap<>();
  queueArguments.put("x-dead-letter-exchange", DLX_EXCHANGE_NAME);
  queueArguments.put("x-dead-letter-routing-key", "123");// 任意RoutingKey
  queueArguments.put("x-message-ttl", 6000);// 6s过期时间
  // 生产者 - 声明普通交换机
  channel.exchangeDeclare(EXCHANGE_NAME, EXCHANGE_TYPE, true, false, false, null);
  // 生产者 - 声明普通队列（由于有TTL参数，所以为TTL队列）
  channel.queueDeclare(QUEUE_NAME, false, false, false, queueArguments);
  // 生产者 - 普通Queue绑定普通Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
  String routingKey = ROUTING_KEY;
  channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
  // 直连式，发送到默认的交换机，由于为TTL队列且没有任何消费者消费，所以消息过期后被重新投递到DLX中
  channel.basicPublish("", QUEUE_NAME, properties, msg.getBytes());
  
  // 消费者 - 声明死信队列交换机(一般手动创建，不在Java代码中创建)
  channel.exchangeDeclare(DLX_EXCHANGE_NAME, DLX_EXCHANGE_TYPE, true, false, false,null);
  // 消费者 - 声明死信队列(一般手动创建，不在Java代码中创建)
  channel.queueDeclare(DLX_QUEUE_NAME, false, false, false, null);
  // 消费者 - 死信队列绑定死信交换机: 表示交换机DLX_EXCHANGE_NAME上ROUTING_KEY的消息会路由到DLX_QUEUE_NAME中
  channel.queueBind(DLX_QUEUE_NAME, DLX_EXCHANGE_NAME, DLX_ROUTING_KEY);
  // 消费者 - 开始消费死信队列DLX_QUEUE_NAME的消息
  channel.basicConsume(DLX_QUEUE_NAME, false, queueingConsumer);
  QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
  channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
  
  ```

##### 延迟消息

延迟消息，就是消息投递到 Broker 后，Broker 会经过根据设定的延迟时间后，才把消息真正的投递到目标的业务 Exchange 中。

- **方案一，TTL 消息 + 单个等待队列 + 死信队列**：设置消息 TTL ，然后把等待队列中已过期的死信，投递到目标的业务 Exchange 中，此时该 Exchange 扮演者 DLX 的角色。

  - **缺点**：由于死信仅会从队头被移除，如果队列头部有一条 TTL 为 10 分钟的消息，后面又有一条 TTL 为 1 分钟的消息，那么第二条消息将等待 10 分钟，导致延迟时间容易失准。

  ```java
  // 方案一，TTL 消息 + 死信队列
  // public static final String X_DELAY = "x-delay";
  // 底层调用 => this.headers.put(X_DELAY, delay);
  org.springframework.amqp.core.messageProperties.setDelay(message.getDelayMills());
  
  ```

- **方案二，TTL 消息 + 多个等待队列 + 死信队列**：类似于方案一，不过不同的是，需要创建多个等待队列，并在队列本身上设置 TTL，比如 1、5 和 15 分钟等，然后根据 TTL 投递消息到不同的等待队列中。

  - **缺点**：设置延迟时间的灵活性有限，如果出现一个不在等待队列已有的 TTL，那么就需要新增一个等待队列，或者允许延迟时间失准，把消息投放到 TTL 相差较小的等待队列中。

- **方案三，NServiceBus**：

  - **原理**：
    1. 基于方案二的思路，使用级联 Topic，通过死信配置和 Topic 路由链接在一起。
    2. 创建多个延迟级别，其中每个级别负责自己的固定 2 的幂次的延迟时间（28 个级别的延迟时间），比如级别 1 为 1 分钟，级别 2 为 2 分钟，级别 3 为 4 分钟，级别 4 为 8 分钟等。
    3. 然后使用二进制样式的路由规则 与 RoutingKey ，在延迟队列之间移动消息（最多 27 次的路由交换），从而实现消息延迟投递。
  - **优点**：可以以 1 分钟的分辨率实现**任何**延迟时间。

  ![1633596886819](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633596886819.png)

#### 高可用架构

##### 主备模式

![1633428088126](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633428088126.png)

warren，兔子窝，Master - Slave 主备方案，与 ActiveMQ 利用 Zookeeper 实现 Master -Slave 方案类似。

- **原理**：如果 Master 挂了，可以利用 HaProxy 自动切换为 Slave，继续提供服务，从而实现热备份。

- **缺点**：服务器利用率低，只能从 Master 进行消费。

- **主备 HaProxy 配置**：

  ```shell
  # 集群名称
  listen rabbitmq_cluster
  # HaProxy IP+端口
  bind 0.0.0.0:5672
  # 配置TCP模式
  mode tcp
  # 简单的轮询，一开始默认为主节点，主节点挂了后轮询到下一个节点作为主节点
  balance roundrobin
  # 主节点
  server bhz76 192.168.11.76：5672 check inter 5000 rise 2 fall 2
  # 备用节点
  server bhz76 192.168.11.76：5672 backup check inter 5000 rise 2 fall 2
  
  ```

##### 远程模式

![1633441813577](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633441813577.png)

**远距离**通信和复制，可以实现**异地双活**的一种模式，简称  Shovel 模式，用于早期版本的多活存储和异地容灾。

- **原理**：通过把消息进行不同数据中心的复制，跨地域地让**两个 MQ 集群互联**。

- **缺点**：由于配置麻烦，无法动态配置，比如加一个 Exchange 必须重启服务，**实际用得并不多**，而且可用性也有待提高。

- **集群配置步骤**：

  ```shell
  # Step1：启动rabbitmq_shovel插件
  rabbitmq-plugins enable amqp_client
  rabbitmq-plugins enable rabbitmq_shovel
  # Step2：创建rabbitmq.config文件
  touch /etc/rabbitmq/rabbitmq.config
  # Step3：添加rabbitmq.config配置（省略，非常复杂，包括需要同步的每一个交换机、队列等信息）
  # Step4：保证源服务器与目的服务器都使用相同的rabbitmq.config配置
  
  ```

##### 镜像模式

![1633442866041](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633442866041.png)

镜像模式，Mirror，是非常经典的一种集群架构，可以保证 100% 数据不丢失，在实际工作中用的最多，并且实现起来**非常简单**，一般大厂都会使用这种架构模式来构建集群。

- **缺点**：只起到高可用的效果，**无限横向扩展没有意义**，因为当消息堆积过多时，无论如何横向扩展机器，每台机器堆积的消息量还是保持不变，机器增多只会增加 RabbitMQ 集群的通信负担，因此，RabbitMQ 集群一般选用 3 个节点保证高可用。

- **原理**：当 Broker 收到投递的消息后，镜像模式会把消息同步到集群中所有的节点，由于使用 Erlang 语言实现，天然地以交换机的方式进行数据同步，保持与原生 Socket 一样的延迟，性能非常好。

  1. Queue 分为 Master 和 Slave 节点，其中 Master 和 Slave 是针对一个 Queue 而言的，即一个 Queue **第一次创建**的 RabbitMQ 节点为 Master，其它 RabbitMQ 节点作为 Slave；而不是某个 RabbitMQ 节点作为所有 Queue 的 Master，其它 RabbitMQ 节点作为 Slave。
  2. 对某个 Queue来说，只有 Master 对外提供服务，而其他 Slave 只提供备份服务，以提供消息冗余，在Master 不可用时，RabbitMQ 会选出一个 Slave 作为新 Master 继续对外提供服务。
  3. 无论 Client 请求打到 Master 还是 Slave，最终数据都是**从 Master 获取**：
  4. 当 Client 请求打到 Master 时，Master 会直接将消息返回给 Client，同时 Master 会通过 GM 协议，将 Queue 的最新状态广播到其他 Slave。
     - GM 协议：Guaranteed Multicast，保证了**广播消息的原子性**，即要么都更新要么都不更新。
  5. 当 Client 请求打到 Slave 时，Slave 需要将 Client 请求先重定向到 Master，Master 再将消息返回给Client，同时 Master 会通过 GM 协议，将 Queue 的最新状态广播到 Slave节点。
  6. 因此，多个 Client 连接不同的镜像队列，不会产生同一 Message 被多次接受的情况。

  ![1633599572589](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633599572589.png)

- **新增节点**：

  - 如果有新节点加入，RabbitMQ 不会同步之前的历史数据，只会复制该节点加入到集群之后新增的消息。
  - 另外，对于 RabbitMQ 节点的重启，也是按照新节点来处理的。

- **Master 选举**：

  - RabbitMQ 集群内部会维护节点的状态**是否已经同步**，使用 rabbitmqctl 的 `synchronised_slave_pids` 参数，就可以查看状态。
  - 如果 `slave_pids` 和 `synchronised_slave_pids` 里面的节点是一致的，那说明全都同步了。
  - 如果不一致，则很容易比较出来哪些还没有同步，集群会在**最老**的 Slave 之间，选一个出来作为新的Master 。
  - 所以，RabbitMQ 选举过程，是不会选择新增节点作为新 Master 的。

- **故障恢复**：假设两个节点 A 和 B，组成一个镜像队列，其中 B 为 Master，A 为 Slave。

  1. **场景1**：A 先停，B 后停。
     - **恢复方案**：先启动 B，再启动A；或者先启动 A，在 30 秒内启动 B，即可恢复镜像队列。
  2. **场景2**：A、B 同时停。
     - **解决方案**：该场景可能是由掉电等原因造成，只需在 30 秒内，连续启动 A、B，即可恢复镜像队列。
  3. **场景3**：A 先停，B 后停，且 A 无法恢复。
     - **解决方案**：该场景是场景 1 的加强版，只需在 B 起来后，调用 `rabbitmqctl forget_cluster_node A`，解除与 A 的 Cluster 关系，再将新 Slave 加入 B，即可重新恢复镜像队列。
  4. **场景4**：A 先停，B 后停，且 B 无法恢复。
     - **解决方案**：
       1. 该场景是场景 3 的加强版，比较难处理，早在 3.1.x 时代之前没什么好的解决方法，由于 B 是 Master，所以直接启动 A 是不行的，而 A 无法启动，也就无法在 A 节点上调用 `rabbitmqctl forget_cluster_node B` 了。
       2. 而在 3.4.2 版本中，`forget_cluster_node` 支持 `–offline` 参数，允许 `rabbitmqctl` 在离线节点上执行 `forget_cluster_node` 命令，迫使 RabbitMQ 在未启动的 Slave 中选择一个作为Master。
       3. 此时，可以在 A 节点执行 `rabbitmqctl forget_cluster_node –offline B` 时，将 B 剔出Cluster，然后 A 就能正常启动了，最后将新 Slave 加入 A，即可重新恢复镜像队列。
  5. **场景5**：A 先停，B 后停，且 A和B 都无法恢复，但是能得到 A 或者 B 的磁盘文件。
     - **解决方案**：
       1. 该场景是场景4的加强版，更加难处理。
       2. 将 A 或 B 的数据库文件（默认在 `$RABBIT_HOME/var/lib`目录中），拷贝至新节点 C 的对应目录下，再把 C的 `hostname` 改成 A 或 B 的 `hostname` 。
       3. 如果拷过来的是 A 节点磁盘文件，则按场景 4 进行处理；如果拷过来的是 B 节点磁盘文件，则按场景 3 进行处理。
       4. 最后将新 Slave 节点加入 C，即可重新恢复镜像队列。
  6. **场景6**：A 先停，B 后停，且 A 和 B 都无法恢复，还无法得到 A 和 B 的磁盘文件。
     - **解决方案**：无法恢复 A 和 B 中的内容。

##### 多活模式

![1633445011959](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633445011959.png)

多活模式，Federation，也是实现**异地数据复制**的主流模式，由于 Shovel 模式配置比较复杂，所以一般来说，实现**异地集群**都是使用双活或者多活模型来实现的。

- **特点**：RabbitMQ 部署架构采用双中心或者多中心模式，各数据中心都部署一套 RabbitMQ 集群，除了需要为业务提供正常的消息服务外，中心与中心之间还需要实现部分关键队列的消息共享。

- **原理**：需要依赖 RabbitMQ#federation 插件。

  - **Federation 插件**：基于镜像队列集群，不需要重新构建集群，使用 **AMQP 协议**通讯，可以在集群之间高效传输消息，同时接受不连续的消息传输，接的双方可以使用不同的 users、virtual hosts、RabbitMQ、甚至 Erlang 环境。

  - **Federation Exchanges**：

    1. 可以看成下游主从上游拉取消息，但并不是拉取所有消息，而是只拉取下游绑定了上游 Queue 的 Exchange 的 消息。
    2. 更新时，通过使用 AMQP 协议实施代理间通信，下游在后台绑定或者解绑，然后把绑定和解除绑定命令，发送到上游交换机，进行动态更新配置。
    3. 因此，Federation Exchange 只接收被订阅了的消息，即只拉取自己有绑定关系的消息。

    ![1633445945055](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633445945055.png)

#### 常见问题解决

##### 如何保证数据不丢失？

在使用 MQ 过程中，应做到消息不能多消费，也不能少消费，如果无法做到可靠性传输，可能会给公司带来千万级别的财产损失。

- **数据丢失场景**：生产端丢数据、MQ 丢数据、消费端丢数据。

###### 生产端丢数据

需要生产端保证可靠性投递，即要保证生产者投递的消息 100% 投递成功，不存在投递失败，比如核心业务，订单下单支付成功后，通知物流时需要 100% 通知成功，一单都不能丢。

- **解决方案**：RabbitMQ 提供 transaction 或者 confirm 机制，来确保生产者不丢消息。

  - **transaction 机制**：

    - **执行流程**：
      1. 发送消息前，开启事务 `channel.txSelect()`。
      2. 然后发送消息。
      3. 如果发送过程中出现什么异常，事务就会回滚 `channel.txRollback()`。
      4. 如果发送成功则提交事务 `channel.txCommit()`。
    - **缺点**：吞吐量会下降很多。

  - **confirm 机制**： 消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿 。

    ![1633339851782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633339851782.png)

    - **实现关键点**：
      1. 保障消息能够成功发出。
      2. 保障 MQ Broker 节点能够成功接收。
      3. 发送端收到 MQ Broker 节点能够确认应答。
      4. 有完善的消息补偿机制。
    - **执行流程**：
      1. **STEP 1**：业务落库 BIZ_DB。
      2. **STEP 2**：消息落库 MSG_DB，需要保证 MSG_DB 与 BIZ_DB 属于同源数据库，即一个 Connection 可以同时操作该地址下面的多个数据库，这样可以使业务和消息落库处于同一个事务内，**保证原子性**。
         - 如果不想单独建立消息库或者消息表，可以在业务表上新增一个字段，用于记录消息的状态。
      3. **STEP 3**：发送消息到 MQ 上。
      4. **STEP 4**：MQ Broker 接收消息成功后返回 ACK 应答。
      5. **STEP 5**：接收到 Broker 的 ACK 应答后，更新 MSG_DB 中对应的消息状态。
      6. **STEP 6**：
         1. 为了防止 MSG_DB 对应的消息状态一直未改变，且已发生超时，或者一次消息投递失败，需要启动一个定时任务，去 MSG_DB 扫出投递超时的、失败可再投递的消息，进行 STEP 7 重新投递。
         2. 同时，如果重新投递的次数超过了最大限制，则说明消息投递最终失败，需要进行**人工介入** 或者 **失败补偿**。
      7. **STEP 7**：定时任务重新投递消息。
      8. **STEP 8**：定时任务定期执行，扫出投递超时的、失败可再投递的消息。

###### MQ 丢数据

处理 MQ 丢数据，需要（**开启持久化**配置 + RabbitMQ confirm 机制）配合使用，在消息持久化后，才给生产者发送一个 ACK 信号，如果消息持久化之前，RabbitMQ 就阵亡了，此时生产者收不到 ACK 信号，生产者就会自动重发，从容防止 MQ 丢数据。

- **开启持久化**：
  1. 将 Queue 的持久化标识 `durable` 设置为 true，代表是一个持久的 Queue。
  2. 在生产者发送消息时，将 `deliveryMode` 设置为2，代表该消息需要被持久化。
  3. 这样设置以后，RabbitMQ就算挂了，重启后也能恢复数据。
- **为什么不对所有消息都开启持久化**？
  1. 是否要对消息进行持久化，需要综合考虑性能的差距，因为写磁盘要比写 RAM 慢得多，开启持久化必然会导致 RabbitMQ 性能的下降，之间的消息吞吐量可能会有 3 倍以上的差距。
  2. 如果想达到单 RabbitMQ 10w/s 以上的消息吞吐量，一种处理方法是，使用非常快速的存储系统，来支持写磁盘持久化消息（比如使用 SSD）。
  3. 另外一种处理方法是，根据业务重要程度，仅对**关键消息**作持久化处理，这时仅仅保证关键消息的持久化不会导致性能瓶颈即可。

###### 消费端丢数据

消费端丢数据，一般是因为采用了**消费者自动 ACK** 的模式，在这种模式下，消费者收到消息后会自动确认，然后 RabbitMQ 则立即将消息删除，如果此时消费者出现异常，确认后没能处理该消息，则会丢失该消息。

- **解决方案**：采用**消费者手工 ACK** 即可。

##### 如何防止重复消费？

这个问题换一种问法就是，如何保证消息队列的**幂等性消费**，即消费者多次消费的结果只会被消费一次。

- **原因**：
  1. 正常情况下，消费者在消费完毕后，会发送一个**确认信息**给消息队列，消息队列就知道该消息被消费了，然后会将该消息从消息队列中删除。
  2. 无论是哪种消息队列，造成重复消费原因其实都是类似的，只是不同的消息队列发送的**确认消息**的形式不同，比如 RabbitMQ 是发送一个 `ACK` 确认消息，RocketMQ是返回一个 `CONSUME_SUCCESS` 成功标志，kafka实际上有个 `offset` 的概念。
  3. 如果出现网络传输等故障，确认信息没有传送到消息队列，导致消息队列不知道该消息已经被消费过了，下次会把该消息，再次分发给其他的消费者进行消费，从而导致重复消费。
- **解决方案**：
  1. **数据库主键去重**：消费这个消息做数据库的 `insert` 操作时，可以给这个消息做一个**主键**，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
     - **局限**：并发时会导致大量的插入失败，浪费性能。
  2. **更新操作天然幂等**：消费这个消息做 Redis 的 `set` 操作时，无需做任何处理，因为无论 `set` 几次结果都是一样的。
     - **优点**：`set ` 操作天然幂等，无需做任何处理。
  3. **全局唯一 ID**：如果以上两种情况都不适合，那么可以准备一个第三方介质，用来做消费记录，以 Redis 为例，给消息分配一个**全局唯一 ID**，只要消费过该消息，可以吧 `ID-Message` 以 K-V 形式写入 Redis，当消费者开始消费前，需要先去 Redis 中查询有没消费记录，如果没有则消费，否则放弃消费。
     - **局限**：仅仅使用这种方案还是有可能重复消费的，因为当线程并发查询消费记录时，可能会导致并发通过消费记录的校验，从而重复创建订单。
  4. **全局唯一ID + 数据库主键去重**：由于高并发解决方案是不能加锁的，而仅仅使用全局唯一 ID，或者数据库主键去重，都是有幂等性缺陷的，因此，最终的解决方案是使用 **全局唯一ID + 数据库主键去重** ，利用消费记录校验来挡住大部分请求，利用数据库主键兜底剩余通过校验的并发请求，从而保证幂等性消费。
     - **优点**：简单有效。

##### 一致性与可用性保障？

###### 集群可调整参数

事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的**最终一致性**以及时刻都接受读取和写入的**高可用性**，因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个**范围的两端**。对此，RabbitMQ 提供了调整参数，以获得更高一致性或者更高可用性。

1. **持久化 Queue / Exchange**：见 Queue / Exchange 的 `Durability` 属性。

   - 开启持久化的 Queue / Exchange 都会被持久化到 Mnesia 数据库，其可以在系统崩溃或服务器故障后，重新启动时，这些 Queue / Exchange 基础设施会重新上线。
   - 而关闭持久队的 Queue / Exchange，在重新启动时，则会被删除。

2. **持久化消息**：Queue / Exchange 的持久化，并不意味着其消息的持久化，只有被生产者设置为 `Delivery mode=2` 的消息，重新启动后才会恢复。

   - **缺点**：持久消息会给代理带来更多负载，所以并不需要对所有消息都做持久化处理，而是根据业务重要程度，仅对**关键消息**作持久化处理，这时仅仅保证关键消息的持久化不会导致性能瓶颈即可。

3. **消息 Confirm 机制**：见《高级特性 - 生产端 Confirm 机制》与《高级特性 - 消费端 ACK/NACK 与消息重回队列 》。

4. **镜像同步策略**：`ha-sync-mode`：

   - **automatic**：自动同步，节点重新上线后，集群会为新节点上的每个队列创建一个镜像，并自动将新 镜像与 Master 进行同步，包括 Master 原始的消息。
     - **为什么不默认使用自动同步**？同步是一个阻塞操作，同步期间 Master 无法执行任何读取或者写入操作，如果 Queue 为一个大队列，原始消息的同步将会耗费大量的时间，保证了一致性，但牺牲了可用性。
   - **manual**：手动同步，默认，节点重新上线后，集群会为新节点上的每个队列创建一个镜像，但该镜像只是保持为空的镜像，不会复制 Master 原始的消息，而仅仅是同步 Master 新写入的消息。

5. **Master 选举策略**：`ha-promote-on-failure` ：

   - **always**：默认值，允许故障转移到**数据未完全同步**的镜像中。
     - **特点**：可能会导致 Master 的消息丢失，但可以保持 Queue 的高可用性。
   - **when-synced**：仅在**数据已完全同步**的镜像中进行故障转移，否则让 Queue 不可用；只当 Master 再次上线时，Queue 才恢复可用，数据未完全同步的镜像继续同步 Master 数据。
     - **特点**：牺牲了可用性，某个方面增加了数据安全；但如果重新上线的 Master 丢失了所有数据，则会导致 Queue 的所有数据**全部丢失**，即使有大部分追上同步进度的镜像也会被丢弃，去同步数据为空的 Master，所以该策略是非常危险的。

6. **脑裂处理策略**：一个集群由于网络链接切断，被一分为二的地方，在分区的每一侧，都有镜像都被提升为 Master，这意味着最终每个队列有不止一个的 Master，RabbitMQ 提供 `cluster_partition_handling` 作为脑裂的处理策略：

   - `Ignore`：忽略模式，默认，此模式选择了**可用性**，当分区发生时，发生了裂脑，而在分区解决后，由管理员来决定分区的哪一边获胜，让失败侧重新启动，并且仅存在于该分区的任何数据都将会丢失。
   - `Autoheal`：自动修复模式，与忽略模式相同，不过是交由集群**自动决定**分区的失败侧，失败的一方会重新加入集群，从而丢失所有未被消耗的消息。
   - `Pause Minority`：暂停少数派模式，**拒绝**对分区的少数方进行读写，这是禁止出现裂脑的**唯一选择**。
     1. Broker 会自动暂停位于分区的少数方，意味着它会关闭所有现有连接，并拒绝任何新连接。
     2. 同时，Broker 会每秒检查一次网络状态，以判断分区是否已自行解决。
     3. 一旦分区已自行解决，Broker 将会自行取消暂停，并让那些少数方重新加入集群。

   ![1633606547241](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633606547241.png)

7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

###### 集群缺陷

- **一致性**：重新加入集群的节点，会被迫丢弃它们自己的数据。
- **可用性**：镜像同步 Master 阻塞时，会导致队列暂时不可用。

###### 追求高可用性

1. **持久化 Queue / Exchange**：开启。
2. **持久化消息**：只持久化关键消息。
3. **生产端 Confirm**：允许投递迅速消息，无需进行消息 Confirm。
4. **镜像同步策略**：`ha-sync-mode=manual`，手动同步镜像。
5. **Master 选举策略**：`ha-promote-on-failure=always`，允许选举数据未完全同步的镜像作为 Master。
6. **脑裂处理策略**： `cluster_partition_handling=Ignore`，忽略模式或者 `cluster_partition_handling=Autoheal`，自动修复模式。
7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

###### 追求高一致性

1. **持久化 Queue / Exchange**：开启。
2. **持久化消息**：只持久化关键/所有消息。
3. **生产端 Confirm**：生产端可靠性投递（消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿） + 消费端幂等性消费 + 消费端手工 ACK。
4. **镜像同步策略**：`ha-sync-mode=automatic`，自动同步镜像，包括 Master 的原始消息。
   - 但对于大队列，由于镜像同步慢，还需要考虑**可用性导致的消息丢失**：生产端可靠性投递（消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿） + 死信队列（超过最大投递次数） + 人工介入。
5. **Master 选举策略**：`ha-promote-on-failure=when-synced`，仅在数据已完全同步的镜像中进行故障转移，否则让 Queue 不可用；只当 Master 再次上线时，Queue 才恢复可用，数据未完全同步的镜像继续同步 Master 数据。
6. **脑裂处理策略**： `cluster_partition_handling=Pause Minority`，暂停少数派模式，**拒绝**对分区的少数方进行读写，只有当分区修复完成后，才会重新加入集群，开放读写。
7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

##### 如何重新平衡队列？

故障恢复后，现有的 Master 可能都落在同一个节点上，这是不理想的情况，需要 Master 重新平衡，以让其在节点之间均匀分布，而不幸的是，RabbitMQ Master 重新平衡没有很好的选择，而应该关注**如何重新平衡队列**： 

- 在 3.8.1 版本以前，可以使用 HA 策略来移动 Master，其工作原理是：

  1. 通过优先级高于现有 HA 策略的临时策略，来删除所有镜像。
  2. 将临时 HA 策略更改为使用 `nodes` 模式，指定要将 Master 迁移到的节点，然后强制**迁移同步队列**。
  3. 迁移完成后，删除临时策略，优先使用原始 HA 策略并创建所需数量的镜像。

  => **缺点**：如果有大队列，或者严格的冗余要求不能删除镜像时，则可能该方案不可行。

- 从 3.8.1 版本开始，可以使用 `rabbitmq-queues rebalance all` 命令，重新平衡镜像队列。

  ```shell
  rabbitmq-queues rebalance "all" --vhost-pattern "a-vhost" --queue-pattern ".*"
  
  ```

##### 如何保证顺序消费？

![1633703487247](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633703487247.png)

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个队列**，目的是防止消费者争抢消息导致乱序消费的情况发生。

- **解决方案**：

  - **多队列、多消费者**：可以使用一致性哈希交换机 `x-consistent-hash Exchange`，来保证同一个 RoutingKey 多次投递，只会顺序进入同一个队列，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。

    ![1633703914760](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633703914760.png)

  - **单队列、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单队列、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单队列、单消费者**：始终保证使用 一个 Queue + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

##### 如何优化消息积压？

###### 影响后果

消息积压在 Queue 中，可能会导致消息被丢弃、MQ 内存打满、MQ性能下降甚至停止服务，影响系统运行。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **提高 `prefetch_count`**：首先要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从等待消息阻塞的角度**入手。

   ![1633794700060](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794700060.png)

   1. 消息消费速度，主要受到 `发送消息时间`、`消息被处理时间`、`消息 ACK 时间` 的影响。
   2. 如果一个消息走完这个流程后，才发送另一个消息的话，整体效率将会非常的低。
   3. 此时，可以让消息在这几个时间内恰当的分配，让消息总是连续不断地被 Consumer 接收处理，确保 Consumer 能够保持饱和的工作状态，从而发挥出其本身真正的后端处理能力，整体上提升 Consumer 的消费速度。
   4. 只有设置 `prefetch_count` 到一个合理的值，才可以最大限度地提升消息的消费速度，这个值的设定可以参考《消费端 Qos 限流》。
   5. **小结**：需要消费端 ACK、需要设置的合理的 `prefetch_count`。

2. **Consumer 批量 ACK**：其次还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   ![1633795791575](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633795791575.png)

   1. 在每条消息分别被 ACK 的情况下，Consumer 需要多次发起 ACK 传输给 Broker，多次的 I/O 浪费了服务器性能与增加了带宽的占用。
   2. 通过批量 ACK 的方式，减少多次发起 ACK，以及结合 `prefetch_count` 批量一次性从 Broker 拉取消息，可以减少很多 I/O 浪费和带宽占用。
   3. 不过，如果 Consumer 在处理某条消息时失败了，而业务上又要求不能丢失任何消息，此时就不能对所有的消息进行批量 ACK，否则 RabbitMQ 就不会再次投递该消息了。
      - **解决方案**：可以跟踪所有消息的处理结果，如果全部成功，则使用批量 ACK；如果部分成功，则有两个选择：1）如果不需要顺序消费，则可以退化为每个消息分多次发送 ACK/NACK；2）如果需要顺序消费，则本次接收到的所有  `prefetch_count` 消息全部 NACK，否则这批消息重新投递时顺序就不一致了，但是需要做好幂等性消费。
   4. **小结**：Consumer 批量 ACK 的前提是，设置了 `prefetch_count` 批量一次性从 Broker 拉取消息，否则批量 ACK 将会失去意义。

   ```java
   // void basicAck(long deliveryTag, boolean multiple) throws IOException;
   // multiple：true表示采用批量ACK，凡是deliveryTag比e.DeliveryTag的消息都会被ACK。
   channel.BasicAck(e.DeliveryTag, true);
   
   ```

3. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手。

   ![1633794760275](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794760275.png)

   1. 多线程并发消费，不需要建立多个 RabbitMQ 连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，同样存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

4. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   ![1633794730033](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794730033.png)

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个 Queue，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 启用 `prefetch_count`。
  2. 先单个 Consumer 消费，`prefetch_count` 设置为 1，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度不满足要求，则提高 `prefetch_count`，**1 次接收多条消息**，甚至批量 ACK，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  4. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，甚至批量 ACK，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则**多个消费者并发消费**，甚至批量 ACK，但要注意并发冲突和顺序消费的问题。
  6. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步，以及批量 ACK 遇到消费失败时进行全部 NACK。

###### 【线上】如何紧急处理消息积压？

如果日常系统正常运转，没有积压或者只有少量积压很快就能消费掉，但是某一个时刻，突然就开始积压消息，并且积压持续上涨，这种情况下需要在短时间内排查消息积压的原因，迅速解决问题才不至于影响业务。

- **排查思路**：能导致积压突然增加，最粗粒度的原因，只有两种，要么是**发送变快了**，要么就是**消费变慢了**。
- **发送变快了**：通过监控数据发现到是，单位时间内发送的消息增多了，即发送变快了，比如说是赶上大促或者抢购。
  - **解决方案**：保证消费速度 大于 提高后的发送速度。
    1. 这种情况，短时间内不太可能优化 Consumer 代码来提升消费性能，唯一的方法是通过扩容 Consumer 实例数来提升总体的消费能力。
    2. 如果没有足够服务器资源进行 Consumer  扩容，没办法的办法，可以考虑将系统降级，通过关闭一些不重要的业务，减少 Producer 发送的数据量，最低限度地让系统还能正常运转，服务一些重要业务。
    3. 当 MQ 快慢了时，如果也降级不了，可以临时写一个专门丢弃的 Consumer，接入不重要的业务进行消费，消费一个记录一个，然后丢弃掉，快速消费掉积压的消息，最后再在空闲时，根据记录到的消息重新补回数据。
- **消费变慢了**：通过监控数据发现到是消费编变慢了。
  - **解决方案**：保证消费速度回到以前的消费速度。
    1. 需要检查 Consumer 实例，分析一下是什么原因导致消费变慢，优先检查一下日志是否有大量的消费错误。
    2. 如果日志没有错误的话，可以通过 Dump 出堆栈信息，看一下消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。
- **其他原因**：还有一种不太常见的情况，就是通过监控发现，无论是发送速度，还是消费速度，都和原来的没什么变化。
  - **解决方案**：需要检查一下 Consumer，是不是存在一条消息消费失败然后导致反复重新投递 + 消费这种情况，因为这种情况也是会拖慢整个系统的消费速度的。

### 1.6. 什么是磁盘衡量指标？

![1634119681801](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634119681801.png)

1. **影响磁盘性能的关键因素**：磁盘服务时间，即磁盘完成一个 I/O 请求所花费的时间，由寻道时间、旋转延迟和数据传输时间三部分构成。
   - **寻道时间**：Tseek，指将读写磁头移动至正确的磁道上所需要的时间，寻道时间越短，I/O 操作越快，目前磁盘的平均寻道时间一般在3-15ms。
   - **旋转延迟**：Trotation，指盘片旋转将请求数据所在的扇区，移动到读写磁盘下方所需要的时间，旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。
     - 比如，7200rpm 的磁盘平均旋转延迟大约为 60*1000/7200/2 = 4.17ms，而转速为15000rpm 的磁盘其平均旋转延迟为 2ms。
   - **数据传输时间**：Ttransfer，指完成传输所请求的数据所需要的时间，取决于数据传输率，其值等于数据大小除以数据传输率。
     - 目前 IDE/ATA 能达到 133MB/s，SATA II 可达到 300MB/s 的接口数据传输率，数据传输时间通常远小于前两部分消耗时间，简单计算时**可忽略**。
2. **衡量磁盘的指标**：IOPS 和吞吐量。
   - **IOPS**：Input/Output Per Second，每秒输入输出量，也叫每秒读写次数，即指每秒内系统能处理的 I/O 请求数量，对于**随机读写频繁**的应用，比如小文件存储等，需要关注随机读写性能，此时 IOPS 则是关键衡量指标。
     - **公式**：IOPS = 1000ms / （Tseek + Trotation + Transfer）。
     - 如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS，常见磁盘的随机读写最大IOPS为：
       - 7200rpm 的磁盘 IOPS = 76 IOPS。
       - 10000rpm 的磁盘 IOPS = 111 IOPS。
       - 15000rpm 的磁盘 IOPS = 166 IOPS。
   - **Throughput**：吞吐量，指单位时间内成功传输的数据数量，对于**顺序读写频繁**的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标，主要取决于磁盘阵列架构、数据通道大小以及磁盘的个数。
     - **磁盘阵列架构**：不同的磁盘阵列存在不同的架构，它们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。
     - **数据通道大小**：磁盘阵列与服务器之间的数据通道，对吞吐量影响很大，比如一个 2Gbps 的光纤通道，其所能支撑的最大流量仅为 250MB/s。
     - **磁盘个数**：磁盘越多，吞吐量也越大。

### 1.7. 什么是 Linux 磁盘读请求模型？

![1634136736890](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634136736890.png)

- **背景**：虽然 15000rpm 的磁盘计算出的理论最大 IOPS 仅为 166，但在实际运行环境中，磁盘的 IOPS 往往能够突破 200，甚至更高，这其实就是在系统调用过程中，**操作系统**进行了一系列的优化。
- **概念**：虚拟文件系统层 -> 具体的文件系统层 -> Cache 层 -> 通用块层 -> I/O 调度层 -> 块设备驱动层 -> 物理块设备层。

#### 虚拟文件系统层

VFS Layer，允许 Linux 中共存众多不同的文件系统，并且对文件的操作可以跨文件系统执行。

- **VFS**：Virtual File System，虚拟文件系统，是一种软件机制，扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中，其作用是，屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。

#### 具体的文件系统层

VFS的下一层即是具体的文件系统，一个文件系统一般使用块设备上一个独立的逻辑分区。

- 对于 Linux Ext2 文件系统来说，硬盘分区首先被划分为一个个的 Block，系统上的每个 Block 都是一样大小的，但是，不同 Ext2 文件系统，Block 大小可能不同，这是在创建 Ext2 系统决定的，一般为1k 或者 4k 。

#### Cache 层

- **目的**：为了提高 Linux 操作系统对磁盘访问的性能。

  - **提高读性能**：在内存中缓存了磁盘中的部分数据，当数据的请求到达时，如果在 Cache 中存在该数据且是最新的，则直接将数据传递给用户程序，避免了对底层磁盘的操作，提高了读性能，是磁盘 IOPS 能突破 200 的重要原因之一。
  - **提高写性能**：通过暂时将数据存在 Cache 里，然后统一**异步**写到磁盘中，通过这种异步的数据 I/O 模式，解决了程序中计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使写性能大大提高。

- **两大功能**：预读和回写。

  - **预读**：根据应用程序是否需要等待预读完成，可分为**同步预读和异步预读**，如果所请求的页面处于预读的页面之中，则进行异步预读；如果所请求的页面处于预读页面之外，则进行同步预读。

    1. **同步预读**：如果所读页面不在 Cache 中，此时操作系统读入所请求的页面，同时，利用局部性原理，继续读入紧随其后的少数几个页面（通常是三个页面），其中第一个读请求必定是同步预读。
    2. **异步预读**：如果所读页面在 Cache 中，则表明前次预读命中，此时操作系统会把预读页的大小扩大一倍，但该预读过程是异步的，应用程序无需等待预读完成即可返回，只需后台慢慢读页面即可。

  - **回写**：

    - Linux 2.6.32 内核之前，采用 `pdflush` 机制将脏页真正地写到磁盘中，其刷脏时机为：

      1. **脏页太多**：在空闲内存大小少于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。
      2. **脏页太久**：当脏页驻留内存时间超过一定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。
      3. 主动调用 `fsync`。

      而回写开始后，`pdflush` 会持续写数据，直到满足以下两个条件：

      1. 已经有指定的最小数目的页被写回到磁盘。
      2. 空闲内存页已经回升，超过了阈值。空闲内存页已经回升，超过了阈值。

    - Linux 2.6.32 内核之后，放弃了原有的 `pdflush` 机制，改成了 `bdi_writeback` 机制，解决了在多磁盘的系统中，由于 `pdflush` 管理了所有磁盘的 Cache 导致了一定程度的 I/O 瓶颈。

      - `bdi_writeback` 机制为每个磁盘都创建了一个线程，专门负责这个磁盘的 Page Cache 的刷脏工作，从而实现了每个磁盘的数据刷新在线程级别上分离，从而提高了 I/O 性能。

    - 回写机制存在的问题：回写不及时，会引发数据丢失，且回写期间读I/O 性能很差。

- **Linux 实现**：一是 Page Cache，另一个 Buffer Cache，每一个Page Cache 包含若干 Buffer Cache。

  - **Page Cache**：主要作为文件系统上的**文件数据缓存**来使用，尤其是针对当进程对文件有 `read/write` 操作的。
  - **Buffer Cache**：主要用来在系统对块设备进行读写时，作为**块进行数据缓存**来使用。

#### 通用块层

通用块层的主要工作是，接收上层发出的磁盘请求，并最终发出I/O请求，该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。

#### I/O 调度层

I/O 调度层的功能是，管理块设备的请求队列，即接收通用块层发出的 I/O 请求，缓存请求并试图合并相邻的请求，并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I/O请求。

- **目的**：
  1. 如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。
  2. 为了优化寻址操作，内核不会一旦接收到 I/O 请求后，就按照请求的次序发起块 I/O 请求，Linux 提供了几种 I/O 调度算法进行优化，其思想是通过合并和排序 I/O 请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。
- **常见的 I/O 调度算法**：
  - **Noop 算法**：No Operation，最简单的 I/O 调度算法，该算法仅适当合并用户请求，是为不需要寻道的块设备而设计的（如 SSD，SSD 没有所谓的寻道时间且 I/O 响应时间非常短），并不排序请求。
    1. 新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。
  - **CFQ 算法**：完全公正排队 I/O 调度算法，其主要目标是在触发 I/O 请求的所有进程中，确保磁盘 I/O 带宽的公平分配。
    1. 使用许多个排序队列，存放了不同进程发出的请求。
    2. 通过散列将同一个进程发出的请求插入同一个队列中。
    3. 采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。
  - **Deadline 算法**：截止时间调度算法，避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。
    1. 引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。
    2. 本质是一个超时定时器，当请求被传给电梯算法时开始计时，一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。
  - **AS 算法**：AS预测调度算法，本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。
    1. 算法统计每个进程I/O操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。
    2. 如果是，立即调度下一个请求。
    3. 否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。

#### 块设备驱动层

驱动层中的驱动程序，对应具体的物理块设备，从上层中取出 I/O 请求，并根据该请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。

#### 物理块设备层

具体的磁盘设备。

### 1.8. 什么是零拷贝技术？

#### 标准 I/O

传统 Linux 系统中，标准的 I/O 接口（比如 `File#read`、`File#write`）都是基于**数据拷贝**操作的，即是 I/O 操作会导致数据在内核地址空间的缓冲区，和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作**缓存 I/O**。

- **过程**：传统 I/O 中，读取一个文件并通过 socket 发送给用户的过程，数据经历了 2 次 DMA 数据拷贝，2 次用户空间与内核空间的 CPU 拷贝操作，以及 4 次上下文切换：

  ![1634173642699](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634173642699.png)

  - **2 次 DMA 数据拷贝**：
    1. 通过 DMA 把文件数据拷贝到内核缓存。
       - **DMA**：Direct Memory Access，直接存储器访问，是一种无需 CPU 参与，让外设和系统内存之间进行双向数据传输的硬件机制，使用DMA可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐量。
    2. 通过 DMA 把内核缓存拷贝并发送到网络。
  - **2 次用户空间与内核空间的 CPU 拷贝操作**：
    1. 从内核空间的内核缓存，读取文件数据，然后拷贝到用户空间的用户缓存。
    2. 用户程序调用 `Socket#write` ，从用户空间的用户缓存，读取文件数据，然后拷贝到内核空间的内核缓存。
  - **4 次上下文切换**：
    1. 用户程序调用 `File#read` 读取文件，需要从用户态切换到内核态。
    2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
    3. 用户程序调用 `Socket#write` 发送数据，需要从用户态切换到内核态。
    4. 文件发送完成后，用户程序又需要从内核态切换回用户态。

- **优点**：如果所请求的数据已经存放在内核的高速缓冲存储器中，就可以减少实际的 I/O 操作。

- **缺点**：数据拷贝的过程会导致 CPU 的开销。

#### 零拷贝技术

- **概念**：零拷贝技术，并不是不需要拷贝，而是减少不必要的拷贝次数，避免多余地将数据从一块存储拷贝到另外一块存储，从而节省数据拷贝带来的CPU开销。
- **分类**：目前零拷贝技术主要有三种类型：

##### 直接 I/O

![1634175610607](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634175610607.png)

数据直接跨过内核，在用户地址空间与 I/O 设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作。

- **实现方法**：采用直接 I/O，需要在调用 `open` 时，传入 `O_DIRECT` 标识符，让操作系统知道接下来对文件的读写操作是使用 直接 I/O 的方式。

  ```c
  // Linux Open函数
  int open(const char *pathname, int oflag, … /*, mode_t mode * / );
  
  ```

- **使用场景**：

  - 这种类型的零拷贝多用于**数据库系统**中，方便他们自己实现一套缓存机制，以更好的提供服务。
  - 再如 Java 的 **Direct Buffer**。

##### 避免内核和用户空间的数据拷贝

当应用程序不需要对数据进行访问时，则可以通过避免将数据从内核空间拷贝到用户空间，实现零拷贝。

###### mmap

`mmap`，Memory Mapped Files，内存映射机制，并不是提供用户进程直接操作内核地址空间的能力，而是把内核中的部分内存空间映射到用户空间的内存，使得用户空间和内核空间共享一块相同的物理内存，从而提供用户进程对内存的直接访问能力。

- **实现方法**：

  ```c
  void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
  
  ```

- **实现原理**：调用 `mmap` 之后，并不会立即读取文件内容并加载到物理内存中，而是会在虚拟内存中分配地址空间，等到实际要访问数据时，才会因为内存地址对应的物理内存中没有数据，产生缺页异常，然后触发数据的加载。

- **使用场景**：

  1. 有了 `mmap` 的支持，从文件中读取数据到内核空间的文件数据缓存后，就不会再拷贝到用户空间的用户缓存了。
  2. 当调用 `Socket#send` 时，数据会直接从内核缓存，直接拷贝到 Socket 缓冲区中，避免了在用户空间中多中转一次。
  3. 所以，在 I/O 过程中，使用 `mmap` 可以减少 2 次用户空间与内核空间的 CPU 拷贝操作，替代为一次内核空间的直接拷贝。

  ![1634177254260](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634177254260.png)

- **局限**：虽然 `mmap` 能减少一次数据拷贝，但是 I/O 过程还是需要 4 次上下文切换：

  1. 用户程序调用 `mmap` 读取文件，需要从用户态切换到内核态。
  2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
  3. 用户程序调用 `Socket#send` 发送数据，需要从用户态切换到内核态。
  4. 文件发送完成后，用户程序又需要从内核态切换回用户态。

###### sendfile

`sendfile` 内核调用，是在 Linux 2.1 版本开始引入的，主要功能是在内核态中，可以在两个文件描述符之间传递数据，避免了用户空间和内核空间之间的数据拷贝操作。

- **实现方法**：

  ```c
  /**
   * in_fd：数据源的文件描述符，必须是一个可以 mmap 的文件描述符，必须指向真实的文件，不能是socket
   * out_fd：待输出的文件描述符，必须是一个socket
   */
  ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
  
  ```

- **实现原理**：使用 `sendfile` 时，数据中转与 `mmap` 类似，不经过用户空间， `sendfile` 全程在内核态执行，一次 I/O 只需要 2 次上下文切换：

  1. 用户程序调用 `sendfile` 通过 socket 发送文件，需要从用户态切换到内核态。
  2. 文件发送完成后，用户程序又需要从内核态切换回用户态。

- **sendfile 优化**：

  1. 在 Linux 2.4 版本中，对 `sendfile` 进一步做了优化，无需 CPU 从文件数据缓存拷贝到 socket缓存，而是让 socket 缓存只存储在文件数据缓存中的位置和偏移量。

  2. 在进行实际发送时，只需根据位置和偏移量，直接将文件数据缓存中的数据通过 DMA 拷贝到网卡设备中，又省掉了一次 CPU 拷贝操作。

     ![1634179262531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634179262531.png)

###### splice

```c
// 功能与sendfile类似，但fd_in和fd_out中，必须至少有一个是管道文件描述符（pipe）
ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags);
```

###### tee

```c
// 功能与sendfile类似，但fd_in和fd_out都必须是管道文件描述符（pipe）
ssize_t tee(int fd_in, int fd_out, size_t len, unsigned int flags);
```

###### sockmap

上面的几种方式，都不支持从 socket 到 socket 的转发，而 Linux 4.14 带来的 `sockmap`，可以支持在内核态中实现从 socket 到 socket 的数据转发。

##### Copy on Writes

- **概念**：写时复制技术，也算是一种零拷贝技术，其核心思想是，数据不需要提前拷贝，而是当需要修改时才进行部分拷贝。
- **原理**：
  1. 当有多个调用者都需要请求相同资源时，一开始资源只会有一份，多个调用者共同读取这一份资源。
  2. 当某个调用者需要修改数据的时候，才会分配一块内存，把数据拷贝过去，供这个调用者使用，而其他调用者依然还是读取最原始的那份数据。
  3. 每次有调用者需要修改数据时，就会重复一次拷贝流程，供调用者修改使用。
- **作用**：使用 `copy-on-write` 可以避免或者减少数据的拷贝操作，极大地提高性能。
- **实现**：其应用十分广泛，比如Linux 的 `fork` 调用、Linux 的文件管理系统、一些数据库服务、Java中的 CopyOnWriteArrayList、C++98/C++03中的std::string等等。

### 1.9. 详细介绍 Kafka？

#### 概念

![1634043435602](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634043435602.png)

Kafka 是一个分布式的、基于发布订阅模式的消息系统，可用于实现高性能数据管道、流分析、数据集成和关键任务等相关的应用程序，在大数据领域的实时计算、日志采集等场景表现出色。

- **通用用途**：异步处理、系统解耦、削峰填谷、蓄流压测。

- **特色用途**：日志收集、数据同步、数据采集。

  - **日志收集**：KafKa 做日志堆积，减轻 Logstash 压力。

    ![1633839541805](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839541805.png)

  - **数据同步**：MySQL 分库分表后，统一经过 Cannal + Kafka 同步到 ES 中，方便搜索查询。

    ![1633839719421](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839719421.png)

  - **数据采集**：实时计算分析平台，埋点采集数据，上报到 Kafka，Flink 周期性从 Kafka 获取数据进行分析。 

    - **用户活动跟踪**：Kafka 常常被用于记录 Web 用户或者 App 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 Kafka Topic 中，然后 Consumer 通过订阅这些 Topic来做运营数据的实时监控分析。

    ![1633839898897](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839898897.png)

| 专业术语       | 释义                                                         |
| -------------- | ------------------------------------------------------------ |
| Broker         | 服务器实体，用于连接 Producer 和 Consumer，单个 Kafka Broker 可以轻松处理数千个 Partition 以及百万级/s的消息量 |
| Message        | 消息，Kafka 中的数据单元，可以看成是数据库里的一个数据行或一条记录 |
| Topic          | 主题，每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic，Topic 是逻辑的概念，物理上不同 Topic 的消息会分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个Broker上，但用户只需指定消息的 Topic，即可生产或者消费数据，而无需关心数据存放在物理上的何处 |
| Partition      | 分区，Parition 是物理上的概念，每个 Topic 包含一个或多个 Partition |
| Replica        | 副本，每个 Partition 有多个 Replica，每个 Replica 都会分布在不同的 Broker 中，都有一个 Leader Replica 进行复制同步 |
| Producer       | 生产者，负责发布消息到 Broker，默认情况下 Broker 会把消息均衡地分布到 Topic 下的所有 Partition 上，另外，也可以通过直接指定、根据 Key 散列取模、轮询方式来得到消息要存放的 Partition |
| Consumer       | 消费者，负责向 Broker Partition 读取消息，Consumer 通过 Consume Offset 来区分已经读过的消息，消费未读过的消息，然后会把每个 Partition 最后读取的 Consume Offset 保存在 Zookeeper 或 Kafka上，使得即使 Consumer 被关闭或重启，当前的读取状态也不会丢失 |
| Consumer Group | 消费者组，每个 Consumer 属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则该 Consumer 属于默认的消费者组；消费者组可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会重新再平衡，接管已失效的 Consumer 的工作 |
| Consume Offset | 消费偏移量，不同消费者组的 Consumer，可以对同一个 Partition 存储不同的 Offset，它们之间互不影响，用于记录读取状态，区分已经读过的消息，消费未读过的消息；指向最后消费的消息，通过在客户端库维护这个偏移量，并且根据 Kafka 版本，存储在 ZooKeeper 或者 Kafka 中 |
| Log Offset     | 日志偏移量，消息写入时，每一个 Partition 都有一个 Offset，它是每个 Partition 中最新、最大的 Offset |
| Log Segment    | 一个 Partition 由多个 LogSegment 组成，一个 LogSegment 由 `.log`、`.index`、 `.timeindex` 组成，`.log` 是顺序追加写入的，其文件名是以文件中第一条 Message 的Offset 来命名的，`.Index` 可以在日志删除和数据查找时进行快速定位，`.timeStamp` 则可以根据时间戳查找对应的偏移量 |

#### 原理

##### 日志分区原理

![1634092563478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634092563478.png)

###### Kafka 本质

Kafka 本质上是一个**分布式的、异步复制的提交日志**，本身并没有队列的概念：

- **分布式**：Kafka 集群可以实现容错和方便扩展。
- **异步复制**：Follow Replica 副本定时异步拉取 Leader Partition Offset，以实现消息跨多个节点复制。
- **提交日志**：消息存储在 Partition 中，附加到 Topic 的日志上。

###### 日志分区模型

1. **消息存储方面**：Kafka 不像 RabbitMQ 那样存储在 Queue 中，只是把消息追加到日志中，无论消息被消费一次还是一千次，消息都会保持原状，最后根据数据的保留策略，来决定是否被删除。
   - RabbitMQ 通过把消息放入 FIFO 的队列 Queue 上，并跟踪 Queue 中该消息的状态，当 Consumer 消费该消息后，无论该消息有没有被持久化，Queue 都会把该消息删除掉。
2. **消息消费方面**：Kafka 不像 RabbitMQ 那样通过 **Broker Push 模型**消费，而是让每个 Consumer 跟踪它自己在日志中的消费偏移量，通过 **Consumer Pull 模型**，每次都从消费偏移量位置开始消费消息。
   - **消费偏移量**：
     - Consume Offset，不同消费者组的 Consumer，可以对同一个 Partition 存储不同的 Offset，它们之间互不影响，用于记录读取状态，区分已经读过的消息，消费未读过的消息。
     - 指向最后消费的消息，通过在客户端库维护这个偏移量，并且根据 Kafka 版本，存储在 ZooKeeper 或者 Kafka 中。
   - **Broker Push VS Consumer Pull 模型**：
     - RabbitMQ 使用 Broker Push 模型，结合 Consumer 配置的预取限制，来防止单个 Consumer 负担过重，对于低延迟消息传递非常有用，适用于 RabbitMQ 基于队列的架构。
     - Kafka 使用 Consumer Pull 模型，Consumer 根据消费偏移量来批量拉取消息，由于 Kafka Partition 能够保证消息顺序，所以可以通过消息批量拉取，来实现更高效的消息传递，从而提供更高的吞吐量。
   - **消息日志优势**：
     1. **消息持久化时间长**：消息投递后，Kafka 会长时间持久化消息，直到删除策略触发，而 RabbitMQ 则是在消息被消费后就删除。 
     2. **允许消费先前消息**：对于 Kafka 而言，可以允许 Consumer 倒带并消费先前偏移量的消息，只需将 Consumer 的偏移量往先前方向移动 N 小时即可，而使用 RabbitMQ 需要以某种方式重新发布先前的消息。
3. **消息分区方面**：
   1. 生产者负责发布消息到 Broker，默认情况下 Broker 会把消息均衡地分布到 **Topic** 下的所有 Partition 上，另外，也可以通过直接指定、根据 Key 散列取模、轮询方式来得到消息要存放的 Partition。
   2. 每个**分区**（Partition ）都是一个单独的数据结构，可以保证消息顺序，但仅在单个 Partition 内得到保证，一个 Partition 不能支持竞争消费者，因此同一个消费者组内只能有一个 Consumer 去消费某个 Partition。
   3. 每个**消费者**（Consumer）属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则属于默认的消费者组。
   4. **消费者组**（Consumer Group）可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会重新再平衡，接管已失效的 Consumer 的工作。
      - 消费者组中的每个  Consumer  将处理 Topic 下所有消息的一个 Partition 子集，即从同一Topic 的不同分区消费。
      - 而 RabbitMQ 的竞争消费者，是从同一个 Queue 中消费，在这一点上，RabbitMQ 看起来更加灵活，因为它保证了队列中的消息顺序，并且能够应对不断变化的竞争消费者数量。

###### 分区分配策略

- **Broker 分区存储**：
  1. 先把所有 Broker 和 Partition 排好序。
  2. 然后把第 i 个 Partition 分配到第 **i mod n** 个 Broker 上。
- **Producer 消息投递**：
  1. 当 key 为空时，Producer 生产的消息，将随机发送到各个 Partition，不同的 Kafka 版本会有不同方式，比如轮训、随机、固定等。
  2. 当 key 不为空时，采取 **key#hash mod Partion#size** 的方式，来决定把消息发送到哪个 Partition 上。
- **Consumer 消息消费**：一个 Partition 只能被同一个 Consumer Group 内的一个 Consumer 消费。
  - **RangeAssignor**：默认，简单相除。
    - **原理**：
      1. 用 Partition#size / Consumer#size 来决定每个 Consumer 消费几个Partition。
      2. 当除不尽时，则前面的 Consumer 会比后面的 Consumer 多消费 Partition。
      3. 当 Consumer#size > Partition#size 时，会有空消费的 Consumer。
    - **缺点**：分配不均匀，可能会出现部分 Consumer 过载的情况。
  - **RoundRobinAssignor**：排序 + 轮训。
    - **原理**：
      1. 把 Consumer Group 内所有 Consumer，以及其所订阅的所有 Topic#Partition 按照字典顺序排好序。
      2. 然后通过轮询的方式，逐个把 Partition 分配给每个 Consumer。
      3. 如果同一个 Consumer Group 内所有 Consumer 订阅的信息都是相同的，那么该策略的分区分配会是均匀的。
      4. 如果同一个 Consumer Group 内所有 Consumer 订阅的信息都不相同，那么在执行分区分配时就不是完全的轮询分配了，可能会导致分区分配的不均匀。
         - 比如某个 Consumer 没有订阅某个Topic，但该 Topic 会被组内其他 Consumer 订阅，则会在分配分区时，该 Consumer 将分配不到该 Topic 的任何 Partition。
    - **缺点**：还是会出现分配均匀的情况。
  - **StickyAssignor**：粘性分配，0.11.x 版本开始引入。
    - **原理**：
      1. 分区的分配要尽可能地均匀。
      2. 分区的分配尽可能地与上次分配的保持相同。
         - 如果发生分区重分配，那么对于同一个  Partition 而言，有可能之前的 Consumer 新指派的 Consumer 不是同一个。
         - 此时，如果使用非粘性策略，则对于之前 Consumer 进行到一半的处理，还要在新指派的消费者中再次复现一遍，很浪费系统资源。
         - 但 StickyAssignor 策略具备一定的粘性，可以尽可能地让前后两次分配相同，进而减少系统资源的损耗，以及其它异常情况的发生。
      3. 当前面两点发生冲突时，第一个点优先于第二个点。
    - **缺点**：实现比较复杂。

##### 日志文件存储原理

![1634213772578](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213772578.png)

1. 在 Kafka 日志文件存储中，同一个 Topic 下会有多个不同的 Partition，每个 Partiton 为一个目录，所以，Partition 是实际物理上的概念，而 Topic 则是逻辑上的概念。
   - **Partition 目录命名规则**：Topic + 有序序号，第一个序号从 0 开始，最大的序号为 Partition 数量减 1。
   - **为什么不能以 Partition 作为存储单位**？
     1. 虽然 Kafka Consumer 能够根据 Consume Offset 查找到具体的某个消息，但是查找过程是顺序查找，如果数据量很大的话，查找效率依然很低，所以，Kafka 采用了**分段和索引**的方式，通过**二分查找**来解决查找效率问题。
     2. 而且，每个 Partition 被平均分配到多个 Segment 文件，也方便 Old Segment 的删除，即方便已消费消息的清理，提高磁盘的利用率。
   - **Segment 分段策略**：
     - **按大小分片**：当日志分段文件大小，超过了 Broker 参数 `log.segment.bytes` 配置的值时，则需要继续分段，默认为 `1073741824（1GB）`。
     - **按时间分片**：当日志分段文件中，消息的最大时间戳与当前系统时间戳的差值，大于 `log.roll.ms` 或者大于 `log.roll.hours` 配置的值时，则需要继续分段，默认为 `168（7天）`。
     - **按索引分片**：当 `.index` 或者 `.timeindex` 文件大小达到 Broker  `log.index.size.max.bytes` 配置的值时，则需要继续分段，默认为 `10MB`。
     - **按偏移量分片**：当新追加消息的偏移量 `offset`，与日志分段文件偏移量的差值 `baseOffset`，大于 `Integer.MAX_VALUE` 时，则需要继续分段。
2. 然后，Partition 还可以细分为多个**小文件段** Segment，一个 Partition 物理上由多个 Segment 组成，Segment 不是一个目录，而是由 3 部分组成，分别为 `.index` 文件、`.timeindex` 文件 和 `.log` 文件，分别表示偏移量索引文件、时间戳索引文件和日志数据文件。
   - **Segment 文件命名规则**：
     1. Partition 中第一个 Segment 从 `0` 开始，数值为 `20` 位数字字符长度，不够的用 `0` 填充。
     2. 后续每个 Segment 文件名，为上一个 Segment 文件**最后一条消息**的 `offset` 值。
   - **Segment 索引文件的作用**：为了进一步提高查找效率，Kafka 还为每个分段后的数据建立了**索引文件**，然后通过索引文件的**稀疏存储**，来降低 Partition 元数据的占用大小。
   - **如何查找偏移量为 118 的消息**？根据时间戳查找的方式同理。
     1. 首先，Kafka 会用一个 `ConcurrentSkipListMap` 跳跃表，来记录每个日志分段，通过它可以根据偏移量 `118` 定位到 Segment 在 00000000000000000000.index 中。
     2. 然后，通过**二分查找**在该 `.index` 文件中，找到**不大于 `offset:118`  的最大索引项**，即 `offset:116` 那栏，得到 `position:9679`。
     3. 接着，从 `.log` 文件中，物理位置为 `position:9679` 的位置，开始顺序查找 `offset:118` 的消息。

##### 生产者消息投递原理

![1634213881470](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213881470.png)

1. Producer 客户端分为两个线程，在创建时会创建一个 `Sender` 守护线程。
2. 主线程负责把生产的消息 -> 拦截器 -> 序列化器 -> 分区器 -> 缓存到消息累加器 -> 追加到每个分区 ProducerBatch 队列的队尾。
3. 其中，消息存放在 ProducerBatch 对象中，相当于 ProducerBatch 队列对消息进行了组装，在满足批次发送的条件时，则会通过 `Sender` 线程批次发送消息，减少网络资源消耗。
   - **批次发送的条件**：缓冲区数据大小达到 `batch.size` ，或者 `linger.ms` 达到上限时。
4. `Sender` 线程会从 ProducerBatch 队列的队头获取消息 -> 创建请求 -> 提交给 Selector 发送到 Broker 指定的分区，同时还会把请求缓存在 Node 结点，代表已发送但为收到 Broker ACK 确认的请求，如果 Producer 收到消息后，则会对其清理。
5. Broker 收到消息后，会根据 Producer 的 `acks` 配置参数，落盘消息到 Partition 中。
6. 如果 Producer 还配置了大于 0 的 `retrires` 参数，当未收到 Broker ACK 确认时，Producer 会对该消息进行重试。

##### 消费者消息消费原理

![1634213916345](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213916345.png)

1. Consumer 客户端负责向 Broker Partition 读取消息，通过 Consume Offset 来区分已经读过的消息，消费未读过的消息。
2. 然后会把每个 Partition 最后读取的 Consume Offset 保存在 Zookeeper 或 Kafka上，使得即使 Consumer 被关闭或重启，当前的读取状态也不会丢失。
3. 而对于消费者组，每个 Consumer 属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则该 Consumer 属于**默认的消费者组**。
4. 消费者组可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会 Rebalance，接管已失效 Consumer 的工作。

##### 高性能原理 | 为什么 Kaka 这么快？

Kafka 对性能做了大量的优化，使得单个 Broker 就可以轻松处理数千个 Partition 以及百万级/s 的消息量，其高性能原理为：

###### 1、利用 Partition 实现并行处理

并行处理可以提升速度，因为多个人搬砖肯定比一个人搬得快。

- **集群优势**：每个 Topic 都包含一个或多个 Partition，不同 Partition 可以位于不同 Broker 节点，因此，可以充分利用集群优势，实现机器间的并行处理。
- **多磁盘优势**：另外，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个 Broker 节点，也可通过配置，让不同 Partition 落于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

###### 2、顺序写磁盘

在许多的开源框架，比如 Kafka、HBase，都通过追加写，即顺序写磁盘的方式，来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。

- **消息写入时**：每个 Partition 是一个有序的、不可变的消息序列，新消息只需不断追加到 Partition 的末尾，实现顺序写磁盘。
  - **顺序写性能高的原因**：机械硬盘的连续读写性能很好，但随机读写性能很差，主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要**不停的移动**，时间都浪费在了磁头寻址上，所以性能不高。
  - **顺序写的缺点**：当从文件中读一些数据时，需要倒序扫描，直到找到所需要的内容，这将会花费更多的时间。
    - **Kafka 解决方案**：日志分段 + 日志索引，见《日志索引原理》。
- **消息清除时**：
  1. 由于磁盘有限，不可能保存所有数据，所以 Kafka 还需要删除旧的数据。
  2. 又由于顺序写入的原因，Kafka 采用各种删除策略进行数据删除时，并非通过使用 `读 - 写` 模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个 Segment 的方式去删除 Partition 内的数据，从而避免了对文件随机写的操作。

###### 3、充分利用 Page Cache

![1634213586951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213586951.png)

- **对于读操作**：可直接在 Page Cache 内进行，避免了对底层磁盘的操作，提高了读性能。
  - 如果消费和生产速度相当，甚至不需要通过物理磁盘，而是直接通过 Page Cache 进行交换数据。
- **对于写操作**：
  1. Broker 收到数据后，写磁盘只是暂时把数据存在 Page Cache 中，然后交由操作系统来统一**异步**写到磁盘中，减少了 Broker 访问磁盘的次数，提高了写性能。
  2. 另外，根据 I/O 调度算法， I/O Scheduler 会把连续的小块写，组装成大块的物理写，同时会尝试将一些写操作重新按顺序排好，减少磁盘头的移动时间，进一步提高了写性能。
  3. **局限**：写磁盘只是把数据写入 Page Cache，并不保证数据一定完全写入磁盘，虽然 Kafka 进程重启时， Page Cache 仍然可用，但如果在机器宕机时，则可能会由于 Page Cache 内的数据未写入磁盘，从而导致数据的丢失。
     - **解决方案**：
       - **副本机制**：这种丢失只发生在机器断电等，造成操作系统不工作的场景里，可以由 Kafka Replication 机制去解决。
       - **强制刷脏**：Kafka 提供了 `flush.messages` 和 `flush.ms` 两个参数，可以把 Page Cache 中的数据强制 Flush 到磁盘中，但是 Kafka 并**不建议使用**，这是因为如果为了保证这写情况下的数据不丢失，而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。

###### 3、使用零拷贝技术

![1634213686949](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213686949.png)

- **背景**：Kafka 存在大量的**网络数据持久化到磁盘**（Producer 到 Broker）和**磁盘文件通过网络发送**（Broker 到 Consumer）的过程，这些过程的性能直接影响 Kafka 整体的吞吐量。

- **Producer 到 Broker**：网络数据持久化到磁盘。

  1. **传统 I/O 模式**：数据从网络传输到文件，需要 4 次数据拷贝、4 次上下文切换和 2 次系统调用。

     ![1634181215053](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634181215053.png)

     - **4 次数据拷贝**：

       1. 首先，通过 DMA copy 将网络数据，拷贝到内核态 Socket Buffer。
       2. 然后，应用程序将内核态 Socket Buffer 数据，通过 CPU copy 读入用户态 Buffer。
       3. 接着，用户程序将用户态 Buffer 数据，再通过 CPU copy 拷贝到内核态 Buffer。
       4. 最后，通过 DMA copy 将数据拷贝到磁盘文件。
          - 这里的数据落盘，对于 Kafka的是**非实时**的，Kafka 充分利用了 Page Cache 来提高 I/O 效率。

     - **4 次上下文切换**：

       1. 用户程序调用 `Socket#read()` 读取网络数据，需要从用户态切换到内核态。
       2. 网络数据读取完成后，用户程序又需要从内核态切换回用户态。
       3. 用户程序调用 `File#write` 写入文件数据到磁盘，需要从用户态切换到内核态。
       4. 文件写入磁盘完成后，用户程序又需要从内核态切换回用户态。

     - **2 次系统调用**：socket#read、file#write。

       ```java
       data = socket.read()；// 读取网络数据 
       File file = new File()；
       file.write(data)；// 持久化到磁盘 
       file.flush()；
       
       ```

  2. **mmap 零拷贝优化 I/O**：

     ![1634181981080](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634181981080.png)

     - **优化思路**：
       1. Broker 读取到 Socket Buffer 的网络数据，其实可以直接在内核空间完成落盘，没有必要将其再拷贝到用户空间中。
       2. 所以，Kafka 采用了 `mmap` ，将内核中读缓冲区 read buffer 的地址与用户空间的缓冲区 user buffer 进行映射，实现内核缓冲区与应用程序内存的共享，省去了用户空间到内核空间复制的开销，减少了 2 次用户空间与内核空间的 CPU 拷贝操作，替代为一次内核空间的直接拷贝，提高了 I/O 性能。
     - **优化实现**：
       1. Kafka Java NIO，提供了一个 `MappedByteBuffer` 类可以用来实现内存映射。
       2. MappedByteBuffer 只能通过调用 `FileChannel#map（）` 抽象方法取得，具体实现是在 `FileChannelImpl.c` ，该方法底层正是调用了 Linux 内核 `mmap` 的API。
       3. 使用 `MappedByteBuffer` 类要注意的是，`mmap` 在 Full GC 时才会被进行释放，手动 Close 时，需要反射调用 `sun.misc.Cleaner` 方法来手动清除内存映射文件。

- **Broker 到 Consumer**：磁盘文件通过网络发送。

  1. **传统 I/O 模式**：数据从文件到网络传输，也需要 4 次数据拷贝、4 次上下文切换和 2 次系统调用。

     ![1634173642699](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634173642699.png)

     - **4 次数据拷贝**：
       1. 首先，调用 `File#read` ，通过 DMA 拷贝将文件数据读入到内核态 Buffer。
       2. 然后，应用程序通过 CPU 拷贝将内存态 Buffer 数据读入到用户态 Buffer。
       3. 接着，调用 `Socket#send `时，将用户态 Buffer 数据，通过 CPU 拷贝到内核态 Buffer。
       4. 最后，通过 DMA 拷贝将数据拷贝到 NIC Buffer。
     - **4 次上下文切换**：
       1. 用户程序调用  `File#read` 读取文件，需要从用户态切换到内核态。
       2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
       3. 用户程序调用  `Socket#send` 发送数据，需要从用户态切换到内核态。
       4. 文件发送完成后，用户程序又需要从内核态切换回用户态。
     - **2 次系统调用**：file#read、socket#send。

     ```java
     buffer = File.read()；// 读取文件
     Socket.send(buffer)；// 发送文件
     
     ```

  2. **sendfile 零拷贝优化 I/O**：

     ![1634190319687](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634190319687.png)

     - **优化思路**：

       1. Linux 2.4+ 内核通过 `sendfile` 系统调用，提供零拷贝，使用 `sendfile` 时，数据中转与 `mmap` 类似，不经过用户空间， `sendfile` 全程在内核态执行，一次 I/O 只需要 2 次上下文切换，数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝，这也是零拷贝这一说法的来源，大大提高了性能。
       2. 在这里，Kafka Customer 从 Broker 读取数据，采用 `sendfile`，将磁盘文件读到内核缓冲区后，转到 NIO buffer 进行网络发送，无需 CPU 拷贝，减少了 CPU 消耗，提高 I/O 吞吐量。

     - **优化实现**：

       1. Java NIO 对 `sendfile` 的支持是 `FileChannel.transferTo()/transferFrom()`，把磁盘文件读取内核缓冲区 fileChannel 后，直接转给 socketChannel 进行发送。

          ```java
          // java.nio.channels.FileChannel
          public abstract long transferTo(long position, long count,
                           WritableByteChannel target) throws IOException;
          public abstract long transferFrom(ReadableByteChannel src,
                           long position, long count) throws IOException;
          ```

       2. Kafka 数据传输通过 `TransportLayer` 来完成，其子类 `PlaintextTransportLayer` 正是通过Java NIO 的 `FileChannel.transferTo()/transferFrom()` 方法实现零拷贝。

       3. 注意，`transferTo()/transferFrom()` 并不保证一定能使用零拷贝，实际上是否能使用零拷贝与操作系统相关，如果操作系统提供 `sendfile` 这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。

###### 4、消息批处理

在很多情况下，系统瓶颈并不是 CPU 或磁盘，而是网络 I/O，所以，Kafka 的客户端和 Broker 还会在通过网络发送数据之前，在一个 Batch 中累积多条记录（包括读和写）再批次发送，分摊数据包网络往返的开销，使用更大的数据包提高带宽的利用率。

###### 5、数据压缩后传输

数据压缩，一般都和批处理作为优化手段配套使用，Producer 可将数据压缩后再传输给 Broker，可以减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4，可通过 `compression.type` 配置。

#### API

##### Server.properties 重要配置

| 属性                               | 释义                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| zookeeper.connect                  | 指明 Broker 要连接的 ZK 集群，多个节点用逗号分隔开，ZK 用于管理 Kafka集群的元数据，比如 Topic、Partition、Leader Partition、副本 Replicas 等 |
| listeners                          | 与客户端进行交互的端口，比如消息投递、消息创建，可结合 `listener.security.protocol.map` 指定具体传输的协议类型，比如有 PLAINTEXT 明文传输、SSL 加密传输等 |
| log.dirs                           | 日志存储路径，建议配置多个路径，因为多个不同磁盘的路径，Kafka 会在含有分区目录最少的文件夹下创建新的分区目录，一来可提高吞吐量，二来可提高磁盘的容错性 |
| log.retention.{hours\|minutes\|ms} | Broker 级别的日志留存寿命，默认为 hours=168                  |
| log.retenion.bytes                 | Broker 级别的日志留存大小，默认为 -1，表示没有限制           |
| message.max.bytes                  | Broker 级别的最大消息大小，默认为 976 KB                     |
| retention.ms                       | Topic 级别的日志留存寿命                                     |
| retention.bytes                    | Topic 级别的日志留存大小                                     |
| max.message.bytes                  | 消息级别的最大消息大小                                       |
| auto.create.topics.enable          | 是否允许自动创建 Topic，建议为 false                         |
| unclean.leader.election.enable     | 是否允许选举未完全同步的副本作为 Leader                      |
| auto.leader.rebalance.enable       | 是否允许一段时间后进行 Leader 重选举，重新更换 Leader，建议为 false |

##### Broker 增删改查

```bash
# 启动Kafka
./kafka-server-start.sh -daemon ../config/server.properties
# 关闭Kafka
./kafka-server-stop.sh ../config/server.properties
# 增
kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x 
								--partitions 1 --replication-factor 1
# 删
kafka-topics.sh --zookeeper localhost:2181/myKafka --delete --topic topic_x
# 改
kafka-topics.sh --zookeeper localhost:2181/myKafka --alter --topic topic_x
								--config max.message.bytes=1048576
# 查
kafka-topics.sh --zookeeper localhost:2181/myKafka --describe --topic topic_x

```

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka_2.12</artifactId>
</dependency>

```

##### Producer | HelloWorld

Producer 是线程安全的，允许多线程使用同一个 Producer 进行消息投递。

###### Producer 必要配置

| 属性              | 释义                                                         |
| ----------------- | ------------------------------------------------------------ |
| bootstrap.servers | Kafka Broker 地址，存在多个时使用逗号分隔，建议使用多个地址，提高容错性 |
| key.serializer    | 消息 Key 序列化器                                            |
| value.serializer  | 消息 Value 序列化器                                          |
| client.id         | 标记 kafka 客户端的 ID                                       |

```java
public static void main(String[] args) {
    // 1. 配置生产者启动的关键属性参数
    Properties properties = new Properties();
    /*1.1. 连接kafka集群的服务列表，如果有多个，使用逗号进行分隔*/
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.111:9092");
    /*1.2. 标记kafkaClient的ID*/
    properties.put(ProducerConfig.CLIENT_ID_CONFIG, "quickstart-producer");
    /*1.3. Key序列化器: kafka用于做消息投递计算具体投递到对应的主题的哪一个partition而需要的*/
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    /*1.4. Value序列化器: 实际发送消息的内容序列化*/
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    // 2. 传递properties属性参数集合, 构造kafka生产者对象
    KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
    for(int i = 0; i < 10; i++){
        // 3. 构造消息内容: topic, 实际消息体
        User user = new User("00" + i, "张三");
        ProducerRecord<String, String> record = new ProducerRecord<>(Const.TOPIC_QUICKSTART, JSON.toJSONString(user));

        // 4. 发送消息, 返回的是一个future对象
        producer.send(record);
        System.err.println("quickstart producer send....");
    }

    // 5. 关闭生产者
    producer.close();
}
```

##### Consumer | HelloWorld

Consumer 是非线程安全的，不允许多线程使用同一个 Consumer 进行消息投递。

- 因为在 `org.apache.kafka.clients.consumer.KafkaConsumer#acquire` 中，会校验同一个 Consumer 是否存在其他线程，如果是则会抛出 `ConcurrentModificationException`，Kafka Consumer 在执行任何都做都会先执行 `acquire` 方法来检测线程是否安全。

###### Consumer 必要配置

| 属性                    | 释义                                                         |
| ----------------------- | ------------------------------------------------------------ |
| bootstrap.servers       | Kafka Broker 地址，存在多个时使用逗号分隔，建议使用多个地址，提高容错性 |
| key.deserializer        | 消息 Key 反序列化器                                          |
| value.deserializer      | 消息 Value 反序列化器                                        |
| group.id                | 消费者所属的消费组，不配置时会使用默认的 `""` 消费者组       |
| subscribe               | 订阅消费的 Topic，支持集合方式（订阅多个 Topic）或者正则表达式（正则匹配 Topic） |
| assign                  | 指定消费 Topic 下的某个 Partition                            |
| enable.auto.commit      | 是否开启自动提交，默认为 true，实际工作中建议设置为 false，即手工提交，分为 `commitSync` 同步提交，以及 `commitAsync` 异步提交两种方式 |
| auto.commit.interval.ms | 自动提交周期，默认值为 5 s                                   |

```java
public static void main(String[] args) {
    // 1. 配置属性参数
    Properties properties = new Properties();
    /*1.1. 连接kafka集群的服务列表，如果有多个，使用逗号进行分隔*/
    properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.111:9092");
    /*1.2. 设置订阅组ID, 与消费者订阅组有关系*/
    properties.put(ConsumerConfig.GROUP_ID_CONFIG, "quickstart-group");
    /*1.3. Key反序列化器*/
    properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    /*1.4. Value反序列化器*/
    properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    /*1.5. 设置常规属性: 会话连接超时时间*/
    properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);
    /*1.6. 设置常规属性: 自动提交与自动提交周期, 默认不用设置*/
    properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
    properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);

    // 2. 创建消费者对象
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);

    // 3. 订阅感兴趣的主题
    consumer.subscribe(Collections.singletonList(Const.TOPIC_QUICKSTART));
    System.err.println("quickstart consumer started...");

    /*监听消息*/
    try {
        while (true){
            // 4. 采用PULL的方式消费数据
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(String.format("topic=%s, partition=%s, offset=%s, key=%s, value=%s",
                                                 record.topic(), record.partition(), record.offset(), record.key(), record.value()));
            }
        }
    } catch (Exception e){
        throw e;
    } finally {
        consumer.close();
    }
}

```

##### 客户端重要配置

###### Producer 重要配置

- 在请求完成之前，Producer 要求 Broker 返回 ACK 确认的策略， 同时也控制着所发送消息的持久性：
  - **acks=0**：如果设置为 0，那么 Producer 不会 Leader Broker 的任何 ACK 确认，该消息记录会被将立即添加到 socket 缓冲区并视为已发送。
    - 在这种情况下，不能保证 Broker 已经收到记录，并且 Producer 配置的重试机制也会生效，为每个记录返回的偏移量将始终设置为 -1。
  - **acks=1**：默认为 1，意味着 Leader Broker 会把记录写入其本地日志，然后做出 ACK 响应给 Producer，并不会等待所有 Follower 确认完。
    - 在这种情况下，如果 Leader Broker 在返回 ACK 确认后发生失败，Follower 被选举为新 Leader 时，由于该记录 Follower 还没完成同步，所以将导致丢失。
  - **acks=all**：相当于 `ack=-1`，意味着 Leader Broker 将等待 ISR 中所有的 Broker 确认后才返回 ACK 响应给 Producer。
    - 这是最高的可用保证，只要至少有一个同步副本保持活动状态，该记录就不会丢失。 

| 属性                    | 释义                                                         |
| ----------------------- | ------------------------------------------------------------ |
| acks                    | Broker ACK 确认策略，默认为 1                                |
| max.request.size        | 用于限制 Producer 发送消息的最大值                           |
| retries                 | 重试次数，默认为 0                                           |
| retry.backoff.msretries | 重试间隔，默认为 100                                         |
| compression.type        | 消息的压缩方式，默认为 none，支持 gzip、snappy、lz4 压缩格式 |
| connections.max.idle.ms | 用于指定在多久之后关闭限制的连接，默认为 540000 ms（9 分钟） |
| linger.ms               | 用于指定 Producer 批发送之前，等待消息加入 ProducerBatch Deque 时间，默认为 0 |
| batch.size              | 指定累加多少条消息，才进行一次批发送                         |
| buffer.memeory          | Producer 缓冲待批发送消息的大小，默认为 32 MB                |
| receive.buffer.bytes    | 用于设置 Socket 接收消息缓冲区 SO_RECBUF 的大小，默认为 32 KB |
| send.buffer.bytes       | 用于设置 Socket 发送消息缓冲区 SO_SNDBUF 的大小，默认为 128 KB |
| request.timeout.ms      | 用于设置 Producer 等待请求响应的最长时间，默认为 3000 ms     |

###### Consumer 重要配置

- 当 Kafka 中没有初始偏移量时，比如偏移量数据已被删除，可以根据以下策略进行设置：
  1. **earliest**：自动将偏移量重置为最早的偏移量。
  2. **latest**：自动将偏移量重置为最新的偏移量。
  3. **none**：如果没有找到之前的偏移量，则向 Consumer 抛出异常。

| 属性                      | 释义                                             |
| ------------------------- | ------------------------------------------------ |
| fetch.min.bytes           | 一次拉取的最小数据量，默认为 1 B                 |
| fetch.max.bytes           | 一次拉取的最大数据量，默认为 50 MB               |
| max.partition.fetch.bytes | 一次拉取一个 Partition 的最大数据量，默认为 1 MB |
| fetch.max.wait.ms         | 拉取请求的最大延迟等待时间，默认为 500 ms        |
| max.poll.records          | 每次拉取的消息最大条数                           |
| auto.offset.reset         | 偏移量丢失处理策略，默认为 latest                |

##### 客户端拦截器

###### Producer 拦截器

```java
// Kafka自定义Producer拦截器
public class CustomProducerInterceptor implements ProducerInterceptor<String, String> {
    // 消息发送前置拦截器
    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {...}
    
    // 消息发送后置拦截器
	@Override
    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {...}
    
    // 生产者关闭拦截器
    @Override
    public void close() {...}
    
    // 生产者初始化拦截器
    @Override
    public void configure(Map<String, ?> map) {...}
}

// Kafka Producer拦截器测试类
public class InterceptorProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加生产者拦截器属性: 可以配置多个拦截器
        properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, CustomProducerInterceptor.class.getName());
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        ... 
    } 
}
```

###### Consumer 拦截器

```java
// Kafka自定义消费者拦截器
public class CustomConsumerInterceptor implements ConsumerInterceptor<String, String> {
    // 消费消息前拦截器
    @Override
    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> consumerRecords) {...}
    
    // 消息消费完毕提交前拦截器: 默认配置了每5s轮训一次是否提交, 所有也会每5s执行该拦截器
    @Override
    public void onCommit(Map<TopicPartition, OffsetAndMetadata> map) {...}
    
    // 消费者关闭拦截器: 从控制台关闭的不会执行, 只有代码自动关闭的才会
    @Override
    public void close() {...}
    
    // 消费者初始化拦截器
    @Override
    public void configure(Map<String, ?> map) {...} 
}

// Kafka Consumer拦截器测试类
public class InterceptorConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加消费端拦截器属性: 可以配置多个拦截器
        properties.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, 	CustomConsumerInterceptor.class.getName());
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        ...
    }
}
```

##### 客户端序列化/反序列化器

###### Producer 序列化器

序列化，Producer 需要用序列化器  Serializer 把对象转换成字节数组，Kafka Broker 才能接受。 

```java
// Kafka自定义User序列化器
public class UserSerializer implements Serializer<User> {
    // User序列化器初始化方法
    @Override
    public void configure(Map<String, ?> map, boolean b) {...}
    
    // User序列化器序列化方法
	@Override
    public byte[] serialize(String s, User user) {
        ...
        // 分配需要传输的字节数组: 各属性字节数组长度 + 各属性实际字节数组
        ByteBuffer byteBuffer = ByteBuffer.allocate(4 + idBytes.length + 4 + nameBytes.length);
        
        // 设置ID属性: 字节数组长度 + 实际字节数组
        byteBuffer.putInt(idBytes.length);
        byteBuffer.put(idBytes);
        
        // 设置NAME属性: 字节数组长度 + 实际字节数组
        byteBuffer.putInt(nameBytes.length);
        byteBuffer.put(nameBytes);
        
        // 返回组装好的字节数组
        return byteBuffer.array();
        ...
    }
    
    // User序列化器关闭方法
    @Override
    public void close() {...}
}

// Kafka 自定义Producer序列化器测试类
public class SerializerProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // Key使用默认的序列化器
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // Value使用自定义的序列化器
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, UserSerializer.class.getName());
        KafkaProducer<String, User> producer = new KafkaProducer<>(properties);
        ...
    }
}

```

###### Consumer 反序列化器

反序列化，Consumer 需要把从 Broker 拉取出来的字节数组，使用反序列化器 Deserializer 转换成相应的对象。

```java
// Kafka自定义User反序列化器
public class UserDeserializer implements Deserializer<User> {
    // 自定义User反序列化器初始化方法
    @Override
    public void configure(Map<String, ?> map, boolean b) {...}
    
    // 自定义User反序列化器反序列化方法
 	@Override
    public User deserialize(String topic, byte[] data) {
        ...
        // 包装字节数组成ByteBuffer对象
        ByteBuffer byteBuffer = ByteBuffer.wrap(data);
        
        // 获取ID属性
        int idLen = byteBuffer.getInt();
        byte[] idBytes = new byte[idLen];
        byteBuffer.get(idBytes);

        // 获取NAME属性
        int nameLen = byteBuffer.getInt();
        byte[] nameBytes = new byte[nameLen];
        byteBuffer.get(nameBytes);
        ...
    }
    
    // 自定义User反序序列化器关闭方法: 从控制台关闭的不会执行, 只有代码自动关闭的才会
    @Override
    public void close() {...}
}

// Kafka 自定义Consumer反序列化器测试类
public class DeserializerConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // Key使用默认的序列化器
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        // Value使用自定义的序列化器
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, UserDeserializer.class.getName());
        KafkaConsumer<String, User> consumer = new KafkaConsumer<>(properties);
        ...
    }
}

```

##### Producer 客户端分区器

- **默认消息分区规则**：org.apache.kafka.clients.producer.internals.DefaultPartitioner

  1. key 为空时，默认为随机值取模。
  2. key 不为空时，默认为使用 `Utils,murmur2` 计算 Hash 值后取模。

- **使用场景**：根据业务 ID Hash 到指定的 Partition，然后根据不同的业务，使用不同的 Consumer 消费。

  ![1634463959870](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634463959870.png)

```java
// 自定义Producer Partition
public class CustomPartitioner implements Partitioner {
    
    // 自定义Producer Partition计算Partition方法
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {...}
    
    // 自定义Producer Partition关闭方法
    @Override
    public void close() {...}
    
    // 自定义Producer Partition自定义方法
    @Override
    public void configure(Map<String, ?> map) {...}
}

// Kafka Producer测试类: 自定义Producer Partition
public class PartitionProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加自定义分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class.getName());
        KafkaProducer<String, User> producer = new KafkaProducer<>(properties);
        ...
    }
}

```

##### Consumer Group 消费者组

![1634464669407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634464669407.png)

- **Consumer Group 与 Consumer 的概念**：
  1. **Consumer Group 与 Consumer 是一对多的关系**：一个 Consumer Group 包含多个 Consumer，一个 Consumer 只能同时出现在一个 Consumer Group 中。
  2. **Partition 与 Consumer Group 是一对多的关系**：一个 Partition 可以被多个 Consumer Group 消费。
  3. **在同一个 Consumer Group 中，Partition 与 Consumer 是一对多的关系**：但同一个 Consumer Group 中，只允许一个 Partition 被 一个 Consumer 去消费，而一个 Consumer 又可以去消费多个 Partition。
     - 在不指定 `group.id` 时，Consumer 会使用默认的 `""` Consumer Group，所以，才会出现一个 Partition 只能被一个 Consumer 消费的规定。
- **应用场景**：得益于 Consumer 与 Consumer Group 的设计，Kafka 同时支持消息中间两种模型：

###### Piont to Piont | 点对点模式

- **概念**：点对点模式，是基于队列的，Producer 发送消息到队列，Consumer 从队列中消费消息，其中 Consumer 只能有一个。

- **Kafka 实现方式**：Consumer 都属于同一个 Consumer Group 时，此时一个 Partition 只能被一个 Consumer 消费，相当于点对点模式。

  ```java
  // Kafka Consumer1: 消费者+消费者组实现点对点模式
  public class ModuleConsumer1 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 同一个消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  // Kafka Consumer2: 消费者+消费者组实现点对点模式
  public class ModuleConsumer2 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 同一个消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  ```

###### Pub/Sub | 发布订阅模式

- **概念**：发布订阅模式，定义了如何向一个内容节点即主题 Topic，进行发布和订阅消息，Publisher 把消息发布到某个 Topic 上，Subscriber 从 Topic 中订阅消息，其中 Subscriber 可以有多个，类似于广播的模式。

- **Kafka 实现方式**：存在多个 Consumer Group 去消费 Partition，此时一个 Partition 可以被多个 Consumer Group 中的 Consumer 消费，相当于发布订阅模式。

  ```java
  // Kafka Consumer1: 消费者+消费者组实现发布订阅模式
  public class ModuleConsumer1 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 不同消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  // Kafka Consumer2: 消费者+消费者组实现发布订阅模式
  public class ModuleConsumer2 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 不同消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-2");
          ...
      } 
  }
  
  ```

##### Consumer subscribe/assign

```java
// Kafka Consumer: 测试消费者订阅参数
public class CoreConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        
        /*1) 对于Consume消息的订阅subscribe方法: 可以订阅一个或者多个topic*/
//        consumer.subscribe(Collections.singletonList(Const.TOPIC_CORE));
        /*2) 对于Consume消息的订阅subscribe方法: 也可以支持正则表达式方式的订阅, 初次如果先执行Consumer会导致一开始找不到Topic的问题, 所以第一次Producer产生的消息会错过*/
//        consumer.subscribe(Pattern.compile("topic-.*"));
        /*3) 对于assign方法: 可以指定订阅某个主题下的某一个或者多个partition*/
//        consumer.assign(Arrays.asList(new TopicPartition(Const.TOPIC_CORE, 0), new TopicPartition(Const.TOPIC_CORE, 2)));
        /*4) 对于assign方法: 还拉取拉取主题下的所有partition*/
        List<TopicPartition> topicPartitionList = new ArrayList<>();
        List<PartitionInfo> partitionInfoList = consumer.partitionsFor(Const.TOPIC_CORE);
        for (PartitionInfo partitionInfo : partitionInfoList) {
            topicPartitionList.add(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()));
        }
        consumer.assign(topicPartitionList);
    }
}

```

##### Consumer 手工提交

###### 开启手工提交

```java
// Kafka Consumer: 测试消费者手工提交方式
public class CommitConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        /* 自动提交*/
//        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
//        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);
        /* 手工提交*/
        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        ...
    }
}

```

###### 整体同步提交

```java
// ... 所有消息都消费完后
/*1) 整体提交: 同步提交(线程阻塞)*/
consumer.commitSync();

```

###### 整体异步提交

```java
// ... 所有消息都消费完后
/*2) 整体提交: 异步提交(线程非阻塞), 可回调可不回调, 这里会轮训回调函数*/
consumer.commitAsync(new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> map, Exception e) {
        if(e != null) {
            System.err.println("error处理");
        }
        System.err.println("整体异步提交成功: " + map);
    }
});
```

###### 按消息同步提交

```java
// ... 遍历、消费每条消息完成后
/*3) 按消息做提交动作: 同步提交, 可靠*/
consumer.commitSync(Collections.singletonMap(consumerRecord.partition(), new OffsetAndMetadata(consumerRecord.offset() + 1)));
```

###### 按消息异步提交

```java
// ... 遍历、消费每条消息完成后
/*4) 在Partition内一条消息做一次提交动作: 异步提交, 可靠且高性能*/
consumer.commitAsync(Collections.singletonMap(consumerRecord.partition(), new OffsetAndMetadata(consumerRecord.offset() + 1))), new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> map, Exception e) {
        if(e != null) {
            System.err.println("error处理");
        }
        System.err.println("在Partition内一条消息做一次异步提交成功: " + map);
    }
});
```

##### Consumer Reblance

```java
// Kafka Consumer: 测试同组消费者再均衡
public class RebalanceConsumer1 {
    public static void main(String[] args) {
        ...
        /*测试同组消费者再均衡*/
        consumer.subscribe(Collections.singletonList(Const.TOPIC_REBALANCE), new ConsumerRebalanceListener() {
            // 撤销/回收已分配的Partition
            @Override
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                System.err.println("Revoked Partitions:" + partitions);
            }

            // 重新分配Partition
            @Override
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                System.err.println("Assigned Partitions:" + partitions);
            }
        });
        ...
    }
}
```

##### Consumer 多线程消费

###### Consumer Group 多线程模型

![1634469825754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634469825754.png)

```java
// 一个Consumer一个线程，同属一个消费者组，消费不同的分区
public class ConsumerTest {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 通过消费者再均衡机制，保证5个分区被5个Consumer消费
        int coreSize = 5;
        ExecutorService executorService = Executors.newFixedThreadPool(coreSize);
        for(int i = 0; i < coreSize; i++){
            executorService.execute(new KafkaConsumerMt1(properties, Const.TOPIC_MT1));
        }
    }
}

// 一个Consumer一个线程，同属一个消费者组，消费不同的分区
public class KafkaConsumerMt1 implements Runnable{
    public KafkaConsumerMt1(Properties properties, String topic) {
        // 构建消费者
        this.consumerName = "KafkaConsumerMt1-" + counter.getAndIncrement();
        this.consumer = new KafkaConsumer<>(properties);

        /*查看同组消费者会再均衡情况*/
        this.consumer.subscribe(Arrays.asList(Const.TOPIC_MT1), new ConsumerRebalanceListener() {
            ...
        });
    }
    
    @Override
    public void run() {
        // 消费当前分区的消息
    }
}

```

###### Master-Worker 多线程模型

![1634470430311](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634470430311.png)

```java
private final KafkaConsumer<String, String> consumer;
private ExecutorService executors;
...

private int workerNum = ...;
executors = new ThreadPoolExecutor(
            workerNum, workerNum, 0L, TimeUnit.MILLISECONDS,
            new ArrayBlockingQueue<>(1000),
            new ThreadPoolExecutor.CallerRunsPolicy());
...

while (true) {
  // 单个Consumer拉取消息
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (final ConsumerRecord record : records) {
        // 多线程分发消息处理，可以包含调用Consumer进行手工提交
        executors.submit(new Worker(record));
    }
}

```

##### SpringBoot POM 依赖

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

```

##### SpringBoot 生产者配置

```properties
# Spring整合Kafka
spring.kafka.bootstrap-servers=192.168.1.111:9092
# Kafka Producer发送消息失败时的重试次数
spring.kafka.producer.retries=0
# 批量发送数据的配置
spring.kafka.producer.batch-size=16384
# 设置Kafka生产者内存缓冲区大小(32M)
spring.kafka.producer.buffer-memory=33554432
# Kafka消息序列化配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# Kafka可靠性投递配置: 是kafka生产端最重要的选项
# Acks = 0: 生产者在成功写入消息之前不会等待任何来自服务器的响应
# Acks = 1: 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应(推荐, 可以发挥Kafka真正的威力)
# Acks = -1: 表示分区leader必须等待消息被成功写入到所有的ISR副本(同步副本)中才认为producer请求成功. 这种方案提供最高的消息持久性保证, 但是理论上吞吐率也是最差的
spring.kafka.producer.acks=1

```

##### SpringBoot 生产者 | HelloWorld

```java
// SpringBoot生产者
@Component
@Slf4j
public class KafkaProducerServiceImpl implements KafkaProducerService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Override
    public void sendMessage(String topic, Object data) {
        ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, data);
        future.addCallback(new ListenableFutureCallback<SendResult<String, Object>>() {
            /**
             * 失败回调
             * @param throwable
             */
            @Override
            public void onFailure(Throwable throwable) {
                log.error("发送消息失败: " + throwable.getMessage());

            }

            /**
             * 成功回调
             * @param result
             */
            @Override
            public void onSuccess(SendResult<String, Object> result) {
                log.info("发送消息成功: " + result.toString());
            }
        });
    }
}

```

##### SpringBoot 消费者配置

```properties
# Spring整合Kafka
spring.kafka.bootstrap-servers=192.168.1.111:9092
# Consumer消息签收机制: 手工签收
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.listener.ack-mode=manual
# 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理:
# none: 抛出异常
# latest: (默认值)在偏移量无效的情况下, 消费者将从最新的记录开始读取数据(在消费者启动之后生成的记录)
# earliest: 在偏移量无效的情况下, 消费者将从起始位置读取分区的记录
spring.kafka.consumer.auto-offset-reset=earliest
# 序列化配置
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费并行数
spring.kafka.listener.concurrency=5

```

##### SpringBoot 消费者 | HelloWorld

```java
// SpringBoot消费者
@Component
@Slf4j
public class KafkaConsumer {
    @KafkaListener(groupId = "group02", topics = "topic02")
    public void onMessage(ConsumerRecord<String, Object> record, Acknowledgment acknowledgment, Consumer<?, ?> consumer){
        log.info("消费端接收消息: {}", record.value());
        acknowledgment.acknowledge();// 手工签收
    }
}

```

#### 高可用架构

1. Kafka 为分区引入了**多副本机制**，通过增加副本数量可以提升容灾能力，以及实现故障的自动转移，当集群中某个 Broker 失效时仍然能保证服务可用，副本处于不同的 Broker 中，当 Leader 副本出现故障时，Kafka 会从 Follower 副本中重新选举新的 Leader副本对外提供服务。
2. 同一分区的不同副本中保存的是相同的消息（不过同一时刻，副本之间可能并非完全一样），副本之间是**一主多从**的关系，Leader 副本负责处理读写请求，Follower 副本只负责与 Leader 副本的消息同步，很多时候Follower 副本中的消息相对 Leader 副本而言会有一定的滞后。
3. Kafka Consumer 也具备一定的容灾能力，Consumer 使用 Pull 模式从 Broker 拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时，可以根据之前保存的消费位置，重新拉取需要的消息进行消费，不会造成消息丢失。

##### 分区多副本机制

1. Kafka 的复制单位是 Partition，每个 Topic 都有一个或多个 Partition，每个 Partition 都有一个 Leader 和零个或多个 Follower，这些 Leader 和 Follower 都可以称为 Replica 副本。
2. 在创建 Topic 时，可以指定分区数和复制因子，复制因子通常为 3，相当于一个 Leader 和两个 Follower。
3. 分区上的所有读取和写入都会转到 Leader Replica，Follower 会定期向 Leader 发送获取请求以获取最新消息，而 Consumer 不会从 Follower 那里消费，Follower 只是为了**冗余和故障转移**而存在。
4. 当 Broker 死亡时，对于那些失去 Leader 的 Partition，剩余节点上的 Follower 可以被提升为 Leader，但要看是否存在与 Leader 完成同步的 Follower，如果没有，还要看具体的配置策略，以决定是否允许故障转移到未完成同步的 Replica。

![1634973615452](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634973615452.png)

##### Leader 选举机制

- **概念**：每个 Kafka 节点集群都与 Zookeeper 集群一起部署，Zookeeper 是一种分布式共识服务，允许分布式系统围绕某个给定状态达成共识，由于本身是分布式的，并且选择了一致性而不是可用性（CP），所以需要过半的 Zookeeper 节点同意后，才能接受读取和写入。

- **Zookeeper 的作用**：Zookeeper 负责存储 Kafka 集群相关状态，总是会更新 Kafka 集群状态的任何变化，以便在故障转移的情况下，Follower 可以顺利过渡到 Leader。

  1. 记录Topic 列表、Partition、配置、Leader Replica、首选 Leader Replica。
  2. **记录集群成员**：每个 Broker 都会向 Zookeeper 集群发送心跳，当 Zookeeper 在一段时间后未能收到心跳时，Zookeeper 会认为 Broker 已失败或不可用。
  3. **记录控制器节点**：包括控制器死机时的故障转移节点。

- **控制器节点**：Electing the controller node，Controller 节点是 Kafka Broker 之一，负责在节点加入或离开集群时选举 Leader，在 Zookeeper 向 Controller 发送有关集群成员和主题更改的通知后， Controller 会对这些更改采取相关的行动，其关系如下：

  1. **创建 Partition**：比如，当创建具有 10 个 Partition 以及复制因子为 3 的新 Topic 时，Controller 会为每个 Partition 选出一个 Leader，尝试在 Broker 之间以最佳方式分配 Leader。
  2. **ISR 变化**：然后，Leader 负责维护 ISR 集合，使用 `replica.lag.time.max.ms` 来确定ISR 成员的资格，当 ISR 发生变化时，Leader 会更新其变化到 ZK，然后由 ZK 通知 Controller 节点。
  3. **Leader 宕机**：而当 Leader 宕机时，ZK 会向 Controller 发送选举新 Leader 的通知，Controller 会向所有 Broker 发送一个命令，通知 Leader 即将发生变化。
  4. 总之，Zookeeper 总是会更新状态的任何变化，以便在故障转移的情况下，**让新 Leader 可以顺利过渡**。

  ![1634979553992](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634979553992.png)

##### Leader Rebalance 方法

1. 虽然 Kafka 有首选副本 Leader（preferred replica leaders）的概念，当 Kafka 创建 Topic 的 Partition 时，会尝试将每个 Partition 的Leader Replica 均匀分布在节点上，并将这些第一个 Leader 标记为首选副本 Leader，但随着时间的推移，由于服务器重启、服务器故障和网络分区等原因，Leader Replica 可能最终都会落在同一个节点上。

2. 为了解决这个问题，Kafka 提供了两个选项：

   - 主题配置  `auto.leader.rebalance.enable=true` ：允许 Controller 节点将领导权重新分配回首选副本 Leader，从而恢复均匀分布。
   - 另外，管理员也可以使用 `kafka-preferred-replica-election.sh` 脚本手动恢复均匀分布。

   ![1634974526584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634974526584.png)

##### ISR、OSR、AR 概念

- **目的**：Partition Replica 机制确实可以实现一定程度的可用性，但实际情况更加复杂，为了**平衡数据一致性与可用性**，Kafka 引入了 ISR 同步副本机制，允许在大多数副本失败时，仍然能够提供可用性，最大程度减少**死副本与慢副本**在延迟方面的影响。

  - 对比 RabbitMQ 镜像模式中，慢速镜像会引入更长的延迟，死镜像则会占用要检测的心跳时间。

- **概念**：

  - **ISR**：In Sync Replicas，分区中所有与 Leader 保持**一定程度同步**的副本集合，在 Kafka 中，消息会先发送到 Leader，然后 Follower 会以 `replica.fetch.wait.max.ms` 间隔发出 fetch 请求，默认为 500ms，从 Leader 中拉取消息进行同步，同步期间内 Follower 相对于 Leader 会存在**一定程度**的滞后，这种 “**一定程度**” 是指 Kafka **可以忍受**的滞后范围，可通过`replica.lag.time.max.ms` 进行配置。
    - **replica.lag.time.max.ms**：指 Follower 每次同步的最大延迟，默认为 10s，在使用 `acks=all` 时则代表每次客户端请求的最大延迟，如果 Follower 在该时间段内的某个时间点能够与 Leader 实现完全同步，则可以认为 Follower 是**一定程度同步**的，Leader 将允许该副本在 ISR 中。
      - 对比 RabbitMQ 的复制不是由镜像发起，而是由 Master 发起，再由 Master 把更改推送到其他镜像。
      - 如果发现死副本或者慢副本，则 Leader 会把它从 ISR 中剔除，而死副本与慢副本的判断与该值有关：
        - **死副本**：如果 Follower 在 `replica.lag.time.max.ms` 时间段内都没有发出 fetch 请求，则 Leader 会认为该 Follower 已经死了。
        - **慢副本**：如果 Follower fetch 时间超过了 `replica.lag.time.max.ms`，则 Leader 会认为该 Follower 是一个慢 Follower。
  - **OSR**：Out Sync Replicas，相对于 ISR 相反，与 Leader 同步滞后过度的副本组成 OSR 集合。
  - **AR**：Assigned Replicas，分区中所有的副本集合，即 AR = ISR + OSR，在正常情况下，所有 Follower 应该都与 Leader 保持**一定程度的同步**，即 AR = ISR，此时 OSR 为空。

  ![1635092377216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635092377216.png)

- **ISR与 OSR 的转换规则**：

  1. Leader 负责维护与跟踪 ISR 中所有 Follower 的滞后状态，当 Follower 落后太多或者失效时，Leader 会把它从 ISR 中剔除；而如果 OSR 中 Follower 追上了 Leader，则 Leader 会将它加入 ISR  集合。
  2. 只有在 ISR 中的副本才有资格被选举为 Leader，而在 OSR 中的副本则没有选举为 Leader 的资格，而这种规则可通过 `unclean.leader.election.enable` 进行配置。

- **局限**：当 ISR 缩小仅为 Leader Replica 时，如果 Leader 宕机，且没有任何同步副本时，则无法保证高可用。

  - **解决方案**：使用 `min.insync.replicas` 主题配置进行控制。

##### LEO、LW、HW、LSO 概念

- **概念**：ISR 与 HW、LEO 有紧密的关系，HW 可以辅助 Kafka 完成副本复制，而如果 LEO#Remote_LEO < Leader#LEO 的时间，不超过 `replica.lag.time.max.ms`，则可以认为该 Remote_LEO 对应的 Follower 处于**一定程度**上的同步，也就处于 ISR 集合中。

  - **LEO**：Log End Offset，日志结束偏移量，表示当前日志文件中下一条待写入消息的 offset。

    - 比如，LEO=15，表示当前日志记录的最后一条消息 offset=14，下一条写入的消息 offset=15。

  - **HW**：High Watermark，高水位标记，表示下一条能消费的 offset，Consumer 只能拉取到这个 offset 之前的消息。

    - 比如，HW=8，表示 Consumer 只能消费 offset < 8 的消息，而 offset=8 的消息对 Consumer 而言是不可见的。
    - 对于 ISR 而言，HW = MIN（LEO），即最小的 LEO 等于分区的 HW，小于等于 HW 的消息都可以被认为**已备份**。
    - **HW 作用**：用于标识哪些消息可以被消费，以及帮助 Kafka 完成副本同步。

    ![1634981204253](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634981204253.png)

  - LW：Low Watermark，低水位标记，标识 AR 集合中最小的 logStartOffset。

    - 副本的拉取请求 FetchRequest，有可能触发新建日志分段以及旧分段的清理，进而导致logStartoffset 的增加，从而促使 LW 的增长。

  - LSO：Last Stable Offset，具体与 Kafka 事务有关，对于未完成的事务而言，LSO 等于事务中的第一条消息所在的位置；对于已经完成的事务而言，LSO 与 HW 相等，因此，LSO <= HW <= LEO。

- **复制流程**：

  1. **初始状态**：初始时，Leader#HW、Leader#LEO、Leader#Remote LEO、Follower#HW、Follower#LEO 都等于 0。

     ![1635137338175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137338175.png)

  2. **Leader 消息持久化**：当 Leader 收到消息时，首先会在本地持久化，注意，这里的持久化，Kafka 只是将消息写入内存，而不是磁盘，此后，Leader#LEO=1。

     - 由于追求性能，Kafka 决定在消息进入内存后，就进行发送 ACK 确认给 Producer，然后每隔一段时间 `fsyncs` 内存中的消息到磁盘，通过**副本冗余**的机制，进行弥补消息未落盘的风险。
     - RabbitMQ 也会定期写入磁盘，但不同的是 RabbitMQ 只会在 Master 和所有镜像都将消息写入磁盘后，才发送 ACK 确认给 Producer。

     ![1635137428129](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137428129.png)

  3. **Follower 第一次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=0 给 Leader，Leader 接收到 Follower#LEO=0 后，则响应 offset=1 消息，以及 Leader#HW=0 给 Follower，此后，Follower#LEO=1，此时，Follower 和 Leader 的 LEO 都等于 1，但各自的 HW 还是为 0，需要在下一轮的拉取中才被更新。

     ![1635137604461](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137604461.png)

  4. **Follower 第二次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=1 给 Leader，Leader 接收到 Follower#LEO=1 后，更新 Leader#Remote LEO=1，然后如果判断到所有 Follower 都以该 offset 持久化完毕后，则会推进 Leader#HW，把 Leader#HW 更新为 1，响应下一条 offset 消息，以及 Leader#HW=1 给 Follower，以让它们更新 Follower#HW=1。

     ![1635137982950](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137982950.png)

  | 更新对象          | 更新时机                                                     |
  | ----------------- | ------------------------------------------------------------ |
  | Leader#LEO        | Leader "持久化" Producer 消息后，会更新其本地的 LEO 值       |
  | Follower#LEO      | Follower 从 Leader 拉取消息并“持久化”后，会更新其本地的 LEO 值 |
  | Leader#Remote LEO | Follower 把自己本地的 Follower#LEO 传给 Leader，告知从哪个位移开始拉取，Leader 会使用这个值更新 Leader#Remote LEO |
  | Follower#HW       | Follower 更新完 Follower#LEO 后，会比较该值与收到的 Leader#HW，取两者中的最小值更新 Follower#HW |
  | Leader#HW         | Leader 更新完 Leader#LEO 或者 Leader#Remote LEO 后，会取 Leader#LEO 与 所有的 Leader#Remote LEO 中的最小值更新 Leader#HW |

- **数据丢失场景**：前提为 `min.insync.replicas=1`，即 ISR 集合只有一个副本也可以提供服务。

  1. **初始状态**：初始时，Leader#HW、Leader#LEO、Leader#Remote LEO、Follower#HW、Follower#LEO 都等于 1。
  2. **Leader 消息持久化**：某个时刻，有一个使用了默认 `acks=1` 设置的 Producer 向 A 发送了一条消息，A 持久化完毕后，会通知 Producer 消息已投递成功。
  3. **Follower 第一次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=1 给 Leader，Leader 接收到 Follower#LEO=1 后，则响应 offset=2 消息，以及 Leader#HW=1 给 Follower，此后，Follower#LEO=2。
     - 此时，Follower 和 Leader 的 LEO 都等于 2，但各自的 HW 还是为 1，需要在下一轮的拉取中才被更新。
  4. **Follower 第二次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=2 给 Leader，Leader 接收到 Follower#LEO=2 后，更新 Leader#Remote LEO=2，然后如果判断到所有 Follower 都以该 offset 持久化完毕后，则会推进 Leader#HW，把 Leader#HW 更新为 2，响应下一条 offset 消息，以及 Leader#HW=2 给 Follower，以让它们更新 Follower#HW=2。
  5. **Follower B 重启并截断**：然而，由于 Follower#HW 的更新时间与 Leader#HW 的更新时间有错配，在 Leader#HW 更新后，响应时 Follower#HW 才会更新，如果响应时 Follower B 发生重启，那么在 B 重启完成后，B 会根据当前的 HW=0 进行日志截断，把 LEO 调整为 0，导致之前更新 LEO=2 的消息在 B 上发生了丢失。
     - **日志阶段的原因**：确保副本之间没有分歧，在选举时截断到新 Leader 的 HW，保证每个 Follower 日志的一致性。
  6. **Leader A 重启并截断**：B 截断后 LEO=2 后，发生定期同步 Leader A 的日志，但此时 Leader A 也发生了重启，需要进行故障转移，如果 B 还在 A 的 ISR 集合中，则 A 会把故障转移到 B，B 就是成为了新的 Leader。当 A 重启恢复后，成为了 B 的 Follower，由于 Follower#HW 不能高于 Leader#HW，所以 A 会对 LEO=2 进行日志截断，导致 offset=2 的消息永久丢失。

  ![1635044350580](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635044350580.png)

- **数据不一致场景**：

  1. 假设有 A、B 两个Broker，初始时 A 是 Leader，B 是 Follower，首先 A 接收到消息 m2，但 B 还没来得及复制，B 就宕机了，然后 A#HW+1=1，A#LEO=1，B#LEO=0，B#HW=0。
  2. 过了一会，A 宕机了，B 却恢复了，B 成为了 Leader，然后又接收了消息 m3，由于 A 仍未恢复，所以 B#HW+1=1，B#LEO=1。
  3. 再过了一会，A 也恢复了，由于 A#HW=B#HW，所以，A 并不会进行日志截断，导致此时出现了消息不一致的情况。

- **Leader Epoch 机制**：出现上面数据丢失、数据不一致场景的根本原因是，Follower#HW 需要在第二轮 Fetch 响应时才被更新，如果在这期间出现 Follower 重启，会导致之前的 LEO 处的日志被截断，对此 Kafka 0.11 引入了 Leader Epoch 机制来取代 HW 的辅助复制工作， 修复这种在 Leader 连续变更场景下的数据丢失和数据不一致问题。

  - **概念**：大致可以认为是 Leader 的版本号，由两部分数据组成。

    - **Epoch**：一个单调增加的版本号，每当 Leader 发生变更时，都会增加该版本号，小版本号的 Leader 会被认为是过期的 Leader，不再行使 Leader 的权力。
    - **Start Offset**：起始位移，Leader 在该 Epoch 上，首条写入消息的 offset。

  - **原理**：

    1. 使用该机制后，每个消息都会包含一个 4 字节的 Epoch 数字，每个 log 目录会创建 **Leader Epoch Sequence File** 来存储 Epoch 和 Start Offset。
    2. 当一个副本**成为 Leader** 后，它会首先在 Leader Epoch Sequence File 末尾添加一个新的记录，并把该记录刷到磁盘中，以后在该 Leader 下每条新的记录就被 Epoch 标记。
    3. 而当一个副本**成为 Follower** 时（比如发生了重启），则会执行以下工作：
       1. 从 Leader Epoch Sequence File 中恢复所有的 Epoch，因为可能宕机太久，这期间换了好几次leader，所以才要把这些 Epoch 消息都恢复过来。
       2. 向 Leader 发送一个 LeaderEpochRequest，其中该请求包含了 Follower#Leader Epoch Sequence File 中最新的 Epoch。
    4. Leader 接收到 LeaderEpochRequest 后，会向 Follower 响应对应 LeaderEpoch 的 LastOffset，这个 **LastOffset** 有两种可能：
       1. 一种是，比 LeaderEpochRequest#Epoch 大 1 的 offset。
       2. 另一种是，如果 LeaderEpochRequest#Epoch 与 Leader#Epoch 相等，则返回 Leader#LEO。
    5. 如果有任何 Follower#StartOffset **大于**返回的 Leader#LastOffset，那么 Follower 会重置自己的 Leader Epoch Sequence File 来和 Leader 保持一致，然后**截断本地日志**到 Leader#LastOffset 位置，再开始从 Leader 获取数据。
    6. 而 Follower 在从 Leader 获取数据时，如果 Follower 发现 Leader#Epoch 比 Follower#Epoch **还大**，那么它会添加这个 Epoch 和 StartOffset 到 Leader Epoch Sequence File 文件，并刷写到磁盘，然后继续获取数据。

  - **解决数据丢失问题**：

    1. 假设有 A、B 两个Broker，初始时 B 为 Leader，首先，Follower A 从 Leader B 中取到消息 m2，此时 A#，但是 A#HW 只在下一轮 RPC 才会更新，所以此时 A#HW 没变。
    2. 这时候 A 重启并恢复，采用 Leader Epoch 机制，A 并不会根据 HW 进行截取自己的日志到 HW，而是向 Leader B 发送 **LeaderEpochRequest**，由于 B#Epoch 等于 LeaderEpochRequest#Epoch，所以 B 返回给 A 的是 B#LEO=2，同时也并不存在 A#StartOffset 大于返回的 B#LEO=2，所以 A 不会对日志进行截取。
    3. 接着，当 B 宕机时，A 成了新的 Leader，则A 会在 Leader Epoch Sequence File 文件中添加新的Epoch 和 StartOffset。
    4. 当 B 恢复时，B 也会采取 Leader Epoch 机制，向 Leader A 发送 **LeaderEpochRequest**，由于 A#Epoch 等于 LeaderEpochRequest#Epoch，所以 A 返回给 B 的是 A#LEO=2，同时也并不存在 B#StartOffset 大于返回的 A#LEO=2，所以 B 也不会对日志进行截取，因此，不会发生消息 m2 永久丢失的情况，即使用 Leader Epoch 机制解决了数据丢失的问题。

    ![1635155757877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635155757877.png)

  - **解决数据不一致问题**：（忽略 m1）

    1. 假设有 A、B 两个Broker，初始时 A 是 Leader，B 是 Follower，首先 A 接收到消息 m2，但 B 还没来得及复制，B 就宕机了，然后 A#HW+1=1，A#LEO=1，B#LEO=0，B#HW=0。
    2. 过了一会，A 宕机了，B 却恢复了，B 成为了 Leader，然后又接收了消息 m3，由于 A 仍未恢复，所以 B#HW+1=1，B#LEO=1，同时又因为采用了 Leader Epoch 机制，B#Epoch+1=1。
    3. 再过了一会，A 也恢复了，由于采用了 Leader Epoch 机制，A 并不根据 A#HW=B#HW 进行日志截断，而是向 B 发送 A#Epoch=0 < B#Epoch，B 返回 B#LEO=1 以及 m3。
    4. A 接收到 m3 后，发现自己的 A#LEO=2 > B#LEO=1 了，同时发现 B#Epoch=1 > A#Epoch，则重置自己的 Leader Epoch Sequence File 来和 B 保持一致，即Epoch=1 和 StartOffset=1，并刷写到磁盘，然后截断本地日志到 B#LEO=1 的位置，从而保证了消息的数据一致性，因此使用 Leader Epoch 机制解决了数据不一致的问题。

    ![1635156753134](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635156753134.png)

##### 节点新加入集群场景

|                  | Kafka                                      | RabbitMQ                        |
| ---------------- | ------------------------------------------ | ------------------------------- |
| 是否会拒绝写入   | 新节点异步获取日志消息，Master 无阻塞      | Master 拒绝任何客户端的读写操作 |
| 是否会读入旧消息 | 是，异步获取，直到追赶上 Leader 被加入 ISR | 会扔掉旧数据                    |
| 适用场景         | 大队列                                     | 小队列                          |

##### 网络分区场景

与 RabbitMQ 相比，Kafka 具有更多的组件，所以当 Kafka 集群出现网络分区时，会出现更复杂的场景，每一种场景都会 Kafka 都会表现出不同的行为：

###### 1. Follower 看不到 Leader，但能看到 ZK

- **分区现象**：

  1. 网络分区把 Broker 3 与 Broker 1、2 分开，但没有和 ZK 分开。
  2. 此时，Broker 3 不再能够发送 fetch 请求，且在由于 `replica.lag.time.max.ms` 被剔出 ISR 集合，将不能参与消息提交。
  3. 而 ZK 在整个过程中，可以继续接收 Leader 的心跳，始终被认为处于活动的状态且运行良好。

- **分区解决后**：一旦分区被解决，Broker 3 将恢复 fetch 请求，在赶上 Leader 一定程度后，会重新加入 ISR 集合。

- **优点**：对比 RabbitMQ，Kafka 分区并不会出现脑裂或暂停节点的现象。

- **缺点**：减少了某个副本的冗余。 

  ![1635238242566](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238242566.png)

###### 2. Leader 看不到 Followers，但能看到 ZK

- **分区现象**：

  1. 网络分区把 Leader 与其他所有 Follower 分开，但仍然可以看到 ZK。
  2. 类似于场景 1 一样，由于 Leader 维护着 ISR 集合，看不到任何 Follower 会导致 ISR 缩小到只有 Leader。
  3. 而 ZK 在整个过程中，可以继续接收 Leader 的心跳，始终被认为处于活动状态且运行良好。

- **分区解决后**：一旦分区被解决，所有 Follower 将恢复与 Leader 的同步，它们在赶上 Leader 一定程度后，会重新加入 ISR 集合。

- **优点**：同样没有裂脑或者暂停节点的发生。

  **缺点**：在分区解决之前，新写入的消息将会丢失所有的副本冗余，当 Leader 宕机，Kafka 将会**停止服务**。

  ![1635238385327](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238385327.png)

###### 3. Follower 能看到 Leader，但看不到 ZK

- **分区现象**：
  1. Follower 与 ZK 分开，但没有和 Leader 分开。
  2. 此时，Follower 可以继续发出 fetch 请求，并维持 ISR 成员的状态。
  3. 而 ZK 将不再接收 Follower 的心跳，会认为它已经死了，但由于它只是一个 Follower，因此不会受到任何影响。
- **分区解决后**：一旦分区被解决，该 Follower 将重新向 ZK 发送心跳包，ZK 则认为它重新上线。
- **优点**：同样没有裂脑或者暂停节点的发生，且没有副本冗余的丢失。

![1635238848539](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238848539.png)

###### 4. Leader 能看到 Followers，但看不到 Zk

- **分区现象**：
  1. Leader 与 ZK 分开，但没有与 Followers 分开。
  2. 一段时间后，ZK 会该 Leader 标记为已死，并且通知 Controller 选举一个 Follower 成为新 Leader。
  3. 然而，旧 Leader 还继续认为它是 Leader，能够在短时间内继续接受 `ack=1` 的写入，而 Follower 则不再向该旧 Leader 发送 fetch 请求，旧 Leader 会认为 Followers 都发生死亡，并尝试把 ISR 缩小到旧 Leader 自身，但它又无法这么做，因为 ISR 的任何变化都会先给 ZK，而它没有与 ZK 相连，将停止接受写入。
  4. 而 `acks=all` 的消息 Producer 将不会得到 ACK 确认，因为旧 ISR 包括所有副本，Followers 不会返回消息确认给旧 Leader，旧 Leader 也就不会返回 ACK 给 Producer，而且 旧 Leader 在尝试把 Followers 都从 ISR 中删除时，由于没有与 ZK 相连，将导致它删除失败，因此会一直拒绝写入。
  5. 而客户端每 60 秒会更新一次最新的元数据，然后他们将被告知 Leader 发生变更，并开始发送消息给新 Leader。
- **分区解决后**：一旦网络分区得到解决，旧 Leader 将知道它自己不再是 Leader，然后会把自己的日志截断到新 Leader#HW 处，然后开始向新 Leader 发送 fetch 请求。
- **优点**：同样没有裂脑或者暂停节点的发生，且没有副本冗余的丢失。
- **缺点**：自网络分区开始以来，对旧 Leader 所做的 `ack=1` 确认写入都将丢失。
  1. 集群会在短时间内处于裂脑的状态，但前提是 `acks=1` 并且 `min.insync.replicas=1` ，当网络分区被解决时，裂脑会自动结束，旧 Leader 将会意识到它不再是 Leader，或者所有客户端都意识到 Leader 已经改变，并开始发送消息给新 Leader，但无论哪种方式，都会在短时间内发生一些消息丢失，但仅限于 `acks=1` 。
  2. 这种情况还有一个变体，就在网络分区之前，Follower 落后，Leader 将 ISR 缩小到自己，然后发生网络分区隔离了 Leader，同时还选举了一个新 Leader，但旧 Leader 仍继续接受写入，甚至 `acks=all` 也因为 ISR 只有旧 Leader 自己，当网络分区解决后，这些写入将发生丢失。
  3. 因此，为了避免这些情况，唯一的解决方案是使用 `min.insync.replicas = 半数节点`。

![1635239217734](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635239217734.png)

###### 5. Follower 完全分区

- **分区现象**： 
  1. Follower 与 Leader 和 ZK 完全隔离。
  2. Follower 只会被简单地从 ISR 中剔除。
- **分区解决后**：一旦网络分区得到解决，它将恢复 fetch 请求，在赶上 Leader 一定程度后，会重新加入 ISR 集合。
- **优点**：同样没有裂脑或者暂停节点的发生。
- **缺点**：减少了某个副本的冗余。

![1635240105377](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635240105377.png)

###### 6. Leader 完全分区

- **分区现象**：
  1. Leader 与 Followers、Controller 和 ZK 完全隔离。
  2. Leader 能够在短时间内继续接受 `ack=1` 的写入，但将不能接受 Followers#fetch 请求，此时会认为 Followers 都发生死亡，并尝试把 ISR 缩小到自身，但它又无法这么做，因为 ISR 的任何变化都会先给 ZK，而它没有与 ZK 相连，将停止接受写入。
  3. 而 `acks=all` 的消息 Producer 将不会得到 ACK 确认，因为旧 ISR 包括所有副本，Followers 不会返回消息确认给旧 Leader，旧 Leader 也就不会返回 ACK 给 Producer，而且 旧 Leader 在尝试把 Followers 都从 ISR 中删除时，由于没有与 ZK 相连，将导致它删除失败，因此会一直拒绝写入。
  4. 同时，一段时间后，ZK 会该 Leader 标记为已死，并且通知 Controller 选举一个 Follower 成为新 Leader。
  5. 而客户端每 60 秒会更新一次最新的元数据，然后他们将被告知 Leader 发生变更，并开始发送消息给新 Leader。
- **分区解决后**：一旦网络分区被解决，旧 Leader 将通过 ZK 发现它不再是 Leader，然后它将把日志截断到新 Leader#HW，并作为 Follower 开始发送 fetch 请求。
- **缺点**：自网络分区开始以来，对旧 Leader 所做的 `ack=1` 确认写入都将丢失。
  1. 集群会在短时间内处于裂脑的状态，但前提是 `acks=1` 并且 `min.insync.replicas=1` ，当网络分区被解决时，裂脑会自动结束，旧 Leader 将会意识到它不再是 Leader，或者所有客户端都意识到 Leader 已经改变，并开始发送消息给新 Leader，但无论哪种方式，都会在短时间内发生一些消息丢失，但仅限于 `acks=1` 。
  2. 这种情况还有一个变体，就在网络分区之前，Follower 落后，Leader 将 ISR 缩小到自己，然后发生网络分区隔离了 Leader，同时还选举了一个新 Leader，但旧 Leader 仍继续接受写入，甚至 `acks=all` 也因为 ISR 只有旧 Leader 自己，当网络分区解决后，这些写入将发生丢失。
  3. 因此，为了避免这些情况，唯一的解决方案是使用 `min.insync.replicas = 半数节点`。

![1635240417911](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635240417911.png)

###### 7. Controller 看不到 Broker

- **分区现象**：
  1. Controller 与 Broker 节点隔离，会导致 Controller 将无法向该 Broker 节点传达任何领导权的变更。
  2. 在最坏的情况下，可能会发生像场景 6 那样短期的裂脑，即 Controller 无法告诉旧 Leader 它已经不是 Leader了，从而使得它与新 Leader 共存，且在短时间内，旧 Leader 仍能接受 `ack=1` 的消息写入。
- **分区解决后**：一旦分区被解决，Controller 将恢复与该 Broker 的通信，该 Broker 也会意识到它不再是 Leader，然后它将把日志截断到新 Leader#HW，并作为 Follower 开始发送 fetch 请求。

###### 8. Controller 看不到 ZK

- **分区现象**：
  1. Controller 与 ZK 隔离。
  2. 由于 Controller 缺少心跳，ZK 会将 broker 标记为已死，并且选举一个新的 Broker 节点作为 Controller。
  3. 旧 Controller 可能会继续认为它自己是 Controller，但由于它无法接收来自 ZK 的任何通知，因此并不会执行任何操作。
- **分区解决后**：一旦分区被解决，它将会意识到它不再是 Controller，而只是一个普通的 Kafka 节点，因此不会造成什么影响。

###### 网络分区场景总结

1. 可以看到，Follower 发生网络分区，不会导致消息丢失，只是减少了 Follow 的副本冗余。
2. Leader 与 Follower 隔离，会丢失所有的副本冗余，当 Leader 还发生宕机，有较小概率发生不可用。
3. Leader 与 ZK 隔离，会发生短暂的脑裂，导致自网络分区开始以来，对旧 Leader 写入 `ack=1` 的消息都会丢失，解决方案为 `ack=all` ，而使用 `min.insync.replicas=半数节点` 可以提供额外的一致性保证，保证脑裂期间不会发生消息丢失，但会失去部分的可用性。
4. Controller 与 Broker 隔离，会导致 Broker 感知不到 Leader 的变化，当隔离的 Broker 刚好为 Leader 时，还可能会发生同 3 一样的短暂脑裂现象，而 Controller 与 ZK 隔离，则不会造成任何影响。

#### 常见问题解决

##### 如何保证数据不丢失？

参考《RabbitMQ - 如何保证数据不丢失》，数据丢失的场景有：生产端丢数据、MQ 丢数据、消费端丢数据：

- **解决方案**：
  1. **生产端丢数据**：生产消息可以通过 Comfirm 机制解决，消息状态打标 + 消息落库 + `ack=all` + 定时重发（`retries` + `retry.backoff.msretries`） + 人工介入/失败补偿 。
  2. **MQ 丢数据**：Broker 使用 ISR 副本机制保证高可用。
  3. **消费端丢数据**：可以关闭自动提交offset功能 `enable.auto.commit=false`，在消费完成后才提交offset。

##### 如何防止重复消费？

参考《RabbitMQ - 如何防止重复消费》。

##### 一致性与可用性保障？

详情见《Kafka - 高可用架构》

`acks=all` 是最安全的选项，但会引入额外的延迟。事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的**最终一致性**以及时刻都接受读取和写入的**高可用性**，因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个**范围的两端**。对此，Kafka 提供了调整参数，以让一致性和可用性适合需要的场景。

###### 集群可调整参数

1. **消息 Confirm 机制**：Producer `ack=all`，以及 Consumer `enable.auto.commit=false`。
2. **分区多副本机制**：在创建 Topic 时，可以指定分区数和复制因子，复制因子通常为 3，相当于一个 Leader 和两个 Follower。
   - 其中，复制因子为 5 且 `min.insync.replicas` 为 3 发生消息丢失，是一件非常罕见的事件。
3. **故障转移策略**：`unclean.leader.election.enable`：
   - **true**：允许故障转移到未完成同步的 Follower。
   - **false**：默认为false，禁止故障转移到未完成同步的 Follower，只允许转移到已经完成同步的 Follower，如果没有任何同步副本，则故障转移时会拒绝客户端所有的读取和写入操作。
4. **ISR 同步策略**：主题配置 `min.insync.replicas`，ISR 集合中最少的副本数量，如果客户端写入消息时，ISR 中的副本数量低于该数量，那么 Broker 以 NotEnoughReplicas 的错误响应给客户端，以拒绝写入。
5. **脑裂处理策略**：`ack=all` + `min.insync.replicas=半数节点` 可以提供最高级别的一致性。
6. **确保客户端连接**：在 Producer 和 Consumer `bootstrap.servers` 配置中，指定多个可以连接的 Broker，这样，即使其中一个 Broker 节点出现故障，客户端也有它知道的多个 Broker 节点，用于打开与 Broker 的连接，此时客户端可以询问出哪个节点，才是托管其想要读/写的分区 Leader。

###### 对比 RabbitMQ

|                      | Kafka                                                        | RabbitMQ                                                     |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 实现持久性与高可用性 | 主从复制                                                     | 主从复制                                                     |
| 持久性与可用性问题   | 异步非阻塞复制，不存在持久性与可用性问题，但复制需要占用大量的网络带宽 | 大队列持久性问题，要么减少冗余增加数据丢失风险，要么接受长时间不可用，可保持小队列，舍弃部分可用性，通过连接重试来处理，以保证冗余，减少数据丢失风险 |
| 集群同步发生故障     | 消息不落盘，效率高，但可能会消息丢失，通过副本冗余机制来减少风险 | 消息落盘，能够发挥出持久化优势，但增加了额外的延迟           |
| 总结                 | 处理大量消息、易扩展、一致性可调                             | 无大队列（大队列可拆成多个小队列）、用法灵活                 |

##### 如何实现 Consumer Rebalance？

Consumer Rebalance，本质上是一种协议，规定了一个 Consumer Group 下，所有 Consumer 如何达成一致，来分配订阅 Topic 下的每个 Partition。

###### 触发条件

Consumer Rebalance 的触发条件有3个：

- **组成员数量发生变化**：比如有新的 Consumer 加入或者离开 Consumer Group。
- **订阅的 Topic 数量发生变化**。
- **订阅 Topic 下的 Partition 数量发生变化**。

###### 对集群的影响

Consumer Rebalance 发生时，Consumer Group 下所有的 Consumer 都会协调在一起，共同参与，以让 Kafka 能够尽量达到最公平的分配，但是，这些 Consumer 都会停止工作，来等待 Consumer Rebalance 过程的完成，如果集群内节点较多，比如上百个，那该过程可能会非常耗时，导致数分钟到数小时，使得 kafka 基本处于不可用的状态，对 TPS 影响极大。

- 经过几轮本地测试，可以发现，每次 Consumer Rebalance 所消耗的时间，大概在 **80ms~100ms** 内，平均耗时在 **87ms** 左右。

###### Group Coordinator

1. Consumer Group Coordinator 是一个服务，每个 Broker 启动时都会启动一个该服务，用于存储 Consumer Group 相关的 Meta 信息，并将对应的 Partition#Offset 信息，记录到内置的 `Topic(__consumer_offsets) ` 中。

2. 而在 0.9 版本之前，Partition#Offset 是基于 ZK# `(consumers/{group}/offsets/{topic}/{partition})` 进行存储的，但由于 ZK 并不适合频繁的写操作，所以，在 0.9 版本之后，通过内置 Topic 的方式，来记录对应 Partition#Offset。

3. 每个 Consumer Group 都会选择一个 Coordinator，来完成组内各 Partition#Offset 信息，选择方式如下：

   1. 计算 Consumer Group 对应在 `Topic(__consumer_offsets)#Partition`。

      ```java
      // Topic(__consumer_offsets)#Partitio计算规则：hash(消费者组的ID) mod 50
      // groupMetadataTopicPartitionCount对应offsets.topic.num.partitions参数值，默认值是50个分区
      partition-Id(__consumer_offsets) = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)
      ```

   2. 根据该 Partition 寻找对应的 Leader Replica#Group Coordinator，作为该 Consumer Group#Coordinator。

###### 执行过程

Rebalance 过程分为两步：**Join 和 Sync**。

1. **Join**：

   1. 加入组，所有 Consumer 会向 Coordinator 发送 `JoinGroup` 请求，请求加入 Consumer Group。
   2. 一旦所有成员都发送了 `JoinGroup` 请求，Coordinator 会从中选择一个 Consumer 来担任 Leader 的角色，并把组成员信息以及订阅信息发给 Leader，由 Leader 来负责制定消费分配方案。
      - 注意，这里的 Leader 和 Coordinator 不是同一个概念，Leader 属于 Consumer，Coordinator 属于 Broker 中的一个服务。

   ![1635483089251](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483089251.png)

2. **Sync**：

   1. Leader 开始分配消费方案，即哪个 Consumer 负责消费哪些 Topic#Partition。
   2. 一旦完成分配，Leader 会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
      - Consumer 的分区分配策略，见《日志分区原理 - 分区分配原理》。
   3. 而非 Leader 也会发 `SyncGroup` 请求，只是内容为空。
   4. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给各个Consumer。
   5. 这样，Consumer Group 内的所有 Consumer 成员，就都知道自己应该消费哪些 Partition 了。

   ![1635483199299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483199299.png)

###### 场景分析

- **新成员加入组**：

  1. 成员 M1 原本就处于 Consumer Group#generation2，成员 M2 新加入 Consumer Group 中。
  2. Coordinator 收到 M2 的 `JoinGroup` 请求后，然后会告诉 M1 重新加入 Consumer Group#generation2 处于 Rebalance 中，需要重新加入。
  3. M1 向 Coordinator 发送 `JoinGroup` 请求。
  4. Coordinator 收到完 Consumer M1 和 M2 的 `JoinGroup` 请求后，则选择 M2 来担任 Leader 角色，并把组成员信息以及订阅信息发给 M2，由 M2 来负责制定消费分配方案，同时其他响应 `JoinGroup` 请求，告诉他们当前处于 Consumer Group#generation3 中的 Follower 角色。
  5. M2 制定方案完毕后，则会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
  6. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给 M1 和 M2，完成一次 Consumer Rebalance 操作。

  ![1635483703977](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483703977.png)

- **组成员主动离开**：

  1. 成员 M1 和 M2 原本就处于 Consumer Group#generation2，成员 M1 请求主动离开。
  2. Coordinator 收到 M1 的 `LeaveGroup` 请求后，则会通过 `HeaderBeat` 响应 M1 同意结果，然后要求 M2 重新加入 Consumer Group。
  3. M2 向 Coordinator 发送 `JoinGroup` 请求。
  4. Coordinator 收到完 Consumer M2 的 `JoinGroup` 请求后，则选择 M2 来担任 Leader 角色，并把组成员信息以及订阅信息发给 M2，由 M2 来负责制定消费分配方案，同时其他响应 `JoinGroup` 请求，告诉他们当前处于 Consumer Group#generation3 中的 Follower 角色。
  5. M2 制定方案完毕后，则会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
  6. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给 M2，完成一次 Consumer Rebalance 操作。

  ![1635484277208](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635484277208.png)

- **组成员崩溃**：

  1. 与组成员主动离开类似，但不同的是，在崩溃时，组成员并不会主动地告知Coordinator 离开组这件事。
  2. 而是 Coordinator 在一个完整的 `session.timeout.ms` 心跳周期后，才检测出组成员的这种崩溃，势必会造成消费滞后，因为期间 M1 停止了消费，而且 Rebalance 所有 Consumer 都会停止消费。
  3. 因此，可以说，主动离开组是主动发起 Consumer Rebalance，而组员崩溃则是被动发起 Consumer Rebalance。

  ![1635484185247](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635484185247.png)

###### 如何避免不必要的 Consumer Rebalance？

- **思路**：

  1. 要避免 Consumer Rebalance，还是要从触发条件入手：
     - **组成员数量发生变化**：比如有新的 Consumer 加入或者离开 Consumer Group。
     - **订阅的 Topic 数量发生变化**。
     - **订阅 Topic 下的 Partition 数量发生变化**。
  2. 对于后两个触发条件，可以人为地去避免，比如控制好 Topic 和 Partition 的数量。
  3. 所以，最常见的原因还是 Consumer Group 中的组成员发生了变化。
     1. Consumer 正常的添加、删除导致的 Rebalance，是无法避免的。
     2. 但是，在某些情况下是可以尽力避免的，比如，Consumer 可能会被 Coordinator 错误地认为已死亡，从而被错误地踢出 Group，导致多余的 Rebalance 发生。

- **调整参数**：

  - `session.timeout.ms`：Coordinator 判定 Consumer 已死亡的超时时间，可在 Consumer 端进行参数配置，默认为 10s。
    1. 当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会以 `heartbeat.interval.ms` 周期地向 Coordinator 发送心跳请求，表明它还存活着。
    2. 但如果某个 Consumer 实例在超过该超时时间，仍未能及时地发送这些心跳请求，那么 Coordinator 就会认为该 Consumer 已经死亡，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。
  - `heartbeat.interval.ms`：Consumer 心跳报发送周期，用于控制发送心跳请求频率，可在 Consumer 端进行参数配置。
    1. 这个值设置得越小，Consumer 发送心跳请求的频率就越高。
    2. 频率高的好处就是，能够更加 Consumer 快速地知晓当前是否开启 Rebalance，因为目前 Coordinator 通知各个 Consumer 开启 Rebalance 的方法，就是将 `REBALANCE_NEEDED` 标志封装进Heartbeat 心跳包的响应体中。
    3. 而坏处就是，会额外消耗带宽资源。
  - `max.poll.interval.ms`：Consumer#pull 方法之间的最大时间间隔，可在 Consumer 端进行参数配置，默认值为 5min，用于控制 Consumer 的实际消费能力。
    1. 如果 Consumer 在该时间间隔内，无法消费完上一次 pull 方法返回的消息，那么该 Consumer 会主动发起离开组的请求，然后 Coordinator 就会开启新一轮的 Rebalance。

- **优化结论**：

  1. **增大超时时间，减少心跳周期**：以减少 Consumer 未能及时发送，Coordinator 未能及时收到心跳，从而 导致 Consumer 被踢出 Group 的非必要 Rebalance 情况发生。

     ```shell
     # 加大超时时间，设置成6s主要是为了，让Coordinator能够更快地定位已经挂掉的Consumer，早日把它们踢出Group
     session.timout.ms=6s
     # 减少心跳周期，加大心跳频率，在Consumer实例在被判定为死亡之前，保证能够发送至少3轮的心跳请求，即session.timeout.ms >= 3*heartbeat.interval.ms
     heartbeat.interval.ms=2s
     
     ```

  2. 增大可消费的时间：以减少某些 Consumer 消费时间过长，超出两次 pull 消息间隔，从而导致 Coordinator 进行非必要的 Rebalance 的情况发生。

     ```shell
     # 增长可消费的时间，总之，要为业务处理逻辑留下充足的时间，这样Consumer就不会因为处理这些消息的时间太长而引发非必要的Rebalance
     max.poll.interval.ms=某个合理值
     
     ```

##### 如何保证顺序消费？

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个分区**，目的是防止消费者争抢消息导致乱序消费的情况发生。

  1. 与 RabbitMQ 保证单消费者消费单个队列不同，由于 Kafka#Consumer Group 机制，天然就能保证单个消费者消费，然后 Kafka 针对的不是队列，而是一个 Partition。

- **解决方案**：参考《RabbitMQ - 如何保证顺序消费》。

  - **多分区、多消费者**：类似于 RabbitMQ#一致性哈希交换机 `x-consistent-hash Exchange`，通过业务ID进行 hash，保证同一个业务 ID 的消息只落在同一个 Partition 中，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
    - **实现方法**：自定义 Producer 分区器与分区规则。

  - **单分区、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单分区、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单分区、单消费者**：始终保证使用 一个 Partition + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

    - **实现方法**：

      ```shell
      # topic_x 只创建一个分区，一个副本
      kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x 
                                      --partitions 1 --replication-factor 1
      
      ```

##### 如何优化消息积压？

###### 影响后果

1. 消息积压越多，Consumer 寻址的性能就越慢，最差的情况则会导致整个 kafka 对外提供服务的性能很差，从而影响其他服务的访问速度，最后造成雪崩效应。
2. 而且还可能发生磁盘被堆满，导致 Producer 消息无法写入磁盘，一直报错，然后引发连锁反应，同样会造成雪崩效应。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Partition、增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **Consumer 批量拉取消息与批量提交 offset**：这里要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   1. 对于每条消息分别拉取的情况，Consumer 需要多次从 Broker 上拉取消息，而对于每条消息分别被提交的情况，Consumer 需要多次发起提交 offset 传输给 Broker，这样的多次 I/O，浪费了服务器性能与增加了带宽的占用。
   2. 通过批量拉取消息+批量提交 offset 的方式，减少多次发起 Broker 请求，可以减少很多 I/O 浪费和带宽占用。
   3. 不过，如果 Consumer 在处理某条消息时失败了，而业务上又要求不能丢失任何消息，此时就不能对所有的消息进行批量提交，因为消费失败的需要重新消费。
      - **解决方案**：可以跟踪所有消息的处理结果，如果全部成功，则使用批量提交 offset；如果部分成功，则有两个选择：1）如果不需要顺序消费，则可以退化为每个消息分多次发送提交 offset；2）如果需要顺序消费，则本次消费失败之后的消息全部重新消费，保证重新消费时消息顺序保持一致。
   4. **小结**：Consumer 批量提交的前提是，设置了批量拉取消息，否则将会失去意义。

   ```java
   // Consumer参数：批量拉取消息
   // 一次拉取的最小数据量，默认为 1 B
   // fetch.min.bytes
   // 一次拉取的最大数据量，默认为 50 MB
   // fetch.max.bytes
   // 一次拉取一个 Partition 的最大数据量，默认为 1 MB
   // max.partition.fetch.bytes
   // 每次拉取的消息最大条数
   // max.poll.records
   
   /* Consumer开启手工提交*/
   properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
   /*1) 整体提交: 同步提交(线程阻塞)*/
   // consumer.commitSync();
   /*2) 或者整体提交: 异步提交(线程非阻塞), 可回调可不回调, 这里会轮训回调函数*/
   consumer.commitAsync(new OffsetCommitCallback() {...}
   ```

2. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手，代码实现见《Kafka API - Consumer 多线程消费》。

   1. 多线程并发消费，不需要建立多个 Kafka 客户端连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

3. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个分区，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 先单个 Consumer 消费，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  2. 如果消费速度不满足要求，则提高 `max.poll.records`，**1 次接收多条消息**，甚至批量提交 offset，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，甚至批量提交 offset，但要注意并发冲突和顺序消费的问题。
  4. 如果消费速度还是不满足要求，则**多个消费者并发消费**，甚至批量提交 offset，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步，以及批量 ACK 遇到消费失败时进行全部 NACK。

###### 【线上】如何紧急处理消息积压？

参考《RabbitMQ - 【线上】如何紧急处理消息积压》。

对于 Kafka 而言，由于 Partition 机制与 RabbitMQ Queue 并不相同，所以除了参考，还有以下的处理方式：

1. **提高 Partition 分区数**：分区数足够，可以提高消费的并行度，并且也决定者同组 Consumer 的最大数量。
2. **临时 Topic + Consumer 进行消息转储消费**：
   1. 如果消息积压的 Topic 在建立时，就没有建立足够多的 Partition，导致同一个 Consumer Group 中的 Consumer#size 已经增加到 Partition#size，却仍有大量的消息积压。
   2. 此时，可以建立一个临时的 Topic、设置足够多的 Partition 以及上线一批足够多的 Consumer ，然后把所有原 Topic 的 Consumer 拉取到的消息统统转储到临时 Topic 上，供新上线那批 Consumer 去消费。
   3. 这样，消费速度上去了，消息积压的问题才有机会解决掉，解决掉后再视实际情况，来决定是否恢复原状。

### 2.0. 什么是系统可用性？

- **概念**：系统可用性，Availability，是信息工业界用来衡量一个信息系统提供**持续服务**的能力，表示在给定时间区间内，系统或者系统某一能力，在特定环境下能够正常工作的**概率**。
- **公式**：系统可用性 = （平均故障间隔时间 MTBF）/ （平均故障间隔时间 MTBF  + 平均故障修复时间 MTTR）
- **应用**：通常，业界习惯用 N 个 9 来表征系统可用性，表示系统可以**正常使用时间与 1 年总时间之比**，比如：
  1. **99.9%**：代表 3 个 9 的可用性，意味着全年不可用时间在 `8.76h` 以内，表示该系统在连续运行 1 年时间里，最多可能的业务中断时间是 `8.76h` 。
  2. **99.99%**：代表 4 个 9 的可用性，意味着全年不可用时间在 `52.6min` 以内，表示该系统在连续运行 1 年时间里，最多可能的业务中断时间是 `52.6min` 。
  3. **99.999%**：代表 5 个 9 的可用性，意味着全年不可用时间在 `5.26min` 以内，缺少故障**自动恢复机制**的系统是很难达到 5 个 9 高可用性的。
  4. 而对于 1、2、6 个 9，它们的不可用时长分别为 36.5D、3.65D、31s，均不符合实际情况（时间太久或者实现成本太高），所以用于表征系统可用性并不合适。

### 2.1. 详细介绍RocketMQ？

#### 概念

RocketMQ 是一款分布式、队列模型的消息中间件，由阿里巴巴自主研发的一款适用于高并发、高可靠性、海量数据场景的消息中间件，其消息路由、存储、集群规划上都参考借鉴了 Kafka 的设计思路，并结合双十一场景进行合理的扩展和丰富了API。

- **通用用途**：异步处理、系统解耦、削峰填谷、蓄流压测。
- **特色用途**：
  1. **支持事务消息**：消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 都不支持。
  2. **支持延迟消息**：RabbitMQ 支持，Kafka 不支持。
  3. **支持 Consumer#tag 过滤**：以减少不必要的网络传输，RabbitMQ 和 Kafka 都不支持。
  4. **支持重复消费**：RabbitMQ 不支持，Kafka 支持。

| 专业术语       | 释义                                                         |
| -------------- | ------------------------------------------------------------ |
| Broker         | 消息核心服务，作为中转角色，用于消息存储与生产消费的转发，通过 Name Server 暴露统一的集群入口给客户端 |
| Name Server    | Name Server 充当路由信息提供者，供生产者与消费者客户端查找 topic，以找到相应的 Broker 列表 |
| Producer       | 消息生产者，负责生产消息，一般由业务系统负责产生消息，完全无状态，可集群部署 |
| Producer Group | 生产者集合，一般用于发送一类消息，防止原始生产者在事务后崩溃 |
| Consumer       | 消息消费者，负责消费消息，一般是后台系统负责异步消费         |
| Consumer Group | 消费者集合，一般用于接受一类消息进行消费，实现消费的负载平衡与容错，消费者组中的消费者必须具有完全相同的 topic 订阅 |
| Push Consumer  | Consumer 的一种，需要向 Broker 注册监听，被动接受推送过来的消息 |
| Pull Consumer  | Consumer 的一种，需要主动请求 Broker 拉取消息                |
| Topic          | 主题，是生产者传递消息和消费者拉取消息的类别，一个主题可能有零个、一个或多个生产者向它发送消息，生产者也可以发送不同主题的消息；一个主题可能被零个、一个或多个消费者组订阅，消费者组也可以订阅一个或多个主题，只要该组的实例保持订阅一致即可 |
| Message        | 消息，是要传递的信息，一条消息必须有一个主题，一条消息也可能有一个可选的标签和额外的键值对 |
| Message Queue  | 消息队列，是逻辑上存储消息的队列，物理上存储消息的是 CommitLog，其中 topic 被划分为一个或多个 tag，每个 tag 对应着一个消息队列 |
| Tag            | 标签，也可以说是子主题，为用户提供了额外的灵活性，使用标签有助于保持代码的整洁和连贯，也方便消息的查询 |

#### 原理

##### 技术架构原理

![1635853277989](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635853277989.png)

###### NameServer 集群

1. 轻量级的配置中心，是一个几乎无状态的节点，只做集群元数据存储和心跳工作。
2. 可集群部署，节点之间没有任何信息同步，不需要保证节点间数据的强一致性。

###### Broker

1. 消息核心服务，作为中转角色，用于消息存储与生产消费的转发，通过 NameServer 暴露统一的集群入口给客户端。
2. Broker 分为 Master 和 Slave，一个Master 可以对应多个 Slave，一个 Slave 只对应一个 Master，可通过指定相同的 BrokerName + 不同的BrokerId 来定义主从关系，即 BrokerId 为 0 的表示 Master 节点，非 0 的表示 Slave 节点。而 Master 也可以多节点部署，从而构成多主多从的集群架构。
3. 每个 Broker 与 Name Server **所有节点**建立长连接，隔 30s 定期地注册 Topic 信息到所有Name Server 节点，Name Server 也会每隔 10s 定时地扫描所有存活的 Broker 连接，如果 Name Server 超过 2min 没有收到 Broker 心跳，则会与 Broker 断开连接。

###### Producer 集群

- Producer，消息生产者，负责生产消息，一般由业务系统负责产生消息，完全无状态，可集群部署。
- Producer 会在 Name Server 集群中**随机选择一个节点**建立长连接，并与提供 Topic 服务的 Master Broker 节点建立长连接。
  1. **每隔 30s 定期地从 Name Server 获取所有 Topic 的最新情况**：可由 `ClientConfig#pollNameServerInterval` 指定。
     - 意味着如果 Broker 不可用，那么 Producer 最多只需要 30s 就能感知到，然后负载均衡到其他 Broker 上，但在此期间内，发往该 Broker 的所有消息都会失败。
  2. **还会每隔 30s 向所有关联的 Broker发送心跳**：可由 `ClientConfig#heartbeatBrokerInterval` 指定。
     - Broker 每隔 10s 会扫描所有存活的连接，如果 Broker 在 2min 内没有收到心跳数据，则会关闭与该 Producer 的连接。

###### Consumer 集群

- 消息消费者，负责消费消息，一般是后台系统负责异步消费，会被标识为 `{IP}@{consumer group}{topic}{tag}`，比如 x.x.x.x@mqtest_producer-group_2m2sTest_tag-zyk，其中任何一个元素不同，都会被认为是不同的 Consumer。
- Consumer 会在 Name Server 集群中**随机选择一个节点**建立长连接，并与提供 Topic 服务的 Master、Slave Broker 节点建立长连接。
  1. **每隔 30s 从 Name server 获取所有 Topic 的最新情况**：
     - 这意味着如果 Broker 不可用，那么 Consumer 最多只需要 30s 就能感知到，然后负载均衡到其他 Broker 上，但在此期间内，消费该 Broker 的所有消息都会失败。
  2. **还会每隔 30s 向所有关联的 Broker发送心跳**：可由 `ClientConfig#heartbeatBrokerInterval` 指定。
     - Broker 每隔 10s 会扫描所有存活的连接，如果 Broker 在 2min 内没有收到心跳数据，则会关闭与该 Consumer 的连接，并向该 Consumer Group 的所有 Consumer 发出通知，让 Group 内的 Consumer 重新分配队列，然后继续消费。
- Consumer 既可以从 Master 订阅消息，也可以从 Slave 订阅消息，订阅规则由 Broker 配置决定。
  - 当 Consumer 收到 Master 宕机通知后，会转向 Slave 进行消费，由于 Slave 不能保证 Master 消息100% 的同步，因此会有少量的消息丢失，但是一旦 Master 恢复，未同步过去的消息最终还是会被消费掉。

##### 消息存储原理

RocketMQ 消息存储是由 Comsume Queue + cimmitlog 配合完成的。

###### CommitLog

1. 在 RocketMQ 中，所有 Topic 消息都存储在一个称为 CommitLog 的文件中，该文件默认最大为 1GB，超过 1GB 后消息就会写到下一个 CommitLog 文件。
2. 通过 CommitLog，RocketMQ 把所有消息存储在一起，以顺序 I/O 的方式写入磁盘，充分利用了磁盘
   顺序写，减少了 I/O 争用，提高了数据存储的性能。
3. 消息在 CommitLog 中的存储格式如下：

![1635674975794](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635674975794.png)

| 属性                       | 长度  | 作用                                                         |
| -------------------------- | ----- | ------------------------------------------------------------ |
| msgLen                     | 4字节 | 消息的长度，为整个消息体所占用的字节数大小                   |
| magicCode                  | 4字节 | 魔数，固定值，分为 MESSAGE_MAGIC_CODE 和 BLANK_MAGIC_CODE    |
| bodyCRC                    | 4字节 | 消息体校验码，用于防止网络、硬件等故障导致数据与发送时不一样带来的问题 |
| queueId                    | 4字节 | 消息 ID，表示消息发到了哪个 MessageQueue，相当于 Kafka#partition |
| flag                       | 4字节 | 消息 flag，是创建 Message 时由 Producer 通过构造器设置的 flag 值 |
| queueOffset                | 8字节 | 消息在 queue 中的偏移量                                      |
| physicalPosition           | 8字节 | 消息在存储文件中的偏移量                                     |
| sysFlag                    | 4字节 | 生产者相关的信息标识                                         |
| msg born timestamp         | 8字节 | 消息创建时间                                                 |
| msg host                   | 8字节 | 消息 Producer 主机地址                                       |
| store timestamp            | 8字节 | 消息存储时间                                                 |
| store host                 | 8字节 | 消息存储机器的主机地址                                       |
| reconsume times            | 4字节 | 消息被重复消费的次数                                         |
| prepare transaction offset | 8字节 | 消息事务相关的偏移量                                         |
| body length                | 4字节 | 消息体长度                                                   |
| msg body                   | N字节 | 消息体，非固定长度，实际长度等于前面标示的4字节消息体长度    |
| topic length               | 1字节 | topic 长度，<= 127 字节，由于有前置校验，超过存储则会报错    |
| topic                      | N字节 | 存储 topic，非固定长度，实际长度等于前面标示的1字节 topic 长度 |
| properties length          | 2字节 | properties 长度，添加在消息中的 poperties 不能太多太大，要保证所有的properties 的 KV 对在拼接成 string 后，占用的字节数 <= 2^15-1 |
| properties                 | N字节 | properties 内容，非固定长度，实际长度等于前面标示的2字节 properties 长度 |

###### Consume Queue

1. 消息逻辑队列，相当于字典的目录，类似于二级索引，用来指定消息在物理文件 commit log 上的位置。
2. 在 Consumer 第一次连接时创建，每个 Consumer 都会拥有一份自己的 Consume Queue，新挂载的 Consume Queue 会拥有 CommitLog 中所有的数据。
3. 一个 Consume Queue 表示 topic#queue，类似于 Kafka#partition，但是 RocketMQ 在消息存储上与 Kafka 有着非常大的不同，RocketMQ#ConsumeQueue 不存储具体的消息，具体的消息由 CommitLog 存储，Consume Queue 中只存储路由到该 queue 中消息在 CommitLog 中的 offset，整个数据包如下，一共只占20个字节：

![1635678633250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678633250.png)

| 属性    | 长度  | 作用                                           |
| ------- | ----- | ---------------------------------------------- |
| offset  | 8字节 | 消息，在 CommitLog 中的 offset，类似于二级索引 |
| size    | 4字节 | 消息大小                                       |
| tagCode | 8字节 | 消息所属的 tagCode，即 tag 的 hash             |

###### 消息存储方式

RocketMQ 消息存储，由 CommitLog + ConsumeQueue 两部分组成，其中 CommitLog 用于存储原始的消息，ConsumeQueue 用于存储投递到某一个 queue 中消息的位置信息，其消息存储方式如下图所示：

1. Consumer 在读取消息时，会先读取 Consume Queue，再通过 Consume Queue 中的 offset，读取
   CommitLog，从而得到原始的消息。

![1635678882127](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678882127.png)

###### 对比 Kafka

1. 在 Kafka 中，每个 Partition 有独立的消息存储，投递到每个 Partition 的消息，会存储在 Partition 自己的文件中，示意图如下：

   ![1635741207241](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635741207241.png)

2. RocketMQ 与 Kafka 消息存储上的对比：

|          | RocketMQ                                                     | Kafka                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 消息存储 | 将所有消息存储在同一个 CommitLog 中，且 Consume Queue 中只存储20个字节每个消息的位置信息 | 将每个 Partition的消息分开存储                               |
| 影响     | 单个 Broker 能支持更多的 Topic 和 Consume Queue，单机支持最高5w个队列，并且Load不会发生明显变化 | 单机超过64个 Partition，Load 会发生明显的飙高，发送消息的响应时间变长，但对于少 Partition 场景， 由于利用了 Partition 并行处理，使得此时的写性能高于 RocketMQ |
| 原因     | 所有消息都存储在同一个文件中，使得消息存储是磁盘顺序写       | 将消息按 Partition 存储在不同的文件中，使得消息存储是磁盘随机写，当 Partition 数量非常大时，随机IO非常多，导致所有 Broker 性能明显下降 |

##### 生产者消息投递原理

Producer 轮询某 Topic 下所有队列的方式来实现**发送方的负载均衡**，如下图所示：

```java
private SendResult sendDefaultImpl(Message msg,......) {
    // 检查Producer状态是否是RUNNING
    this.makeSureStateOK();
    // 检查msg是否合法：是否为null、topic & body是否为空、body是否超长
    Validators.checkMessage(msg, this.defaultMQProducer);
    // 获取topic路由信息
    TopicPublishInfo topicPublishInfo = 
this.tryToFindTopicPublishInfo(msg.getTopic());
    // 从路由信息中选择一个消息队列
    MessageQueue mq = topicPublishInfo.selectOneMessageQueue(lastBrokerName);
    // 将消息发送到该队列上去
    sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, 
timeout);
}
```

![1635741977981](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635741977981.png)

##### 消费者消息消费原理

- **消费方的负载均衡**：

  1. 遍历 Consumer 下所有的 Topic，然后根据 Topic 订阅消息。
  2. 获取同一 Topic 和 Consume Group 下所有的 Consumer。
  3. 然后根据具体的分配策略，来分配消费队列，比如平均分配、消费端配置等。

  ![1635742208490](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635742208490.png)

- **两种消息订阅模式**：但无论是哪种模式，在实现上都是 Consumer 到 Broker 上主动拉取消息。

  1. 一种是 push 模式，即 Broker 主动向 Consumer 推送消息，是通过**长轮询**方式来实现的：

     1. Consumer 通过一个线程，将 LinkBlockingQueue 中的 PullRequest，每隔一段时间主动发送到Broker 去拉取消息（这样可以防止 Consumer 一直被阻塞）。
     2. Broker 在收到 PullRequest 时，如果队列里有消息，就立即返回数据，Consumer 在收到消息后，然后回调设置的 Listener 方法。
     3. Broker 在收到 PullRequest 时，如果队列里没有数据，则 Broker 会**阻塞该请求**，把 PullRequest 扔到 ConcurrentHashMap 中缓存起来，后台会有个线程不停地从 ConcurrentHashMap 取出PullRequest 进行检查，直到有数据投递过来或者发生超时后，才响应返回给 Consumer。

     ![1635742907979](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635742907979.png)

  2. 另一种是 pull 模式，即 Consumer **在需要时**，主动到 Broker 上拉取消息。

##### 事务消息实现原理

###### 单机事务

![1635743492688](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743492688.png)

- **优点**：可以保证数据一致性，耗时正常。
- **缺点**：系统规模变大时，可能会演变成分布式事务。

###### 分布式事务

![1635743625395](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743625395.png)

- **优点**：满足系统规模变大的需求。
- **缺点**：数据一致性的实现复杂，且需要经过网络，导致整体耗时成倍增加。

###### 小事务 + 异步消息

![1635743951460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743951460.png)

- **优点**：将大事务拆分成多个小事务，然后异步执行，基本把分布式事务的执行效率优化到与单机的一致。

- **注意点**：图中执行本地事务（Bob 账户扣款）和发送异步消息，应该保证同时成功或者同时失败，也就是扣款成功了，发送消息也一定要成功，如果扣款失败了，就不能发送消息。那么问题来了，是要先扣款还是先发送
  消息呢？

  1. **先发送消息**：

     - **存在问题**：如果消息发送成功，但是扣款失败，Consumer 就会消费此消息，进而向 Smith 账户加钱，不可取。

     ![1635744186519](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744186519.png)

  2. **先扣款**：

     - **存在问题**：如果扣款成功，发送消息失败，就会出现 Bob 扣钱了，但是 Smith 账户未加钱。
       - **解决方案**：把发消息放到 Bob 扣款的事务中去，如果发送失败，就抛出异常，事务回滚，从而保证 Bob 钱是正确的，也没有发送到消息。

     ![1635744257263](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744257263.png)

###### 事务消息

![1635744412458](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744412458.png)

事务消息，可以被认为是**两阶段提交**的消息实现，确保本地事务的执行和消息的发送可以原子地执行，实现分布式系统的最终一致性，使用事务消息，可以从框架 API 层面，实现分布式事务的需求，减少编程工作量。

- **事务消息执行时，程序分三个阶段**：
  1. **第一阶段**：发送 Prepared 消息，拿到消息的地址。
     1. RocketMQ 会定期扫描消息集群中的事务消息，如果发现了 Prepared 消息，则会向 Producer 确认，Bob 钱到底是减了还是没减，如果没减，则会继续等待。
     2. 如果减了，还要根据 Producer 设置的策略，来决定到底是回滚，还是会继续发送确认消息。
     3. 从而保证消息发送与本地事务同时成功或者同时失败。
  2. **第二阶段**：执行本地事务。
  3. **第三阶段**：通过第一阶段拿到的地址，去访问消息，并修改消息的状态。
- **存在问题**：Consumer 消费可能会失败，或者发生超时。

###### 事务消息 + 消费重试

![1635747736118](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635747736118.png)

- **优点**：通过不断消费重试，可以解决消费超时的问题，但需要注意重复消费的问题。
- **缺点**：但解决不了消费失败的问题。
  - **解决方案**：人工解决。
    1. 如果按照事务的流程，这种由于 Smith 加款失败，是需要回滚整个流程的。
    2. 而消息系统要实现这个回滚流程，系统的复杂度将大大提升，并且很容易出现 Bug，估计出现 Bug 的概率，都会比消费失败的概率大很多，这也是 RocketMQ 目前暂时没有解决这个问题的原因。
    3. 在设计实现消息系统时，需要衡量是否值得花这么大的代价，来解决一个出现概率非常小的问题。
    4. 因此，对于这种小概率问题人工解决就好，比如阿里的网上银行，发生补钱的流程通过自家的银行人工补偿就好。

#### API

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>org.apache.rocketmq</groupId>
    <artifactId>rocketmq-client</artifactId>
    <version>4.9.2</version>
</dependency>
```

##### Producer | HelloWorld

###### 同步发送

可靠的同步发送，应用于广泛的场景，比如重要通知消息、短信通知、短信营销系统等。

| SendResult.sendStatus | 释义                                                         |
| --------------------- | ------------------------------------------------------------ |
| SEND_OK               | 消息发送成功，不过发送成功并不意味着可靠性投递，要想确保不丢，还要启用同步刷盘 `SYNC_FLUSH` 与同步复制 `SYNC_MASTER` |
| FLUSH_DISK_TIMEOUT    | 消息发送成功但 Master 刷盘超时，当 Master 启用了同步刷盘，却未能在同步刷盘时间内（默认 5s）完成刷盘，则会返回该状态 |
| FLUSH_SLAVE_TIMEOUT   | 消息发送成功但 Slave 同步超时，当 Master 启用了同步复制，Slave 却未能在同步复制时间内（默认 5s）完成与 Master 的同步，则会返回该状态 |
| SLAVE_NOT_AVAILABLE   | 消息发送成功但 Slave 不可用，当 Master 启用了同步复制，却没有配置任何 Slave，则会返回该状态 |

```java
public class SyncProducer {
    public static void main(String[] args) throws Exception {
        DefaultMQProducer producer = new
            DefaultMQProducer("please_rename_unique_group_name");
        producer.setNamesrvAddr("localhost:9876");
        producer.start();
        for (int i = 0; i < 100; i++) {
            Message msg = new Message("TopicTest", "TagA", 
            ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
            // 同步发送: 只要这个方法不抛出任何异常，就代表消息已经发送成功
            SendResult sendResult = producer.send(msg);
            System.out.printf("%s%n", sendResult);
        }
        producer.shutdown();
    }
}

```

###### 异步发送

异步发送，适用于链路耗时较长，对响应时间敏感的业务场景。

```java
public class AsyncProducer {
    public static void main(String[] args) throws Exception {
        ...
        // 异步发送
        producer.send(msg, new SendCallback() {
            @Override
            public void onSuccess(SendResult sendResult) {
                countDownLatch.countDown();
                System.out.printf("%-10d OK %s %n", index, sendResult.getMsgId());
            }

            @Override
            public void onException(Throwable e) {
                countDownLatch.countDown();
                System.out.printf("%-10d Exception %s %n", index, e);
                e.printStackTrace();
            }
        });
        ...
    }
}

```

###### 单向发送

单向发送，用于需要中等可靠性的情况，比如日志收集。

```java
public class OnewayProducer {
    public static void main(String[] args) throws Exception{
        ...
		producer.sendOneway(msg);
        ...
    }
}
```

##### Consumer | HelloWorld

```java
public class Consumer {
    public static void main(String[] args) throws InterruptedException, MQClientException {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name");
        consumer.setNamesrvAddr("localhost:9876");
        consumer.subscribe("TopicTest", "*");
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
                ConsumeConcurrentlyContext context) {
                System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        consumer.start();
        System.out.printf("Consumer Started.%n");
    }
}
```

##### Producer | 自定义路由

```java
public class OrderedProducer {
    public static void main(String[] args) throws Exception {
        SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
            @Override
            public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                // 自定义路由 -> 队列数量取模
                Integer id = (Integer) arg;
                int index = id % mqs.size();
                return mqs.get(index);
            }
        }, orderId);
    }
}
```

##### Consumer | 广播订阅

```java
public class BroadcastConsumer {
    public static void main(String[] args) throws Exception {
        ...
        // 广播订阅
        consumer.setMessageModel(MessageModel.BROADCASTING);
        consumer.subscribe("TopicTest", "TagA || TagC || TagD");
        ...
    }
}
```

##### Producer | 延迟消息

```java
 public class ScheduledMessageProducer {
     public static void main(String[] args) throws Exception {
         Message message = new Message("TestTopic", ("Hello scheduled message " + i).getBytes());
         // 延迟消息: This message will be delivered to consumer 10 seconds later.
         message.setDelayTimeLevel(3);
         producer.send(message);
     }
        
 }
```

##### Producer | 批量发送

```java
String topic = "BatchTest";
List<Message> messages = new ArrayList<>();
messages.add(new Message(topic, "TagA", "OrderID001", "Hello world 0".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID002", "Hello world 1".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID003", "Hello world 2".getBytes()));
try {
    producer.send(messages);
} catch (Exception e) {
    e.printStackTrace();
}

```

##### Consumer | Tag 过滤器

```java
DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("CID_EXAMPLE");
// 只消费topic为TOPIC，tag为TAGA、TAGB、TAGC的消息
// consumer.subscribe("TOPIC", "TAGA || TAGB || TAGC");
// 只消费topic为TopicTest，tag为 0<=a<=3 的消息
consumer.subscribe("TopicTest", MessageSelector.bySql("a between 0 and 3");

```

##### Producer | 事务消息

```java
public class TransactionProducer {
    public static void main(String[] args) throws MQClientException, InterruptedException {
        TransactionListener transactionListener = new TransactionListenerImpl();
        TransactionMQProducer producer = new TransactionMQProducer("please_rename_unique_group_name");
        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {
            @Override
            public Thread newThread(Runnable r) {
                Thread thread = new Thread(r);
                thread.setName("client-transaction-msg-check-thread");
                return thread;
            }
        });

        // 设置自定义线程池来处理检查本地事务状态
        producer.setExecutorService(executorService);
        producer.setTransactionListener(transactionListener);
        producer.start();

        String[] tags = new String[] {"TagA", "TagB", "TagC", "TagD", "TagE"};
        for (int i = 0; i < 10; i++) {
            try {
                Message msg =
                    new Message("TopicTest1234", tags[i % tags.length], "KEY" + i,
                        ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
                SendResult sendResult = producer.sendMessageInTransaction(msg, null);
                System.out.printf("%s%n", sendResult);
                
                Thread.sleep(10);
            } catch (MQClientException | UnsupportedEncodingException e) {
                e.printStackTrace();
            }
        }

        for (int i = 0; i < 100000; i++) {
            Thread.sleep(1000);
        }
        
        producer.shutdown();
    }
}

// 实现TransactionListener接口
public class TransactionListenerImpl implements TransactionListener {
    private AtomicInteger transactionIndex = new AtomicInteger(0);
    // transactionId-status
    private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();

    // 在发送半消息成功时，执行本地事务，返回三种事务状态之一
    @Override
    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
        int value = transactionIndex.getAndIncrement();
        int status = value % 3;
        localTrans.put(msg.getTransactionId(), status);
        return LocalTransactionState.UNKNOW;
    }

    // 检查本地事务状态，并响应MQ检查请求，返回三种事务状态之一
    @Override
    public LocalTransactionState checkLocalTransaction(MessageExt msg) {
        Integer status = localTrans.get(msg.getTransactionId());
        if (null != status) {
            switch (status) {
                case 0:
                    // 中间状态，表示需要MQ回检来确定状态
                    return LocalTransactionState.UNKNOW;
                case 1:
                    // 提交事务，表示允许消费者消费这条消息
                    return LocalTransactionState.COMMIT_MESSAGE;
                case 2:
                    // 回滚事务，表示消息将被删除，不允许消费
                    return LocalTransactionState.ROLLBACK_MESSAGE;
            }
        }
        return LocalTransactionState.COMMIT_MESSAGE;
    }
}
```

#### 常见问题解决

##### 如何保证数据不丢失？

参考《RabbitMQ - 如何保证数据不丢失》，数据丢失的场景有：生产端丢数据、MQ 丢数据、消费端丢数据：

- **解决方案**：

  1. **生产端丢数据**：生产消息可以通过 Comfirm 机制解决，消息状态打标 + 消息落库 + 定时重发 + 人工介入/失败补偿（同步发送时根据 SendResult.sendStatus 判断，异步发送时在回调函数里判断）。

     ```java
     // 同步发送消息的重试次数, 默认为2
     producer.setRetryTimesWhenSendFailed(3);
     // 异步发送消息的重试次数, 默认为2
     // producer.setRetryTimesWhenSendAsyncFailed(3);
     
     ```

  2. **MQ 丢数据**：同步刷盘 + 同步复制（也叫同步双写）。

     1. **同步刷盘**：
        1. 默认情况下，刷盘策略为 `flushDiskType=ASYNC_FLUSH`，表示异步刷盘，消息到了 Broker 将会优先保存到内存中，然后立刻返回确认响应给 Producer。
        2. Broker 再定期批量地把一组消息，从内存异步刷入到磁盘中。
        3. 虽然这种方式减少了 I/O 次数，可以取得更好的性能，但如果机器发生断电、异常、宕机等情况，导致消息未能及时刷入磁盘，就会出现消息丢失。
        4. 如果要 Broker 不丢消息，保证消息可靠性，需要把刷盘机制修改为同步刷盘方式 `flushDiskType = SYNC_FLUSH`，当消息存入到磁盘成功后，才返回响应给 Producer。
     2. **同步复制**：
        1. 为了保证 RocketMQ 的可用性，Broker 通常采用一主多从的部署方式，Slave 会从 Master 复制消息。
        2. 默认情况下，复制策略为 `brokerRole=ASYNC_MASTER`，表示异步复制，消息写入 Master 成功后，就可以返回响应给 Producer 了，接着消息才会异步复制到 Slave 节点。
        3. 但如果复制期间，Master 发生宕机且不可恢复，那么未复制到 Slave 的消息将可能会发生丢失。
        4. 为了进一步提高消息可靠性，可以采用同步复制的方式 `brokerRole=SYNC_MASTER`，消息写入 Master 时，会同步等待 Slave 节点复制完成后，才返回响应给 Producer。

  3. **消费端丢数据**：

     1. Consumer 从 Broker 拉取消息，然后执行相应的业务逻辑。
     2. 如果执行成功，将返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS` 消费成功状态给 Broker。
     3. 而如果执行失败或者发生异常，则返回 `ConsumeConcurrentlyStatus.RECONSUME_LATER` 稍后重试状态给 Broker。
     4. 如果 Broker 未收到 Consumer 响应，或者收到除消费成功外的其他状态，那么 Consumer 下次还会再次拉取到该条消息进行重试。
     5. 这样有效避免了 Consumer 消费过程发生异常，或者消息在网络传输中丢失的情况。

- **总结**：

  1. 虽然提高了消息的可靠性，但会降低 MQ 的性能，生产实践中需要综合实际情况进行选择。
  2. 另外，还可能导致消息重发、Consumer 重复消费的情况，所以，对于 Consumer 而言，需要注意保证消费的**幂等性**。

##### 如何防止重复消费？

RocketMQ 不保证消息不重复，如果业务系统需要保证严格的不重复消息，需要自己在业务端进行去
重，具体解决方案参考《RabbitMQ - 如何防止重复消费》。

##### 一致性与可用性保障？

###### 集群部署方案

1. **单 Master 模式**：也就是只有一个 Master 节点。
   - **缺点**：如果 Master 节点挂了，则会导致整个服务不可用，线上不宜使用，只适用于个人学习使用。
2. **多 Master 模式**：多个 Master 节点组成集群。 
   - **优点**：所有模式中性能最高，且单个 Master 节点宕机或者重启，对应用没有影响。
   - **缺点**：单个 Master 节点宕机期间，未被消费的消息在节点恢复之前不可用，消息实时性受到影响。
     - **解决方案**：使用同步刷盘可以保证消息不丢失，同时 Topic 相对应的 Queue 应该分布在集群中各个 Master 节点，而不是只在某 Master 节点上，否则，该节点宕机会对订阅该 Topic 的应用造成影响。
3. **多 Master 多 Slave + 异步复制**：在多 Master 模式的基础上，让每个 Master 节点都有至少一个对应的 Slave，其中 Master 节点可读可写，而 Slave 只能读不能写，类似于 MySQL 的主从模式。
   - **优点**： 在 Master 宕机时，消费者可以从 Slave 读取消息，消息实时性不会受影响，性能几乎和多 Master 一样。 
   - **缺点**：使用异步复制有可能会发生消息丢失的问题。
4. **多 Master 多 Slave + 同步双写**： 与多 Master 多 Slave + 异步复制类似，但区别在于 Master 和 Slave 之间的数据同步方式为同步复制。
   - **优点**：同步双写能保证数据不丢失。 
   - **缺点**：发送单个消息 RT 会略长，性能相比异步复制低10%左右，即要保证数据可靠，需要采用同步刷盘和同步复制的方式，但性能会较其他方式低。

###### 可用性

![1635853268227](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635853268227.png)

1. **Name Server 高可用**：
   1. 由于 Name Server 节点是无状态的，且各个节点直接的数据是一致的，没有任何节点通信，每个 Broker 对接所有 Name Server 节点。
   2. 因此，在多个 NameServer 节点的情况下，当部分 Name Server 不可用时，也可以保证 MQ 服务正常运行。
2. **Broker 高可用**：
   1. Broker 通过 Master 和 Slave 的配合，达到模块的高可用，即一个 Master 可以配置多个 Slave 的一主多从模式，以及配置多个 Master-Slave 的多主多从模式。
   2. 当其中一个 Master 出现问题时：
      - **一主多从模式**：由于 Slave 只负责读，当 Master 不可用时，Slave 仍能保证消息被正常消费。
      - **多主多从模式**：由于配置了多组 Master-Slave，当 Master 不可用时，其他的 Master-Slave 还会保证消息的正常发送和消费。
   3. 新版本的 RocketMQ，支持 Slave 自动转成 Master，而老版本则要手动停止 Slave Broker，更改配置文 件，用新的配置文件启动 Broker，把 Slave 转成 Master。
3. **Consumer 高可用**：
   1. Consumer 高可用依赖于 Master-Slave 配置，由于 Master 能够支持读写消息，Slave 支持读消息，当 Master 不可用时， Consumer 会被自动切换到从 Slave 进行读取。
   2. 此时，Master 发生机器故障时，消息仍可从 Slave 中被消费。
4. **Producer 高可用**：
   1. 在创建 Topic 时，把 Topic 的多个 Message Queue 创建在多个 Master Broker 上。
   2. 这样，当其中一个 Master Broker 不可用后，其他的 Master Broker 仍然可用，Producer 可以继续发送消息。

###### 一致性（可靠性）

**4 可靠性**

- **异步刷盘**：Broker 在返回 Producer 消息写成功时，消息可能只是被写入了内存的 PageCahce，这样的写操作返回快，吞吐量大，当内存里的消息量积累到一定程度时，会统一触发写磁盘操作，快速批量写入。
  - **优点**：减少了多次写磁盘的 I/O，性能高。
  - **缺点**：当 Master 宕机，或者在磁盘损坏的情况下，会丢失少量的消息，导致 MQ 的消息状态和 Producer、Consumer 的消息状态不一致。
  - **配置参数**：默认，`flushDiskType=ASYNC_FLUSH` 。
- **同步刷盘**：Broker 在返回 Producer 消息写成功前，消息已经被真正地写入了磁盘，具体流程是，消息写入内存的 PageCache后，会立刻通知刷盘线程进行刷盘，在等待刷盘线程刷盘完成后，才唤醒等待的写消息线程，返回消息写成功的状态给 Producer。
  - **优点**：可以保持 MQ 的消息状态和 Producer、Consumer 的消息状态一致。
  - **缺点**：性能比异步的低。
  - **配置参数**：`flushDiskType = SYNC_FLUSH` 。
- **异步复制**：Broker 只要在 Master 写成功后，即可返回消息写成功状态给 Producer。
  - **优点**：复制具有较低的延迟和较高的吞吐量。
  - **缺点**：如果 Master 出现故障，有些数据会因为没有被写入 Slave，而丢失少量消息。
  - **配置参数**：默认，`brokerRole=ASYNC_MASTER` 。
- **同步复制**：Broker 会等到 Master 和 Slave 都写成功后，才返回消息写成功状态给 Producer。
  - **优点**：如果 Master 出现故障，Slave 有全部的备份数据，消息不丢失，容易实现完整恢复。
  - **缺点**：增大了复制的写入延迟，降低了系统吞吐量，性能比异步复制略低，大约低 10% 左右。
  - **配置参数**：`brokerRole=SYNC_MASTER` 。

###### 总结

1. **Master + Slave + 同步刷盘 + 同步双写**是最安全的方案，但会引入额外的延迟。
2. 事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的最终一致性，以及时刻都接受读取和写入的高可用性。
3. 因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个范围的两端。

##### 如何实现 Consumer Rebalance？

###### 概念

Consumer Rebalance，消费者再均衡机制，指将一个 Topic 下的多个 Queue，在同一个 Consumer Group下的多个 Consumer 之间进行重新分配。 

1. Consumer Rebalance 机制，目的是为了提升消息的并行处理能力。
2. 比如，一个 Topic 下有 5 个 Queue，在只有 1 个 Consumer 的情况下，那么该 Consumer 将会负责处理这 5 个队列的消息。
3. 如果此时增加了一个 Consumer，那么则可以给其中一个 Consumer 分配 2 个 Queue，给另一个分配 3 个 Queue，从而提升消息的并行处理能力。

![1635925188314](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635925188314.png)

###### 局限与危害

- **空消费**：由于一个 Queue 最多分配给一个 Consumer，因此，当某个 Consumer Group 下的 Consumer#size > Queue#size 时，多余的 Consumer 将分配不到任何 Queue。
- **消费暂停**：
  1. 在只有 Consumer 1 负责消费所有 5 个 Queue 的情况下，在新增 Consumer 2，触发 Consumer Rebalance 时，需要分配 2 个Queue 给 Consumer 2 消费。
  2. 那么，此时 Consumer 1 就需要停止这 2 个 Queue 的消费，等到这 2 个 Queue 分配给 Consumer 2 后，这 2 个 Queue 才能被继续消费。
- **重复消费**：
  1. Consumer 2 在消费分配给自己的 2 个 Queue 时，必须接着从 Consumer 1 之前已经消费到的 offset 继续开始消费。
  2. 然而，默认情况下，offset 是异步提交的，比如 Consumer 1 当前消费到 offset=10，但是异步提交给Broker#offset=8。
  3. 那么，如果 Consumer 2 从 offset=8 开始消费，那么就会有 2 条消息被重复消费，也就是说，Consumer 2 并不会等待 Consumer 1 提交完 offset 后，再进行 Rebalance，因此，Consumer 1 提交间隔越长，可能造成的重复消费就越多。 
- **消费突刺**：由于 Consumer Rebalance 可能导致重复消费，如果需要重复消费的消息过多，或者因为Consumer Rebalance 暂停时间过长，导致 MQ 积压了较多消息，导致在 Consumer Rebalance 结束之后的瞬间，Consumer 需要消费很多消息。

###### 触发条件

Consumer Rebalance 的触发条件有 2 个：

1. 订阅了 Topic 的 Queue 信息发生变化。
2. Consumer Group 信息发生变化。

| 订阅了 Topic 的 Queue 信息发生变化 | Consumer Group 信息发生变化                |
| ---------------------------------- | ------------------------------------------ |
| Broker 宕机                        | Consumer 发布过程中的停止与启动            |
| Broker 升级等运维操作              | Consumer 异常宕机                          |
| Queue 扩容或者缩容                 | 网络异常，导致 Consumer 与 Broker 断开连接 |
|                                    | Consumer 扩容或者缩容                      |
|                                    | Topic 订阅信息发生变化                     |

###### 场景分析

对于 Consumer Group 信息发生变化，具体场景有，Consumer 在启动/运行/停止时，都有可能触发 Consumer Rebalance。

- **启动时**：
  1. Consumer 启动后会立即向所有 Broker 发送一次发送 `HEART_BEAT` 心跳请求。
  2. Broker 收到该请求后，则会将 Consumer 添加到由 ConsumerManager 维护的某个消费者组中。
  3. 然后该 Consumer 自己会触发一次 Consumer Rebalance。
- **运行时**：Consumer 接收到 Broker Rebalance 通知后，会立即触发一次 Consumer Rebalance，同时为了避免 Rebalance 通知丢失，还会周期性触发 Consumer Rebalance。
- **停止时**：
  1. Consumer 向所有 Broker 发送 `UNREGISTER_CLIENT` 命令。
  2. Broker 收到后，则将 Consumer 从 ConsumerManager 中移除，并通知其他 Consumer 进行 Consumer Rebalance。

###### 执行过程

- **单 Topic 队列分配**：调用 `RebalanceImpl#rebalanceByTopic`。

  1. 获得 Rebalance 元数据信息：即当前消费者组订阅 Topic 的 Queue 信息，以及当前消费者组所有 Consumer#ID 集合。

  2. 调用 `AllocateMessageQueueStrategy#allocate` 根据具体的**队列分配策略**，进行队列分配，此时需要传入消费者组、当前 Consumer#ID、当前消费者组可分配的队列集合、当前消费者组所有 Consumer#ID 集合。

     | 队列分配策略实现                      | 实现原理       |
     | ------------------------------------- | -------------- |
     | AllocateMessageQueueAveragely         | 默认，平均分配 |
     | AllocateMessageQueueAveragelyByCircle | 循环分配       |
     | AllocateMessageQueueConsistentHash    | 一致性哈希分配 |
     | AllocateMessageQueueByConfig          | 根据配置分配   |
     | AllocateMessageQueueByMachineRoom     | 根据机房分配   |
     | AllocateMachineRoomNearby             | 就近分配       |

  3. 调用 `RebalanceImpl#updateProcessQueueTableInRebalance` 进行队列的实际分配。

- **多 Topic 分配**：每个 Topic 都会调用一次 `RebalanceImpl#rebalanceByTopic`，触发一次队列分配策略。

###### 对比 Kafka Consumer Rebalance

- **相同点**：二者的 Rebalance 都是在 Consumer 客户端进行。
- **不同点**：
  1. Kafka 会在 Consumer Group 中，选出一个 Consumer 作为 Group Leader，再由这个 Group Leader 来进行分区分配，最后的分配结果通过 Cordinator Broker 同步给其他 Consumer，即 Kafka 分区分配只有一个大脑 Group Leader。
  2. 而 RocketMQ 则是，通过 Broker 通知每个 Consumer 各自进行 Consumer Rebalance，每个Consumer 自己给自己重新分配队列，而不是 Broker 将分配好的结果告知 Consumer，即每个 Consumer 都是一个大脑。
- **RocketMQ#Consumer Rebalance 一致性保证原理**：
  - **定时 Rebalance 保证**：每个 Consumer 都会定时触发 Rebalance，避免 Rebalance 通知丢失。
  - **队列分配策略保证**：
    1. 每个 Consumer 在调用 `AllocateMessageQueueStrategy#allocate` 时，会传入自身实例#ID，用于获取在当前消费组所有 Consumer#ID 集合中的索引位置。
    2. 然后根据具体的策略实现，可以使得每个索引所处的 Consumer 分配的队列各不相同。
    3. 这样可以让 RocketMQ 即使没有一个中心节点做统一的队列分配，也能完成 Consumer Rebalance。

##### 如何保证顺序消费？

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个队列**，类似于 Kafka 的单消费者单个分区，目的是防止消费者争抢消息导致乱序消费的情况发生。

  1. 与 RabbitMQ 保证单消费者消费单个队列不同，但与 Kafka 类似，由于 RocketMQ#Consumer Group 机制，天然就能保证单个消费者消费，虽然 RocketMQ 针对的是 Queue，但却类似于一个 Kafka#Partition。

- **解决方案**：参考《RabbitMQ - 如何保证顺序消费》。

  - **多队列、多消费者**：类似于 RabbitMQ#一致性哈希交换机 `x-consistent-hash Exchange`，通过业务ID进行 hash，保证同一个业务 ID 的消息只落在同一个 Queue 中，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。

    - **实现方法**：

      ```java
      // 通过MessageQueueSelector中实现的算法，来确定消息发送到哪一个Queue上
      SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
          @Override
          public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) 
      {
              Integer id = (Integer) arg;
              int index = id % mqs.size();
              return mqs.get(index);
          }
      }, orderId);
      
      ```

  - **单队列、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单分区、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单队列、单消费者**：始终保证使用 一个 Queue + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

    - **实现方法**：

      ```shell
      # -b : broker地址,表示topic建在该broker
      # -c : cluster名称,表示topic建在该集群
      # -n : nameserve服务地址列表
      # -r : 可读队列数(默认为8)
      # -w : 可写队列数(默认为8)
      # -t： topic名称
      mqadmin updateTopic -b localhost:10911 -t TopicTest
      ```

##### 如何优化消息积压？

###### 影响后果

1. 消息积压越多，Consumer 寻址的性能就越慢，最差的情况则会导致整个 RocketMQ 对外提供服务的性能很差，从而影响其他服务的访问速度，最后造成雪崩效应。
2. 而且还可能发生磁盘被堆满，导致 Producer 消息无法写入磁盘，一直报错，然后引发连锁反应，同样会造成雪崩效应。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Partition、增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **Consumer 批量拉取消息**：这里要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   1. 对于每条消息分别拉取的情况，Consumer 需要多次从 Broker 上拉取消息，这样的多次 I/O，浪费了服务器性能与增加了带宽的占用。
   2. 通过批量拉取消息的方式，减少多次发起 Broker 请求，可以减少很多 I/O 浪费和带宽占用。

   ```java
   // 每次拉取10条
   consumer.setConsumeMessageBatchMaxSize(10);
   
   ```

2. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手，参考《Kafka API - Consumer 多线程消费》。

   1. 多线程并发消费，不需要建立多个 RocketMQ 客户端连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

3. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个队列，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 先单个 Consumer 消费，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  2. 如果消费速度不满足要求，则提高 `consumer.setConsumeMessageBatchMaxSize(10)`，**1 次接收多条消息**，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，但要注意并发冲突和顺序消费的问题。
  4. 如果消费速度还是不满足要求，则**多个消费者并发消费**，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步。

###### 【线上】如何紧急处理消息积压？

参考《RabbitMQ - 【线上】如何紧急处理消息积压》。

对于 RocketMQ 而言，由于 Queue 机制与 RabbitMQ Queue 并不相同，所以除了参考，还有以下的处理方式：

1. **提高 Queue 队列数**：队列数足够，可以提高消费的并行度，并且也决定者同组 Consumer 的最大数量。
2. **临时 Topic + Consumer 进行消息转储消费**：
   1. 如果消息积压的 Topic 在建立时，就没有建立足够多的 Queue，导致同一个 Consumer Group 中的 Consumer#size 已经增加到 Queue#size，却仍有大量的消息积压。
   2. 此时，可以建立一个临时的 Topic、设置足够多的 Queue 以及上线一批足够多的 Consumer ，然后把所有原 Topic 的 Consumer 拉取到的消息统统转储到临时 Topic 上，供新上线那批 Consumer 去消费。
   3. 这样，消费速度上去了，消息积压的问题才有机会解决掉，解决掉后再视实际情况，来决定是否恢复原状。

