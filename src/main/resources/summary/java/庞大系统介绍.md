### 十三、庞大系统介绍

| 考察维度 | 精讲部分（必须掌握、背熟）                                   |
| -------- | ------------------------------------------------------------ |
| Redis    | 分布式锁、Redis 常用数据结构                                 |
| 消息队列 | 可靠性保证                                                   |
| MySQL    | MVCC、Explain、SQL 语句调优、分布式 ID 实现方案              |
| JVM      | 运行时数据区、垃圾收集器、垃圾回收算法                       |
| Spring   | Spring 启动原理、SpringBoot  自动装配、MVC 原理、IOC 原理、AOP 原理、Spring 事务原理 |
| Dubbo    | 架构图、Provider 服务注册原理、Consumer 服务引用原理、调用原理 |
| Java     | ThreadLocal、HashMap、ConcurrentHashMap、ThreadPoolExecutor、Synchronized、Volatile、AQS 原理、Queue |

#### 1.1.1.1. 项目上用到了 SpringCloud 哪些组件？

##### 1、总

用到了 Eureka 做**服务注册**，Feign 做**服务通信**，Ribbon 做**负载均衡**，Sleuth+Zipkin 做**链路追踪**，Config 做**配置中心**、Stream+Bus 做**消息驱动**。

##### 2、分

1. 服务注册的意思就是，在微服务中，由于服务可能会比较多，其 IP 也经常会发生变化，如果**手动维护**每个服务的 IP+端口 的话，那么就太耗时耗力了，此时可以通过服务启动时，**上报**包括自己当前的 IP 地址、端口、健康状态等信息，到一个注册中心中，由注册中心来统一收集并管理它们，从而减轻人工维护的成本，且信息也比较及时和准确。
2. 服务通信的意思就是，在微服务中，由于模块与模块之间，常常需要相互获取数据，那么就需要进行通信，此时可以到注册中心那里，获取一份想要访问的服务器的**注册表**，得到它的 IP+端口，然后发起比如 HTTP 的远程调用，从而获取到某个参数下远程服务器的执行结果。
3. 负载均衡的意思就是，在微服务中，由于服务实例常常不止一个，如果没有一个合适的访问策略，那么很可能会导致某个实例**访问过热**，此时就需要一种策略来**打散这些流量**，这就是负载均衡，在 SpringCloud 中的实现是 Ribbon 组件，其原理是服务实例启动时，通过获取注册中心中所有的服务列表，然后缓存到机器内存中，在要发起服务调用时，会经过 Ribbon 配置的负载算法，来保证调用的均衡性。
4. 链路追踪的意思就是，在微服务中，由于一个前端请求，可能会拉起多个服务间的调用，导致排查问题可能需要跨机器的挨个挨个排查，浪费人力精力，此时可以通过使用一个**全局 ID** 来标记当前请求，在需要跨机器请求时，全局 ID 不变，但生成一个新的**局部 ID**，以及**时间戳**，传递到下一台机器，这样全局 ID 标记也就跟着过去，同时，还可以通过使用当前时间戳减去传过去的时间戳，从而计算出本次跨机器请求所花费的时间，完成链路追踪。
5. 配置中心的意思就是，在微服务中，由于服务实例可能会有很多，且每个模块的业务、参数等配置可能会不一样，导致配置可能会有多个版本，如果以人工的方式去登记每个模块配置的不同之处，识别哪个版本是哪个服务的配置的话，很容易出错，且难以维护和管理，此时可以抽象出一个配置中心，通过**按路径、按标签**地存放所有服务模块的配置信息，在每个服务启动时，再去配置中心**拉取**对应自己的配置，填入自己配置的**占位符**中，然后再去加载容器，从而实现**远端配置**的统一管理与控制。
6. 消息驱动的意思就是，在微服务中，常常需要用到消息中间件，但不同中间件的 API 使用方式不同，比如业务代码基于 RabbitMQ 做了实现，如果某一天想要更换底层为 Kafka，就需要对原有的业务代码进行修改，此时，可以抽取出一个统一的消息驱动组件，来**屏蔽底层的实现差异**，只负责输入输出消息即可，从而实现一套从上层来看是以**消息作为事件驱动**的架构。

##### 3、总

综上，就是我对 Spring Cloud 微服务的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.2. 如何在 Feign 调用时增强一下 Header？

关键字：RequestInterceptor#apply()、RequestTemplate、ThreadLocal。

##### 1、总

可以实现 `RequestInterceptor#apply()` 方法，该方法会传入一个 `RequestTemplate`，然后从上下文，比如 `ThreadLocal` 中取出需要增强的属性，然后设置到 `RequestTemplate#header` 中即可，比如这样：

```java
@Component
@Slf4j
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate requestTemplate) {
        // Member User信息
        MemberUser memberUser = GlobalMemberContext.getMemberUser();
        if(memberUser != null){
            try {
                requestTemplate.header(ProjectConstant.MEMBER_USER_INFO, URLEncoder.encode(JSON.toJSONString(memberUser), Charsets.UTF_8.name()));
            } catch (UnsupportedEncodingException e) {
                log.info("member user编码失败");
            }
        }
    }
}
```

##### 2、分

其中，Feign 的底层原理是这样的，

- **注入原理**：
  1. 由于 SpringBootApplication 上打了 @EnableFeignClients 注解，所以会回调注解导入的 **ImportBeanDefinitionRegistrar**#registerBeanDefinitions 方法，该方法可以扫描并注册 FeignClient。
  2. 其中注册 FeignClient 时， 会在 BeanDefinitionRegistry 中添加 FeignClientFactoryBean#beanDefinition。
  3. 由于 FeignClientFactoryBean 实现了 FactoryBean 接口，所以在对应的 FeignClient 被注入时，则会调用 **FactoryBean#getObject** 方法。
  4. 然后该 FeignClientFactoryBean#getObject 方法在构造 Feign.Builder 时，获取到容器中所有打了 @Component 注解，且实现 **RequestInterceptors** 接口的拦截器，然后注入到 Feign.Builder#requestInterceptors 属性中。
  5. 接着就是使用 Feign.Builder 来构建 LoadBalancer 的动态代理，返回对应的动态代理对象。

```java
Map<String, RequestInterceptor> requestInterceptors = context
				.getInstances(this.contextId, RequestInterceptor.class);
if (requestInterceptors != null) {
    builder.requestInterceptors(requestInterceptors.values());
}
```

- **执行原理**：
  1. 当业务方法调用注入的 FeignClient 实例对应的接口方法时，则会触发 JDK 动态代理，回调到 **InvocationHandler** 的 invoke 方法。
  2. 在 invoke 方法中，会去遍历所有的 **requestInterceptors**，并执行他们的 **apply** 方法，从而实现 Header 的增强。

```java
final class SynchronousMethodHandler implements MethodHandler {
    @Override
    public Object invoke(Object[] argv) throws Throwable {
        ...
        return executeAndDecode(template, options);
    }
    
    Object executeAndDecode(RequestTemplate template, Options options) throws Throwable {
    	Request request = targetRequest(template);
        ...
    }
    
  	Request targetRequest(RequestTemplate template) {
    	for (RequestInterceptor interceptor : requestInterceptors) {
      		interceptor.apply(template);
    	}
    	return target.apply(template);
  	}
}
```

##### 3、总

以上，就是我对 Feign Client 的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.3. Feign 的调优参数有哪些，以及HTTP 连接池优化？ 

| 参数解释                               | 具体配置                                                     |
| -------------------------------------- | ------------------------------------------------------------ |
| 具体服务的连接超时时间（ms）           | xxx.ribbon.ConnectionTimeout                                 |
| 具体服务的读取超时时间（ms）           | xxx.ribbon.ReadTimeout                                       |
| 具体服务的重试开关（true / false）     | xxx.ribbon.okToRetryOnAllOperations                          |
| 具体服务的超时重试次数（不包括首次）   | xxx.ribbon.MaxAutoRetries                                    |
| 具体服务的超时重试机器数（不包括首台） | xxx.ribbon.MaxAutoRetriesNextServer                          |
| 更换 Feign 的客户端（池化连接对象）    | feign.okhttp（新起之秀） / .httpClient（老牌 HC），两者性能差距不大，默认为  JDK 的 HttpUrlConnection |
| 日志调用配置                           | feign.client.config.default.loggerLevel：full                |
| 拦截器配置                             | 实现 RequestInterceptor#apply()                              |
| 自定义解码器                           | 实现 feign.codec.Decoder#decode()                            |
| 降级配置                               | @FeignClient fallback：继承接口自定义 Handler，或者实现 FallBackFactory#create() |

#### 1.1.1.4. SpringBoot 自动装配和自定义 starter？

##### 1、总

Starter 是什么：
1. Starter 就是一个 jar 包，写一个 @Configuration 的配置类，把这些 Bean 的定义都包含在其中，然后在 Starter 包下的 `META-INF/spring.factories` 中写入该配置类，SpringBoot 程序在启动时，就会按照约定来加载该配置类。
2. 开发人员只需要将相应的 Starter 包依赖进应用中，然后进行相关的属性配置，就可以进行代码开发，而不需要再单独对 Bean 进行配置。

##### 2、分

原理：
1. 当启动 SpringBoot 应用时，会先创建 SpringApplication 的对象，在对象的构造方法中，会进行某些参数的初始化工作，最主要的是判断当前应用的类型（比如 Servlet 类型），以及通过 SPI 的方式加载整个应用的 `spring.factories` 文件中的初始化器和监听器的 Class。
2. SpringApplication 对象创建完成之后，开始执行 `run()` 方法，来完成整个启动，启动过程中最主要的有两个方法，第一个叫做 `prepareContext()`，第二个叫做 `refreshContext()`，在这两个步骤中完成了自动装配的核心功能，而其他方法的处理逻辑包含了上下文对象的创建、Banner 的打印、异常报告期的准备等各个准备工作，方便后续来进行调用。
3. 在 `prepareContext()` 方法中，主要完成了对上下文对象的初始化工作，包括比如 `Enviroment`对象属性值的设置，在整个过程中，有一个非常重要的方法 `load()`，`load()` 主要完成一件事，那就是将**启动类**作为BeanDefinition 注册到 Registry 中，方便后续在进行 BeanFactoryPostProcessor 调用执行时，找到对应的启动类来完成 `@SpringBootApplication` 和 `@EnableAutoConfiguration` 等注解的解析工作。
4. 在 `refreshContext()` 方法中，会进行整个容器的刷新过程，会调用 Spring 中的启动流程，即`AbstractApplicationContext#refresh()`，有 13 个关键方法，来完成整个 Spring 应用的启动，其中会调用 `invokeBeanFactoryPostProcessor()` 方法，主要是对`ConfigurationClassPostProcessor` 的处理，会先调用实现 `BeanDefinitionRegistryPostProcessor` 接口的 `postProcessBeanDefinitionRegistry()` 方法，然后再调用自己实现的 `postProcessBeanFactory()` 方法，处理各种包括 @PropertySource、@ComponentScan、@Import、@ImportResource、@Bean 等注解。
5. 其中，在解析 @Import 注解时，会有一个 `getImports()` 的方法，会从**启动类**开始递归解析注解，把所有包含 @Import 注解都收集到，然后在 `processImport()` 方法中，对 Import 导入的类进行分类，这里主要起识别作用的是 `ImportSelect` 的实现类  `AutoConfigurationImportSelect`，来调用 `selectImports()` 方法使用 SPI 的方式，来获取并加载 `spring.factories` 中的 `EnableAutoConfiguration` 自动装配配置类的 Class，完成自动装配。
6. 接着，还调用子类上下文 `ServletWebServerApplicationContext#onRefresh` 方法，来拉起嵌入式的 Tomcat 容器。
7. 最后，就是实例化 Bean，即 `finishBeanFactoryInitialization()` 方法，主要是实例化所有剩下非懒加载的单例 Bean，并完成它们的初始化和依赖注入，通过遍历所有 beanNames，然后挨个判断是走 FactoryBean 的流程，还是走 BeanFactory 的流程，其中主要步骤总结起来分为 3 步，分别是 NewInstance 实例化、Populate 属性赋值 和 Initialization 初始化，从而完成自动装配配置 Bean 的注入。

##### 3、总

自定义 Starter：

1. 创建 Starter 项目，定义 Starter 需要的 Properties 配置类，比如数据库连接信息等。
2. 然后编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean。
3. 编写 `META-INF/spring.factories` 文件，以让 SpringBoot 在启动时加载自动配置类。
4. 然后在项目中，引入自定义 Starter 的 Maven 依赖，增加对应的配置值后，然后即可直接使用。

#### 1.1.1.5. SpringMVC 请求前改写 @RequestBody 参数？

##### 1、总

有三种方法，分别是 (Filter + HttpServletRequestWrapper) + HandlerInterceptor + WebMvcInterceptorConfig、RequestBodyAdvice + @ControllerAdvice 和 Controller AOP。

| Spring MVC 请求扩展点                 | 执行顺序 | 方法                                                         | 作用                                                         |
| ------------------------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Filter                                | 1        | doFilter(ServletRequest, ServletResponse)                    | 根据 params、header 过滤非法请求、包装 HttpServletRequest，不做改写 Body |
| HandlerInterceptor                    | 2        | preHandle(HttpServletRequest, HttpServletResponse, Object)   | Handler Method 处理前拦截                                    |
| RequestBodyAdvice + @ControllerAdvice | 3        | afterBodyRead(Object, HttpInputMessage, MethodParameter, Type, Class) | HandlerAdapter#handleInternal 执行过程时解析 Method 参数     |
| Controller AOP                        | 4        | @Before、@Around                                             | point.proceed(args) 前改写 args 参数                         |

##### 2、分

###### HandlerInterceptor | 实现最麻烦

**实现最麻烦**，需要在 Filter 处添加 RequestWrapper 包装，然后在包装类里替换掉 Reader 读取的输入流，最后在 MVC 的拦截器 preHandle 实现 body 替换。

```java
@Component
public class UserFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.err.println("init");
    }

    @Override
    public void destroy() {
        System.err.println("destroy");
    }

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        ((ResponseFacade) response).addHeader("sign", request.getParameter("sign"));
        System.err.println("doFilter");
        
        // 1、结合UserBodyWrapper包装request
        chain.doFilter(new UserBodyWrapper((HttpServletRequest) request), response);
    }
}

public class UserBodyWrapper extends HttpServletRequestWrapper {

    private String body;

    public String getBody() {
        return body;
    }

    public void setBody(String body) {
        this.body = body;
    }

    public UserBodyWrapper(HttpServletRequest request) throws IOException {
        super(request);

        // 2、先读取一次输入流, 获取body内容
        this.body = IOUtils.toString(request.getInputStream(), StandardCharsets.UTF_8);
    }

    @Override
    public ServletInputStream getInputStream() throws IOException {
        ByteArrayInputStream bais = new ByteArrayInputStream(body.getBytes(StandardCharsets.UTF_8));

        // 3、以后读取输入流时, 只读取内存中的这个body
        return new ServletInputStream() {
            @Override
            public boolean isFinished() {
                return false;
            }

            @Override
            public boolean isReady() {
                return false;
            }

            @Override
            public void setReadListener(ReadListener listener) {

            }

            @Override
            public int read() throws IOException {
                return bais.read();
            }
        };
    }

    @Override
    public BufferedReader getReader() throws IOException {
        // 4、以后读取输入流时, 只读取内存中的这个body
        return new BufferedReader(new InputStreamReader(getInputStream()));
    }
}

public class UserHandlerInterceptor implements HandlerInterceptor {

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        System.err.println("preHandle");

        UserBodyWrapper userBodyWrapper = (UserBodyWrapper) request;
        String body = userBodyWrapper.getBody();
		
        // 5、获取body，改写body
        User user = JSONObject.parseObject(body, User.class);
        user.setUsername("测试添加前缀" + user.getUsername());
        ((UserBodyWrapper) request).setBody(JSONObject.toJSONString(user));
        
        return true;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        System.err.println("postHandle");
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        System.err.println("afterCompletion");
    }
}

@Configuration
public class WebMvcInterceptorConfig implements WebMvcConfigurer {

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        // 6、添加WebMvc拦截器配置类
        registry.addInterceptor(new UserHandlerInterceptor()).addPathPatterns("/**");
    }
}
```

###### RequestBodyAdvice | 时机最适合

```java
@ControllerAdvice
public class UserRequestBodyAdvice implements RequestBodyAdvice {

    @Override
    public boolean supports(MethodParameter methodParameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("supports");
        return true;
    }

    @Override
    public HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) throws IOException {
        System.err.println("beforeBodyRead");
        return inputMessage;
    }

    // 1、在 HandlerAdpater#resolveArgments 时，HttpMessageConverter读取完body后，进行回调改写body
    @Override
    public Object afterBodyRead(Object body, HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("afterBodyRead");

        JSONObject jsonObject = JSONObject.parseObject(JSONObject.toJSONString(body));
        Long id = jsonObject.getLong("id");
        String username = jsonObject.getString("username");
        String password = jsonObject.getString("password");

        try {
            Constructor constructor = ((Class) targetType).getConstructor(Long.class, String.class, String.class);
            return constructor.newInstance(id, username + "测试添加后缀", password);
        } catch (Exception e) {
            e.printStackTrace();
        }

        return body;
    }

    @Override
    public Object handleEmptyBody(Object body, HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("handleEmptyBody");
        return body;
    }
}
```

###### Controller AOP | 实现简单强大

```java
@Aspect
@Component
public class AspectJConfig {

    @Pointcut("execution(* com.jsonyao.cs.controller.*.*(..))")
    private void pointcut() {

    }

    @Around("pointcut()")
    public Object around(ProceedingJoinPoint point) throws Throwable {
        System.err.println("around");
        long start = System.currentTimeMillis();
        
        // 1、业务方法调用前，改写body
        Object[] args = point.getArgs();
        User user = User.class.cast(args[0]);
        user.setUsername(user.getUsername() + "测试AOP后缀");
        
        Object res = point.proceed(new Object[] {user});
        
        long end = System.currentTimeMillis();
        System.err.println("执行结果: " + res + ", 消耗时间: " + (end - start));
        return res;
    }
}
```

##### 3、总

综上，HandlerInterceptor  实现最麻烦，但处理位置比较通用，适合一些公共的设置，RequestBodyAdvice 回调的位置**最适合改写 @RequestBody**，适合统一对 @RequestBody 进行设置，Controller AOP 更强大，实现也简单，适合一些通用方法级别的拦截。

#### 1.1.1.6. Spring MVC 拦截器和过滤器的区别？

##### 1、总

拦截器 HandlerInterceptor，过滤器 Filter，虽然可以对请求进行一定处理，但：

1. **实现人不同**：HandlerInterceptor 属于 Spring#Web 包下，Filter 属于 Tomcat#javax 包下。
2. **配置方式不同**：HandlerInterceptor 在 Spring#WebMvcConfigurer 中配置，而 Filter 在 web.xml 中配置。
3. **处理时机不同**：HandlerInterceptor 作用更强大，方法处理前的拦截、处理后的拦截、返回前的拦截，而 Filter 则是在进入DispatcherServlet 前进行一定的请求过滤处理。

##### 2、分

![1645947452956](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645947452956.png)

Spring MVC 客户端请求的生命周期管理：

1. **Filter#doFilter** 执行链过滤客户端请求。
2. DispatcherServlet，表示中心控制器，在客户端发出请求后，经过 Web 容器（比如 Tomcat）后，会打到 DispatcherServlet 上，并由其来处理请求。
3. HandlerMapping，表示处理器映射，DispatcherServlet 收到请求后，会调用 HandlerMapping，HandlerMapping 会根据请求 url 去查找对应的 Handler，即一个 Handler Method 对象，指的是 url 对应 Controller 中的对应方法。
4. HandlerExecutionChain，表示处理器执行链，Handler 解析完 url  后，会返回一个处理器执行链给DispatcherServlet，其中就包括一堆 HandlerInterceptor。
5. HandlerAdapter，表示处理器适配器，DispatcherServlet 会按照规则去匹配对应的 HandlerAdapter。
6. 再由对应的 Handler Method 去处理请求，其中就包括调用去执行我们编写的 Controller 业务逻辑。
   - 但在执行前，会先调用 **HandlerInterceptor#preHandle** 进行  handler 方法处理前的拦截。
7. Controller 代理对象，则会去访问数据库，填充好模型后，再把 ModelAndView 返回给 HandlerAdapter。
   - 其中，在 HandlerAdpater#resolveArgments 时，HttpMessageConverter读取完 body 前/后，可以对 **RequestBodyAdvice#beforeBodyRead/afterBodyRead** 进行回调，从而改写 body。
   - 而我们平常使用的 @ResponseBoday 的方法，返回的 ModelAndView 为空，也就是不会返回视图给客户端，而是经过 `RequestResponseBodyMethodProcessor`，把 JSON 串写入到 Response 的 Body 中。
8. HandlerAdapter 收到后，再将 ModelAndView  传递给 DispatcherServlet。
9. DispatcherServlet 收到后，则调用视图解析器 ViewResolver，来解析 ModelAndView。
10. ViewResolver 会解析逻辑视图名，根据逻辑的 View 找到实例的 View，并返回给 DispatcherServlet。
11. DispatcherServlet 收到后，则根据 ViewResolver 解析出的 View，调用对应的实际视图，结合 Model 进行渲染。
    - 但在执行前，会先调用 **HandlerInterceptor#postHandle** 进行 handler 方法处理后的拦截。
12. 最后，DispatcherServlet 再将渲染后的 View 作为结果，响应给客户端。
    - 在执行后，返回结果前，会调用 **HandlerInterceptor#afterCompletion** 进行响应前的拦截。

##### 3、总

以上，就是我对 Spring MVC 拦截器和过滤器的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.7. Kafka 的高可靠保证？

##### 1、总

对于 Kafka 高可靠，需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 + `acks=all`（或者 `acks=1`）  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 `acks=all` 保证消息成功写入所有 ISR，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 ISR 机制来保证，配合生产端 `acks=all` 来保证每次写入消息，必须在 ISR 集合中的所有 Broker 写入成功后才认为消息写入成功，响应 ACK 给生产端。
3. **消费端**：通过 `enable-auto-commit=false` 关闭自动 ACK，`ack-mode=manual` 打开手工 ACK，在处理消息完毕后，才进行一次手工 ACK `acknowledgement.acknowledge()`，避免处理异常后，不能再次重复消费的情况。

##### 3、总

以上，就是我对 Kafka 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.8. RabbitMQ 的高可靠保证？

##### 1、总

与 Kafka 高可靠类似，对于 RabbitMQ 高可靠，也需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 +  `publisher-confirms=true` 以及实现 ConfirmCallback 函数开启 Broker 消息 Confirm 机制  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 Broker Confirm 机制，保证消息成功写入 Broker，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 `druable=true` 开启持久化队列 + 生产端消息设置 `deliveryMode=2` 开启持久化消息 ，来保证消息写入后，如果未被消费前，会保存在 Broker 中，防止 MQ 丢消息。
3. **消费端**：通过 `acknowledge-mode=mannul` 关闭自动 ACK，打开手工 ACK，在处理消息完毕后，才 `channel.basicAck` 进行一次手工 ACK，避免处理异常后，RabbitMQ 立即把消息删除，丢失消息的情况。

##### 3、总

以上，就是我对 RabbitMQ 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.9. JDK 的新特性、新 JVM？

| JDK 版本 | 新特性                                                       |
| -------- | ------------------------------------------------------------ |
| JDK 5    | 自动拆装箱、 Foreach 循环、枚举类、泛型、JUC                 |
| JDK 6    | 对脚本语言 Ruby、Groovvy、JS 的支持                          |
| JDK 7    | switch 支持 String，开始转移永久代，静态变量、字符串常量池转移到了堆中 |
| JDK 8    | 函数式接口，Lambda 表达式，Stream API、接口支持 default 方法、HashMap 和 ConcurrentHasMap 性能提升、元空间完全取代永久代 |
| JDK 9    | 集合添加 List.of(xxx, xxx) 等工厂方法 、接口支持 private 方法，默认使用 G1垃圾收集器 |
| JDK 10   | G1 多线程并行 Full GC，降低 G1 STW 时间                      |
| JDK 11   | 新增 ZGC，比 G1 更细粒度的内存管理，采用并行回收策略         |
| JDK 12   | 新增 Shenandoah GC 算法、优化 G1 将垃圾分为强制部分和可选部分，强制部分会被回收，可选部分可能不会被回收，提高 GC 效率 |
| JDK 13   | ZGC 优化，将标记长时间空闲的堆内存返还给操作系统，只要保证堆大小不会小于 -Xms 即可 |
| JDK 14   | 删除 CMS 、弃用  Parallel Scavenge + SerialOld 的 GC 组合、将 ZGC 应用到 MacOS 和 Win 中 |
| JDK 15   | 新增隐藏类、密封类（避免抽象类被滥用）                       |
| JDK 16   | ZGC 性能优化，此版本相当于是对 JDK 14 和 15 的一些特性进行了正式的引入 |
| JDK 17   | 正式引入密封类 sealed class，限制抽象类的实现                |

#### 1.2.1.1. JDK 8 VS JDK 7？

| JDK 8 新特性                          | 解释                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| 函数式接口，Lambda 表达式，Stream API | 在需要一个函数，但又不想费神去命名一个函数时使用，也就是匿名函数，同时，还可以把函数作为参数，传递进某个方法中 |
| 接口支持 default 方法                 | 接口的默认实现                                               |
| 元空间完全取代永久代                  | 元空间使用本地内存，永久代使用 JVM 内存，从而根本上解决了永久代溢出的问题 |
| HashMap 性能提升                      | 拉链 >= 8 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、扩容时无需重新 rehash，只需要分高低位转移链表即可、改用尾插法解决并发插入时的 CPU 100% 问题 |
| ConcurrentHasMap 性能提升             | 拉链 >= 8 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、Node+CAS+synchronzied+TreeBin 读写锁，替换掉 Segment+HashEntry+ ReentrantLock 分段锁、采用 CAS+synchronzied 实现渐进式并发扩容 |

#### 1.2.1.2. JDK 8 函数式接口的实现原理？

##### 1、总

1. 函数式接口，指**有且只有一个抽象方法的接口**，接口中的 static 方法、default 方法、Object 方法都不算抽象方法，且有个专门的注解 `@FunctionInterface`，但它不是必须的，如果接口符合以上函数式编程的语义，那么加不加这个注解都不影响，加上只是为了编译器进行检查而已，但如果不符合语义，又加上了该注解，那么编译器则会报错。
2. 有且只有一个抽象方法的原因是，由于函数式接口 ` () -> {} ` 的写法，主要是为了简化代码，相当于是一个**匿名内部类的匿名函数**，如果有多个抽象方法，编译器则不知道是重写哪个方法了，所以只能有且只有一个抽象方法。

##### 2、分

在 JDK 8 中，函数式接口主要分为 4 类，分别是**供给型、消费型、断言型和方法型**，其中它们的方法又可以和定义的 default 方法进行**连用**。

| 接口           | 方法               | 说明                                          |
| -------------- | ------------------ | --------------------------------------------- |
| Supplier< T >  | T get();           | 供给型，无参，返回一个函数返回的一个泛型对象  |
| Consumer< T >  | void accept(T t);  | 消费型，传入一个泛型对象，但没有返回值        |
| Predicate< T > | boolean test(T t); | 断言型，传入一个泛型对象，但返回 boolean 类型 |
| Function< T >  | R apply(T t);      | 方法型，传入一个泛型对象，返回另一个泛型结果  |

##### 3、总

以上就是我对 JDK 8 函数式接口的理解，它是 Lambda 表达式和 Stream API 的基础，使用这种方式来编码，既简洁又高效。

#### 1.2.1.3. 线程池核心参数，以及选取原则？

##### 1、总

对于这个问题，我打算从线程池的概念、线程复用原理、线程淘汰原理、构造参数、数据结构、生命周期、工作原理和调优原则这几个方面进行回答。

##### 2、分

1. **线程池的概念**：线程池，ThreadPoolExecutor，允许使用多个线程之一，来执行每个提交的任务，通过**线程复用**，来降低线程创建和销毁所带来的开销，同时任务到达时，可以无需等待线程的创建就能立即执行，从而提高任务的处理速度。

2. **线程复用原理**：通过设计一个**任务队列**，来承放并缓冲更多的执行任务，使得**本已存在的线程**，在处理完它们手上的任务后，可以立马从任务队列的**另一端取出执行任务**，接着继续往下执行，周而复始，从而不用每次都构建一个新的线程再执行，实现线程复用。

3. **线程池的构造参数**：但是，这种线程复用太过于简单暴力，为了让线程池稳定可控，还需要其他参数进行优化：

   - 考虑到，那些本已存在的线程应该有个上限，就需要指定一个 `corePoolSize` 核心线程数，核心线程的意思就是，默认情况下没有保活时间，不会被回收，在不超 `corePoolSize` 上限且收到新任务时会被创建。
   - 考虑到，在任务过多，核心线程处理不过来的情况，就需要指定一个 `maximumPoolSize` 最大线程数。
   - 考虑到，在任务峰值过后，非核心线程可能会空闲一段时间，但仍然占据系统资源的情况，就需要指定一个 `keepAliveTime` 非核心线程的最大空闲时间以及 `TimeUnit` 时间单位。
     - 这也是**线程淘汰**的原理所在，如果在从任务队列中取任务的时间，超过了指定的 `keepAliveTime` 还没取到任务，则可以认为队列中没有多余的任务了，也就是轮训任务队列的这个线程空闲了 `keepAliveTime` 这么久的时间，那么就要对这个线程进行淘汰处理，以节省系统资源。
   - 考虑到，任务需要装入任务队列，就需要指定一个 `BlockingQueue` 阻塞队列接口的具体实现。
   - 考虑到，在构建核心或者非核心线程时，可能需要对线程本身进行一些，比如线程名称等参数设置的情况，就需要指定一个 `ThreadFactory` 的具体实现。
   - 考虑到，任务队列和最大线程都超上限，即线程池超负载时，任务还源源不断到来的情况，就需要指定一种 `RejectedExecutionHandler` 的具体实现，来执行相应的拒绝策略逻辑。

4. **线程池的数据结构**：

   - 根据以上分析，可以容易得到，如果构建一个好点的线程池，就至少需要持有核心线程数、最大线程数、非核心线程的最大空闲时间、任务队列、线程工厂、拒绝策略程序的引用。
   - 另外，JDK 在实现方面，还抽象了一个 `Worker` 类，通过使用 `Worker` 自己持有的 `Thread` 实例，在轮训任务队列时进行任务消费。
   - 同时还持有了一个 `AtomicInteger` 原子类型的 `ctl  ` 线程池控制位，来管理线程池的生命周期及有效线程的数量。

5. **线程池的生命周期**：线程池控制位 ctl，JDK 把 Integer 的高 3 位作为**线程池的状态**，低 29 位作为**有效线程的数量**，前者一个存在 5 种状态，规定：

   -  **-1 为 RUNNING 运行态**，此状态下能够接收新提交的任务，同时还能处理任务队列中的任务。
   -  **0 为 SHUTDOWN 关闭态**，此状态下不会再接受新提交的任务，但还可以继续处理任务队列中的任务。
   -  **1 为 STOP 停止态**，此状态下不会再接收新提交的任务，也不能继续处理任务队列中的任务，并且还会尝试中断正在处理任务的线程。
   -  **2 为 TIDYING 整理态**，此状态下所有的线程都已终止了，此时有效工作数量为 0。
   -  **3 为 TERMINATED 终止态**，在 TIDYING 整理态回调完 `terminated()` 钩子函数以后，会进行此状态。

   ![1645968027493](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645968027493.png)

6. **线程池的工作原理**：

   1. 首先根据线程控制位 `ctl`，判断当前有效线程数是否小于设定的核心线程数，如果是小于，那么就可以把当前任务作为首个任务 `firstTask`，去**创建核心线程**并执行任务。
   2. 如果发现超出了核心线程数，或者并发下核心线程创建失败了，那么就在检查完线程池还在运行状态后，就尝试**把任务投递到任务队列中**。
   3. 如果任务投递成功，则还要做线程池状态的双重检查，防止线程池突然被关闭，如果发现线程池确实不再是运行态了，那么就需要把刚才投递成功的任务给取出来，再**执行拒绝策略程序**；而如果发现还是运行态，则视有效线程数量是否为 0，来决定是否需要**补充非核心线程**，以保证任务队列中的任务不会永远停留在内存中。
      1. 注意这里**补充非核心线程**的操作，它可以保证 `corePoolSize=0 & maximumPoolSize > 0` 且任务队列还没达到上限时，仍能生成 1 个非核心线程去消费任务队列，避免队列内存溢出的发生，关于这里的细节就可以说说我们的一段生产事故了~
      2. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
      3. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
      4. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
      5. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
      6. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。
   4. 如果任务投递失败了，则**尝试补充非核心线程**，如果因为线程池不是为运行态，或者超出了最大核心线程数，导致非核心线程补充失败的话，那么就需要**执行拒绝策略程序**，因为此时要么是 SHUTDOWN 关闭状态不能接受新任务了，要么就是任务队列满了需要拒绝添加新任务了。

   ![1645967491556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645967491556.png)

7. **线程池的调优原则**：

   - **线程池大小的设置**：需要先确定任务的类型，分为 CPU 密集型、IO 密集型以及混合型的任务：

      | 类型       | 概念                                                         | 目的                                                         | 合理的经验公式                                               |
      | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | CPU 密集型 | 任务需要大量的运算，中间没有阻塞，CPU 一直全速运行           | 需要尽可能少的线程数量，以减少线程上下切换的次数，提高 CPU 的利用率 | CPU 核数 + 1                                                 |
      | IO 密集型  | 任务大量时间都花在 IO 的阻塞上，希望 CPU 尽可能去调度其他任务，而不是在等待阻塞的线程、浪费 CPU 资源，所以需要更多的线程数以供 CPU 调度 | 需要尽可能多的线程数，但过多的线程也会带来过多的上下文切换   | CPU 核数 * 2                                                 |
      | 混合型     | 既有 CPU 密集型的特点，又有 IO 密集型的特点                  | 需要看平均线程等待时间，和平均线程运行时间，来决定对应的线程数，可通过 Github#PoolSize Calculator 工具类进行粗略的计算 | CPU 核心数 * 目标 CPU 利用率 * （1 + 平均线程等待时间 / 平均线程运行时间），可见，平均线程等待时间越长，平均线程运行时间越短，则需要的线程就越多 |

      => 但这些只是经验公式，最优的参数还需要根据实际环境不断压测、调优才能得到。

   - **任务队列的设置**：控制任务队列容量，实际上就是在考量**内存占用**和**任务的排队策略**，常用的阻塞队列实现有：

      | 实现类              | 特性                                                         | 排队策略   | 优点                                                         | 缺点                                                         |
      | ------------------- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | SynchronousQueue    | 无界同步队列，容量为 0，不存储任何元素，每个插入操作都会阻塞等到另一个线程进行相应的删除操作才会恢复（利用 CAS 自旋 + LockSupport 方式实现阻塞） | 直接交接   | 最小的内存花销                                               | 当任务到达速度大于处理速度时，如果搭配无界池，可能会出现无限线程增长的问题 |
      | LinkedBlockingQueue | 单向链表有界阻塞队列，容量可选，空参构造时为 Integer.MAX_VALUE，相当于无界队列 | "无界"队列 | 核心线程繁忙时，任务会在队列中排队，适合用于平滑瞬间爆发的流量 | 如果任务到达速度大于处理速度，可能会导致任务队列元素无限增长，占用较大的内存花销 |
      | ArrayBlockingQueue  | 数组有界阻塞队列，初始时必须先指定容量大小，一旦指定，就不能再修改了 | 有界队列   | 与最大线程数一起使用，可以防止资源被耗尽                     | 任务队列初始化好了后，就难以再动态的调整和控制了             |

   - **拒绝策略程序的设置**：当线程池被关闭，或者任务队列和线程都已经饱和时，新提交的任务会走到拒绝策略程序的处理逻辑中，默认的拒绝策略程序都是定义在 ThreadPoolExecutor 的内部类中：

      | 实现类              | 特性                                                         | 适用场景                                                     |
      | ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | AbortPolicy         | 默认的拒绝策略程序，在任务被拒绝时，会抛出 RejectedExecutionException 异常 | 可以阻止系统正常运行下去                                     |
      | CallerRunsPolicy    | 调用 Runnable#run，当前主线程会自己去运行任务                | 不会造成任务的丢失，可以让线程池有一定的缓冲时间             |
      | DiscardPolicy       | 任务会被简单的丢弃掉                                         | 允许任务丢失时，这是最好的一种丢弃策略                       |
      | DiscardOldestPolicy | 丢弃任务队列头部的任务，然后重新执行一开始的工作流程         | 会丢弃最老的一个任务，也就是可能马上就被执行的任务，然后重新提交当前任务 |

##### 3、总

以上，就是我对线程池核心参数及原理的一个理解，请问有什么细节需要补充的吗？

#### 1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？

##### 1、总

分布式锁指的是，在不同的系统或者同一个系统的不同主机之间，共享访问某个资源时，用来互斥地防止彼此干扰保证一致性的锁实现，其实现方式有：

- **基于数据库实现**：通过乐观锁，或者唯一索引实现。
- **基于分布式缓存实现**： 典型的有，通过 Redis 实现。
- **基于分布式一致性算法实现**：典型的有，通过 ZK 实现。

##### 2、分

###### 1）基于数据库实现 | 负担大

- **基于乐观锁实现**：原理是，根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。
- **基于唯一索引实现**：原理是，在表上建立唯一索引，当想要获得锁时，向表中插入一条记录，释放锁时则删除这条记录。
  - **缺点**：
    1. **锁没有失效时间**，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
    2. **不可重入**，同一线程在没有释放锁之前无法再获取到锁。

###### 2）基于分布式缓存实现 | 锁失效

- **基于 Redis 单机实现**：使用 `SET NX EX` 指令加锁，保证**原子性**地给锁设置**过期时间，防止死锁**，使用 LUA 脚本 `redis.call` 指令，保证 key 值判断与删除键指令原子性执行，且防止由于 STW 时间过长，锁被其他进程误删。

  - **缺点**：会出现由于**时钟漂移** 或者 任务执行时间过长，导致的锁被提前释放的问题。
- **基于 Redisson 实现**：它是一个 Redis 的客户端，其分布式锁的实现原理是，让获得锁的线程开启一个定时守护线程，每隔 expireTime / 3 的时间就去检查一下，该线程持有的锁是否还存在，如果存在，则对锁的过期时间重新设置为 expireTime，完成守护线程对**锁的续约**，防止锁由于过期提前释放。

  - **缺点**：这些只是在 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 是**异步复制**的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下，发生了故障转移，那么其他客户端上的线程依然可以获取到锁，丧失了锁的安全性。

- **基于 RedLock 算法实现**：红锁算法的原理是，

  1. 先获取当前时间 `t1`，然后按顺序依次尝试从 n 个 Redis 实例，使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁的失效时间 `expire`，还应该设置超时时间 `timeout`，且这个超时时间 **<** 锁的失效时间 `expire` ，这样可以避免 Redis 已经挂掉的情况下，客户端不用一直等待响应结果，而是尽快地去尝试另外一个 Redis 实例来获取锁。
  2. 客户端通过使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从过半数（N/2+1 个）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` **<** 锁失效时间 `expire` 时，锁才算获取成功，如果获取到了锁，那么 key 的真正有效时间 `real_expire` 等于锁失效时间 `expire` **减去**锁花费的总时间 `T`。
  3. 如果获取锁失败，客户端则应该在所有的 Redis 实例上使用 **Lua 脚本进行解锁**，原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端到服务器的通信是正常的，但反方向却是有问题的，虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功，因此，释放锁时，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起解锁请求。

  - **缺点**：
    1. **性能过重**：使用 RedLock 需要维护那么多的 Redis 实例，提升了系统的维护成本。
    2. **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生回调，则会导致它持有的锁提前过期释放，还是不能保证锁的安全性，这个是基于时间来实现自动释放的分布式锁，都无法解决的问题。

###### 3）基于分布式一致性算法实现 | 强一致

基于 ZK 实现：可以利用**顺序临时节点**的特性，结点在创建时，会自动在结点名后加一个数字后缀，以保证有序，同时，如果客户端连接失效，则还会立即删除结点，再利用 **watcher 监视器**的特性，注册某个结点的监视器，当节点状态发生改变时，watcher 被触发时，ZK 会向客户端发送一条通知。其分布式锁的实现原理是，

1. 创建一个锁目录 lock，希望获得锁的线程 A 在 lock 目录下，将创建**顺序临时结点**。
2. A 先获取锁目录下所有的子结点，判断是否存在序号比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则线程 A 获得锁。
3. 当另外一个线程 B 获取锁时，判断到 B 自己不是最小的结点，存在有更小的线程 A 结点，则设置  watcher 监听器，只监听比自己**次小**的结点 A。
4. 当线程 A 处理完业务后，会删除结点 A，释放掉分布式锁，然后线程 B 监听到节点状态变更事件后，判断自己已经是最小的结点了，则成功获得锁。

##### 3、总

以上就是我对分布式锁一些实现方案的理解，总结一下就是，

- **基于数据库实现**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：但这样会增加数据库的负担。
- **基于分布式缓存实现**：
  - **优点**：属于 AP 模型，性能高，实现起来较为方便，在允许偶发性的锁失效情况发生，不影响系统正常使用时，可以采用分布式缓存来实现锁。
  - **缺点**：通过过期时间实现的锁超时机制不是十分可靠，当业务必须要数据的**强一致性**，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下，就不能使用分布式缓存来实现锁了，此时可以使用 CP 模型来实现，比如 Zookeeper。
- **基于分布式一致性算法实现**：
  - **优点**：不依靠过期时间来释放锁，可靠性高，当系统要求高可靠性时，可以采用分布式一致性算法来实现锁。
  - **缺点**：性能比不上分布式缓存实现的锁，因为 ZK 需要频繁的创建和删除结点。

#### 1.2.1.5. Redis 数据结构？

##### 1、总

对于这个问题，我打算先介绍 Redis 对象 `RedisObject`，

1. 其数据结构包含一个 4 字节的 `type` 对象类型属性，分为 STRING、HASH、LIST、SET 和 ZSET。
2. 一个 4 字节的 `encoding` 对象编码属性，包括 INT、EMBSTR、RAW、HT、LINKEDLIST、ZIPLIST、INTSET 和 SKIPLIST。
3. 以及一个 `ptr` piont 指针，指向底层实现的数据结构。

然后我再按照上面所说的对象类型（String、Hash、List、Set、ZSet）按顺序进行介绍。

##### 2、分

###### 1）String

1. 首先是 String，常见的 API 有， SET、SET NX EX、GET、APPEND、STRLEN、SETRANGE、GETRANGE、MSET、MGET、INCRBY、DECRBY 等命令，适合存储帖子、评论、热点数据等缓存，其底层的数据结构分为 3 种编码，分别为 INT、EMBSTR 和 RAW：

2. **INT**：只能存储 long 类型的整数，`ptr` 指针指向对应的整数值。

   ![1631946982581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631946982581.png)

3. **EMBSTR**：（< 3.2 版本时）在字符串值小于等于 39 字节时会使用此编码，其优点是，它是对 `SDS` 的一个小优化，通过将 `RedisObject` 对象头和 `SDS` 存放在一起，采用**连续空间保存**，只需要一次内存分配，避免了它们各自进行空间分配，提高了字符串的内存分配效率，同时还可以减少内存碎片和 `ptr` 指针的占用，节约内存，提高空间的利用率。

   - `SDS`：是 Redis 自己实现一个字符串数据结构，通过持有 `len` 来标识字符串长度，`free` 来记录空闲字符的个数，`buf` 则指向真实的字符数组，能够在 O（1）内获取字符串长度，具有空间预分配、惰性释放内存，以减少分配次数的特点。

   - **缺点**：EMBSTR 是**只读**的形式，要修改时，只能转换为 RAW 编码，才能进行修改。

   ![1631878253168](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878253168.png)

4. **RAW**：（< 3.2 版本时）在字符串值大于 39 字节时会使用此编码，`ptr` 指针指向一个 `SDS` 数据结构，也就是以 `SDS` 的形式存储，主要为了解决长度计算和追击字符效率的问题。

   ![1631947051873](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631947051873.png)

###### 2）Hash

1. 然后就是 Hash，常见的 API 有，HSET、HGET、HEXSITS、HDEL、HLEN、 HSTRLEN、HINCRBY、HMSET、HMGET、HKEYS、HVALUES 等命令，适合存储结构化的对象数据，其底层的数据结构分为 ZIPLIST 和 HT。

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 HASH 取值时，可以通过**向后或者向前遍历**找到对应的键和值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631950146881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950146881.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631950298985](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950298985.png)

###### 3）List

1. 接着就是 List，常见的 API 有：LPUSH、LPOP、RPUSH、RPOP、LREM、LINSERT、LSET、LINDEX、LRANGE、LTRIM、BLPOP、BRPOP、RPOPLPUSH、BRPOPLPUSH，适合用作评论列表、商品列表、发布与订阅等功能，其底层的数据结构分为 ZIPLIST、LINKEDLIST 和 QUICKLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 LIST 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631952569099](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952569099.png)

3. **LINKEDLIST**：双向链表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，它是 Redis 自己实现的一条双向链表，包含头节点、尾结点、前驱和后继，可以很方便的进行向后或者向前遍历，同时持有 `len` 长度计数器，可以 O（1）内获取到 LIST 的长度 。

   - **缺点**：每个节点都有自己的前后指针，指针这部分所占用的内存较多，且每个节点是单独进行内存分配，当节点过多时，造成的内存碎片会比较多，影响内存管理的效率。

   ![1631952812216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952812216.png)

4. **QUICKLIST**：快速列表，大于 3.2 版本后，LIST 统一采用此格式进行存储，是 ZIPLIST 和 LINKEDLIST 的混合体，它将 LINKEDLIST 按段切分，每一段使用 ZIPLIST 来紧凑存储，多个 ZIPLIST 之间使用双向指针串接起来，缓解了 LINKEDLIST 指针内存浪费和内存碎片多的问题，同时解决 ZIPLIST 数据量过大时导致的性能变差问题。

   - **缺点**：ZIPLIST 节点太小的话（比如只存 1 个元素时），快速列表会退化成普通的链表，起不到应有的节省内存的作用，而 ZIPLIST 节点太大的话（比如只有一个 ZIPLIST 节点时），快速列表会退化成压缩列表，还是会出现数据量过大时导致的性能变差问题。
   - 因此，快速列表内部默认定义的单个 ZIPLIST 节点大小为 `8k 字节`，可以由参数 `list-max-ziplist-size` 来控制，其作用是，在分配结点时，如果发现当前 ZIPLIST 节点超过了这个大小，则会重新分配一个 ZIPLIST 节点。

   ![1631953074136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631953074136.png)

###### 4）Set

1. 再然后就是 Set，常见的 API 有：SADD、SPOP、SREM、SRANGMEMBER、SISMEMBER、SCARD、SMEMBERS、SINTER、SINTERSTORE、SUNION、SUNIONSTORE、SDIFF、SDIFFSTORE，适合用于求交集、并集、差集，比如朋友关系，其底层的数据结构分为 INTSET 和 HT 编码。 

2. **INTSET**：整数集合，（< 3.2 版本时）只存储 long 范围内的整数值，且在元素个数 < 512 个时会使用此编码，持有对应整数的编码类型 `encoding` 总是使用容纳数字的**最小编码进行存储**，以节约内存、集合元素数量 `length` 可以在 O（1） 内获取到对应长度、以及元素使用数组  `contents`  来进行**连续存储**，可以减少内存碎片和指针内存的占用，以节约内存。

   - **缺点**：编码类型只能升级不能降级，在大数字删除后，整数集合还是会使用大类型存储小数字，造成空间的浪费。

   ![1631954240528](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954240528.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631954355626](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954355626.png)

###### 5）ZSet

1. 最后就是 ZSet，常见的 API 有：ZADD、ZREM、ZSCORE、ZINCRBY、ZRNAGE（指定偏移，score 从小到大，分数相等，则再按值顺序排序）、 ZRERANGE（指定偏移，score 从大到小，分数相等，则再按值逆序排序）、ZRNAGEBYSOCRE（指定分数）、 ZRERANGEBYSOCRE（指定分数）、ZRANK、ZRERANK、ZCARD、ZCOUNT（区间个数统计） 等命令，可以在去重后进行排序，适合排名的场景，其底层的数据结构分为 ZIPLIST、SKIPLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 **128** 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 ZSet 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631954526032](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954526032.png)

3. **SKIPLIST**：（< 3.2 版本时）在元素大小大于等于 64 字节且元素个数大于等于 **128** 个时会使用此编码，由跳跃表 + 哈希表来实现，通过在有序链表上维护每级 25% 概率生成的索引，从而达到 O（logn）访问元素的目的，通过累加查找路径中的 `SPAN` 跨度，来计算当前节点所处的排名，通过哈希表存储跳跃表节点，以实现在 O（1）内完成根据名称找到对应的得分。

   - **缺点**：由于新节点插入的 LEVEL 是随机的，导致老节点的查找路径可能发生变化，**缓存友好性不如**红黑树，而红黑树则是插入新节点后，大部分老节点仍然处于原查找路径上。
   - **为什么 Redis#ZSet 使用跳跃表而不是红黑树**？
     1. **范围查找效率高**：
        1. 对于 `ZRANGE` 和 `ZREVRANGE` 命令的范围查找，如果使用哈希表，则只能做单值查找，不适合做范围查找。
        2. 如果使用红黑树，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]，效率低且实现复杂。
        3. 而使用 skiplilst 只需要 O（logn）定位头尾结点，然后遍历链表即可，简单又高效。
     2. **内存占用少**：Redis skiplist 索引的默认生成概率为 25%，即每个结点平均只包含 **1.33** 个指针，内存占用比红黑树的 2 个指针要少。
     3. **实现与调试容易**：使用 skiplist 比红黑树更容易实现与调试。

   ![1631955510770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955510770.png)

##### 3、总

以上就是我对 Redis 常用数据结构的一些理解，请问还有什么细节需要补充的吗？

#### 1.2.1.6. 提升技术的方法？

1. **看视频**：入门。
2. **做实验**：踩坑。
3. **看源码**：找答案。
4. **看书**：系统性总结。

#### 1.2.1.7. 技术不足的地方？

某些技术缺乏实际场景应用，久而久之细节就忘却了，以及有许多知识点学完了，但没做系统性整理，比如 ES、Docker、K8S 这些。

#### 2.1.1.1. 项目自我介绍？

##### 1、自我介绍

面试官你好，我叫姚超松，2019 毕业于广东工业大学，读的是电子信息工程专业，毕业时秋招进了美的集团的美云智数事业部，的供应商部门，主要工作内容是负责功能模块的全栈开发，以及架构的优化。

下面我打算以时间倒序的方式，介绍一下我的项目经历：

1. 第一个，也是最近在做的一个项目是，美的集团的 GSRM 产品，也就是供应商关系管理，包括寻源、资质审查、现场评审、供方生效、退出、失效、画像等业务，技术的话用到了 SpringCloud 来拆的微服务，Sharding JDBC 和 MySQL 做的分库分表，中间件的话用到了 Redis 和 Kafka ，以及 MongoDB 做的一个接口日志收集，我在里面主要负责迭代现场评审模块，和供应商画像模块，以及一些外部接口对接的工作。
2. 再往前一点的话，就是一个自研的 Sass 产品，包括抽象了美的 QMS 业务的品质云，抽象了 MES 业务的进销存云，抽象了 SRM 业务的 SRM 云等等，技术的话，重构之前用到的是一个 SpringBoot 做的应用，数据库用的是 MySQL，中间件的话用到了 Redis 和集团的 ESB 企业总线，我在里面主要负责品质和进销存的需求开发，和数据中台的建设，以及后期品质云 SpringCloud 微服务的落地。
3. 再往前的话，就是推广到比亚迪的一个外部产品的迭代，在 SRM 2.0 的基础上级为 SRM 3.0，主要是增加了服务和资产类的交付、验收、结算等业务，技术的话，用到了 SpringMVC + Dubbo 做的应用，数据库用的是 Oracle，中间件的话用到了 Redis 和 RabbitMQ，我在里面主要负责交付单模块的开发，以及和云平台接口对接的工作。 

以上，就是我的自我介绍，请问有什么细节需要补充的吗？

##### 2、项目细节

###### 1）GSRMC

1. **微服务模块**：

   | 模块名 | 模块业务 | 备注                                                         |
   | ------ | -------- | ------------------------------------------------------------ |
   | BASE   | 基础数据 | 字典、物料、采购分类、研发分类等主数据                       |
   | POS    | 生命周期 | 寻源、资质审查、现场评审、供方生效、信息变更、黑名单管理、质保金管理、供方退出、失效等供应商主数据 |
   | PERF   | 考核绩效 | 供方送货不合格、交期、品质、服务考核 -> 考核会影响绩效（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | QUO    | 比例管理 | 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | BID    | 集采招标 | BID 招标定价，给物料定价 -> 一揽子价格                       |
   | PRICE  | 价格管理 | 生效之后，研发工程师在 PLM 分解POM，核价员估价，给定价做参考、线下定价以及BID 招标定价，给物料定价 -> 一揽子价格 |
   | CON    | 电子合同 | 电子合同模块，签署框架协议，合作时要遵守的规则               |
   | -      | -        | 还有ESB 交易数据、JOBS/TASK 定时任务、MIP 审批流程、SYNC 数据同步、INDEX 指标工作台等非核心业务模块 |

2. **主要业务流程**：

   1. 研发工程师在 PLM 根据业务，创建新物料 ITEM，跟 SRM 的采购分类进行关联。
   2. 然后选定采购分类和需求图纸等信息，在供应商库中做**寻源匹配**。
   3. 寻源完毕后，送样到供应商 GSC 进行初步**估价**。
   4. 然后 SRM 根据**资质**和价格进行筛选。
   5. 筛选通过后，PLM 进行试用，SRM 对供应商生产环境进行**现场评审**。
   6. 评审通过后生成供应商品类 ASL，此后就可以按照比例进行批量供货了。
   7. 其中， SRM 可以对供方送货不合格、交期、品质、服务等进行考核 -> 考核会影响**绩效**（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配**比例**（也叫配额） -> ERP根据比例决定供货数量。
   8. 送货完毕后，SRM 需要对品类进行**核价**，包括招标转定价、意向价、直接定价、线下议价等方式。
   9. 最后走价格审批，把价格同步到 ERP，每月 25 号对上个月进行结算。

   => 总的来说，SRM 就是负责供应商从生到死的生命周期管理，以及物料价格和供货数量管理，也就是寻源到生效、需求到生产、定价到付款三个方向的业务。

3. **主要用到的技术组件**：

   | 组件                    | 作用                                                         | 部署           |
   | ----------------------- | ------------------------------------------------------------ | -------------- |
   | Vue + I-View            | 前端                                                         | 8 Apache       |
   |                         | 负载均衡                                                     | F5、Nginx      |
   | SpringCloud             | Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Zipkin 做链路追踪，Config 做配置中心、Stream+Bus 做消息驱动 | 126 应用服务器 |
   | Sharding JDBC + MyBatis | Sharding JDBC 分表，MyBatis ORM 映射                         | 126 应用服务器 |
   | MySQL                   | 数据库                                                       | 8 主 8 从      |
   | MongoDB                 | 文档数据库                                                   | 3 主备         |
   | Redis、Redisson         | 缓存中间件                                                   | 3 主备 + 哨兵  |
   | Kafka、ZK               | 消息中间件                                                   | 3 集群架构     |

4. **分表与分片规则的设置**：

   | 分表                   | 数据量     | 表注释             | 数据库 | 分片规则               |
   | ---------------------- | ---------- | ------------------ | ------ | ---------------------- |
   | srm_sys_items_submeter | 3280.19 w+ | 物料表             | BASE   | ${organization_code}   |
   | srm_sys_item_cates_sub | 1613.38 w+ | 物料采购分类关系表 | BASE   | ${organization_code}   |
   | srm_sys_item_keycs     | 2153.11w+  | 物料研发分类关系表 | BASE   | ${organization_code}   |
   | srm_po_receive_det     | 3.0813 E+  | 采购接收表         | PRICE  | ${period_month / year} |
   | srm_po_line_locations  | 1.0220 E+  | 一揽子价格表       | PRICE  | ${bu_code}             |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 126 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块           | 数量              | CPU           | 内存               | 硬盘  |
   | -------------- | ----------------- | ------------- | ------------------ | ----- |
   | 前端 Apache    | 8                 | 4 C           | 16 G               | 50 G  |
   | Eureka         | 3                 | 1 C           | 1 G                | 10 G  |
   | BASE           | 13                | 8 C           | 16 G               | 100 G |
   | POS            | 19                | 8 C           | 16 G               | 100 G |
   | PERF           | 7                 | 8 C           | 16 G               | 100 G |
   | QUO            | 6                 | 8 C           | 16 G               | 100 G |
   | BID            | 3                 | 8 C           | 16 G               | 100 G |
   | PRICE          | 13                | 8 C           | 16 G               | 100 G |
   | CON            | 6                 | 8 C           | 16 G               | 100 G |
   | ESB            | 5                 | 8 C           | 16 G               | 100 G |
   | JOBS           | 9                 | 8 C           | 16 G               | 100 G |
   | TASK           | 5                 | 8 C           | 16 G               | 100 G |
   | MIP            | 4                 | 8 C           | 16 G               | 100 G |
   | SYNC           | 5                 | 8 C           | 16 G               | 100 G |
   | INDEX          | 3                 | 8 C           | 16 G               | 100 G |
   | 其他模块       | 25                | 8 C           | 16 G               | 100 G |
   | MySQL          | 16（8 主 8 从）   | 32 C          | 128 G              | 3 T   |
   | MongoDB        | 3                 | 8 C           | 16 G               | 500 G |
   | Redis          | 3                 | 8 C           | 32 G               | 100 G |
   | Kafka          | 3                 | 8 C           | 16 G               | 100 G |
   | 报表导出 OSS   | 文件数： 500 / 天 | 数据量：10 G  | 增长量：300 M / 天 | -     |
   | 供应商附件 OSS | 文件数：10 w / 年 | 数据量：200 G | 增长量：200 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

   `gc.log`：

   ![1648004562016](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648004562016.png)

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

###### 2）云化项目

1. **微服务模块**：（品质云）

   | 模块名 | 模块业务     | 备注                                                |
   | ------ | ------------ | --------------------------------------------------- |
   | BASE   | 基础数据模块 | 字典、IDM 用户、权限、系统附件、企业、客户、组织等  |
   | OEM    | 代工生产模块 | OEM 供方成品下线、抽检、出库等                      |
   | APP    | 综合模块     | SPC 过程检验，PQC  半成品检验、OQC 成品出货检验等   |
   | JOBS   | 定时任务模块 | 包括数据中台、PSI、QMS、GSC、GSRM、MES 等的数据同步 |

2. **品质云主要业务流程**：

   1. 供方原材料上线，MES 进行来料检测后，会走到各制程工序。
   2. 在每个制程工序的 CTQ 品质关键点上，会进行相应的 SPC 过程检验。
   3. 然后，还在工序的检验岗位上，进行对应的 PQC 半成品检验。
   4. 最后，在成品准备入库出货前，则进行 OQC 成品出货检验。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，还需要进行对应的彩箱、大箱、地台板条码的绑定操作后，才能进行后面的入库出货操作。

   => 总的来说，品质云就是实时管控供方生产的**品质质量**。

3. **进销存云主要业务流程**：

   1. 接收到 GSC 供应商门户 的采购订单，就在进销存为供方生成对应的销售订单。
   2. 然后根据物料 BOM 信息，生成后续的生产订单。
   3. 在生产前，获取原材料时，可以直接在原材料仓进行扣减，也可以发起原材料的采购订单，进行补充原材料。
   4. 在生产完工后，会创建生产入库单，把成品送入成品仓，更新供方成品库存。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，品质会把彩箱、大箱条码传入进销存，进销存再做对应的地台板绑定、销售出库、以及推送物流平台。

   => 总的来说，进销存就是用来实时管控供方的**库存情况**。

4. **数据中台主要业务流程**：数据中台，主要承担物料、ASL、寻源品质进销存的一些统计工作。

5. **主要用到的技术组件**：

   | 组件             | 作用                                                         | 部署         |
   | ---------------- | ------------------------------------------------------------ | ------------ |
   | Vue + Element UI | 前端                                                         | 8 Nginx      |
   |                  | 负载均衡                                                     | F5、Nginx    |
   | SpringCloud      | 微服务拆分后，Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Skywalking+ELK 做链路追踪，Config 做配置中心，Gateway 做服务网关 | 应用服务器   |
   | SpringBoot       | 微服务拆分前，还是单体应用                                   | 3 应用服务器 |
   | MyBatis          | MyBatis ORM 映射                                             | 3 应用服务器 |
   | MySQL            | 数据库                                                       | 1主          |
   | Redis、Jedis     | 缓存中间件                                                   | 3 主 3从集群 |

6. **表数据量**：

   | 分表                        | 数据量    | 表注释         | 系统 | 分片规则               |
   | --------------------------- | --------- | -------------- | ---- | ---------------------- |
   | qc_oem_order_line           | 1200 w+   | 成品下线表     | QC   | 手工按日期分片备份旧表 |
   | qc_oqc_item_standard_value  | 1500 w+   | 物料抽检标准表 | QC   | 手工按日期分片备份旧表 |
   | oem_external_mes_colorcode  | 722.26 w+ | MES 条码表     | QC   | 无分片                 |
   | psi_base_packing_relation   | 315.28 w+ | 箱包关系表     | PSI  | 无分片                 |
   | psi_prd_pallet_box_relation | 250.03 w+ | 板箱关系表     | PSI  | 无分片                 |
   | psi_base_barcode            | 314.67 w+ | 下线条码表     | PSI  | 无分片                 |
   | psi_sales_stock_out         | 840.58 w+ | 销售出库表     | PSI  | 无分片                 |
   | cloud_gsrm_item             | 38.61 w+  | 物料表         | DC   | 无分片                 |
   | cloud_gsrm_asl              | 31.63 w+  | ASL 物料表     | DC   | 无分片                 |
   | mcc_company_info            | 1321      | 企业统计表     | DC   | 无分片                 |
   | mcc_deliver_receive_sum     | 2.24 w+   | 企业下线出库表 | DC   | 无分片                 |
   | mcc_order_quotation_sum     | 342       | 企业寻源报价表 | DC   | 无分片                 |

7. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 14 个服务。
   - **数据库**：监控显示，16 C、64 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 3                | 4 C          | 16 G              | 50 G  |
   | Eureka           | 3                | 1 C          | 1 G               | 10 G  |
   | BASE             | 3                | 8 C          | 16 G              | 100 G |
   | APP              | 3                | 8 C          | 16 G              | 100 G |
   | OEM              | 3                | 8 C          | 16 G              | 100 G |
   | JOBS             | 2                | 8 C          | 16 G              | 100 G |
   | MySQL            | 1 主             | 16 C         | 64 G              | 3 T   |
   | Redis            | 6                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

8. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

###### 3）比亚迪 SRM

1. **微服务模块**：

   | 模块名 | 模块业务       | 备注               |
   | ------ | -------------- | ------------------ |
   | APP    | 前端控制器模块 | Controller，6 台   |
   | MID    | 业务处理模块   | Service，7 台      |
   | RPORT  | 报表模块       | 报表导出，6 台     |
   | NGINX  | 前端模块       | WEX5、Jquery，2 台 |

2. **主要业务流程**：

   1. 定时同步云平台 SAP 需要的基础信息，比如采购订单、采购金额、采购数量等到 SRM，按照履行模板和规则，生成相应的履行计划和付款计划。
   2. 通过履行计划触发，生成交付、验收、结算对应节点的订单与待办信息，通知对应的责任人进行审批或者验收。
   3. 通过迁移线下交付单到线上，完成各类的无纸化交付，交付单审批通过后，会推进下一个节点的履行计划和付款计划。
   4. 通过付款计划触发，生成发货款、到货款、调试款、验收款、上线款、完工款等多种款项的待办，通知对应的责任人进行审批或者结算。

   => 总的来说，就是通过交付单推进履行计划和付款计划，来数字化线下供方结算与付款流程。

3. **主要用到的技术组件**：

   | 组件                | 作用             | 部署          |
   | ------------------- | ---------------- | ------------- |
   | JQuery + Element UI | 前端             | 2 Nginx       |
   |                     | 负载均衡         | 2 Nginx       |
   | Spring MVC + Tomcat | 后端应用         | 19 应用服务器 |
   | MyBatis             | MyBatis ORM 映射 | 19 应用服务器 |
   | Oracle              | 数据库           | 1 主          |
   | Redis、Jedis        | 缓存中间件       | 3 主备 + 哨兵 |
   | RabbitMQ            | 消息中间件       | 3 镜像集群    |

4. **表数据量**：

   | 分表          | 数据量     | 表注释              | 系统   | 分片规则 |
   | ------------- | ---------- | ------------------- | ------ | -------- |
   | SAP_CDHDR     | 6.39 E+    | PO 单增量表         | 云平台 | 无需分片 |
   | SAP_EKPO      | 4019.80 w+ | PO 行表             | 云平台 | 无需分片 |
   | SAP_ZMMSSBM03 | 1544.27 w+ | PO 描述表           | 云平台 | 无需分片 |
   | SAP_EKKO      | 1147.68 w+ | PO 币种表           | 云平台 | 无需分片 |
   | SAP_ZEKKO     | 965.70 w+  | PO 寻源表           | 云平台 | 无需分片 |
   | PR / PO       | 1948.13 w+ | 采购需求 / 采购订单 | SRM    | 无需分片 |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 21 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 2                | 4 C          | 16 G              | 50 G  |
   | APP              | 6                | 8 C          | 16 G              | 100 G |
   | MID              | 7                | 8 C          | 16 G              | 100 G |
   | RPORT            | 6                | 8 C          | 16 G              | 100 G |
   | Oracle           | 1                | 32 C         | 128 G             | 3 T   |
   | Redis            | 3                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

##### 3、项目亮点

| 系统       | 亮点清单          | 关键词                                                       |
| ---------- | ----------------- | ------------------------------------------------------------ |
| GSRMC      | PLM 配套接口      | Around 切面注解、Kafka + MongoDB 、MD5  + AES、多线程 + Future、Redis、Jmeter |
|            | 供应商画像同步    | 缓存型线程池、工厂 + 建造者 + 责任链、EsJob + Kafka + MongoDB、线程池调优 |
|            | 线程池调优        | 线程池源码、调优原则                                         |
|            | 死锁问题排查      | 意向锁、间隙锁、可重复读、并发                               |
|            | 内存溢出排查      | MAT、POI、ArrayList                                          |
| Sass 产品  | 条码销售出库      | Druid 监控、SQL 调优、Redis                                  |
|            | 品质云微服务拆分  | SpringCloud                                                  |
|            | 校验失败问题      | 分布式锁、QMS Client Json 对比、问题排查                     |
| 比亚迪 SRM | 大文件上传        | FastDFS、Redis List                                          |
|            | 邮件发送组件      | 线程池 + RabbitMQ + 定时任务                                 |
|            | 发版平台 CPU 过高 | Tomcat Manager、ELK、CPU 95%                                 |

STAR 法则，是情境（Situation）、任务（Task）、行动（Action）、结果（Result）四项的缩写，是一种讲述自己故事的方式，或者说，是一个清晰、条理的作文模板，合理熟练运用该法则，可以轻松的描述事情的逻辑方式，表现出分析与问题的逻辑性、条理性和逻辑性。

1. Situation：情境，本次事件是在什么情况下发生的。
2. Task：任务，在本次事件中，主要负责什么任务。
3. Action：行动，在本次事件中，针对这些情况的分析，采用了什么样的行动。
4. Result：结果，本次事件最后的结果是怎么样的，以及学到了什么。

| 举例 | 内容（大一辩论比赛获得冠军）                                 |
| ---- | ------------------------------------------------------------ |
| S    | 系里一共有 5 支队伍，实例...，我们小组...                    |
| T    | 熟悉辩论流程，掌握辩论技巧，获得系冠军                       |
| A    | 自己主动整理资料，组织小组学习流程，编制训练题，小组训练，根据每个人的特点，分配任务（要尽量详细，包括当中遇到的困难是什么，怎么解决的） |
| R    | 获得系辩论赛冠军                                             |

###### 1）PLM 配套接口 | 分表、并发、Redis

1. **背景 Situation**：供应链体系管理专员反馈，他们在 PLM 建送样申请单时，由于物料配套没有**自动匹配**，导致经常选错配套人员，然后就要撤回、修改、重新提交，影响业务流程效率。

2. **任务 Task**：所以他们希望在 PLM 上，根据物料就可以**自动匹配** SRM 品类分工中的**配套专员信息**，方便他们走业务流程。

3. **行动 Action**：

   1. 接口的实现逻辑大体是这样的，根据 ITEM_CODE + ORG_CODE 找对应分表的采购分类，找不到就根据 ITEM_CODE 找全部库存组织分表的采购分类，再找不到的话就认为要去查物料试用表了，以当前作为试用 P 编码找到对应转正后的编码，然后重走一遍上面逻辑，找到后就合并按照 BU_CODE + 特征名称 + 特征值 + 研发分类 ID，查找研发分类中的采购分类，然后根据采购分类查找品类分工表中的配套人员信息，去重后返回即可。

      ![1644903196224](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644903196224.png)

   2. 接口实现比较复杂，其中需要优化的点有：

      - 1）第一，接口日志要做统一的收集。
      - 2）第二，接口要做安全性校验。
      - 3）第三，接口要查询所有的库存组织的采购分类分表。
      - 4）第四，接口需要频繁按照 ORG_CODE 查找 BU_CODE。

4. **结果 Result**：所以我当时优化的手段就是：

   - 1）第一，写了一个 Around 类型的切面注解，对公共的日志收集逻辑进行了提取，然后把收集到的日志投递到 Kafka 中，再由消费者插入到 MongoDB，这种做法的好处是，使得日志收集逻辑解耦了业务代码，同时异步收集的话经过测试，对比同步插入还有一定的性能提升。
   - 2）第二，安全性校验这边统一采用的是 MD5 对整个请求体生成摘要，SRM 需要重新生成一遍，然后与传过来的比对是否一致，一致才认为请求体没被修改过，然后再根据缓存中的 AES 秘钥进行解密，得到真正的请求 JSON 串。
   - 3）第三，使用线程池多线程并发的方式，查询每个采购分类分表，通过 FutureTask 监听汇总所有的采购分类编码，对比串行查询有一定的性能提升。
   - 4）第四，由于 ORG_CODE 与 BU_CODE 是那些不怎么会改变的数据，所以通过使用了 Redis 对这些关系进行了远端缓存（使用 Guava Cache 重启可能会导致缓存雪崩，且数据量过大还会占用应用内存，本身也才 2 G，所以放 Redis 中，虽然增多了一次 I/O 这也是可以接受的），使得多次请求只会获取一次库存事业部关系，对比批量查询时有一定的性能提升。 

###### 2）供应商画像同步 | 架构、设计模式、Kafka

1. **背景 Situation**：
   1. 业务方需要一个页面，可观地展示出供应商各维度的一个画像，包括抬头展示它的**基本信息**，词云浓缩它的**肖像标签**，动画展示它自美的引入以后所走的一些**历程**，对接天眼查展示对应它的一些企业经营风险，柱状图展示它历年的**招投标**、**红黄牌**以及**采购金额**的数量，折线图展示它历年的**考核**和**绩效**的趋势，饼图展示它的**分级**和**供货编码**的占比情况，用来横向、纵向辅助对比找出优质供方。
   2. 允许数据延迟，可以每隔 15 天同步一次。
2. **任务 Task**：这样，要做的东西就有，在 TASK 模块的定时任务触发时，要一一查找每家供应商的 POS 供方生命周期库的基本信息、红黄牌、获奖以及供货编码信息，查找 BID 招标库的历年招标信息，查找 PERF 考核绩效库的历年考核、绩效以及分级信息，查找 PRICE 价格库的采购金额信息，对接天眼查找告警风险，最后再根据规则组装出要展示的肖像标签。
3. **行动 Action**：当时有几种方案，
   - 1）第一种就是，1 个定时器，负责同步所有供应商的上述所有维度的信息，优点是实现简单，不用做其他的架构设计，缺点是如果同步实现的话一个事务完成所有工作，任意一处异常则全局回滚，如果异步实现的话，由于是单点触发定时任务，还是会有单台机器负担过重的问题。
   - 2）第二种就是，10 个定时器，每个定时器只负责同步所有供应商的某个维度的信息，优点是可以分为 10 台机器分别触发定时，避免了单台机器负担过重，缺点是一个定时器一个事务，还是会出现任意一处一处则全局回滚，以及定时器过多，管理麻烦。
   - 3）第三种就是，1 个定时器 + 分布式消费，定时器只负责找出要生成画像的供应商编码，封装成消息，扔到 Kafka 上，自己不负责画像的生成，而是交给消费者去进行处理，消费者每次消费一个消息，相当于生成一个供应商的画像，这样做的好处就是，定时逻辑和画像生成逻辑解耦，1 个定时器即可完成任务，要管理维护的地方少，然后就是，画像生成的效率取决于 Partition 和机器的数量，能够充分利用集群多实例部署的优点，还有就是，即使某次供应商画像生成失败了，可以不进行手工 ACK，下次再从 Kafka 里拿消息出来进行重复消费即可。
4. **结果 Result**：所以，当时就采用了第三种方案，在实现时又有几个优化点：
   - 1）第一就是，还是没能解决由于一个供应商所有维度处于同一个事务，出现异常时的全局回滚问题，解决方案就是，通过线程池的方式异步实现，每个线程一个事务，只完成一个维度的信息同步，这样即使某个回滚了也不影响全局。
   - 2）第二就是，由于一共有 10 个维度的信息要同步，就需要 10 个 Callable 任务给线程去执行，所以就抽象了公共的接口。
   - 3）第三就是，由于任务较多，所以就采用了工厂 + 建造者 + 责任链来串联式地组织任务，而且到了后期，由于是责任链的组织方式，就可以根据业务组合出很多种画像的同步方案出来，体现了灵活性。
   - 4）第四就是，由于任务与任务间，经常有重复的信息要查询，所以就对这个接口分为了同步式实现和异步式实现的抽象类，业务只需要继承抽象类实现对应的业务即可，同步式实现主要是为了在一开始给执行链设置公共上下文，避免重复查询，异步式实现则是交给线程池去执行，在要拿那些”重复“信息时只需要去上下文中获取即可。
   - 5）第五就是，某次消费异常，也就是执行链中某个节点异常，其堆栈信息需要对其进行合理记录，方便后面排查问题，解决方案就是，通过如果有任务异常后，那么就收集放到执行链上下文中，返回时再统一地打包成对象，存放到 MongoDB 上。
   - 6）最后，这样设计和实现，用 Kafka + 线程池，保证了分布式高性能消费，用 Kafka + 异常时不手工 ACK 来重复生成画像，保证可靠性，用 MongoDB 记录异常日志，保证异常排查的便捷性。

###### 3）线程池调优 | 线程池、源码、调优

1. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
2. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
3. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
4. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
5. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。

###### 4）死锁问题排查 | 间隙锁、可重复读、并发

1. **背景 Situation**：在现场评审优化了一版上线后，DBA 反馈说，POS 数据库因为有大量死锁，导致数据库不断地重启，并且也把问题的 SQL 给发了出来，是一条删除语句导致的：

   ```sql
   DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3;
   ```

2. **任务 Task**：然后我们很快就定位到代码，找到了以下逻辑：方法传入一个 `List<DTO>`，先是获取第一行的  locale_review_id `${localeReviewId}`，对满足 locale_review_id= `${localeReviewId}` 的都进行删除，完成删除后，再批量插入 locale_review_id= `${localeReviewId}` 的 `List<DTO>` 数据：

   ```java
   int flag=0;
   Long localeReviewId=new Long("1");
   for (AuditEvidenceDto auditEvidenceDto : list) {
       if (auditEvidenceDto.getEvidenceId()!=null){
           flag=1;
           localeReviewId=auditEvidenceDto.getLocaleReviewId();
       }
   }
   HashMap<String,Object>params =new HashMap<>();
   if (flag==1){
       params.put("localeReviewId",localeReviewId);
       params.put("categoryCode",list.get(0).getCategoryCode());
       params.put("reviewType",list.get(0).getReviewType());
       auditEvidenceService.deleteFlag(params);
   }
   if(!"Y".equals(list.get(0).getAttribute1())){
       list.sort(Comparator.comparing(AuditEvidenceDto::getFileType));
       auditEvidenceService.batchInsertAuditEvidence(list);
   
   }
   ```

3. **行动 Action**：

   1. 对于这种写法，首先，在代码里做业务逻辑操作，肯定是不对的，当时事态紧急，也没有做过多的分析，最直接的解决思路就是，找到对应的同事，让他把 Controller  `delete` 和 `insert` 操作都放入一个 Service 中，用同一个事务管理，做一个紧急发版看下能否解决。

   2. 发了新版后，好像问题是解决了，但是结合 `show engine innodb status`，就分析出在并发场景下，还是会死锁的问题，步骤是：

      1. 先在表中先插入几条数据，然后给 locale_review_id 加普通索引（而在表全新，且没有数据时，有没有索引都会加一个行 X 锁，然后也会出现下面的情况）。
      2. 然后，事务 1 对 locale_review_id=3 的记录进行删除，则会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁。
      3. 同理，事务 2 再对 locale_review_id=3 的记录进行删除，也会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁，由于间隙锁不冲突，所以事务 2 不会等待。
      4. 接着，事务 1 再插入  locale_review_id=3 的记录时，由于已经存在事务 2 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
         - 在插入行之前，会设置一种称为**插入意图的间隙锁**，表示插入的意图，即如果插入到同一索引间隙中的多个事务未插入到间隙内的同一位置，则它们无需相互等待，是不冲突的。
         - 而如果发生重复键错误，则会在重复索引记录上设置**共享锁**，并且如果另一个会话已经拥有排他锁，那么如果有多个会话尝试插入同一行，则使用共享锁可能会导致**死锁**，比如说后面分析的那种情况。
      5. 同理，事务 2 再插入  locale_review_id=3 的记录时，由于已经存在事务 1 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
      6. 此时，就发生了死锁，即事务 1 持有间隙锁，同时等待事务 2 的间隙锁，事务 2 也持有间隙锁，同时等待事务 1 的间隙锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 2 的事务，让事务 1 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      ```sql
      -- 使得 show engine innodb status; 能展示锁的信息
      set GLOBAL innodb_status_output_locks=ON;
      -- 查看事务锁持有情况
      show engine innodb status;
      ```

      | 步骤 | 事务 1                                                       | 事务 2                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |
      | 3    |                                                              | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |
      | 4    | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 5    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); |
      | 6    |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    | 插入成功                                                     |                                                              |

   3. 所以，这种方案也不是万全之策，然后我们重新考虑新的方案，其思路是打算先把一开始的死锁给复现出来，再做解决方案的分析。

   4. 不久后，场景就被模拟出来了，那是 `delete` + `insert` 在不同事务中导致死锁的发生，具体的步骤是：

      1. 事务 1 执行删除，但未提交，由于 locale_review_id=3 的记录已经存在，所以在 locale_review_id=3 行上了排他锁，此时该行的主键 ID 也是等于 3，即 ID=3。
      2. 然后，事务 2 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 2 进入等待。
      3. 同理，事务 3 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 3 也进入等待。
      4. 接着，事务 1 提交，ID=3 的行记录被标记为删除状态（这些标识为删除状态的记录，会后续由后台的 Purge 操作进行物理删除，但是，此时还是会在索引中存放一段时间），ID=3 上的排他锁被释放。
      5. 然后，事务 2、3 就成功抢到了共享锁，打算执行插入操作，由于已经存在事务 3 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 2 进入等待。
      6. 同理，由于已经存在事务 2 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 3 也进入等待。
      7. 此时，就发生了死锁，即事务 2 持有共享锁，同时等待事务 3 的共享锁，事务 3 也持有共享锁，同时等待事务 2 的共享锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 3 的事务，让事务 2 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      | 步骤 | 事务 1                                                       | 事务 2                                                       | 事务 3                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; TRANSACTION;                             | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |                                                              |
      | 3    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 4    |                                                              |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |
      | 5    | COMMIT;                                                      |                                                              |                                                              |
      | 6    |                                                              |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    |                                                              | 插入成功                                                     |                                                              |

   5. 面对以上的分析情况，解决方案有两个，第一个方案是，在后面批量插入前，先把 ID 给置为 NULL，利用自增机制去设置 ID，避免两个 `insert` 语句同时插入同一个位置，但问题是，`delete` 在释放排他锁后，两个 `insert` 语句都会执行成功，会比正确结果多出来一条记录，所以此方案放弃。

   6. 第二个方案是，把 `delete` + `insert` 的操作，转换为 `update` 操作，则可以避免上述死锁的发生，通过。

4. **结果 Result**：最后我们就是通过第二个方案，把这段有问题的代码，又重新优化了一遍，解决了这种死锁的问题。

###### 5）内存溢出排查 | MAT、POI、ArrayList

1. **背景 Situation**：生产的一台 POS 服务器宕机了，由于配置了 `-XX:+HeapDumpOnOutOfMemoryError`，所以崩溃时导出了对应的 hprof 文件。

2. **任务 Task**：导入 hprof 到 MAT，分析应用崩溃的原因。 

3. **行动 Action**：

   1. MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，一个 Tomcat 的线程使用了 78.58% 的堆大小，共 1.2 GB。

      ![1646412309344](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646412309344.png)

      ![1646413204478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413204478.png)

   2. 然后，查看 List Objects -> with outgoing references，观察一个占据了 22.68% 内存的 ArrayList 的保留集，发现它引用了 27.69 w 个元素，估计是某个 SQL 查了太多元素导致。

      ![1646413486175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413486175.png)

   3. 所以，就继续查看堆栈信息，定位问题代码，是一个 Service 实现类的 `setData()` 方法。

      ![1646413368891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413368891.png)

   4. 原来，是调用了 Controller 的 `downloadItemDailyCapacityTemplate()` 方法，看了下业务含义，大概的意思是，在导出日常产能预测模板时，由于把产能表每日信息的查询结果，放入到了上面所说的那个 27.69 w 个元素的 ArrayList 中，然后再遍历这个列表，调用 POI#API 在内存中生成 excel，但由于堆内存只配置了 `-Xmx=2048m`，所以导致了内存溢出！

      ![1646413877943](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413877943.png)

4. **结果 Result**：因此，解决方案是，持有这么大的 ArrayList 时，不应该把 excel 还写入内存中，而是遍历过程中，先把 excel 一点一点写入到磁盘，释放掉这个 ArrayList 后，再读取磁盘的 excel 文件的字节流，写入到 response 输出流中，或者直接扩大堆内存大小 `-Xmx=4096m `，从而解决堆内存溢出的问题。 

###### 6）自研 DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源

1. **背景 Situation**：生产 JOBS 模块，采购金额汇总导出接口报错：同一线程不允许切换数据源读写类型，定位到报错的代码位置，发生在 `@DataSource` 自研注解，的管理器 `DataSourceClusterManager` 中的一个段逻辑代码上：

   ```java
   private static final ThreadLocal<DataSourceThreadInfo> dataNodeInfo = new ThreadLocal();
   
   public static void set(String nodeName, boolean readOnly) {
       if (StringUtils.isBlank(nodeName)) {
           nodeName = getDefaultNode();
           if (StringUtils.isBlank(nodeName)) {
               throw new RuntimeException("系统未配置缺省数据节点");
           }
       }
   
       DataSourceThreadInfo nodeInfo = (DataSourceThreadInfo)dataNodeInfo.get();
       if (nodeInfo != null) {
           if (!StringUtils.equals(nodeName, nodeInfo.getNodeName())) {
               throw new RuntimeException("同一线程不允许切换数据源");
           } else if (readOnly != nodeInfo.isReadOnly()) {
               throw new RuntimeException("同一线程不允许切换数据源读写类型");
           }
       } else {
           dataNodeInfo.set(new DataSourceThreadInfo(nodeName, readOnly));
       }
   }
   ```

2. **任务 Task**：分析逻辑代码就可以知道，是因为在设置注解属性 `readOnly` 时，发现和已有的 `readOnly` 不等，比如 `true != false`，然后就想到是存储这些属性的 `ThreadLocal` 变量，在上一次使用完的线程，没清除掉这些变量，就被下一个接口复用了，从而导致的问题发生，经过各种实验，也证明了确实是这个原因。

3. **行动 Action**：

   1. 至于问题的解决，首先还是看发生问题的业务代码，它把一些查询封装成了 Lambda 表达式，然后调用了数据源切换工具类的方法，丢给线程池去执行。

   2. 问题就在于这个 Lambda 表达式中，比如先调用 `DataSourceThreadInfo.set("srmpos"，true)`，然后调用 mapper 接口查询数据库，最后在却没有在释放掉线程本地变量，导致另一个接口复用这个线程时设置 `DataSourceThreadInfo.set("srmpos"，false)` 报错。

   3. 然后，查找了整个系统这些问题代码，发现很多都没作释放的，此时最好的方案要么是 AOP，要么是代理。

   4. AOP 的话，由于没有很好的一个切点表达式，因为如果只找那些打了 `@DataSource` 注解的 service 或者 mapper，那么就会漏掉一些直接 `DataSourceThreadInfo.set(..)` 设置的，这也正是为什么之前配了 `DataSourceAfterAspect` 切面，还是会发生这个问题的原因所在，所以这个方案放弃。

      ```java
      @Aspect
      @Component
      @Order(0)
      public class DataSourceAfterAspect {
          /**
           * 数据源处理完后清理
           * @param joinPoint
           */
         @After("@within(com.midea.mcomponent.mybatisplus.datasource.DataSource) || @annotation(com.midea.mcomponent.mybatisplus.datasource.DataSource)")
          public void after(JoinPoint joinPoint) {
              DataSourceClusterManager.clean();
          }
      }
      ```

   5. 代理的话，可以在切换工具类的 `queryMethod.query(params)` 方法调用后，通过在 `finally` 中实现线程本地变量的释放。

      ```java
      //  baseNode 数据源 线程池
      public static <V> Future<V> executeSrmBaseQuery(QueryMethod<V> queryMethod, Object... params) {
          return executeSrmBase.submit(() -> {
              try {
                  return queryMethod.query(params);
              } finally {
                  DataSourceClusterManager.clean();
              }
          });
      }
      ```

4. **结果 Result**：最终，发版测试，没问题后上线，最终解决问题。

###### 7）条码销售出库 | 索引调优、生产问题

1. **背景 Situation**：OEM 供应商反馈，系统响应扫码速度过慢，专门用手机计时，记录延迟有 4.55 s，扫码枪扫完一整板的货，系统才开始对异常条码报错，导致如果一板出现问题条码的话，就需要这一整板重新扫过，才能找出问题条码，影响了供方出货的效率。

2. **任务 Task**：当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，根据视频中的操作速度，大概是 4~5 个 / 1s，所以也就是并发数为 5 * 2 = 10 的 QPS，分摊到 3 台服务器的话，每台服务器需要让接口满足 300 ms 以下的延迟，因此，在不增加服务器的情况下，尽量让接口的延迟足够低。

3. **行动 Action**：根据供方提供的截图，找到对应的接口，然后在测试环境模拟跑一遍接口，把接口路过的 SQL 日志都收集起来，统一分析，最终发现有几处索引是没有添加的，分别是：

   1. **psi_base_barcode**：条码表，314.67w+，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 1000 ms 左右，优化后 Druid SQL 监控显示 35 ms 左右。

      ```sql
      ALTER TABLE psi_base_barcode ADD INDEX psi_base_barcode_n2(CUS_COMPANY_CODE, PRODUCT_CODE);
      ```

   2. **psi_base_packing_relation**：箱包关系表，315.28w，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 650 ms 左右，优化后 Druid SQL 监控显示 32 ms 左右。

      ```sql
      -- 4、判断条码是否已出库：增加【CARTON_BARCODE】和【BARCODE】索引有提升
      SELECT COUNT(1)
      FROM psi_sales_stock_out
      WHERE (CARTON_BARCODE = '331100007920401110191W' OR BARCODE = '331100007920401110191W');
      ```

   3. **psi_sales_stock_out**：已出库条码表，840.58w，16 c 64 G MySQL，优化前 Druid SQL 监控【执行时间】显示  2290ms 左右，优化后 Druid SQL 监控显示 40 ms 左右。

      ```sql
      -- Add Index： explain => index_merge，Using union(psi_sales_stock_out_n1,psi_sales_stock_out_n2); Using where
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n1(CARTON_BARCODE);
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n2(BARCODE);
      ```

4. **结果 Result**：最终通过使用 Druid 监控，发现关键 SQL 的耗时已经满足要求了，psi_base_barcode 提效 96.51%，psi_base_packing_relation 提效 95.08%，psi_sales_stock_out 提效 98.25%。

###### 8）品质云微服务拆分 | 微服务、架构、设计

1. **背景 Situation**：

   1. 当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，不能停线的那种，此时如果品质这块有新需求要发，就需要工厂停线，等我们发版、验证通过了才能继续生产，对于大家来说其实都不好。
   2. 而且，由于是单体， OEM 生产功能与其他零部件供方的 SPC、PQC、OQC 的代码统统在一块，导致系统的负载比较高，常常是能看到 3 台服务器，每台 CPU 和内存都过 60%，有时遇到生产高峰以及定时器触发的话，会出现半夜电话报障说，应用宕机了，需要紧急重启的情况。

2. **任务 Task**：所以出于上面说的诉求，以及加上对未来供方不断上线，当时就规划了对各单体云，进行微服务拆分，共用一个注册中心和配置中心，其中就由我来负责品质云的微服务落地。

3. **行动 Action**：

   1. 我这边拆了 4 个业务模块（2 个月左右），分别是 BASE 基础数据模块，主要是一些字典、用户权限、企业、客户、组织等基础业务。
   2. OEM 代工生产模块，也就是上面所说的主要诉求点，包括成品下线、抽检、出库等业务，把这块生产线相关的业务剥离出去，可以做针对性的优化以及灵活的发版处理。
   3. 而剩余的其他业务，都统统放 APP 综合模块，与单体时的业务基本保持不变，主要是零部件供应商的 SPC 过程检验、PQC 半成品检验、OQC 成品出货检验等业务。
   4. JOBS 定时任务模块，则是后来继续剥离的一个模块，剥离这个模块可以保证生产高峰期时，在夜间也能平滑运行，不会受到大量定时器触发，导致的负载突然增高的影响，主要是一些与外围系统数据同步等业务的处理。

4. **结果 Result**：中间遇到的难点有：

   - 1）**服务的依赖边界问题**：

     1. 在拆分时，一开始我是直接把下线扫码、抽检、出库给拆开，SPC、PQC、OQC 也都拆开，然后就发现拆得粒度过小，出现了很多相互的依赖调用，就又要去考虑，如何代价尽可能小地，去避免带来新的分布式事务和性能问题。
     2. 而最后，是根据业务诉求，以及拆分后的风险与成本的评估，才认为最好的方案应该是，下线扫码、抽检、出库这三个生产线相关的业务合回一个 OEM 模块，其他的 SPC、PQC、OQC 等不是本次诉求的业务又合回一个 APP 模块。

   - 2）**Feign 远程调用时，遇到的响应结果被统一包装的问题**：

     1. 一开始单体时的系统，是有对响应结果做 `Result` 统一包装的，其原理是实现了 `HandlerMethodReturnValueHandler#handleReturnValue()` 方法，这是在 `invocableMethod.invokeForRequest()` 方法处理完 Handler Method 并拿到结果后，调用 `this.returnValueHandlers.handleReturnValue` 对返回结果进行的一个后置处理。

        ```java
        // 统一包装
        public class ResponseBodyWrapperHandler implements HandlerMethodReturnValueHandler {
        	@Override
        	public void handleReturnValue(Object returnValue,
        			MethodParameter returnType, ModelAndViewContainer mavContainer,
        			NativeWebRequest webRequest) throws Exception {
        		_logger.info("return data is " + returnValue);
        		if (returnValue instanceof Void) {
        			returnValue = Result.DefaultSuccessResult;
        		} else {
        			if (!(returnValue instanceof Result)) {
        				returnValue = Result.build(true, ResultCode.SUCCESS_CODE, "", returnValue);
        			}
        		}
        		handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);
        	}
        }
        ```

     2. 这个包装主要是为了打印原始的响应结果，以及自定义 `retCode` 响应码和 `retMsg` 响应语，但在使用 Feign 调用后，就出现，如果使用那边 Controller 的方法返回值类型，作为这边 Fegin 接口的返回值类型，则收到的就只是一个 null，因为中间做了一层 `Result` 的包装，此时需要对其进行解码，解码的话是实现了 `feign.codec.Decoder#decode()` 方法，通过注入并使用`com.fasterxml.jackson.databind.ObjectMapper` 进行读取 body 并修改，从而实现包装的统一解码工作，避免了在业务代码中，写过多的包装解码代码。

        ```java
        // 自定义Feign解码器
        @Component
        class FeignResultDecoder implements Decoder {
        
            @Autowired
            private ObjectMapper objectMapper;
        
            @Override
            public Object decode(Response response, Type type) throws IOException, DecodeException, FeignException {
                if (response.body() == null)
                    throw new DecodeException(response.status(),  "接口没有返回有效的数据, url: " + response.request().url(), response.request());
        
                // 解析body, 得到统一包装Result实例
                Result result = objectMapper.readValue(Util.toString(response.body().asReader(Util.UTF_8)), Result.class);
                if (ResultCode.ERROR_CODE.equals(result.getRetCode()))
                    throw new DecodeException(response.status(), "接口返回错误: " + result.getRetMsg() + ", url: " + response.request().url(), response.request());
        
                // 重新解析Result#data实例并返回
                return objectMapper.readValue(objectMapper.writeValueAsString(result.getData()), TypeFactory.defaultInstance().constructType(type));
            }
        }
        ```

   - 3）**网关路由问题**：由于主要是后端进行的微服务拆分，前端基本保持不变，所以就需要在收到请求后，对原始 url 进行截断，找到对应的关键字进行服务路由，当时采用的是 Gateway 做了服务网关，其好处就是高性能、对开发友好，只需要在代码中更改路由规则即可 、以及对接注册中心，服务地址不需要经常在网关上配来配去。

   - 4）**过滤器问题**：单体时的过滤器是实现 `javax` 包下的 `Filter` 类来实现的，主要是对一些 token 做校验、给上下文设置当前用户信息等操作，但由于 Feign 调用使用的是 HTTP 请求，也会经过这一层层的 `Filter` 校验，在有了服务网关后，就在网关上做了前置的过滤，主要是实现 `GatewayFilter` 和 `GlobalFilter` 接口来完成对应的过滤，这样，服务间调用就无需走那一层层的 `Filter` 校验了，只需要在网关中被校验一次即可，从而保证远程调用时的性能问题。

###### 9）token 校验失败问题 | 分布式锁、QMS Client Json 对比、问题排查

1. **背景 Situation**：OQC 零部件供方在成品出货报告新建完毕后，需要把报告推送给 QMS，在接口联调时没有问题，但放到生产上就偶尔能推得过去，偶尔推不过去，导致供方有些成品无法继续出货，货物堆在了仓库外面，需要马上解决这个问题。
2. **任务 Task**：
   1. 根据日志记录，推不过去的原因是，品质这边的客户端，收到了 QMS 的一个异常返回结果 `token校验失败`，这就很奇怪了，token 如果校验失败的话，那么为什么有时候能够成功呢，不应该一直都是失败的吗？
   2. 然后就翻了日志，与 QMS 收到的 token 进行比对，发现确实是 token 的问题。
   3. 这个 token 呢，是根据 DTO 对象转成 json 字符串后，使用内存中 QMS 的一个序列号 `appSec` 进行 MD5 加盐，生成摘要而得到的，由于其他参数都是写"死"的，也就是问题出在，用于生成摘要的 DTO 对象与传输过去的 DTO 对象不一致！
3. **行动 Action**：
   1. 然后，我扒出了有问题的推送报文，与 QMS 收到的报文进行对比，用了在线 Json 比对工具 `www.bejson.com`，结果放入后就明显看到，QMS 收到了多余的 `NULL串` ，从而造成两边生成的 token 不同。
   2. 果然，看回代码就发现，发送给 QMS 的 json 串和用于生成摘要的 json 串的生成逻辑不一样，前者是交给 `forest.httpClient` 做 json 转换，而后者是直接用了 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 和 `ObjectMapper#writeValueAsString()` 做的生成。
   3. 在这个工具类里，ObjectMapper 实例作为成员变量，如果先调 ``ObjectMapper#writeValueAsString()` 填充好了 NULL 序列化器，那么这个 ObjectMapper 每次都会输出 `NULL串` ，而如果先调的是 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 设置了普通序列化器，那么这个 ObjectMapper 每次都不会输出 `NULL串`，这也是为什么 token 时对时不对的原因所在。
   4. 所以，解决方法就是，在工具类中分开两者的使用，持有一个生成 `NULL串` 的 ObjectMapper，再持有一个生成正常串的 ObjectMapper，在生成 token 时使用后者，从而解决 token 不正确的问题。
4. **结果 Result**：最后，再使用分布式锁做一个单点定时，每隔 3 分钟把推送失败的报告重新推送过去，并设置 3 次的最大重推次数，保证这个推送接口的可靠性，和业务的连续性。

###### 10）大文件上传 | FastDFS、Redis List

1. **背景 Situation**：在建广告类交付单时，要求上传大视频，以让审批人去浏览理解当前交付的广告内容。

2. **任务 Task**：当时系统文件存储用的是 FastDFS，主要是用来存储中小文件，比如用户头像、图片、附件等内容，对文件大小也是做了 200 M 的限制，当时如果要实现大视频的话，一来文件接收上限要放宽，违反了组件用来上传小文件的约定，二来，会有大文件不能续点上传的问题，所以最直接的思路就是，对上传过来的文件进行分片上传，接收到所有分片后再合并成进行大文件存储，具体的做法是：

3. **行动 Action**：

   1. 前端方面，用的是 WebUploader 组件对文件进行分片，其原理是，在获取到文件后，先计算它的一个 MD5 文件摘要，然后对其按照每 200 M 作为一个 chunk 分片，并使用序号顺序标记每个 chunk，再调用后端提供的一个接口进行上传。
   2. 后端这边，接口则接收文件名、文件 MD5 摘要值、有无分片、最大分片号、当前分片号、MultipartFile，以及一些其他辅助信息，接收到后，先是用 MD5 判断当前这个大文件是否曾经上传过，如果上传过就不再处理了，再判断 MD5 + 分片号是否存在了，存在则不再处理了，从而解决即使分片报文重复，或者前一次中断然后本次重新上传的问题，实现续点上传。
   3. 然后，调用框架 API 保存好分片，这个框架主要是对FastDFS 做了封装，把文件存到特定的位置，然后返回文件存储对象的元数据。
   4. 接着，把【分片号 + 文件ID 】顺序放入用的 MD5 值做 key 的 Redis List 中。
   5. 最后，在收到最后一个分片时，则取出 Redis 中的所有【分片号 + 文件ID 】，对分片号做一次排序，从而解决分片不按顺序到达的问题，再顺序合并所有分片成为一个大文件，调用框架 API 保存好这个大文件，拿到它的元数据存储到文件关系表中，这样，下次在下载时，则可以根据文件 ID 找到当时的元数据，再去拿存储服务器上对应路径下的大文件即可，从而完成一次大视频文件的上传和下载。

4. **结果 Result**：总的来说，就是用了 WebUploader 前端组件进行文件分片，后端则是共用同一个接口，先对分片进行缓存，然后再顺序合并成大文件，解决大文件续点上传的问题。

   ![1646294342544](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294342544.png)

   ![1646294375795](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294375795.png)

###### 11）邮件发送组件 | 设计、RabbitMQ

1. **背景 Situation**：交付单触发待办提醒时，需要发送邮件通知对应的责任人进行处理，此时需要对接比亚迪的一个邮件服务器，进行邮件发送。
2. **任务 Task**：由于邮件发送不需要非常的及时，所以就采用了异步发送的发送，以提高性能。
3. **行动 Action**：
   1. 当时采用的方案是异步发送，接口把邮件对象丢给线程池，就返回响应客户端其他信息了，再由子线程去把邮件落库。
   2. 然后定时触发，捞取对应未发送和发送失败的邮件，进行批量发送，直连式地把消息发送到一个 `SCC_COMMON_EXCHANGE` 的 `SCC_MAIL_QUEUE` 的队列中，在收到 Broker ACK Confirm 后，则标记为发送成功，否则继续被下轮定时器触发捞取出来重新发送。
   3. 最后，由比亚迪那边的消费者进行消费，发送到邮件服务器中，完成异步邮件发送。
4. **结果 Result**：基于上述的方案，我封装了一个异步邮件发送工具类，在每次遇到需要异步发送邮件时，则调用那个工具类的对应方法即可，既方便，又解耦了业务代码，然后还拥有不错的性能。

###### 12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%

1. **背景 Situation**：我们团队这次的迭代，需要在云平台开发几个接口，然后在和 SRM 联调测试时，为了不用等比亚迪 SAP 测试环境的发版窗口，就需要有我们自己的一个云平台测试环境，方便快速发版快速验证。

2. **任务 Task**：那时由我负责来负责搭建，但由于是在内网环境进行开发，访问不了外网，就拉取不到 Jenkins 的依赖，当然也没有云原生这些基础设施，所以采取了 Tomcat Manager + ELK 部署的方式来发版，前者是 Tomcat 的后台，可以开发完代码后导出 war 包，然后在浏览器上把 war 包进行上传部署，后者是用于在 Kibana 上观察接口的异常日志。

3. **行动 Action**：

   1. 就这样，一个简单易用的发版平台就搭建好了，不过没几天问题就来了，我们发现每一次上传 war 包到启动完成，所花的时间好像都会比上一次的要久，最后一次 war 包上传则是浏览器一直在转了。

   2. 当时为了不阻塞测试进度，就到发版平台的服务器上看，先是使用 `top` 命令看到 118243 的 Tomcat 进程，居然占用了 95.3% 的 `%CPU`：

      ![1646305025603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305025603.png)

   3. 然后使用 `top -Hp 118243 ` ，查看 Tomcat 进程的所有线程，发现最高的一个线程 `118332` 占用了 73.3% `%CPU`：

      ![1646305182797](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305182797.png)

   4. 然后使用 `printf %x 118332`，获取对应的 16 进制线程号，用于后面的 jstack 文件搜索：

      ![1646305395917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305395917.png)

   5. 然后就是 `jstack -l 118243 > thread-dump.txt `，导出对应 `118243` 进程的线程快照，打开搜索对应的 `1ef96` 16 进制线程号（这个是当时真实的线程号，上面是后期模拟的） ，就定位到了一堆 `ParallelGC` 线程，原来是 GC 太多而导致的 CPU 飚高，那么为什么一个发版的 Tomcat，会有这么多 GC 线程呢？会不会是项目代码哪里写的有问题啊？

      ![1646305627751](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305627751.png)

   6. 然后我就使用 `jmap -dump:format=b,file=heap-dump.hproft 118243`，以 `hprof` 格式导出 `118243`  Tomcat 进程的堆内存快照，再导入到 MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，有 18 个 `ParallelWebappClassLoader`  共占据了 44.61% 堆空间，咦？为什么要 18 个这种类加载器呢？

      ![1646306496272](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306496272.png)

      ![1646306148994](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306148994.png)

   7. 然后我就想起 Tomcat 的类加载过程，是打破了双亲委派机制的：

      1. **ext -> bootstarp模型**：保证了 JRE 核心类库不会被重复加载，满足了加载JVM共同类库的需求。
      2. **ext -> webapp模型**：实现了每个 web 应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离的需求。
      3. **webapp -> share -> common模型**：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了加载其他共同类库的需求。

      ![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

   8. 也就是一个 `ParallelWebappClassLoader` 对应一个 Web App 项目，但用来发版的 Tomcat 应该就只有一个项目呀，所以我就怀疑应该是每次发版没把上一版的项目卸载掉所导致的。

4. **结果 Result**：所以我就让组内的成员，大家在下次发版前，先用 Tomcat Manager 把上一个项目卸载掉，再发新的 war 包上去，这样做了后，就没碰到过这样的情况出现了，应该算是蒙对了吧~哈哈

#### 2.1.1.2. 分片广播式定时的设计及原理？

##### 1、总

除了用 Kafka 去实现分片广播式定时，我还知道以下解决方案：

##### 2、分

1. 基于 **Redis ZSet** 有序集合实现：

   - 1）添加定时任务，把每个画像消息作为一个定时任务元素，定义好任务数据结构（表任务 ID、开始时间戳、循环条件等），然后使用 `ZADD` 命令把定时任务加入有序集合中，分数为开始时间戳。
   - 2）取定时任务，则是通过应用轮训去取，每隔 1 秒去消费有序集合，其中要注意的点是，由于应用是集群部署的，所以消费时要先获取分布式锁，获取到的才能进行消费。
   - 3）获取集合最低的分数，判断分数是否比当前时间戳小，是的话则执行后删除元素，然后根据循环条件来决定是否需要将其重新加入集合中，在下次循环之前，释放分布式锁，否的话则直接释放分布式锁。

   => 优点是，Redis 保证任务顺序执行，但可能会存在一定延迟，缺点是，每次轮训都发生所有应用来抢占分布式锁，网络带宽可能会受到影响。

2. 基于 **DB** 实现：

   - 1）添加定时任务，把每个画像消息作为一条记录，带上开始时间戳、循环条件丢到表里。
   - 2）取定时任务，由应用去查找该表最新的一条记录，通过乐观锁的方式，更新版本号，更新成功的则代表获取到此行的分布式锁，然后去执行此行的任务，执行完毕后删除任务，根据循环条件来决定是否需要将其重新加入表中。

   => 优点是，实现简单，没有多余的组件，缺点是，对单表压力大，相当于基于数据库实现的每个任务作为一个分布式锁。

3. 基于开源组件实现：EsJob、Xxl-job 等。

##### 3、总

以上就是我对除 Kafka 消息方案以外的一些实现分片广播式定时的方案，请指教一下方案是否合理？

#### 2.1.1.3. 目前生产上的机器规模？

##### 1、GSRMC

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 126 个服务。
- **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块           | 数量              | CPU           | 内存               | 硬盘  |
| -------------- | ----------------- | ------------- | ------------------ | ----- |
| 前端 Apache    | 8                 | 4 C           | 16 G               | 50 G  |
| Eureka         | 3                 | 1 C           | 1 G                | 10 G  |
| BASE           | 13                | 8 C           | 16 G               | 100 G |
| POS            | 19                | 8 C           | 16 G               | 100 G |
| PERF           | 7                 | 8 C           | 16 G               | 100 G |
| QUO            | 6                 | 8 C           | 16 G               | 100 G |
| BID            | 3                 | 8 C           | 16 G               | 100 G |
| PRICE          | 13                | 8 C           | 16 G               | 100 G |
| CON            | 6                 | 8 C           | 16 G               | 100 G |
| ESB            | 5                 | 8 C           | 16 G               | 100 G |
| JOBS           | 9                 | 8 C           | 16 G               | 100 G |
| TASK           | 5                 | 8 C           | 16 G               | 100 G |
| MIP            | 4                 | 8 C           | 16 G               | 100 G |
| SYNC           | 5                 | 8 C           | 16 G               | 100 G |
| INDEX          | 3                 | 8 C           | 16 G               | 100 G |
| 其他模块       | 25                | 8 C           | 16 G               | 100 G |
| MySQL          | 16（8 主 8 从）   | 32 C          | 128 G              | 3 T   |
| MongoDB        | 3                 | 8 C           | 16 G               | 500 G |
| Redis          | 3                 | 8 C           | 32 G               | 100 G |
| Kafka          | 3                 | 8 C           | 16 G               | 100 G |
| 报表导出 OSS   | 文件数： 500 / 天 | 数据量：10 G  | 增长量：300 M / 天 | -     |
| 供应商附件 OSS | 文件数：10 w / 年 | 数据量：200 G | 增长量：200 G / 年 | -     |

##### 2、云化项目

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 14 个服务。
- **数据库**：监控显示，16 C、64 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块             | 数量             | CPU          | 内存              | 硬盘  |
| ---------------- | ---------------- | ------------ | ----------------- | ----- |
| 前端 Nginx       | 3                | 4 C          | 16 G              | 50 G  |
| Eureka           | 3                | 1 C          | 1 G               | 10 G  |
| BASE             | 3                | 8 C          | 16 G              | 100 G |
| APP              | 3                | 8 C          | 16 G              | 100 G |
| OEM              | 3                | 8 C          | 16 G              | 100 G |
| JOBS             | 2                | 8 C          | 16 G              | 100 G |
| MySQL            | 1 主             | 16 C         | 64 G              | 3 T   |
| Redis            | 6                | 8 C          | 16 G              | 100 G |
| 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

##### 3、比亚迪 SRM

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 21 个服务。
- **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块             | 数量             | CPU          | 内存              | 硬盘  |
| ---------------- | ---------------- | ------------ | ----------------- | ----- |
| 前端 Nginx       | 2                | 4 C          | 16 G              | 50 G  |
| APP              | 6                | 8 C          | 16 G              | 100 G |
| MID              | 7                | 8 C          | 16 G              | 100 G |
| RPORT            | 6                | 8 C          | 16 G              | 100 G |
| Oracle           | 1                | 32 C         | 128 G             | 3 T   |
| Redis            | 3                | 8 C          | 16 G              | 100 G |
| 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

#### 2.1.1.4. 生产慢问题修复的例子？

见项目自我介绍里的，线程池调优，以及 CPU 95% 的例子。

##### 1、线程池调优 | 线程池、源码、调优

1. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
2. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
3. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
4. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
5. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。

##### 2、发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%

1. **背景 Situation**：我们团队这次的迭代，需要在云平台开发几个接口，然后在和 SRM 联调测试时，为了不用等比亚迪 SAP 测试环境的发版窗口，就需要有我们自己的一个云平台测试环境，方便快速发版快速验证。

2. **任务 Task**：那时由我负责来负责搭建，但由于是在内网环境进行开发，访问不了外网，就拉取不到 Jenkins 的依赖，当然也没有云原生这些基础设施，所以采取了 Tomcat Manager + ELK 部署的方式来发版，前者是 Tomcat 的后台，可以开发完代码后导出 war 包，然后在浏览器上把 war 包进行上传部署，后者是用于在 Kibana 上观察接口的异常日志。

3. **行动 Action**：

   1. 就这样，一个简单易用的发版平台就搭建好了，不过没几天问题就来了，我们发现每一次上传 war 包到启动完成，所花的时间好像都会比上一次的要久，最后一次 war 包上传则是浏览器一直在转了。

   2. 当时为了不阻塞测试进度，就到发版平台的服务器上看，先是使用 `top` 命令看到 118243 的 Tomcat 进程，居然占用了 95.3% 的 `%CPU`：

      ![1646305025603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305025603.png)

   3. 然后使用 `top -Hp 118243 ` ，查看 Tomcat 进程的所有线程，发现最高的一个线程 `118332` 占用了 73.3% `%CPU`：

      ![1646305182797](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305182797.png)

   4. 然后使用 `printf %x 118332`，获取对应的 16 进制线程号，用于后面的 jstack 文件搜索：

      ![1646305395917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305395917.png)

   5. 然后就是 `jstack -l 118243 > thread-dump.txt `，导出对应 `118243` 进程的线程快照，打开搜索对应的 `1ef96` 16 进制线程号（这个是当时真实的线程号，上面是后期模拟的） ，就定位到了一堆 `ParallelGC` 线程，原来是 GC 太多而导致的 CPU 飚高，那么为什么一个发版的 Tomcat，会有这么多 GC 线程呢？会不会是项目代码哪里写的有问题啊？

      ![1646305627751](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305627751.png)

   6. 然后我就使用 `jmap -dump:format=b,file=heap-dump.hproft 118243`，以 `hprof` 格式导出 `118243`  Tomcat 进程的堆内存快照，再导入到 MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，有 18 个 `ParallelWebappClassLoader`  共占据了 44.61% 堆空间，咦？为什么要 18 个这种类加载器呢？

      ![1646306496272](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306496272.png)

      ![1646306148994](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306148994.png)

   7. 然后我就想起 Tomcat 的类加载过程，是打破了双亲委派机制的：

      1. **ext -> bootstarp模型**：保证了 JRE 核心类库不会被重复加载，满足了加载JVM共同类库的需求。
      2. **ext -> webapp模型**：实现了每个 web 应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离的需求。
      3. **webapp -> share -> common模型**：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了加载其他共同类库的需求。

      ![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

   8. 也就是一个 `ParallelWebappClassLoader` 对应一个 Web App 项目，但用来发版的 Tomcat 应该就只有一个项目呀，所以我就怀疑应该是每次发版没把上一版的项目卸载掉所导致的。

4. **结果 Result**：所以我就让组内的成员，大家在下次发版前，先用 Tomcat Manager 把上一个项目卸载掉，再发新的 war 包上去，这样做了后，就没碰到过这样的情况出现了，应该算是蒙对了吧~哈哈

#### 2.1.1.5. MySQL MVCC？

##### 1、总

MVCC，Multi-Version Concurrency Control，多版本并发控制，可以实现数据库读写冲突时的无锁并发访问，可以做到在读时不阻塞写，写时不阻塞读，提高了数据库并发的读写性能，同时还可以解决 MySQL 不可重复读、幻读等事务并发问题。

##### 2、分

1. 首先，需要讲一下 MySQL 中的当前读和快照读：

   - 1）**当前读**：非 MVCC 实现，读取的是记录的最新版本，读取时，要保证其他并发事务不能修改当前记录，因此会对读取的记录进行加锁。
     - 举例：select lock in share mode（共享锁）, select for update（排他锁），update、insert、delete（排他锁）、串行化事务隔离级别等。
   - 2）**快照读**：MySQL 实现 MVCC 模型的中一个具体的非阻塞读功能，可以避免读时的加锁操作，从而降低开销、提高并发性能，但快照读可能读到的不一定是数据的最新版本，而是之前的历史版本，但前提是，事务使用非串行化的隔离级别，否则串行化级别下的快照读会退化成当前读。
     - 举例：不加锁的 select。

2. 然后就是实现原理，MySQL 是由 undo log + 版本链 + Read View 来实现 MVCC 的：

3. 第一个是 **undo log**，回滚日志，属于逻辑日志，记录的是 sql 执行相关的信息，是 MySQL 中事务原子性和隔离性实现的基础，其实现原理是：

   - 1）在 MySQL InnoDB 中，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log。
   - 2）如果事务执行失败或调用了 rollback，导致事务需要回滚时，就可以根据 undo log 的内容做与之前相反的工作，把数据回滚到修改之前的样子，以实现事务原子性操作。
   - 3）对于每个 insert，回滚时会执行 delete。对于每个 delete，回滚时会执行 insert。对于每个 update，回滚时会执行一个相反的 update，把数据改回去。
   - 4）而 MVCC 则是采用 undo log 来记录旧版本，链首为最新的旧记录，链尾为最早的旧记录。

4. 第二个是**版本链**，在 InnoDB 中，每次修改版本都会在版本链中记录，通过 undo log + trix_id + roll_pointer 来实现，undo log 原理如上所说，

   ![1630673126935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630673126935.png)

   - 1）**trx_id**：当前版本的事务ID，用来存储每次对某条记录进行修改时的事务ID，其中事务 ID 则是，当每个事务开启时，都会被分配一个ID，而这个ID是递增的，因此越新的事务其ID值越大。
   - 2）**roll_pointer**：回滚指针，由于每次对记录修改时，都会把老版本写入到 undo 日志中，使用回滚指针 roll_pointer 来指向这条记录上一个版本的位置，通过它来获得上一个版本的记录信息，其中，插入操作的 undo 日志是没有 roll_pointer 的，因为它没有老版本。

5. 第三个是 Read View，它是事务进行快照读操作时产生的读视图，是数据库当前的一个快照，记录了系统当前活跃事务ID 集合（即还没有提交的事务 ID），用来做可见性判断，即当某个事务执行快照读时，会对该记录创建一个Read View 读视图， 并把它作为条件，来判断当前事务能够看到哪个版本的数据，其中可能是当前版本的数据，也有可能是该行记录 undo log 里面某个版本的老数据，具体原理如下：

   ![1630674963257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630674963257.png)

   1. **trx_id == creator_trx_id**：可以访问这个版本，这个版本的事务 ID 等于当前创建 Read View的事务 ID，即自己能够读到自己的版本。
   2. **trx_id < min_trx_id**：可以访问这个版本，这个版本的事务 ID 小于最小活跃事务 ID，说明这个版本已经被提交过了，对于当前做可见性判断的事务来说，是可以看见的。
   3. **trx_id > max_trx_id**：不可以访问这个版本，这个版本的事务 ID 大于下一个事务 ID，说明这个版本记录是在该 Read View 生成之后产生的，已经超出了版本链范围，而快照读只能读取版本链中的版本，因此该版本对于当前做可见性判断的事务来说，是不应该看见的。
   4. **min_trx_id <= trx_id <= max_trx_id**：
      - 如果这个版本的事务 ID 为 m_ids 中的某个值，则不可以访问这个版本的，因为m_ids 都是活跃的、还没提交的事务，说明该版本记录还没有提交，对于当前做可见性判断的事务来说，是不应该看见的。
      - 如果这个版本的事务 ID 不为 m_ids 中的某个值，则可以访问这个版本，因为没在 m_ids 里，又小于等于 max_trx_id，说明该版本记录已提交了，对于当前做可见性判断的事务来说，是可以看见的。

   => 因此，可见性判断总的来说就是，要当前事务能看到的版本应该是自己创建的或者已经提交了的，这也是实现 MVCC 的原理所在。

##### 3、总

以上，就是我对 MySQL MVCC 的一个理解，请问有什么细节需要补充的吗？

#### 2.1.1.6. Dubbo 配置的注意点有哪些？

##### 1、Provider 多配置 Consumer 参数

1. 作为服务提供⽅，自己⽐消费⽅更清楚服务的这些接口参数的取值，比如超时时间、重试次数、负载均衡策略等。
2. 由于配置覆盖策略存在，在 Provider 端配置后，Consumer 端不配置则会使⽤ Provider 端配置，即 Provider 配置可以作为 Consumer 的缺省值。
3. 而如果 Provider 不配置，Consumer 也不直接配置，则会使⽤ Consumer 端的全局设置，这对于 Provider 是不可控的，并且往往是不合理的。
4. 因此，Provider 端尽量多配置、完善这些接口参数，让 Provider 实现者⼀开始就思考 Provider 端的服
   务特点和服务质量等问题。

![1636882183556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636882183556.png)

##### 2、Provider 合理配置性能参数

比如，**threads**（服务线程池⼤⼩）、**executes**（服务提供者并发请求的上限）。

##### 3、服务使用固定端口

使⽤固定端⼝来暴露服务，不要使⽤随机端⼝，这样在注册中⼼推送延迟的情况下，消费端仍然能够通过缓存列表，调⽤到原地址+原端口的服务，保证调⽤成功。

##### 4、推荐使用 XML 进行配置

XML 配置优先级高于 properties 和 yml，且标签的配置方式更加容易阅读和理解。

##### 5、应用配置负责人参数

配置 `dubbo:application#owner` 负责人参数，这些可以在运维平台上看到，以便于在发现问题时，找到对应服务负责⼈。

#### 2.1.1.7. Dubbo 提供者、消费者服务启动原理？

##### 1、总

1. 首先是 Dubbo 与 Spring 的融合原理，基于 dubbo.jar 内的 `META-INF/spring.handlers` 配置，Spring 在遇到 Dubbo XML 配置的名称空间 `http\://dubbo.apache.org/schema/dubbo` 时，会回调 `DubboNamespaceHandler` 。
2. 而 `http\://dubbo.apache.org/schema/dubbo/dubbo.xsd` 则定义了 Dubbo XML 的标签语法，所有 dubbo 的标签，都统一用 `DubboNamespaceHandler#DubboBeanDefinitionParser` 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。
3. Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent` 回调时，或者 Consumer 在接口注入 `FactoryBean#getObject` 时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 Dubbo#URL，然后将 Dubbo#URL 传给 Protocol 扩展点，基于扩展点的 SPI 机制，根据 Dubbo#URL 的协议头，进行不同协议的服务暴露或者引用。

##### 2、分

###### 1）Provider 服务发布原理

1. `ServiceConfig` 在 XML 解析后，拿到对外提供实现类 `XML#ref` 配置。
2. 然后，Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent` 回调时，通过 `ProxyFactory#getInvoker（）` 为 `XML#ref` ，生成一个 interfaceClass 的 javasist 动态代理 Wrapper 包装类 Invoker 实例，可以动态代理调用 `XML#ref` 实现类的方法，到这一步就完成了具体实现类到 `Invoker` 的转化。
3. 接下来，就是 `Invoker` 转换到 `Exporter` 的过程，是服务暴露的关键过程，其转换分为两种类型：
   - 1）**暴露本地服务**：
     1. 指服务暴露和引用都在同一个 JVM 里，自己调用自己接口，没必要进行远程通信。
     2. 会调用 `InjvmProtocol#export（）` 把 invoker 转换为 `InjvmExporter`，并存进 exporters 缓存中。
     3. 调用则是获取 exporters 缓存中的 `InjvmExporter`，进行一个普通的动态代理到实现类的方法。
   - 2）**暴露远程服务**：
     1. 指服务暴露给远程客户端IP和端口号，以实现远程通信。
     2. 会调用 `DubboProtocol#export（）`  把 invoker 转换为 `DubboExporter`，然后打开 Netty 服务器暴露服务，并存进 exporters 缓存中。
     3. 然后调用 `RegistryProtocol#register（）`，使用 Curator 客户端建立 ZK 连接，注册 provider 持久化结点、当前服务的非持久化结点、configurators 非持久化结点，并设置监听器，当配置发生变更时，则会回调监听器的 `notify（）` 方法，来修改 invoker 信息。
     4. 调用则是通过 `Netty#channelRead()` 方法，当有数据请求时，则调用 handler 和线程池进行接收、处理，最终获取缓存中的 `DubboExporter`，动态代理到实现类的方法。

![1637067703250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637067703250.png)

###### 2）Consumer 服务引用原理

1.  Consumer 在接口注入 `FactoryBean#getObject` 时，调用 `Protocol#refer（）`生成 `Invoker` 实例，是服务消费的关键，其分类 3 种类型：
   - **本地服务引用**：如果为本地暴露服务，则 `InjvmProtocol` 生成本地执行的 `InjvmInvoker` 。
   - **直连服务引用**：如果为直连服务，则 `DubboProtocol` 创建 Netty 客户端，连接 url 服务，构建 `DubboInvoker` 。
   - **远程服务引用**：
     1. 如果为非直连的远程服务引用，则会调用 `RegistryProtocol` 进行 Consumer 注册到 ZK 并订阅，拉取相关 url 和 配置信息，当有发生变更时，则触发监听器的回调函数，调用 `DubboProtocol#refer()` 生成 `DubboInvoker` ，并加入集群，最后默认伪装返回一个 `FailoverClusterInvoker`。
2. 最后利用动态代理，把 `Invoker` 转换为客户端需要的接口实现类。
3. 当应用对代理对象进行方法调用时，则是动态代理到对应 `Invoker#invoke` 方法，调用本地方法或者发起远程请求。

![1637149757299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637149757299.png)

###### 3）Consumer 远程调用 Provider 原理

1. 消费方使用的接口动态代理实现类 proxy，调用其对应的 `Invoker`，发起真正的远程服务调用。

2. 而提供方的实现类，则会被封装成为一个 `AbstractProxyInvoker` ，然后生成一个 `Exporter` ，当服务提供方收到一个请求后，则会找到对应的 `Exporter` 实例，并调用它所对应的 `AbstractProxyInvoker` 实例，从而真正调用了服务提供者的代码。

3. 整个**消费方调用提供方**的调用链架构如下：

   ![1637150417647](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637150417647.png)

   1. **服务引用**：通过 Javassist 反向代理，代理调用 InvokerInvocationHandler#invoke 方法。
   2. **服务本地调用、降级、缓存**。
   3. **集群容错与负载均衡**：非 mock Invoker 筛选，Invoker 目录查找，根据容错策略、负载均衡策略，挑选唯一的 Invoker。
   4. **服务过滤链、监听器、包装类 SPI 扩展**。
   5. **服务协议**：根据协议，使用不同的 Invoker 调用不同的网络传输底层。
   6. **网络传输**：抽象 Netty、Mina 等统一接口，把消息序列化后发送到网络，传输给 Server 端。
   7. **消息接收与异步处理**：Server 端接收到消息后，经过反序列化后，交由线程池异步处理。
   8. **服务协议**：根据协议，选择不同的 Exporter 进行调用。
   9. **服务过滤链、监听器、包装类 SPI 扩展**。
   10. **服务调用**：最后调用真正的接口实现类，得到方法执行结果。

4. 而**提供方响应消费方**的顺序为：

   1. **服务响应**：在得到方法执行结果后，通过网络传输底层，序列化后发送响应报文给客户端。
   2. **结果接收**：客户端接收到响应报文后，交由线程池异步处理程序，经过反序列化后塞回到 Future 对象中，完成一次服务调用。

##### 3、总

以上，就是我对 Dubbo Provider 和 Consumer 启动过程以及远程调用过程的一个理解，请问有什么细节需要补充的吗？

#### 2.1.1.8. SpringBoot 的启动原理？

见《[1.1.1.4. SpringBoot 自动装配和自定义 starter？](#1.1.1.4. SpringBoot 自动装配和自定义 starter？)》。

#### 2.1.1.9. Spring MVC 中过滤器和拦截器的区别？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 2.1.2.0. 算法题 | 实际问题中树的深度优先遍历

思路就是，把对应的数据结构，转换为树结点的数据结构，然后进行常规的深度优先遍历即可，比如二叉树的**先序遍历**：

##### 1、递归法 | O（n）

- **思路**：递归遍历，中 -> 左 -> 右，因此在一开始来到中时，就把节点的值加入集合中即可。
- **结论**：时间，0ms，100%，36.4mb，92.56%，非常简单。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        return res;
    }
    
    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        res.add(root.val);
        f(root.left, res);
        f(root.right, res);
    }
}
```

##### 2、迭代法 | O（n）

- **思路**：迭代法中，先序遍历实现最简单，因为当前使用的 while 循环可以认为是“中”，然后模拟系统栈把右、左一次压栈即可（可以认为是方法倒过来压栈）。
- **结论**：时间，0ms，100%，36.4mb，93.30%，注意添加和使用前都做个判空，防止空指针和节省空间的使用。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        if(root != null) {
            stack.push(root);
        }
        
        List<Integer> res = new LinkedList<>();
        while(!stack.isEmpty()) {
            root = stack.pop();
            if(root != null) {
                res.add(root.val);
                if(root.right != null) {
                    stack.push(root.right);
                }
                if(root.left != null) {
                    stack.push(root.left);
                }
            }
        }

        return res;
    }
}
```

#### 2.1.2.1. 算法题 | Linux#uniq 指令、Java BufferedReader#ready 和 readLine

这道题的难点在于，Linux#uniq 指令的作用，和 Java BufferedReader 的 API。

##### 1、Linux#uniq 文档编辑命令

Linux#uniq，输入一个文件，检查文本文件中重复出现的行列，并输出到另一个文件，-c 代表在每列旁边显示该行重复出现的次数，-d 代表仅显示重复出现的行列，-u 代表仅显示只出现一次的行列。

##### 2、Java BufferedReader API

BufferedReader 可以从字符输入流中读取文本，并缓冲字符，以便有效地读取字符，使用时可以通过构造函数指定缓冲区大小或者也可以只使用默认大小 8192，同时建议使用 BufferedReader 包装 Reader 实例，以提高效率。

```java
private static void printLinuxCmd(File file) throws IOException {
    // 使用 BufferedReader 包装 Reader 实例
    BufferedReader reader = new BufferedReader(new FileReader(file));
    Set<String> res = new HashSet<>();

    // 允许读取：ready()
    String str;
    while (reader.ready()) {
        // 按行读取：readLine()
        str = reader.readLine();
        if(str.contains("abc")) {
            res.add(str);
        }
    }
    
    // 排序后去重
    List<String> reslist = res.stream().sorted(Comparator.comparingInt(Object::hashCode)).collect(Collectors.toList());
    System.err.println(reslist);
    
    // 底层是去关闭输入流
    reader.close();
}
```

#### 3.1.1.1. sychrozied 锁升级流程？

##### 1、总

sychrozied 锁状态一共有 4 种，级别由低到高分别为：无锁、偏向锁、轻量级锁和重量级锁。

1. 在 JDK 1.6 之前，sychrozied  锁是一个重量级锁，效率比较低下。
2. 在 JDK 1.6 之后，为了提高锁的获取和释放效率，就对 synchronized 的实现进行了优化，引入了偏向锁和轻量级锁。
3. 从此 synchronized 锁就有了以上 4 种状态，并且它们会随着竞争的情况逐渐升级，但不可降级。

对于 sychrozied  优化后的，锁执行过程总结如下：

![1629617805708](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617805708.png)

![1629617826584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617826584.png)

1. **确认是否为可偏向状态**：线程抢锁时，JVM 首先检测内置锁对象 Mark Word 中的 biased_lock（偏向锁标识）是否设置成 1，lock（锁标志位）是否为 01，如果都满足，则确认内置锁对象为**可偏向状态**。
2. **确认线程 ID**：在内置锁对象确认为可偏向状态后， JVM 会检查 Mark Word 中的线程 ID 是否为抢锁线程的 ID。
3. **同线程 ID，直接执行临界区代码**：如果是，则表示抢锁线程处于偏向锁状态，然后抢锁线程快速获得锁，开始执行临界区代码。
4. **竞争锁成功，升级为偏向锁**：如果 Mark Word 中的线程 ID 并未指向抢锁线程，则通过 CAS 操作去竞争锁。
   - 如果竞争成功，则将 Mark Word 中的线程 ID 设置为抢锁线程，偏向标志位设置为 1，锁标志位设置为 01，然后执行临界区代码，此时内置锁对象为**偏向锁状态**。
5. **发生锁竞争失败，偏向锁升级为轻量级锁**：如果 CAS 操作竞争失败，说明发生了竞争，此时 JVM 会去检查原先持有锁的线程是否存活。
   - 如果原线程已经死亡，则设置 Mark Word 为抢到锁的线程 ID，内置锁继续保持为偏向锁。
   - 如果原线程没有死亡，且其堆栈中存在该 sychrozied 锁的所记录，则需要撤销偏向锁，进而升级为**轻量级锁**（继续由原持有锁线程持有）。
6. **其他线程继续 CAS 竞争，以获取轻量级锁**：如果仍然有其他线程继续竞争轻量级锁，则在 JVM 将在替换锁对象 Mark Word 中的 ptr_to_lock_record 过程中，使用 CAS 替换为抢锁线程的锁记录指针。
   - 如果替换成功，则代表抢锁线程获得了**轻量级锁**。
   - 如果替换失败，表明存在其他线程竞争锁，则 JVM 接着尝试使用 CAS + 自旋方式来替换。
     - 如果替换成功，代表抢锁成功，则锁对象继续保持为**轻量级锁状态**。
7. **CAS + 自旋失败，轻量级锁升级为重量级锁**：如果 CAS + 自旋替换失败，即超过了最大自旋次数，轻量级锁则升级为重量级锁，此后等待锁的线程都需要进入**阻塞状态**。

=> 总的来说：

1. **偏向锁**是在没有发生锁争用的情况下使用的。
2. 一旦有了第二个线程争用锁，偏向锁则会升级为**轻量级锁**。
3. 如果锁争用很激烈，轻量级锁的 CAS + 自旋到达自旋阈值后，轻量级锁则会升级为**重量级锁**。

##### 2、分

###### 1）无锁

![1629597556442](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597556442.png)

无锁，即无线程竞争，在 java 对象刚创建时，还没有任何线程来竞争，对象处于无锁状态，此时，偏向标志位为0，锁状态标志位为 01。

###### 2）偏向锁

![1629597869808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597869808.png)

偏向锁，是指一段同步代码，一直被同一个线程所访问，偏向锁状态下的 Mark Word，会记录 synchronized 锁偏爱的线程 ID，从而让 synchronized 锁认定该线程为“熟人”，从而该线程可以自动获取锁，降低获取锁的代价。

- **主要解决无竞争下的锁性能问题**：由于线程 ID 被记录在锁对象的 Mark Word 中（CAS设置），以后该线程获取锁时，只需要判断一下线程 ID 和标志位，就可以直接进入同步块，连 CAS 操作都不需要，省去了大量有关锁申请的操作，消除了无锁竞争情况下的同步原语，从而提高了程序的性能。
- **偏向锁的膨胀**：
  1. 如果偏向锁已经被 A 占据，一旦有第二个线程 B 来争抢这个对象，由于偏向锁不会主动释放，所以 B 看到的 synchronized 锁是偏向状态，表明已经存在了竞争，则 JVM 会去检查原来持有该对象锁的占有线程A 是否依然存活。
  2. 如果发现 A 已经挂了，则将锁对象变为无锁状态，然后重新偏向 B 线程。
  3. 如果发现 A 依然存活，则会进一步检查 A 的调用堆栈是否有锁记录持有该偏向锁。
  4. 如果存在锁记录，表明原来的线程 A 仍然在使用该偏向锁，即 A 和 B 此时发生了锁竞争，则 JVM 会撤销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。
- **偏向锁的撤销**：如果锁对象经常被多个线程竞争，那么偏向锁就是多余的，并且撤销偏向锁的过程也会带来一些性能开销。
  1. 在一个安全点停止拥有锁的线程。
  2. 遍历线程的栈帧，检查是否存在锁记录，如果存在，则需要清空锁记录（锁记录是线程私有的，每个线程都有自己的一份锁记录），使其变为无锁状态，并修复锁记录指向的 Mark Word，清除其线程 ID。
  3. 将当前锁升级为轻量级锁。
  4. 唤醒当前线程。
- **偏向锁的撤销条件**：
  - 多个线程竞争偏向锁。
  - 调用偏向锁对象的 `hashCode（）`方法，或者 `System.identityHashCode（）`方法，计算对象的HashCode 之后，将哈希码放置到了 Mark Word 中，synchronized 锁变成无锁状态，偏向锁会被撤销。

=> 经验表明，大部分情况下，一个同步代码块的线程都是同一个线程，总体来说，使用偏向锁带来的好处大于偏向锁撤销和膨胀带来的代价。如果某些临界区存在两个，或者两个以上的线程竞争，偏向锁反而会降低性能，此时可以在启动 JVM 时，把偏向锁的默认功能关闭。

###### 3）轻量级锁

![1629598045639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629598045639.png)

轻量级锁，也被成为非阻塞同步锁、或者叫乐观锁，是指当锁处于偏向锁，又被另一个线程企图抢占时，偏向锁就会升级为轻量级锁，而企图抢占的线程会通过自旋的形式尝试获取锁，不会阻塞抢锁线程，以提高性能，其中，哪个线程先占有锁对象，锁对象的 Mark Word 就会指向哪个线程栈帧中的锁记录。

- **引入轻量级锁的主要目的**：在多线程竞争不激烈的情况下，通过 CAS 机制竞争锁，减少重量级锁产生的性能损耗，尽可能不动用操作系统层面的互斥锁，在应用层面上通过自旋来解决线程同步的问题。

  - **自旋原理**：如果持有锁的线程能在很短时间内释放锁资源，竞争等待锁的线程则不需要进行内核态和用户态的切换进入阻塞状态，它们只需要 CPU 自旋，等待持有锁的线程释放锁后即可立即获取锁，避免了用户线程和内核切换的消耗，从而提高性能。
  - **自旋锁分类**：
    - **普通自旋锁**：指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。
      - JDK 1.6 的轻量级锁使用的是普通自旋锁，需要使用 `-XX：+UseSpinning` 选项手工开启。
      - 默认情况下，自旋次数为 10 次，可以通过 `-XX：PreBlockSpin` 选项来进行更改。
      - 然而，线程自旋需要消耗 CPU，如果一直获取不到锁，那么线程也不能一直占用 CPU 自旋做无用功，因此需要设定一个自旋等待的最大时间。
    - **适应性自旋锁**：
      - JVM 对于自旋周期的选择，JDK 1.7 引入了适应性自旋锁（自动开启），指的是自旋的时间不是固定式的，而是由前一次在同一个锁上的自旋时间，以及锁的拥有者状态来决定的，解决的是锁竞争时间不确定的问题，使得竞争程度趋于稳定。
      - **自旋成功了则下次自旋的次数就会更多**：如果抢锁线程在同一个锁对象上之前成功获得过锁（竞争力强，适合竞争），JVM 则会认为这次自旋很可能再次成功，此次允许自旋等待持续相对更长的时间。
      - **自旋失败了则下次自旋的次数就会减少**：如果对于某个锁，抢锁线程很少成功获得过（竞争力弱，不适合竞争），JVM 则减少自旋时间甚至省略自旋过程，以避免浪费 CPU 资源。

- **轻量级锁的抢占过程**：

  1. 在抢锁线程进入临界区之前，如果该 synchronized 锁没有被锁定，JVM 首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前 Mark Word 的拷贝。

     ![1629601733727](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629601733727.png)

  2. 然后，抢锁线程将使用 CAS 自旋操作，尝试将内置锁对象头的 Mark Word 的 ptr_to_lock_record（锁记录指针），更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，这个线程就拥有了对象锁。

  3. 接着，JVM 将 Mark Word 中的 lock 标记位改为 00，代表该内置锁对象处于轻量级锁状态。

  4. 抢锁成功之后，JVM 会将 Mark Word 中原来的锁对象信息（如哈希码等），保存在抢锁线程锁记录中的Displaced Mark Word 字段中，再将抢锁线程中锁记录的 owner 指针指向锁对象。

     ![1629602512221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629602512221.png)

- **轻量级锁的膨胀**：

  - 如果临界区代码执行耗时较长，在其执行期间，其他线程都在原地 CAS + 自旋等待替换ptr_to_lock_record，导致一直空耗 CPU，带来很大的性能损耗。
  - 而轻量级锁的本意，是为了减少多线程进入操作系统层面互斥锁的概率，并不是要替代其互斥锁。
  - 因此，在内置锁争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁实现的重量级锁。

###### 4）重量级锁

![1629599089661](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629599089661.png)

重量级锁，也称为同步锁，是指当锁处于轻量级锁，如果持有锁的线程执行的时间，超过了自旋等待的最大时间仍然没有释放锁，自旋等待锁的线程不会一直自旋下去，而是会进入阻塞状态，该锁也膨胀为重量级锁。

- 锁对象的 Mark Word 会再次发生变化，指向一个监视器对象，该监视器对象会用集合的形式来登记和管理排队的线程。

  - **监视器**：是一个同步工具，相当于一个许可证，拿到许可证的线程即可进入临界区进行操作，没有拿到的则需要阻塞等待。在 JVM 中，每个对象都关联一个监视器，监视器和对象一起创建、销毁，保证同一时间只有一个线程可以访问被保护的临界区代码。监视器也可以说是同步机制，主要特点是：
    - **同步**：监视器所保护的临界区代码互斥地执行，一个监视器是一个运行许可，任一线程进入临界区代码都需要获得这个许可，离开时会把许可归还。
    - **协作**：监视器提供 Signal 机制，允许正持有许可的线程，暂时放弃许可进入阻塞等待状态，等待其他线程发送 Signal 去唤醒；其他拥有许可的线程可以发送 Signal，唤醒正在阻塞等待的线程，让它可以重新获得许可并启动执行。

- 重量级锁通过监视器的方式，保障了任何时间，只允许一个线程通过受到监视器保护的临界区代码。在Hotspot 虚拟机中，监视器由 C++ 类 ObjectMonitor 实现：

  ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

  - **_recursions**：线程的重入次数。
  - **_owner**：标识拥有该 Monitor 的线程，即获得锁的线程。
  - **cxq**：竞争队列，所有请求锁的线程首先会被放入这个竞争队列中。cxq 由 Node 及其 next 指针逻辑构成（单向链表），并不存在一个队列的数据结构，只是一个虚拟队列：
    1. 在线程进入 cxq 前，抢锁线程会先尝试通过 CAS 自旋获取锁，如果获取不到，则会进入 cxq 队列，显然抢锁操作这对于那些已经进入了 cxq 队列的线程是不公平的，因此 synchronized 同步块所使用的重量级锁是**非公平锁**。
    2. 每次新加入的 Node 会在 cxq 的队头进行，通过 CAS 改变第一个结点的指针为新增结点，同时设置新增结点的 next 指向后续结点。
    3. 从 cxq 取出元素时，会从队尾获取。由于只有 owner 线程才能从队尾取出元素，即线程出列操作无争用，因此 cxq 是无锁结构。
  - **_EntryList**： 候选竞争队列，由于 cxq 会被线程并发访问，为了降低对 cxq 队尾的争用，在 owner 线程释放锁时，JVM 会从 cxq 中迁移线程到 EntryList 中，并会指定 EntryList 中某个线程（一般为 Head）为OnDeck Thread（Ready Thread），因此 EntryList 中的线程是作为候选竞争线程而存在的。
    - **OnDeck Thread**：
      - JVM 不直接把锁传递给 Owner Thread，而是把锁竞争的权利交给 OnDeck Thread，On Deck 需要重新竞争锁，这种行为称为竞争切换，虽然牺牲了一些公平性，但极大提升了系统的吞吐量。
      - OnDeck Thread 获取到锁资源后将会变为 Owner Thread，无法获得锁的 OnDeck Thread 则会依然留在 EntryList 中。
      - 另外，在 OnDeck Thread 成为 Owner 的过程中，还要一个**不公平**的事情：后来的新抢锁线程可能会直接通过 CAS 自旋成为 Owner 而获得锁。
  - **_WaitSet**：等待队列，某个拥有 ObjectMonitor 的线程（owner 线程）在调用 Object.wait（）方法之后将被阻塞，然后该线程将被放置在 _WaitSet 链表中，直到某个时刻通过 Object.notify（）或者Object.notifyAll（）唤醒后，该线程才会重新进入 EntryList 中继续候选竞争锁。

- **重量级锁性能低**：重量级锁使用了操作系统底层的互斥锁（Mutex Lock），会导致线程在用户态和内核态之间的频繁切换，从而带来较大的性能损耗。

  - 处于 cxq、EntryList、WaitSet 中的线程都处于阻塞状态，线程的阻塞或者唤醒，都需要操作系统来帮忙。比如在 Linux 内核中采用 pthread_mutex_lock 系统调用（互斥锁）来实现，因此，进程需要从用户态切换到内核态。
  - 进程从用户态切换到内核态，这种切换需要消耗很多时间，有可能比用户执行代码的时间还要长，而由于轻量级锁使用 CAS 进行自旋抢锁，都处于用户态下，进程不存在用户态和内核态之间的切换，因此轻量级锁开销较小，而重量级锁使用了 Linux 内核态下的互斥锁，会造成较大的性能开销。

##### 3、总

适用场景总结：

| 锁       | 优点                                                         | 缺点                                             | 适用场景                                 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ---------------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比，仅存在纳秒级的差距 | 如果线程间存在锁竞争，则会带来额外的锁撤销消耗   | 适用于只有一个线程访问临界区的场景       |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 抢不到锁竞争的线程会使用CAS 自旋等待，会消耗 CPU | 锁占用时间很短，追求响应时间，但吞吐量低 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗 CPU                             | 使用系统互斥锁，线程阻塞，响应时间缓慢           | 吞吐量高，追求吞吐量，但锁占用时间较长   |

=> 以上，就是我对 sychrozied 的一个理解，请问有什么细节需要补充的吗？

#### 3.1.1.2. Java 线程同步方式？

##### 1、总

1. 线程同步，指当有一个线程对内存进行操作时，其他线程都不可以对这个内存进行操作，直到此线程完成操作后，其他线程才能对这个内存进行操作。
2. 在 Java 中，实现线程同步的基础是，操作系统的 mutex 互斥锁、volatile 保证内存可见性和 CAS 比较交换，从上层表现形式来看，可以划分为以下几种同步方式：

##### 2、分

1. **锁式**：指的是，互斥访问同步代码块，拿到互斥量的线程进行同步代码块执行，拿不到互斥量的线程则进入阻塞状态，比如 synchronized 内置锁、Lock 接口的实现类比如 ReentrantLock 重入锁、ReentrantReadWriteLock 读写锁。
2. **事件通知式**：指的是，通过事件通知来协调线程，安全地访问同一块内存，阻塞后的线程需要等待其他线程来唤醒，比如 Object#wait()、notify()、notifyAll()，LockSupport#park()、unpark()，Lock.Condition#await()、signal()。
3. **资源控制式**：指的是，通过控制资源数量，来决定线程是否能够访问临界区或者内存，拿到资源的则可以访问，拿不到的则进入阻塞或者排队等待，比如 Semaphore 信号量。
4. **排队等待式**：指的是，通过队列来实现线程的有序访问，比如 AQS CLH 自旋锁队列、BlockingQueue 阻塞队列。

##### 3、总

以上，就是我对 Java 线程同步方式的一个理解，请问有什么细节需要补充的吗？

#### 3.1.1.3. 你为什么值这么多？

##### 1、总

对于这个问题，我认为我个人对于技术的研究，其广度和深度都是十分符合当前条件。

##### 2、分

1. 首先是广度，
   - 1）开发使用方面，本人有全栈开发经验，对于前后端的实现角度，都有自己一些独特的理解，应用开发上自然也能驾驭得不错。
   - 2）应用架构方面，本人对主流开源框架基本所有了解、掌握，在架构设计时能够有足够多的灵感来源，基本能够覆盖较多的需求实现。
   - 3）系统架构方面，本人对于一些系统部署相关的，做了较多实验，也从中得到了不错的经验和心得，比如 LVS、Haproxy、Nginx、Redis、RabbitMQ、Kafka、ELK、Docker、K8s、Cloud Foundry、Mesos、Marathon，以及一些性能调优方面的等等。
2. 然后是深度，
   - 1）java 语言方面的原理，个人研究过集合和并发框架源码，能够在日常开发中保证需求完成的同时，还能保持代码的高质量。
   - 2）应用框架方面的原理，也是能研究都尽量研究了，比如 java 写的 Spring、Spring MVC、Spring Boot、Spring Cloud、Dubbo、MyBatis 源码等，对于非 java 写的比如 MySQL、Redis、RabbitMQ、Kafka 的一些常见原理也是有所掌握，能够在日常工作中解决掉突发的线上问题。

##### 3、总

综上，我认为这些原因都能很好的回答这个问题，希望能够得到您的认可。

#### 3.2.1.1. epoll 详解，以及与 select 的区别？

##### 1、总

1. `select`、`poll`、`epoll` 都是 Linux 为 I/O 多路复用模型提供的函数。
2. 其中，I/O多路复用，是指可以通过一种机制，让一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

##### 2、分

###### 1）select

```c++
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

1. `select` 函数监视的文件描述符分 3 类，分别是 `readfds`、`writefds` 和 `exceptfds`。
2. 调用后，`select` 函数会阻塞，直到有描述副就绪（比如有数据 可读、可写、或者有 except），或者超时（`timeout` 指定等待时间，如果立即返回设为 null 即可），则函数返回。
3. 当 `select` 函数返回后，可以通过遍历 `fdset` ，来找到就绪的描述符。

- **优点**：`select` 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
- **缺点**：`select` 的一个缺点是，单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义，甚至重新编译内核的方式来提升这一限制，但是这样也会造成效率的降低。

###### 2）poll

```c++
int poll (struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

- **特点**：
  1. 不同与 `select` 使用三个位图来表示三个 `fdset` 的方式，`poll` 只使用一个 `pollfd` 的指针来实现。
  2. `pollfd` 结构包含了要监视的 event，和 发生的 event，不再使用 `select` “参数-值” 的传递方式。
  3. 同时，`pollfd` 并没有最大数量限制，但数量过大后性能也还是会下降。 
  4. 和 `select` 函数一样，`poll` 返回后，需要轮询 `pollfd` 来获取就绪的描述符。
- **缺点**：
  1. 从上面看，`select` 和 `poll` 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。
  2. 事实上，同时连接的大量客户端，在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

###### 3）epoll

`epoll` 是在 Linux 2.6 内核中提出的，是之前的 `select` 和`poll` 的增强版本。

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

1. 在 `select` / `poll` 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描。
2. 而 `epoll` 事先通过 `epoll_ctl()` 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 `callback` 的回调机制，迅速激活这个文件描述符，当进程调用 `epoll_wait()` 时便得到通知，从而去掉了对文件描述符的遍历操作。

- **优点**：
  1. **监视的描述符数量不受限制**：`epoll` 所支持的 fd 上限，是最大可以打开文件的数目，这个数字一般远大于 2048。比如，在 1GB 内存的机器上大约为10 万左右，具体数目可以 `cat /proc/sys/fs/file-max` 察看，一般来说这个数目和系统内存关系很大。
     - `select` 的最大缺点就是，进程打开的 fd 是有数量限制的，这对于连接数量比较大的服务器来说，根本不能满足。
  2. **I/O 效率不会随着监视 fd 的数量的增长而下降**：`epoll` 不同于 `select` 和 `poll` 轮询的方式，而是通过每个 fd 定义的回调函数来实现的，只有就绪的 fd 才会执行回调函数。
- **局限**：如果没有大量的 idle -connection 或者 dead-connection，`epoll` 的效率并不会比 `select` / `poll` 高很多，但是当遇到大量的 idle- connection，就会发现 `epoll` 的效率大大高于 `select` / `poll`。

##### 3、总

以上，就是我对 select、poll、epoll 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.2. Netty 采用了哪种 I/O 多路复用模式？

##### 1、总

1. Netty 采用的是 Reactor 模式，应用于同步 I/O 的操作。
2. 然后， Reactor 根据实现方式的不同，其线层模型又分为 3 种，分别是单 Reactor 单线程模式、单 Reactor 多线程模式、主从 Reactor 多线程模式，其中，Netty 采用的是主从 Reactor 多线程模式。

##### 2、分

首先是 I/O 设计模式，分为 Reactor 模式和 Proactor 模式，

###### 1）Reactor 模式

Reactor 模式，应用于同步 I/O 场景，以 read 操作为例，Reactor 中的具体步骤为：

1. 应用程序注册 `读就绪` 事件和相关联的事件处理器。
2. 事件分离器等待事件的发生。
3. 当发生 `读就绪` 事件时，事件分离器调用第一步注册的事件处理器。
4. 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理。

![1646831826891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831826891.png)

**Reactor 优点**：

1. 响应快，可以不必被单个同步时间所阻塞，可以最大程度地避免复杂了多线程及同步问题，以及多线程 / 进程切换的开销。
2. 扩展性好，可以方便的通过增加 Reactor 实例个数，来充分利用 CPU 资源。
3. 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

###### 2）Proactor 模式

Reactor 和 Proactor 模式的主要区别就是，真正的读取和写入操作是由谁来完成的，Reactor 中需要应用程序自己读取或者写入数据，而 Proactor 模式中，应用程序不需要进行实际的读写过程，只需要从缓存区读取或者写入即可，操作系统会写入缓存区或者从缓存区读取并写入到真正的 I/O 设备中。

Proactor 模式 read 操作过程为：

1. 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注 `读取就绪` 事件，而是关注 `读完成` 事件，这是区别于 Reactor 的关键点 1。
2. 事件分离器等待 `读完成` 事件。
3. 在事件分离器等待 `读完成` 时，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中，这是区别于 Reactor 的关键点 2，在 Proactor 中，应用程序**需要传递缓存区**。
4. 事件分离器捕获到 `读完成` 事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
5. 而 Proactor 中的 write 操作和 read 操作类似，即感兴趣的事件是 `写完成` 事件。

![1646831843451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831843451.png)

###### 3）单 Reactor 单线程模式

然后，就是 Reactor 第一种线程模型，单 Reactor 单线程模式，

![1646831937063](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831937063.png)

1. `selector.select()` 是多路复用模型 NIO#API ，可以实现一个阻塞对象监听多路的连接请求。
2. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后通过 `dispatch()` 进行分发。
3. 如果是建立连接请求事件，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理连接完成后的后续业务处理。
4. 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应。
5. `Handler` 会完成 `read()` -> `doBusiness()` 业务处理 -> `send()` 一个完整的业务流程。

- **优点**：服务器使用一个线程，通过多路复用搞定所有 I/O 操作（包括连接、读、写等），编码简单，清晰明了，但如果客户端连接数量较多，将无法支撑。
- **缺点**：
  1. **性能问题**：只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上业务时，整个进程无法处理其它连接事件，容易导致性能瓶颈。
  2. **可靠性问题**：线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

###### 4）单 Reactor 多线程模式

![1646889343446](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889343446.png)

1. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后，通过 `dispatch()` 进行分发。
2. 如果是建立连接请求，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理完成连接后的各种事件。
3. 如果不是连接请求，则由 `Reactor` 对象分发调用连接对应的 `Handler` 来处理。
4. 此时，`Handler` 只负责读取和响应事件，不做具体的业务处理，通过 `read()` 读取数据后，会分发给后面的 `Worker` 线程池的某个线程进行处理业务。
5. `Worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `Handler`。
6. `Handler` 收到线程池处理完的结果后，通过 `send()` 将结果返回给 Client。

- **优点**：可以充分利用多核 CPU 的处理能力。
- **缺点**：
  1. 多线程在需要数据共享时，可能实现比较复杂。
  2. Reactor 单线程处理完所有的监听、连接、读、写事件，在高并发场景下，容易出现性能瓶颈。

###### 5）主从 Reactor 多线程模式

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

##### 3、总

因此，总结的话，Reactor 模式线程模型可以比喻为，

| Reactor 线程模型    | 比喻                                           | 优点                                                         | 缺点                           |
| ------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------ |
| 单 Reactor 单线程   | 前台接待员和服务员都是同一个人，全程为顾客服务 | 主线程负责所有的连接、读写、业务处理，编程简单               | 性能问题、可靠性问题           |
| 单 Reactor 多线程   | 1 个前台接待员，多个服务员，接待员只负责接待   | 主线程负责所有的连接、读写，Worker 负责业务处理              | 高并发场景下，容易出现性能瓶颈 |
| 主从 Reactor 多线程 | 多个前台接待员，多个服务生                     | MainReactor 负责连接、SubReactor 负责读写、Worker 负责业务处理，充分发挥多核 CPU 的优势，满足高并发场景 | 编程复杂                       |

=> 以上，就是我对 Netty 多路复用模式 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.3. RocketMQ、Kafka 底层文件原理？

##### 1、总

RocketMQ 消息存储是由 Comsume Queue + Commit Log 配合完成的，Kafka 消息存储是由多 Partition 进行存储的。

##### 2、分

###### RocketMQ

1. 在 RocketMQ 中，所有 Topic 消息都存储在一个称为 Commit Log 的文件中，默认最大为 1GB，超过 1GB 后消息后，就会写到下一个 Commit Log 文件。

2. 通过 CommitLog，RocketMQ 把所有消息存储在一起，以顺序 I/O 的方式写入磁盘，充分利用了磁盘顺序写，减少了 I/O 争用，提高了数据存储的性能。

3. 每个 Consumer 在第一次连接时，都会创建  Consume Queue，一个 Consume Queue 表示 topic#queue，不存储具体的消息，只存储路由到在 CommitLog 中的消息  offset，即具体的消息由 CommitLog 存储。

4. Consumer 在读取消息时，会先读取 Consume Queue，再通过 Consume Queue 中的 offset，读取
   CommitLog，从而得到原始的消息。

   ![1635678882127](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678882127.png)

###### Kafka

1. 在 Kafka 日志文件存储中，同一个 Topic 下会有多个不同的 Partition，每个 Partiton 为一个目录，Partition 是实际物理上的概念，而 Topic 则是逻辑上的概念。
2. 同时，一个 Partition 物理上又被分为多个 Log Segment 组成，Segment 不是一个目录，而是由 3 部分组成，分别为 `.index` 文件、`.timeindex` 文件 和 `.log` 文件，分别表示偏移量索引文件、时间戳索引文件和日志数据文件。
3. 然后，通过二分查找来解决查找效率问题，每个 Partition 被平均分配到多个 Segment 文件，也方便 Old Segment 已消费消息的清理，提高磁盘的利用率。

![1634213772578](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213772578.png)

**如何查找偏移量为 118 的消息**？根据时间戳查找的方式同理。

1. 首先，Kafka 会用一个 `ConcurrentSkipListMap` 跳跃表，来记录每个日志分段，通过它可以根据偏移量 `118` 定位到 Segment 在 00000000000000000000.index 中。
2. 然后，通过**二分查找**在该 `.index` 文件中，找到**不大于 `offset:118`  的最大索引项**，即 `offset:116` 那栏，得到 `position:9679`。
3. 接着，从 `.log` 文件中，物理位置为 `position:9679` 的位置，开始顺序查找 `offset:118` 的消息。

##### 3、总

因此，RocketMQ 与 Kafka 消息存储上的对比总结为：

|          | RocketMQ                                                     | Kafka                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 消息存储 | 将所有消息存储在同一个 CommitLog 中，且 Consume Queue 中只存储20个字节每个消息的位置信息 | 将每个 Partition的消息分开存储                               |
| 影响     | 单个 Broker 能支持更多的 Topic 和 Consume Queue，单机支持最高5w个队列，并且 Load 不会发生明显变化 | 单机超过 64 个 Partition，Load 会发生明显的飙高，发送消息的响应时间变长，但对于少 Partition 场景， 由于利用了 Partition 并行处理，使得此时的写性能高于 RocketMQ |
| 原因     | 所有消息都存储在同一个文件中，使得消息存储是磁盘顺序写       | 将消息按 Partition 存储在不同的文件中，使得整体消息存储是随机写，当 Partition 数量非常大时，会出现很多随机 I/O，导致所有 Broker 性能明显下降 |

=> 以上，就是我对 RocketMQ 和 Kafka 底层文件存储原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.4. ThreadLocal 底层原理？

##### 1、总

1. ThreadLocal，线程本地变量，可以将某个变量放到对象中，使该变量在每个线程中都有专属的引用，不会出现一个线程读取时，被另一个线程修改的现象，从而保证线程安全访问。
2. ThreadLocal，用作**线程隔离**，是解决线程安全问题一个较好的方案，比直接使用同步机制（如 synchronized）解决更简单、更方便、更高效，因为避免了加同步锁带来的性能损失，大大提升了并发性的性能，比如，数据库连接、Session 管理等。
3. 另外，根据 ThreadLocal 的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到，从而可以方便地实现**跨函数的数据传递**，避免通过参数传递数据带来的高耦合。

##### 2、分

其**线程隔离原理**为：

1. ThreadLocal 内部定义了一个静态的  `ThreadLocalMap`，在线程第一次调用 `get()/set()` 方法时，会被构造出来，并由 Thread 实例持有该引用。
2. 然后，ThreadLocal 实例作为 `ThreadLocalMap` 的 Key，也就是只要传入所需的 ThreadLocal 变量的引用，就可以获取到保存在 `ThreadLocalMap` 中对应的值。
3. 从而保证每个线程，即使在获取同一个 `ThreadLocal ` 变量的值时，也能保证值是互相隔离的。

TheadLocalMap#Entry 定义为**弱键的好处**：

1. 比如，线程 t 调用一个 `funcA()` 方法，新建了一个 ThreadLocal 实例 local，然后调用 `local.set()` 方法设置一个 100 后，调用 `local.get()` 方法去获取值。

   ```java
   public void funcA() {
       ThreadLocal<Integer> local = new ThreadLocal<>();
       local.set(100);
       local.get();
   }
   ```

2. 此时的内存结构是，local 被线程 t 强引用，在 `set()` 调用后，线程 t#ThreadLocalMap，会新建一个 Entry 实例，其 Key 以弱引用的方式包装，`WeakReference` 指向 ThreadLocal 实例。

3. 当线程 t 执行完 `funcA()` 方法后，该方法的栈帧会被销毁，栈帧中的 `local` 强引用则会被回收，但如果线程 t 还在继续调用其他方式时，则会导致 t#ThreadLocalMap 中对应的 Entry.Key 引用，还指向 ThreadLocal 实例。

4. 如果 Entry#Key 引用是**强引用**的话，那么就会导致 Key 引用指向的 ThreadLocal 实例以及对应的 Value 值，都不能被 GC 回收，造成内存泄漏的发生。

5. 如果 Entry#Key 引用是**弱引用**的话，那么在下次 GC 发生时就会，让使那些没有被其他强引用指向、仅被Entry#Key 所指向的 ThreadLocal 实例被顺利回收，在 Entry#Key 引用被回收之后，其 Entry#Key 被设置 null，在后续调用 `get()/set()/remove()` 时，ThreadLocalMap 的内部代码就会清除这些 Key 为 null 的 Entry，从而释放对应的内存，避免内存泄露的发生。

**内存泄露**发生的场景：

1. 然而，即使 ThreadLocalMap#Entry 的 Key 被设置为弱键，可以避免内存泄露的发生，但是，如果 ThreadLocal  使用不当的话，还是可能会出现内存泄露。
2. 第一种情况是，**Entry.value 导致的内存泄露**：
   - 1）在`set()` 方法调用后， 假设没 调用 ` get()` 方法，就退出这个  `funA()` 方法，`local` 局部变量被回收后，t#ThreadLocalMap 的 Entry#key 被设置 null。
   - 2）然后，线程 t 继续运行，没有被销毁，也没有调用过任何 `get()/set()/remove()` 方法，导致那一整个 key 为 null 的 Entry 都不会被回收， 导致 Entry.value 内存泄露额度发生。
   - 3）这种现象很容易，发生在线程池中的 Thread 实例中，解决方法是， 只要后续存在任何一个 `get()/set()/remove()` 方法被调用，就会触发 Key为 null 的 Entry 的清理工作，释放掉对应的 Entry 内存，解决 Entry.value 内存泄露的问题。
3. 而第二种情况则是，**static、final 修饰 ThreadLocal 导致的内存泄露**：
   - 1）首先，ThreadLocal 实例被 static 修饰，可以保证每个线程操作这个 ThreadLocal，作为 ThreadLocalMap Entry#key 时，都会共享一份地址空间，节省内存的使用。
   - 2）其次，使用 final 修饰，可以确保 ThreadLocal 实例的唯一性，防止使用过程中发生动态变更。
   - 3）此时，由于修饰后的 ThreadLocal 会以单例的形式存在，一直被 GC Root 强引用，导致引用该 ThreadLocal 实例的 ThreadLocalMap，它的 Entry#Key 在 Thread t 实例的生命周期内，始终会保持为非 null。
   - 4）这样，该 Entry 就不能被 ThreadLocal 自动清空掉，导致其 Value 所指向的对象，一直被 Entry 强引用，于是这个对象就在该线程 t 的生命周期内，一直不会被释放掉，导致内存泄漏的发生。
   - 5）所以，在使用完 static、final 修饰的 ThreadLocal 实例后，要及时调用 `remove()` 来进行显式地释放掉。

##### 3、总

1. 综上，虽然使用 ThreadLocal 可以轻量级地保证变量的线程隔离。

2. 但如果使用不当，就容易发生内存泄漏，如果我们在 ThreadLocal 使用完毕后，及时调用 `remove()` 方法，就可简单、有效地避免这些内存泄漏的情况发生。

   => 这里可以讲一下这个实际案例《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 6）自研 DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源。

3. 以上，就是我对 ThreadLocal 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.5. HashMap 底层原理？

##### 1、总

HashMap，是 Map 接口的散列表非线程安全形式的实现，可以允许 null 值和 null 键，但不保证元素的顺序，在散列均匀的情况下，`get()/put()/remove()` 方法时间复杂度都是 O（1），当发生哈希冲突时，是通过拉链法来解决，在 JDK 7 中是通过数组 + 链表来实现，在 JDK 8 中是通过数组 + 链表 + 红黑树来实现。

其中，它有几个**重要的参数**：

1. `table.length`：当前散列表的桶容量，初始时默认为 16。

2. `size`：当前 HashMap 的实际大小，等于 Entry 条目总数。

3. `threshold`：HashMap 的阈值，当实际大小超过阈值时，HashMap 会发生扩容为 2 倍的桶容量和阈值，在 JDK 8 中，初始化时 = 默认负载因子 0.75f * 默认桶容量 16 = 12，扩容后超过 Integer.MAX_VALUE 时，等于扩容后的容量 * 设定的负载因子，在 JDK 7 中，初始化和扩容时，都 = 设定的负载因子 * 桶容量。

4. `loadFactor`：HashMap 的负载因子，由于会涉及 HashMap 阈值的计算，所以它是 HashMap 桶容量满意程度的表现，初始时默认为 0.75f，

   - 如果负载因子大于 0.75f，虽然会减少空间的开销，在 JDK 7 中，会导致阈值变大，扩容次数减少，桶拉链变长，增加查找的成本。
   - 如果负载因子小于 0.75f，则会让阈值变小，增加了扩容次数，增大空间的开销，不过好处在于，可以让哈希冲突减少，桶拉链变短，查找效率提高。

   => 所以，0.75f 的负载因子，是 JDK 对 HashMap 在时间和空间成本之间，做的一个很好的权衡取舍。

##### 2、分

在 JDK 8 中，

1. **散列原理**：

   - 1） Key 需要先传入 `hash（Object）` 扰动函数，将 HashCode 右移 16 位，从而混合 HashCode 的高位和低位，加大低位的随机性，减少哈希碰撞发生的概率，是一种性能、效用和质量的折衷方案。
     - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查找效率。
     - HashCode 右移 16 位，使得高位能被利用起来，保证了效用性。
     - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。
   - 2）`（n - 1） & hash` 计算哈希索引，相当于 `hash % n` 取模计算，n 指散列表当前的桶容量，hash 指获取 key#hashCode 扰动后的结果。
     1. 之所以**要取模计算**，不能直接使用 HashCode 作为索引的原因是，hashCode 为 int 类型，范围为[-2^32，2^32 - 1]，如果散列表数组与 HashCode 一一对应，那么就需要 40 亿的空间，明显在内存中是放不下的，所以 hashCode 是不能直接作为数组索引的。而如果使用 hashCode 对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组，也还能利用上 hashCode。
     2. 1）之所以要 n 散列表的桶容量，要取为 **n 的 2 幂次**，原因之一是为了，让 HashMap 在取模计算时，能够通过 n-1，来获得取低位掩码，然后通过低位掩码与扰动后的 hash 值进行一次与运算，即可得到该 hash 值，在散列表数组中的索引。
     3. 2）而另外一个原因是，为了让 HashMap 在扩容时，可通过旧 hash 值与低位掩码相与，只移动少部分与结果高位为 1 的条目，其他条目无需移动，减少了扩容时要搬运的条目数量，减少扩容时间。

2. **条目获取原理**：2 个常用的顶层 API 方法 `get()/getOrDefault()`，都依赖于 `getNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果桶 p 不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的节点，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果 p 没有 next 节点，则返回 null，代表 HashMap 中不存在对应的结点。
     3. 否则，说明 p 节点有 next 节点，如果 p 为红黑树结点，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。
     4. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。

3. **条目添加原理**：3 个常用的顶层 API 方法 `put()/putIfAbsent()/putAll()`，都依赖于 `putVal()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果 p 桶为 null，则直接 new Node 放到该桶即可。
   - 3）如果 p 桶不为 null，则要分为 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果桶头结点 p 为红黑树结点，则使用 `TreeNode#putTreeVal()` 添加 key：value 条目。
     3. 如果 p 为普通链表结点，则遍历 p 桶链表，遍历过程中，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     4. 如果遍历 p 桶链表，没找到对应的结点，则在链尾 new Node 一个结点，且添加后，判断如果当前链表至少有 8 个结点，则调用 `HashMap#treeBin()` 将当前桶链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#HashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）如果发生的不是值替换，则更新修改模数，以及 HashMap 的实际大小，如果实际大小大于阈值，则还需要调用 `resize（）` 进行扩容并转移结点。
   - 5）最后返回 null，代表条目插入成功。

4. **扩容原理**：

   - 1）在添加条目后，判断到实际大小大于阈值时，则会触发 HashMap 的扩容操作。
   - 2）扩容前，正常情况下是，让容量 * 2，阈值 * 2 作为新容量和新阈值，而如果阈值超出了 Integer.MAX_VALUE，则新阈值会被设置为新容量 * 设定的负载因子。
   - 3）然后，根据新容量，创建新数组作为新的散列表： `(Node<K,V>[])new Node[newCap]` 。
   - 4）接着，从头遍历旧的散列表数组，挨个判断桶头节点，或者桶链表：
     1. 如果桶 j 只有一个元素，则重新计算哈希索引，转移元素到新表即可。
     2. 如果桶 j 为红黑树，则调用红黑树的 `TreeNode#split()` 方法，可通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，然后分别判断 lo、hi 链表长度小于等于 6，则退化成普通链表，否则树化为红黑树。这也正是 n 之所以要为 2 幂次的其中一个原因。
     3. 如果桶 j 为普通链表，则通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引。

5. **条目删除原理**：2 个常用的顶层 API 方法 `remove(Object)/remove(Object, Object)`，都依赖于`removeNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果 p 桶不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，则将 p 引用赋值给 node 引用，待后面做删除操作。
     2. 否则，说明在桶头没找到对应的节点，如果桶头结点 p 也没有 next 节点，则将 p 引用赋值给 node 引用，待后面做删除操作。
     3. 否则，说明 p 节点有 next 节点，如果 p 为红黑树结点，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，并将其引用赋值给 node 引用，待后面做删除操作。
     4. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，并将其引用赋值给 node 引用，待后面做删除操作。
     5. 如果找不到，则设置 node 引用为 null。
   - 4）如果 node 引用为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 5）如果 node 引用不为 null，说明找到了对应的结点，如果此时 matchValue 为 true，则还要判断 value 对象 equals，分为 3 种情况判断：
     1. 如果 node 为红黑树结点，则调用 `TreeNode#removeTreeNode()` 删除节点。
     2. 如果 node 为普通结点，且作为桶头，则脱钩 node 节点，并更新 node 后继作为新的桶头。
     3. 如果 node 为普通结点，也不为桶头，则链接它的前驱和后继，脱钩 node 节点。
   - 6）最后，如果脱钩 node 节点成功，则更新修改模数、实际大小，返回 node 节点引用。

6. **红黑树 TreeNode 节点性质**：

   - **性质 1**：红黑树的结点要么是红色，要么是黑色。
   - **性质 2**：红黑树的根结点是黑色的。
   - **性质 3**：红黑树的叶子结点（nil）都是黑色的。
   - **性质 4**：红黑树的红色结点必须有两个黑色结点。
     - 推论：从根结点到每个叶子结点的所有路径上，不可能存在两个连续的红色结点。
   - **性质5**：红黑树是黑色平衡的，即从根结点到每个叶子结点的所有路径中，所经过的黑色结点数都是一样的。
     - 推论：如果一个结点右黑色的子结点，那么该结点一定是有两个孩子结点，因为必须有另一半才能保证该结点黑色平衡。

7. **红黑树旋转原理**：目的是，为了在结点的添加和删除后，避免子树高度发生变化，通过调整树结构，来保证树重新达到平衡。

   - **左旋**：口诀，**左右左右右**，即以 x 结点作为旋转点进行**左**旋，旋转后，x 的**右**结点 p 成为 x 的父结点，p 原本的**左**结点成为 x 结点的**右**结点，p 原本的**右**结点保持不变。
   - **右旋**：口诀，**右左右左左**，即以 x 结点作为旋转点进行**右**旋，旋转后，x 的**左**结点p成为x的父结点，p 原本的**右**结点成为 x 结点的**左**结点，p 原本的**左**结点保持不变。

8. **红黑树节点插入原理**：`putTreeVal（HashMap，Node，int，K，V）`

   - 1）从根结点遍历比较待插入结点 x 的 hash 值，小于等于 0 的，说明 x 应该在左边，大于 0 的说明
     x 应该在右边。
   - 2）找到合适位置后（叶子结点），构建 TreeNode 结点，维护 x 与父结点、prev 前驱结点、next 后继结点的关系。
   - 3）插入后，再平衡红黑树，返回 null，表示插入成功。

   其中，插入后，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：

   - 1）为空结点新增：x 插入后，将成为一个 2 结点，插入前，树为 null，插入后， x 需要变黑色，作为根结点，明显在 HashMap 中，不可能会有这种情况，因为链表长度至少要为 8。
   - 2）合并到 2 结点：x 插入后，将成为一个 3 结点，插入前，2 结点为黑色，插入后无论是（上黑下左红 |  上黑下右红）, 都符合 3 结点要求，因此无需调整。
   - 3）合并到 3 结点中：x 插入后，将成为一个 4 结点，插入前，为 3 结点（上黑下左红 |  上黑下右红），插入后，成为 4 结点（黑红红），其中，根据 x 插入位置的不同，又分为 6 种情况：
     1. x 插入后，为左三(中左 左*) 黑红 红，不符合红黑树定义，需要调整，则中 1 右旋，中 1 变红，左 1 变黑。
     2. x 插入后，为(中左右*)  黑红红，其实就相当于左三，如果对父结点进行左旋，就可得到左三 ，不符合红黑树定义，需要调整，则左 1 左旋（得到左三），中 1 右旋，中 1 变红，新左变黑。
     3. x 插入后，为右三(中 右右*) 黑红红，不符合红黑树定义，需要调整，则中 1 左旋，中 1 变红，右 1 变黑。
     4. x 插入后，为(中 右左*) 黑红红，其实就相当于右三，如果对父结点进行右旋，就可得到右三，不符合红黑树定义，需要调整，则右 1 右旋（得到右三），中 1 左旋，中 1 变红，新右变黑。
     5. x 插入后，为(中左 右*) 黑红 红，符合红黑树定义，因此无需调整。
     6. x 插入后，为(中左* 右) 黑红 红，符合红黑树定义，因此也无需调整。
   - 4）合并到 4 结点中：x 插入后，成为一个裂变状态即升元，插入前，为 4 结点（黑红红），插入后，4 结点需要颜色反转，爷结点成为新的 x 结点，继续下一轮的向上调整，其中，根据 x 插入的位置不同，分为 4 种情况：
     1. x 插入后，为(中左左* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红， 右 1 变黑，中看作为“插入结点”，继续向上调整。
     2. x 插入后，为(中左右* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 保持为红，右 2 变黑，中看作为“插入结点”，继续向上调整。
     3. x 插入后，为(中左 右左*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红，右 1 变黑，中看作为“插入结点”，继续向上调整。
     4. x 插入后，为(中左 右右*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 变黑，右 2 保持为红，中看作为“插入结点”，继续向上调整。

9. **红黑树节点删除原理**：`removeTreeNode（HashMap，Node，boolean）`

   - 1）首选，由于红黑树是一种自平衡的二叉搜索树，而二叉搜索树删除，本质上就是找前驱，或者后继结点来替代删除。

   - 2）如果要删除的结点，是叶子结点，则直接删除即可（肯定是黑色），不过由于是黑色，打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 3）如果要删除的结点，只有 1 个孩子结点，则使用孩子节点进行替代，然后删除"替代"的孩子节点，由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 4）如果要删除的结点，有 2 个孩子结点，则需要找到后继进行替代，然后删除"替代节点"，其中，"替代节点"删除时又要分为 2 种情况：

     1. 如果替代结点，没有孩子结点，说明为 2-3-4 树的 2 结点，则直接选择为"替代结点"进行删除。
     2. 如果替代结点，有孩子结点，且孩子结点为替代方向（后继方向），说明所在的结点为 2-3-4 树的 3 结点或者 4 结点，则选择孩子结点作为"替代结点"进行删除。

     由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   => 其中，删除时，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：`balanceDeletion（TreeNode，TreeNode）` 。

   - 1）x 自己搞得定：

     1. 自己搞得定的意思是，可以在 2-3-4 树节点内部，自己处理完毕，不会影响其他节点的结构。
     2. 对应的情况为，x 要么为 3 结点，要么为 4 结点中的红结点，则直接置黑，返回 x 用作删除即可，因为红节点不会打破黑色平衡。

   - 2）x 自己搞不定，但兄弟搞得定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟搞得定的意思是，兄弟结点存在多余的子结点，即兄弟结点为 3 结点或者 4 结点，这样，x 的父结点，就可以借出结点下来合并到 x 结点，兄弟结点再借出结点合并到父结点，就可以顺利删除 x 了，同时 2-3-4 树的结构还可以保持不变。
     3. 但是，前提是 x 的兄弟结点是真正的兄弟结点，即为黑色的结点，如果为红色的结点，说明其只是父结点（3结点）的红结点，此时还需要对父结点进行旋转，以保证 x 有真正的兄弟结点。

     此时，根据情况又分为 3 种情况：比如 x 为左边时，右边情况同理。

     1. 兄弟结点为 3 结点，同时有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右孩子，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点），xpr 借出去的结点颜色为 xp 借出去的结点颜色，xp 借出去的结点颜色一定要为黑色（相当于3结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。
     2. 兄弟结点为 3 结点，但没有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 没右孩子，不能直接对父结点进行左旋，所以，这是一个临时情况，需要对 xpr 进行右旋，转换为有右孩子的情况一，再做一的相同处理即可。
     3. 兄弟结点为 4 结点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点，而且还多借出左孩子合并到 x 结点中，这里选择借出 2 个结点，可以进一步减少花销），xpr 合并到父结点的颜色为 xp 借出去的结点颜色（而借出去的左孩子本来为红色所以不用变），xp 借出去的结点颜色一定要为黑色（相当于 4 结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。

   - 3）x 自己搞不定，并且兄弟也搞不定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟也搞不定的意思是，兄弟结点也为黑结点，没有多余的子结点，如果直接删除 x，则会导致叔结点所在路径多了一个黑色结点，造成黑色不平衡。

     1. 这种情况是，兄弟结点为 2 结点，为了让 x 能够顺利删除，兄弟结点需要置红（自损），这样 x 在删除后，x 父结点所在树还是黑色平衡的。
     2. 但是，如果 x 父结点为黑色，x 爷结点所在树则不黑色平衡了，因为父结点这边少了一个黑色结点，所以，父结点的叔结点要也要被置红。
     3. 因此，需要一路向上自损，直到碰到任意一个终止条件，即可结束自损：
        - **向上碰到根结点**：经过一路置红叔结点，直到循环到根结点时（因为上面已经没有父节点了），则代表自损完毕，此时整棵树都是黑色平衡的了（都减少了一个黑色结点）。
        - **向上碰到红结点**：如果碰到红色结点，只需要把该结点置黑，无需再置红叔结点了，相当于在父结点这边子树补回了一个黑色结点，不影响这边子树的黑色结点数目，整棵树还是黑色平衡的。

10. **红黑树节点获取原理**：`getTreeNode（int，Object）`

    - 1）根据 hash 值和 key 值，从根结点开始查找红黑树结点，小于等于 0 的，说明 x 应该在左边，大于 0 的，说明 x 应该在右边。
    - 2）直到找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，说明该结点就是要找的结点，则直接返回即可。
    - 3）如果找不到，则返回 null，代表没找到对应的结点。

11. **链表树化成红黑树**：`HashMap#treeifyBin()`

    - 1）先判断桶容量，是否大于等于 64，如果不是，则调用 `resize()` 扩容即可。
    - 2）如果确实大于等于 64，则先挨个维护每个桶的链表，为双向无环链表。
    - 3）接着，调用 `TreeNode#treeify` 树化该链表成为红黑树，其步骤为：
      1. 取桶头结点作为根结点，置黑。
      2. 然后遍历桶链表，比较根结点 hash 值与当前遍历结点的 hash 值，小于等于的，则继续遍历左子树，大于的，则遍历右子树，然后插入当前遍历结点到对应的位置，再平衡红黑树。
    - 4）直到散列表所有桶、每个桶的链表结点遍历完毕，再返回。

12. **红黑树退化成普通链表**：`untreeify（HashMap）`

    - 1）遍历桶链表，重新构建为 `next=null` 的 Node 结点。
    - 2）再重新维护每个它的 next 指针。
    - 3）直到遍历结束，最后返回链头指针 hd 即可。

##### 3、总

相对于 JDK 7#HashMap，JDK 8 主要优化了以下 3 点：

1. **引用红黑树**：避免链表过长影响查找效率，同时还可以保证插入性能。
2. **`resize()` 扩容优化** 以及**头插法改成尾插法** ：取消了 rehash 操作，通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，以及由于头插法会使得结点转移后节点倒序，改用头插法改成尾插法，可以保证转移后，链表结点的相对顺序不变，从而解决了并发情况下扩容导致的死循环问题。

但 HashMap 仍是非线程安全的，并发下添加结点，可能会造成数据丢失，而线程安全的 Map 使用方式有：

1. **在 HashMap API 外层使用锁，**来保证线程安全。
2. **使用 Collections 内部类 SynchronizedMap**：通过持有传入的 Map 引用，以及 `mutex` 对象锁，使用 synchronized 关键字来修饰 Map 方法，从而包装成线程安全的 Map 实现类。
3. **使用 HashTable**：散列表线程安全的实现类，默认初始容量 11，默认负载因子 0.75f，不允许为 null 键和null 值，底层通过使用 synchronized 关键字修饰方法，来保证线程安全，所以效率低下。
4. **使用 ConcurrentHashMap**：支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可以在保持并发可读的同时，还能最小化锁争用。

=> 以上，就是我对 HashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.6. ConcurrentHashMap 底层原理？

##### 1、总

ConcurrentHashMap，支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可在保持并发可读的同时，还能最小化锁争用。

其中，它有几个**重要的参数**：

1. `table`：当前正在使用的散列表，volatile 修饰，具有并发可见性。
2. `nextTable`：并发扩容时，持有的另外一个散列表，volatile 修饰，具有并发可见性。
3. `sizeCtl`：ConcurrentHashMap 的控制变量，volatile 修饰，具有并发可见性，提供 `SIZECTL` 通过 CAS 进行原子性更新。
   - 1）在构造函数中为（1.5 倍指定容量 + 1，或者指定容量 / 负载因子）的最小 2 幂次。
   - 2）当分布式计数统计结果，大于 `sizeCtl` 时，则触发并发扩容机制，高 16 位为扩容标记，低 16 位为并发扩容线程数（步长为 1，然后再每有一个线程参与协助扩容则 +1）。
   - 3）在扩容完成后，等于 0.75f * 旧表桶容量，作为下一次扩容的阈值判断条件。

几种重要的**结点类型**：

1. `Node`：实现 Map.Entry，是 ConcurrentHashMap 中最普通的链表结点，拥有 hash、key、val、next 成员变量，是其他类型结点的父类，其中 val 和 next 使用 volatile 修饰，保证了并发可见性。
2. `TreeNode`：继承 Node 结点，是 ConcurrentHashMap 中的红黑树结点，在 Node 结点的基础上，还维护了parent、left、right、red 红黑树成员变量。
3. `TreeBins`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中红黑树的桶头结点，hash 值为-2，持有红黑树根结点root 指针和链头 first 指针，不保存键和值。
   - 2）同时还维护了读写锁，强迫写线程必须等待所有读线程完成后，才能进行红黑树结点操作。
   - 3）当读时不存在并发写线程，使用 root 指针走红黑树遍历方式查找结点，当读时存在并发写线程，使用first 指针走链表遍历方式去查找结点。
4. `ForwardingNode`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中的转发结点，hash 值为 -1，持有 nextTable 引用，没有键和值。
   - 2）在线程协助转移结点到新表后，会在旧表原位置维护一个 `Forwarding` 结点，以标识旧表正在发生扩容操作，让下一个线程碰到时，可以协助进行转移旧表结点。

##### 2、分

在 JDK 8 中，

1. **散列原理**：原理与 HashMap 类似，但不同的地方在于，HashMap 的扰动函数叫 `hash(Object)`，而 ConcurrentHashMap 的扰动函数叫 `spread（Object）` 。

2. **条目获取原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）`getOrDefault()`，依赖于 `get()` 方法，其中 val 和 next 使用 volatile 修饰，保证线程可见性，所以，`get()` 方法可以不加锁地照常遍历，而在读红黑树时，由于并发更新需要涉及到旋转，所以有写时会走链表方式去读，在树方式读时，不能并发下对红黑树进行写。
   - 2）因此，可与 `put()` 和 `remove()` 等更新方法同时执行，但反映的只是，最近完成更新的结果，并发检索可能只反映出部分条目的更新。

3. **条目添加原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p 为null，new Node 以后是通过 CAS 的方式放入到散列表中的。
   - 2）然后，如果桶 p 不为 null，还要判断是否为 `Forwardding` 节点（p#hash = -2），如果是的话，则当前线程要参与协助扩容。
   - 3）然后，如果桶 p 也不为 `Forwardding` 节点，那么还会对其加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果桶 p#hash 值小于 0，说明 p 为红黑树，则使用 `TreeBin#putTreeVal()` 添加 key：value 条目。
     2. 如果桶 p#hash 值大于等于 0，说明为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent为false，则发生值替换，直接返回即可。
     3. 如果没找到对应的结点，则在链尾直接 new Node 一个结点。
     4. 如果添加后，当前链表至少有 8 个结点，则调用 `ConcurrentHashMap#treeBin()`，将当前链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#ConcurrentHashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）最后，如果发生的不是值替换，而是条目插入，还要并发分布式计数，然后判断是否需要扩容，要的话则发起扩容。，返回 null，代表结点插入成功。

4. **条目删除原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p，为 `Forwardding` 节点，则当前线程要参与协助扩容。
   - 2）如果 p 不为 `Forwardding` 结点，则会对 p 进行加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果 p#hash 小于 0，说明 p 为红黑树，则调用 `TreeNode#getTreeNode()`，来获取 hash 和 key 对应的结点，调用 `TreeNode#removeTreeNode()` 删除该结点。
     2. 如果 p#hash 值大于等于0，说明它为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，则脱钩该结点。
     3. 如果没找到对应的结点，则返回 null，代表 ConcurrentHashMap 不存在对应的结点。
   - 3）最后，如果脱钩结点成功，则还要并发分布式计数，返回旧值，代表删除成功。

5. **分布式计数相关变量**：

   - 1）`baseCount`：分布式计数基数，volatile 修饰，具有并发可见性，提供 `BASECOUNT` 通过 CAS 进行原子性更新。
   - 2）`counterCells`：分布计数单元格数组，volatile 修饰，具有并发可见性，提供 `CELLVALUE` 通过 CAS 进行原子性更新。
   - 3）`cellsBusy`：分布式计数单元格繁忙标记，volatile 修饰，具有并发可见性，提供 `CELLSBUSY` 通过 CAS 进行原子性更新。

   => 在要获取 ConcurrentHashMap 实际大小 `sumCount()`  时，可以通过 `baseCount` + 累加 `counterCells` 数组所有格子的值，得到一个瞬时的累加和作为实际大小。

6. **并发分布式计数原理**：在 `putVal()` 和 `removeNode()` 方法更新玩后，还需要并发叠加 `x=1/-1`，叠加成功后，获取瞬时的累加和作为实际大小，用于扩容判断，其步骤为：

   - 1）先尝试在 `baseCount` 叠加 x，如果叠加成功，则继续做扩容判断。
   - 2）如果 `baseCount` 叠加 x 失败，则根据当前线程随机值 `h=ThreadLocalRandom.getProbe()`，尝试在 `CounterCell[h * (n-1)]` 叠加 x，如果叠加成功，则做扩容判断。
   - 3）如果 `CountCell` 叠加 x 失败，则调用 `fullAddCount()` 自旋 + CAS 竞争添加 x 到 `CounterCell[] as` 中。

7. **并发扩容原理**：

   - 1）如果 `sumCount()` 获取到的瞬时累加和，大于 `sizeCtl` ，说明需要扩容，则启动扩容机制，调用 `resizeStamp（n）` 生成扩容标记 `rs`，保证扩容过程不会被重复启动。
   - 2）如果 rs 大于等于 0，说明散列表还没被扩容，则 CAS 更新 `sizeCtrl=(rs << RESIZE_STAMP_SHIFT) + 2)`，更新成功后，rs 为一个负数，再第一次调用 `transfer(tab, null)`，开始扩容创建 2 倍旧表容量的 nextTab，并开始转移旧表结点到新表。
   - 3）如果 rs 小于 0，说明散列表正在被其他线程扩容，则 CAS 更新并发扩容线程数 `sizeCtrl=sc+1`，更新成功后调用 `transfer(tab, nt)`，加入扩容一起转移旧表结点到新表。
   - 4）其中，在某个桶结点被转移后，会在旧表中留下一个 `Forwardding` 节点，其他线程在调用`put()/remove()` 时，如果遇到这种节点，则会根据它持有的 `nextTab`，参与协助扩容。
   - 5）最后，`transfer()` 中会根据 `(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT` 来判断，当前转移线程是否为最后一个扩容线程，如果是的话，则会提交新散列表，正式把 `nextTab` 设置为 `table`，然后设置 `sizeCtl` 为 0.75f * 旧表桶容量（作为下一次扩容的阈值判断条件）才返回，返回后还要自旋判断一次是否需要再次扩容，防止并发情况下桶容量又不够的情况。

8. **红黑树线程安全原理**：

   - 1）ConcurrentHashMap 的红黑树过程与 HashMap 类似，但不同的地方在于，由于并发更新时，红黑树可能会涉及到旋转，TreeBin 维护了一个读写锁，在调用 `TreeBin#putTreeVal()` 或者 `TreeBin#removeTreeNode()` 方法时，即使外层有获取可重入锁 synchronized，在操作红黑树之前，也要调用 `lockRoot()`，调用完成后再 `unlockRoot()`，保证写时走链式读，走树读时不能写。
   - 2）其原理如下：
     1. TreeBin 持有 lockState 属性，值有读、等待写、以及写状态（WRITER=1，WAITER=2，READER=4，读/写状态可与等待状态结合）。
     2. 调用 `lockRoot()` 时，CAS 竞争更新 lockState 为 `WRITER`，竞争成功，说明当前线程持有写锁成功，可以继续做红黑树操作，操作完后 `unlockRoot` 释放写锁，置 lockState 为 0。
     3. 竞争失败，则调用 `contendedLock()` 继续争抢写锁，争抢不到则会进入阻塞状态，直到所有调用`TreeBin#find(int，Object)` 的线程，都调用完毕后，才会被唤醒，然后重新争抢写锁。

##### 3、总

相对于 JDK 7#ConcurrentHashMap，JDK 8 主要优化了以下 3 点：

1. **数据结构**：取消 Segment[] + HashEntry[] + 链表的数据结构，改用 Node[] + 链表 + 红黑树的数据结构，提升查找效率。
2. **线程安全方式**：取消了 Segment#ReentrantLock 分段锁保证线程安全的方式，改用 Node + CAS 自旋锁+ synchronized 锁定桶结点 + TreeBin 读写锁的方式，来保证并发安全，进一步提高并发量。
3. **扩容方式**：取消了获取锁再做计数 + 扩容的方式，改用释放 synchronized 同步锁，利用 CAS 自旋锁 + 并发分布式计数 + 并发扩容的方式，支持更高的并发更新与查询。

=> 以上，就是我对 ConcurrentHashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.7. 红黑树性能稳定吗？

经过大量实验证明，红黑树可以保证，在最好甚至最坏情况下，所有操作（插入/删除/查找等）的时间复杂度，都是对数级别 O（logN），无论插入顺序如何，红黑树都是接近完美平衡的，其操作成本（包括旋转和变色），比 BST 降低 40% 左右。

![1647876146340](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647876146340.png)

=> 因此，红黑树性能是稳定的，任何时间复杂度都为 O（logn）级别。

#### 3.2.1.8. 设计模式有了解哪些？线程池这种是什么设计模式？

##### 1、总

我了解过单例、工厂、建造者、观察者、装饰者、代理、责任链这几个常用的设计模式。

##### 2、分

1. **单例**：某个类只能生成一个实例，该实例被全局访问，比如 Spring 容器一级缓存里的单例池。

   - 实现方式：饿汉式、懒汉式、**双重检查锁、静态内部类、枚举类**等多种实现方式。

2. **工厂**：工厂中最简单实用的模式，简单工厂模式，可以理解为是不同工厂模式的一个特殊实现，比如 Spring 中的 BeanFactory、ApplicationContext。

   实现方式：

   - 简单工厂，是由一个工厂同一个方法来创建多个产品实例。
   - 工厂方法，则是对工厂做了抽象，做到一个产品一个工厂。
   - 抽象工厂，则是一个工厂提供多个创建接口，分别创建不同的产品实例。

3. **建造者**：可以将一个复杂对象的构造与他的表示分离，使同样的构建过程可以创建不同的表示，比如 SpringCloud 中的 FeignClientBuilder。

   - 建造者关注的是组装过程，类似于组装车间，工厂关注的是创建过程，类似于生产车间。

4. **观察者**：在被观察者本身的状态改变时，主动发出通知，呼叫各观察者所提供的方法走对应的实现，比如 Spring 中的各种 ApplicationContextEvent 和 ApplicationListener，Dubbo 中的 InvokerListener、ExporterListener。

5. **装饰者**：通过创建一个包装对象，也就是用包裹真实的对象，在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能，比如 JDK#I/O 中的处理流和节点流 。

6. **代理**：为其他对象提供一种代理，在前后织入业务代理，以增强原始对象，比如 JDK 动态代理，Spring AOP 中的 CGLIB 动态代理，Dubbo 中的 Javassist 动态代理。

   - 静态代理：静态代理，是由程序员创建或者工具生成代理类的源码，再在编译生成代理类。所谓静态，也就是程序运行前就已经存在代理类的字节码文件，这时代理类和委托了类的关系在运行前就确定了。
   - 动态代理：动态代理在实现阶段不用关心代理类，而在运行阶段才指定哪一个对象。

7. **责任链**：通过持有下一个实现类的引用，进行链式调用，比如 Web 中的 Filter、Spring Cloud 中的 GatewayFilter、Dubbo 中的 ProtocolFilterWrapper。

##### 3、总

1. 线程池这种属于享元模式。
2. 享元模式，Flyweight Pattern，会尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象，主要用于减少创建对象的数量，以减少内存占用和提高性能。
3. 比如还有数据库连接池、Http 连接池等。

=> 以上，就是我对 设计模式 的一些理解，请问有什么细节需要补充的吗？

#### 3.2.1.9. 动态代理实现原理，如果给你实现的话你会怎么做？

##### 1、总

对于我阅读过源码的动态代理有，JDK 动态代理和 CGLIB 动态代理。

##### 2、分

###### 1）JDK 动态代理

1. **条件**：JDK 动态代理，需要提供接口。
2. **使用方式**：
   - 1）实现 `InvocationHandler` 接口，并重写 `invoke()`，在反射调用前后，编写需要代理的业务逻辑。
   - 2）通过 `Proxy.newProxyInstance(..)` 方法，来获取动态代理对象，其**方法参数**有：
     - `ClassLoader loader`：动态代理类的类加载器，一般取原委托类的类加载器。
     - `Class<?>[] interfaces`：原委托类实现的接口 Class 对象数组。
     - `InvocationHandler`：动态代理处理程序，在调用动态代理类的增强方法时，会触发回调到它的 `invoker()` 方法。
3. **实现原理**：
   - 1）`newProxyInstance()` 通过反射，生成含有接口方法的 `$Proxy0` 代理类，`$Proxy0` 继承了 `Proxy` 类。
   - 2）在 `$Proxy0` 的构造方法中，会先调用父类的构造方法，让 `Proxy` 父类持有 `InvocationHandler` 实现类的引用。
   - 3）最后，该代理对象的所有方法，都会转发调用到，父类持有的 `InvocationHandler#invoke()` 方法。
   - 4）`InvocationHandler#invoke()`：该方法会传入原始方法的 Method 对象，用于反射调用原始方法。
   - 5）这样，只需要在反射调用前后，编写需要代理的业务逻辑，即可增强原始方法，实现动态代理。

```java
public interface MessageService { 
    void sendMessage(); 
}

public class MessageServiceImpl implements MessageService {
    public void sendMessage() {
        System.out.println("MessageServiceImpl.sendMessage"); 
    } 
}

public class JdkProxy<T> implements InvocationHandler {

    T target;

    public T getProxy(T target) {
        this.target = target;

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理拦截开始！");
        Object result =  method.invoke(target, args);
        System.out.println("JDK动态代理拦截结束！");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        JdkProxy<MessageService> jdkProxy = new JdkProxy();
        MessageService messageService = jdkProxy.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

###### 2）CGLIB 动态代理

1. **条件**：CGLIB 动态代理，无需提供接口，即可实现，当然，也可以代理有接口的原委托类。
2. **使用方式**：
   - 1）实现一个 `MethodInterceptor`：代理方法调用时，会被转发到该类的 `intercept()` 方法。
   - 2）构建 `net.sf.cglib.proxy.Enhacner`：通过 `setSuperClass(Class)` 指定原委托类，`setCallback(Class)` 指定当前 `MethodInterceptor` 实现类 。
   - 3）最后，通过调用 `(T) enhancer.create()` 方法，获取代理对象。
3. **实现原理**：
   - 1）利用 ASM 开源包，通过修改原委托类 Class 文件的字节码，生成子类，覆盖原委托类的方法，并在覆盖方法中实现了增强。
   - 2）在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理。

```java
public class PlayService {
    public void play() {
        System.out.println("PlayService.play");
    }
}

public class CglibProxy<T> implements MethodInterceptor {

    T target;

    public T getProxy(T target) {
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return (T) enhancer.create();
    }

    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理拦截开始!");
        Object result = methodProxy.invokeSuper(o, objects);
        System.out.println("CGLIB动态代理拦截结束!");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        CglibProxy<PlayService> cglibProxy = new CglibProxy();
        
        // 测试代理无接口服务类
        PlayService playService = cglibProxy.getProxy(new PlayService());
        playService.play();
		
        // 测试代理有接口服务类
        CglibProxy<MessageService> cglibProxy1 = new CglibProxy(); 
        MessageService messageService = cglibProxy1.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

##### 3、总

因此，总的来说，

1. JDK 动态代理，是在调用代理类方法时，通过调用 `InvocationHandler#invoke()`，再反射调用原始方法，从而实现动态代理，属于反射调用，会存在一定的性能花销。
2. CGLIB 动态代理，是在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理，属于父类方法调用，在初次调用时，由于需要生成 FastClass，效率会比较低，但在 FastClass 生成后，往后访问由于不用涉及反射调用，此时性能花销非常小。

=> 以上，就是我对 动态代理 的一些理解，CGLIB 动态代理类生成的具体细节也不太记得了~

#### 3.2.2.0. 线上 CPU 100% 如何解决？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%。

#### 3.2.2.1. Redis 哨兵模式和集群模式的区别？

##### 1、总

Redis 支持三种集群架构，分别是主从模式、哨兵模式、集群模式。

##### 2、分

###### 1）主从模式 | 无高可用、简单

将哨兵模式之前，就需要先介绍一下主从模式~

![1632299571516](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632299571516.png)

1. **是什么**：

   - 1）只是简单地使用了主从复制，一个 Master 可以有多个 Slave，Slave 也可以有自己的 Slave。
   - 2）默认使用异步复制， Slave 会以每秒 1 次的频率，向 Master 报告当前复制流的处理进度。
   - 3）复制时，不会阻塞 Master，即使是正在进行初次同步， Master 也可以继续处理命令请求，也不会阻塞 Slave，即使 Slave 正在进行初次同步， 也可以使用旧版本的数据集来处理命令查询。
   - 4）同时，还支持读写分离模式，Master 负责读写，Slave 只负责读。

2. **怎么配置**：

   ```shell
   # Slave方参数
   # 1、配置主从复制Master的IP+端口
   slaveof <masterip> <masterport>
   # 2、如果Master通过requirepass配置密码，则Slave也需要进行相应的配置
   masterauth <master-password>
   # 3、默认允许，Slave初次同步未完成时，继续使用旧数据来响应客户端，配置no会阻塞初次同步期间的所有请求
   slave-serve-stale-data yes
   # 4、默认开启读写分离，Slave只能读取数据，不能写入数据
   slave-read-only yes
   
   # Master方参数
   # 5、默认关闭无磁盘化复制，Master磁盘不生成RDB文件，直接通过网络同步给Slave
   repl-diskless-sync no
   # 6、默认为3和10，如果至少有3个从服务器，并且这3服务器的延迟值都少于10秒，Master才会执行客户端请求的写操作
   # min-slaves-to-write 3
   # min-slaves-max-lag 10
   ```

3. **实现原理**：

   - 1）当建立一个 Slave 时， Slave 会向 Master 发送一个 `PSYNC master_run_id offset` 命令。
   - 2）如果 Slave 是首次连接，由于 Master 中不存在该 Slave 的复制偏移量，所以会触发一次完整重同步操作， 此时，Master 开始执行 `BGSAVE`， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。
   - 3）当 Master  `BGSAVE` 执行完毕后， Master 将执行保存操作所得的 .rdb 文件发送给 Slave， Slave 接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
   - 4）之后，Master 会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给 Slave，Slave 则实时同步这些数据。
   - 5）如果主从复制期间 Slave 断开连接，在自动重连后，会使用 `PSYNC master_run_id offset` 命令来进行同步，Master 会以增量复制的形式，向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。

   重连后的**部分重同步原理**：

   - 1）Master 会为被发送的复制流创建一个缓冲区 `in-memory backlog`， 并且 Master 和所有 Slave 之间都记录一个复制偏移量 `replication offset` 和一个主服务器 ID `master run id`。
   - 2）当出现网络连接断开时， Slave 重新连接后，会向 Master 请求继续执行原来的复制进程。
   - 3）如果 Slave 记录的主服务器 ID `master run id` ，和当前要连接的主服务器 ID `master run id` 相同， 并且 Slave 记录的偏移量 `replication offset` 所指定的数据，仍然保存在 Master 的复制流缓冲区 `in-memory backlog` 里面， 那么 Master 会向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
   - 4）否则，Slave 就要执行完整重同步操作。

4. **优点**：

   - 1）**部署简单**：仅使用两个节点，即可构成主从模式。
   - 2）**可以通过读写分离**：来避免读和写同时不可用的情况。

5. **缺点**：

   - 1）**无高可用保证**：一旦 Master 节点出现故障，主从节点就无法自动切换，直接导致 SLA 服务等级下降。
     - **解决方案**：添加哨兵监控。
   - 2）**Master 压力大**：所有的 Slave 节点数据的复制和同步，都由 Master 节点来处理，会造成 Master 节点压力过大。
     - **解决方案**：可以使用主从从的结构，通过引入从从同步，可以减少主从同步的次数。

6. **适用场景**：一般用于业务发展初期、并发量低、运维成本低的情况。

###### 2）哨兵模式 | 高可用、读多

![1632320226337](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632320226337.png)

1. **是什么**：Sentinel，哨兵，是 Redis 高可用的一种解决方案，可以监视一个或者多个 Redis Master 服务，以及其所有的从服务，当某个 Master 服务宕机后，会自动把这个 Master 下的某个从服务升级为 Master，从而代替已宕机的 Master，保证继续工作。

   Sentinel 的作用有：

   - 1）**监控**：Monitoring，Sentinel 会不断地检查 Master 和 Slave 是否运作正常。
   - 2）**提醒**：Notification，当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
   - 3）**自动故障迁移**：Automatic failover。当一个 Master 不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效 Master 的其中一个 Slave 升级为新的 Master， 并且让失效 Master 的其他 Slave 改为复制新的 Master。当客户端试图连接失效的 Master 时， 集群也会向客户端返回新 Master 的地址， 使得集群可以使用新 Master 代替失效 Master。

2. **怎么配置**：

   ```shell
   # 1、配置监控 127.0.0.1：6379 的 mymaster 服务器，并且客观下线需要取得2个(quorum)哨兵的同意，但是无论该值配置了多少，都需要多数哨兵的选举后，才能发起一次自动故障转移
   sentinel monitor mymaster 127.0.0.1 6379 2
   # 2、配置Master服务器密码（如果Master有配置的话）
   sentinel auth-pass <master-name> <password>
   # 3、配置判定mymaster主观下线的毫秒数
   sentinel down-after-milliseconds mymaster 60000
   # 4、配置主从切换的超时时间，需要自动故障转移时，如果当前哨兵没有去执行，那么在超过这个时间后，会由其他的哨兵来进行处理
   sentinel failover-timeout mymaster 180000
   # 5、配置在执行故障转移时，同步新mymaster的最大Slave并行数，如果全部Slave一起对新Master进行同步，由于在Slave载入RDB时会阻塞客户端请求，所以可能会造成所有Slave在短时间内全部不可用的情况出现
   sentinel parallel-syncs mymaster 1
   
   # 启动命令
   # 6、运行纯Sentinel服务器
   redis-sentinel /path/to/sentinel.conf
   # 7、在Redis Server上运行哨兵
   redis-server /path/to/sentinel.conf --sentinel
   
   # 运维命令
   # 8、查看imooc-master下的master节点信息
   sentinel master imooc-master
   # 9、查看imooc-master下的slaves节点信息
   sentinel slaves imooc-master
   # 10、查看imooc-master下的哨兵节点信息
   sentinel sentinels imooc-master
   ```

3. **Sentinel 自动发现原理**：

   - 1）一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换，通过发布与订阅功能，向频道 `__sentinel__:hello` 发送信息，来自动发现正在监视相同 Master 的其他 Sentinel ，无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址。
   - 2）**发布**：每个 Sentinel 会以 2 次 / s 的频率， 通过发布与订阅功能， 向被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道发送一条信息， 信息中包含了 Sentinel 的 IP、端口和运行 ID `runid`，还包括完整的 Master 当前配置。如果一个 Sentinel 包含的 Master 配置，比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。
   - 3）**订阅**：每个 Sentinel 都订阅了被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道， 查找之前未出现过的 Sentinel，当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了已知的、正在监视同一个 Master 的所有其他 Sentinel 。

4. **故障判定原理**：

   - 1）Sentinel 会以 1 次 / s的频率，向它所知的 Master、Slave、以及其他 Sentinel 实例，发送一个 `PING` 命令。
   - 2）如果某个实例距离最后一次有效回复 `PING` 命令的时间，超过了 `down-after-milliseconds` 的值， 那么这个实例会被 Sentinel 标记为**主观下线**。 
   - 3）如果一个 Master 被标记为主观下线， 那么正在监视这个 Master 的所有 Sentinel，都要以 1 次 / s 的频率，确认Master 是否真的进入了主观下线状态。
   - 4）当 Master 重新向 Sentinel 的 `PING` 命令，返回有效回复时，Master 的主观下线状态就会被移除。
   - 5）否则，如果有足够数量（>= `quorum` ）的 Sentinel，在指定的时间范围内，同意这一判断， 那么这个主服务器被标记为**客观下线**。
   - 6）而当没有足够数量（>= `quorum` ）的 Sentinel 同意主服务器已经下线， Master 的客观下线状态就会被移除。

   **主观下线**：

   - 1）主观下线，Subjectively Down， 简称 SDOWN，指的是单个 Sentinel 实例，对超时服务实例做出的判断。
   - 2）只有一个 Sentinel 认为是主观下线时，并不一定会引起服务实例的故障迁移，只有在足够数量（>= `quorum` ）的 Sentinel 都将一个服务实例标记为主观下线之后， 服务器才会被标记为**客观下线**， 此时自动故障迁移才会执行。

   **客观下线**：

   - 1）客观下线，Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对同一个服务实例做出 SDOWN 判断， 并且在经过通过  `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务实例下线判断。
   - 2）客观下线条件只适用于 Master，对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以  Slave 或者其他 Sentinel 永远不会达到客观下线的条件。
   - 3）只要 Sentinel 发现某个 Master 进入了客观下线状态，某个 Sentinel 会被其他 Sentinel 推选出， 并对失效的 Master 执行**自动故障迁移**操作。

5. **自动故障转移原理**：

   - 1）**Leader Sentinel 选举**：当一个 Master 被判定为**客观下线**后，监视这个 Master 的所有Sentinel会通过 `Raft` 选举算法，选出一个 Leader Sentinel 去执行故障转移 `failover` 操作。
   - 2）**Master 重新选择**：当选举出 Leader Sentinel 后，Leader Sentinel 会根据以下规则，在失效 Master 属下的 Slave 当中，选择出新的 Master：
     1. 先淘汰主观下线 | 已断线 | 最后一次回复 `PING` 命令时间大于5秒钟 | 与失效 Master 断开连接时长超过 10 倍主观判断时长 `down-after-milliseconds` 的 Slave 节点。
     2. 选择配置 `slave-priority` 最高的 Slave 节点，如果没有，则继续选择。
     3. 选择复制偏移量 `replication offset` 最大的 Slave 节点，复制偏移量越大，说明数据复制的越完整。
     4. 如果复制偏移量不可用，或者 Slave 的复制偏移量相同， 则选择运行 ID `run_id` 最小的 Slave 节点，`run_id` 越小，说明重启次数越少。
   - 3）**故障转移流程**：
     1. Leader Sentinel  则根据 Master 选择规则，选出一个 Slave，向其发送 `SLAVEOF NO ONE` 命令，让它转变为 Master。
     2. 然后， Leader Sentinel 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel，让其他 Sentinel 对它们自己的配置进行更新。
     3. 接着， Leader Sentinel 会向已下线 Master 的其他 Slave，发送 `SLAVEOF host port` 命令， 让它们去复制新的 Master。
     4. 最后，当所有 Slave 都已经开始复制新的 Master 时， Leader Sentinel 则结束这次故障迁移操作。

6. **优点**：监控、提醒、自动故障转移，从而实现 Redis 的高可用。

7. **缺点**：如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

8. **适用场景**：适合读远多于写的业务场景，比如在秒杀系统中，用来缓存活动信息。

###### 3）集群模式 | 高可用、写多

![1632464692288](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632464692288.png)

1. **是什么**：

   - 1）Redis Cluster，是 Redis 3.0 版本之后推出的高可用实现。
   - 2）采用哈希虚拟槽的数据分区方案，把 key 分布到各个 Master 节点上，每个 Master 还可以跟若干个 Slave 做主从切换。
   - 3）由于做了数据分区，使用的功能，也就只是普通单机 Redis 所有功能的一个子集，比如不支持同时使用多个键的 Redis 命令、不支持多数据库只能适用 0 号数据库。
   - 4）路由方面，客户端可以连接任意 Master 节点，集群内部会按照不同的 key，告诉客户端，把请求转发到其他 Master 节点，同时让请求成功的客户端，还会缓存对应的映射关系，以提高下次集群访问的查询效率。

2. **怎么配置**：

   ```shell
   # 1、开启集群模式
   cluster-enabled yes
   # 2、每一个节点都需要有这么一个配置文件，3主3从则一共需要6份，用于存储集群模式下的集群状态等信息，由Redis自己维护，而这些信息会相互告知其他所有节点。如果要重新创建集群，只需要把这个文件删除掉就行。
   cluster-config-file nodes-201.conf
   # 3、节点超时时限，如果发生超时则会被认定为PFAIL，如果超过半数其他Master认定为PFAIL，则会被集群认定为FIAL，然后会进行主从切换
   cluster-node-timeout 5000
   # 4、开启AOF
   appendonly yes
   
   # 5、Redis3.x旧版集群构建方式，需要使用redis-trib.rb来构建集群，最新版使用C语言来构建了，这个要注意
   # ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
   
   # 新版Redis集群构建方式
   # 6、创建集群，主节点和从节点比例为1，1-3为主，4-6为从，1和4，2和5，3和6分别对应为主从关系，这也是最经典用的最多的集群模式
   redis-cli --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1
   # 7、集群客户端
   redis-cli -c -p 7000
   # 8、检查集群信息
   redis-cli --cluster check 127.0.0.1:6379
   ```

3. **分区实现原理**：Redis 集群的键空间被分割为 `16384` 个槽（slot）， 集群的最大节点数量也是 `16384` 个，但推荐的最大节点数量为 1000 个左右，每个主节点都负责处理 `16384` 个哈希槽的其中一部分，其键的映射算法为 `HASH_SLOT = CRC16(key) mod 16384`。

   为什么哈希槽数为 16384 个？

   `CRC16` 算法产生的 hash 值有 16 bit，即可产生 2 ^ 16 = 65536 个值，换句话说，值是分布在 0 ~ 65535 之间，那 Redis 在做 `mod` 运算的时候，为什么不 `mod` 65536，而是选择 `mod` 16384 呢？

   - 1）槽位数不宜过大：如果槽位为 65536，那么节点发送 `PING/PONG` 心跳包消息头所占用的空间会达到 8k （65536 / 8），过于庞大，传输时浪费带宽，而如果使用 16384 个槽位，心跳包消息头所占用的空间仅为 2k（16384 / 8），则大小还能接受。
   - 2）槽位数不宜过小：Redis Master 的哈希槽配置，是通过一张 bitmap 的形式来保存的，其填充率为 slots / N，N为节点数目，在 N 固定的情况下，如果槽位数越小，bitmap 填充率就越小，导致 bitmap 在传输过程中的压缩率就越高，就越消耗 CPU 资源。
   - 3）因此，16384 个插槽，是综合了心跳包大小、网络带宽、压缩率等方面考虑的结果，同时还能满足各种业务需求。

4. **路由转向原理**：

   - 1）一个 Redis 客户端可以向集群中的任意节点（包括从节点）发送 `GET key` 命令请求。

   - 2）集群节点会对命令请求进行分析， 如果该命令是集群可以执行的命令， 那么节点会查找这个命令所要处理的键所在的哈希槽。

   - 3）如果要查找的哈希槽正好就处于当前节点中，则接收到的命令由当前节点负责处理。

   - 4）如果所查找的哈希槽不处于当前节点中，则当前节点会先查看自身内部所保存的，哈希槽到节点 ID 的映射记录，然后向客户端回复一个 `-MOVED` 转向错误。

     ```shell
     GET x
     # GET命令收到一个 -MOVED 转向错误
     # x真正所在的目标哈希槽，目标节点IP，目标节点端口号
     -MOVED 3999 127.0.0.1:6381
     ```

   - 5）客户端收到 `-MOVED` 转向错误后，根据目标节点 IP 与端口号，会再向目标节点重新发送一次 `GET key`命令请求。

   - 6）如果客户端在重新发送 `GET key` 命令时，集群刚好又更改了 key 的 slot 配置， 此时客户端请求目标哈希槽，会再次收到 `-MOVED` 转向错误， 需要再次向新的目标节点重新发送一次 `GET key`命令请求。

   - 7）客户端会循环以上操作，直到该命令请求成功，然后记录下该成功请求的哈希槽的目标节点信息，在下次执行相同 key 命令时，加快正确节点的寻找速度。

5. **高可用原理**：

   - 1）**节点失效检测**：当一个节点 `PING` 不通另一个节点时，则会把它标记为 `PFAIL`；当一个节点要把另一个节点从 `PFAIL` 标记为 `FAIL` 时， 则必须得到大部分 Master 的同意才行。
   - 2）**从节点选举**：一旦某个 Master 进入 `FAIL` 状态， 如果这个 Master 有一个或多个 Slave 存在， 那么其中一个 Slave 会被升级为新的 Master， 而其他 Slave 则会开始对这个新的 Master 进行复制。

6. **优点**：

   - 1）高可用：当集群中的一部分节点失效或者无法进行通讯时， 集群仍然可以通过主从切换，继续处理命令请求。
   - 2）高性能：操作某个 key 时，Redis 不会先找到节点再处理，而是直接让客户端重定向，到目标 Redis 实例进行请求，这相较代理分片少了 proxy 的连接损耗。
   - 3）高拓展：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

7. **缺点**：

   - 只能使用普通单机 Redis 所有功能的一个子集：不支持同时使用多个键的 Redis 命令，不支持多数据库功能， 只能使用默认的 0 号数据库。
   - 占用带宽：虽然避免了 Master 单节点的问题，但集群内的数据同步、节点通信会占用一定的带宽。
   - 数据弱一致性：与其他高可用方案一样，Redis 集群属于 AP 模型，不保证数据的强一致性，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。

8. **适用场景**：在写操作比较多的情况下，集群模式才更有优势，相对于其他大多数情况，使用哨兵模式就能满足需求了。

##### 3、总

Redis AKF 拆分：

![1632542544732](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542544732.png)

###### 1）X 轴扩展 | 主从复制

- **特点**：
  1. 按照主从设计，Master 负责读写， Slave 负责读。
  2. 再结合哨兵集群，在 Master 故障时，使用 Slave 进行切换，从而实现高可用。
- **优点**：
  1. 主从，解决了读并发压力大的问题。
  2. 哨兵，解决了单点故障问题。
- **缺点**：单机容量会有限制，并且会出现写并发压力大的问题。

###### 2）Y 轴扩展 | 业务拆分

- **特点**：
  1. 把 Redis 所有键，按照业务进行拆分，拆分到不同的 Redis 实例上。
  2. 可以在 Y 轴的基础上，再进行 X 轴的主从复制的扩展，形成不同业务的 Redis 集群。
- **优点**：从分离不同业务数据的角度，暂时解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：当某个业务的集群达到一定规模后，如果数据量过大，仍然会出现单机容量受限，以及写并发压力大的问题。

###### 3）Z 轴扩展 | 数据分区

- **特点**：
  1. 将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。
  2. 可以在 Z 轴的基础上，叠加 X 轴的主从复制，集群内进行数据分片，比如 Redis Cluster。
  3. 可以再叠加 Y 轴的业务拆分，把整个 Redis 系统划分成多个不同业务的、数据分片过的 Redis Cluster。
- **优点**：增加了整个集群的算力、带宽和内存，从根本上解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：
  1. 数据分区后，不支持跨实例的命令与事务。
  2. 备份管理要复杂得多。
  3. 扩缩容时可能需要对数据再平衡。

综上，Redis 哨兵模式与 Redis Cluster 的主要区别为：

1. 原理上，Redis 哨兵模式是通过主从复制 + 故障时 Sentinel 做主从切换实现的，而 Redis Cluster 则是通过哈希虚拟槽分区 + 重定向客户端请求 + 主从复制 + 故障时 从节点选举 做主从切换实现的。
2. 使用上，由于 Redis Cluster 对数据做了分区，所以只能使用普通单机 Redis 所有功能的一个子集，比如不能使用多键命令，只能使用 0 号数据库，而 Redis 哨兵模式本质上是主从模式，依然可以使用所有命令。

=> 以上，就是我对 Redis 高可用架构 的一些理解，请问有什么细节需要补充的吗？

#### 3.2.2.2. 算法题 | 100 个数实现随机取两次，不能拿重复？

最优解见方案二~

```java
/**
 * 随机从连续的100个不重复数中, 取出100个不重复的随机数
 */
public class Random100 {

    public static void main(String[] args) {
        Random100 random100 = new Random100();

        // 验证方案一: 全Right!
        System.err.println("方案一开始~");
        for(int i = 0; i < 50000; i++) {
            random100.fun1();
        }

        // 验证方案二: 全Right!
        System.err.println("方案二开始~");
        for (int i = 0; i < 50000; i++) {
            random100.fun2();
        }
    }

    /**
     * 方案一思路：100个顺序int数组, 随机取出, 碰到相同的则重新取, 直到取完
     * <p>
     * 时间复杂度：最坏情况下, 第一次要取1次, 第二次要取2次,...,第100次要去100次, 时间复杂度为O(n^2)
     * 额外空间复杂度: 一开始的100长度数组, 以及返回的100长度数组, 都是是题目需要的, 所以额外空间复杂读为O(1)
     */
    private void fun1() {
        int len = 100;

        int[] nums = getInitNums(len);
        List<Integer> res = new ArrayList<>();

        int i = 0, index;
        Random random = new Random();
        while (i < len) {
            index = random.nextInt(len);
            if (nums[index] != -1) {
                res.add(nums[index]);
                nums[index] = -1;
                i++;
            }
        }

        printIfError(res);
    }

    /**
     * 方案二思路：100个顺序int数组, 随机取出, 取出后替换到末尾位置, 直到取完
     * <p>
     * 时间复杂度：由于每次只需要取1次, 共取100次, 所以时间复杂度为O(n)
     * 额外空间复杂度: 一开始的100长度数组, 以及返回的100长度数组, 都是是题目需要的, 所以额外空间复杂读为O(1)
     */
    private void fun2() {
        int len = 100;

        int[] nums = getInitNums(len);
        List<Integer> res = new ArrayList<>();

        int i = 0, index, tmp;
        Random random = new Random();
        while (i < len) {
            index = random.nextInt(len);
            res.add(nums[index]);

            // 交换index到末尾
            tmp = nums[index];
            nums[index] = nums[len - 1];
            nums[len - 1] = tmp;

            // 数组末尾前移
            len--;

            // 继续下一轮随机取
            i++;
        }

        printIfError(res);
    }
    
    /**
     * 获取连续len个不重复数数组
     *
     * @param len
     * @return
     */
    private int[] getInitNums(int len) {
        int[] nums = new int[len];
        for (int i = 0; i < len; i++) {
            nums[i] = i;
        }
        return nums;
    }

    /**
     * 判断是否有重复, 有则打印Error!
     *
     * @param res
     */
    private void printIfError(List<Integer> res) {
        Set<Integer> set = new HashSet<>(res);
        if (res.size() != set.size()) {
            System.err.println("Error!");
        }
    }
}
```

#### 4.1.1.1. 项目介绍，分表规则、服务器配置、JVM 配置？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 4.1.1.2. 线程池参数？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 4.1.1.3. Spring MVC 的处理过程？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 4.1.1.4. Spring MVC 拦截器和过滤器的区别？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 4.1.1.5. Spring AOP 的原理？

##### 1、总

AOP，Aspect-Oriented Programming，⾯向切⾯编程，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑，或者责任封装起来（比如事务管理、⽇志管理、权限控制等），以便于减少系统的重复代码，降低模块间的耦合度，有利于未来的可拓展性和可维护性。

##### 2、分

1. AOP 有 **7 个核心概念**：

   - 1）**切面**：Aspect，指对哪些方法进行拦截处理的横切关注点，可能会横切多个对象，比如 Spring 的事务管理， 在 Spring AOP 中，切面可以在普通类中以 `@Aspect` 注解来实现。
   - 2）**连接点**：Join point，指在程序执行过程中某个特定的点，比如某个方法调用的时间点，或者处理异常的时间点，在 Spring AOP 中，一个连接点代表一个方法的执行。
   - 3）**通知**：Advice，在切面的某个特定的连接点上*执行的动作，通知有多种类型，包括 `around`， `before`， 和 `after` 等等。
   - 4）**切点**：Pointcut，匹配连接点的断言，通知会在满足这个切点的连接点上运行，比如 AOP 去执行某个特定名称的方法。
   - 5）**目标对象**：Target object，被一个或者多个切面所通知的对象，也被称作被通知的业务对象。
   - 6）**织入**：Weaving，把切面连接到目标对象上，并创建一个代理对象的过程。
   - 7）**AOP 代理**：AOP proxy，AOP 框架创建的对象，用来实现切面契约，包括通知方法执行等功能，在Spring 中，AOP代理可以是 JDK 动态代理，或者是 CGLIB 动态代理。

   => 比如日志管理的公共代码，可以抽象出一个**切面**，然后注入到**目标对象**中（具体的业务对象），通过**动态代理**，将对目标对象进行代理，在进行调用时，代理对象会根据**通知**类型，在对应的时间点，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

2. **实现原理**：

   - 1）Spring AOP 是基于动态代理实现的，是 IoC 的一个扩展功能，是在 IoC 整个流程中新增的一个 BeanPostProcessor（`AbstractAutoProxyCreator`）扩展点而已。
   - 2）`AbstractAutoProxyCreator` 实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
   - 3）如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
   - 4）⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 asm框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。

##### 3、总

=> 以上，就是我对 Spring AOP 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.6. Spring @Transactional 原理？

##### 1、总

`@Transactional`，是 Spring 中事务传播配置的注解，可通过 `@EnableTransactionManagement` 启用事务传播特性，其中，Spring 事务传播属性分为以下几种：

| 属性                     | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| REQUIRED（默认属性）     | 如果存在一个事务，则支持**当前事务**，如果没有事务，则开启一个**新的事务** |
| MANDATORY                | 支持**当前事务**，如果当前没有事务，就**抛出异常**           |
| NEVER                    | 以**非事务**方式执行，如果当前存在事务，则**抛出异常**       |
| NOT_SUPPORTED            | 以**非事务**方式执行操作，如果当前存在事务，就把当前事务**挂起** |
| REQUIRES_NEW（相互独立） | **新建事务**，如果当前存在事务，把当前**事务挂起**，内外两个事务相互独立，互不影响，当外层事务失败时，并不会回滚内层事务所做的动作，而内层事务操作失败时，也不会引起外层事务的回滚 |
| SUPPORTS                 | 支持**当前事务**，如果当前没有事务，就以**非事务**方式执行   |
| NESTED（局部回滚）       | 支持**当前事务**，新增 Savepoint 点，与当前事务**同步提交或回滚**。嵌套事务一个非常重要的概念，就是内层事务依赖于外层事务，当外层事务失败时，会回滚内层事务所做的动作，而内层事务操作失败时，并不会引起外层事务的回滚 |

##### 2、分

其**实现原理**为：

1. Spring 的事务是由 AOP 来实现的，首先按照 AOP 的整套流程来执行具体的操作逻辑，使用 `InfrastructureAdvisorAutoProxyCreator` （AbstractAutoProxyCreator 的子类）来生成具体的代理对象。
2. 然后通过一个 `TransactionInterceptor` 来实现，在调用 `JdkDynamicAopProxy#invoke(proxy, method, args)` 方法时，则代理到 `TransactionInterceptor`  实现的具体逻辑中。
3. 在调用代理方法时，会先做准备工作，解析各个方法上事务相关的属性，根据具体的属性来判断是否开始新事务。
4. 当需要开启事务时，则获取数据库连接，关闭自动提交功能，开启事务。
5. 然后执行原始业务逻辑。
6. 如果在执行过程中发生异常，那么会通过 `completeTransactionAfterThrowing` 来完成事务的回滚操作，回滚的具体逻辑是通过 `doRollBack` 方法来实现的，实现的时候也是要先获取链接对象，再通过连接对象来回滚。
7. 而如果执行过程中，没有任何意外情况的发生，那么通过 `commitTransactionAfterReturning` 来完成事务的提交操作，提交的具体逻辑是通过 `doCommit` 方法来实现的，实现的时候也要获取链接，通过链接对象来提交。
8. 当事务执行完毕之后，需要通过 `cleanupTransactionInfo` 来清除相关的事务信息。 

##### 3、总

因此，在平常使用过程中，应该留心以下**注意事项**：

1. 事务函数中不要处理耗时任务，会导致长期占有数据库连接。
2. 事务函数中不要处理无关业务，防止产生异常导致事务回滚。
3. 一些 Spring 事务传播**失效场景**有：
   - 1）Bean 对象没有被 Spring 容器所管理。
   - 2）调用方法的访问修饰符不是 public。
   - 3）数据源没有配置事务管理器。
   - 4）数据库不支持事务。
   - 5）异常被捕获，所以没有回滚。

=> 以上，就是我对 Spring @Transactional 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.7. JDK 8 的内存分布情况，年轻代和老年代默认的比值，以及 Eden 区的比值，以及为什么？

##### 1、总

![1647941457503](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941457503.png)

JVM 在执行 Java 程序的过程中，会把它所管理的内存区域，划分为同 JVM 生命周期的线程共享区域，有方法区和堆区，以及生命周期随着线程启动和结束，而建立和销毁的非线程共享区域，有程序计数器、虚拟机栈和本地方法栈。

##### 2、分

###### 1）程序计数器

1. Program Counter Register，非线程共享，是 JVM 当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，从而实现分支、循环、跳转、异常处理、线程恢复等基础功能。
2. 出现的原因是：
   - 1）由于 JVM 多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，线程是最小的执行单位，没有“记忆”功能，只负责去干。
   - 2）为了在线程切换后，能恢复到正确的执行位置，需要记住原线程下一条要执行的指令的位置，此时，每条线程就需要有一个独立存储、互不影响、内存不共享的程序计数器。

###### 2）虚拟机栈

![1647941408114](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941408114.png)

1. 每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致，其内存空间只包含基础数据类型的局部变量、以及对象引用。

2. 虚拟机栈的单位是栈帧，在每个方法执行时，都会创建一个栈帧压入虚拟机栈中，在方法执行完毕或者发生异常，对应的栈帧则会从虚拟机栈中出栈。

3. 其中，每个栈帧都存放着局部变量表、操作数栈、动态链接和方法返回地址，还有一些附加信息。

   - 1）**局部变量表**：

     1. 是一组变量值的存储空间，用于存放方法参数，和方法内部定义的局部变量。
     2. 存放了编译期可知的各种基本数据类型 `boolean、byte、char、short、int、float、long、double`（对包装类型则在栈中保存其引用地址，在堆中保存值）、以及对象引用。
     3. 其内存空间，在编译期间完成分配，所以，在方法在运行之前，其内存空间是固定的，运行期间也不会发生改变。

   - 2）**操作数栈**：

     1. 用于保存计算过程中的中间结果，同时作为计算过程中变量临时的存储空间。
     2. 操作数栈在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈和出栈操作。

     ```java
     public class Test {
         public void add() {
             int a = 15;
             int b = 1;
             int c = a + b;
         }
     }
     ```

     => 以上过程，其操作数栈与局部变量表的**交互顺序**为：

     1. 15 入栈：操作数栈写入数据。
     2. 15 出栈：操作数栈提取数据到局部变量表。
     3. 1 入栈：操作数栈写入数据。
     4. 1 出栈：操作数栈提取数据到局部变量表。
     5. 15 入栈：加载局部变量表变量 15。
     6. 1入栈：加载局部变量表变量 1。
     7. `iadd`：执行相加 15 + 1 指令。
     8. 16 出栈：操作数栈提取结果到局部变量表。
     9. `return`：如果返回值为void，则当前栈帧出栈即可；如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中。

   - 3）**动态链接**：

     1. 每个栈帧都包含一个，指向运行时常量池中，当前栈帧所属的方法引用，持有这个引用是为了支持方法在调用过程中的动态链接（Dynamic Linking）。
     2. Class 文件的常量池中，存在大量的符号引用，这些符号引用一部分会在类加载阶段，或者第一次使用时转化为直接引用，这种转化成为静态连接。
     3. 而另一部分则在每一次运行期间都转化为直接引用，这部分称为动态连接。

   - 4）**方法返回地址**：

     1. 指向下一条字节码指令的地址，方法正常退出时，PC 计数器会记录其返回地址，保存在栈帧中。
     2. 而在方法异常退出时，返回地址，则要通过异常处理器表来确定，栈帧中不会保存这部分的信息。

   - 5）**附加信息**：虚拟机规范还允许一些的实现，可以增加一些规范里没有描述的信息到栈帧中，比如，与调试相关的信息等。

###### 3）本地方法栈

1. 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是用来服务 Java 方法的，而本地方法栈，则是用来服务虚拟机调用 Native 方法的。

###### 4）堆区

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

1. Java Heap，线程共享，在 JVM 启动时创建，是 Java 虚拟机中内存最大的一块，专门用来保存对象，几乎所有对象、以及数组的内存都在堆上分配。

2. 对象在堆中分配好以后，会在栈中保存一个 4 字节的实例，用来指向对象堆内存地址，定位对应的对象在堆中的位置，便于找到该对象，因此，操作实例，实际上是通过实例指针间接操作对象。

   - 另外，`ClassA a = new ClassA()`，a 叫做实例，而不能说成 a 对象，因为实例在栈上，对象在堆中。

   - 以及，在开启逃逸分析后，某些未逃逸的对象，也可以通过标量替换的方式在栈上分配。

3. 栈中的数据，和堆中的数据销毁并不是同步的，方法一旦结束，栈中的局部变量会立即销毁，而堆中的对象不一定会销毁，可能有其他变量也指向了该对象，一直等到没有变量指向该对象，它才有可能被垃圾回收掉。

4. 同时，堆是垃圾回收 GC 的主要场所，从内存回收角度来看，可以分为新生代和老年代，默认比值为 `1：2 `，原因是，老年代需要占用更多的内存空间。

5. 对于新生代又可以分为 Eden区（伊甸园）、Survivor 区（存活区），默认比值为 `8：2`，原因是，大部分对象生命周期活不到存活区。

6. Survivor 区又分为 Surviver0（From Survivor）和 Survivor1（To Survivor），默认比值为 `1：1`，原因是，存活区使用的是复制算法。

7. 堆中还有个概念，叫做 TLAB：Thread Local Allocation Buffer，线程私有分配缓存区，是一块线程专用的内存分配区域，JVM 会为每个线程分配一块 TLAB 区域，实质占用的是 Eden 区的空间（分配独享、使用共享），用于给每个线程往自己的 TLAB 中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。

   - 1）优点 - 加速对象分配：
     1. 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM 底层采用 CAS + 失败重试的方式来做同步处理。
     2. 如果多线程竞争非常激烈，那么在堆中分配对象性能是非常差的。
     3. 因此，JVM 设计了 TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
   - 2）缺点 - 大的对象无法分配：由于 TLAB 空间比较小，所以大的对象无法在 TLAB 分配，此时只能直接分配到其他堆空间中。

###### 5）方法区

![1647944132277](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647944132277.png)

1. Methed Area，别名 Non-Heap 非堆，线程共享，是 JVM 规范中定义的一个**逻辑概念**，用于存储已被虚拟机加载的类信息、常量、静态变量、以及即时编译后的代码，具体放在哪里，不同的实现可能会放在不同的地方。
2. 在 JDK 8 HotSpot 中，方法区存储空间分为堆和元空间，类信息（类版本、字段、方法、接口、父类等描述信息、静态常量池）、运行时常量池放在元空间中，静态变量、字符串常量池放在了堆中。
3. 讲到元空间，就要先讲一下永久代了：
   - 1）永久代，是 Hotspot 虚拟机特有的概念，是方法区的一种实现，主要存放类信息、常量等方法区内容。
   - 2）在 JDK 6 中，方法区中包含的数据，除了 JIT 编译生成的代码外（存放在native memory的CodeCache区域），其他都存放在永久代中。
   - 3）而移除永久代的工作，是从 JDK 7 开始的，但并没完全移除，比如符号引用转移到了本地内存中，字面量（见字符串常量池）、类的静态变量（class statics）转移到了堆中。
   - 4）在 Java 8 中，永久代就彻底被移除，取而代之的是，另一块与堆不相连的本地内存，叫做元空间（Metaspace）中，此时 `‑XX:MaxPermSize` 失去了意义，取而代之的是 `-XX：MaxMetaspaceSize `。
4. 再回到元空间：它是在 JDK 8 以后，用于替代永久代，存储类的元数据信息，存放的地方并不在 JVM 虚拟机中，而是在本地内存中，其大小仅受本地内存的限制，从而解决了永久代容易溢出的问题。
5. 再回到方法区，在 JDK8 以后，元空间替代了永久代，使得方法区与堆存在了交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是 class 文件里的常量池，未加载前并不占用内存。
   - 1）**静态常量池**：也叫 class 文件常量池，即 class 文件中的常量池，占用 class 文件绝大部分空间，主要存放：
     1. 字面量，相当于 Java 语言层面常量的概念，如文本字符串、final 修饰的变量。
     2. 符号引用，属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
   - 2）**运行时常量池**：当 class 文件加载到内存后，JVM 会将静态常量池中的内容，存放到运行时常量池中，这就是我们常说的常量池，主要存放：
     1. 编译期间产生的字面量和符号引用。
     2. 运行时常量池具有动态性，并非只能通过 class 文件常量池进入，运行期间也可以将新的常量放入池中。
   - 3）**字符串常量池**：可以理解为，运行时常量池中分出来的字符串部分，当类加载到内存时，字符串会存到字符串常量池里。
     1. `String#intern()` 方法，native方法，返回规范的字符串，底层调用 `equals()` 会先判断常量池是否有存在的字符串，如果没有，则会将字符串加入常量池。
     2. 程序运行时，除非手动向常量池中添加常量，比如调用 `String#intern()` 方法，否则 JVM 不会自动添加常量到字符串常量池中。
     3. 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量，则会加入常量池，如果是变量，由于地址不能确定，所以在不调用 `String#intern()` 时，是并不会加入常量池的。

##### 3、总

=> 以上，就是我对 JDK 8 运行时数据区 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.8. 项目中的垃圾收集器用了哪些？

##### 1、总

1. 由于 JVM 启动参数没配置具体的垃圾收集器，所以使用的是默认的垃圾收集器。

   ```shell
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

2. 这时可以去看 gc.log 中的抬头，打印出来的是 `-XX:+UseParallelGC` ，即 `Parallel Scavenge` + `Parallel Old` 的组合。

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

JDK 中有如下的垃圾收集器（挑着讲）：

![1648022290125](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022290125.png)

###### 1）新生代 - Serial 收集器 | 单线程

![1648022517445](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022517445.png)

1. 最基本的、发展历史最悠久的收集器，采用的是复制算法。
2. 其特点是，单线程，可以专心做垃圾回收，不存在与其他线程的交互开销，效率较高，但收集过程全程 Stop The World。
3. 只适用于客户端程序、或者嵌入式低性能的单核机器。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用复制算法，执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 2）新生代 - ParNew 收集器 | 多线程并行

![1648022570986](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022570986.png)

1. 相当于 Serial 收集器的多线程版本，采用的也是复制算法，收集过程全程也是 Stop The World。
2. 可使用 `-XX：ParallelGCThreads`，来设置并行线程数，一般设置为 CPU 核心数。
3. 主要用来和 CMS 收集器配合使用。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 3）新生代 - Parallel  Scavenge 收集器 | 多线程并行

![1648022746240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022746240.png)

1. 也叫吞吐量优先收集器，也是多线程并行的垃圾收集器，采用的也是复制算法。
2. 其特点是：
   - 1）可以通过配置，以达到一个可控制的吞吐量：
     1. `-XX：MaxGCPauseMillis`：设置后，JVM 将尽力控制垃圾收集时的最大的停顿时间。
     2. `-XX：GCTimeRatio`：用于设置吞吐量的大小，取值为 0~100，设置后，JVM 将花费不超过 `1 + / （1+n）` 的时间，去做垃圾收集。
   - 2）支持自适应 GC：
     1. 可使用 `-XX：+UseAdptiveSizePolicy` 启用，启用后，将无需再手动设置 `-Xmn、-XX：SurvivorRatio` 等参数，虚拟机会根据系统的运行状况，收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。
     2. 可见，Parallel  Scavenge 收集器存在着一定的智能性。
3. 适用于比较注重吞吐量的场景。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 4）老年代 - Serial Old 收集器 | 单线程

![1648023100553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023100553.png)

1. 也叫串行的老年代收集器，相当于 Serial 收集器的老年代版本，采用的算法是标记整理算法。
2. 和 Serial、ParNew、Parallel Scavenge 三个新生代收集器，都可以形成配合。
3. 在 CMS 收集器出现故障时，则会使用 Serial Old 收集器作为备用。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用标记整理算法，执行老年代垃圾回收，回收完毕后，用户线程继续运行。

###### 5）老年代 - Parallel Old 收集器 | 多线程并行

![1648023323242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023323242.png)

1. 相当于 Parallel Scavenge 的老年代版本，采用的是标记整理算法，只能和 Parallel Scavenge 新生代收集器配合使用。
2. 与 Parallel Scavenge 一样，适用于关注吞吐量的场景。
3. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用标记整理算法，并行执行老年代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 6）老年代 - CMS 收集器 | 多线程并发

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

1. CMS，Concurrent Mark Sweep，并发标记清除收集器，可以与用户线程同时工作，采用的是标记清除算法，而 Serial Old、Parallel Scavenge 采用的都是标记整理算法。

2. 优点是，CMS 的 Stop The World 时间比较短，大多过程都是并发执行的，只有初始标记和重新标记，存在者 Stop The World，其他阶段都是并发执行的。

3. 缺点是：

   - 1）**会存在内存碎片**：这也是最令人诟病的地方，这是因为 CMS 采用的是标记清除算法，会导致内存碎片的产生。
     1. 可使用 `UseCMSCompactAtFullCollection`（默认打开），在每次 Full GC 完成后，进行内存碎片的整理。
     2. 也可使用 `CMSFullGCsBeforeCompaction`（默认为0），在进行几次 Full GC 后，就进行一次内存碎片的整理。
   - 2）无法处理浮动垃圾：由于并发清除阶段，用户线程在并发执行，可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而 CMS 是无法在本次 GC 清理掉这些浮动垃圾的，需要留到下次 GC 才能清理掉。
   - 3）不能等到老年代几乎满了才开始收集：
     1. 如果 CMS 执行期间，预留的老年代内存，不能满足用户程序的需要，则会出现一次 Concurrent Mode  Failure 异常，会导致 JVM 改用备用的 Serial Old 收集器，去收集老年代的垃圾，从而导致更长的 Stop The World。
     2. 因此，必须为老年代预留足够的内存给用户线程使用，可使用 `CMSInitiatingOccupancyFraction`（默认68%），来设置老年代占比达到多少后，才会触发 CMS 垃圾回收。
   - 4）CPU 资源比较敏感，并发执行阶段会导致应用吞吐量的降低：由于垃圾收集线程也需要占用一定的 CPU 资源，与业务线程一起去争抢 CPU 时间片，影响业务线程的执行效率，降低应用的吞吐量。

4. 适用于希望系统停顿时间短，响应速度快的场景，比如各种服务端应用。

5. 执行过程为：

   - 1）**初始标记**：initial  mark，标记那些 GC Roots 能直接关联到的对象，此时能够标记到的对象会比较少m。执行期间，存在 Stop The World，但由于标记的对象比较少，所以 STW 的时间也是比较短的。

   - 2）**并发标记**：concurrent mark，找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程，和用户线程并发执行，不存在 Stop The World。

   - 3）**并发预清理**：concurrent-preclean，是一个不一定会执行的阶段，可通过 `-XX：-CMSPrecleaningEnabled`（默认打开），关闭并发预清理阶段，本阶段，JVM 会重新标记那些在并发标记阶段期间，引用被更新了的对象，比如某些新晋升到老年代的对象，从而减少后面重新标记阶段的工作量。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

   - 4）**并发可中止的预清理阶段**：concurrent-abortable-preclean，也是不一定会执行的阶段，使用该阶段的前提条件是，当 Eden 使用量大于 `CMSScheduleRemarkEdenSizeThreshold` 阈值时（默认2M）才会执行，工作内容与并发预清理阶段是一样的。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

     1. 本阶段的主要作用是，允许用户能够控制预清理阶段的结束时机。
     2. 比如，可用 `CMSMaxAbortablePrecleanTime`（默认 5 秒）进行设置扫描时长。
     3. 再如，可用 `CMSScheduleRemarkEdenPenetration` 设置（默认 50%），当 Eden 使用占比达到多大，就结束本阶段。

   - 5）**重新标记**：remark，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象，错误地标记成为了死亡，则可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World，一般来说，本阶段所花费的时间，会比初始标记阶段的要长一些，但会比并发标记阶段的短一些。

   - 6）**并发清除**：concurrent sweep，会基于标记结果，清除掉要前面标记出来、需要清除的垃圾，不做整理，所以会存在内存碎片。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

     那么为什么是并发清除，而不是并发整理？

     1. 因为本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     2. 如果是并发整理，则既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，实现起来会变得非常困难，还容易出错，而采用并发清除，就变得容易了许多。
     3. 因此，这里是并发清除，而不是并发整理。

   - 7）**并发重置**：concurrent reset，清理本次 GC 的上下文信息，为下一次 GC 做准备。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

###### 7）新生代&老年代 - G1 收集器 | 多线程并发

![1648024834453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648024834453.png)

1. Garbge First，是一款价值优先、既可以用在新生代、又可以用在老年代（即整个堆内存）的垃圾收集器，由于采用的是复制算法，所以无内存碎片的问题。

2. 而其革命性的变化在于：

   - 1）它将整个堆，划分成了若干个大小相等的区域，每个区域叫一个 Region，这个 Region 可通过 `-XX：G1HeapRegionSize` 来指定，取值范围为 1M~32M ，且必须为 2 的幂次。
   - 2）在 G1 中，一共分为 4 类 Region，分别为 Eden Region 伊甸园、Survivor Region 存活区、Old Region 老年代、Humongous Region 存储大对象，同一代对象可能是不连续的，而超过 Humongous Region 大小一半的特大对象，则会被分配到连续的 Humongous Region 里面。
   - 3）然后，G1 会去跟踪每个 Region 里面的垃圾堆积的价值大小，即回收一个 Region 能够获取到多大的剩余空间。
   - 4）最后，构建一个优先列表，根据允许的收集时间，优先回收价值高的 Region，即回收后能够得到更大空间的 Region，以获得更高的垃圾收集效率。

3. 主要用来替换 CMS，适用于占用内存较大（6G 以上）的应用。

   - 1）> JDK 8 都可以使用 G1（如果内存 <= 6G，建议使用 CMS，如果内存 > 6G，可以考虑使用 G1），而 CMS 则从 JDK 8 开始就被废弃了。

4. 执行过程为：

   1、**Young GC**：与之前的 Minor GC 差不多，采用的都是复制算法，只不过回收的单位是 Region 而已。

   - 1）当所有 Eden Region 都满了时，会触发 Young GC，Eden Region 里面所有的存活对象，都会转移到Survivor Region 里面去。
   - 2）而原先在 Survivor Region 中存活的对象，则会转移到新的 Survivor Region 中，或者晋升到 Old Region 中。
   - 3）然后，空闲的 Region 则会被放入空闲的列表中，等待下次被使用。

   2、**Mixed GC**：

   ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

   - 1）最能体现 G1 的设计思想，与 CMS 过程类似，但采用的是复制算法。
   - 2）在老年代大小，占整个堆的百分比达到 `-XX：InitiatingHeapOccupancyPercent` 时（默认 45%），则会触发 Mixed GC。

   - 3）Mixed GC 会回收所有的 Young Region，同时根据收集时间与回收价值回收部分的 Old Region。

   对于**执行过程**，除了并发标记是并发执行外，其他阶段都需要 Stop The World，但由于每次只回收部分的 Region，所以整体 Stop The World 的时间是可控的。

   - 1）**初始标记**：Initial Marking，与 CMS 初始标记类似，都是标记 GC Roots 能直接关联到的对象。执行期间，存在 Stop The World，不过由于标记的对象比较少，所以 STW 的时间比较短。
   - 2）**并发标记**：Concurrent Marking，也与 CMS 并发标记类似，都是找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。
   - 3）**最终标记**：Final Marking，也与 CMS 重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World。
   - 4）**筛选回收**：Live Data Counting and Evaluation，会对各个 Region 的回收价值与成本，进行排序，根据用户所期望的停顿时间 `MaxGCPauseMillis`，来制定回收计划，以选择回收某些 Region。执行期间，存在 Stop The World。
     1. 回收过程，采用的是复制算法，因此无内存碎片产生。
     2. 首先，G1 会选择一系列 Region 构成一个回收集。
     3. 接着，G1 会把决定要回收的 Region 中的存活对象，复制一个空的 Region 中。
     4. 最后，再删除掉需要回收的 Region。

   3、**Full  GC**：

   - 1）当 G1 在复制对象时，发现内存不够，或者无法分配足够内存，比如特大对象没有足够连续的 Humongous Region 可分配时，则会触发 Full GC。
   - 2）一旦触发 Full GC，在 Full GC 模式下，使用的是类似于 Serial Old 的垃圾回收，将出现长时间的 Stop The World。

5. 调优原则 => 因此，使用 G1 时，应该尽量减少 Full GC 的发生，让其只停留在 Young GC，或者 Mixed GC 的模式上进行垃圾回收。

   - 1）**增加预留的内存**：可加大 `-XX：G1ReserveRercent` ，默认为堆的 10%。
   - 2）**更早地进行回收垃圾**：可降低 `-XX：InitiatingHeapOccupancyPercent`（默认 45%），降低老年代大小，占整个堆的百分比的阈值，提早触发 Mixed GC。
   - 3）**增加并发阶段使用的线程数**：可增大 `-XX：ConcGCThreads`，让更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

##### 3、总

最后，选择垃圾收集器，不能纸上谈兵，要根据实际情况选择。

1. 桌面端应用、是单核的，可以使用 `Serial + Serial Old`。
2. Web 应用，追求响应快、吞吐量高的，可以使用 `Parallel Scavenge + Parallel Old`。
3. Web 应用，追求低延迟的，可以使用 `ParNew + CMS`、或者 G1。

=> 以上，就是我对 JVM 垃圾收集器 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.9. 线上怎么确定是老年代还是年轻代的 GC 时间过长？

##### 1、总

查看方式有：

1. 看 Skywalking：

   ![1648027659855](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648027659855.png)

2. 用 `jstat` 监控统计命令：

   ```shell
   # 查看remote.domain机器上，40496进程，垃圾收集相关的统计信息摘要（每隔1秒采样1次）
   jstat -gcutil 40496@remote.domain 1000
   
   # option参数解释：
   -class    :：显示类加载器的统计信息
   -gcutil    ：垃圾回收统计概述
   -gc        ：垃圾回收堆的行为统计
   -gcnew     ：新生代行为统计
   -gcold     ：年老代和永生代行为统计
   -gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计
   ```

3. 看 gc.log，手动计算所花时间：

   ```shell
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

Minor/Young GC 时间过长原因：

1. **存活对象的标注时间过长**：
   - 1）比如重载了 `Object#finalize()` 方法，会导致标记 Final Reference 耗时过长。
   - 2）或者 `String#intern()` 方法使用不当，导致 GC 扫描 StringTable 时间过长。
   - 3）可以通过配置 `-XX:+PrintReferenceGC` ，显示 GC 处理在 Reference 时的耗时。
2. **对象生命周期变长**：
   - 1）比如本地缓存使用不当，积累了太多存活对象，其中，它们还可能晋升到老年代，增长 FullGC 时间。
   - 2）或者锁竞争严重，导致线程阻塞，引起局部变量的生命周期变长。

Major/Full GC 时间过长原因：

1. **长生命周期的对象多**：过多的全局变量或者静态变量等，会导致标记和复制过程的耗时增加。

##### 3、总

=> 以上，就是我对 GC 时间过长调优 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.0. 线上出现慢 SQL 是怎么解决的？

1. Druid 监控拿去 SQL。
2. 然后进行 Explain 本地调优。

=> 见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 7）条码销售出库 | 索引调优、生产问题。

#### 4.1.2.1. 讲一下 SQL Explain？

##### 1、总

1. 使用 EXPLAIN 关键字，可以模拟优化器执行 SQL 语句，分析查询 SQL 语句的性能瓶颈。
2. 在 select 语句之前增加 explain 关键字，MySQL 就会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是真正去执行 SQL。

##### 2、分

Explain 结果字段有如下几个：

| Explain 结果字段 | json 名称     | 含义                                                         |
| ---------------- | ------------- | ------------------------------------------------------------ |
| **id**           | select_id     | 该语句的唯一标识，id 越大，越先执行，相同 id 的，从上到下执行 |
| select_type      | 无            | 查询类型                                                     |
| table            | table_name    | 表名                                                         |
| partitions       | partitions    | 匹配的分区                                                   |
| **type**         | access_tpye   | 联接类型                                                     |
| possible_keys    | possible_keys | 可能的索引选择                                               |
| key              | key           | 实际选择的索引                                               |
| **key_len**      | key_length    | 索引的长度                                                   |
| ref              | ref           | 索引的哪一列被引用了                                         |
| **rows**         | rows          | 估计要扫描的行                                               |
| filtered         | filtered      | 表示符合查询条件的数据百分比                                 |
| **extra**        | 没有          | 附件信息                                                     |

其中，影响性能的字段主要有：

###### 1）type | 连接类型

type 有以下几种取值，性能从好到坏：

| 连接类型        | 含义                                                         | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| system          | 该表只有一行，相当于系统表                                   | system是const的特例                                          |
| const           | 针对主键或者唯一索引的等值查询，最多返回一行数据             | 查询速度非常快                                               |
| eq_ref          | 当使用了索引的全部组成部分，并且索引是**主键或者非空唯一索引**才会发生 | 性能仅次于system和const                                      |
| ref             | 当满足索引的最左前缀规则，或者索引**不是主键也不是唯一索引**时才会发生 | 如果索引只匹配到少量的行，则性能也是不错的                   |
| fulltext        | 全文索引                                                     | 使用MyISAM存储引擎才有                                       |
| ref_or_null     | 该类型类似于ref，但MySQL会额外搜索哪些行包含NULL，           | SELECT * FROM ref_table WHERE key_col = expr OR key_col IS NULL； |
| index_merge     | 该类型表示使用了索引合并优化，表示一个查询里面用到了多个索引 | -                                                            |
| unique_subquery | 该类型和eq_ref类型，但使用了**IN查询**，且**子查询是主键或者唯一索引** | value IN (SLECT id FROM single_talbe WHERE expr)             |
| index_subquery  | 和unique_subquery类型，只是**子查询使用的是非唯一索引**      | value IN (SELECT key_col FROM single_table WHERE other_expr) |
| range           | 范围扫描，表示检索了指定范围的行，主要用于有限制的索引扫描   | 常见的有，BETWEEN、>、>=、<、<=、IS NULL、<=>、LIKE、IN      |
| index           | 全索引扫描，和ALL类型，只不过index是全盘扫描了索引的数据     | 当查询仅使用索引中的一部分列时，会使用该类型，有两种触发场景：1）覆盖索引，比ALL快，此时只扫描索引数，Extra列为Using Index；2）全表扫描，同ALL，此时会回表查询数据，Extra列不会出现Using Index； |
| ALL             | 全表扫描                                                     | 性能最差                                                     |

###### 2）key_len | 索引的字段长度

1. 索引字段长度，当字段允许为 NULL 时，key_len 会比不允许为 NULL 的大 1 个字节。
2. 长度越短，一页就能装 更多的 B+ 树节点，磁盘 I/O 次数就越少，性能就越高。

###### 3）rows | 估算的扫描行数

MySQL 估算会扫描的行数，数值越小，性能越高。

###### 4）extra | 查询的附加信息

用于展示有关本次查询的附件信息，重要的取值有：

| 附件信息                                                     | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Using filesort**                                           | 当Query中包含ORDER BY操作，而且无法利用索引完成排序操作时，MySQL Query Optimizer不得不选择相应的排序算法来实现。在数据较少时，从内存排序，否则从磁盘排序。 其中，Explain不会显式地告诉客户端用哪种排序。 |
| **Using Index**                                              | 仅使用索引树中的检索列信息，不必进行其他查找以读取实际行，当查询仅使用属于单个索引的列时，会使用此策略 |
| **Using index condition**                                    | 使用索引下推时出现，表示先按条件过滤索引，过滤完索引后，找到符合索引条件的数据行，随后用WHERE子句中的其他非索引条件，去过滤这些数据行。 |
| **Using index for group-by**                                 | 数据访问和Using Index一样，所需数据只需要读取索引，当Query中使用GROUP BY或者DISTINCT子句时，如果所有分组字段也在索引中，该信息就会出现 |
| Using join buffer（Block Nested Loop），Using join Buffer（Batched Key  Access） | 使用Block Nested Loop或者Batched Key  Access算法来提高join的性能 |
| Using MRR                                                    | 使用了Muti-Range Read优化策略                                |
| Using sort_union（..），Using union（..），Using intersect（..） | 这些提示索引扫描如何合并为index_merge连接类型                |
| **Using temporary**                                          | 为了解决该查询，MySQL创建了一个临时表来保存结果，如果查询包含不同列的GROUP BY和ORDER BY子句，通常会发生这种情况。 |
| **Using Where**                                              | 如果不是读取表的所有数据，或者不仅仅通过索引就可以获取所有需要的数据时，则会出现该值 |

##### 3、总

=> 以上，就是我对 SQL Explain 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.2. 讲一下为什么要用 Https？

##### 1、总

1. Https，Hyper Text  Transfer Protocol over SecureSocket Layer，是以安全为目标的 Http 通道，在 Http 的基础上，通过传输加密、以及身份认证，保证了传输过程的安全性。
2. Https 在证书验证阶段，使用的是安全性高的非对称加密。在内容传输阶段，使用的是速度快的对称加密，
   - 对称加密：双方持有相同的密钥，加密速度快。典型的对称加密算法有，AES 和 DES。
   - 非对称加密：密钥成对出现（私钥和公钥），加密速度慢。私钥只有自己知道，不在网络中传输。公钥可以公开，A 使用 B 公钥加密后传输给 B，B 可以使用 B 的私钥解密得到原始内容。典型的非对称加密算法有，RSA 和 DSA。

##### 2、分

其执行原理为，

1. **发起请求阶段**：首先，客户端将它所支持的算法列表，和一个用作产生密钥的随机数 1，发送给服务器。
2. **返回证书阶段**：然后，服务器从算法列表中，选择一种算法，并将它和一份包含服务器公钥的证书（即数字签名）、以及随机数 2 ，返回给客户端。
3. **证书验证阶段**：
   - 1）客户端对服务器的证书进行验证，抽取服务器给的公钥，生成一个 `pre_master_secret` 随机密码串 + 服务器公钥，使用非对称加密，将加密后的信息（预主密钥）发送给服务器。
   - 2）以及根据预主密钥、随机数 1、随机数 2，独立计算出 MAC 密钥，作为接下来的会话密钥。
4. **服务器解密阶段**：服务器通过服务器私钥，对客户端发送过来的加密信息进行解密，得到预主密钥，与随机数1、随机数2，独立计算出 MAC 密钥，也作为接下来的会话密钥。
5. **客户端发起测试阶段**：客户端将握手消息，使用对称加密得到 MAC 值，发送给服务端，验证服务器能否正常接受客户端对称加密后的信息。
6. **服务器响应测试阶段**：同理，服务器收到后，，使用对称加密得到 MAC 值，返回给客户端。
7. **连接完成阶段**：如果客户端能够接受，并返回确认报文，则 SSL 层建立完成，开始 Https 对称加密传输。

##### 3、总

最后，总结一下，Https 与 Http 的主要区别为：

| HTTP                           | HTTPS                                         |
| ------------------------------ | --------------------------------------------- |
| 默认端口 80                    | 默认端口 443                                  |
| URL 以 http:// 开头            | URL 以 https:// 开头                          |
| 明文传输、数据未加密、安全性差 | 传输过程 SSL 加密、安全性好、需要用到 CA 证书 |
| 消耗资源少、响应速度快         | 消耗资源多、响应速度慢                        |

=> 以上，就是我对 Https 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.3. Docker 和 K8S 有了解过吗？

##### 1、总

1. Docker，由 Go 语言开发，思想如 logo 一样，即集装箱 Container 容器思想，负责容器的运行和管理，通过隔离机制，使得每个容器间互不影响，以及通过限制每个容器的 CPU、内存和 I/O 资源，最大程度地压榨服务器资源源。
2. K8S，指 Kubernetes，是 Google#Omega 的开源版本，是目前市场占有率最高的容器编排产品，可以自动化部署、管理、扩展容器以及容器网络通信处理，为应用提供了理想的部署单元，和独立的执行环境，使得微服务部署更加简单，同时还支持集成到 CI/CD 工作流，提效 DevOps 团队工作。

##### 2、分

###### Docker 架构原理

![1647495796223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495796223.png)

1. Client：Docker 的客户端模块，用于运行 Docker 命令以及 Restful API。
2. Docker host：Docker 的服务器模块，存在一个 Docker Daemon 后台进程，负责整个 Docker 容器的生命周期管理，连接 Registry 下载镜像，以及提供 Client 的 API 端口来处理发送过来的命令。
3. Registry：Docker 的镜像仓库，分为 Docker Hub 官方公有的镜像仓库、Docker Datacenter 企业信任仓库、以及 Docker 内网私有仓库。
4. Images：Docker 镜像，可本地制作，也可来源于镜像仓库，是容器运行前代码、配置、环境变量、操作系统资源的打包，运行起来了之后叫做容器，类似于 VM 的配置模板，通过 UnionFS 联合文件系统，支持镜像的一层层叠加。
5. Containers：Docker 容器，每个容器共享主机的操作系统，通过 namespace 对 pid 进程、net 网络、ipc 信号量、mnt 文件系统、uts 用户组等进行**隔离**，通过 cgroup 对每个容器的 cpu、mem、io 等资源进行**限制**。

###### K8S 架构原理

![1647516641430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647516641430.png)

1. **Kubernetes Cluster**：K8S 集群，是计算、存储和网络资源的集合，是掌握所有计算、存储、网络资源，进行统计管理、调度的节点群。
2. **Namespace**：虚拟 K8S 集群，解决在同一个 Cluster 集群中，如何区分开 Controller 和 Pod 的问题，默认两个虚拟集群，`kube-system` 用于自身管理的集群，`kube-default` 用于应用部署的默认集群（不指定集群名称时）。

k8s 集群，分为一个 Master 节点和多个 Node 节点，

1. **Kubernets Maseter**：K8S 大脑节点，决定将应用放在哪里运行，它相比图中，该节点还隐藏了许多容器，比如：
   - **1）API Server**：API 服务端，通过控制台、网络，接收传过来的命令，判断是否符合语法标准，并根据实际环境进行处理。
   - **2）Scheduler**：调度执行器，对所有资源按照应用资源，执行统一调度，以及任务发布，负责决定将 Pod 放到哪⼀个 Node 上运⾏。
   - **3）Controller Manager**：控制器管理器，负责 Cluster 各种资源的统筹管理。
   - **4）ETCD**：类似于 ZK，对 K8S 集群的配置进行统一管理，保存了 K8S 的相关配置和状态信息，如果 POD 有发⽣变化，那么它会迅速通知相关的组件进⾏处理。
2. **Kubernets Node**：K8S 手脚节点，负责运行容器应用。
   - **1）Kubelet**：核心工作单元，是 K8S 里唯一一个没有以容器形式运行的组件，负责根据 Scheduler 发过来的信息，去创建和运⾏容器，并向 Master 报告运⾏状态，是直接跟 Docker 容器进行沟通。 
   - **2）Docker daemon**：Docker 后台容器。
   - **3）Kube-proxy**：网络通讯、服务发现负载模块，是网络代理的概念，当 service 接收到请求后，转发到某个 node 时，会由该 node 的 kube-proxy 模块负责接收，然后转发到后端的容器中，如果有多个副本，还能提供负载均衡的能⼒。
   - **4）Pod**：是 K8S 的最小工作单元（所以，K8S 最小工作单元不是容器！），是运行在 Node 手脚节点上的一堆容器集合，相当于是比容器更大的"集装箱"，对网络共享、存储共享的一堆 Docker 容器，封装成一个 Pod，作为一个小单元进行管理，从而扩大管理粒度，降低管理复杂度，实现统一部署，共享网络和存储。
   - **5）Controller**：负责对 Pod 进行统一管理。
     1. **Deployment**：一个应用资源，基于 ReplicaSet，会产生一个部署请求，形成一堆 Pod。
     2. **ReplicaSet**：一个会在多个点节点部署多个的 Pod，以完成更多的功能。
     3. **DaemonSet**：一个在同一节点只会运行一份的 Pod。
     4. **StatefulSet**：一个有状态的服务，对外提供的 Pod 名称永远不变。
     5. **Job**：一个短时、定时作业的 Pod。
   - **6）Service**：
     1. 为 Pod 提供了负载均衡：在当 Pod 之间需要相互访问时，会去 DNS Server 找到对应的 IP 地址，通过 Kube-proxy 服务发现功能，进行网络数据包转发，实现网络服务功能，以用于描述 Pod 和 Pod 之间的应用访问。
     2. 为客户端提供固定的 IP + 端口：当 Pod 的 IP 发生变化时，Service 可以保证，客户端面对的 Pod 还是固定 IP 和端口。
3. 当需要执行部署，并指定两个副本时，其**执行流程**为：
   - 1）Kuberctl 发送部署请求到 API Server。
   - 2）API Server 通知 Controller Manager，去创建一个 Deployment 资源。
   - 3）Scheduler 执行调度任务，将两个副本 Pod，分发到 Node1 和 Node2 上。
   - 4）Node1 和 Node2 上的 Kubelet 在各自的节点上，创建并运行 Pod。

##### 3、总

=> 以上，就是我对 Docker 和 K8S 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.4. 算法题 | n 的二进制 1 的个数

leetcode -《汉明距离》。

##### 1）内置函数法 | O（1）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 内置函数》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.1mb，7.67%，时间上，由于内置函数也是位移操作，所以时间复杂度为 O（1），空间上，由于只使用有限几个变量，所以空间复杂度也是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        return Integer.bitCount(x ^ y);
    }
}
```

##### 2）右位移法 | O（logn）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 右位移法》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.6mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        do {
            if((res & 1) == 1) {
                count++;
            }
        } while((res >>>= 1) > 0);
        return count;
    }
}
```

##### 3）Brian Kernighan  算法 | O（logn）

- **思路**：
  - 通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - Brian Kernighan  算法 》的思路解决即可。
  - Brian Kernighan （布莱恩·克尼汉）算法给出，对于任意整数 x，令 x = x &（x-1），可将 x 的二进制表示的最后一个 1 变为 0，因此，如果不断循环执行这个过程则可以获得 x 为 1的比特位个数。
- **结论**：时间，0ms，100%，38.5mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        while(res > 0) {
            res &= res - 1;
            count++;
        }
        return count;
    }
}
```

#### 4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？

按位所在的值，去生成文件夹，每个文件夹只能存一个 ID，最后再收集（如果顺序收集，则还可以排序）所有文件夹的 ID，输出到一个文件里，那个文件就是最终去重后了的答案了。

#### 4.1.2.6. 是否有参加过开源项目，或者 ACM 比赛获奖什么的？

回答了没有，但有提交过 BUG 验证给 Oracle 官网的 JDK 组织，讲的是提交红黑树在删除后调整，判断红黑树是否为合法的红黑树时，没有判断两个连续红节点的情况，最后 Oracle 反馈说需要提供详细的例子证明，但我没有一个很好的数据状态，事件就不了了之了。

=> 结果不太好，下次别说了~

#### 5.1.1.1. List 与 Set 的区别？



#### 5.1.1.2. ArrayList 扩容机制？



#### 5.1.1.3. ArrayList 与 LinkedList 的区别？



#### 5.1.1.4. 如何保证 List 的线程安全？



#### 5.1.1.5. HashMap 的数据结构？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.6. HashMap 的扩容机制，以及为什么是 2^n？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.7. JDK 7 与 JDK 8 中 HashMap 的区别？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.8. HashMap 如何保证线程安全？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.9. JDK 7 与 JDK 8 中 ConcurrentHashMap 的区别？

见《[3.2.1.6. ConcurrentHashMap 底层原理？](#3.2.1.6. ConcurrentHashMap 底层原理？)》。

#### 5.1.2.0. CAS 的缺点，以及什么是总线风暴？



#### 5.1.2.1. volatile 关键字的实现原理？



#### 5.1.2.2. 线程池的数据结构，实现原理，以及线程数如何选择？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 5.1.2.3. MySQL 主键索引、二级索引、联合索引查找数据的原理？



#### 5.1.2.4. MySQL 联合索引失效原理？



#### 5.1.2.5. MySQL 3 个二级索引好还是 1 个 3 字段的联合索引好？



#### 5.1.2.6. MySQL 二级索引和联合索引是不是建的越多越好？



#### 5.1.2.7. 介绍一下 B+ 树，以及 MySQL 为什么采用 B+ 树？



#### 5.1.2.8. 分布式 ID 的实现方案？

雪花算法、发号服务器、Leaf 雪花算法以及分段发号原理

#### 5.1.2.9. MySQL 隐藏主键生成原理？



#### 5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？



#### 5.1.3.1. MySQL 持久性保证原理？

Buffer Pool、redo log。

#### 5.1.3.2. MySQL Buffer Pool 满了以后会怎么样？

页面置换算法，以及 Redis  LRU、LFU 等内存淘汰策略。

#### 5.1.3.3. Redis 键过期策略？

定期扫描，惰性删除，键+守护线程。

#### 5.1.3.4. Redis 常用数据结构，以及 ZSet 底层原理？

见《[1.2.1.5. Redis 数据结构？](#1.2.1.5. Redis 数据结构？)》。

#### 5.1.3.5. Spring AOP 的原理？

见《[4.1.1.5. Spring AOP 的原理？](#4.1.1.5. Spring AOP 的原理？)》。

#### 5.1.3.5. Spring @Transactional 原理？

见《[4.1.1.6. Spring @Transactional 原理？](#4.1.1.6. Spring @Transactional 原理？)》。

#### 5.2.1.1. 自我介绍，以及项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 5.2.1.2.  线程池调优？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 5.2.1.3. Kafka 高可靠保证？

见《[1.1.1.7. Kafka 的高可靠保证？](#1.1.1.7. Kafka 的高可靠保证？)》。

#### 6.1.1.1. Kafka 高可靠保证？

见《[1.1.1.7. Kafka 的高可靠保证？](#1.1.1.7. Kafka 的高可靠保证？)》。

#### 6.1.1.2. 如果一个 Broker 宕机了，还能保证高可靠吗？



#### 6.1.1.3. 算法题 | 1T 字符串数字 ID，怎么在 2C4G 的机器上做去重并且排序？

见《[4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？](#4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？)》。

#### 6.1.1.4. Netty 有了解过吗？

回答了怎么用，但具体原理记不清了

#### 6.1.1.5. 自动打包有了解过吗？

回答了 Jenkins

#### 6.1.1.6. 低代码平台，或者说代码生成器，有了解过吗，给你设计你怎么设计？



#### 6.1.1.7. 一张表每月一条记录实现员工日常打卡记录？

主键，员工号，年，月，打卡信息字段（使用每一位二进制位，来代表每一天的打卡信息，或上2^n）实现

#### 6.1.1.8. 怎么用程序模拟浏览器上的手工业务操作，且会经常掉线？

答了抓包参数+程序发起连接+异常捕捉+重新连接获取token+递归处理业务+递归出口为执行次数或者时间

#### 7.1.1.1. CountDownLatch 和 AQS 讲一下？



#### 7.1.1.2. 分布式锁的实现方案？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 7.1.1.3. AOP 的实现原理？

见《[4.1.1.5. Spring AOP 的原理？](#4.1.1.5. Spring AOP 的原理？)》。

#### 7.1.1.4. 责任链模式的特点，以及与适配器模式的区别？



#### 7.2.1.1. 项目亮点讲一下？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 7.2.1.2. Kafka 分区日志存储原理？

见《[3.2.1.3. RocketMQ、Kafka 底层文件原理？](#3.2.1.3. RocketMQ、Kafka 底层文件原理？)》。

#### 7.2.1.3. Kafka 有进行过调优吗？



#### 7.2.1.4. ZK 与 Redis 分布式锁的区别？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 7.2.1.5. 设计一个注解，实现对返回值（比如手机号码）进行脱敏，基于 Spring、Spring MVC 如何实现？



#### 7.2.1.6.  设置一个配置中心，以满足配置动态刷新的需求？



#### 7.2.1.7. k8s 架构图？

见《[4.1.2.3. Docker 和 K8S 有了解过吗？](#4.1.2.3. Docker 和 K8S 有了解过吗？)》。

#### 7.2.1.8. 阻塞队列有哪些？



#### 7.2.1.9. ArrayBlockingQueue 与 LinkedBlockingQueue 的异同，比如在锁的角度呢？



#### 7.2.2.0. 有参与过 JVM 调优吗，只有过 MAT 吗，OGLIB 有听过没？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 5）内存溢出排查 | MAT、POI、ArrayList、12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%。

#### 7.2.2.1. CMS 和 G1 有什么差别？

见《[4.1.1.8. 项目中的垃圾收集器用了哪些？](#4.1.1.8. 项目中的垃圾收集器用了哪些？)》。

#### 7.2.2.2. 反射的 API 里有哪些类？



#### 7.3.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 7.3.1.2. 为什么要离职？



#### 7.3.1.3. 根据已有的经验，谈谈你对未来 G 系统迭代方向的一些看法？



#### 8.1.1.1. 项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 8.1.1.2. 谈一下你对微服务的一个理解？

见《[1.1.1.1. 项目上用到了 SpringCloud 哪些组件？](#1.1.1.1. 项目上用到了 SpringCloud 哪些组件？)》。

#### 8.1.1.3. 分库分表方案是怎么设计的？



#### 8.1.1.4. 分布式锁的实现方案？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 8.2.1.1. 讲一下 Eureka 源码？

服务注册、服务发现、服务续约、服务下线、服务剔除

#### 8.2.1.2. 服务下线后，TCP 会立马感应到吗？



#### 8.2.1.3. 设计一个负载均衡算法，实现实时动态感知？

Google 论文：60分以下的会在续约时剔除掉，客户端通过超时降级+重试+挑选优质服务实例，其中90+分挑选优质服务实例则从随机选择一个，保证唯一解，60-90分的淘汰选择，从而保证类实时感知

