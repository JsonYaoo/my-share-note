### 十六、庞大系统介绍

| 序号 | 公司                               |
| ---- | ---------------------------------- |
| 1    | 十方融海一面、二面                 |
| 2    | 来未来一面                         |
| 3    | 天翼云一面、二面                   |
| 4    | 欢聚时代（供应链）一面             |
| 5    | SHEIN 一面、二面、三面             |
| 6    | 梦网科技一面                       |
| 7    | 平安财险一面、二面、HR 面          |
| 8    | 追一科技一面、二面                 |
| 9    | 字节（供应链）一面                 |
| 10   | 虾皮（保险）一面、二面             |
| 11   | bigo（imo）一面、二面、三面、HR 面 |
| 12   | 字节（飞书）一面、二面、三面、四面 |

#### 1.1.1.1. 项目上用到了 SpringCloud 哪些组件？

##### 1、总

用到了 Eureka 做**服务注册**，Feign 做**服务通信**，Ribbon 做**负载均衡**，Sleuth+Zipkin 做**链路追踪**，Config 做**配置中心**、Stream+Bus 做**消息驱动**。

##### 2、分

1. 服务注册的意思就是，在微服务中，由于服务可能会比较多，其 IP 也经常会发生变化，如果**手动维护**每个服务的 IP+端口 的话，那么就太耗时耗力了，此时可以通过服务启动时，**上报**包括自己当前的 IP 地址、端口、健康状态等信息，到一个注册中心中，由注册中心来统一收集并管理它们，从而减轻人工维护的成本，且信息也比较及时和准确。
2. 服务通信的意思就是，在微服务中，由于模块与模块之间，常常需要相互获取数据，那么就需要进行通信，此时可以到注册中心那里，获取一份想要访问的服务器的**注册表**，得到它的 IP+端口，然后发起比如 HTTP 的远程调用，从而获取到某个参数下远程服务器的执行结果。
3. 负载均衡的意思就是，在微服务中，由于服务实例常常不止一个，如果没有一个合适的访问策略，那么很可能会导致某个实例**访问过热**，此时就需要一种策略来**打散这些流量**，这就是负载均衡，在 SpringCloud 中的实现是 Ribbon 组件，其原理是服务实例启动时，通过获取注册中心中所有的服务列表，然后缓存到机器内存中，在要发起服务调用时，会经过 Ribbon 配置的负载算法，来保证调用的均衡性。
4. 链路追踪的意思就是，在微服务中，由于一个前端请求，可能会拉起多个服务间的调用，导致排查问题可能需要跨机器的挨个挨个排查，浪费人力精力，此时可以通过使用一个**全局 ID** 来标记当前请求，在需要跨机器请求时，全局 ID 不变，但生成一个新的**局部 ID**，以及**时间戳**，传递到下一台机器，这样全局 ID 标记也就跟着过去，同时，还可以通过使用当前时间戳减去传过去的时间戳，从而计算出本次跨机器请求所花费的时间，完成链路追踪。
5. 配置中心的意思就是，在微服务中，由于服务实例可能会有很多，且每个模块的业务、参数等配置可能会不一样，导致配置可能会有多个版本，如果以人工的方式去登记每个模块配置的不同之处，识别哪个版本是哪个服务的配置的话，很容易出错，且难以维护和管理，此时可以抽象出一个配置中心，通过**按路径、按标签**地存放所有服务模块的配置信息，在每个服务启动时，再去配置中心**拉取**对应自己的配置，填入自己配置的**占位符**中，然后再去加载容器，从而实现**远端配置**的统一管理与控制。
6. 消息驱动的意思就是，在微服务中，常常需要用到消息中间件，但不同中间件的 API 使用方式不同，比如业务代码基于 RabbitMQ 做了实现，如果某一天想要更换底层为 Kafka，就需要对原有的业务代码进行修改，此时，可以抽取出一个统一的消息驱动组件，来**屏蔽底层的实现差异**，只负责输入输出消息即可，从而实现一套从上层来看是以**消息作为事件驱动**的架构。

##### 3、总

综上，就是我对 Spring Cloud 微服务的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.2. 如何在 Feign 调用时增强一下 Header？

关键字：RequestInterceptor#apply()、RequestTemplate、ThreadLocal。

##### 1、总

可以实现 `RequestInterceptor#apply()` 方法，该方法会传入一个 `RequestTemplate`，然后从上下文，比如 `ThreadLocal` 中取出需要增强的属性，然后设置到 `RequestTemplate#header` 中即可，比如这样：

```java
@Component
@Slf4j
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate requestTemplate) {
        // Member User信息
        MemberUser memberUser = GlobalMemberContext.getMemberUser();
        if(memberUser != null){
            try {
                requestTemplate.header(ProjectConstant.MEMBER_USER_INFO, URLEncoder.encode(JSON.toJSONString(memberUser), Charsets.UTF_8.name()));
            } catch (UnsupportedEncodingException e) {
                log.info("member user编码失败");
            }
        }
    }
}
```

##### 2、分

其中，Feign 的底层原理是这样的，

- **注入原理**：
  1. 由于 SpringBootApplication 上打了 @EnableFeignClients 注解，所以会回调注解导入的 **ImportBeanDefinitionRegistrar**#registerBeanDefinitions 方法，该方法可以扫描并注册 FeignClient。
  2. 其中注册 FeignClient 时， 会在 BeanDefinitionRegistry 中添加 FeignClientFactoryBean#beanDefinition。
  3. 由于 FeignClientFactoryBean 实现了 FactoryBean 接口，所以在对应的 FeignClient 被注入时，则会调用 **FactoryBean#getObject** 方法。
  4. 然后该 FeignClientFactoryBean#getObject 方法在构造 Feign.Builder 时，获取到容器中所有打了 @Component 注解，且实现 **RequestInterceptors** 接口的拦截器，然后注入到 Feign.Builder#requestInterceptors 属性中。
  5. 接着就是使用 Feign.Builder 来构建 LoadBalancer 的动态代理，返回对应的动态代理对象。

```java
Map<String, RequestInterceptor> requestInterceptors = context
				.getInstances(this.contextId, RequestInterceptor.class);
if (requestInterceptors != null) {
    builder.requestInterceptors(requestInterceptors.values());
}
```

- **执行原理**：
  1. 当业务方法调用注入的 FeignClient 实例对应的接口方法时，则会触发 JDK 动态代理，回调到 **InvocationHandler** 的 invoke 方法。
  2. 在 invoke 方法中，会去遍历所有的 **requestInterceptors**，并执行他们的 **apply** 方法，从而实现 Header 的增强。

```java
final class SynchronousMethodHandler implements MethodHandler {
    @Override
    public Object invoke(Object[] argv) throws Throwable {
        ...
        return executeAndDecode(template, options);
    }
    
    Object executeAndDecode(RequestTemplate template, Options options) throws Throwable {
    	Request request = targetRequest(template);
        ...
    }
    
  	Request targetRequest(RequestTemplate template) {
    	for (RequestInterceptor interceptor : requestInterceptors) {
      		interceptor.apply(template);
    	}
    	return target.apply(template);
  	}
}
```

##### 3、总

以上，就是我对 Feign Client 的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.3. Feign 的调优参数有哪些，以及HTTP 连接池优化？ 

| 参数解释                               | 具体配置                                                     |
| -------------------------------------- | ------------------------------------------------------------ |
| 具体服务的连接超时时间（ms）           | xxx.ribbon.ConnectionTimeout                                 |
| 具体服务的读取超时时间（ms）           | xxx.ribbon.ReadTimeout                                       |
| 具体服务的重试开关（true / false）     | xxx.ribbon.okToRetryOnAllOperations                          |
| 具体服务的超时重试次数（不包括首次）   | xxx.ribbon.MaxAutoRetries                                    |
| 具体服务的超时重试机器数（不包括首台） | xxx.ribbon.MaxAutoRetriesNextServer                          |
| 更换 Feign 的客户端（池化连接对象）    | feign.okhttp（新起之秀） / .httpClient（老牌 HC），两者性能差距不大，默认为  JDK 的 HttpUrlConnection |
| 日志调用配置                           | feign.client.config.default.loggerLevel：full                |
| 拦截器配置                             | 实现 RequestInterceptor#apply()                              |
| 自定义解码器                           | 实现 feign.codec.Decoder#decode()                            |
| 降级配置                               | @FeignClient fallback：继承接口自定义 Handler，或者实现 FallBackFactory#create() |

#### 1.1.1.4. SpringBoot 自动装配和自定义 starter？

##### 1、总

Starter 是什么：
1. Starter 就是一个 jar 包，写一个 @Configuration 的配置类，把这些 Bean 的定义都包含在其中，然后在 Starter 包下的 `META-INF/spring.factories` 中写入该配置类，SpringBoot 程序在启动时，就会按照约定来加载该配置类。
2. 开发人员只需要将相应的 Starter 包依赖进应用中，然后进行相关的属性配置，就可以进行代码开发，而不需要再单独对 Bean 进行配置。

##### 2、分

原理：
1. 当启动 SpringBoot 应用时，会先创建 SpringApplication 的对象，在对象的构造方法中，会进行某些参数的初始化工作，最主要的是判断当前应用的类型（比如 Servlet 类型），以及通过 SPI 的方式加载整个应用的 `spring.factories` 文件中的初始化器和监听器的 Class。
2. SpringApplication 对象创建完成之后，开始执行 `run()` 方法，来完成整个启动，启动过程中最主要的有两个方法，第一个叫做 `prepareContext()`，第二个叫做 `refreshContext()`，在这两个步骤中完成了自动装配的核心功能，而其他方法的处理逻辑包含了上下文对象的创建、Banner 的打印、异常报告期的准备等各个准备工作，方便后续来进行调用。
3. 在 `prepareContext()` 方法中，主要完成了对上下文对象的初始化工作，包括比如 `Enviroment`对象属性值的设置，在整个过程中，有一个非常重要的方法 `load()`，`load()` 主要完成一件事，那就是将**启动类**作为BeanDefinition 注册到 Registry 中，方便后续在进行 BeanFactoryPostProcessor 调用执行时，找到对应的启动类来完成 `@SpringBootApplication` 和 `@EnableAutoConfiguration` 等注解的解析工作。
4. 在 `refreshContext()` 方法中，会进行整个容器的刷新过程，会调用 Spring 中的启动流程，即`AbstractApplicationContext#refresh()`，有 13 个关键方法，来完成整个 Spring 应用的启动，其中会调用 `invokeBeanFactoryPostProcessor()` 方法，主要是对`ConfigurationClassPostProcessor` 的处理，会先调用实现 `BeanDefinitionRegistryPostProcessor` 接口的 `postProcessBeanDefinitionRegistry()` 方法，然后再调用自己实现的 `postProcessBeanFactory()` 方法，处理各种包括 @PropertySource、@ComponentScan、@Import、@ImportResource、@Bean 等注解。
5. 其中，在解析 @Import 注解时，会有一个 `getImports()` 的方法，会从**启动类**开始递归解析注解，把所有包含 @Import 注解都收集到，然后在 `processImport()` 方法中，对 Import 导入的类进行分类，这里主要起识别作用的是 `ImportSelect` 的实现类  `AutoConfigurationImportSelect`，来调用 `selectImports()` 方法使用 SPI 的方式，来获取并加载 `spring.factories` 中的 `EnableAutoConfiguration` 自动装配配置类的 Class，完成自动装配。
6. 接着，还调用子类上下文 `ServletWebServerApplicationContext#onRefresh` 方法，来拉起嵌入式的 Tomcat 容器。
7. 最后，就是实例化 Bean，即 `finishBeanFactoryInitialization()` 方法，主要是实例化所有剩下非懒加载的单例 Bean，并完成它们的初始化和依赖注入，通过遍历所有 beanNames，然后挨个判断是走 FactoryBean 的流程，还是走 BeanFactory 的流程，其中主要步骤总结起来分为 3 步，分别是 NewInstance 实例化、Populate 属性赋值 和 Initialization 初始化，从而完成自动装配配置 Bean 的注入。

##### 3、总

自定义 Starter：

1. 创建 Starter 项目，定义 Starter 需要的 Properties 配置类，比如数据库连接信息等。
2. 然后编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean。
3. 编写 `META-INF/spring.factories` 文件，以让 SpringBoot 在启动时加载自动配置类。
4. 然后在项目中，引入自定义 Starter 的 Maven 依赖，增加对应的配置值后，然后即可直接使用。

#### 1.1.1.5. SpringMVC 请求前改写 @RequestBody 参数？

##### 1、总

有三种方法，分别是 (Filter + HttpServletRequestWrapper) + HandlerInterceptor + WebMvcInterceptorConfig、RequestBodyAdvice + @ControllerAdvice 和 Controller AOP。

| Spring MVC 请求扩展点                 | 执行顺序 | 方法                                                         | 作用                                                         |
| ------------------------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Filter                                | 1        | doFilter(ServletRequest, ServletResponse)                    | 根据 params、header 过滤非法请求、包装 HttpServletRequest，不做改写 Body |
| HandlerInterceptor                    | 2        | preHandle(HttpServletRequest, HttpServletResponse, Object)   | Handler Method 处理前拦截                                    |
| RequestBodyAdvice + @ControllerAdvice | 3        | afterBodyRead(Object, HttpInputMessage, MethodParameter, Type, Class) | HandlerAdapter#handleInternal 执行过程时解析 Method 参数     |
| Controller AOP                        | 4        | @Before、@Around                                             | point.proceed(args) 前改写 args 参数                         |

##### 2、分

###### HandlerInterceptor | 实现最麻烦

**实现最麻烦**，需要在 Filter 处添加 RequestWrapper 包装，然后在包装类里替换掉 Reader 读取的输入流，最后在 MVC 的拦截器 preHandle 实现 body 替换。

```java
@Component
public class UserFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.err.println("init");
    }

    @Override
    public void destroy() {
        System.err.println("destroy");
    }

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        ((ResponseFacade) response).addHeader("sign", request.getParameter("sign"));
        System.err.println("doFilter");
        
        // 1、结合UserBodyWrapper包装request
        chain.doFilter(new UserBodyWrapper((HttpServletRequest) request), response);
    }
}

public class UserBodyWrapper extends HttpServletRequestWrapper {

    private String body;

    public String getBody() {
        return body;
    }

    public void setBody(String body) {
        this.body = body;
    }

    public UserBodyWrapper(HttpServletRequest request) throws IOException {
        super(request);

        // 2、先读取一次输入流, 获取body内容
        this.body = IOUtils.toString(request.getInputStream(), StandardCharsets.UTF_8);
    }

    @Override
    public ServletInputStream getInputStream() throws IOException {
        ByteArrayInputStream bais = new ByteArrayInputStream(body.getBytes(StandardCharsets.UTF_8));

        // 3、以后读取输入流时, 只读取内存中的这个body
        return new ServletInputStream() {
            @Override
            public boolean isFinished() {
                return false;
            }

            @Override
            public boolean isReady() {
                return false;
            }

            @Override
            public void setReadListener(ReadListener listener) {

            }

            @Override
            public int read() throws IOException {
                return bais.read();
            }
        };
    }

    @Override
    public BufferedReader getReader() throws IOException {
        // 4、以后读取输入流时, 只读取内存中的这个body
        return new BufferedReader(new InputStreamReader(getInputStream()));
    }
}

public class UserHandlerInterceptor implements HandlerInterceptor {

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        System.err.println("preHandle");

        UserBodyWrapper userBodyWrapper = (UserBodyWrapper) request;
        String body = userBodyWrapper.getBody();
		
        // 5、获取body，改写body
        User user = JSONObject.parseObject(body, User.class);
        user.setUsername("测试添加前缀" + user.getUsername());
        ((UserBodyWrapper) request).setBody(JSONObject.toJSONString(user));
        
        return true;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        System.err.println("postHandle");
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        System.err.println("afterCompletion");
    }
}

@Configuration
public class WebMvcInterceptorConfig implements WebMvcConfigurer {

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        // 6、添加WebMvc拦截器配置类
        registry.addInterceptor(new UserHandlerInterceptor()).addPathPatterns("/**");
    }
}
```

###### RequestBodyAdvice | 时机最适合

```java
@ControllerAdvice
public class UserRequestBodyAdvice implements RequestBodyAdvice {

    @Override
    public boolean supports(MethodParameter methodParameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("supports");
        return true;
    }

    @Override
    public HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) throws IOException {
        System.err.println("beforeBodyRead");
        return inputMessage;
    }

    // 1、在 HandlerAdpater#resolveArgments 时，HttpMessageConverter读取完body后，进行回调改写body
    @Override
    public Object afterBodyRead(Object body, HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("afterBodyRead");

        JSONObject jsonObject = JSONObject.parseObject(JSONObject.toJSONString(body));
        Long id = jsonObject.getLong("id");
        String username = jsonObject.getString("username");
        String password = jsonObject.getString("password");

        try {
            Constructor constructor = ((Class) targetType).getConstructor(Long.class, String.class, String.class);
            return constructor.newInstance(id, username + "测试添加后缀", password);
        } catch (Exception e) {
            e.printStackTrace();
        }

        return body;
    }

    @Override
    public Object handleEmptyBody(Object body, HttpInputMessage inputMessage, MethodParameter parameter, Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
        System.err.println("handleEmptyBody");
        return body;
    }
}
```

###### Controller AOP | 实现简单强大

```java
@Aspect
@Component
public class AspectJConfig {

    @Pointcut("execution(* com.jsonyao.cs.controller.*.*(..))")
    private void pointcut() {

    }

    @Around("pointcut()")
    public Object around(ProceedingJoinPoint point) throws Throwable {
        System.err.println("around");
        long start = System.currentTimeMillis();
        
        // 1、业务方法调用前，改写body
        Object[] args = point.getArgs();
        User user = User.class.cast(args[0]);
        user.setUsername(user.getUsername() + "测试AOP后缀");
        
        Object res = point.proceed(new Object[] {user});
        
        long end = System.currentTimeMillis();
        System.err.println("执行结果: " + res + ", 消耗时间: " + (end - start));
        return res;
    }
}
```

##### 3、总

综上，HandlerInterceptor  实现最麻烦，但处理位置比较通用，适合一些公共的设置，RequestBodyAdvice 回调的位置**最适合改写 @RequestBody**，适合统一对 @RequestBody 进行设置，Controller AOP 更强大，实现也简单，适合一些通用方法级别的拦截。

#### 1.1.1.6. Spring MVC 拦截器和过滤器的区别？

##### 1、总

拦截器 HandlerInterceptor，过滤器 Filter，虽然可以对请求进行一定处理，但：

1. **实现人不同**：HandlerInterceptor 属于 Spring#Web 包下，Filter 属于 Tomcat#javax 包下。
2. **配置方式不同**：HandlerInterceptor 在 Spring#WebMvcConfigurer 中配置，而 Filter 在 web.xml 中配置。
3. **处理时机不同**：HandlerInterceptor 作用更强大，方法处理前的拦截、处理后的拦截、返回前的拦截，而 Filter 则是在进入DispatcherServlet 前进行一定的请求过滤处理。

##### 2、分

![1645947452956](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645947452956.png)

Spring MVC 客户端请求的生命周期管理：

1. **Filter#doFilter** 执行链过滤客户端请求。
2. DispatcherServlet，表示中心控制器，在客户端发出请求后，经过 Web 容器（比如 Tomcat）后，会打到 DispatcherServlet 上，并由其来处理请求。
3. HandlerMapping，表示处理器映射，DispatcherServlet 收到请求后，会调用 HandlerMapping，HandlerMapping 会根据请求 url 去查找对应的 Handler，即一个 Handler Method 对象，指的是 url 对应 Controller 中的对应方法。
4. HandlerExecutionChain，表示处理器执行链，Handler 解析完 url  后，会返回一个处理器执行链给DispatcherServlet，其中就包括一堆 HandlerInterceptor。
5. HandlerAdapter，表示处理器适配器，DispatcherServlet 会按照规则去匹配对应的 HandlerAdapter。
6. 再由对应的 Handler Method 去处理请求，其中就包括调用去执行我们编写的 Controller 业务逻辑。
   - 但在执行前，会先调用 **HandlerInterceptor#preHandle** 进行  handler 方法处理前的拦截。
7. Controller 代理对象，则会去访问数据库，填充好模型后，再把 ModelAndView 返回给 HandlerAdapter。
   - 其中，在 HandlerAdpater#resolveArgments 时，HttpMessageConverter读取完 body 前/后，可以对 **RequestBodyAdvice#beforeBodyRead/afterBodyRead** 进行回调，从而改写 body。
   - 而我们平常使用的 @ResponseBoday 的方法，返回的 ModelAndView 为空，也就是不会返回视图给客户端，而是经过 `RequestResponseBodyMethodProcessor`，把 JSON 串写入到 Response 的 Body 中。
8. HandlerAdapter 收到后，再将 ModelAndView  传递给 DispatcherServlet。
9. DispatcherServlet 收到后，则调用视图解析器 ViewResolver，来解析 ModelAndView。
10. ViewResolver 会解析逻辑视图名，根据逻辑的 View 找到实例的 View，并返回给 DispatcherServlet。
11. DispatcherServlet 收到后，则根据 ViewResolver 解析出的 View，调用对应的实际视图，结合 Model 进行渲染。
    - 但在执行前，会先调用 **HandlerInterceptor#postHandle** 进行 handler 方法处理后的拦截。
12. 最后，DispatcherServlet 再将渲染后的 View 作为结果，响应给客户端。
    - 在执行后，返回结果前，会调用 **HandlerInterceptor#afterCompletion** 进行响应前的拦截。

##### 3、总

以上，就是我对 Spring MVC 拦截器和过滤器的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.7. Kafka 的高可靠保证？

##### 1、总

对于 Kafka 高可靠，需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 + `acks=all`（或者 `acks=1`）  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 `acks=all` 保证消息成功写入所有 ISR，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 ISR 机制来保证，配合生产端 `acks=all` 来保证每次写入消息，必须在 ISR 集合中的所有 Broker 写入成功后才认为消息写入成功，响应 ACK 给生产端。
3. **消费端**：通过 `enable-auto-commit=false` 关闭自动 ACK，`ack-mode=manual` 打开手工 ACK，在处理消息完毕后，才进行一次手工 ACK `acknowledgement.acknowledge()`，避免处理异常后，不能再次重复消费的情况。

##### 3、总

以上，就是我对 Kafka 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.8. RabbitMQ 的高可靠保证？

##### 1、总

与 Kafka 高可靠类似，对于 RabbitMQ 高可靠，也需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 +  `publisher-confirms=true` 以及实现 ConfirmCallback 函数开启 Broker 消息 Confirm 机制  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 Broker Confirm 机制，保证消息成功写入 Broker，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 `druable=true` 开启持久化队列 + 生产端消息设置 `deliveryMode=2` 开启持久化消息 ，来保证消息写入后，如果未被消费前，会保存在 Broker 中，防止 MQ 丢消息。
3. **消费端**：通过 `acknowledge-mode=mannul` 关闭自动 ACK，打开手工 ACK，在处理消息完毕后，才 `channel.basicAck` 进行一次手工 ACK，避免处理异常后，RabbitMQ 立即把消息删除，丢失消息的情况。

##### 3、总

以上，就是我对 RabbitMQ 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.1.1.9. JDK 的新特性、新 JVM？

| JDK 版本 | 新特性                                                       |
| -------- | ------------------------------------------------------------ |
| JDK 5    | 自动拆装箱、 Foreach 循环、枚举类、泛型、JUC                 |
| JDK 6    | 对脚本语言 Ruby、Groovvy、JS 的支持                          |
| JDK 7    | switch 支持 String，开始转移永久代，静态变量、字符串常量池转移到了堆中 |
| JDK 8    | 函数式接口，Lambda 表达式，Stream API、接口支持 default 方法、HashMap 和 ConcurrentHasMap 性能提升、元空间完全取代永久代 |
| JDK 9    | 集合添加 List.of(xxx, xxx) 等工厂方法 、接口支持 private 方法，默认使用 G1垃圾收集器 |
| JDK 10   | G1 多线程并行 Full GC，降低 G1 STW 时间                      |
| JDK 11   | 新增 ZGC，比 G1 更细粒度的内存管理，采用并行回收策略         |
| JDK 12   | 新增 Shenandoah GC 算法、优化 G1 将垃圾分为强制部分和可选部分，强制部分会被回收，可选部分可能不会被回收，提高 GC 效率 |
| JDK 13   | ZGC 优化，将标记长时间空闲的堆内存返还给操作系统，只要保证堆大小不会小于 -Xms 即可 |
| JDK 14   | 删除 CMS 、弃用  Parallel Scavenge + SerialOld 的 GC 组合、将 ZGC 应用到 MacOS 和 Win 中 |
| JDK 15   | 新增隐藏类、密封类（避免抽象类被滥用）                       |
| JDK 16   | ZGC 性能优化，此版本相当于是对 JDK 14 和 15 的一些特性进行了正式的引入 |
| JDK 17   | 正式引入密封类 sealed class，限制抽象类的实现                |

#### 1.2.1.1. JDK 8 VS JDK 7？

| JDK 8 新特性                          | 解释                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| 函数式接口，Lambda 表达式，Stream API | 在需要一个函数，但又不想费神去命名一个函数时使用，也就是匿名函数，同时，还可以把函数作为参数，传递进某个方法中 |
| 接口支持 default 方法                 | 接口的默认实现                                               |
| 元空间完全取代永久代                  | 元空间使用本地内存，永久代使用 JVM 内存，从而根本上解决了永久代溢出的问题 |
| HashMap 性能提升                      | 拉链 >= 8 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、扩容时无需重新 rehash，只需要分高低位转移链表即可、改用尾插法解决并发插入时的 CPU 100% 问题 |
| ConcurrentHasMap 性能提升             | 拉链 >= 8 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、Node+CAS+synchronzied+TreeBin 读写锁，替换掉 Segment+HashEntry+ ReentrantLock 分段锁、采用 CAS+synchronzied 实现渐进式并发扩容 |

#### 1.2.1.2. JDK 8 函数式接口的实现原理？

##### 1、总

1. 函数式接口，指**有且只有一个抽象方法的接口**，接口中的 static 方法、default 方法、Object 方法都不算抽象方法，且有个专门的注解 `@FunctionInterface`，但它不是必须的，如果接口符合以上函数式编程的语义，那么加不加这个注解都不影响，加上只是为了编译器进行检查而已，但如果不符合语义，又加上了该注解，那么编译器则会报错。
2. 有且只有一个抽象方法的原因是，由于函数式接口 ` () -> {} ` 的写法，主要是为了简化代码，相当于是一个**匿名内部类的匿名函数**，如果有多个抽象方法，编译器则不知道是重写哪个方法了，所以只能有且只有一个抽象方法。

##### 2、分

在 JDK 8 中，函数式接口主要分为 4 类，分别是**供给型、消费型、断言型和方法型**，其中它们的方法又可以和定义的 default 方法进行**连用**。

| 接口           | 方法               | 说明                                          |
| -------------- | ------------------ | --------------------------------------------- |
| Supplier< T >  | T get();           | 供给型，无参，返回一个函数返回的一个泛型对象  |
| Consumer< T >  | void accept(T t);  | 消费型，传入一个泛型对象，但没有返回值        |
| Predicate< T > | boolean test(T t); | 断言型，传入一个泛型对象，但返回 boolean 类型 |
| Function< T >  | R apply(T t);      | 方法型，传入一个泛型对象，返回另一个泛型结果  |

##### 3、总

以上就是我对 JDK 8 函数式接口的理解，它是 Lambda 表达式和 Stream API 的基础，使用这种方式来编码，既简洁又高效。

#### 1.2.1.3. 线程池核心参数，以及选取原则？

##### 1、总

对于这个问题，我打算从线程池的概念、线程复用原理、线程淘汰原理、构造参数、数据结构、生命周期、工作原理和调优原则这几个方面进行回答。

##### 2、分

1. **线程池的概念**：线程池，ThreadPoolExecutor，允许使用多个线程之一，来执行每个提交的任务，通过**线程复用**，来降低线程创建和销毁所带来的开销，同时任务到达时，可以无需等待线程的创建就能立即执行，从而提高任务的处理速度。

2. **线程复用原理**：通过设计一个**任务队列**，来承放并缓冲更多的执行任务，使得**本已存在的线程**，在处理完它们手上的任务后，可以立马从任务队列的**另一端取出执行任务**，接着继续往下执行，周而复始，从而不用每次都构建一个新的线程再执行，实现线程复用。

3. **线程池的构造参数**：但是，这种线程复用太过于简单暴力，为了让线程池稳定可控，还需要其他参数进行优化：

   - 考虑到，那些本已存在的线程应该有个上限，就需要指定一个 `corePoolSize` 核心线程数，核心线程的意思就是，默认情况下没有保活时间，不会被回收，在不超 `corePoolSize` 上限且收到新任务时会被创建。
   - 考虑到，在任务过多，核心线程处理不过来的情况，就需要指定一个 `maximumPoolSize` 最大线程数。
   - 考虑到，在任务峰值过后，非核心线程可能会空闲一段时间，但仍然占据系统资源的情况，就需要指定一个 `keepAliveTime` 非核心线程的最大空闲时间以及 `TimeUnit` 时间单位。
     - 这也是**线程淘汰**的原理所在，如果在从任务队列中取任务的时间，超过了指定的 `keepAliveTime` 还没取到任务，则可以认为队列中没有多余的任务了，也就是轮训任务队列的这个线程空闲了 `keepAliveTime` 这么久的时间，那么就要对这个线程进行淘汰处理，以节省系统资源。
   - 考虑到，任务需要装入任务队列，就需要指定一个 `BlockingQueue` 阻塞队列接口的具体实现。
   - 考虑到，在构建核心或者非核心线程时，可能需要对线程本身进行一些，比如线程名称等参数设置的情况，就需要指定一个 `ThreadFactory` 的具体实现。
   - 考虑到，任务队列和最大线程都超上限，即线程池超负载时，任务还源源不断到来的情况，就需要指定一种 `RejectedExecutionHandler` 的具体实现，来执行相应的拒绝策略逻辑。

4. **线程池的数据结构**：

   - 根据以上分析，可以容易得到，如果构建一个好点的线程池，就至少需要持有核心线程数、最大线程数、非核心线程的最大空闲时间、任务队列、线程工厂、拒绝策略程序的引用。
   - 另外，JDK 在实现方面，还抽象了一个 `Worker` 类，通过使用 `Worker` 自己持有的 `Thread` 实例，在轮训任务队列时进行任务消费。
   - 同时还持有了一个 `AtomicInteger` 原子类型的 `ctl  ` 线程池控制位，来管理线程池的生命周期及有效线程的数量。

5. **线程池的生命周期**：线程池控制位 ctl，JDK 把 Integer 的高 3 位作为**线程池的状态**，低 29 位作为**有效线程的数量**，前者一个存在 5 种状态，规定：

   -  **-1 为 RUNNING 运行态**，此状态下能够接收新提交的任务，同时还能处理任务队列中的任务。
   -  **0 为 SHUTDOWN 关闭态**，此状态下不会再接受新提交的任务，但还可以继续处理任务队列中的任务。
   -  **1 为 STOP 停止态**，此状态下不会再接收新提交的任务，也不能继续处理任务队列中的任务，并且还会尝试中断正在处理任务的线程。
   -  **2 为 TIDYING 整理态**，此状态下所有的线程都已终止了，此时有效工作数量为 0。
   -  **3 为 TERMINATED 终止态**，在 TIDYING 整理态回调完 `terminated()` 钩子函数以后，会进行此状态。

   ![1645968027493](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645968027493.png)

6. **线程池的工作原理**：

   1. 首先根据线程控制位 `ctl`，判断当前有效线程数是否小于设定的核心线程数，如果是小于，那么就可以把当前任务作为首个任务 `firstTask`，去**创建核心线程**并执行任务。
   2. 如果发现超出了核心线程数，或者并发下核心线程创建失败了，那么就在检查完线程池还在运行状态后，就尝试**把任务投递到任务队列中**。
   3. 如果任务投递成功，则还要做线程池状态的双重检查，防止线程池突然被关闭，如果发现线程池确实不再是运行态了，那么就需要把刚才投递成功的任务给取出来，再**执行拒绝策略程序**；而如果发现还是运行态，则视有效线程数量是否为 0，来决定是否需要**补充非核心线程**，以保证任务队列中的任务不会永远停留在内存中。
      1. 注意这里**补充非核心线程**的操作，它可以保证 `corePoolSize=0 & maximumPoolSize > 0` 且任务队列还没达到上限时，仍能生成 1 个非核心线程去消费任务队列，避免队列内存溢出的发生，关于这里的细节就可以说说我们的一段生产事故了~
      2. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
      3. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
      4. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
      5. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
      6. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。
   4. 如果任务投递失败了，则**尝试补充非核心线程**，如果因为线程池不是为运行态，或者超出了最大核心线程数，导致非核心线程补充失败的话，那么就需要**执行拒绝策略程序**，因为此时要么是 SHUTDOWN 关闭状态不能接受新任务了，要么就是任务队列满了需要拒绝添加新任务了。

   ![1645967491556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645967491556.png)

7. **线程池的调优原则**：

   - **线程池大小的设置**：需要先确定任务的类型，分为 CPU 密集型、IO 密集型以及混合型的任务：

      | 类型       | 概念                                                         | 目的                                                         | 合理的经验公式                                               |
      | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | CPU 密集型 | 任务需要大量的运算，中间没有阻塞，CPU 一直全速运行           | 需要尽可能少的线程数量，以减少线程上下切换的次数，提高 CPU 的利用率 | CPU 核数 + 1                                                 |
      | IO 密集型  | 任务大量时间都花在 IO 的阻塞上，希望 CPU 尽可能去调度其他任务，而不是在等待阻塞的线程、浪费 CPU 资源，所以需要更多的线程数以供 CPU 调度 | 需要尽可能多的线程数，但过多的线程也会带来过多的上下文切换   | CPU 核数 * 2                                                 |
      | 混合型     | 既有 CPU 密集型的特点，又有 IO 密集型的特点                  | 需要看平均线程等待时间，和平均线程运行时间，来决定对应的线程数，可通过 Github#PoolSize Calculator 工具类进行粗略的计算 | CPU 核心数 * 目标 CPU 利用率 * （1 + 平均线程等待时间 / 平均线程运行时间），可见，平均线程等待时间越长，平均线程运行时间越短，则需要的线程就越多 |

      => 但这些只是经验公式，最优的参数还需要根据实际环境不断压测、调优才能得到。

   - **任务队列的设置**：控制任务队列容量，实际上就是在考量**内存占用**和**任务的排队策略**，常用的阻塞队列实现有：

      | 实现类              | 特性                                                         | 排队策略   | 优点                                                         | 缺点                                                         |
      | ------------------- | ------------------------------------------------------------ | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | SynchronousQueue    | 无界同步队列，容量为 0，不存储任何元素，每个插入操作都会阻塞等到另一个线程进行相应的删除操作才会恢复（利用 CAS 自旋 + LockSupport 方式实现阻塞） | 直接交接   | 最小的内存花销                                               | 当任务到达速度大于处理速度时，如果搭配无界池，可能会出现无限线程增长的问题 |
      | LinkedBlockingQueue | 单向链表有界阻塞队列，容量可选，空参构造时为 Integer.MAX_VALUE，相当于无界队列 | "无界"队列 | 核心线程繁忙时，任务会在队列中排队，适合用于平滑瞬间爆发的流量 | 如果任务到达速度大于处理速度，可能会导致任务队列元素无限增长，占用较大的内存花销 |
      | ArrayBlockingQueue  | 数组有界阻塞队列，初始时必须先指定容量大小，一旦指定，就不能再修改了 | 有界队列   | 与最大线程数一起使用，可以防止资源被耗尽                     | 任务队列初始化好了后，就难以再动态的调整和控制了             |

   - **拒绝策略程序的设置**：当线程池被关闭，或者任务队列和线程都已经饱和时，新提交的任务会走到拒绝策略程序的处理逻辑中，默认的拒绝策略程序都是定义在 ThreadPoolExecutor 的内部类中：

      | 实现类              | 特性                                                         | 适用场景                                                     |
      | ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | AbortPolicy         | 默认的拒绝策略程序，在任务被拒绝时，会抛出 RejectedExecutionException 异常 | 可以阻止系统正常运行下去                                     |
      | CallerRunsPolicy    | 调用 Runnable#run，当前主线程会自己去运行任务                | 不会造成任务的丢失，可以让线程池有一定的缓冲时间             |
      | DiscardPolicy       | 任务会被简单的丢弃掉                                         | 允许任务丢失时，这是最好的一种丢弃策略                       |
      | DiscardOldestPolicy | 丢弃任务队列头部的任务，然后重新执行一开始的工作流程         | 会丢弃最老的一个任务，也就是可能马上就被执行的任务，然后重新提交当前任务 |

##### 3、总

以上，就是我对线程池核心参数及原理的一个理解，请问有什么细节需要补充的吗？

#### 1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？

##### 1、总

分布式锁指的是，在不同的系统或者同一个系统的不同主机之间，共享访问某个资源时，用来互斥地防止彼此干扰保证一致性的锁实现，其实现方式有：

- **基于数据库实现**：通过乐观锁，或者唯一索引实现。
- **基于分布式缓存实现**： 典型的有，通过 Redis 实现。
- **基于分布式一致性算法实现**：典型的有，通过 ZK 实现。

##### 2、分

###### 1）基于数据库实现 | 负担大

- **基于乐观锁实现**：原理是，根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。
- **基于唯一索引实现**：原理是，在表上建立唯一索引，当想要获得锁时，向表中插入一条记录，释放锁时则删除这条记录。
  - **缺点**：
    1. **锁没有失效时间**，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
    2. **不可重入**，同一线程在没有释放锁之前无法再获取到锁。

###### 2）基于分布式缓存实现 | 锁失效

- **基于 Redis 单机实现**：使用 `SET NX EX` 指令加锁，保证**原子性**地给锁设置**过期时间，防止死锁**，使用 LUA 脚本 `redis.call` 指令，保证 key 值判断与删除键指令原子性执行，且防止由于 STW 时间过长，锁被其他进程误删。

  - **缺点**：会出现由于**时钟漂移** 或者 任务执行时间过长，导致的锁被提前释放的问题。
- **基于 Redisson 实现**：它是一个 Redis 的客户端，其分布式锁的实现原理是，让获得锁的线程开启一个定时守护线程，每隔 expireTime / 3 的时间就去检查一下，该线程持有的锁是否还存在，如果存在，则对锁的过期时间重新设置为 expireTime，完成守护线程对**锁的续约**，防止锁由于过期提前释放。

  - **缺点**：这些只是在 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 是**异步复制**的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下，发生了故障转移，那么其他客户端上的线程依然可以获取到锁，丧失了锁的安全性。

- **基于 RedLock 算法实现**：红锁算法的原理是，

  1. 先获取当前时间 `t1`，然后按顺序依次尝试从 n 个 Redis 实例，使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁的失效时间 `expire`，还应该设置超时时间 `timeout`，且这个超时时间 **<** 锁的失效时间 `expire` ，这样可以避免 Redis 已经挂掉的情况下，客户端不用一直等待响应结果，而是尽快地去尝试另外一个 Redis 实例来获取锁。
  2. 客户端通过使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从过半数（N/2+1 个）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` **<** 锁失效时间 `expire` 时，锁才算获取成功，如果获取到了锁，那么 key 的真正有效时间 `real_expire` 等于锁失效时间 `expire` **减去**锁花费的总时间 `T`。
  3. 如果获取锁失败，客户端则应该在所有的 Redis 实例上使用 **Lua 脚本进行解锁**，原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端到服务器的通信是正常的，但反方向却是有问题的，虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功，因此，释放锁时，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起解锁请求。

  - **缺点**：
    1. **性能过重**：使用 RedLock 需要维护那么多的 Redis 实例，提升了系统的维护成本。
    2. **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生回调，则会导致它持有的锁提前过期释放，还是不能保证锁的安全性，这个是基于时间来实现自动释放的分布式锁，都无法解决的问题。

###### 3）基于分布式一致性算法实现 | 强一致

基于 ZK 实现：可以利用**顺序临时节点**的特性，结点在创建时，会自动在结点名后加一个数字后缀，以保证有序，同时，如果客户端连接失效，则还会立即删除结点，再利用 **watcher 监视器**的特性，注册某个结点的监视器，当节点状态发生改变时，watcher 被触发时，ZK 会向客户端发送一条通知。其分布式锁的实现原理是，

1. 创建一个锁目录 lock，希望获得锁的线程 A 在 lock 目录下，将创建**顺序临时结点**。
2. A 先获取锁目录下所有的子结点，判断是否存在序号比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则线程 A 获得锁。
3. 当另外一个线程 B 获取锁时，判断到 B 自己不是最小的结点，存在有更小的线程 A 结点，则设置  watcher 监听器，只监听比自己**次小**的结点 A。
4. 当线程 A 处理完业务后，会删除结点 A，释放掉分布式锁，然后线程 B 监听到节点状态变更事件后，判断自己已经是最小的结点了，则成功获得锁。

##### 3、总

以上就是我对分布式锁一些实现方案的理解，总结一下就是，

- **基于数据库实现**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：但这样会增加数据库的负担。
- **基于分布式缓存实现**：
  - **优点**：属于 AP 模型，性能高，实现起来较为方便，在允许偶发性的锁失效情况发生，不影响系统正常使用时，可以采用分布式缓存来实现锁。
  - **缺点**：通过过期时间实现的锁超时机制不是十分可靠，当业务必须要数据的**强一致性**，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下，就不能使用分布式缓存来实现锁了，此时可以使用 CP 模型来实现，比如 Zookeeper。
- **基于分布式一致性算法实现**：
  - **优点**：不依靠过期时间来释放锁，可靠性高，当系统要求高可靠性时，可以采用分布式一致性算法来实现锁。
  - **缺点**：性能比不上分布式缓存实现的锁，因为 ZK 需要频繁的创建和删除结点。

#### 1.2.1.5. Redis 数据结构？

##### 1、总

对于这个问题，我打算先介绍 Redis 对象 `RedisObject`，

1. 其数据结构包含一个 4 字节的 `type` 对象类型属性，分为 STRING、HASH、LIST、SET 和 ZSET。
2. 一个 4 字节的 `encoding` 对象编码属性，包括 INT、EMBSTR、RAW、HT、LINKEDLIST、ZIPLIST、INTSET 和 SKIPLIST。
3. 以及一个 `ptr` piont 指针，指向底层实现的数据结构。

然后我再按照上面所说的对象类型（String、Hash、List、Set、ZSet）按顺序进行介绍。

##### 2、分

###### 1）String

1. 首先是 String，常见的 API 有， SET、SET NX EX、GET、APPEND、STRLEN、SETRANGE、GETRANGE、MSET、MGET、INCRBY、DECRBY 等命令，适合存储帖子、评论、热点数据等缓存，其底层的数据结构分为 3 种编码，分别为 INT、EMBSTR 和 RAW：

2. **INT**：只能存储 long 类型的整数，`ptr` 指针指向对应的整数值。

   ![1631946982581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631946982581.png)

3. **EMBSTR**：（< 3.2 版本时）在字符串值小于等于 39 字节时会使用此编码，其优点是，它是对 `SDS` 的一个小优化，通过将 `RedisObject` 对象头和 `SDS` 存放在一起，采用**连续空间保存**，只需要一次内存分配，避免了它们各自进行空间分配，提高了字符串的内存分配效率，同时还可以减少内存碎片和 `ptr` 指针的占用，节约内存，提高空间的利用率。

   - `SDS`：是 Redis 自己实现一个字符串数据结构，通过持有 `len` 来标识字符串长度，`free` 来记录空闲字符的个数，`buf` 则指向真实的字符数组，能够在 O（1）内获取字符串长度，具有空间预分配、惰性释放内存，以减少分配次数的特点。

   - **缺点**：EMBSTR 是**只读**的形式，要修改时，只能转换为 RAW 编码，才能进行修改。

   ![1631878253168](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878253168.png)

4. **RAW**：（< 3.2 版本时）在字符串值大于 39 字节时会使用此编码，`ptr` 指针指向一个 `SDS` 数据结构，也就是以 `SDS` 的形式存储，主要为了解决长度计算和追击字符效率的问题。

   ![1631947051873](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631947051873.png)

###### 2）Hash

1. 然后就是 Hash，常见的 API 有，HSET、HGET、HEXSITS、HDEL、HLEN、 HSTRLEN、HINCRBY、HMSET、HMGET、HKEYS、HVALUES 等命令，适合存储结构化的对象数据，其底层的数据结构分为 ZIPLIST 和 HT。

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 HASH 取值时，可以通过**向后或者向前遍历**找到对应的键和值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631950146881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950146881.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631950298985](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950298985.png)

###### 3）List

1. 接着就是 List，常见的 API 有：LPUSH、LPOP、RPUSH、RPOP、LREM、LINSERT、LSET、LINDEX、LRANGE、LTRIM、BLPOP、BRPOP、RPOPLPUSH、BRPOPLPUSH，适合用作评论列表、商品列表、发布与订阅等功能，其底层的数据结构分为 ZIPLIST、LINKEDLIST 和 QUICKLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 LIST 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631952569099](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952569099.png)

3. **LINKEDLIST**：双向链表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，它是 Redis 自己实现的一条双向链表，包含头节点、尾结点、前驱和后继，可以很方便的进行向后或者向前遍历，同时持有 `len` 长度计数器，可以 O（1）内获取到 LIST 的长度 。

   - **缺点**：每个节点都有自己的前后指针，指针这部分所占用的内存较多，且每个节点是单独进行内存分配，当节点过多时，造成的内存碎片会比较多，影响内存管理的效率。

   ![1631952812216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952812216.png)

4. **QUICKLIST**：快速列表，大于 3.2 版本后，LIST 统一采用此格式进行存储，是 ZIPLIST 和 LINKEDLIST 的混合体，它将 LINKEDLIST 按段切分，每一段使用 ZIPLIST 来紧凑存储，多个 ZIPLIST 之间使用双向指针串接起来，缓解了 LINKEDLIST 指针内存浪费和内存碎片多的问题，同时解决 ZIPLIST 数据量过大时导致的性能变差问题。

   - **缺点**：ZIPLIST 节点太小的话（比如只存 1 个元素时），快速列表会退化成普通的链表，起不到应有的节省内存的作用，而 ZIPLIST 节点太大的话（比如只有一个 ZIPLIST 节点时），快速列表会退化成压缩列表，还是会出现数据量过大时导致的性能变差问题。
   - 因此，快速列表内部默认定义的单个 ZIPLIST 节点大小为 `8k 字节`，可以由参数 `list-max-ziplist-size` 来控制，其作用是，在分配结点时，如果发现当前 ZIPLIST 节点超过了这个大小，则会重新分配一个 ZIPLIST 节点。

   ![1631953074136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631953074136.png)

###### 4）Set

1. 再然后就是 Set，常见的 API 有：SADD、SPOP、SREM、SRANGMEMBER、SISMEMBER、SCARD、SMEMBERS、SINTER、SINTERSTORE、SUNION、SUNIONSTORE、SDIFF、SDIFFSTORE，适合用于求交集、并集、差集，比如朋友关系，其底层的数据结构分为 INTSET 和 HT 编码。 

2. **INTSET**：整数集合，（< 3.2 版本时）只存储 long 范围内的整数值，且在元素个数 < 512 个时会使用此编码，持有对应整数的编码类型 `encoding` 总是使用容纳数字的**最小编码进行存储**，以节约内存、集合元素数量 `length` 可以在 O（1） 内获取到对应长度、以及元素使用数组  `contents`  来进行**连续存储**，可以减少内存碎片和指针内存的占用，以节约内存。

   - **缺点**：编码类型只能升级不能降级，在大数字删除后，整数集合还是会使用大类型存储小数字，造成空间的浪费。

   ![1631954240528](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954240528.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631954355626](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954355626.png)

###### 5）ZSet

1. 最后就是 ZSet，常见的 API 有：ZADD、ZREM、ZSCORE、ZINCRBY、ZRNAGE（指定偏移，score 从小到大，分数相等，则再按值顺序排序）、 ZRERANGE（指定偏移，score 从大到小，分数相等，则再按值逆序排序）、ZRNAGEBYSOCRE（指定分数）、 ZRERANGEBYSOCRE（指定分数）、ZRANK、ZRERANK、ZCARD、ZCOUNT（区间个数统计） 等命令，可以在去重后进行排序，适合排名的场景，其底层的数据结构分为 ZIPLIST、SKIPLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 **128** 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 ZSet 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631954526032](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954526032.png)

3. **SKIPLIST**：（< 3.2 版本时）在元素大小大于等于 64 字节且元素个数大于等于 **128** 个时会使用此编码，由跳跃表 + 哈希表来实现，通过在有序链表上维护每级 25% 概率生成的索引，从而达到 O（logn）访问元素的目的，通过累加查找路径中的 `SPAN` 跨度，来计算当前节点所处的排名，通过哈希表存储跳跃表节点，以实现在 O（1）内完成根据名称找到对应的得分。

   - **缺点**：由于新节点插入的 LEVEL 是随机的，导致老节点的查找路径可能发生变化，**缓存友好性不如**红黑树，而红黑树则是插入新节点后，大部分老节点仍然处于原查找路径上。
   - **为什么 Redis#ZSet 使用跳跃表而不是红黑树**？
     1. **范围查找效率高**：
        1. 对于 `ZRANGE` 和 `ZREVRANGE` 命令的范围查找，如果使用哈希表，则只能做单值查找，不适合做范围查找。
        2. 如果使用红黑树，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]，效率低且实现复杂。
        3. 而使用 skiplilst 只需要 O（logn）定位头尾结点，然后遍历链表即可，简单又高效。
     2. **内存占用少**：Redis skiplist 索引的默认生成概率为 25%，即每个结点平均只包含 **1.33** 个指针，内存占用比红黑树的 2 个指针要少。
     3. **实现与调试容易**：使用 skiplist 比红黑树更容易实现与调试。

   ![1631955510770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955510770.png)

##### 3、总

以上就是我对 Redis 常用数据结构的一些理解，请问还有什么细节需要补充的吗？

#### 1.2.1.6. 提升技术的方法？

1. **看视频**：入门。
2. **做实验**：踩坑。
3. **看源码**：找答案。
4. **看书**：系统性总结。

#### 1.2.1.7. 技术不足的地方？

某些技术缺乏实际场景应用，久而久之细节就忘却了，以及有许多知识点学完了，但没做系统性整理，比如 ES、Docker、K8S 这些。

#### 2.1.1.1. 项目自我介绍？

##### 1、自我介绍

面试官你好，我叫姚超松，2019 毕业于广东工业大学，读的是电子信息工程专业，毕业秋招到了美的集团 - 美云智数事业部 - 供应链部门。

1. 首先是，推广 SRM 到比亚迪，我主要是负责交付单模块的全栈开发，以及造过一些轮子，比如：
   - 1）一是，分片上传文件，实现广告类交付单视频材料的断点续传。
   - 2）二是，对接一个邮件队列，实现异步邮件的投递。
   - 3）三是，为团队搭建了一个代码发布平台，中间还解决过 CPU 占比 95% 的问题。
2. 第二块是，SASS 产品的研发，前期主要是负责品质云的业务开发，后期用了 SpringCloud 拆分出 4 个微服务，来降低负载、提高系统可用性，除了这些，中间印象比较深的还有：
   - 1）一是，通过 SQL 调优，提效条码出库接口 96%，解决超时的问题。
   - 2）二是，通过细节的对比，定位出 BUG 并解决，然后用分布式锁，做单点定时的方式兜底，紧急解决了成品出货不了，导致仓库堆积的问题。
3. 第三块是，集团的 GSRM 研发，这个系统是在 19 年从 EBS 给重构过来的，拆了 20 几个微服务，数据库分了 8 主 8 从，某些表又做了水平的拆分，我主要做了几件事：
   - 1）一是，采用线程池并发方式查询，结合 Redis 缓存热点数据、异步收集接口日志，提效给 PLM 提供的配套接口 52%，最后压测可以顶住单机 2500 左右的并发。
   - 2）二是，用 Kafka 解耦，实现分片广播式定时，用比如责任链、享元等设计模式组织代码，高效、优雅地生成供应商画像，使得生成时间从 3 h 32 min，降低到只要 8 min 18 s。
   - 3）还有就是实际生产过程中，碰到的几类事故问题的解决，比如线程池调优、数据库死锁分析、内存溢出调优这些。

=> 以上，就是我的一些资料，请问有什么细节需要补充吗？

##### 2、项目细节

###### 1）GSRMC

1. **微服务模块**：

   | 模块名 | 模块业务 | 备注                                                         |
   | ------ | -------- | ------------------------------------------------------------ |
   | BASE   | 基础数据 | 字典、物料、采购分类、研发分类等主数据                       |
   | POS    | 生命周期 | 寻源、资质审查、现场评审、供方生效、信息变更、黑名单管理、质保金管理、供方退出、失效等供应商主数据 |
   | PERF   | 考核绩效 | 供方送货不合格、交期、品质、服务考核 -> 考核会影响绩效（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | QUO    | 比例管理 | 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | BID    | 集采招标 | BID 招标定价，给物料定价 -> 一揽子价格                       |
   | PRICE  | 价格管理 | 生效之后，研发工程师在 PLM 分解POM，核价员估价，给定价做参考、线下定价以及BID 招标定价，给物料定价 -> 一揽子价格 |
   | CON    | 电子合同 | 电子合同模块，签署框架协议，合作时要遵守的规则               |
   | -      | -        | 还有ESB 交易数据、JOBS/TASK 定时任务、MIP 审批流程、SYNC 数据同步、INDEX 指标工作台等非核心业务模块 |

2. **主要业务流程**：

   1. 研发工程师在 PLM 根据业务，创建新物料 ITEM，跟 SRM 的采购分类进行关联。
   2. 然后选定采购分类和需求图纸等信息，在供应商库中做**寻源匹配**。
   3. 寻源完毕后，送样到供应商 GSC 进行初步**估价**。
   4. 然后 SRM 根据**资质**和价格进行筛选。
   5. 筛选通过后，PLM 进行试用，SRM 对供应商生产环境进行**现场评审**。
   6. 评审通过后生成供应商品类 ASL，此后就可以按照比例进行批量供货了。
   7. 其中， SRM 可以对供方送货不合格、交期、品质、服务等进行考核 -> 考核会影响**绩效**（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配**比例**（也叫配额） -> ERP根据比例决定供货数量。
   8. 送货完毕后，SRM 需要对品类进行**核价**，包括招标转定价、意向价、直接定价、线下议价等方式。
   9. 最后走价格审批，把价格同步到 ERP，每月 25 号对上个月进行结算。

   => 总的来说，SRM 就是负责供应商从生到死的生命周期管理，以及物料价格和供货数量管理，也就是寻源到生效、需求到生产、定价到付款三个方向的业务。

3. **主要用到的技术组件**：

   | 组件                    | 作用                                                         | 部署           |
   | ----------------------- | ------------------------------------------------------------ | -------------- |
   | Vue + I-View            | 前端                                                         | 8 Apache       |
   |                         | 负载均衡                                                     | F5、Nginx      |
   | SpringCloud             | Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Zipkin 做链路追踪，Config 做配置中心、Stream+Bus 做消息驱动 | 126 应用服务器 |
   | Sharding JDBC + MyBatis | Sharding JDBC 分表，MyBatis ORM 映射                         | 126 应用服务器 |
   | MySQL                   | 数据库                                                       | 8 主 8 从      |
   | MongoDB                 | 文档数据库                                                   | 3 主备         |
   | Redis、Redisson         | 缓存中间件                                                   | 3 主备 + 哨兵  |
   | Kafka、ZK               | 消息中间件                                                   | 3 集群架构     |

4. **分表与分片规则的设置**：

   | 分表                   | 数据量     | 表注释             | 数据库 | 分片规则               |
   | ---------------------- | ---------- | ------------------ | ------ | ---------------------- |
   | srm_sys_items_submeter | 3280.19 w+ | 物料表             | BASE   | ${organization_code}   |
   | srm_sys_item_cates_sub | 1613.38 w+ | 物料采购分类关系表 | BASE   | ${organization_code}   |
   | srm_sys_item_keycs     | 2153.11w+  | 物料研发分类关系表 | BASE   | ${organization_code}   |
   | srm_po_receive_det     | 3.0813 E+  | 采购接收表         | PRICE  | ${period_month / year} |
   | srm_po_line_locations  | 1.0220 E+  | 一揽子价格表       | PRICE  | ${bu_code}             |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 126 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块           | 数量              | CPU           | 内存               | 硬盘  |
   | -------------- | ----------------- | ------------- | ------------------ | ----- |
   | 前端 Apache    | 8                 | 4 C           | 16 G               | 50 G  |
   | Eureka         | 3                 | 1 C           | 1 G                | 10 G  |
   | BASE           | 13                | 8 C           | 16 G               | 100 G |
   | POS            | 19                | 8 C           | 16 G               | 100 G |
   | PERF           | 7                 | 8 C           | 16 G               | 100 G |
   | QUO            | 6                 | 8 C           | 16 G               | 100 G |
   | BID            | 3                 | 8 C           | 16 G               | 100 G |
   | PRICE          | 13                | 8 C           | 16 G               | 100 G |
   | CON            | 6                 | 8 C           | 16 G               | 100 G |
   | ESB            | 5                 | 8 C           | 16 G               | 100 G |
   | JOBS           | 9                 | 8 C           | 16 G               | 100 G |
   | TASK           | 5                 | 8 C           | 16 G               | 100 G |
   | MIP            | 4                 | 8 C           | 16 G               | 100 G |
   | SYNC           | 5                 | 8 C           | 16 G               | 100 G |
   | INDEX          | 3                 | 8 C           | 16 G               | 100 G |
   | 其他模块       | 25                | 8 C           | 16 G               | 100 G |
   | MySQL          | 16（8 主 8 从）   | 32 C          | 128 G              | 3 T   |
   | MongoDB        | 3                 | 8 C           | 16 G               | 500 G |
   | Redis          | 3                 | 8 C           | 32 G               | 100 G |
   | Kafka          | 3                 | 8 C           | 16 G               | 100 G |
   | 报表导出 OSS   | 文件数： 500 / 天 | 数据量：10 G  | 增长量：300 M / 天 | -     |
   | 供应商附件 OSS | 文件数：10 w / 年 | 数据量：200 G | 增长量：200 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

   `gc.log`：

   ![1648004562016](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648004562016.png)

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

###### 2）云化项目

1. **微服务模块**：（品质云）

   | 模块名 | 模块业务     | 备注                                                |
   | ------ | ------------ | --------------------------------------------------- |
   | BASE   | 基础数据模块 | 字典、IDM 用户、权限、系统附件、企业、客户、组织等  |
   | OEM    | 代工生产模块 | OEM 供方成品下线、抽检、出库等                      |
   | APP    | 综合模块     | SPC 过程检验，PQC  半成品检验、OQC 成品出货检验等   |
   | JOBS   | 定时任务模块 | 包括数据中台、PSI、QMS、GSC、GSRM、MES 等的数据同步 |

2. **品质云主要业务流程**：

   1. 供方原材料上线，MES 进行来料检测后，会走到各制程工序。
   2. 在每个制程工序的 CTQ 品质关键点上，会进行相应的 SPC 过程检验。
   3. 然后，还在工序的检验岗位上，进行对应的 PQC 半成品检验。
   4. 最后，在成品准备入库出货前，则进行 OQC 成品出货检验。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，还需要进行对应的彩箱、大箱、地台板条码的绑定操作后，才能进行后面的入库出货操作。

   => 总的来说，品质云就是实时管控供方生产的**品质质量**。

3. **进销存云主要业务流程**：

   1. 接收到 GSC 供应商门户 的采购订单，就在进销存为供方生成对应的销售订单。
   2. 然后根据物料 BOM 信息，生成后续的生产订单。
   3. 在生产前，获取原材料时，可以直接在原材料仓进行扣减，也可以发起原材料的采购订单，进行补充原材料。
   4. 在生产完工后，会创建生产入库单，把成品送入成品仓，更新供方成品库存。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，品质会把彩箱、大箱条码传入进销存，进销存再做对应的地台板绑定、销售出库、以及推送物流平台。

   => 总的来说，进销存就是用来实时管控供方的**库存情况**。

4. **数据中台主要业务流程**：数据中台，主要承担物料、ASL、寻源品质进销存的一些统计工作。

5. **主要用到的技术组件**：

   | 组件             | 作用                                                         | 部署         |
   | ---------------- | ------------------------------------------------------------ | ------------ |
   | Vue + Element UI | 前端                                                         | 8 Nginx      |
   |                  | 负载均衡                                                     | F5、Nginx    |
   | SpringCloud      | 微服务拆分后，Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Skywalking+ELK 做链路追踪，Config 做配置中心，Gateway 做服务网关 | 应用服务器   |
   | SpringBoot       | 微服务拆分前，还是单体应用                                   | 3 应用服务器 |
   | MyBatis          | MyBatis ORM 映射                                             | 3 应用服务器 |
   | MySQL            | 数据库                                                       | 1主          |
   | Redis、Jedis     | 缓存中间件                                                   | 3 主 3从集群 |

6. **表数据量**：

   | 分表                        | 数据量    | 表注释         | 系统 | 分片规则               |
   | --------------------------- | --------- | -------------- | ---- | ---------------------- |
   | qc_oem_order_line           | 1200 w+   | 成品下线表     | QC   | 手工按日期分片备份旧表 |
   | qc_oqc_item_standard_value  | 1500 w+   | 物料抽检标准表 | QC   | 手工按日期分片备份旧表 |
   | oem_external_mes_colorcode  | 722.26 w+ | MES 条码表     | QC   | 无分片                 |
   | psi_base_packing_relation   | 315.28 w+ | 箱包关系表     | PSI  | 无分片                 |
   | psi_prd_pallet_box_relation | 250.03 w+ | 板箱关系表     | PSI  | 无分片                 |
   | psi_base_barcode            | 314.67 w+ | 下线条码表     | PSI  | 无分片                 |
   | psi_sales_stock_out         | 840.58 w+ | 销售出库表     | PSI  | 无分片                 |
   | cloud_gsrm_item             | 38.61 w+  | 物料表         | DC   | 无分片                 |
   | cloud_gsrm_asl              | 31.63 w+  | ASL 物料表     | DC   | 无分片                 |
   | mcc_company_info            | 1321      | 企业统计表     | DC   | 无分片                 |
   | mcc_deliver_receive_sum     | 2.24 w+   | 企业下线出库表 | DC   | 无分片                 |
   | mcc_order_quotation_sum     | 342       | 企业寻源报价表 | DC   | 无分片                 |

7. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 14 个服务。
   - **数据库**：监控显示，16 C、64 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 3                | 4 C          | 16 G              | 50 G  |
   | Eureka           | 3                | 1 C          | 1 G               | 10 G  |
   | BASE             | 3                | 8 C          | 16 G              | 100 G |
   | APP              | 3                | 8 C          | 16 G              | 100 G |
   | OEM              | 3                | 8 C          | 16 G              | 100 G |
   | JOBS             | 2                | 8 C          | 16 G              | 100 G |
   | MySQL            | 1 主             | 16 C         | 64 G              | 3 T   |
   | Redis            | 6                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

8. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

###### 3）比亚迪 SRM

1. **微服务模块**：

   | 模块名 | 模块业务       | 备注               |
   | ------ | -------------- | ------------------ |
   | APP    | 前端控制器模块 | Controller，6 台   |
   | MID    | 业务处理模块   | Service，7 台      |
   | RPORT  | 报表模块       | 报表导出，6 台     |
   | NGINX  | 前端模块       | WEX5、Jquery，2 台 |

2. **主要业务流程**：

   1. 定时同步云平台 SAP 需要的基础信息，比如采购订单、采购金额、采购数量等到 SRM，按照履行模板和规则，生成相应的履行计划和付款计划。
   2. 通过履行计划触发，生成交付、验收、结算对应节点的订单与待办信息，通知对应的责任人进行审批或者验收。
   3. 通过迁移线下交付单到线上，完成各类的无纸化交付，交付单审批通过后，会推进下一个节点的履行计划和付款计划。
   4. 通过付款计划触发，生成发货款、到货款、调试款、验收款、上线款、完工款等多种款项的待办，通知对应的责任人进行审批或者结算。

   => 总的来说，就是通过交付单推进履行计划和付款计划，来数字化线下供方结算与付款流程。

3. **主要用到的技术组件**：

   | 组件                | 作用             | 部署          |
   | ------------------- | ---------------- | ------------- |
   | JQuery + Element UI | 前端             | 2 Nginx       |
   |                     | 负载均衡         | 2 Nginx       |
   | Spring MVC + Tomcat | 后端应用         | 19 应用服务器 |
   | MyBatis             | MyBatis ORM 映射 | 19 应用服务器 |
   | Oracle              | 数据库           | 1 主          |
   | Redis、Jedis        | 缓存中间件       | 3 主备 + 哨兵 |
   | RabbitMQ            | 消息中间件       | 3 镜像集群    |

4. **表数据量**：

   | 分表          | 数据量     | 表注释              | 系统   | 分片规则 |
   | ------------- | ---------- | ------------------- | ------ | -------- |
   | SAP_CDHDR     | 6.39 E+    | PO 单增量表         | 云平台 | 无需分片 |
   | SAP_EKPO      | 4019.80 w+ | PO 行表             | 云平台 | 无需分片 |
   | SAP_ZMMSSBM03 | 1544.27 w+ | PO 描述表           | 云平台 | 无需分片 |
   | SAP_EKKO      | 1147.68 w+ | PO 币种表           | 云平台 | 无需分片 |
   | SAP_ZEKKO     | 965.70 w+  | PO 寻源表           | 云平台 | 无需分片 |
   | PR / PO       | 1948.13 w+ | 采购需求 / 采购订单 | SRM    | 无需分片 |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 21 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 2                | 4 C          | 16 G              | 50 G  |
   | APP              | 6                | 8 C          | 16 G              | 100 G |
   | MID              | 7                | 8 C          | 16 G              | 100 G |
   | RPORT            | 6                | 8 C          | 16 G              | 100 G |
   | Oracle           | 1                | 32 C         | 128 G             | 3 T   |
   | Redis            | 3                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

##### 3、项目亮点

| 系统       | 亮点清单          | 关键词                                                       |
| ---------- | ----------------- | ------------------------------------------------------------ |
| GSRMC      | PLM 配套接口      | Around 切面注解、Kafka + MongoDB 、MD5  + AES、多线程 + Future、Redis、Jmeter |
|            | 供应商画像同步    | 缓存型线程池、工厂 + 建造者 + 责任链、EsJob + Kafka + MongoDB、线程池调优 |
|            | 线程池调优        | 线程池源码、调优原则                                         |
|            | 死锁问题排查      | 意向锁、间隙锁、可重复读、并发                               |
|            | 内存溢出排查      | MAT、POI、ArrayList                                          |
| Sass 产品  | 条码销售出库      | Druid 监控、SQL 调优、Redis                                  |
|            | 品质云微服务拆分  | SpringCloud                                                  |
|            | 校验失败问题      | 分布式锁、QMS Client Json 对比、问题排查                     |
| 比亚迪 SRM | 大文件上传        | FastDFS、Redis List                                          |
|            | 邮件发送组件      | 线程池 + RabbitMQ + 定时任务                                 |
|            | 发版平台 CPU 过高 | Tomcat Manager、ELK、CPU 95%                                 |

STAR 法则，是情境（Situation）、任务（Task）、行动（Action）、结果（Result）四项的缩写，是一种讲述自己故事的方式，或者说，是一个清晰、条理的作文模板，合理熟练运用该法则，可以轻松的描述事情的逻辑方式，表现出分析与问题的逻辑性、条理性和逻辑性。

1. Situation：情境，本次事件是在什么情况下发生的。
2. Task：任务，在本次事件中，主要负责什么任务。
3. Action：行动，在本次事件中，针对这些情况的分析，采用了什么样的行动。
4. Result：结果，本次事件最后的结果是怎么样的，以及学到了什么。

| 举例 | 内容（大一辩论比赛获得冠军）                                 |
| ---- | ------------------------------------------------------------ |
| S    | 系里一共有 5 支队伍，实例...，我们小组...                    |
| T    | 熟悉辩论流程，掌握辩论技巧，获得系冠军                       |
| A    | 自己主动整理资料，组织小组学习流程，编制训练题，小组训练，根据每个人的特点，分配任务（要尽量详细，包括当中遇到的困难是什么，怎么解决的） |
| R    | 获得系辩论赛冠军                                             |

###### 1）PLM 配套接口 | 分表、并发、Redis

1. **背景 Situation**：供应链体系管理专员反馈，他们在 PLM 建送样申请单时，由于物料配套没有**自动匹配**，导致经常选错配套人员，然后就要撤回、修改、重新提交，影响业务流程效率。

2. **任务 Task**：所以他们希望在 PLM 上，根据物料就可以**自动匹配** SRM 品类分工中的**配套专员信息**，方便他们走业务流程。

3. **行动 Action**：

   1. 接口的实现逻辑大体是这样的，根据 ITEM_CODE + ORG_CODE 找对应分表的采购分类，找不到就根据 ITEM_CODE 找全部库存组织分表的采购分类，再找不到的话就认为要去查物料试用表了，以当前作为试用 P 编码找到对应转正后的编码，然后重走一遍上面逻辑，找到后就合并按照 BU_CODE + 特征名称 + 特征值 + 研发分类 ID，查找研发分类中的采购分类，然后根据采购分类查找品类分工表中的配套人员信息，去重后返回即可。

      ![1644903196224](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644903196224.png)

   2. 接口实现比较复杂，其中需要优化的点有：

      - 1）第一，接口日志要做统一的收集。
      - 2）第二，接口要做安全性校验。
      - 3）第三，接口要查询所有的库存组织的采购分类分表。
      - 4）第四，接口需要频繁按照 ORG_CODE 查找 BU_CODE。

4. **结果 Result**：所以我当时优化的手段就是：

   - 1）第一，写了一个 Around 类型的切面注解，对公共的日志收集逻辑进行了提取，然后把收集到的日志投递到 Kafka 中，再由消费者插入到 MongoDB，这种做法的好处是，使得日志收集逻辑解耦了业务代码，同时异步收集的话经过测试，对比同步插入还有一定的性能提升。
   - 2）第二，安全性校验这边统一采用的是 MD5 对整个请求体生成摘要，SRM 需要重新生成一遍，然后与传过来的比对是否一致，一致才认为请求体没被修改过，然后再根据缓存中的 AES 秘钥进行解密，得到真正的请求 JSON 串。
   - 3）第三，使用线程池多线程并发的方式，查询每个采购分类分表，通过 FutureTask 监听汇总所有的采购分类编码，对比串行查询有一定的性能提升。
   - 4）第四，由于 ORG_CODE 与 BU_CODE 是那些不怎么会改变的数据，所以通过使用了 Redis 对这些关系进行了远端缓存（使用 Guava Cache 重启可能会导致缓存雪崩，且数据量过大还会占用应用内存，本身也才 2 G，所以放 Redis 中，虽然增多了一次 I/O 这也是可以接受的），使得多次请求只会获取一次库存事业部关系，对比批量查询时有一定的性能提升。 

###### 2）供应商画像同步 | 架构、设计模式、Kafka

1. **背景 Situation**：
   1. 业务方需要一个页面，可观地展示出供应商各维度的一个画像，包括抬头展示它的**基本信息**，词云浓缩它的**肖像标签**，动画展示它自美的引入以后所走的一些**历程**，对接天眼查展示对应它的一些企业经营风险，柱状图展示它历年的**招投标**、**红黄牌**以及**采购金额**的数量，折线图展示它历年的**考核**和**绩效**的趋势，饼图展示它的**分级**和**供货编码**的占比情况，用来横向、纵向辅助对比找出优质供方。
   2. 允许数据延迟，可以每隔 15 天同步一次。
2. **任务 Task**：这样，要做的东西就有，在 TASK 模块的定时任务触发时，要一一查找每家供应商的 POS 供方生命周期库的基本信息、红黄牌、获奖以及供货编码信息，查找 BID 招标库的历年招标信息，查找 PERF 考核绩效库的历年考核、绩效以及分级信息，查找 PRICE 价格库的采购金额信息，对接天眼查找告警风险，最后再根据规则组装出要展示的肖像标签。
3. **行动 Action**：当时有几种方案，
   - 1）第一种就是，1 个定时器，负责同步所有供应商的上述所有维度的信息，优点是实现简单，不用做其他的架构设计，缺点是如果同步实现的话一个事务完成所有工作，任意一处异常则全局回滚，如果异步实现的话，由于是单点触发定时任务，还是会有单台机器负担过重的问题。
   - 2）第二种就是，10 个定时器，每个定时器只负责同步所有供应商的某个维度的信息，优点是可以分为 10 台机器分别触发定时，避免了单台机器负担过重，缺点是一个定时器一个事务，还是会出现任意一处一处则全局回滚，以及定时器过多，管理麻烦。
   - 3）第三种就是，1 个定时器 + 分布式消费，定时器只负责找出要生成画像的供应商编码，封装成消息，扔到 Kafka 上，自己不负责画像的生成，而是交给消费者去进行处理，消费者每次消费一个消息，相当于生成一个供应商的画像，这样做的好处就是，定时逻辑和画像生成逻辑解耦，1 个定时器即可完成任务，要管理维护的地方少，然后就是，画像生成的效率取决于 Partition 和机器的数量，能够充分利用集群多实例部署的优点，还有就是，即使某次供应商画像生成失败了，可以不进行手工 ACK，下次再从 Kafka 里拿消息出来进行重复消费即可。
4. **结果 Result**：所以，当时就采用了第三种方案，在实现时又有几个优化点：
   - 1）第一就是，还是没能解决由于一个供应商所有维度处于同一个事务，出现异常时的全局回滚问题，解决方案就是，通过线程池的方式异步实现，每个线程一个事务，只完成一个维度的信息同步，这样即使某个回滚了也不影响全局。
   - 2）第二就是，由于一共有 10 个维度的信息要同步，就需要 10 个 Callable 任务给线程去执行，所以就抽象了公共的接口。
   - 3）第三就是，由于任务较多，所以就采用了工厂 + 建造者 + 责任链来串联式地组织任务，而且到了后期，由于是责任链的组织方式，就可以根据业务组合出很多种画像的同步方案出来，体现了灵活性。
   - 4）第四就是，由于任务与任务间，经常有重复的信息要查询，所以就对这个接口分为了同步式实现和异步式实现的抽象类，业务只需要继承抽象类实现对应的业务即可，同步式实现主要是为了在一开始给执行链设置公共上下文，避免重复查询，异步式实现则是交给线程池去执行，在要拿那些”重复“信息时只需要去上下文中获取即可。
   - 5）第五就是，某次消费异常，也就是执行链中某个节点异常，其堆栈信息需要对其进行合理记录，方便后面排查问题，解决方案就是，通过如果有任务异常后，那么就收集放到执行链上下文中，返回时再统一地打包成对象，存放到 MongoDB 上。
   - 6）最后，这样设计和实现，用 Kafka + 线程池，保证了分布式高性能消费，用 Kafka + 异常时不手工 ACK 来重复生成画像，保证可靠性，用 MongoDB 记录异常日志，保证异常排查的便捷性。

###### 3）线程池调优 | 线程池、源码、调优

1. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
2. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
3. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
4. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
5. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。

###### 4）死锁问题排查 | 间隙锁、可重复读、并发

1. **背景 Situation**：在现场评审优化了一版上线后，DBA 反馈说，POS 数据库因为有大量死锁，导致数据库不断地重启，并且也把问题的 SQL 给发了出来，是一条删除语句导致的：

   ```sql
   DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3;
   ```

2. **任务 Task**：然后我们很快就定位到代码，找到了以下逻辑：方法传入一个 `List<DTO>`，先是获取第一行的  locale_review_id `${localeReviewId}`，对满足 locale_review_id= `${localeReviewId}` 的都进行删除，完成删除后，再批量插入 locale_review_id= `${localeReviewId}` 的 `List<DTO>` 数据：

   ```java
   int flag=0;
   Long localeReviewId=new Long("1");
   for (AuditEvidenceDto auditEvidenceDto : list) {
       if (auditEvidenceDto.getEvidenceId()!=null){
           flag=1;
           localeReviewId=auditEvidenceDto.getLocaleReviewId();
       }
   }
   HashMap<String,Object>params =new HashMap<>();
   if (flag==1){
       params.put("localeReviewId",localeReviewId);
       params.put("categoryCode",list.get(0).getCategoryCode());
       params.put("reviewType",list.get(0).getReviewType());
       auditEvidenceService.deleteFlag(params);
   }
   if(!"Y".equals(list.get(0).getAttribute1())){
       list.sort(Comparator.comparing(AuditEvidenceDto::getFileType));
       auditEvidenceService.batchInsertAuditEvidence(list);
   
   }
   ```

3. **行动 Action**：

   1. 对于这种写法，首先，在代码里做业务逻辑操作，肯定是不对的，当时事态紧急，也没有做过多的分析，最直接的解决思路就是，找到对应的同事，让他把 Controller  `delete` 和 `insert` 操作都放入一个 Service 中，用同一个事务管理，做一个紧急发版看下能否解决。

   2. 发了新版后，好像问题是解决了，但是结合 `show engine innodb status`，就分析出在并发场景下，还是会死锁的问题，步骤是：

      1. 先在表中先插入几条数据，然后给 locale_review_id 加普通索引（而在表全新，且没有数据时，有没有索引都会加一个行 X 锁，然后也会出现下面的情况）。
      2. 然后，事务 1 对 locale_review_id=3 的记录进行删除，则会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁。
      3. 同理，事务 2 再对 locale_review_id=3 的记录进行删除，也会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁，由于间隙锁不冲突，所以事务 2 不会等待。
      4. 接着，事务 1 再插入  locale_review_id=3 的记录时，由于已经存在事务 2 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
         - 在插入行之前，会设置一种称为**插入意图的间隙锁**，表示插入的意图，即如果插入到同一索引间隙中的多个事务未插入到间隙内的同一位置，则它们无需相互等待，是不冲突的。
         - 而如果发生重复键错误，则会在重复索引记录上设置**共享锁**，并且如果另一个会话已经拥有排他锁，那么如果有多个会话尝试插入同一行，则使用共享锁可能会导致**死锁**，比如说后面分析的那种情况。
      5. 同理，事务 2 再插入  locale_review_id=3 的记录时，由于已经存在事务 1 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
      6. 此时，就发生了死锁，即事务 1 持有间隙锁，同时等待事务 2 的间隙锁，事务 2 也持有间隙锁，同时等待事务 1 的间隙锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 2 的事务，让事务 1 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      ```sql
      -- 使得 show engine innodb status; 能展示锁的信息
      set GLOBAL innodb_status_output_locks=ON;
      -- 查看事务锁持有情况
      show engine innodb status;
      ```

      | 步骤 | 事务 1                                                       | 事务 2                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |
      | 3    |                                                              | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |
      | 4    | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 5    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); |
      | 6    |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    | 插入成功                                                     |                                                              |

   3. 所以，这种方案也不是万全之策，然后我们重新考虑新的方案，其思路是打算先把一开始的死锁给复现出来，再做解决方案的分析。

   4. 不久后，场景就被模拟出来了，那是 `delete` + `insert` 在不同事务中导致死锁的发生，具体的步骤是：

      1. 事务 1 执行删除，但未提交，由于 locale_review_id=3 的记录已经存在，所以在 locale_review_id=3 行上了排他锁，此时该行的主键 ID 也是等于 3，即 ID=3。
      2. 然后，事务 2 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 2 进入等待。
      3. 同理，事务 3 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 3 也进入等待。
      4. 接着，事务 1 提交，ID=3 的行记录被标记为删除状态（这些标识为删除状态的记录，会后续由后台的 Purge 操作进行物理删除，但是，此时还是会在索引中存放一段时间），ID=3 上的排他锁被释放。
      5. 然后，事务 2、3 就成功抢到了共享锁，打算执行插入操作，由于已经存在事务 3 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 2 进入等待。
      6. 同理，由于已经存在事务 2 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 3 也进入等待。
      7. 此时，就发生了死锁，即事务 2 持有共享锁，同时等待事务 3 的共享锁，事务 3 也持有共享锁，同时等待事务 2 的共享锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 3 的事务，让事务 2 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      | 步骤 | 事务 1                                                       | 事务 2                                                       | 事务 3                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; TRANSACTION;                             | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |                                                              |
      | 3    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 4    |                                                              |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |
      | 5    | COMMIT;                                                      |                                                              |                                                              |
      | 6    |                                                              |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    |                                                              | 插入成功                                                     |                                                              |

   5. 面对以上的分析情况，解决方案有两个，第一个方案是，在后面批量插入前，先把 ID 给置为 NULL，利用自增机制去设置 ID，避免两个 `insert` 语句同时插入同一个位置，但问题是，`delete` 在释放排他锁后，两个 `insert` 语句都会执行成功，会比正确结果多出来一条记录，所以此方案放弃。

   6. 第二个方案是，把 `delete` + `insert` 的操作，转换为 `update` 操作，则可以避免上述死锁的发生，通过。

4. **结果 Result**：最后我们就是通过第二个方案，把这段有问题的代码，又重新优化了一遍，解决了这种死锁的问题。

###### 5）内存溢出排查 | MAT、POI、ArrayList

1. **背景 Situation**：生产的一台 POS 服务器宕机了，由于配置了 `-XX:+HeapDumpOnOutOfMemoryError`，所以崩溃时导出了对应的 hprof 文件。

2. **任务 Task**：导入 hprof 到 MAT，分析应用崩溃的原因。 

3. **行动 Action**：

   1. MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，一个 Tomcat 的线程使用了 78.58% 的堆大小，共 1.2 GB。

      ![1646412309344](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646412309344.png)

      ![1646413204478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413204478.png)

   2. 然后，查看 List Objects -> with outgoing references，观察一个占据了 22.68% 内存的 ArrayList 的保留集，发现它引用了 27.69 w 个元素，估计是某个 SQL 查了太多元素导致。

      ![1646413486175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413486175.png)

   3. 所以，就继续查看堆栈信息，定位问题代码，是一个 Service 实现类的 `setData()` 方法。

      ![1646413368891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413368891.png)

   4. 原来，是调用了 Controller 的 `downloadItemDailyCapacityTemplate()` 方法，看了下业务含义，大概的意思是，在导出日常产能预测模板时，由于把产能表每日信息的查询结果，放入到了上面所说的那个 27.69 w 个元素的 ArrayList 中，然后再遍历这个列表，调用 POI#API 在内存中生成 excel，但由于堆内存只配置了 `-Xmx=2048m`，所以导致了内存溢出！

      ![1646413877943](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413877943.png)

4. **结果 Result**：因此，解决方案是，持有这么大的 ArrayList 时，不应该把 excel 还写入内存中，而是遍历过程中，先把 excel 一点一点写入到磁盘，释放掉这个 ArrayList 后，再读取磁盘的 excel 文件的字节流，写入到 response 输出流中，或者直接扩大堆内存大小 `-Xmx=4096m `，从而解决堆内存溢出的问题。 

###### 6）自研 @DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源

1. **背景 Situation**：生产 JOBS 模块，采购金额汇总导出接口报错：同一线程不允许切换数据源读写类型，定位到报错的代码位置，发生在 `@DataSource` 自研注解，的管理器 `DataSourceClusterManager` 中的一个段逻辑代码上：

   ```java
   private static final ThreadLocal<DataSourceThreadInfo> dataNodeInfo = new ThreadLocal();
   
   public static void set(String nodeName, boolean readOnly) {
       if (StringUtils.isBlank(nodeName)) {
           nodeName = getDefaultNode();
           if (StringUtils.isBlank(nodeName)) {
               throw new RuntimeException("系统未配置缺省数据节点");
           }
       }
   
       DataSourceThreadInfo nodeInfo = (DataSourceThreadInfo)dataNodeInfo.get();
       if (nodeInfo != null) {
           if (!StringUtils.equals(nodeName, nodeInfo.getNodeName())) {
               throw new RuntimeException("同一线程不允许切换数据源");
           } else if (readOnly != nodeInfo.isReadOnly()) {
               throw new RuntimeException("同一线程不允许切换数据源读写类型");
           }
       } else {
           dataNodeInfo.set(new DataSourceThreadInfo(nodeName, readOnly));
       }
   }
   ```

2. **任务 Task**：分析逻辑代码就可以知道，是因为在设置注解属性 `readOnly` 时，发现和已有的 `readOnly` 不等，比如 `true != false`，然后就想到是存储这些属性的 `ThreadLocal` 变量，在上一次使用完的线程，没清除掉这些变量，就被下一个接口复用了，从而导致的问题发生，经过各种实验，也证明了确实是这个原因。

3. **行动 Action**：

   1. 至于问题的解决，首先还是看发生问题的业务代码，它把一些查询封装成了 Lambda 表达式，然后调用了数据源切换工具类的方法，丢给线程池去执行。

   2. 问题就在于这个 Lambda 表达式中，比如先调用 `DataSourceThreadInfo.set("srmpos"，true)`，然后调用 mapper 接口查询数据库，最后在却没有在释放掉线程本地变量，导致另一个接口复用这个线程时设置 `DataSourceThreadInfo.set("srmpos"，false)` 报错。

   3. 然后，查找了整个系统这些问题代码，发现很多都没作释放的，此时最好的方案要么是 AOP，要么是代理。

   4. AOP 的话，由于没有很好的一个切点表达式，因为如果只找那些打了 `@DataSource` 注解的 service 或者 mapper，那么就会漏掉一些直接 `DataSourceThreadInfo.set(..)` 设置的，这也正是为什么之前配了 `DataSourceAfterAspect` 切面，还是会发生这个问题的原因所在，所以这个方案放弃。

      ```java
      @Aspect
      @Component
      @Order(0)
      public class DataSourceAfterAspect {
          /**
           * 数据源处理完后清理
           * @param joinPoint
           */
         @After("@within(com.midea.mcomponent.mybatisplus.datasource.DataSource) || @annotation(com.midea.mcomponent.mybatisplus.datasource.DataSource)")
          public void after(JoinPoint joinPoint) {
              DataSourceClusterManager.clean();
          }
      }
      ```

   5. 代理的话，可以在切换工具类的 `queryMethod.query(params)` 方法调用后，通过在 `finally` 中实现线程本地变量的释放。

      ```java
      //  baseNode 数据源 线程池
      public static <V> Future<V> executeSrmBaseQuery(QueryMethod<V> queryMethod, Object... params) {
          return executeSrmBase.submit(() -> {
              try {
                  return queryMethod.query(params);
              } finally {
                  DataSourceClusterManager.clean();
              }
          });
      }
      ```

4. **结果 Result**：最终，发版测试，没问题后上线，最终解决问题。

###### 7）条码销售出库 | 索引调优、生产问题

1. **背景 Situation**：OEM 供应商反馈，系统响应扫码速度过慢，专门用手机计时，记录延迟有 4.55 s，扫码枪扫完一整板的货，系统才开始对异常条码报错，导致如果一板出现问题条码的话，就需要这一整板重新扫过，才能找出问题条码，影响了供方出货的效率。

2. **任务 Task**：当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，根据视频中的操作速度，大概是 4~5 个 / 1s，所以也就是并发数为 5 * 2 = 10 的 QPS，分摊到 3 台服务器的话，每台服务器需要让接口满足 300 ms 以下的延迟，因此，在不增加服务器的情况下，尽量让接口的延迟足够低。

3. **行动 Action**：根据供方提供的截图，找到对应的接口，然后在测试环境模拟跑一遍接口，把接口路过的 SQL 日志都收集起来，统一分析，最终发现有几处索引是没有添加的，分别是：

   1. **psi_base_barcode**：条码表，314.67w+，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 1000 ms 左右，优化后 Druid SQL 监控显示 35 ms 左右。

      ```sql
      ALTER TABLE psi_base_barcode ADD INDEX psi_base_barcode_n2(CUS_COMPANY_CODE, PRODUCT_CODE);
      ```

   2. **psi_base_packing_relation**：箱包关系表，315.28w，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 650 ms 左右，优化后 Druid SQL 监控显示 32 ms 左右。

      ```sql
      -- 4、判断条码是否已出库：增加【CARTON_BARCODE】和【BARCODE】索引有提升
      SELECT COUNT(1)
      FROM psi_sales_stock_out
      WHERE (CARTON_BARCODE = '331100007920401110191W' OR BARCODE = '331100007920401110191W');
      ```

   3. **psi_sales_stock_out**：已出库条码表，840.58w，16 c 64 G MySQL，优化前 Druid SQL 监控【执行时间】显示  2290ms 左右，优化后 Druid SQL 监控显示 40 ms 左右。

      ```sql
      -- Add Index： explain => index_merge，Using union(psi_sales_stock_out_n1,psi_sales_stock_out_n2); Using where
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n1(CARTON_BARCODE);
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n2(BARCODE);
      ```

4. **结果 Result**：最终通过使用 Druid 监控，发现关键 SQL 的耗时已经满足要求了，psi_base_barcode 提效 96.51%，psi_base_packing_relation 提效 95.08%，psi_sales_stock_out 提效 98.25%。

###### 8）品质云微服务拆分 | 微服务、架构、设计

1. **背景 Situation**：

   1. 当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，不能停线的那种，此时如果品质这块有新需求要发，就需要工厂停线，等我们发版、验证通过了才能继续生产，对于大家来说其实都不好。
   2. 而且，由于是单体， OEM 生产功能与其他零部件供方的 SPC、PQC、OQC 的代码统统在一块，导致系统的负载比较高，常常是能看到 3 台服务器，每台 CPU 和内存都过 60%，有时遇到生产高峰以及定时器触发的话，会出现半夜电话报障说，应用宕机了，需要紧急重启的情况。

2. **任务 Task**：所以出于上面说的诉求，以及加上对未来供方不断上线，当时就规划了对各单体云，进行微服务拆分，共用一个注册中心和配置中心，其中就由我来负责品质云的微服务落地。

3. **行动 Action**：

   1. 我这边拆了 4 个业务模块（2 个月左右），分别是 BASE 基础数据模块，主要是一些字典、用户权限、企业、客户、组织等基础业务。
   2. OEM 代工生产模块，也就是上面所说的主要诉求点，包括成品下线、抽检、出库等业务，把这块生产线相关的业务剥离出去，可以做针对性的优化以及灵活的发版处理。
   3. 而剩余的其他业务，都统统放 APP 综合模块，与单体时的业务基本保持不变，主要是零部件供应商的 SPC 过程检验、PQC 半成品检验、OQC 成品出货检验等业务。
   4. JOBS 定时任务模块，则是后来继续剥离的一个模块，剥离这个模块可以保证生产高峰期时，在夜间也能平滑运行，不会受到大量定时器触发，导致的负载突然增高的影响，主要是一些与外围系统数据同步等业务的处理。

4. **结果 Result**：中间遇到的难点有：

   - 1）**服务的依赖边界问题**：

     1. 在拆分时，一开始我是直接把下线扫码、抽检、出库给拆开，SPC、PQC、OQC 也都拆开，然后就发现拆得粒度过小，出现了很多相互的依赖调用，就又要去考虑，如何代价尽可能小地，去避免带来新的分布式事务和性能问题。
     2. 而最后，是根据业务诉求，以及拆分后的风险与成本的评估，才认为最好的方案应该是，下线扫码、抽检、出库这三个生产线相关的业务合回一个 OEM 模块，其他的 SPC、PQC、OQC 等不是本次诉求的业务又合回一个 APP 模块。

   - 2）**Feign 远程调用时，遇到的响应结果被统一包装的问题**：

     1. 一开始单体时的系统，是有对响应结果做 `Result` 统一包装的，其原理是实现了 `HandlerMethodReturnValueHandler#handleReturnValue()` 方法，这是在 `invocableMethod.invokeForRequest()` 方法处理完 Handler Method 并拿到结果后，调用 `this.returnValueHandlers.handleReturnValue` 对返回结果进行的一个后置处理。

        ```java
        // 统一包装
        public class ResponseBodyWrapperHandler implements HandlerMethodReturnValueHandler {
        	@Override
        	public void handleReturnValue(Object returnValue,
        			MethodParameter returnType, ModelAndViewContainer mavContainer,
        			NativeWebRequest webRequest) throws Exception {
        		_logger.info("return data is " + returnValue);
        		if (returnValue instanceof Void) {
        			returnValue = Result.DefaultSuccessResult;
        		} else {
        			if (!(returnValue instanceof Result)) {
        				returnValue = Result.build(true, ResultCode.SUCCESS_CODE, "", returnValue);
        			}
        		}
        		handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);
        	}
        }
        ```

     2. 这个包装主要是为了打印原始的响应结果，以及自定义 `retCode` 响应码和 `retMsg` 响应语，但在使用 Feign 调用后，就出现，如果使用那边 Controller 的方法返回值类型，作为这边 Fegin 接口的返回值类型，则收到的就只是一个 null，因为中间做了一层 `Result` 的包装，此时需要对其进行解码，解码的话是实现了 `feign.codec.Decoder#decode()` 方法，通过注入并使用`com.fasterxml.jackson.databind.ObjectMapper` 进行读取 body 并修改，从而实现包装的统一解码工作，避免了在业务代码中，写过多的包装解码代码。

        ```java
        // 自定义Feign解码器
        @Component
        class FeignResultDecoder implements Decoder {
        
            @Autowired
            private ObjectMapper objectMapper;
        
            @Override
            public Object decode(Response response, Type type) throws IOException, DecodeException, FeignException {
                if (response.body() == null)
                    throw new DecodeException(response.status(),  "接口没有返回有效的数据, url: " + response.request().url(), response.request());
        
                // 解析body, 得到统一包装Result实例
                Result result = objectMapper.readValue(Util.toString(response.body().asReader(Util.UTF_8)), Result.class);
                if (ResultCode.ERROR_CODE.equals(result.getRetCode()))
                    throw new DecodeException(response.status(), "接口返回错误: " + result.getRetMsg() + ", url: " + response.request().url(), response.request());
        
                // 重新解析Result#data实例并返回
                return objectMapper.readValue(objectMapper.writeValueAsString(result.getData()), TypeFactory.defaultInstance().constructType(type));
            }
        }
        ```

   - 3）**网关路由问题**：由于主要是后端进行的微服务拆分，前端基本保持不变，所以就需要在收到请求后，对原始 url 进行截断，找到对应的关键字进行服务路由，当时采用的是 Gateway 做了服务网关，其好处就是高性能、对开发友好，只需要在代码中更改路由规则即可 、以及对接注册中心，服务地址不需要经常在网关上配来配去。

   - 4）**过滤器问题**：单体时的过滤器是实现 `javax` 包下的 `Filter` 类来实现的，主要是对一些 token 做校验、给上下文设置当前用户信息等操作，但由于 Feign 调用使用的是 HTTP 请求，也会经过这一层层的 `Filter` 校验，在有了服务网关后，就在网关上做了前置的过滤，主要是实现 `GatewayFilter` 和 `GlobalFilter` 接口来完成对应的过滤，这样，服务间调用就无需走那一层层的 `Filter` 校验了，只需要在网关中被校验一次即可，从而保证远程调用时的性能问题。

###### 9）token 校验失败问题 | 分布式锁、QMS Client Json 对比、问题排查

1. **背景 Situation**：OQC 零部件供方在成品出货报告新建完毕后，需要把报告推送给 QMS，在接口联调时没有问题，但放到生产上就偶尔能推得过去，偶尔推不过去，导致供方有些成品无法继续出货，货物堆在了仓库外面，需要马上解决这个问题。
2. **任务 Task**：
   1. 根据日志记录，推不过去的原因是，品质这边的客户端，收到了 QMS 的一个异常返回结果 `token校验失败`，这就很奇怪了，token 如果校验失败的话，那么为什么有时候能够成功呢，不应该一直都是失败的吗？
   2. 然后就翻了日志，与 QMS 收到的 token 进行比对，发现确实是 token 的问题。
   3. 这个 token 呢，是根据 DTO 对象转成 json 字符串后，使用内存中 QMS 的一个序列号 `appSec` 进行 MD5 加盐，生成摘要而得到的，由于其他参数都是写"死"的，也就是问题出在，用于生成摘要的 DTO 对象与传输过去的 DTO 对象不一致！
3. **行动 Action**：
   1. 然后，我扒出了有问题的推送报文，与 QMS 收到的报文进行对比，用了在线 Json 比对工具 `www.bejson.com`，结果放入后就明显看到，QMS 收到了多余的 `NULL串` ，从而造成两边生成的 token 不同。
   2. 果然，看回代码就发现，发送给 QMS 的 json 串和用于生成摘要的 json 串的生成逻辑不一样，前者是交给 `forest.httpClient` 做 json 转换，而后者是直接用了 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 和 `ObjectMapper#writeValueAsString()` 做的生成。
   3. 在这个工具类里，ObjectMapper 实例作为成员变量，如果先调 ``ObjectMapper#writeValueAsString()` 填充好了 NULL 序列化器，那么这个 ObjectMapper 每次都会输出 `NULL串` ，而如果先调的是 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 设置了普通序列化器，那么这个 ObjectMapper 每次都不会输出 `NULL串`，这也是为什么 token 时对时不对的原因所在。
   4. 所以，解决方法就是，在工具类中分开两者的使用，持有一个生成 `NULL串` 的 ObjectMapper，再持有一个生成正常串的 ObjectMapper，在生成 token 时使用后者，从而解决 token 不正确的问题。
4. **结果 Result**：最后，再使用分布式锁做一个单点定时，每隔 3 分钟把推送失败的报告重新推送过去，并设置 3 次的最大重推次数，保证这个推送接口的可靠性，和业务的连续性。

###### 10）大文件上传 | FastDFS、Redis List

1. **背景 Situation**：在建广告类交付单时，要求上传大视频，以让审批人去浏览理解当前交付的广告内容。

2. **任务 Task**：当时系统文件存储用的是 FastDFS，主要是用来存储中小文件，比如用户头像、图片、附件等内容，对文件大小也是做了 200 M 的限制，当时如果要实现大视频的话，一来文件接收上限要放宽，违反了组件用来上传小文件的约定，二来，会有大文件不能续点上传的问题，所以最直接的思路就是，对上传过来的文件进行分片上传，接收到所有分片后再合并成进行大文件存储，具体的做法是：

3. **行动 Action**：

   1. 前端方面，用的是 WebUploader 组件对文件进行分片，其原理是，在获取到文件后，先计算它的一个 MD5 文件摘要，然后对其按照每 200 M 作为一个 chunk 分片，并使用序号顺序标记每个 chunk，再调用后端提供的一个接口进行上传。
   2. 后端这边，接口则接收文件名、文件 MD5 摘要值、有无分片、最大分片号、当前分片号、MultipartFile，以及一些其他辅助信息，接收到后，先是用 MD5 判断当前这个大文件是否曾经上传过，如果上传过就不再处理了，再判断 MD5 + 分片号是否存在了，存在则不再处理了，从而解决即使分片报文重复，或者前一次中断然后本次重新上传的问题，实现续点上传。
   3. 然后，调用框架 API 保存好分片，这个框架主要是对FastDFS 做了封装，把文件存到特定的位置，然后返回文件存储对象的元数据。
   4. 接着，把【分片号 + 文件ID 】顺序放入用的 MD5 值做 key 的 Redis List 中。
   5. 最后，在收到最后一个分片时，则取出 Redis 中的所有【分片号 + 文件ID 】，对分片号做一次排序，从而解决分片不按顺序到达的问题，再顺序合并所有分片成为一个大文件，调用框架 API 保存好这个大文件，拿到它的元数据存储到文件关系表中，这样，下次在下载时，则可以根据文件 ID 找到当时的元数据，再去拿存储服务器上对应路径下的大文件即可，从而完成一次大视频文件的上传和下载。

4. **结果 Result**：总的来说，就是用了 WebUploader 前端组件进行文件分片，后端则是共用同一个接口，先对分片进行缓存，然后再顺序合并成大文件，解决大文件续点上传的问题。

   ![1646294342544](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294342544.png)

   ![1646294375795](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294375795.png)

###### 11）邮件发送组件 | 设计、RabbitMQ

1. **背景 Situation**：交付单触发待办提醒时，需要发送邮件通知对应的责任人进行处理，此时需要对接比亚迪的一个邮件服务器，进行邮件发送。
2. **任务 Task**：由于邮件发送不需要非常的及时，所以就采用了异步发送的发送，以提高性能。
3. **行动 Action**：
   1. 当时采用的方案是异步发送，接口把邮件对象丢给线程池，就返回响应客户端其他信息了，再由子线程去把邮件落库。
   2. 然后定时触发，捞取对应未发送和发送失败的邮件，进行批量发送，直连式地把消息发送到一个 `SCC_COMMON_EXCHANGE` 的 `SCC_MAIL_QUEUE` 的队列中，在收到 Broker ACK Confirm 后，则标记为发送成功，否则继续被下轮定时器触发捞取出来重新发送。
   3. 最后，由比亚迪那边的消费者进行消费，发送到邮件服务器中，完成异步邮件发送。
4. **结果 Result**：基于上述的方案，我封装了一个异步邮件发送工具类，在每次遇到需要异步发送邮件时，则调用那个工具类的对应方法即可，既方便，又解耦了业务代码，然后还拥有不错的性能。

###### 12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%

1. **背景 Situation**：我们团队这次的迭代，需要在云平台开发几个接口，然后在和 SRM 联调测试时，为了不用等比亚迪 SAP 测试环境的发版窗口，就需要有我们自己的一个云平台测试环境，方便快速发版快速验证。

2. **任务 Task**：那时由我负责来负责搭建，但由于是在内网环境进行开发，访问不了外网，就拉取不到 Jenkins 的依赖，当然也没有云原生这些基础设施，所以采取了 Tomcat Manager + ELK 部署的方式来发版，前者是 Tomcat 的后台，可以开发完代码后导出 war 包，然后在浏览器上把 war 包进行上传部署，后者是用于在 Kibana 上观察接口的异常日志。

3. **行动 Action**：

   1. 就这样，一个简单易用的发版平台就搭建好了，不过没几天问题就来了，我们发现每一次上传 war 包到启动完成，所花的时间好像都会比上一次的要久，最后一次 war 包上传则是浏览器一直在转了。

   2. 当时为了不阻塞测试进度，就到发版平台的服务器上看，先是使用 `top` 命令看到 118243 的 Tomcat 进程，居然占用了 95.3% 的 `%CPU`：

      ![1646305025603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305025603.png)

   3. 然后使用 `top -Hp 118243 ` ，查看 Tomcat 进程的所有线程，发现最高的一个线程 `118332` 占用了 73.3% `%CPU`：

      ![1646305182797](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305182797.png)

   4. 然后使用 `printf %x 118332`，获取对应的 16 进制线程号，用于后面的 jstack 文件搜索：

      ![1646305395917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305395917.png)

   5. 然后就是 `jstack -l 118243 > thread-dump.txt `，导出对应 `118243` 进程的线程快照，打开搜索对应的 `1ef96` 16 进制线程号（这个是当时真实的线程号，上面是后期模拟的） ，就定位到了一堆 `ParallelGC` 线程，原来是 GC 太多而导致的 CPU 飚高，那么为什么一个发版的 Tomcat，会有这么多 GC 线程呢？会不会是项目代码哪里写的有问题啊？

      ![1646305627751](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305627751.png)

   6. 然后我就使用 `jmap -dump:format=b,file=heap-dump.hproft 118243`，以 `hprof` 格式导出 `118243`  Tomcat 进程的堆内存快照，再导入到 MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，有 18 个 `ParallelWebappClassLoader`  共占据了 44.61% 堆空间，咦？为什么要 18 个这种类加载器呢？

      ![1646306496272](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306496272.png)

      ![1646306148994](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306148994.png)

   7. 然后我就想起 Tomcat 的类加载过程，是打破了双亲委派机制的：

      1. **ext -> bootstarp模型**：保证了 JRE 核心类库不会被重复加载，满足了加载JVM共同类库的需求。
      2. **ext -> webapp模型**：实现了每个 web 应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离的需求。
      3. **webapp -> share -> common模型**：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了加载其他共同类库的需求。

      ![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

   8. 也就是一个 `ParallelWebappClassLoader` 对应一个 Web App 项目，但用来发版的 Tomcat 应该就只有一个项目呀，所以我就怀疑应该是每次发版没把上一版的项目卸载掉所导致的。

4. **结果 Result**：所以我就让组内的成员，大家在下次发版前，先用 Tomcat Manager 把上一个项目卸载掉，再发新的 war 包上去，这样做了后，就没碰到过这样的情况出现了，应该算是蒙对了吧~哈哈

#### 2.1.1.2. 分片广播式定时的设计及原理？

##### 1、总

除了用 Kafka 去实现分片广播式定时，我还知道以下解决方案：

##### 2、分

1. 基于 **Redis ZSet** 有序集合实现：

   - 1）添加定时任务，把每个画像消息作为一个定时任务元素，定义好任务数据结构（表任务 ID、开始时间戳、循环条件等），然后使用 `ZADD` 命令把定时任务加入有序集合中，分数为开始时间戳。
   - 2）取定时任务，则是通过应用轮训去取，每隔 1 秒去消费有序集合，其中要注意的点是，由于应用是集群部署的，所以消费时要先获取分布式锁，获取到的才能进行消费。
   - 3）获取集合最低的分数，判断分数是否比当前时间戳小，是的话则执行后删除元素，然后根据循环条件来决定是否需要将其重新加入集合中，在下次循环之前，释放分布式锁，否的话则直接释放分布式锁。

   => 优点是，Redis 保证任务顺序执行，但可能会存在一定延迟，缺点是，每次轮训都发生所有应用来抢占分布式锁，网络带宽可能会受到影响。

2. 基于 **DB** 实现：

   - 1）添加定时任务，把每个画像消息作为一条记录，带上开始时间戳、循环条件丢到表里。
   - 2）取定时任务，由应用去查找该表最新的一条记录，通过乐观锁的方式，更新版本号，更新成功的则代表获取到此行的分布式锁，然后去执行此行的任务，执行完毕后删除任务，根据循环条件来决定是否需要将其重新加入表中。

   => 优点是，实现简单，没有多余的组件，缺点是，对单表压力大，相当于基于数据库实现的每个任务作为一个分布式锁。

3. 基于开源组件实现：EsJob、Xxl-job 等。

##### 3、总

以上就是我对除 Kafka 消息方案以外的一些实现分片广播式定时的方案，请指教一下方案是否合理？

#### 2.1.1.3. 目前生产上的机器规模？

##### 1、GSRMC

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 126 个服务。
- **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块           | 数量              | CPU           | 内存               | 硬盘  |
| -------------- | ----------------- | ------------- | ------------------ | ----- |
| 前端 Apache    | 8                 | 4 C           | 16 G               | 50 G  |
| Eureka         | 3                 | 1 C           | 1 G                | 10 G  |
| BASE           | 13                | 8 C           | 16 G               | 100 G |
| POS            | 19                | 8 C           | 16 G               | 100 G |
| PERF           | 7                 | 8 C           | 16 G               | 100 G |
| QUO            | 6                 | 8 C           | 16 G               | 100 G |
| BID            | 3                 | 8 C           | 16 G               | 100 G |
| PRICE          | 13                | 8 C           | 16 G               | 100 G |
| CON            | 6                 | 8 C           | 16 G               | 100 G |
| ESB            | 5                 | 8 C           | 16 G               | 100 G |
| JOBS           | 9                 | 8 C           | 16 G               | 100 G |
| TASK           | 5                 | 8 C           | 16 G               | 100 G |
| MIP            | 4                 | 8 C           | 16 G               | 100 G |
| SYNC           | 5                 | 8 C           | 16 G               | 100 G |
| INDEX          | 3                 | 8 C           | 16 G               | 100 G |
| 其他模块       | 25                | 8 C           | 16 G               | 100 G |
| MySQL          | 16（8 主 8 从）   | 32 C          | 128 G              | 3 T   |
| MongoDB        | 3                 | 8 C           | 16 G               | 500 G |
| Redis          | 3                 | 8 C           | 32 G               | 100 G |
| Kafka          | 3                 | 8 C           | 16 G               | 100 G |
| 报表导出 OSS   | 文件数： 500 / 天 | 数据量：10 G  | 增长量：300 M / 天 | -     |
| 供应商附件 OSS | 文件数：10 w / 年 | 数据量：200 G | 增长量：200 G / 年 | -     |

##### 2、云化项目

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 14 个服务。
- **数据库**：监控显示，16 C、64 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块             | 数量             | CPU          | 内存              | 硬盘  |
| ---------------- | ---------------- | ------------ | ----------------- | ----- |
| 前端 Nginx       | 3                | 4 C          | 16 G              | 50 G  |
| Eureka           | 3                | 1 C          | 1 G               | 10 G  |
| BASE             | 3                | 8 C          | 16 G              | 100 G |
| APP              | 3                | 8 C          | 16 G              | 100 G |
| OEM              | 3                | 8 C          | 16 G              | 100 G |
| JOBS             | 2                | 8 C          | 16 G              | 100 G |
| MySQL            | 1 主             | 16 C         | 64 G              | 3 T   |
| Redis            | 6                | 8 C          | 16 G              | 100 G |
| 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

##### 3、比亚迪 SRM

- **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 21 个服务。
- **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

| 模块             | 数量             | CPU          | 内存              | 硬盘  |
| ---------------- | ---------------- | ------------ | ----------------- | ----- |
| 前端 Nginx       | 2                | 4 C          | 16 G              | 50 G  |
| APP              | 6                | 8 C          | 16 G              | 100 G |
| MID              | 7                | 8 C          | 16 G              | 100 G |
| RPORT            | 6                | 8 C          | 16 G              | 100 G |
| Oracle           | 1                | 32 C         | 128 G             | 3 T   |
| Redis            | 3                | 8 C          | 16 G              | 100 G |
| 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

#### 2.1.1.4. 生产慢问题修复的例子？

见项目自我介绍里的，线程池调优，以及 CPU 95% 的例子。

##### 1、线程池调优 | 线程池、源码、调优

1. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
2. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
3. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
4. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
5. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。

##### 2、发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%

1. **背景 Situation**：我们团队这次的迭代，需要在云平台开发几个接口，然后在和 SRM 联调测试时，为了不用等比亚迪 SAP 测试环境的发版窗口，就需要有我们自己的一个云平台测试环境，方便快速发版快速验证。

2. **任务 Task**：那时由我负责来负责搭建，但由于是在内网环境进行开发，访问不了外网，就拉取不到 Jenkins 的依赖，当然也没有云原生这些基础设施，所以采取了 Tomcat Manager + ELK 部署的方式来发版，前者是 Tomcat 的后台，可以开发完代码后导出 war 包，然后在浏览器上把 war 包进行上传部署，后者是用于在 Kibana 上观察接口的异常日志。

3. **行动 Action**：

   1. 就这样，一个简单易用的发版平台就搭建好了，不过没几天问题就来了，我们发现每一次上传 war 包到启动完成，所花的时间好像都会比上一次的要久，最后一次 war 包上传则是浏览器一直在转了。

   2. 当时为了不阻塞测试进度，就到发版平台的服务器上看，先是使用 `top` 命令看到 118243 的 Tomcat 进程，居然占用了 95.3% 的 `%CPU`：

      ![1646305025603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305025603.png)

   3. 然后使用 `top -Hp 118243 ` ，查看 Tomcat 进程的所有线程，发现最高的一个线程 `118332` 占用了 73.3% `%CPU`：

      ![1646305182797](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305182797.png)

   4. 然后使用 `printf %x 118332`，获取对应的 16 进制线程号，用于后面的 jstack 文件搜索：

      ![1646305395917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305395917.png)

   5. 然后就是 `jstack -l 118243 > thread-dump.txt `，导出对应 `118243` 进程的线程快照，打开搜索对应的 `1ef96` 16 进制线程号（这个是当时真实的线程号，上面是后期模拟的） ，就定位到了一堆 `ParallelGC` 线程，原来是 GC 太多而导致的 CPU 飚高，那么为什么一个发版的 Tomcat，会有这么多 GC 线程呢？会不会是项目代码哪里写的有问题啊？

      ![1646305627751](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305627751.png)

   6. 然后我就使用 `jmap -dump:format=b,file=heap-dump.hproft 118243`，以 `hprof` 格式导出 `118243`  Tomcat 进程的堆内存快照，再导入到 MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，有 18 个 `ParallelWebappClassLoader`  共占据了 44.61% 堆空间，咦？为什么要 18 个这种类加载器呢？

      ![1646306496272](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306496272.png)

      ![1646306148994](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306148994.png)

   7. 然后我就想起 Tomcat 的类加载过程，是打破了双亲委派机制的：

      1. **ext -> bootstarp模型**：保证了 JRE 核心类库不会被重复加载，满足了加载JVM共同类库的需求。
      2. **ext -> webapp模型**：实现了每个 web 应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离的需求。
      3. **webapp -> share -> common模型**：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了加载其他共同类库的需求。

      ![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

   8. 也就是一个 `ParallelWebappClassLoader` 对应一个 Web App 项目，但用来发版的 Tomcat 应该就只有一个项目呀，所以我就怀疑应该是每次发版没把上一版的项目卸载掉所导致的。

4. **结果 Result**：所以我就让组内的成员，大家在下次发版前，先用 Tomcat Manager 把上一个项目卸载掉，再发新的 war 包上去，这样做了后，就没碰到过这样的情况出现了，应该算是蒙对了吧~哈哈

#### 2.1.1.5. MySQL MVCC？

##### 1、总

MVCC，Multi-Version Concurrency Control，多版本并发控制，可以实现数据库读写冲突时的无锁并发访问，可以做到在读时不阻塞写，写时不阻塞读，提高了数据库并发的读写性能，同时还可以解决 MySQL 不可重复读、幻读等事务并发问题。

##### 2、分

1. 首先，需要讲一下 MySQL 中的当前读和快照读：

   - 1）**当前读**：非 MVCC 实现，读取的是记录的最新版本，读取时，要保证其他并发事务不能修改当前记录，因此会对读取的记录进行加锁。
     - 举例：select lock in share mode（共享锁）, select for update（排他锁），update、insert、delete（排他锁）、串行化事务隔离级别等。
   - 2）**快照读**：MySQL 实现 MVCC 模型的中一个具体的非阻塞读功能，可以避免读时的加锁操作，从而降低开销、提高并发性能，但快照读可能读到的不一定是数据的最新版本，而是之前的历史版本，但前提是，事务使用非串行化的隔离级别，否则串行化级别下的快照读会退化成当前读。
     - 举例：不加锁的 select。

2. 然后就是实现原理，MySQL 是由 undo log + 版本链 + Read View 来实现 MVCC 的：

3. 第一个是 **undo log**，回滚日志，属于逻辑日志，记录的是 sql 执行相关的信息，是 MySQL 中事务原子性和隔离性实现的基础，其实现原理是：

   - 1）在 MySQL InnoDB 中，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log。
   - 2）如果事务执行失败或调用了 rollback，导致事务需要回滚时，就可以根据 undo log 的内容做与之前相反的工作，把数据回滚到修改之前的样子，以实现事务原子性操作。
   - 3）对于每个 insert，回滚时会执行 delete。对于每个 delete，回滚时会执行 insert。对于每个 update，回滚时会执行一个相反的 update，把数据改回去。
   - 4）而 MVCC 则是采用 undo log 来记录旧版本，链首为最新的旧记录，链尾为最早的旧记录。

4. 第二个是**版本链**，在 InnoDB 中，每次修改版本都会在版本链中记录，通过 undo log + trix_id + roll_pointer 来实现，undo log 原理如上所说，

   ![1630673126935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630673126935.png)

   - 1）**trx_id**：当前版本的事务ID，用来存储每次对某条记录进行修改时的事务ID，其中事务 ID 则是，当每个事务开启时，都会被分配一个ID，而这个ID是递增的，因此越新的事务其ID值越大。
   - 2）**roll_pointer**：回滚指针，由于每次对记录修改时，都会把老版本写入到 undo 日志中，使用回滚指针 roll_pointer 来指向这条记录上一个版本的位置，通过它来获得上一个版本的记录信息，其中，插入操作的 undo 日志是没有 roll_pointer 的，因为它没有老版本。

5. 第三个是 Read View，它是事务进行快照读操作时产生的读视图，是数据库当前的一个快照，记录了系统当前活跃事务ID 集合（即还没有提交的事务 ID），用来做可见性判断，即当某个事务执行快照读时，会对该记录创建一个Read View 读视图， 并把它作为条件，来判断当前事务能够看到哪个版本的数据，其中可能是当前版本的数据，也有可能是该行记录 undo log 里面某个版本的老数据，具体原理如下：

   ![1630674963257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630674963257.png)

   1. **trx_id == creator_trx_id**：可以访问这个版本，这个版本的事务 ID 等于当前创建 Read View的事务 ID，即自己能够读到自己的版本。
   2. **trx_id < min_trx_id**：可以访问这个版本，这个版本的事务 ID 小于最小活跃事务 ID，说明这个版本已经被提交过了，对于当前做可见性判断的事务来说，是可以看见的。
   3. **trx_id > max_trx_id**：不可以访问这个版本，这个版本的事务 ID 大于下一个事务 ID，说明这个版本记录是在该 Read View 生成之后产生的，已经超出了版本链范围，而快照读只能读取版本链中的版本，因此该版本对于当前做可见性判断的事务来说，是不应该看见的。
   4. **min_trx_id <= trx_id <= max_trx_id**：
      - 如果这个版本的事务 ID 为 m_ids 中的某个值，则不可以访问这个版本的，因为m_ids 都是活跃的、还没提交的事务，说明该版本记录还没有提交，对于当前做可见性判断的事务来说，是不应该看见的。
      - 如果这个版本的事务 ID 不为 m_ids 中的某个值，则可以访问这个版本，因为没在 m_ids 里，又小于等于 max_trx_id，说明该版本记录已提交了，对于当前做可见性判断的事务来说，是可以看见的。

   => 因此，可见性判断总的来说就是，要当前事务能看到的版本应该是自己创建的或者已经提交了的，这也是实现 MVCC 的原理所在。

##### 3、总

以上，就是我对 MySQL MVCC 的一个理解，请问有什么细节需要补充的吗？

#### 2.1.1.6. Dubbo 配置的注意点有哪些？

##### 1、Provider 多配置 Consumer 参数

1. 作为服务提供⽅，自己⽐消费⽅更清楚服务的这些接口参数的取值，比如超时时间、重试次数、负载均衡策略等。
2. 由于配置覆盖策略存在，在 Provider 端配置后，Consumer 端不配置则会使⽤ Provider 端配置，即 Provider 配置可以作为 Consumer 的缺省值。
3. 而如果 Provider 不配置，Consumer 也不直接配置，则会使⽤ Consumer 端的全局设置，这对于 Provider 是不可控的，并且往往是不合理的。
4. 因此，Provider 端尽量多配置、完善这些接口参数，让 Provider 实现者⼀开始就思考 Provider 端的服
   务特点和服务质量等问题。

![1636882183556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636882183556.png)

##### 2、Provider 合理配置性能参数

比如，**threads**（服务线程池⼤⼩）、**executes**（服务提供者并发请求的上限）。

##### 3、服务使用固定端口

使⽤固定端⼝来暴露服务，不要使⽤随机端⼝，这样在注册中⼼推送延迟的情况下，消费端仍然能够通过缓存列表，调⽤到原地址+原端口的服务，保证调⽤成功。

##### 4、推荐使用 XML 进行配置

XML 配置优先级高于 properties 和 yml，且标签的配置方式更加容易阅读和理解。

##### 5、应用配置负责人参数

配置 `dubbo:application#owner` 负责人参数，这些可以在运维平台上看到，以便于在发现问题时，找到对应服务负责⼈。

#### 2.1.1.7. Dubbo 提供者、消费者服务启动原理？

##### 1、总

1. 首先是 Dubbo 与 Spring 的融合原理，基于 dubbo.jar 内的 `META-INF/spring.handlers` 配置，Spring 在遇到 Dubbo XML 配置的名称空间 `http\://dubbo.apache.org/schema/dubbo` 时，会回调 `DubboNamespaceHandler` 。
2. 而 `http\://dubbo.apache.org/schema/dubbo/dubbo.xsd` 则定义了 Dubbo XML 的标签语法，所有 dubbo 的标签，都统一用 `DubboNamespaceHandler#DubboBeanDefinitionParser` 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。
3. Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent` 回调时，或者 Consumer 在接口注入 `FactoryBean#getObject` 时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 Dubbo#URL，然后将 Dubbo#URL 传给 Protocol 扩展点，基于扩展点的 SPI 机制，根据 Dubbo#URL 的协议头，进行不同协议的服务暴露或者引用。

##### 2、分

###### 1）Provider 服务发布原理

1. `ServiceConfig` 在 XML 解析后，拿到对外提供实现类 `XML#ref` 配置。
2. 然后，Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent` 回调时，通过 `ProxyFactory#getInvoker（）` 为 `XML#ref` ，生成一个 interfaceClass 的 javasist 动态代理 Wrapper 包装类 Invoker 实例，可以动态代理调用 `XML#ref` 实现类的方法，到这一步就完成了具体实现类到 `Invoker` 的转化。
3. 接下来，就是 `Invoker` 转换到 `Exporter` 的过程，是服务暴露的关键过程，其转换分为两种类型：
   - 1）**暴露本地服务**：
     1. 指服务暴露和引用都在同一个 JVM 里，自己调用自己接口，没必要进行远程通信。
     2. 会调用 `InjvmProtocol#export（）` 把 invoker 转换为 `InjvmExporter`，并存进 exporters 缓存中。
     3. 调用则是获取 exporters 缓存中的 `InjvmExporter`，进行一个普通的动态代理到实现类的方法。
   - 2）**暴露远程服务**：
     1. 指服务暴露给远程客户端IP和端口号，以实现远程通信。
     2. 会调用 `DubboProtocol#export（）`  把 invoker 转换为 `DubboExporter`，然后打开 Netty 服务器暴露服务，并存进 exporters 缓存中。
     3. 然后调用 `RegistryProtocol#register（）`，使用 Curator 客户端建立 ZK 连接，注册 provider 持久化结点、当前服务的非持久化结点、configurators 非持久化结点，并设置监听器，当配置发生变更时，则会回调监听器的 `notify（）` 方法，来修改 invoker 信息。
     4. 调用则是通过 `Netty#channelRead()` 方法，当有数据请求时，则调用 handler 和线程池进行接收、处理，最终获取缓存中的 `DubboExporter`，动态代理到实现类的方法。

![1637067703250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637067703250.png)

###### 2）Consumer 服务引用原理

1.  Consumer 在接口注入 `FactoryBean#getObject` 时，调用 `Protocol#refer（）`生成 `Invoker` 实例，是服务消费的关键，其分类 3 种类型：
   - **本地服务引用**：如果为本地暴露服务，则 `InjvmProtocol` 生成本地执行的 `InjvmInvoker` 。
   - **直连服务引用**：如果为直连服务，则 `DubboProtocol` 创建 Netty 客户端，连接 url 服务，构建 `DubboInvoker` 。
   - **远程服务引用**：
     1. 如果为非直连的远程服务引用，则会调用 `RegistryProtocol` 进行 Consumer 注册到 ZK 并订阅，拉取相关 url 和 配置信息，当有发生变更时，则触发监听器的回调函数，调用 `DubboProtocol#refer()` 生成 `DubboInvoker` ，并加入集群，最后默认伪装返回一个 `FailoverClusterInvoker`。
2. 最后利用动态代理，把 `Invoker` 转换为客户端需要的接口实现类。
3. 当应用对代理对象进行方法调用时，则是动态代理到对应 `Invoker#invoke` 方法，调用本地方法或者发起远程请求。

![1637149757299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637149757299.png)

###### 3）Consumer 远程调用 Provider 原理

1. 消费方使用的接口动态代理实现类 proxy，调用其对应的 `Invoker`，发起真正的远程服务调用。

2. 而提供方的实现类，则会被封装成为一个 `AbstractProxyInvoker` ，然后生成一个 `Exporter` ，当服务提供方收到一个请求后，则会找到对应的 `Exporter` 实例，并调用它所对应的 `AbstractProxyInvoker` 实例，从而真正调用了服务提供者的代码。

3. 整个**消费方调用提供方**的调用链架构如下：

   ![1637150417647](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637150417647.png)

   1. **服务引用**：通过 Javassist 反向代理，代理调用 InvokerInvocationHandler#invoke 方法。
   2. **服务本地调用、降级、缓存**。
   3. **集群容错与负载均衡**：非 mock Invoker 筛选，Invoker 目录查找，根据容错策略、负载均衡策略，挑选唯一的 Invoker。
   4. **服务过滤链、监听器、包装类 SPI 扩展**。
   5. **服务协议**：根据协议，使用不同的 Invoker 调用不同的网络传输底层。
   6. **网络传输**：抽象 Netty、Mina 等统一接口，把消息序列化后发送到网络，传输给 Server 端。
   7. **消息接收与异步处理**：Server 端接收到消息后，经过反序列化后，交由线程池异步处理。
   8. **服务协议**：根据协议，选择不同的 Exporter 进行调用。
   9. **服务过滤链、监听器、包装类 SPI 扩展**。
   10. **服务调用**：最后调用真正的接口实现类，得到方法执行结果。

4. 而**提供方响应消费方**的顺序为：

   1. **服务响应**：在得到方法执行结果后，通过网络传输底层，序列化后发送响应报文给客户端。
   2. **结果接收**：客户端接收到响应报文后，交由线程池异步处理程序，经过反序列化后塞回到 Future 对象中，完成一次服务调用。

##### 3、总

以上，就是我对 Dubbo Provider 和 Consumer 启动过程以及远程调用过程的一个理解，请问有什么细节需要补充的吗？

#### 2.1.1.8. SpringBoot 的启动原理？

见《[1.1.1.4. SpringBoot 自动装配和自定义 starter？](#1.1.1.4. SpringBoot 自动装配和自定义 starter？)》。

#### 2.1.1.9. Spring MVC 中过滤器和拦截器的区别？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 2.1.2.0. 算法题 | 实际问题中树的深度优先遍历

思路就是，把对应的数据结构，转换为树结点的数据结构，然后进行常规的深度优先遍历即可，比如二叉树的**先序遍历**：

##### 1、递归法 | O（n）

- **思路**：递归遍历，中 -> 左 -> 右，因此在一开始来到中时，就把节点的值加入集合中即可。
- **结论**：时间，0ms，100%，36.4mb，92.56%，非常简单。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        return res;
    }
    
    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        res.add(root.val);
        f(root.left, res);
        f(root.right, res);
    }
}
```

##### 2、迭代法 | O（n）

- **思路**：迭代法中，先序遍历实现最简单，因为当前使用的 while 循环可以认为是“中”，然后模拟系统栈把右、左一次压栈即可（可以认为是方法倒过来压栈）。
- **结论**：时间，0ms，100%，36.4mb，93.30%，注意添加和使用前都做个判空，防止空指针和节省空间的使用。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        if(root != null) {
            stack.push(root);
        }
        
        List<Integer> res = new LinkedList<>();
        while(!stack.isEmpty()) {
            root = stack.pop();
            if(root != null) {
                res.add(root.val);
                if(root.right != null) {
                    stack.push(root.right);
                }
                if(root.left != null) {
                    stack.push(root.left);
                }
            }
        }

        return res;
    }
}
```

#### 2.1.2.1. 算法题 | Linux#uniq 指令、Java BufferedReader#ready 和 readLine

这道题的难点在于，Linux#uniq 指令的作用，和 Java BufferedReader 的 API。

##### 1、Linux#uniq 文档编辑命令

Linux#uniq，输入一个文件，检查文本文件中重复出现的行列，并输出到另一个文件，-c 代表在每列旁边显示该行重复出现的次数，-d 代表仅显示重复出现的行列，-u 代表仅显示只出现一次的行列。

##### 2、Java BufferedReader API

BufferedReader 可以从字符输入流中读取文本，并缓冲字符，以便有效地读取字符，使用时可以通过构造函数指定缓冲区大小或者也可以只使用默认大小 8192，同时建议使用 BufferedReader 包装 Reader 实例，以提高效率。

```java
private static void printLinuxCmd(File file) throws IOException {
    // 使用 BufferedReader 包装 Reader 实例
    BufferedReader reader = new BufferedReader(new FileReader(file));
    Set<String> res = new HashSet<>();

    // 允许读取：ready()
    String str;
    while (reader.ready()) {
        // 按行读取：readLine()
        str = reader.readLine();
        if(str.contains("abc")) {
            res.add(str);
        }
    }
    
    // 排序后去重
    List<String> reslist = res.stream().sorted(Comparator.comparingInt(Object::hashCode)).collect(Collectors.toList());
    System.err.println(reslist);
    
    // 底层是去关闭输入流
    reader.close();
}
```

#### 3.1.1.1. sychrozied 锁升级流程？

##### 1、总

sychrozied 锁状态一共有 4 种，级别由低到高分别为：无锁、偏向锁、轻量级锁和重量级锁。

1. 在 JDK 1.6 之前，sychrozied  锁是一个重量级锁，效率比较低下。
2. 在 JDK 1.6 之后，为了提高锁的获取和释放效率，就对 synchronized 的实现进行了优化，引入了偏向锁和轻量级锁。
3. 从此 synchronized 锁就有了以上 4 种状态，并且它们会随着竞争的情况逐渐升级，但不可降级。

对于 sychrozied  优化后的，锁执行过程总结如下：

![1629617805708](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617805708.png)

![1629617826584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617826584.png)

1. **确认是否为可偏向状态**：线程抢锁时，JVM 首先检测内置锁对象 Mark Word 中的 biased_lock（偏向锁标识）是否设置成 1，lock（锁标志位）是否为 01，如果都满足，则确认内置锁对象为**可偏向状态**。
2. **确认线程 ID**：在内置锁对象确认为可偏向状态后， JVM 会检查 Mark Word 中的线程 ID 是否为抢锁线程的 ID。
3. **同线程 ID，直接执行临界区代码**：如果是，则表示抢锁线程处于偏向锁状态，然后抢锁线程快速获得锁，开始执行临界区代码。
4. **竞争锁成功，升级为偏向锁**：如果 Mark Word 中的线程 ID 并未指向抢锁线程，则通过 CAS 操作去竞争锁。
   - 如果竞争成功，则将 Mark Word 中的线程 ID 设置为抢锁线程，偏向标志位设置为 1，锁标志位设置为 01，然后执行临界区代码，此时内置锁对象为**偏向锁状态**。
5. **发生锁竞争失败，偏向锁升级为轻量级锁**：如果 CAS 操作竞争失败，说明发生了竞争，此时 JVM 会去检查原先持有锁的线程是否存活。
   - 如果原线程已经死亡，则设置 Mark Word 为抢到锁的线程 ID，内置锁继续保持为偏向锁。
   - 如果原线程没有死亡，且其堆栈中存在该 sychrozied 锁的所记录，则需要撤销偏向锁，进而升级为**轻量级锁**（继续由原持有锁线程持有）。
6. **其他线程继续 CAS 竞争，以获取轻量级锁**：如果仍然有其他线程继续竞争轻量级锁，则在 JVM 将在替换锁对象 Mark Word 中的 ptr_to_lock_record 过程中，使用 CAS 替换为抢锁线程的锁记录指针。
   - 如果替换成功，则代表抢锁线程获得了**轻量级锁**。
   - 如果替换失败，表明存在其他线程竞争锁，则 JVM 接着尝试使用 CAS + 自旋方式来替换。
     - 如果替换成功，代表抢锁成功，则锁对象继续保持为**轻量级锁状态**。
7. **CAS + 自旋失败，轻量级锁升级为重量级锁**：如果 CAS + 自旋替换失败，即超过了最大自旋次数，轻量级锁则升级为重量级锁，此后等待锁的线程都需要进入**阻塞状态**。

=> 总的来说：

1. **偏向锁**是在没有发生锁争用的情况下使用的。
2. 一旦有了第二个线程争用锁，偏向锁则会升级为**轻量级锁**。
3. 如果锁争用很激烈，轻量级锁的 CAS + 自旋到达自旋阈值后，轻量级锁则会升级为**重量级锁**。

##### 2、分

###### 1）无锁

![1629597556442](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597556442.png)

无锁，即无线程竞争，在 java 对象刚创建时，还没有任何线程来竞争，对象处于无锁状态，此时，偏向标志位为0，锁状态标志位为 01。

###### 2）偏向锁

![1629597869808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597869808.png)

偏向锁，是指一段同步代码，一直被同一个线程所访问，偏向锁状态下的 Mark Word，会记录 synchronized 锁偏爱的线程 ID，从而让 synchronized 锁认定该线程为“熟人”，从而该线程可以自动获取锁，降低获取锁的代价。

- **主要解决无竞争下的锁性能问题**：由于线程 ID 被记录在锁对象的 Mark Word 中（CAS设置），以后该线程获取锁时，只需要判断一下线程 ID 和标志位，就可以直接进入同步块，连 CAS 操作都不需要，省去了大量有关锁申请的操作，消除了无锁竞争情况下的同步原语，从而提高了程序的性能。
- **偏向锁的膨胀**：
  1. 如果偏向锁已经被 A 占据，一旦有第二个线程 B 来争抢这个对象，由于偏向锁不会主动释放，所以 B 看到的 synchronized 锁是偏向状态，表明已经存在了竞争，则 JVM 会去检查原来持有该对象锁的占有线程A 是否依然存活。
  2. 如果发现 A 已经挂了，则将锁对象变为无锁状态，然后重新偏向 B 线程。
  3. 如果发现 A 依然存活，则会进一步检查 A 的调用堆栈是否有锁记录持有该偏向锁。
  4. 如果存在锁记录，表明原来的线程 A 仍然在使用该偏向锁，即 A 和 B 此时发生了锁竞争，则 JVM 会撤销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。
- **偏向锁的撤销**：如果锁对象经常被多个线程竞争，那么偏向锁就是多余的，并且撤销偏向锁的过程也会带来一些性能开销。
  1. 在一个安全点停止拥有锁的线程。
  2. 遍历线程的栈帧，检查是否存在锁记录，如果存在，则需要清空锁记录（锁记录是线程私有的，每个线程都有自己的一份锁记录），使其变为无锁状态，并修复锁记录指向的 Mark Word，清除其线程 ID。
  3. 将当前锁升级为轻量级锁。
  4. 唤醒当前线程。
- **偏向锁的撤销条件**：
  - 多个线程竞争偏向锁。
  - 调用偏向锁对象的 `hashCode（）`方法，或者 `System.identityHashCode（）`方法，计算对象的HashCode 之后，将哈希码放置到了 Mark Word 中，synchronized 锁变成无锁状态，偏向锁会被撤销。

=> 经验表明，大部分情况下，一个同步代码块的线程都是同一个线程，总体来说，使用偏向锁带来的好处大于偏向锁撤销和膨胀带来的代价。如果某些临界区存在两个，或者两个以上的线程竞争，偏向锁反而会降低性能，此时可以在启动 JVM 时，把偏向锁的默认功能关闭。

###### 3）轻量级锁

![1629598045639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629598045639.png)

轻量级锁，也被成为非阻塞同步锁、或者叫乐观锁，是指当锁处于偏向锁，又被另一个线程企图抢占时，偏向锁就会升级为轻量级锁，而企图抢占的线程会通过自旋的形式尝试获取锁，不会阻塞抢锁线程，以提高性能，其中，哪个线程先占有锁对象，锁对象的 Mark Word 就会指向哪个线程栈帧中的锁记录。

- **引入轻量级锁的主要目的**：在多线程竞争不激烈的情况下，通过 CAS 机制竞争锁，减少重量级锁产生的性能损耗，尽可能不动用操作系统层面的互斥锁，在应用层面上通过自旋来解决线程同步的问题。

  - **自旋原理**：如果持有锁的线程能在很短时间内释放锁资源，竞争等待锁的线程则不需要进行内核态和用户态的切换进入阻塞状态，它们只需要 CPU 自旋，等待持有锁的线程释放锁后即可立即获取锁，避免了用户线程和内核切换的消耗，从而提高性能。
  - **自旋锁分类**：
    - **普通自旋锁**：指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。
      - JDK 1.6 的轻量级锁使用的是普通自旋锁，需要使用 `-XX：+UseSpinning` 选项手工开启。
      - 默认情况下，自旋次数为 10 次，可以通过 `-XX：PreBlockSpin` 选项来进行更改。
      - 然而，线程自旋需要消耗 CPU，如果一直获取不到锁，那么线程也不能一直占用 CPU 自旋做无用功，因此需要设定一个自旋等待的最大时间。
    - **适应性自旋锁**：
      - JVM 对于自旋周期的选择，JDK 1.7 引入了适应性自旋锁（自动开启），指的是自旋的时间不是固定式的，而是由前一次在同一个锁上的自旋时间，以及锁的拥有者状态来决定的，解决的是锁竞争时间不确定的问题，使得竞争程度趋于稳定。
      - **自旋成功了则下次自旋的次数就会更多**：如果抢锁线程在同一个锁对象上之前成功获得过锁（竞争力强，适合竞争），JVM 则会认为这次自旋很可能再次成功，此次允许自旋等待持续相对更长的时间。
      - **自旋失败了则下次自旋的次数就会减少**：如果对于某个锁，抢锁线程很少成功获得过（竞争力弱，不适合竞争），JVM 则减少自旋时间甚至省略自旋过程，以避免浪费 CPU 资源。

- **轻量级锁的抢占过程**：

  1. 在抢锁线程进入临界区之前，如果该 synchronized 锁没有被锁定，JVM 首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前 Mark Word 的拷贝。

     ![1629601733727](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629601733727.png)

  2. 然后，抢锁线程将使用 CAS 自旋操作，尝试将内置锁对象头的 Mark Word 的 ptr_to_lock_record（锁记录指针），更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，这个线程就拥有了对象锁。

  3. 接着，JVM 将 Mark Word 中的 lock 标记位改为 00，代表该内置锁对象处于轻量级锁状态。

  4. 抢锁成功之后，JVM 会将 Mark Word 中原来的锁对象信息（如哈希码等），保存在抢锁线程锁记录中的Displaced Mark Word 字段中，再将抢锁线程中锁记录的 owner 指针指向锁对象。

     ![1629602512221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629602512221.png)

- **轻量级锁的膨胀**：

  - 如果临界区代码执行耗时较长，在其执行期间，其他线程都在原地 CAS + 自旋等待替换ptr_to_lock_record，导致一直空耗 CPU，带来很大的性能损耗。
  - 而轻量级锁的本意，是为了减少多线程进入操作系统层面互斥锁的概率，并不是要替代其互斥锁。
  - 因此，在内置锁争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁实现的重量级锁。

###### 4）重量级锁

![1629599089661](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629599089661.png)

重量级锁，也称为同步锁，是指当锁处于轻量级锁，如果持有锁的线程执行的时间，超过了自旋等待的最大时间仍然没有释放锁，自旋等待锁的线程不会一直自旋下去，而是会进入阻塞状态，该锁也膨胀为重量级锁。

- 锁对象的 Mark Word 会再次发生变化，指向一个监视器对象，该监视器对象会用集合的形式来登记和管理排队的线程。

  - **监视器**：是一个同步工具，相当于一个许可证，拿到许可证的线程即可进入临界区进行操作，没有拿到的则需要阻塞等待。在 JVM 中，每个对象都关联一个监视器，监视器和对象一起创建、销毁，保证同一时间只有一个线程可以访问被保护的临界区代码。监视器也可以说是同步机制，主要特点是：
    - **同步**：监视器所保护的临界区代码互斥地执行，一个监视器是一个运行许可，任一线程进入临界区代码都需要获得这个许可，离开时会把许可归还。
    - **协作**：监视器提供 Signal 机制，允许正持有许可的线程，暂时放弃许可进入阻塞等待状态，等待其他线程发送 Signal 去唤醒；其他拥有许可的线程可以发送 Signal，唤醒正在阻塞等待的线程，让它可以重新获得许可并启动执行。

- 重量级锁通过监视器的方式，保障了任何时间，只允许一个线程通过受到监视器保护的临界区代码。在Hotspot 虚拟机中，监视器由 C++ 类 ObjectMonitor 实现：

  ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

  - **_recursions**：线程的重入次数。
  - **_owner**：标识拥有该 Monitor 的线程，即获得锁的线程。
  - **cxq**：竞争队列，所有请求锁的线程首先会被放入这个竞争队列中。cxq 由 Node 及其 next 指针逻辑构成（单向链表），并不存在一个队列的数据结构，只是一个虚拟队列：
    1. 在线程进入 cxq 前，抢锁线程会先尝试通过 CAS 自旋获取锁，如果获取不到，则会进入 cxq 队列，显然抢锁操作这对于那些已经进入了 cxq 队列的线程是不公平的，因此 synchronized 同步块所使用的重量级锁是**非公平锁**。
    2. 每次新加入的 Node 会在 cxq 的队头进行，通过 CAS 改变第一个结点的指针为新增结点，同时设置新增结点的 next 指向后续结点。
    3. 从 cxq 取出元素时，会从队尾获取。由于只有 owner 线程才能从队尾取出元素，即线程出列操作无争用，因此 cxq 是无锁结构。
  - **_EntryList**： 候选竞争队列，在 owner 线程释放锁时，JVM 会从 cxq 中迁移线程到 EntryList 中，然后指定 EntryList 中的某个线程（一般为 Head），为 OnDeck Thread（Ready Thread），因此 EntryList 中的线程，是作为候选竞争线程而存在的。
    - **OnDeck Thread**：
      - JVM 不直接把锁传递给 Owner Thread，而是还要让 OnDeck Thread 与后来的新抢锁线程竞争抢锁，虽然牺牲了一些公平性，但极大提升了系统的吞吐量。
      - OnDeck Thread 获取到锁资源后，就会变为 Owner Thread，而没获得锁的 Thread 则会依然留在 EntryList 中。
  - **_WaitSet**：等待队列，某个拥有 ObjectMonitor 的线程（owner 线程），在调用 Object.wait（）方法之后将被阻塞，然后该线程将被放置在 _WaitSet 链表中，直到某个时刻通过 Object.notify（）或者Object.notifyAll（）唤醒后，该线程才会重新进入 EntryList 中继续候选竞争锁。

- **重量级锁性能低**：重量级锁使用了操作系统底层的互斥锁（Mutex Lock），会导致线程在用户态和内核态之间的频繁切换，从而带来较大的性能损耗。

  - 处于 cxq、EntryList、WaitSet 中的线程都处于阻塞状态，线程的阻塞或者唤醒，都需要操作系统来帮忙。比如在 Linux 内核中采用 pthread_mutex_lock 系统调用（互斥锁）来实现，因此，进程需要从用户态切换到内核态。
  - 进程从用户态切换到内核态，这种切换需要消耗很多时间，有可能比用户执行代码的时间还要长，而由于轻量级锁使用 CAS 进行自旋抢锁，都处于用户态下，进程不存在用户态和内核态之间的切换，因此轻量级锁开销较小，而重量级锁使用了 Linux 内核态下的互斥锁，会造成较大的性能开销。

##### 3、总

适用场景总结：

| 锁       | 优点                                                         | 缺点                                             | 适用场景                                 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ---------------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比，仅存在纳秒级的差距 | 如果线程间存在锁竞争，则会带来额外的锁撤销消耗   | 适用于只有一个线程访问临界区的场景       |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 抢不到锁竞争的线程会使用CAS 自旋等待，会消耗 CPU | 锁占用时间很短，追求响应时间，但吞吐量低 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗 CPU                             | 使用系统互斥锁，线程阻塞，响应时间缓慢           | 吞吐量高，追求吞吐量，但锁占用时间较长   |

=> 以上，就是我对 sychrozied 的一个理解，请问有什么细节需要补充的吗？

#### 3.1.1.2. Java 线程同步方式？

##### 1、总

1. 线程同步，指当有一个线程对内存进行操作时，其他线程都不可以对这个内存进行操作，直到此线程完成操作后，其他线程才能对这个内存进行操作。
2. 在 Java 中，实现线程同步的基础是，操作系统的 mutex 互斥锁、volatile 保证内存可见性和 CAS 比较交换，从上层表现形式来看，可以划分为以下几种同步方式：

##### 2、分

1. **锁式**：指的是，互斥访问同步代码块，拿到互斥量的线程进行同步代码块执行，拿不到互斥量的线程则进入阻塞状态，比如 synchronized 内置锁、Lock 接口的实现类比如 ReentrantLock 重入锁、ReentrantReadWriteLock 读写锁。
2. **事件通知式**：指的是，通过事件通知来协调线程，安全地访问同一块内存，阻塞后的线程需要等待其他线程来唤醒，比如 Object#wait()、notify()、notifyAll()，LockSupport#park()、unpark()，Lock.Condition#await()、signal()。
3. **资源控制式**：指的是，通过控制资源数量，来决定线程是否能够访问临界区或者内存，拿到资源的则可以访问，拿不到的则进入阻塞或者排队等待，比如 Semaphore 信号量。
4. **排队等待式**：指的是，通过队列来实现线程的有序访问，比如 AQS CLH 自旋锁队列、BlockingQueue 阻塞队列。

##### 3、总

以上，就是我对 Java 线程同步方式的一个理解，请问有什么细节需要补充的吗？

#### 3.1.1.3. 你为什么值这么多？

##### 1、总

对于这个问题，我认为我个人对于技术的研究，其广度和深度都是十分符合当前条件。

##### 2、分

1. 首先是广度，
   - 1）开发使用方面，本人有全栈开发经验，对于前后端的实现角度，都有自己一些独特的理解，应用开发上自然也能驾驭得不错。
   - 2）应用架构方面，本人对主流开源框架基本所有了解、掌握，在架构设计时能够有足够多的灵感来源，基本能够覆盖较多的需求实现。
   - 3）系统架构方面，本人对于一些系统部署相关的，做了较多实验，也从中得到了不错的经验和心得，比如 LVS、Haproxy、Nginx、Redis、RabbitMQ、Kafka、ELK、Docker、K8s、Cloud Foundry、Mesos、Marathon，以及一些性能调优方面的等等。
2. 然后是深度，
   - 1）java 语言方面的原理，个人研究过集合和并发框架源码，能够在日常开发中保证需求完成的同时，还能保持代码的高质量。
   - 2）应用框架方面的原理，也是能研究都尽量研究了，比如 java 写的 Spring、Spring MVC、Spring Boot、Spring Cloud、Dubbo、MyBatis 源码等，对于非 java 写的比如 MySQL、Redis、RabbitMQ、Kafka 的一些常见原理也是有所掌握，能够在日常工作中解决掉突发的线上问题。

##### 3、总

综上，我认为这些原因都能很好的回答这个问题，希望能够得到您的认可。

#### 3.2.1.1. epoll 详解，以及与 select 的区别？

##### 1、总

1. `select`、`poll`、`epoll` 都是 Linux 为 I/O 多路复用模型提供的函数。
2. 其中，I/O多路复用，是指可以通过一种机制，让一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

##### 2、分

###### 1）select

```c++
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

1. `select` 函数监视的文件描述符分 3 类，分别是 `readfds`、`writefds` 和 `exceptfds`。
2. 调用后，`select` 函数会阻塞，直到有描述副就绪（比如有数据 可读、可写、或者有 except），或者超时（`timeout` 指定等待时间，如果立即返回设为 null 即可），则函数返回。
3. 当 `select` 函数返回后，可以通过遍历 `fdset` ，来找到就绪的描述符。

- **优点**：`select` 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
- **缺点**：`select` 的一个缺点是，单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义，甚至重新编译内核的方式来提升这一限制，但是这样也会造成效率的降低。

###### 2）poll

```c++
int poll (struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

- **特点**：
  1. 不同与 `select` 使用三个位图来表示三个 `fdset` 的方式，`poll` 只使用一个 `pollfd` 的指针来实现。
  2. `pollfd` 结构包含了要监视的 event，和 发生的 event，不再使用 `select` “参数-值” 的传递方式。
  3. 同时，`pollfd` 并没有最大数量限制，但数量过大后性能也还是会下降。 
  4. 和 `select` 函数一样，`poll` 返回后，需要轮询 `pollfd` 来获取就绪的描述符。
- **缺点**：
  1. 从上面看，`select` 和 `poll` 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。
  2. 事实上，同时连接的大量客户端，在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

###### 3）epoll

`epoll` 是在 Linux 2.6 内核中提出的，是之前的 `select` 和`poll` 的增强版本。

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

1. 在 `select` / `poll` 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描。
2. 而 `epoll` 事先通过 `epoll_ctl()` 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 `callback` 的回调机制，迅速激活这个文件描述符，当进程调用 `epoll_wait()` 时便得到通知，从而去掉了对文件描述符的遍历操作。

- **优点**：
  1. **监视的描述符数量不受限制**：`epoll` 所支持的 fd 上限，是最大可以打开文件的数目，这个数字一般远大于 2048。比如，在 1GB 内存的机器上大约为10 万左右，具体数目可以 `cat /proc/sys/fs/file-max` 察看，一般来说这个数目和系统内存关系很大。
     - `select` 的最大缺点就是，进程打开的 fd 是有数量限制的，这对于连接数量比较大的服务器来说，根本不能满足。
  2. **I/O 效率不会随着监视 fd 的数量的增长而下降**：`epoll` 不同于 `select` 和 `poll` 轮询的方式，而是通过每个 fd 定义的回调函数来实现的，只有就绪的 fd 才会执行回调函数。
- **局限**：如果没有大量的 idle -connection 或者 dead-connection，`epoll` 的效率并不会比 `select` / `poll` 高很多，但是当遇到大量的 idle- connection，就会发现 `epoll` 的效率大大高于 `select` / `poll`。

##### 3、总

以上，就是我对 select、poll、epoll 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.2. Netty 采用了哪种 I/O 多路复用模式？

##### 1、总

1. Netty 采用的是 Reactor 模式，应用于同步 I/O 的操作。
2. 然后， Reactor 根据实现方式的不同，其线层模型又分为 3 种，分别是单 Reactor 单线程模式、单 Reactor 多线程模式、主从 Reactor 多线程模式，其中，Netty 采用的是主从 Reactor 多线程模式。

##### 2、分

首先是 I/O 设计模式，分为 Reactor 模式和 Proactor 模式，

###### 1）Reactor 模式

Reactor 模式，应用于同步 I/O 场景，以 read 操作为例，Reactor 中的具体步骤为：

1. 应用程序注册 `读就绪` 事件和相关联的事件处理器。
2. 事件分离器等待事件的发生。
3. 当发生 `读就绪` 事件时，事件分离器调用第一步注册的事件处理器。
4. 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理。

![1646831826891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831826891.png)

**Reactor 优点**：

1. 响应快，可以不必被单个同步时间所阻塞，可以最大程度地避免复杂了多线程及同步问题，以及多线程 / 进程切换的开销。
2. 扩展性好，可以方便的通过增加 Reactor 实例个数，来充分利用 CPU 资源。
3. 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

###### 2）Proactor 模式

Reactor 和 Proactor 模式的主要区别就是，真正的读取和写入操作是由谁来完成的，Reactor 中需要应用程序自己读取或者写入数据，而 Proactor 模式中，应用程序不需要进行实际的读写过程，只需要从缓存区读取或者写入即可，操作系统会写入缓存区或者从缓存区读取并写入到真正的 I/O 设备中。

Proactor 模式 read 操作过程为：

1. 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注 `读取就绪` 事件，而是关注 `读完成` 事件，这是区别于 Reactor 的关键点 1。
2. 事件分离器等待 `读完成` 事件。
3. 在事件分离器等待 `读完成` 时，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中，这是区别于 Reactor 的关键点 2，在 Proactor 中，应用程序**需要传递缓存区**。
4. 事件分离器捕获到 `读完成` 事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
5. 而 Proactor 中的 write 操作和 read 操作类似，即感兴趣的事件是 `写完成` 事件。

![1646831843451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831843451.png)

###### 3）单 Reactor 单线程模式

然后，就是 Reactor 第一种线程模型，单 Reactor 单线程模式，

![1646831937063](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831937063.png)

1. `selector.select()` 是多路复用模型 NIO#API ，可以实现一个阻塞对象监听多路的连接请求。
2. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后通过 `dispatch()` 进行分发。
3. 如果是建立连接请求事件，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理连接完成后的后续业务处理。
4. 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应。
5. `Handler` 会完成 `read()` -> `doBusiness()` 业务处理 -> `send()` 一个完整的业务流程。

- **优点**：服务器使用一个线程，通过多路复用搞定所有 I/O 操作（包括连接、读、写等），编码简单，清晰明了，但如果客户端连接数量较多，将无法支撑。
- **缺点**：
  1. **性能问题**：只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上业务时，整个进程无法处理其它连接事件，容易导致性能瓶颈。
  2. **可靠性问题**：线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

###### 4）单 Reactor 多线程模式

![1646889343446](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889343446.png)

1. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后，通过 `dispatch()` 进行分发。
2. 如果是建立连接请求，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理完成连接后的各种事件。
3. 如果不是连接请求，则由 `Reactor` 对象分发调用连接对应的 `Handler` 来处理。
4. 此时，`Handler` 只负责读取和响应事件，不做具体的业务处理，通过 `read()` 读取数据后，会分发给后面的 `Worker` 线程池的某个线程进行处理业务。
5. `Worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `Handler`。
6. `Handler` 收到线程池处理完的结果后，通过 `send()` 将结果返回给 Client。

- **优点**：可以充分利用多核 CPU 的处理能力。
- **缺点**：
  1. 多线程在需要数据共享时，可能实现比较复杂。
  2. Reactor 单线程处理完所有的监听、连接、读、写事件，在高并发场景下，容易出现性能瓶颈。

###### 5）主从 Reactor 多线程模式

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

##### 3、总

因此，总结的话，Reactor 模式线程模型可以比喻为，

| Reactor 线程模型    | 比喻                                           | 优点                                                         | 缺点                           |
| ------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------ |
| 单 Reactor 单线程   | 前台接待员和服务员都是同一个人，全程为顾客服务 | 主线程负责所有的连接、读写、业务处理，编程简单               | 性能问题、可靠性问题           |
| 单 Reactor 多线程   | 1 个前台接待员，多个服务员，接待员只负责接待   | 主线程负责所有的连接、读写，Worker 负责业务处理              | 高并发场景下，容易出现性能瓶颈 |
| 主从 Reactor 多线程 | 多个前台接待员，多个服务生                     | MainReactor 负责连接、SubReactor 负责读写、Worker 负责业务处理，充分发挥多核 CPU 的优势，满足高并发场景 | 编程复杂                       |

=> 以上，就是我对 Netty 多路复用模式 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.3. RocketMQ、Kafka 底层文件原理？

##### 1、总

RocketMQ 消息存储是由 Comsume Queue + Commit Log 配合完成的，Kafka 消息存储是由多 Partition 进行存储的。

##### 2、分

###### RocketMQ

1. 在 RocketMQ 中，所有 Topic 消息都存储在一个称为 Commit Log 的文件中，默认最大为 1GB，超过 1GB 后消息后，就会写到下一个 Commit Log 文件。

2. 通过 CommitLog，RocketMQ 把所有消息存储在一起，以顺序 I/O 的方式写入磁盘，充分利用了磁盘顺序写，减少了 I/O 争用，提高了数据存储的性能。

3. 每个 Consumer 在第一次连接时，都会创建  Consume Queue，一个 Consume Queue 表示 topic#queue，不存储具体的消息，只存储路由到在 CommitLog 中的消息  offset，即具体的消息由 CommitLog 存储。

4. Consumer 在读取消息时，会先读取 Consume Queue，再通过 Consume Queue 中的 offset，读取
   CommitLog，从而得到原始的消息。

   ![1635678882127](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678882127.png)

###### Kafka

1. 在 Kafka 日志文件存储中，同一个 Topic 下会有多个不同的 Partition，每个 Partiton 为一个目录，Partition 是实际物理上的概念，而 Topic 则是逻辑上的概念。
2. 同时，一个 Partition 物理上又被分为多个 Log Segment 组成，Segment 不是一个目录，而是由 3 部分组成，分别为 `.index` 文件、`.timeindex` 文件 和 `.log` 文件，分别表示偏移量索引文件、时间戳索引文件和日志数据文件。
3. 然后，通过二分查找来解决查找效率问题，每个 Partition 被平均分配到多个 Segment 文件，也方便 Old Segment 已消费消息的清理，提高磁盘的利用率。

![1634213772578](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213772578.png)

**如何查找偏移量为 118 的消息**？根据时间戳查找的方式同理。

1. 首先，Kafka 会用一个 `ConcurrentSkipListMap` 跳跃表，来记录每个日志分段，通过它可以根据偏移量 `118` 定位到 Segment 在 00000000000000000000.index 中。
2. 然后，通过**二分查找**在该 `.index` 文件中，找到**不大于 `offset:118`  的最大索引项**，即 `offset:116` 那栏，得到 `position:9679`。
3. 接着，从 `.log` 文件中，物理位置为 `position:9679` 的位置，开始顺序查找 `offset:118` 的消息。

##### 3、总

因此，RocketMQ 与 Kafka 消息存储上的对比总结为：

|          | RocketMQ                                                     | Kafka                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 消息存储 | 将所有消息存储在同一个 CommitLog 中，且 Consume Queue 中只存储20个字节每个消息的位置信息 | 将每个 Partition的消息分开存储                               |
| 影响     | 单个 Broker 能支持更多的 Topic 和 Consume Queue，单机支持最高5w个队列，并且 Load 不会发生明显变化 | 单机超过 64 个 Partition，Load 会发生明显的飙高，发送消息的响应时间变长，但对于少 Partition 场景， 由于利用了 Partition 并行处理，使得此时的写性能高于 RocketMQ |
| 原因     | 所有消息都存储在同一个文件中，使得消息存储是磁盘顺序写       | 将消息按 Partition 存储在不同的文件中，使得整体消息存储是随机写，当 Partition 数量非常大时，会出现很多随机 I/O，导致所有 Broker 性能明显下降 |

=> 以上，就是我对 RocketMQ 和 Kafka 底层文件存储原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.4. ThreadLocal 底层原理？

##### 1、总

1. ThreadLocal，线程本地变量，可以将某个变量放到对象中，使该变量在每个线程中都有专属的引用，不会出现一个线程读取时，被另一个线程修改的现象，从而保证线程安全访问。
2. ThreadLocal，用作**线程隔离**，是解决线程安全问题一个较好的方案，比直接使用同步机制（如 synchronized）解决更简单、更方便、更高效，因为避免了加同步锁带来的性能损失，大大提升了并发性的性能，比如，数据库连接、Session 管理等。
3. 另外，根据 ThreadLocal 的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到，从而可以方便地实现**跨函数的数据传递**，避免通过参数传递数据带来的高耦合。

##### 2、分

其**线程隔离原理**为：

1. ThreadLocal 内部定义了一个静态的  `ThreadLocalMap`，在线程第一次调用 `get()/set()` 方法时，会被构造出来，并由 Thread 实例持有该引用。
2. 然后，ThreadLocal 实例作为 `ThreadLocalMap` 的 Key，也就是只要传入所需的 ThreadLocal 变量的引用，就可以获取到保存在 `ThreadLocalMap` 中对应的值。
3. 从而保证每个线程，即使在获取同一个 `ThreadLocal ` 变量的值时，也能保证值是互相隔离的。

TheadLocalMap#Entry 定义为**弱键的好处**：

1. 比如，线程 t 调用一个 `funcA()` 方法，新建了一个 ThreadLocal 实例 local，然后调用 `local.set()` 方法设置一个 100 后，调用 `local.get()` 方法去获取值。

   ```java
   public void funcA() {
       ThreadLocal<Integer> local = new ThreadLocal<>();
       local.set(100);
       local.get();
   }
   ```

2. 此时的内存结构是，local 被线程 t 强引用，在 `set()` 调用后，线程 t#ThreadLocalMap，会新建一个 Entry 实例，其 Key 以弱引用的方式包装，`WeakReference` 指向 ThreadLocal 实例。

3. 当线程 t 执行完 `funcA()` 方法后，该方法的栈帧会被销毁，栈帧中的 `local` 强引用则会被回收，但如果线程 t 还在继续调用其他方式时，则会导致 t#ThreadLocalMap 中对应的 Entry.Key 引用，还指向 ThreadLocal 实例。

4. 如果 Entry#Key 引用是**强引用**的话，那么就会导致 Key 引用指向的 ThreadLocal 实例以及对应的 Value 值，都不能被 GC 回收，造成内存泄漏的发生。

5. 如果 Entry#Key 引用是**弱引用**的话，那么在下次 GC 发生时就会，让使那些没有被其他强引用指向、仅被Entry#Key 所指向的 ThreadLocal 实例被顺利回收，在 Entry#Key 引用被回收之后，其 Entry#Key 被设置 null，在后续调用 `get()/set()/remove()` 时，ThreadLocalMap 的内部代码就会清除这些 Key 为 null 的 Entry，从而释放对应的内存，避免内存泄露的发生。

**内存泄露**发生的场景：

1. 然而，即使 ThreadLocalMap#Entry 的 Key 被设置为弱键，可以避免内存泄露的发生，但是，如果 ThreadLocal  使用不当的话，还是可能会出现内存泄露。
2. 第一种情况是，**Entry.value 导致的内存泄露**：
   - 1）在`set()` 方法调用后， 假设没 调用 ` get()` 方法，就退出这个  `funA()` 方法，`local` 局部变量被回收后，t#ThreadLocalMap 的 Entry#key 被设置 null。
   - 2）然后，线程 t 继续运行，没有被销毁，也没有调用过任何 `get()/set()/remove()` 方法，导致那一整个 key 为 null 的 Entry 都不会被回收， 导致 Entry.value 内存泄露额度发生。
   - 3）这种现象很容易，发生在线程池中的 Thread 实例中，解决方法是， 只要后续存在任何一个 `get()/set()/remove()` 方法被调用，就会触发 Key为 null 的 Entry 的清理工作，释放掉对应的 Entry 内存，解决 Entry.value 内存泄露的问题。
3. 而第二种情况则是，**static、final 修饰 ThreadLocal 导致的内存泄露**：
   - 1）首先，ThreadLocal 实例被 static 修饰，可以保证每个线程操作这个 ThreadLocal，作为 ThreadLocalMap Entry#key 时，都会共享一份地址空间，节省内存的使用。
   - 2）其次，使用 final 修饰，可以确保 ThreadLocal 实例的唯一性，防止使用过程中发生动态变更。
   - 3）此时，由于修饰后的 ThreadLocal 会以单例的形式存在，一直被 GC Root 强引用，导致引用该 ThreadLocal 实例的 ThreadLocalMap，它的 Entry#Key 在 Thread t 实例的生命周期内，始终会保持为非 null。
   - 4）这样，该 Entry 就不能被 ThreadLocal 自动清空掉，导致其 Value 所指向的对象，一直被 Entry 强引用，于是这个对象就在该线程 t 的生命周期内，一直不会被释放掉，导致内存泄漏的发生。
   - 5）所以，在使用完 static、final 修饰的 ThreadLocal 实例后，要及时调用 `remove()` 来进行显式地释放掉。

##### 3、总

1. 综上，虽然使用 ThreadLocal 可以轻量级地保证变量的线程隔离。

2. 但如果使用不当，就容易发生内存泄漏，如果我们在 ThreadLocal 使用完毕后，及时调用 `remove()` 方法，就可简单、有效地避免这些内存泄漏的情况发生。

   => 这里可以讲一下这个实际案例《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 6）自研 @DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源。

3. 以上，就是我对 ThreadLocal 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.5. HashMap 底层原理？

##### 1、总

HashMap，是 Map 接口的散列表非线程安全形式的实现，可以允许 null 值和 null 键，但不保证元素的顺序，在散列均匀的情况下，`get()/put()/remove()` 方法时间复杂度都是 O（1），当发生哈希冲突时，是通过拉链法来解决，在 JDK 7 中是通过数组 + 链表来实现，在 JDK 8 中是通过数组 + 链表 + 红黑树来实现。

其中，它有几个**重要的参数**：

1. `table.length`：当前散列表的桶容量，初始时默认为 16。

2. `size`：当前 HashMap 的实际大小，等于 Entry 条目总数。

3. `threshold`：HashMap 的阈值，当实际大小超过阈值时，HashMap 会发生扩容为 2 倍的桶容量和阈值，在 JDK 8 中，初始化时 = 默认负载因子 0.75f * 默认桶容量 16 = 12，扩容后超过 Integer.MAX_VALUE 时，等于扩容后的容量 * 设定的负载因子，在 JDK 7 中，初始化和扩容时，都 = 设定的负载因子 * 桶容量。

4. `loadFactor`：HashMap 的负载因子，由于会涉及 HashMap 阈值的计算，所以它是 HashMap 桶容量满意程度的表现，初始时默认为 0.75f，

   - 如果负载因子大于 0.75f，虽然会减少空间的开销，在 JDK 7 中，会导致阈值变大，扩容次数减少，桶拉链变长，增加查找的成本。
   - 如果负载因子小于 0.75f，则会让阈值变小，增加了扩容次数，增大空间的开销，不过好处在于，可以让哈希冲突减少，桶拉链变短，查找效率提高。

   => 所以，0.75f 的负载因子，是 JDK 对 HashMap 在时间和空间成本之间，做的一个很好的权衡取舍。

##### 2、分

在 JDK 8 中，

1. **散列原理**：

   - 1） Key 需要先传入 `hash（Object）` 扰动函数，将 HashCode 右移 16 位，从而混合 HashCode 的高位和低位，加大低位的随机性，减少哈希碰撞发生的概率，是一种性能、效用和质量的折衷方案。
     - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查找效率。
     - HashCode 右移 16 位，使得高位能被利用起来，保证了效用性。
     - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。
   - 2）`（n - 1） & hash` 计算哈希索引，相当于 `hash % n` 取模计算，n 指散列表当前的桶容量，hash 指获取 key#hashCode 扰动后的结果。
     1. 之所以**要取模计算**，不能直接使用 HashCode 作为索引的原因是，hashCode 为 int 类型，范围为[-2^32，2^32 - 1]，如果散列表数组与 HashCode 一一对应，那么就需要 40 亿的空间，明显在内存中是放不下的，所以 hashCode 是不能直接作为数组索引的。而如果使用 hashCode 对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组，也还能利用上 hashCode。
     2. 1）之所以要 n 散列表的桶容量，要取为 **n 的 2 幂次**，原因之一是为了，让 HashMap 在取模计算时，能够通过 n-1，来获得取低位掩码，然后通过低位掩码与扰动后的 hash 值进行一次与运算，即可得到该 hash 值，在散列表数组中的索引。
     3. 2）而另外一个原因是，为了让 HashMap 在扩容时，可通过旧 hash 值与低位掩码相与，只移动少部分与结果高位为 1 的条目，其他条目无需移动，减少了扩容时要搬运的条目数量，减少扩容时间。

2. **条目获取原理**：2 个常用的顶层 API 方法 `get()/getOrDefault()`，都依赖于 `getNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果桶 p 不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的节点，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果 p 没有 next 节点，则返回 null，代表 HashMap 中不存在对应的结点。
     3. 否则，说明 p 节点有 next 节点，如果 p 为红黑树结点，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。
     4. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。

3. **条目添加原理**：3 个常用的顶层 API 方法 `put()/putIfAbsent()/putAll()`，都依赖于 `putVal()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果 p 桶为 null，则直接 new Node 放到该桶即可。
   - 3）如果 p 桶不为 null，则要分为 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果桶头结点 p 为红黑树结点，则使用 `TreeNode#putTreeVal()` 添加 key：value 条目。
     3. 如果 p 为普通链表结点，则遍历 p 桶链表，遍历过程中，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     4. 如果遍历 p 桶链表，没找到对应的结点，则在链尾 new Node 一个结点，且添加后，判断如果当前链表至少有 8 个结点，则调用 `HashMap#treeBin()` 将当前桶链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#HashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）如果发生的不是值替换，则更新修改模数，以及 HashMap 的实际大小，如果实际大小大于阈值，则还需要调用 `resize（）` 进行扩容并转移结点。
   - 5）最后返回 null，代表条目插入成功。

4. **扩容原理**：

   - 1）在添加条目后，判断到实际大小大于阈值时，则会触发 HashMap 的扩容操作。
   - 2）扩容前，正常情况下是，让容量 * 2，阈值 * 2 作为新容量和新阈值，而如果阈值超出了 Integer.MAX_VALUE，则新阈值会被设置为新容量 * 设定的负载因子。
   - 3）然后，根据新容量，创建新数组作为新的散列表： `(Node<K,V>[])new Node[newCap]` 。
   - 4）接着，从头遍历旧的散列表数组，挨个判断桶头节点，或者桶链表：
     1. 如果桶 j 只有一个元素，则重新计算哈希索引，转移元素到新表即可。
     2. 如果桶 j 为红黑树，则调用红黑树的 `TreeNode#split()` 方法，可通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，然后分别判断 lo、hi 链表长度小于等于 6，则退化成普通链表，否则树化为红黑树。这也正是 n 之所以要为 2 幂次的其中一个原因。
     3. 如果桶 j 为普通链表，则通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引。

5. **条目删除原理**：2 个常用的顶层 API 方法 `remove(Object)/remove(Object, Object)`，都依赖于`removeNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果 p 桶不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，则将 p 引用赋值给 node 引用，待后面做删除操作。
     2. 否则，说明在桶头没找到对应的节点，如果桶头结点 p 也没有 next 节点，则将 p 引用赋值给 node 引用，待后面做删除操作。
     3. 否则，说明 p 节点有 next 节点，如果 p 为红黑树结点，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，并将其引用赋值给 node 引用，待后面做删除操作。
     4. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，并将其引用赋值给 node 引用，待后面做删除操作。
     5. 如果找不到，则设置 node 引用为 null。
   - 4）如果 node 引用为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 5）如果 node 引用不为 null，说明找到了对应的结点，如果此时 matchValue 为 true，则还要判断 value 对象 equals，分为 3 种情况判断：
     1. 如果 node 为红黑树结点，则调用 `TreeNode#removeTreeNode()` 删除节点。
     2. 如果 node 为普通结点，且作为桶头，则脱钩 node 节点，并更新 node 后继作为新的桶头。
     3. 如果 node 为普通结点，也不为桶头，则链接它的前驱和后继，脱钩 node 节点。
   - 6）最后，如果脱钩 node 节点成功，则更新修改模数、实际大小，返回 node 节点引用。

6. **红黑树 TreeNode 节点性质**：

   - **性质 1**：红黑树的结点要么是红色，要么是黑色。
   - **性质 2**：红黑树的根结点是黑色的。
   - **性质 3**：红黑树的叶子结点（nil）都是黑色的。
   - **性质 4**：红黑树的红色结点必须有两个黑色结点。
     - 推论：从根结点到每个叶子结点的所有路径上，不可能存在两个连续的红色结点。
   - **性质5**：红黑树是黑色平衡的，即从根结点到每个叶子结点的所有路径中，所经过的黑色结点数都是一样的。
     - 推论：如果一个结点右黑色的子结点，那么该结点一定是有两个孩子结点，因为必须有另一半才能保证该结点黑色平衡。

7. **红黑树旋转原理**：目的是，为了在结点的添加和删除后，避免子树高度发生变化，通过调整树结构，来保证树重新达到平衡。

   - **左旋**：口诀，**左右左右右**，即以 x 结点作为旋转点进行**左**旋，旋转后，x 的**右**结点 p 成为 x 的父结点，p 原本的**左**结点成为 x 结点的**右**结点，p 原本的**右**结点保持不变。
   - **右旋**：口诀，**右左右左左**，即以 x 结点作为旋转点进行**右**旋，旋转后，x 的**左**结点p成为x的父结点，p 原本的**右**结点成为 x 结点的**左**结点，p 原本的**左**结点保持不变。

8. **红黑树节点插入原理**：`putTreeVal（HashMap，Node，int，K，V）`

   - 1）从根结点遍历比较待插入结点 x 的 hash 值，小于等于 0 的，说明 x 应该在左边，大于 0 的说明
     x 应该在右边。
   - 2）找到合适位置后（叶子结点），构建 TreeNode 结点，维护 x 与父结点、prev 前驱结点、next 后继结点的关系。
   - 3）插入后，再平衡红黑树，返回 null，表示插入成功。

   其中，插入后，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：

   - 1）为空结点新增：x 插入后，将成为一个 2 结点，插入前，树为 null，插入后， x 需要变黑色，作为根结点，明显在 HashMap 中，不可能会有这种情况，因为链表长度至少要为 8。
   - 2）合并到 2 结点：x 插入后，将成为一个 3 结点，插入前，2 结点为黑色，插入后无论是（上黑下左红 |  上黑下右红）, 都符合 3 结点要求，因此无需调整。
   - 3）合并到 3 结点中：x 插入后，将成为一个 4 结点，插入前，为 3 结点（上黑下左红 |  上黑下右红），插入后，成为 4 结点（黑红红），其中，根据 x 插入位置的不同，又分为 6 种情况：
     1. x 插入后，为左三(中左 左*) 黑红 红，不符合红黑树定义，需要调整，则中 1 右旋，中 1 变红，左 1 变黑。
     2. x 插入后，为(中左右*)  黑红红，其实就相当于左三，如果对父结点进行左旋，就可得到左三 ，不符合红黑树定义，需要调整，则左 1 左旋（得到左三），中 1 右旋，中 1 变红，新左变黑。
     3. x 插入后，为右三(中 右右*) 黑红红，不符合红黑树定义，需要调整，则中 1 左旋，中 1 变红，右 1 变黑。
     4. x 插入后，为(中 右左*) 黑红红，其实就相当于右三，如果对父结点进行右旋，就可得到右三，不符合红黑树定义，需要调整，则右 1 右旋（得到右三），中 1 左旋，中 1 变红，新右变黑。
     5. x 插入后，为(中左 右*) 黑红 红，符合红黑树定义，因此无需调整。
     6. x 插入后，为(中左* 右) 黑红 红，符合红黑树定义，因此也无需调整。
   - 4）合并到 4 结点中：x 插入后，成为一个裂变状态即升元，插入前，为 4 结点（黑红红），插入后，4 结点需要颜色反转，爷结点成为新的 x 结点，继续下一轮的向上调整，其中，根据 x 插入的位置不同，分为 4 种情况：
     1. x 插入后，为(中左左* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红， 右 1 变黑，中看作为“插入结点”，继续向上调整。
     2. x 插入后，为(中左右* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 保持为红，右 2 变黑，中看作为“插入结点”，继续向上调整。
     3. x 插入后，为(中左 右左*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红，右 1 变黑，中看作为“插入结点”，继续向上调整。
     4. x 插入后，为(中左 右右*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 变黑，右 2 保持为红，中看作为“插入结点”，继续向上调整。

9. **红黑树节点删除原理**：`removeTreeNode（HashMap，Node，boolean）`

   - 1）首选，由于红黑树是一种自平衡的二叉搜索树，而二叉搜索树删除，本质上就是找前驱，或者后继结点来替代删除。

   - 2）如果要删除的结点，是叶子结点，则直接删除即可（肯定是黑色），不过由于是黑色，打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 3）如果要删除的结点，只有 1 个孩子结点，则使用孩子节点进行替代，然后删除"替代"的孩子节点，由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 4）如果要删除的结点，有 2 个孩子结点，则需要找到后继进行替代，然后删除"替代节点"，其中，"替代节点"删除时又要分为 2 种情况：

     1. 如果替代结点，没有孩子结点，说明为 2-3-4 树的 2 结点，则直接选择为"替代结点"进行删除。
     2. 如果替代结点，有孩子结点，且孩子结点为替代方向（后继方向），说明所在的结点为 2-3-4 树的 3 结点或者 4 结点，则选择孩子结点作为"替代结点"进行删除。

     由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   => 其中，删除时，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：`balanceDeletion（TreeNode，TreeNode）` 。

   - 1）x 自己搞得定：

     1. 自己搞得定的意思是，可以在 2-3-4 树节点内部，自己处理完毕，不会影响其他节点的结构。
     2. 对应的情况为，x 要么为 3 结点，要么为 4 结点中的红结点，则直接置黑，返回 x 用作删除即可，因为红节点不会打破黑色平衡。

   - 2）x 自己搞不定，但兄弟搞得定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟搞得定的意思是，兄弟结点存在多余的子结点，即兄弟结点为 3 结点或者 4 结点，这样，x 的父结点，就可以借出结点下来合并到 x 结点，兄弟结点再借出结点合并到父结点，就可以顺利删除 x 了，同时 2-3-4 树的结构还可以保持不变。
     3. 但是，前提是 x 的兄弟结点是真正的兄弟结点，即为黑色的结点，如果为红色的结点，说明其只是父结点（3结点）的红结点，此时还需要对父结点进行旋转，以保证 x 有真正的兄弟结点。

     此时，根据情况又分为 3 种情况：比如 x 为左边时，右边情况同理。

     1. 兄弟结点为 3 结点，同时有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右孩子，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点），xpr 借出去的结点颜色为 xp 借出去的结点颜色，xp 借出去的结点颜色一定要为黑色（相当于3结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。
     2. 兄弟结点为 3 结点，但没有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 没右孩子，不能直接对父结点进行左旋，所以，这是一个临时情况，需要对 xpr 进行右旋，转换为有右孩子的情况一，再做一的相同处理即可。
     3. 兄弟结点为 4 结点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点，而且还多借出左孩子合并到 x 结点中，这里选择借出 2 个结点，可以进一步减少花销），xpr 合并到父结点的颜色为 xp 借出去的结点颜色（而借出去的左孩子本来为红色所以不用变），xp 借出去的结点颜色一定要为黑色（相当于 4 结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。

   - 3）x 自己搞不定，并且兄弟也搞不定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟也搞不定的意思是，兄弟结点也为黑结点，没有多余的子结点，如果直接删除 x，则会导致叔结点所在路径多了一个黑色结点，造成黑色不平衡。

     1. 这种情况是，兄弟结点为 2 结点，为了让 x 能够顺利删除，兄弟结点需要置红（自损），这样 x 在删除后，x 父结点所在树还是黑色平衡的。
     2. 但是，如果 x 父结点为黑色，x 爷结点所在树则不黑色平衡了，因为父结点这边少了一个黑色结点，所以，父结点的叔结点要也要被置红。
     3. 因此，需要一路向上自损，直到碰到任意一个终止条件，即可结束自损：
        - **向上碰到根结点**：经过一路置红叔结点，直到循环到根结点时（因为上面已经没有父节点了），则代表自损完毕，此时整棵树都是黑色平衡的了（都减少了一个黑色结点）。
        - **向上碰到红结点**：如果碰到红色结点，只需要把该结点置黑，无需再置红叔结点了，相当于在父结点这边子树补回了一个黑色结点，不影响这边子树的黑色结点数目，整棵树还是黑色平衡的。

10. **红黑树节点获取原理**：`getTreeNode（int，Object）`

    - 1）根据 hash 值和 key 值，从根结点开始查找红黑树结点，小于等于 0 的，说明 x 应该在左边，大于 0 的，说明 x 应该在右边。
    - 2）直到找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，说明该结点就是要找的结点，则直接返回即可。
    - 3）如果找不到，则返回 null，代表没找到对应的结点。

11. **链表树化成红黑树**：`HashMap#treeifyBin()`

    - 1）先判断桶容量，是否大于等于 64，如果不是，则调用 `resize()` 扩容即可。
    - 2）如果确实大于等于 64，则先挨个维护每个桶的链表，为双向无环链表。
    - 3）接着，调用 `TreeNode#treeify` 树化该链表成为红黑树，其步骤为：
      1. 取桶头结点作为根结点，置黑。
      2. 然后遍历桶链表，比较根结点 hash 值与当前遍历结点的 hash 值，小于等于的，则继续遍历左子树，大于的，则遍历右子树，然后插入当前遍历结点到对应的位置，再平衡红黑树。
    - 4）直到散列表所有桶、每个桶的链表结点遍历完毕，再返回。

12. **红黑树退化成普通链表**：`untreeify（HashMap）`

    - 1）遍历桶链表，重新构建为 `next=null` 的 Node 结点。
    - 2）再重新维护每个它的 next 指针。
    - 3）直到遍历结束，最后返回链头指针 hd 即可。

##### 3、总

相对于 JDK 7#HashMap，JDK 8 主要优化了以下 3 点：

1. **引用红黑树**：避免链表过长影响查找效率，同时还可以保证插入性能。
2. **`resize()` 扩容优化** 以及**头插法改成尾插法** ：取消了 rehash 操作，通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，以及由于头插法会使得结点转移后节点倒序，改用头插法改成尾插法，可以保证转移后，链表结点的相对顺序不变，从而解决了并发情况下扩容导致的死循环问题。

但 HashMap 仍是非线程安全的，并发下添加结点，可能会造成数据丢失，而线程安全的 Map 使用方式有：

1. **在 HashMap API 外层使用锁，**来保证线程安全。
2. **使用 Collections 内部类 SynchronizedMap**：底层原理是，通过持有传入的 Map 引用，以及 `mutex` 对象锁，使用 synchronized 关键字来修饰 Map 方法，从而包装成线程安全的 Map 实现类。
3. **使用 HashTable**：散列表线程安全的实现类，默认初始容量 11，默认负载因子 0.75f，不允许为 null 键和null 值，底层通过使用 synchronized 关键字修饰方法，来保证线程安全，所以效率低下。
4. **使用 ConcurrentHashMap**：支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可以在保持并发可读的同时，还能最小化锁争用。

=> 以上，就是我对 HashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.6. ConcurrentHashMap 底层原理？

##### 1、总

ConcurrentHashMap，支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可在保持并发可读的同时，还能最小化锁争用。

其中，它有几个**重要的参数**：

1. `table`：当前正在使用的散列表，volatile 修饰，具有并发可见性。
2. `nextTable`：并发扩容时，持有的另外一个散列表，volatile 修饰，具有并发可见性。
3. `sizeCtl`：ConcurrentHashMap 的控制变量，volatile 修饰，具有并发可见性，提供 `SIZECTL` 通过 CAS 进行原子性更新。
   - 1）在构造函数中为（1.5 倍指定容量 + 1，或者指定容量 / 负载因子）的最小 2 幂次。
   - 2）当分布式计数统计结果，大于 `sizeCtl` 时，则触发并发扩容机制，高 16 位为扩容标记，低 16 位为并发扩容线程数（步长为 1，然后再每有一个线程参与协助扩容则 +1）。
   - 3）在扩容完成后，等于 0.75f * 旧表桶容量，作为下一次扩容的阈值判断条件。

几种重要的**结点类型**：

1. `Node`：实现 Map.Entry，是 ConcurrentHashMap 中最普通的链表结点，拥有 hash、key、val、next 成员变量，是其他类型结点的父类，其中 val 和 next 使用 volatile 修饰，保证了并发可见性。
2. `TreeNode`：继承 Node 结点，是 ConcurrentHashMap 中的红黑树结点，在 Node 结点的基础上，还维护了parent、left、right、red 红黑树成员变量。
3. `TreeBins`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中红黑树的桶头结点，hash 值为-2，持有红黑树根结点root 指针和链头 first 指针，不保存键和值。
   - 2）同时还维护了读写锁，强迫写线程必须等待所有读线程完成后，才能进行红黑树结点操作。
   - 3）当读时不存在并发写线程，使用 root 指针走红黑树遍历方式查找结点，当读时存在并发写线程，使用first 指针走链表遍历方式去查找结点。
4. `ForwardingNode`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中的转发结点，hash 值为 -1，持有 nextTable 引用，没有键和值。
   - 2）在线程协助转移结点到新表后，会在旧表原位置维护一个 `Forwarding` 结点，以标识旧表正在发生扩容操作，让下一个线程碰到时，可以协助进行转移旧表结点。

##### 2、分

在 JDK 8 中，

1. **散列原理**：原理与 HashMap 类似，但不同的地方在于，HashMap 的扰动函数叫 `hash(Object)`，而 ConcurrentHashMap 的扰动函数叫 `spread（Object）` 。

2. **条目获取原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）`getOrDefault()`，依赖于 `get()` 方法，其中 val 和 next 使用 volatile 修饰，保证线程可见性，所以，`get()` 方法可以不加锁地照常遍历，而在读红黑树时，由于并发更新需要涉及到旋转，所以有写时会走链表方式去读，在树方式读时，不能并发下对红黑树进行写。
   - 2）因此，可与 `put()` 和 `remove()` 等更新方法同时执行，但反映的只是，最近完成更新的结果，并发检索可能只反映出部分条目的更新。

3. **条目添加原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p 为null，new Node 以后是通过 CAS 的方式放入到散列表中的。
   - 2）然后，如果桶 p 不为 null，还要判断是否为 `Forwardding` 节点（p#hash = -2），如果是的话，则当前线程要参与协助扩容。
   - 3）然后，如果桶 p 也不为 `Forwardding` 节点，那么还会对其加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果桶 p#hash 值小于 0，说明 p 为红黑树，则使用 `TreeBin#putTreeVal()` 添加 key：value 条目。
     2. 如果桶 p#hash 值大于等于 0，说明为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent为false，则发生值替换，直接返回即可。
     3. 如果没找到对应的结点，则在链尾直接 new Node 一个结点。
     4. 如果添加后，当前链表至少有 8 个结点，则调用 `ConcurrentHashMap#treeBin()`，将当前链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#ConcurrentHashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）最后，如果发生的不是值替换，而是条目插入，还要并发分布式计数，然后判断是否需要扩容，要的话则发起扩容。，返回 null，代表结点插入成功。

4. **条目删除原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p，为 `Forwardding` 节点，则当前线程要参与协助扩容。
   - 2）如果 p 不为 `Forwardding` 结点，则会对 p 进行加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果 p#hash 小于 0，说明 p 为红黑树，则调用 `TreeNode#getTreeNode()`，来获取 hash 和 key 对应的结点，调用 `TreeNode#removeTreeNode()` 删除该结点。
     2. 如果 p#hash 值大于等于0，说明它为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，则脱钩该结点。
     3. 如果没找到对应的结点，则返回 null，代表 ConcurrentHashMap 不存在对应的结点。
   - 3）最后，如果脱钩结点成功，则还要并发分布式计数，返回旧值，代表删除成功。

5. **分布式计数相关变量**：

   - 1）`baseCount`：分布式计数基数，volatile 修饰，具有并发可见性，提供 `BASECOUNT` 通过 CAS 进行原子性更新。
   - 2）`counterCells`：分布计数单元格数组，volatile 修饰，具有并发可见性，提供 `CELLVALUE` 通过 CAS 进行原子性更新。
   - 3）`cellsBusy`：分布式计数单元格繁忙标记，volatile 修饰，具有并发可见性，提供 `CELLSBUSY` 通过 CAS 进行原子性更新。

   => 在要获取 ConcurrentHashMap 实际大小 `sumCount()`  时，可以通过 `baseCount` + 累加 `counterCells` 数组所有格子的值，得到一个瞬时的累加和作为实际大小。

6. **并发分布式计数原理**：在 `putVal()` 和 `removeNode()` 方法更新玩后，还需要并发叠加 `x=1/-1`，叠加成功后，获取瞬时的累加和作为实际大小，用于扩容判断，其步骤为：

   - 1）先尝试在 `baseCount` 叠加 x，如果叠加成功，则继续做扩容判断。
   - 2）如果 `baseCount` 叠加 x 失败，则根据当前线程随机值 `h=ThreadLocalRandom.getProbe()`，尝试在 `CounterCell[h * (n-1)]` 叠加 x，如果叠加成功，则做扩容判断。
   - 3）如果 `CountCell` 叠加 x 失败，则调用 `fullAddCount()` 自旋 + CAS 竞争添加 x 到 `CounterCell[] as` 中。

7. **并发扩容原理**：

   - 1）如果 `sumCount()` 获取到的瞬时累加和，大于 `sizeCtl` ，说明需要扩容，则启动扩容机制，调用 `resizeStamp（n）` 生成扩容标记 `rs`，保证扩容过程不会被重复启动。
   - 2）如果 rs 大于等于 0，说明散列表还没被扩容，则 CAS 更新 `sizeCtrl=(rs << RESIZE_STAMP_SHIFT) + 2)`，更新成功后，rs 为一个负数，再第一次调用 `transfer(tab, null)`，开始扩容创建 2 倍旧表容量的 nextTab，并开始转移旧表结点到新表。
   - 3）如果 rs 小于 0，说明散列表正在被其他线程扩容，则 CAS 更新并发扩容线程数 `sizeCtrl=sc+1`，更新成功后调用 `transfer(tab, nt)`，加入扩容一起转移旧表结点到新表。
   - 4）其中，在某个桶结点被转移后，会在旧表中留下一个 `Forwardding` 节点，其他线程在调用`put()/remove()` 时，如果遇到这种节点，则会根据它持有的 `nextTab`，参与协助扩容。
   - 5）最后，`transfer()` 中会根据 `(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT` 来判断，当前转移线程是否为最后一个扩容线程，如果是的话，则会提交新散列表，正式把 `nextTab` 设置为 `table`，然后设置 `sizeCtl` 为 0.75f * 旧表桶容量（作为下一次扩容的阈值判断条件）才返回，返回后还要自旋判断一次是否需要再次扩容，防止并发情况下桶容量又不够的情况。

8. **红黑树线程安全原理**：

   - 1）ConcurrentHashMap 的红黑树过程与 HashMap 类似，但不同的地方在于，由于并发更新时，红黑树可能会涉及到旋转，TreeBin 维护了一个读写锁，在调用 `TreeBin#putTreeVal()` 或者 `TreeBin#removeTreeNode()` 方法时，即使外层有获取可重入锁 synchronized，在操作红黑树之前，也要调用 `lockRoot()`，调用完成后再 `unlockRoot()`，保证写时走链式读，走树读时不能写。
   - 2）其原理如下：
     1. TreeBin 持有 lockState 属性，值有读、等待写、以及写状态（WRITER=1，WAITER=2，READER=4，读/写状态可与等待状态结合）。
     2. 调用 `lockRoot()` 时，CAS 竞争更新 lockState 为 `WRITER`，竞争成功，说明当前线程持有写锁成功，可以继续做红黑树操作，操作完后 `unlockRoot` 释放写锁，置 lockState 为 0。
     3. 竞争失败，则调用 `contendedLock()` 继续争抢写锁，争抢不到则会进入阻塞状态，直到所有调用`TreeBin#find(int，Object)` 的线程，都调用完毕后，才会被唤醒，然后重新争抢写锁。

##### 3、总

相对于 JDK 7#ConcurrentHashMap，JDK 8 主要优化了以下 3 点：

1. **数据结构**：取消 Segment[] + HashEntry[] + 链表的数据结构，改用 Node[] + 链表 + 红黑树的数据结构，提升查找效率。
2. **线程安全方式**：取消了 Segment#ReentrantLock 分段锁保证线程安全的方式，改用 Node + CAS 自旋锁+ synchronized 锁定桶结点 + TreeBin 读写锁的方式，来保证并发安全，进一步提高并发量。
3. **扩容方式**：取消了获取锁再做计数 + 扩容的方式，改用释放 synchronized 同步锁，利用 CAS 自旋锁 + 并发分布式计数 + 并发扩容的方式，支持更高的并发更新与查询。

=> 以上，就是我对 ConcurrentHashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 3.2.1.7. 红黑树性能稳定吗？

经过大量实验证明，红黑树可以保证，在最好甚至最坏情况下，所有操作（插入/删除/查找等）的时间复杂度，都是对数级别 O（logN），无论插入顺序如何，红黑树都是接近完美平衡的，其操作成本（包括旋转和变色），比 BST 降低 40% 左右。

![1647876146340](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647876146340.png)

=> 因此，红黑树性能是稳定的，任何时间复杂度都为 O（logn）级别。

#### 3.2.1.8. 设计模式有了解哪些？线程池这种是什么设计模式？

##### 1、总

我了解过单例、工厂、建造者、观察者、装饰者、代理、责任链这几个常用的设计模式。

##### 2、分

1. **单例**：某个类只能生成一个实例，该实例被全局访问，比如 Spring 容器一级缓存里的单例池。

   - 实现方式：饿汉式、懒汉式、**双重检查锁、静态内部类、枚举类**等多种实现方式。

2. **工厂**：工厂中最简单实用的模式，简单工厂模式，可以理解为是不同工厂模式的一个特殊实现，比如 Spring 中的 BeanFactory、ApplicationContext。

   实现方式：

   - 简单工厂，是由一个工厂同一个方法来创建多个产品实例。
   - 工厂方法，则是对工厂做了抽象，做到一个产品一个工厂。
   - 抽象工厂，则是一个工厂提供多个创建接口，分别创建不同的产品实例。

3. **建造者**：可以将一个复杂对象的构造与他的表示分离，使同样的构建过程可以创建不同的表示，比如 SpringCloud 中的 FeignClientBuilder。

   - 建造者关注的是组装过程，类似于组装车间，工厂关注的是创建过程，类似于生产车间。

4. **观察者**：在被观察者本身的状态改变时，主动发出通知，呼叫各观察者所提供的方法走对应的实现，比如 Spring 中的各种 ApplicationContextEvent 和 ApplicationListener，Dubbo 中的 InvokerListener、ExporterListener。

5. **装饰者**：通过创建一个包装对象，也就是用包裹真实的对象，在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能，比如 JDK#I/O 中的处理流和节点流 。

6. **代理**：为其他对象提供一种代理，在前后织入业务代理，以增强原始对象，比如 JDK 动态代理，Spring AOP 中的 CGLIB 动态代理，Dubbo 中的 Javassist 动态代理。

   - 静态代理：静态代理，是由程序员创建或者工具生成代理类的源码，再在编译生成代理类。所谓静态，也就是程序运行前就已经存在代理类的字节码文件，这时代理类和委托了类的关系在运行前就确定了。
   - 动态代理：动态代理在实现阶段不用关心代理类，而在运行阶段才指定哪一个对象。

7. **责任链**：通过持有下一个实现类的引用，进行链式调用，比如 Web 中的 Filter、Spring Cloud 中的 GatewayFilter、Dubbo 中的 ProtocolFilterWrapper。

8. **适配器**：定义一个包装类，用来包装不兼容接口的对象，把一个类的接口，转换成所期待的另一种接口，从而使原本接口不匹配、无法工作的两个类能够一起工作。

##### 3、总

1. 线程池这种属于享元模式。
2. 享元模式，Flyweight Pattern，会尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象，主要用于减少创建对象的数量，以减少内存占用和提高性能。
3. 比如还有数据库连接池、Http 连接池等。

=> 以上，就是我对 设计模式 的一些理解，请问有什么细节需要补充的吗？

#### 3.2.1.9. 动态代理实现原理，如果给你实现的话你会怎么做？

##### 1、总

对于我阅读过源码的动态代理有，JDK 动态代理和 CGLIB 动态代理。

##### 2、分

###### 1）JDK 动态代理

1. **条件**：JDK 动态代理，需要提供接口。
2. **使用方式**：
   - 1）实现 `InvocationHandler` 接口，并重写 `invoke()`，在反射调用前后，编写需要代理的业务逻辑。
   - 2）通过 `Proxy.newProxyInstance(..)` 方法，来获取动态代理对象，其**方法参数**有：
     - `ClassLoader loader`：动态代理类的类加载器，一般取原委托类的类加载器。
     - `Class<?>[] interfaces`：原委托类实现的接口 Class 对象数组。
     - `InvocationHandler`：动态代理处理程序，在调用动态代理类的增强方法时，会触发回调到它的 `invoker()` 方法。
3. **实现原理**：
   - 1）`newProxyInstance()` 通过反射，生成含有接口方法的 `$Proxy0` 代理类，`$Proxy0` 继承了 `Proxy` 类。
   - 2）在 `$Proxy0` 的构造方法中，会先调用父类的构造方法，让 `Proxy` 父类持有 `InvocationHandler` 实现类的引用。
   - 3）最后，该代理对象的所有方法，都会转发调用到，父类持有的 `InvocationHandler#invoke()` 方法。
   - 4）`InvocationHandler#invoke()`：该方法会传入原始方法的 Method 对象，用于反射调用原始方法。
   - 5）这样，只需要在反射调用前后，编写需要代理的业务逻辑，即可增强原始方法，实现动态代理。

```java
public interface MessageService { 
    void sendMessage(); 
}

public class MessageServiceImpl implements MessageService {
    public void sendMessage() {
        System.out.println("MessageServiceImpl.sendMessage"); 
    } 
}

public class JdkProxy<T> implements InvocationHandler {

    T target;

    public T getProxy(T target) {
        this.target = target;

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理拦截开始！");
        Object result =  method.invoke(target, args);
        System.out.println("JDK动态代理拦截结束！");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        JdkProxy<MessageService> jdkProxy = new JdkProxy();
        MessageService messageService = jdkProxy.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

###### 2）CGLIB 动态代理

1. **条件**：CGLIB 动态代理，无需提供接口，即可实现，当然，也可以代理有接口的原委托类。
2. **使用方式**：
   - 1）实现一个 `MethodInterceptor`：代理方法调用时，会被转发到该类的 `intercept()` 方法。
   - 2）构建 `net.sf.cglib.proxy.Enhacner`：通过 `setSuperClass(Class)` 指定原委托类，`setCallback(Class)` 指定当前 `MethodInterceptor` 实现类 。
   - 3）最后，通过调用 `(T) enhancer.create()` 方法，获取代理对象。
3. **实现原理**：
   - 1）利用 ASM 开源包，通过修改原委托类 Class 文件的字节码，生成子类，覆盖原委托类的方法，并在覆盖方法中实现了增强。
   - 2）在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理。

```java
public class PlayService {
    public void play() {
        System.out.println("PlayService.play");
    }
}

public class CglibProxy<T> implements MethodInterceptor {

    T target;

    public T getProxy(T target) {
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return (T) enhancer.create();
    }

    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理拦截开始!");
        Object result = methodProxy.invokeSuper(o, objects);
        System.out.println("CGLIB动态代理拦截结束!");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        CglibProxy<PlayService> cglibProxy = new CglibProxy();
        
        // 测试代理无接口服务类
        PlayService playService = cglibProxy.getProxy(new PlayService());
        playService.play();
		
        // 测试代理有接口服务类
        CglibProxy<MessageService> cglibProxy1 = new CglibProxy(); 
        MessageService messageService = cglibProxy1.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

##### 3、总

因此，总的来说，

1. JDK 动态代理，是在调用代理类方法时，通过调用 `InvocationHandler#invoke()`，再反射调用原始方法，从而实现动态代理，属于反射调用，会存在一定的性能花销。
2. CGLIB 动态代理，是在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理，属于父类方法调用，在初次调用时，由于需要生成 FastClass，效率会比较低，但在 FastClass 生成后，往后访问由于不用涉及反射调用，此时性能花销非常小。

=> 以上，就是我对 动态代理 的一些理解，CGLIB 动态代理类生成的具体细节也不太记得了~

#### 3.2.2.0. 线上 CPU 100% 如何解决？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%。

#### 3.2.2.1. Redis 哨兵模式和集群模式的区别？

##### 1、总

Redis 支持三种集群架构，分别是主从模式、哨兵模式、集群模式。

##### 2、分

###### 1）主从模式 | 无高可用、简单

将哨兵模式之前，就需要先介绍一下主从模式~

![1632299571516](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632299571516.png)

1. **是什么**：

   - 1）只是简单地使用了主从复制，一个 Master 可以有多个 Slave，Slave 也可以有自己的 Slave。
   - 2）默认使用异步复制， Slave 会以每秒 1 次的频率，向 Master 报告当前复制流的处理进度。
   - 3）复制时，不会阻塞 Master，即使是正在进行初次同步， Master 也可以继续处理命令请求，也不会阻塞 Slave，即使 Slave 正在进行初次同步， 也可以使用旧版本的数据集来处理命令查询。
   - 4）同时，还支持读写分离模式，Master 负责读写，Slave 只负责读。

2. **怎么配置**：

   ```shell
   # Slave方参数
   # 1、配置主从复制Master的IP+端口
   slaveof <masterip> <masterport>
   # 2、如果Master通过requirepass配置密码，则Slave也需要进行相应的配置
   masterauth <master-password>
   # 3、默认允许，Slave初次同步未完成时，继续使用旧数据来响应客户端，配置no会阻塞初次同步期间的所有请求
   slave-serve-stale-data yes
   # 4、默认开启读写分离，Slave只能读取数据，不能写入数据
   slave-read-only yes
   
   # Master方参数
   # 5、默认关闭无磁盘化复制，Master磁盘不生成RDB文件，直接通过网络同步给Slave
   repl-diskless-sync no
   # 6、默认为3和10，如果至少有3个从服务器，并且这3服务器的延迟值都少于10秒，Master才会执行客户端请求的写操作
   # min-slaves-to-write 3
   # min-slaves-max-lag 10
   ```

3. **实现原理**：

   - 1）当建立一个 Slave 时， Slave 会向 Master 发送一个 `PSYNC master_run_id offset` 命令。
   - 2）如果 Slave 是首次连接，由于 Master 中不存在该 Slave 的复制偏移量，所以会触发一次完整重同步操作， 此时，Master 开始执行 `BGSAVE`， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。
   - 3）当 Master  `BGSAVE` 执行完毕后， Master 将执行保存操作所得的 .rdb 文件发送给 Slave， Slave 接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
   - 4）之后，Master 会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给 Slave，Slave 则实时同步这些数据。
   - 5）如果主从复制期间 Slave 断开连接，在自动重连后，会使用 `PSYNC master_run_id offset` 命令来进行同步，Master 会以增量复制的形式，向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。

   重连后的**部分重同步原理**：

   - 1）Master 会为被发送的复制流创建一个缓冲区 `in-memory backlog`， 并且 Master 和所有 Slave 之间都记录一个复制偏移量 `replication offset` 和一个主服务器 ID `master run id`。
   - 2）当出现网络连接断开时， Slave 重新连接后，会向 Master 请求继续执行原来的复制进程。
   - 3）如果 Slave 记录的主服务器 ID `master run id` ，和当前要连接的主服务器 ID `master run id` 相同， 并且 Slave 记录的偏移量 `replication offset` 所指定的数据，仍然保存在 Master 的复制流缓冲区 `in-memory backlog` 里面， 那么 Master 会向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
   - 4）否则，Slave 就要执行完整重同步操作。

4. **优点**：

   - 1）**部署简单**：仅使用两个节点，即可构成主从模式。
   - 2）**可以通过读写分离**：来避免读和写同时不可用的情况。

5. **缺点**：

   - 1）**无高可用保证**：一旦 Master 节点出现故障，主从节点就无法自动切换，直接导致 SLA 服务等级下降。
     - **解决方案**：添加哨兵监控。
   - 2）**Master 压力大**：所有的 Slave 节点数据的复制和同步，都由 Master 节点来处理，会造成 Master 节点压力过大。
     - **解决方案**：可以使用主从从的结构，通过引入从从同步，可以减少主从同步的次数。

6. **适用场景**：一般用于业务发展初期、并发量低、运维成本低的情况。

###### 2）哨兵模式 | 高可用、读多

![1632320226337](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632320226337.png)

1. **是什么**：Sentinel，哨兵，是 Redis 高可用的一种解决方案，可以监视一个或者多个 Redis Master 服务，以及其所有的从服务，当某个 Master 服务宕机后，会自动把这个 Master 下的某个从服务升级为 Master，从而代替已宕机的 Master，保证继续工作。

   Sentinel 的作用有：

   - 1）**监控**：Monitoring，Sentinel 会不断地检查 Master 和 Slave 是否运作正常。
   - 2）**提醒**：Notification，当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
   - 3）**自动故障迁移**：Automatic failover。当一个 Master 不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效 Master 的其中一个 Slave 升级为新的 Master， 并且让失效 Master 的其他 Slave 改为复制新的 Master。当客户端试图连接失效的 Master 时， 集群也会向客户端返回新 Master 的地址， 使得集群可以使用新 Master 代替失效 Master。

2. **怎么配置**：

   ```shell
   # 1、配置监控 127.0.0.1：6379 的 mymaster 服务器，并且客观下线需要取得2个(quorum)哨兵的同意，但是无论该值配置了多少，都需要多数哨兵的选举后，才能发起一次自动故障转移
   sentinel monitor mymaster 127.0.0.1 6379 2
   # 2、配置Master服务器密码（如果Master有配置的话）
   sentinel auth-pass <master-name> <password>
   # 3、配置判定mymaster主观下线的毫秒数
   sentinel down-after-milliseconds mymaster 60000
   # 4、配置主从切换的超时时间，需要自动故障转移时，如果当前哨兵没有去执行，那么在超过这个时间后，会由其他的哨兵来进行处理
   sentinel failover-timeout mymaster 180000
   # 5、配置在执行故障转移时，同步新mymaster的最大Slave并行数，如果全部Slave一起对新Master进行同步，由于在Slave载入RDB时会阻塞客户端请求，所以可能会造成所有Slave在短时间内全部不可用的情况出现
   sentinel parallel-syncs mymaster 1
   
   # 启动命令
   # 6、运行纯Sentinel服务器
   redis-sentinel /path/to/sentinel.conf
   # 7、在Redis Server上运行哨兵
   redis-server /path/to/sentinel.conf --sentinel
   
   # 运维命令
   # 8、查看imooc-master下的master节点信息
   sentinel master imooc-master
   # 9、查看imooc-master下的slaves节点信息
   sentinel slaves imooc-master
   # 10、查看imooc-master下的哨兵节点信息
   sentinel sentinels imooc-master
   ```

3. **Sentinel 自动发现原理**：

   - 1）一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换，通过发布与订阅功能，向频道 `__sentinel__:hello` 发送信息，来自动发现正在监视相同 Master 的其他 Sentinel ，无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址。
   - 2）**发布**：每个 Sentinel 会以 2 次 / s 的频率， 通过发布与订阅功能， 向被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道发送一条信息， 信息中包含了 Sentinel 的 IP、端口和运行 ID `runid`，还包括完整的 Master 当前配置。如果一个 Sentinel 包含的 Master 配置，比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。
   - 3）**订阅**：每个 Sentinel 都订阅了被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道， 查找之前未出现过的 Sentinel，当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了已知的、正在监视同一个 Master 的所有其他 Sentinel 。

4. **故障判定原理**：

   - 1）Sentinel 会以 1 次 / s的频率，向它所知的 Master、Slave、以及其他 Sentinel 实例，发送一个 `PING` 命令。
   - 2）如果某个实例距离最后一次有效回复 `PING` 命令的时间，超过了 `down-after-milliseconds` 的值， 那么这个实例会被 Sentinel 标记为**主观下线**。 
   - 3）如果一个 Master 被标记为主观下线， 那么正在监视这个 Master 的所有 Sentinel，都要以 1 次 / s 的频率，确认Master 是否真的进入了主观下线状态。
   - 4）当 Master 重新向 Sentinel 的 `PING` 命令，返回有效回复时，Master 的主观下线状态就会被移除。
   - 5）否则，如果有足够数量（>= `quorum` ）的 Sentinel，在指定的时间范围内，同意这一判断， 那么这个主服务器被标记为**客观下线**。
   - 6）而当没有足够数量（>= `quorum` ）的 Sentinel 同意主服务器已经下线， Master 的客观下线状态就会被移除。

   **主观下线**：

   - 1）主观下线，Subjectively Down， 简称 SDOWN，指的是单个 Sentinel 实例，对超时服务实例做出的判断。
   - 2）只有一个 Sentinel 认为是主观下线时，并不一定会引起服务实例的故障迁移，只有在足够数量（>= `quorum` ）的 Sentinel 都将一个服务实例标记为主观下线之后， 服务器才会被标记为**客观下线**， 此时自动故障迁移才会执行。

   **客观下线**：

   - 1）客观下线，Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对同一个服务实例做出 SDOWN 判断， 并且在经过通过  `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务实例下线判断。
   - 2）客观下线条件只适用于 Master，对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以  Slave 或者其他 Sentinel 永远不会达到客观下线的条件。
   - 3）只要 Sentinel 发现某个 Master 进入了客观下线状态，某个 Sentinel 会被其他 Sentinel 推选出， 并对失效的 Master 执行**自动故障迁移**操作。

5. **自动故障转移原理**：

   - 1）**Leader Sentinel 选举**：当一个 Master 被判定为**客观下线**后，监视这个 Master 的所有Sentinel会通过 `Raft` 选举算法，选出一个 Leader Sentinel 去执行故障转移 `failover` 操作。
   - 2）**Master 重新选择**：当选举出 Leader Sentinel 后，Leader Sentinel 会根据以下规则，在失效 Master 属下的 Slave 当中，选择出新的 Master：
     1. 先淘汰主观下线 | 已断线 | 最后一次回复 `PING` 命令时间大于5秒钟 | 与失效 Master 断开连接时长超过 10 倍主观判断时长 `down-after-milliseconds` 的 Slave 节点。
     2. 选择配置 `slave-priority` 最高的 Slave 节点，如果没有，则继续选择。
     3. 选择复制偏移量 `replication offset` 最大的 Slave 节点，复制偏移量越大，说明数据复制的越完整。
     4. 如果复制偏移量不可用，或者 Slave 的复制偏移量相同， 则选择运行 ID `run_id` 最小的 Slave 节点，`run_id` 越小，说明重启次数越少。
   - 3）**故障转移流程**：
     1. Leader Sentinel  则根据 Master 选择规则，选出一个 Slave，向其发送 `SLAVEOF NO ONE` 命令，让它转变为 Master。
     2. 然后， Leader Sentinel 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel，让其他 Sentinel 对它们自己的配置进行更新。
     3. 接着， Leader Sentinel 会向已下线 Master 的其他 Slave，发送 `SLAVEOF host port` 命令， 让它们去复制新的 Master。
     4. 最后，当所有 Slave 都已经开始复制新的 Master 时， Leader Sentinel 则结束这次故障迁移操作。

6. **优点**：监控、提醒、自动故障转移，从而实现 Redis 的高可用。

7. **缺点**：如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

8. **适用场景**：适合读远多于写的业务场景，比如在秒杀系统中，用来缓存活动信息。

###### 3）集群模式 | 高可用、写多

![1632464692288](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632464692288.png)

1. **是什么**：

   - 1）Redis Cluster，是 Redis 3.0 版本之后推出的高可用实现。
   - 2）采用哈希虚拟槽的数据分区方案，把 key 分布到各个 Master 节点上，每个 Master 还可以跟若干个 Slave 做主从切换。
   - 3）由于做了数据分区，使用的功能，也就只是普通单机 Redis 所有功能的一个子集，比如不支持同时使用多个键的 Redis 命令、不支持多数据库只能适用 0 号数据库。
   - 4）路由方面，客户端可以连接任意 Master 节点，集群内部会按照不同的 key，告诉客户端，把请求转发到其他 Master 节点，同时让请求成功的客户端，还会缓存对应的映射关系，以提高下次集群访问的查询效率。

2. **怎么配置**：

   ```shell
   # 1、开启集群模式
   cluster-enabled yes
   # 2、每一个节点都需要有这么一个配置文件，3主3从则一共需要6份，用于存储集群模式下的集群状态等信息，由Redis自己维护，而这些信息会相互告知其他所有节点。如果要重新创建集群，只需要把这个文件删除掉就行。
   cluster-config-file nodes-201.conf
   # 3、节点超时时限，如果发生超时则会被认定为PFAIL，如果超过半数其他Master认定为PFAIL，则会被集群认定为FIAL，然后会进行主从切换
   cluster-node-timeout 5000
   # 4、开启AOF
   appendonly yes
   
   # 5、Redis3.x旧版集群构建方式，需要使用redis-trib.rb来构建集群，最新版使用C语言来构建了，这个要注意
   # ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
   
   # 新版Redis集群构建方式
   # 6、创建集群，主节点和从节点比例为1，1-3为主，4-6为从，1和4，2和5，3和6分别对应为主从关系，这也是最经典用的最多的集群模式
   redis-cli --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1
   # 7、集群客户端
   redis-cli -c -p 7000
   # 8、检查集群信息
   redis-cli --cluster check 127.0.0.1:6379
   ```

3. **分区实现原理**：Redis 集群的键空间被分割为 `16384` 个槽（slot）， 集群的最大节点数量也是 `16384` 个，但推荐的最大节点数量为 1000 个左右，每个主节点都负责处理 `16384` 个哈希槽的其中一部分，其键的映射算法为 `HASH_SLOT = CRC16(key) mod 16384`。

   为什么哈希槽数为 16384 个？

   `CRC16` 算法产生的 hash 值有 16 bit，即可产生 2 ^ 16 = 65536 个值，换句话说，值是分布在 0 ~ 65535 之间，那 Redis 在做 `mod` 运算的时候，为什么不 `mod` 65536，而是选择 `mod` 16384 呢？

   - 1）槽位数不宜过大：如果槽位为 65536，那么节点发送 `PING/PONG` 心跳包消息头所占用的空间会达到 8k （65536 / 8），过于庞大，传输时浪费带宽，而如果使用 16384 个槽位，心跳包消息头所占用的空间仅为 2k（16384 / 8），则大小还能接受。
   - 2）槽位数不宜过小：Redis Master 的哈希槽配置，是通过一张 bitmap 的形式来保存的，其填充率为 slots / N，N为节点数目，在 N 固定的情况下，如果槽位数越小，bitmap 填充率就越小，导致 bitmap 在传输过程中的压缩率就越高，就越消耗 CPU 资源。
   - 3）因此，16384 个插槽，是综合了心跳包大小、网络带宽、压缩率等方面考虑的结果，同时还能满足各种业务需求。

4. **路由转向原理**：

   - 1）一个 Redis 客户端可以向集群中的任意节点（包括从节点）发送 `GET key` 命令请求。

   - 2）集群节点会对命令请求进行分析， 如果该命令是集群可以执行的命令， 那么节点会查找这个命令所要处理的键所在的哈希槽。

   - 3）如果要查找的哈希槽正好就处于当前节点中，则接收到的命令由当前节点负责处理。

   - 4）如果所查找的哈希槽不处于当前节点中，则当前节点会先查看自身内部所保存的，哈希槽到节点 ID 的映射记录，然后向客户端回复一个 `-MOVED` 转向错误。

     ```shell
     GET x
     # GET命令收到一个 -MOVED 转向错误
     # x真正所在的目标哈希槽，目标节点IP，目标节点端口号
     -MOVED 3999 127.0.0.1:6381
     ```

   - 5）客户端收到 `-MOVED` 转向错误后，根据目标节点 IP 与端口号，会再向目标节点重新发送一次 `GET key`命令请求。

   - 6）如果客户端在重新发送 `GET key` 命令时，集群刚好又更改了 key 的 slot 配置， 此时客户端请求目标哈希槽，会再次收到 `-MOVED` 转向错误， 需要再次向新的目标节点重新发送一次 `GET key`命令请求。

   - 7）客户端会循环以上操作，直到该命令请求成功，然后记录下该成功请求的哈希槽的目标节点信息，在下次执行相同 key 命令时，加快正确节点的寻找速度。

5. **高可用原理**：

   - 1）**节点失效检测**：当一个节点 `PING` 不通另一个节点时，则会把它标记为 `PFAIL`；当一个节点要把另一个节点从 `PFAIL` 标记为 `FAIL` 时， 则必须得到大部分 Master 的同意才行。
   - 2）**从节点选举**：一旦某个 Master 进入 `FAIL` 状态， 如果这个 Master 有一个或多个 Slave 存在， 那么其中一个 Slave 会被升级为新的 Master， 而其他 Slave 则会开始对这个新的 Master 进行复制。

6. **优点**：

   - 1）高可用：当集群中的一部分节点失效或者无法进行通讯时， 集群仍然可以通过主从切换，继续处理命令请求。
   - 2）高性能：操作某个 key 时，Redis 不会先找到节点再处理，而是直接让客户端重定向，到目标 Redis 实例进行请求，这相较代理分片少了 proxy 的连接损耗。
   - 3）高拓展：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

7. **缺点**：

   - 只能使用普通单机 Redis 所有功能的一个子集：不支持同时使用多个键的 Redis 命令，不支持多数据库功能， 只能使用默认的 0 号数据库。
   - 占用带宽：虽然避免了 Master 单节点的问题，但集群内的数据同步、节点通信会占用一定的带宽。
   - 数据弱一致性：与其他高可用方案一样，Redis 集群属于 AP 模型，不保证数据的强一致性，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。

8. **适用场景**：在写操作比较多的情况下，集群模式才更有优势，相对于其他大多数情况，使用哨兵模式就能满足需求了。

##### 3、总

Redis AKF 拆分：

![1632542544732](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542544732.png)

###### 1）X 轴扩展 | 主从复制

- **特点**：
  1. 按照主从设计，Master 负责读写， Slave 负责读。
  2. 再结合哨兵集群，在 Master 故障时，使用 Slave 进行切换，从而实现高可用。
- **优点**：
  1. 主从，解决了读并发压力大的问题。
  2. 哨兵，解决了单点故障问题。
- **缺点**：单机容量会有限制，并且会出现写并发压力大的问题。

###### 2）Y 轴扩展 | 业务拆分

- **特点**：
  1. 把 Redis 所有键，按照业务进行拆分，拆分到不同的 Redis 实例上。
  2. 可以在 Y 轴的基础上，再进行 X 轴的主从复制的扩展，形成不同业务的 Redis 集群。
- **优点**：从分离不同业务数据的角度，暂时解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：当某个业务的集群达到一定规模后，如果数据量过大，仍然会出现单机容量受限，以及写并发压力大的问题。

###### 3）Z 轴扩展 | 数据分区

- **特点**：
  1. 将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。
  2. 可以在 Z 轴的基础上，叠加 X 轴的主从复制，集群内进行数据分片，比如 Redis Cluster。
  3. 可以再叠加 Y 轴的业务拆分，把整个 Redis 系统划分成多个不同业务的、数据分片过的 Redis Cluster。
- **优点**：增加了整个集群的算力、带宽和内存，从根本上解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：
  1. 数据分区后，不支持跨实例的命令与事务。
  2. 备份管理要复杂得多。
  3. 扩缩容时可能需要对数据再平衡。

综上，Redis 哨兵模式与 Redis Cluster 的主要区别为：

1. 原理上，Redis 哨兵模式是通过主从复制 + 故障时 Sentinel 做主从切换实现的，而 Redis Cluster 则是通过哈希虚拟槽分区 + 重定向客户端请求 + 主从复制 + 故障时 从节点选举 做主从切换实现的。
2. 使用上，由于 Redis Cluster 对数据做了分区，所以只能使用普通单机 Redis 所有功能的一个子集，比如不能使用多键命令，只能使用 0 号数据库，而 Redis 哨兵模式本质上是主从模式，依然可以使用所有命令。

=> 以上，就是我对 Redis 高可用架构 的一些理解，请问有什么细节需要补充的吗？

#### 3.2.2.2. 算法题 | 100 个数实现随机取两次，不能拿重复？

最优解见方案二~

```java
/**
 * 随机从连续的100个不重复数中, 取出100个不重复的随机数
 */
public class Random100 {

    public static void main(String[] args) {
        Random100 random100 = new Random100();

        // 验证方案一: 全Right!
        System.err.println("方案一开始~");
        for(int i = 0; i < 50000; i++) {
            random100.fun1();
        }

        // 验证方案二: 全Right!
        System.err.println("方案二开始~");
        for (int i = 0; i < 50000; i++) {
            random100.fun2();
        }
    }

    /**
     * 方案一思路：100个顺序int数组, 随机取出, 碰到相同的则重新取, 直到取完
     * <p>
     * 时间复杂度：最坏情况下, 第一次要取1次, 第二次要取2次,...,第100次要去100次, 时间复杂度为O(n^2)
     * 额外空间复杂度: 一开始的100长度数组, 以及返回的100长度数组, 都是是题目需要的, 所以额外空间复杂读为O(1)
     */
    private void fun1() {
        int len = 100;

        int[] nums = getInitNums(len);
        List<Integer> res = new ArrayList<>();

        int i = 0, index;
        Random random = new Random();
        while (i < len) {
            index = random.nextInt(len);
            if (nums[index] != -1) {
                res.add(nums[index]);
                nums[index] = -1;
                i++;
            }
        }

        printIfError(res);
    }

    /**
     * 方案二思路：100个顺序int数组, 随机取出, 取出后替换到末尾位置, 直到取完
     * <p>
     * 时间复杂度：由于每次只需要取1次, 共取100次, 所以时间复杂度为O(n)
     * 额外空间复杂度: 一开始的100长度数组, 以及返回的100长度数组, 都是是题目需要的, 所以额外空间复杂读为O(1)
     */
    private void fun2() {
        int len = 100;

        int[] nums = getInitNums(len);
        List<Integer> res = new ArrayList<>();

        int i = 0, index, tmp;
        Random random = new Random();
        while (i < len) {
            index = random.nextInt(len);
            res.add(nums[index]);

            // 交换index到末尾
            tmp = nums[index];
            nums[index] = nums[len - 1];
            nums[len - 1] = tmp;

            // 数组末尾前移
            len--;

            // 继续下一轮随机取
            i++;
        }

        printIfError(res);
    }
    
    /**
     * 获取连续len个不重复数数组
     *
     * @param len
     * @return
     */
    private int[] getInitNums(int len) {
        int[] nums = new int[len];
        for (int i = 0; i < len; i++) {
            nums[i] = i;
        }
        return nums;
    }

    /**
     * 判断是否有重复, 有则打印Error!
     *
     * @param res
     */
    private void printIfError(List<Integer> res) {
        Set<Integer> set = new HashSet<>(res);
        if (res.size() != set.size()) {
            System.err.println("Error!");
        }
    }
}
```

#### 4.1.1.1. 项目介绍，分表规则、服务器配置、JVM 配置？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 4.1.1.2. 线程池参数？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 4.1.1.3. Spring MVC 的处理过程？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 4.1.1.4. Spring MVC 拦截器和过滤器的区别？

见《[1.1.1.6. Spring MVC 拦截器和过滤器的区别？](#1.1.1.6. Spring MVC 拦截器和过滤器的区别？)》。

#### 4.1.1.5. Spring AOP 的原理？

##### 1、总

AOP，Aspect-Oriented Programming，⾯向切⾯编程，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑，或者责任封装起来（比如事务管理、⽇志管理、权限控制等），以便于减少系统的重复代码，降低模块间的耦合度，有利于未来的可拓展性和可维护性。

##### 2、分

1. AOP 有 **7 个核心概念**：

   - 1）**切面**：Aspect，指对哪些方法进行拦截处理的横切关注点，可能会横切多个对象，比如 Spring 的事务管理， 在 Spring AOP 中，切面可以在普通类中以 `@Aspect` 注解来实现。
   - 2）**连接点**：Join point，指在程序执行过程中某个特定的点，比如某个方法调用的时间点，或者处理异常的时间点，在 Spring AOP 中，一个连接点代表一个方法的执行。
   - 3）**通知**：Advice，在切面的某个特定的连接点上*执行的动作，通知有多种类型，包括 `around`， `before`， 和 `after` 等等。
   - 4）**切点**：Pointcut，匹配连接点的断言，通知会在满足这个切点的连接点上运行，比如 AOP 去执行某个特定名称的方法。
   - 5）**目标对象**：Target object，被一个或者多个切面所通知的对象，也被称作被通知的业务对象。
   - 6）**织入**：Weaving，把切面连接到目标对象上，并创建一个代理对象的过程。
   - 7）**AOP 代理**：AOP proxy，AOP 框架创建的对象，用来实现切面契约，包括通知方法执行等功能，在Spring 中，AOP代理可以是 JDK 动态代理，或者是 CGLIB 动态代理。

   => 比如日志管理的公共代码，可以抽象出一个**切面**，然后注入到**目标对象**中（具体的业务对象），通过**动态代理**，将对目标对象进行代理，在进行调用时，代理对象会根据**通知**类型，在对应的时间点，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

2. **实现原理**：

   - 1）Spring AOP 是基于动态代理实现的，是 IoC 的一个扩展功能，是在 IoC 整个流程中新增的一个 BeanPostProcessor（`AbstractAutoProxyCreator`）扩展点而已。
   - 2）`AbstractAutoProxyCreator` 实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
   - 3）如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
   - 4）⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 asm框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。

##### 3、总

=> 以上，就是我对 Spring AOP 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.6. Spring @Transactional 原理？

##### 1、总

`@Transactional`，是 Spring 中事务传播配置的注解，可通过 `@EnableTransactionManagement` 启用事务传播特性，其中，Spring 事务传播属性分为以下几种：

| 属性                     | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| REQUIRED（默认属性）     | 如果存在一个事务，则支持**当前事务**，如果没有事务，则开启一个**新的事务** |
| MANDATORY                | 支持**当前事务**，如果当前没有事务，就**抛出异常**           |
| NEVER                    | 以**非事务**方式执行，如果当前存在事务，则**抛出异常**       |
| NOT_SUPPORTED            | 以**非事务**方式执行操作，如果当前存在事务，就把当前事务**挂起** |
| REQUIRES_NEW（相互独立） | **新建事务**，如果当前存在事务，把当前**事务挂起**，内外两个事务相互独立，互不影响，当外层事务失败时，并不会回滚内层事务所做的动作，而内层事务操作失败时，也不会引起外层事务的回滚 |
| SUPPORTS                 | 支持**当前事务**，如果当前没有事务，就以**非事务**方式执行   |
| NESTED（局部回滚）       | 支持**当前事务**，新增 Savepoint 点，与当前事务**同步提交或回滚**。嵌套事务一个非常重要的概念，就是内层事务依赖于外层事务，当外层事务失败时，会回滚内层事务所做的动作，而内层事务操作失败时，并不会引起外层事务的回滚 |

##### 2、分

其**实现原理**为：

1. Spring 的事务是由 AOP 来实现的，首先按照 AOP 的整套流程来执行具体的操作逻辑，使用 `InfrastructureAdvisorAutoProxyCreator` （AbstractAutoProxyCreator 的子类）来生成具体的代理对象。
2. 然后通过一个 `TransactionInterceptor` 来实现，在调用 `JdkDynamicAopProxy#invoke(proxy, method, args)` 方法时，则代理到 `TransactionInterceptor`  实现的具体逻辑中。
3. 在调用代理方法时，会先做准备工作，解析各个方法上事务相关的属性，根据具体的属性来判断是否开始新事务。
4. 当需要开启事务时，则获取数据库连接，关闭自动提交功能，开启事务。
5. 然后执行原始业务逻辑。
6. 如果在执行过程中发生异常，那么会通过 `completeTransactionAfterThrowing` 来完成事务的回滚操作，回滚的具体逻辑是通过 `doRollBack` 方法来实现的，实现的时候也是要先获取链接对象，再通过连接对象来回滚。
7. 而如果执行过程中，没有任何意外情况的发生，那么通过 `commitTransactionAfterReturning` 来完成事务的提交操作，提交的具体逻辑是通过 `doCommit` 方法来实现的，实现的时候也要获取链接，通过链接对象来提交。
8. 当事务执行完毕之后，需要通过 `cleanupTransactionInfo` 来清除相关的事务信息。 

##### 3、总

因此，在平常使用过程中，应该留心以下**注意事项**：

1. 事务函数中不要处理耗时任务，会导致长期占有数据库连接。
2. 事务函数中不要处理无关业务，防止产生异常导致事务回滚。
3. 一些 Spring 事务传播**失效场景**有：
   - 1）Bean 对象没有被 Spring 容器所管理。
   - 2）调用方法的访问修饰符不是 public。
   - 3）数据源没有配置事务管理器。
   - 4）数据库不支持事务。
   - 5）异常被捕获，所以没有回滚。

=> 以上，就是我对 Spring @Transactional 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.7. JDK 8 的内存分布情况，年轻代和老年代默认的比值，以及 Eden 区的比值，以及为什么？

##### 1、总

![1647941457503](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941457503.png)

JVM 在执行 Java 程序的过程中，会把它所管理的内存区域，划分为同 JVM 生命周期的线程共享区域，有方法区和堆区，以及生命周期随着线程启动和结束，而建立和销毁的非线程共享区域，有程序计数器、虚拟机栈和本地方法栈。

##### 2、分

###### 1）程序计数器

1. Program Counter Register，非线程共享，是 JVM 当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，从而实现分支、循环、跳转、异常处理、线程恢复等基础功能。
2. 出现的原因是：
   - 1）由于 JVM 多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，线程是最小的执行单位，没有“记忆”功能，只负责去干。
   - 2）为了在线程切换后，能恢复到正确的执行位置，需要记住原线程下一条要执行的指令的位置，此时，每条线程就需要有一个独立存储、互不影响、内存不共享的程序计数器。

###### 2）虚拟机栈

![1647941408114](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941408114.png)

1. 每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致，其内存空间只包含基础数据类型的局部变量、以及对象引用。

2. 虚拟机栈的单位是栈帧，在每个方法执行时，都会创建一个栈帧压入虚拟机栈中，在方法执行完毕或者发生异常，对应的栈帧则会从虚拟机栈中出栈。

3. 其中，每个栈帧都存放着局部变量表、操作数栈、动态链接和方法返回地址，还有一些附加信息。

   - 1）**局部变量表**：

     1. 是一组变量值的存储空间，用于存放方法参数，和方法内部定义的局部变量。
     2. 存放了编译期可知的各种基本数据类型 `boolean、byte、char、short、int、float、long、double`（对包装类型则在栈中保存其引用地址，在堆中保存值）、以及对象引用。
     3. 其内存空间，在编译期间完成分配，所以，在方法在运行之前，其内存空间是固定的，运行期间也不会发生改变。

   - 2）**操作数栈**：

     1. 用于保存计算过程中的中间结果，同时作为计算过程中变量临时的存储空间。
     2. 操作数栈在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈和出栈操作。

     ```java
     public class Test {
         public void add() {
             int a = 15;
             int b = 1;
             int c = a + b;
         }
     }
     ```

     => 以上过程，其操作数栈与局部变量表的**交互顺序**为：

     1. 15 入栈：操作数栈写入数据。
     2. 15 出栈：操作数栈提取数据到局部变量表。
     3. 1 入栈：操作数栈写入数据。
     4. 1 出栈：操作数栈提取数据到局部变量表。
     5. 15 入栈：加载局部变量表变量 15。
     6. 1入栈：加载局部变量表变量 1。
     7. `iadd`：执行相加 15 + 1 指令。
     8. 16 出栈：操作数栈提取结果到局部变量表。
     9. `return`：如果返回值为void，则当前栈帧出栈即可；如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中。

   - 3）**动态链接**：

     1. 每个栈帧都包含一个，指向运行时常量池中，当前栈帧所属的方法引用，持有这个引用是为了支持方法在调用过程中的动态链接（Dynamic Linking）。
     2. Class 文件的常量池中，存在大量的符号引用，这些符号引用一部分会在类加载阶段，或者第一次使用时转化为直接引用，这种转化成为静态连接。
     3. 而另一部分则在每一次运行期间都转化为直接引用，这部分称为动态连接。

   - 4）**方法返回地址**：

     1. 指向下一条字节码指令的地址，方法正常退出时，PC 计数器会记录其返回地址，保存在栈帧中。
     2. 而在方法异常退出时，返回地址，则要通过异常处理器表来确定，栈帧中不会保存这部分的信息。

   - 5）**附加信息**：虚拟机规范还允许一些的实现，可以增加一些规范里没有描述的信息到栈帧中，比如，与调试相关的信息等。

###### 3）本地方法栈

1. 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是用来服务 Java 方法的，而本地方法栈，则是用来服务虚拟机调用 Native 方法的。

###### 4）堆区

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

1. Java Heap，线程共享，在 JVM 启动时创建，是 Java 虚拟机中内存最大的一块，专门用来保存对象，几乎所有对象、以及数组的内存都在堆上分配。

2. 对象在堆中分配好以后，会在栈中保存一个 4 字节的实例，用来指向对象堆内存地址，定位对应的对象在堆中的位置，便于找到该对象，因此，操作实例，实际上是通过实例指针间接操作对象。

   - 另外，`ClassA a = new ClassA()`，a 叫做实例，而不能说成 a 对象，因为实例在栈上，对象在堆中。

   - 以及，在开启逃逸分析后，某些未逃逸的对象，也可以通过标量替换的方式在栈上分配。

3. 栈中的数据，和堆中的数据销毁并不是同步的，方法一旦结束，栈中的局部变量会立即销毁，而堆中的对象不一定会销毁，可能有其他变量也指向了该对象，一直等到没有变量指向该对象，它才有可能被垃圾回收掉。

4. 同时，堆是垃圾回收 GC 的主要场所，从内存回收角度来看，可以分为新生代和老年代，默认比值为 `1：2 `，原因是，老年代需要占用更多的内存空间。

5. 对于新生代又可以分为 Eden区（伊甸园）、Survivor 区（存活区），默认比值为 `8：2`，原因是，大部分对象生命周期活不到存活区。

6. Survivor 区又分为 Surviver0（From Survivor）和 Survivor1（To Survivor），默认比值为 `1：1`，原因是，存活区使用的是复制算法。

7. 堆中还有个概念，叫做 TLAB：Thread Local Allocation Buffer，线程私有分配缓存区，是一块线程专用的内存分配区域，JVM 会为每个线程分配一块 TLAB 区域，实质占用的是 Eden 区的空间（分配独享、使用共享），用于给每个线程往自己的 TLAB 中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。

   - 1）优点 - 加速对象分配：
     1. 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM 底层采用 CAS + 失败重试的方式来做同步处理。
     2. 如果多线程竞争非常激烈，那么在堆中分配对象性能是非常差的。
     3. 因此，JVM 设计了 TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
   - 2）缺点 - 大的对象无法分配：由于 TLAB 空间比较小，所以大的对象无法在 TLAB 分配，此时只能直接分配到其他堆空间中。

###### 5）方法区

![1647944132277](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647944132277.png)

1. Methed Area，别名 Non-Heap 非堆，线程共享，是 JVM 规范中定义的一个**逻辑概念**，用于存储已被虚拟机加载的类信息、常量、静态变量、以及即时编译后的代码，具体放在哪里，不同的实现可能会放在不同的地方。
2. 在 JDK 8 HotSpot 中，方法区存储空间分为堆和元空间，类信息（类版本、字段、方法、接口、父类等描述信息、静态常量池）、运行时常量池放在元空间中，静态变量、字符串常量池放在了堆中。
3. 讲到元空间，就要先讲一下永久代了：
   - 1）永久代，是 Hotspot 虚拟机特有的概念，是方法区的一种实现，主要存放类信息、常量等方法区内容。
   - 2）在 JDK 6 中，方法区中包含的数据，除了 JIT 编译生成的代码外（存放在native memory的CodeCache区域），其他都存放在永久代中。
   - 3）而移除永久代的工作，是从 JDK 7 开始的，但并没完全移除，比如符号引用转移到了本地内存中，字面量（见字符串常量池）、类的静态变量（class statics）转移到了堆中。
   - 4）在 Java 8 中，永久代就彻底被移除，取而代之的是，另一块与堆不相连的本地内存，叫做元空间（Metaspace）中，此时 `‑XX:MaxPermSize` 失去了意义，取而代之的是 `-XX：MaxMetaspaceSize `。
4. 再回到元空间：它是在 JDK 8 以后，用于替代永久代，存储类的元数据信息，存放的地方并不在 JVM 虚拟机中，而是在本地内存中，其大小仅受本地内存的限制，从而解决了永久代容易溢出的问题。
5. 再回到方法区，在 JDK8 以后，元空间替代了永久代，使得方法区与堆存在了交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是 class 文件里的常量池，未加载前并不占用内存。
   - 1）**静态常量池**：也叫 class 文件常量池，即 class 文件中的常量池，占用 class 文件绝大部分空间，主要存放：
     1. 字面量，相当于 Java 语言层面常量的概念，如文本字符串、final 修饰的变量。
     2. 符号引用，属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
   - 2）**运行时常量池**：当 class 文件加载到内存后，JVM 会将静态常量池中的内容，存放到运行时常量池中，这就是我们常说的常量池，主要存放：
     1. 编译期间产生的字面量和符号引用。
     2. 运行时常量池具有动态性，并非只能通过 class 文件常量池进入，运行期间也可以将新的常量放入池中。
   - 3）**字符串常量池**：可以理解为，运行时常量池中分出来的字符串部分，当类加载到内存时，字符串会存到字符串常量池里。
     1. `String#intern()` 方法，native方法，返回规范的字符串，底层调用 `equals()` 会先判断常量池是否有存在的字符串，如果没有，则会将字符串加入常量池。
     2. 程序运行时，除非手动向常量池中添加常量，比如调用 `String#intern()` 方法，否则 JVM 不会自动添加常量到字符串常量池中。
     3. 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量，则会加入常量池，如果是变量，由于地址不能确定，所以在不调用 `String#intern()` 时，是并不会加入常量池的。

##### 3、总

=> 以上，就是我对 JDK 8 运行时数据区 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.8. 项目中的垃圾收集器用了哪些？

##### 1、总

1. 由于 JVM 启动参数没配置具体的垃圾收集器，所以使用的是默认的垃圾收集器。

   ```shell
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

2. 这时可以去看 gc.log 中的抬头，打印出来的是 `-XX:+UseParallelGC` ，即 `Parallel Scavenge` + `Parallel Old` 的组合。

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

JDK 中有如下的垃圾收集器（挑着讲）：

![1648022290125](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022290125.png)

###### 1）新生代 - Serial 收集器 | 单线程

![1648022517445](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022517445.png)

1. 最基本的、发展历史最悠久的收集器，采用的是复制算法。
2. 其特点是，单线程，可以专心做垃圾回收，不存在与其他线程的交互开销，效率较高，但收集过程全程 Stop The World。
3. 只适用于客户端程序、或者嵌入式低性能的单核机器。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用复制算法，执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 2）新生代 - ParNew 收集器 | 多线程并行

![1648022570986](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022570986.png)

1. 相当于 Serial 收集器的多线程版本，采用的也是复制算法，收集过程全程也是 Stop The World。
2. 可使用 `-XX：ParallelGCThreads`，来设置并行线程数，一般设置为 CPU 核心数。
3. 主要用来和 CMS 收集器配合使用。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 3）新生代 - Parallel  Scavenge 收集器 | 多线程并行

![1648022746240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022746240.png)

1. 也叫吞吐量优先收集器，也是多线程并行的垃圾收集器，采用的也是复制算法。
2. 其特点是：
   - 1）可以通过配置，以达到一个可控制的吞吐量：
     1. `-XX：MaxGCPauseMillis`：设置后，JVM 将尽力控制垃圾收集时的最大的停顿时间。
     2. `-XX：GCTimeRatio`：用于设置吞吐量的大小，取值为 0~100，设置后，JVM 将花费不超过 `1 + / （1+n）` 的时间，去做垃圾收集。
   - 2）支持自适应 GC：
     1. 可使用 `-XX：+UseAdptiveSizePolicy` 启用，启用后，将无需再手动设置 `-Xmn、-XX：SurvivorRatio` 等参数，虚拟机会根据系统的运行状况，收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。
     2. 可见，Parallel  Scavenge 收集器存在着一定的智能性。
3. 适用于比较注重吞吐量的场景。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 4）老年代 - Serial Old 收集器 | 单线程

![1648023100553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023100553.png)

1. 也叫串行的老年代收集器，相当于 Serial 收集器的老年代版本，采用的算法是标记整理算法。
2. 和 Serial、ParNew、Parallel Scavenge 三个新生代收集器，都可以形成配合。
3. 在 CMS 收集器出现故障时，则会使用 Serial Old 收集器作为备用。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用标记整理算法，执行老年代垃圾回收，回收完毕后，用户线程继续运行。

###### 5）老年代 - Parallel Old 收集器 | 多线程并行

![1648023323242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023323242.png)

1. 相当于 Parallel Scavenge 的老年代版本，采用的是标记整理算法，只能和 Parallel Scavenge 新生代收集器配合使用。
2. 与 Parallel Scavenge 一样，适用于关注吞吐量的场景。
3. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用标记整理算法，并行执行老年代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 6）老年代 - CMS 收集器 | 多线程并发

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

1. CMS，Concurrent Mark Sweep，并发标记清除收集器，可以与用户线程同时工作，采用的是标记清除算法，而 Serial Old、Parallel Scavenge 采用的都是标记整理算法。

2. 优点是，CMS 的 Stop The World 时间比较短，大多过程都是并发执行的，只有初始标记和重新标记，存在者 Stop The World，其他阶段都是并发执行的。

3. 缺点是：

   - 1）**会存在内存碎片**：这也是最令人诟病的地方，这是因为 CMS 采用的是标记清除算法，会导致内存碎片的产生。
     1. 可使用 `UseCMSCompactAtFullCollection`（默认打开），在每次 Full GC 完成后，进行内存碎片的整理。
     2. 也可使用 `CMSFullGCsBeforeCompaction`（默认为0），在进行几次 Full GC 后，就进行一次内存碎片的整理。
   - 2）无法处理浮动垃圾：由于并发清除阶段，用户线程在并发执行，可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而 CMS 是无法在本次 GC 清理掉这些浮动垃圾的，需要留到下次 GC 才能清理掉。
   - 3）不能等到老年代几乎满了才开始收集：
     1. 如果 CMS 执行期间，预留的老年代内存，不能满足用户程序的需要，则会出现一次 Concurrent Mode  Failure 异常，会导致 JVM 改用备用的 Serial Old 收集器，去收集老年代的垃圾，从而导致更长的 Stop The World。
     2. 因此，必须为老年代预留足够的内存给用户线程使用，可使用 `CMSInitiatingOccupancyFraction`（默认68%），来设置老年代占比达到多少后，才会触发 CMS 垃圾回收。
   - 4）CPU 资源比较敏感，并发执行阶段会导致应用吞吐量的降低：由于垃圾收集线程也需要占用一定的 CPU 资源，与业务线程一起去争抢 CPU 时间片，影响业务线程的执行效率，降低应用的吞吐量。

4. 适用于希望系统停顿时间短，响应速度快的场景，比如各种服务端应用。

5. 执行过程为：

   - 1）**初始标记**：initial  mark，标记那些 GC Roots 能直接关联到的对象，此时能够标记到的对象会比较少m。执行期间，存在 Stop The World，但由于标记的对象比较少，所以 STW 的时间也是比较短的。

   - 2）**并发标记**：concurrent mark，找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程，和用户线程并发执行，不存在 Stop The World。

   - 3）**并发预清理**：concurrent-preclean，是一个不一定会执行的阶段，可通过 `-XX：-CMSPrecleaningEnabled`（默认打开），关闭并发预清理阶段，本阶段，JVM 会重新标记那些在并发标记阶段期间，引用被更新了的对象，比如某些新晋升到老年代的对象，从而减少后面重新标记阶段的工作量。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

   - 4）**并发可中止的预清理阶段**：concurrent-abortable-preclean，也是不一定会执行的阶段，使用该阶段的前提条件是，当 Eden 使用量大于 `CMSScheduleRemarkEdenSizeThreshold` 阈值时（默认2M）才会执行，工作内容与并发预清理阶段是一样的。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

     1. 本阶段的主要作用是，允许用户能够控制预清理阶段的结束时机。
     2. 比如，可用 `CMSMaxAbortablePrecleanTime`（默认 5 秒）进行设置扫描时长。
     3. 再如，可用 `CMSScheduleRemarkEdenPenetration` 设置（默认 50%），当 Eden 使用占比达到多大，就结束本阶段。

   - 5）**重新标记**：remark，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象，错误地标记成为了死亡，则可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World，一般来说，本阶段所花费的时间，会比初始标记阶段的要长一些，但会比并发标记阶段的短一些。

   - 6）**并发清除**：concurrent sweep，会基于标记结果，清除掉要前面标记出来、需要清除的垃圾，不做整理，所以会存在内存碎片。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

     那么为什么是并发清除，而不是并发整理？

     1. 因为本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     2. 如果是并发整理，则既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，实现起来会变得非常困难，还容易出错，而采用并发清除，就变得容易了许多。
     3. 因此，这里是并发清除，而不是并发整理。

   - 7）**并发重置**：concurrent reset，清理本次 GC 的上下文信息，为下一次 GC 做准备。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

###### 7）新生代&老年代 - G1 收集器 | 多线程并发

![1648024834453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648024834453.png)

1. Garbge First，是一款价值优先、既可以用在新生代、又可以用在老年代（即整个堆内存）的垃圾收集器，由于采用的是复制算法，所以无内存碎片的问题。

2. 而其革命性的变化在于：

   - 1）它将整个堆，划分成了若干个大小相等的区域，每个区域叫一个 Region，这个 Region 可通过 `-XX：G1HeapRegionSize` 来指定，取值范围为 1M~32M ，且必须为 2 的幂次。
   - 2）在 G1 中，一共分为 4 类 Region，分别为 Eden Region 伊甸园、Survivor Region 存活区、Old Region 老年代、Humongous Region 存储大对象，同一代对象可能是不连续的，而超过 Humongous Region 大小一半的特大对象，则会被分配到连续的 Humongous Region 里面。
   - 3）然后，G1 会去跟踪每个 Region 里面的垃圾堆积的价值大小，即回收一个 Region 能够获取到多大的剩余空间。
   - 4）最后，构建一个优先列表，根据允许的收集时间，优先回收价值高的 Region，即回收后能够得到更大空间的 Region，以获得更高的垃圾收集效率。

3. 主要用来替换 CMS，适用于占用内存较大（6G 以上）的应用。

   - 1）> JDK 8 都可以使用 G1（如果内存 <= 6G，建议使用 CMS，如果内存 > 6G，可以考虑使用 G1），而 CMS 则从 JDK 8 开始就被废弃了。

4. 执行过程为：

   1、**Young GC**：与之前的 Minor GC 差不多，采用的都是复制算法，只不过回收的单位是 Region 而已。

   - 1）当所有 Eden Region 都满了时，会触发 Young GC，Eden Region 里面所有的存活对象，都会转移到Survivor Region 里面去。
   - 2）而原先在 Survivor Region 中存活的对象，则会转移到新的 Survivor Region 中，或者晋升到 Old Region 中。
   - 3）然后，空闲的 Region 则会被放入空闲的列表中，等待下次被使用。

   2、**Mixed GC**：

   ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

   - 1）最能体现 G1 的设计思想，与 CMS 过程类似，但采用的是复制算法。
   - 2）在老年代大小，占整个堆的百分比达到 `-XX：InitiatingHeapOccupancyPercent` 时（默认 45%），则会触发 Mixed GC。

   - 3）Mixed GC 会回收所有的 Young Region，同时根据收集时间与回收价值回收部分的 Old Region。

   对于**执行过程**，除了并发标记是并发执行外，其他阶段都需要 Stop The World，但由于每次只回收部分的 Region，所以整体 Stop The World 的时间是可控的。

   - 1）**初始标记**：Initial Marking，与 CMS 初始标记类似，都是标记 GC Roots 能直接关联到的对象。执行期间，存在 Stop The World，不过由于标记的对象比较少，所以 STW 的时间比较短。
   - 2）**并发标记**：Concurrent Marking，也与 CMS 并发标记类似，都是找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。
   - 3）**最终标记**：Final Marking，也与 CMS 重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World。
   - 4）**筛选回收**：Live Data Counting and Evaluation，会对各个 Region 的回收价值与成本，进行排序，根据用户所期望的停顿时间 `MaxGCPauseMillis`，来制定回收计划，以选择回收某些 Region。执行期间，存在 Stop The World。
     1. 回收过程，采用的是复制算法，因此无内存碎片产生。
     2. 首先，G1 会选择一系列 Region 构成一个回收集。
     3. 接着，G1 会把决定要回收的 Region 中的存活对象，复制一个空的 Region 中。
     4. 最后，再删除掉需要回收的 Region。

   3、**Full  GC**：

   - 1）当 G1 在复制对象时，发现内存不够，或者无法分配足够内存，比如特大对象没有足够连续的 Humongous Region 可分配时，则会触发 Full GC。
   - 2）一旦触发 Full GC，在 Full GC 模式下，使用的是类似于 Serial Old 的垃圾回收，将出现长时间的 Stop The World。

5. 调优原则 => 因此，使用 G1 时，应该尽量减少 Full GC 的发生，让其只停留在 Young GC，或者 Mixed GC 的模式上进行垃圾回收。

   - 1）**增加预留的内存**：可加大 `-XX：G1ReserveRercent` ，默认为堆的 10%。
   - 2）**更早地进行回收垃圾**：可降低 `-XX：InitiatingHeapOccupancyPercent`（默认 45%），降低老年代大小，占整个堆的百分比的阈值，提早触发 Mixed GC。
   - 3）**增加并发阶段使用的线程数**：可增大 `-XX：ConcGCThreads`，让更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

##### 3、总

最后，选择垃圾收集器，不能纸上谈兵，要根据实际情况选择。

1. 桌面端应用、是单核的，可以使用 `Serial + Serial Old`。
2. Web 应用，追求响应快、吞吐量高的，可以使用 `Parallel Scavenge + Parallel Old`。
3. Web 应用，追求低延迟的，可以使用 `ParNew + CMS`、或者 G1。

=> 以上，就是我对 JVM 垃圾收集器 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.1.9. 线上怎么确定是老年代还是年轻代的 GC 时间过长？

##### 1、总

查看方式有：

1. 看 Skywalking：

   ![1648027659855](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648027659855.png)

2. 用 `jstat` 监控统计命令：

   ```shell
   # 查看remote.domain机器上，40496进程，垃圾收集相关的统计信息摘要（每隔1秒采样1次）
   jstat -gcutil 40496@remote.domain 1000
   
   # option参数解释：
   -class    :：显示类加载器的统计信息
   -gcutil    ：垃圾回收统计概述
   -gc        ：垃圾回收堆的行为统计
   -gcnew     ：新生代行为统计
   -gcold     ：年老代和永生代行为统计
   -gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计
   ```

3. 看 gc.log，手动计算所花时间：

   ```shell
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

Minor/Young GC 时间过长原因：

1. **存活对象的标注时间过长**：
   - 1）比如重载了 `Object#finalize()` 方法，会导致标记 Final Reference 耗时过长。
   - 2）或者 `String#intern()` 方法使用不当，导致 GC 扫描 StringTable 时间过长。
   - 3）可以通过配置 `-XX:+PrintReferenceGC` ，显示 GC 处理在 Reference 时的耗时。
2. **对象生命周期变长**：
   - 1）比如本地缓存使用不当，积累了太多存活对象，其中，它们还可能晋升到老年代，增长 FullGC 时间。
   - 2）或者锁竞争严重，导致线程阻塞，引起局部变量的生命周期变长。

Major/Full GC 时间过长原因：

1. **长生命周期的对象多**：过多的全局变量或者静态变量等，会导致标记和复制过程的耗时增加。

##### 3、总

=> 以上，就是我对 GC 时间过长调优 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.0. 线上出现慢 SQL 是怎么解决的？

1. Druid 监控拿去 SQL。
2. 然后进行 Explain 本地调优。

=> 见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 7）条码销售出库 | 索引调优、生产问题。

#### 4.1.2.1. 讲一下 SQL Explain？

##### 1、总

1. 使用 EXPLAIN 关键字，可以模拟优化器执行 SQL 语句，分析查询 SQL 语句的性能瓶颈。
2. 在 select 语句之前增加 explain 关键字，MySQL 就会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是真正去执行 SQL。

##### 2、分

Explain 结果字段有如下几个：

| Explain 结果字段 | json 名称     | 含义                                                         |
| ---------------- | ------------- | ------------------------------------------------------------ |
| **id**           | select_id     | 该语句的唯一标识，id 越大，越先执行，相同 id 的，从上到下执行 |
| select_type      | 无            | 查询类型                                                     |
| table            | table_name    | 表名                                                         |
| partitions       | partitions    | 匹配的分区                                                   |
| **type**         | access_tpye   | 联接类型                                                     |
| possible_keys    | possible_keys | 可能的索引选择                                               |
| key              | key           | 实际选择的索引                                               |
| **key_len**      | key_length    | 索引的长度                                                   |
| ref              | ref           | 索引的哪一列被引用了                                         |
| **rows**         | rows          | 估计要扫描的行                                               |
| filtered         | filtered      | 表示符合查询条件的数据百分比                                 |
| **extra**        | 没有          | 附件信息                                                     |

其中，影响性能的字段主要有：

###### 1）type | 连接类型

type 有以下几种取值，性能从好到坏：

| 连接类型        | 含义                                                         | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| system          | 该表只有一行，相当于系统表                                   | system是const的特例                                          |
| const           | 针对主键或者唯一索引的等值查询，最多返回一行数据             | 查询速度非常快                                               |
| eq_ref          | 当使用了索引的全部组成部分，并且索引是**主键或者非空唯一索引**才会发生 | 性能仅次于system和const                                      |
| ref             | 当满足索引的最左前缀规则，或者索引**不是主键也不是唯一索引**时才会发生 | 如果索引只匹配到少量的行，则性能也是不错的                   |
| fulltext        | 全文索引                                                     | 使用MyISAM存储引擎才有                                       |
| ref_or_null     | 该类型类似于ref，但MySQL会额外搜索哪些行包含NULL，           | SELECT * FROM ref_table WHERE key_col = expr OR key_col IS NULL； |
| index_merge     | 该类型表示使用了索引合并优化，表示一个查询里面用到了多个索引 | -                                                            |
| unique_subquery | 该类型和eq_ref类型，但使用了**IN查询**，且**子查询是主键或者唯一索引** | value IN (SLECT id FROM single_talbe WHERE expr)             |
| index_subquery  | 和unique_subquery类型，只是**子查询使用的是非唯一索引**      | value IN (SELECT key_col FROM single_table WHERE other_expr) |
| range           | 范围扫描，表示检索了指定范围的行，主要用于有限制的索引扫描   | 常见的有，BETWEEN、>、>=、<、<=、IS NULL、<=>、LIKE、IN      |
| index           | 全索引扫描，和ALL类型，只不过index是全盘扫描了索引的数据     | 当查询仅使用索引中的一部分列时，会使用该类型，有两种触发场景：1）覆盖索引，比ALL快，此时只扫描索引数，Extra列为Using Index；2）全表扫描，同ALL，此时会回表查询数据，Extra列不会出现Using Index； |
| ALL             | 全表扫描                                                     | 性能最差                                                     |

###### 2）key_len | 索引的字段长度

1. 索引字段长度，当字段允许为 NULL 时，key_len 会比不允许为 NULL 的大 1 个字节。
2. 长度越短，一页就能装更多的 B+ 树节点，磁盘 I/O 次数就越少，性能就越高。

###### 3）rows | 估算的扫描行数

MySQL 估算会扫描的行数，数值越小，性能越高。

###### 4）extra | 查询的附加信息

用于展示有关本次查询的附件信息，重要的取值有：

| 附件信息                                                     | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Using filesort**                                           | 当Query中包含ORDER BY操作，而且无法利用索引完成排序操作时，MySQL Query Optimizer不得不选择相应的排序算法来实现。在数据较少时，从内存排序，否则从磁盘排序。 其中，Explain不会显式地告诉客户端用哪种排序。 |
| **Using Index**                                              | 仅使用索引树中的检索列信息，不必进行其他查找以读取实际行，当查询仅使用属于单个索引的列时，会使用此策略 |
| **Using index condition**                                    | 使用索引下推时出现，表示先按条件过滤索引，过滤完索引后，找到符合索引条件的数据行，随后用WHERE子句中的其他非索引条件，去过滤这些数据行。 |
| **Using index for group-by**                                 | 数据访问和Using Index一样，所需数据只需要读取索引，当Query中使用GROUP BY或者DISTINCT子句时，如果所有分组字段也在索引中，该信息就会出现 |
| Using join buffer（Block Nested Loop），Using join Buffer（Batched Key  Access） | 使用Block Nested Loop或者Batched Key  Access算法来提高join的性能 |
| Using MRR                                                    | 使用了Muti-Range Read优化策略                                |
| Using sort_union（..），Using union（..），Using intersect（..） | 这些提示索引扫描如何合并为index_merge连接类型                |
| **Using temporary**                                          | 为了解决该查询，MySQL创建了一个临时表来保存结果，如果查询包含不同列的GROUP BY和ORDER BY子句，通常会发生这种情况。 |
| **Using Where**                                              | 如果不是读取表的所有数据，或者不仅仅通过索引就可以获取所有需要的数据时，则会出现该值 |

##### 3、总

=> 以上，就是我对 SQL Explain 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.2. 讲一下为什么要用 Https？

##### 1、总

1. Https，Hyper Text  Transfer Protocol over SecureSocket Layer，是以安全为目标的 Http 通道，在 Http 的基础上，通过传输加密、以及身份认证，保证了传输过程的安全性。
2. Https 在证书验证阶段，使用的是安全性高的非对称加密。在内容传输阶段，使用的是速度快的对称加密，
   - 对称加密：双方持有相同的密钥，加密速度快。典型的对称加密算法有，AES 和 DES。
   - 非对称加密：密钥成对出现（私钥和公钥），加密速度慢。私钥只有自己知道，不在网络中传输。公钥可以公开，A 使用 B 公钥加密后传输给 B，B 可以使用 B 的私钥解密得到原始内容。典型的非对称加密算法有，RSA 和 DSA。

##### 2、分

其执行原理为，

1. **发起请求阶段**：首先，客户端将它所支持的算法列表，和一个用作产生密钥的随机数 1，发送给服务器。
2. **返回证书阶段**：然后，服务器从算法列表中，选择一种算法，并将它和一份包含服务器公钥的证书（即数字签名）、以及随机数 2 ，返回给客户端。
3. **证书验证阶段**：
   - 1）客户端对服务器的证书进行验证，抽取服务器给的公钥，生成一个 `pre_master_secret` 随机密码串 + 服务器公钥，使用非对称加密，将加密后的信息（预主密钥）发送给服务器。
   - 2）以及根据预主密钥、随机数 1、随机数 2，独立计算出 MAC 密钥，作为接下来的会话密钥。
4. **服务器解密阶段**：服务器通过服务器私钥，对客户端发送过来的加密信息进行解密，得到预主密钥，与随机数1、随机数2，独立计算出 MAC 密钥，也作为接下来的会话密钥。
5. **客户端发起测试阶段**：客户端将握手消息，使用对称加密得到 MAC 值，发送给服务端，验证服务器能否正常接受客户端对称加密后的信息。
6. **服务器响应测试阶段**：同理，服务器收到后，，使用对称加密得到 MAC 值，返回给客户端。
7. **连接完成阶段**：如果客户端能够接受，并返回确认报文，则 SSL 层建立完成，开始 Https 对称加密传输。

##### 3、总

最后，总结一下，Https 与 Http 的主要区别为：

| HTTP                           | HTTPS                                         |
| ------------------------------ | --------------------------------------------- |
| 默认端口 80                    | 默认端口 443                                  |
| URL 以 http:// 开头            | URL 以 https:// 开头                          |
| 明文传输、数据未加密、安全性差 | 传输过程 SSL 加密、安全性好、需要用到 CA 证书 |
| 消耗资源少、响应速度快         | 消耗资源多、响应速度慢                        |

=> 以上，就是我对 Https 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.3. Docker 和 K8S 有了解过吗？

##### 1、总

1. Docker，由 Go 语言开发，思想如 logo 一样，即集装箱 Container 容器思想，负责容器的运行和管理，通过隔离机制，使得每个容器间互不影响，以及通过限制每个容器的 CPU、内存和 I/O 资源，最大程度地压榨服务器资源源。
2. K8S，指 Kubernetes，是 Google#Omega 的开源版本，是目前市场占有率最高的容器编排产品，可以自动化部署、管理、扩展容器以及容器网络通信处理，为应用提供了理想的部署单元，和独立的执行环境，使得微服务部署更加简单，同时还支持集成到 CI/CD 工作流，提效 DevOps 团队工作。

##### 2、分

###### Docker 架构原理

![1647495796223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495796223.png)

1. Client：Docker 的客户端模块，用于运行 Docker 命令以及 Restful API。
2. Docker host：Docker 的服务器模块，存在一个 Docker Daemon 后台进程，负责整个 Docker 容器的生命周期管理，连接 Registry 下载镜像，以及提供 Client 的 API 端口来处理发送过来的命令。
3. Registry：Docker 的镜像仓库，分为 Docker Hub 官方公有的镜像仓库、Docker Datacenter 企业信任仓库、以及 Docker 内网私有仓库。
4. Images：Docker 镜像，可本地制作，也可来源于镜像仓库，是容器运行前代码、配置、环境变量、操作系统资源的打包，运行起来了之后叫做容器，类似于 VM 的配置模板，通过 UnionFS 联合文件系统，支持镜像的一层层叠加。
5. Containers：Docker 容器，每个容器共享主机的操作系统，通过 namespace 对 pid 进程、net 网络、ipc 信号量、mnt 文件系统、uts 用户组等进行**隔离**，通过 cgroup 对每个容器的 cpu、mem、io 等资源进行**限制**。

###### K8S 架构原理

![1647516641430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647516641430.png)

1. **Kubernetes Cluster**：K8S 集群，是计算、存储和网络资源的集合，是掌握所有计算、存储、网络资源，进行统计管理、调度的节点群。
2. **Namespace**：虚拟 K8S 集群，解决在同一个 Cluster 集群中，如何区分开 Controller 和 Pod 的问题，默认两个虚拟集群，`kube-system` 用于自身管理的集群，`kube-default` 用于应用部署的默认集群（不指定集群名称时）。

k8s 集群，分为一个 Master 节点和多个 Node 节点，

1. **Kubernets Maseter**：K8S 大脑节点，决定将应用放在哪里运行，它相比图中，该节点还隐藏了许多容器，比如：
   - **1）API Server**：API 服务端，通过控制台、网络，接收传过来的命令，判断是否符合语法标准，并根据实际环境进行处理。
   - **2）Scheduler**：调度执行器，对所有资源按照应用资源，执行统一调度，以及任务发布，负责决定将 Pod 放到哪⼀个 Node 上运⾏。
   - **3）Controller Manager**：控制器管理器，负责 Cluster 各种资源的统筹管理。
   - **4）ETCD**：类似于 ZK，对 K8S 集群的配置进行统一管理，保存了 K8S 的相关配置和状态信息，如果 POD 有发⽣变化，那么它会迅速通知相关的组件进⾏处理。
2. **Kubernets Node**：K8S 手脚节点，负责运行容器应用。
   - **1）Kubelet**：核心工作单元，是 K8S 里唯一一个没有以容器形式运行的组件，负责根据 Scheduler 发过来的信息，去创建和运⾏容器，并向 Master 报告运⾏状态，是直接跟 Docker 容器进行沟通。 
   - **2）Docker daemon**：Docker 后台容器。
   - **3）Kube-proxy**：网络通讯、服务发现负载模块，是网络代理的概念，当 service 接收到请求后，转发到某个 node 时，会由该 node 的 kube-proxy 模块负责接收，然后转发到后端的容器中，如果有多个副本，还能提供负载均衡的能⼒。
   - **4）Pod**：是 K8S 的最小工作单元（所以，K8S 最小工作单元不是容器！），是运行在 Node 手脚节点上的一堆容器集合，相当于是比容器更大的"集装箱"，对网络共享、存储共享的一堆 Docker 容器，封装成一个 Pod，作为一个小单元进行管理，从而扩大管理粒度，降低管理复杂度，实现统一部署，共享网络和存储。
   - **5）Controller**：负责对 Pod 进行统一管理。
     1. **Deployment**：一个应用资源，基于 ReplicaSet，会产生一个部署请求，形成一堆 Pod。
     2. **ReplicaSet**：一个会在多个点节点部署多个的 Pod，以完成更多的功能。
     3. **DaemonSet**：一个在同一节点只会运行一份的 Pod。
     4. **StatefulSet**：一个有状态的服务，对外提供的 Pod 名称永远不变。
     5. **Job**：一个短时、定时作业的 Pod。
   - **6）Service**：
     1. 为 Pod 提供了负载均衡：在当 Pod 之间需要相互访问时，会去 DNS Server 找到对应的 IP 地址，通过 Kube-proxy 服务发现功能，进行网络数据包转发，实现网络服务功能，以用于描述 Pod 和 Pod 之间的应用访问。
     2. 为客户端提供固定的 IP + 端口：当 Pod 的 IP 发生变化时，Service 可以保证，客户端面对的 Pod 还是固定 IP 和端口。
3. 当需要执行部署，并指定两个副本时，其**执行流程**为：
   - 1）Kuberctl 发送部署请求到 API Server。
   - 2）API Server 通知 Controller Manager，去创建一个 Deployment 资源。
   - 3）Scheduler 执行调度任务，将两个副本 Pod，分发到 Node1 和 Node2 上。
   - 4）Node1 和 Node2 上的 Kubelet 在各自的节点上，创建并运行 Pod。

##### 3、总

=> 以上，就是我对 Docker 和 K8S 的一些理解，请问有什么细节需要补充的吗？

#### 4.1.2.4. 算法题 | n 的二进制 1 的个数

leetcode -《汉明距离》。

##### 1）内置函数法 | O（1）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 内置函数》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.1mb，7.67%，时间上，由于内置函数也是位移操作，所以时间复杂度为 O（1），空间上，由于只使用有限几个变量，所以空间复杂度也是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        return Integer.bitCount(x ^ y);
    }
}
```

##### 2）右位移法 | O（logn）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 右位移法》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.6mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        do {
            if((res & 1) == 1) {
                count++;
            }
        } while((res >>>= 1) > 0);
        return count;
    }
}
```

##### 3）Brian Kernighan  算法 | O（logn）

- **思路**：
  - 通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - Brian Kernighan  算法 》的思路解决即可。
  - Brian Kernighan （布莱恩·克尼汉）算法给出，对于任意整数 x，令 x = x &（x-1），可将 x 的二进制表示的最后一个 1 变为 0，因此，如果不断循环执行这个过程则可以获得 x 为 1的比特位个数。
- **结论**：时间，0ms，100%，38.5mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        while(res > 0) {
            res &= res - 1;
            count++;
        }
        return count;
    }
}
```

#### 4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？

按位所在的值，去生成文件夹，每个文件夹只能存一个 ID，最后再收集（如果顺序收集，则还可以排序）所有文件夹的 ID，输出到一个文件里，那个文件就是最终去重后了的答案了。

#### 4.1.2.6. 是否有参加过开源项目，或者 ACM 比赛获奖什么的？

回答了没有，但有提交过 BUG 验证给 Oracle 官网的 JDK 组织，讲的是提交红黑树在删除后调整，判断红黑树是否为合法的红黑树时，没有判断两个连续红节点的情况，最后 Oracle 反馈说需要提供详细的例子证明，但我没有一个很好的数据状态，事件就不了了之了。

=> 结果不太好，下次别说了~

#### 5.1.1.1. List 与 Set 的区别？

**相同点**：存储元素、接口继承自 Collection 接口、支持泛型。

**不同点**：

1. **List**，有序列表，使用此接口，用户可以通过索引，精确控制列表中每个元素的插入位置，以及访问对应位置的元素，典型实现有 ArrayList、LinkedList、CopyOnWriteArrayList、Vector 和 以及继承自 Vector 的 Stack。
2. **Set**，不包含重复元素的集合，最多包含一个 NULL 元素，典型实现有 HashSet 和 LinkedHashSet，底层都是基于散列表实现的。

#### 5.1.1.2. ArrayList 扩容机制？

##### 1、总

1. ArrayList 是一个基于数组的、非线程安全的 List 接口实现类，它允许添加 NULL 元素，支持对元素进行快速随机访问，适合随机查找和遍历，不适合大量插入和删除。
2. 默认初始容量为 10，当数组容量不够时，会触发扩容机制，扩大到原来容量的 1.5 倍，然后将原来数组的数据，通过 `System.arraycopy(..)` 复制到新数组中。
3. 当从 ArrayList 的中间位置，进行插入或者删除元素时，需要对数组进行复制、移动，代价较高。

##### 2、分

1. 元素获取原理：直接根据索引，获取数组中对应的元素，时间复杂度为 O（1）。
2. 元素添加原理：模拟实际大小 + 1，判断是否需要扩容，然后在末尾添加元素，或者先通过 `System.arraycopy(..)` 把索引及其右边的元素，复制到索引右边去，以腾出索引位置添加新元素。
3. ArrayList 扩容机制：模拟实际大小 + 1，通过与当前容量判断，大于的，则需要触发扩容机制，扩容为原来容量的 1.5 倍，然后通过 `System.arraycopy(..)` 复制到新数组中。
4. 元素删除原理：直接根据索引，或者从头找到第一个 equals 的元素，然后删除，删除之后，需要扣减实际大小，以及通过 `System.arraycopy(..)` 把索引右边的元素，复制到索引这个位置来，以避免出现空位置浪费存储空间。

##### 3、总

=> 以上，就是我对 ArrayList 的一些理解，请问有什么细节需要补充的吗？

#### 5.1.1.3. ArrayList 与 LinkedList 的区别？

##### 1、总

1. LinkedList，是一个基于双向链表的、非线程安全的 List 接口实现类，它允许添加 NULL 元素，适合数据的动态插入和删除。
2. 使用它，可以直接操作表头、表尾元素，由于实现了 List、Queue、Deque 接口，以及提供 Stack#API，可以把它，当作有序列表、队列、双端队列、以及栈来使用，非常多功能。

##### 2、分

1. 元素获取原理：由于是基于双向链表实现，所以不能直接根据索引进行查找，而是要从头、或者从尾开始挨个遍历查找，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾获取元素，时间复杂度为 O（1）。
2. 元素添加原理：同理，由于是基于双向链表实现，所以不能直接根据索引进行添加，而是要从头、或者从尾开始挨个遍历，找到对应的位置后，才能进行元素添加，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾添加元素，时间复杂度为 O（1），添加元素时，处理好前后指针关系即可。
3. Linked 扩容机制：由于是基于双向链表实现，理论上不存在达到容器边界这种情况，所以也无需扩容，只需要连接前后指针即可。
4. 元素删除原理：同理，由于是基于双向链表实现，所以不能直接根据索引进行删除，而是要从头、或者从尾开始挨个遍历，找到对应的元素后，才能进行元素删除，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾删除元素，时间复杂度为 O（1），删除元素时，处理好前后指针关系即可。

##### 3、总

=> 以上，就是我对 LinkedList 的一些理解，请问有什么细节需要补充的吗？

总的来说，ArrayList 和 LinkedList 的**区别**有：

|                    | ArrayList                                          | LinkedList                                                   |
| ------------------ | -------------------------------------------------- | ------------------------------------------------------------ |
| 1、提供的 API 不同 | 只提供了 List#API                                  | 除了提供 List#API 外，还提供 Queue、Deque、以及 Stack#API    |
| 2、数据结构不同    | 是基于数组实现的                                   | 是基于双向链表实现的                                         |
| 3、扩容机制不同    | 默认初始容量为 10，每次扩容到原来容量的 1.5 倍     | 无需初始容量，也无需扩容机制，只需要处理好前后的指针关系即可 |
| 4、适用场景不同    | 适合随机查找和遍历元素，不适合大量元素的插入和删除 | 适合动态插入和删除元素，不适合元素的随机访问，因为每次都需要从头、或者从尾遍历链表 |

#### 5.1.1.4. 如何保证 List 的线程安全？

1. 在 List#API 外，使用同步锁，来保证线程安全。

2. 直接使用 `Collections#SynchronizedList`，底层原理是，通过持有传入的 List 引用，以及 `mutex` 对象锁，使用 synchronized 关键字来修饰 List 方法，从而包装成线程安全的 List 实现类。
3. 使用 Vector 实现类，它是一个可增长的数组，默认初始容量为 10，每次扩容为原来容量的 2 倍，底层原理是，通过每个 API 方法都使用 synchronized 关键字来修饰，从而保证线程安全。
4. 使用 CopyOnWriteArrayList，它是一个写时复制、读操作无需加锁、写时加锁复制、只保证数据最终一致性，无法保证实时性的、线程安全的 List 实现类。

#### 5.1.1.5. HashMap 的数据结构？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.6. HashMap 的扩容机制，以及为什么是 2^n？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.7. JDK 7 与 JDK 8 中 HashMap 的区别？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.8. HashMap 如何保证线程安全？

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 5.1.1.9. JDK 7 与 JDK 8 中 ConcurrentHashMap 的区别？

见《[3.2.1.6. ConcurrentHashMap 底层原理？](#3.2.1.6. ConcurrentHashMap 底层原理？)》。

#### 5.1.2.0. CAS 的缺点，以及什么是总线风暴？

##### 1、总

1. CAS，CompareAndSwap，比较并交换，一种乐观锁的实现方式，是一种无锁算法，该算法关键依赖两个值，分别是期望值和新值，底层 CPU 利用原子操作，判断期望值是否还等于旧值，只有等于才会赋新值，否则就不做更新操作，而是继续自旋、继续比较。
2. 在 JDK 中，常常用到的地方有，ConcurrentHashMap、Atomic 原子类、FutureTask、synchronized 轻量级锁、ReentrantLock 显式锁、以及 AQS 等。

##### 2、分

1. 实现原理为，在操作系统层面，CAS 是一条 CPU `cmpxchg` 的原子指令，由于该指令具备原子性，所以，在使用 CAS 操作数据时，并不会造成数据不一致的问题。

2. 使用 CAS 进行无锁编程的步骤大致为：
   - 1）获得字段的期望值（oldValue）。
   - 2）计算出需要替换的新值（newValue）。
   - 3）然后，通过 CAS，尝试将新值（newValue）放入对应的内存地址中。
   - 4）如果 CAS 失败，就重复第（1）步到第（2）步，一直到CAS成功，这种重复就叫做 CAS 自旋。

3. 其**优点**是，性能开销小，
   - 1）由于 CAS 是处于用户态下 CPU 指令级的原子操作，所以，在用于线程同步时，线程也无需进入阻塞态，没有用户态与内核态之间的切换，性能开销较小。
   - 2）而 synchronized 重量级锁，涉及操作系统内核态下互斥锁的使用，线程的阻塞和唤醒，都需要在用户态和内核态间的切换，导致开销大、性能低下。
   - 3）然后就有了 synchronized  轻量级锁，使用 CAS 进行自旋抢锁优化，由于一直处于用户态下，所以，轻量级锁的开销是比较小。

4. 而其**缺点**则是，
   - 1）**只能保证单个变量的原子性**，当对一个变量执行操作时，可以使用 CAS 自旋的方式，来保证其原子性，但是，如果面对多个变量的操作时，CAS 就无法保证操作的原子性了。
     1. 解决方案是，把多个变量，合并成一个变量来操作。
   - 2）**空耗CPU资源**，在高并发场景下，大量的 CAS 做空自旋，会浪费很多 CPU 资源。
     1. 优化思路是，当并发修改的线程很少，冲突出现的机会很少时，自旋的次数很少，CAS 的性能会很高，而当并发修改的线程很多，冲突出现的机会很多时，自旋的次数很多，CAS 的性能则大大降低，所以，提升 CAS 无锁编程效率，关键在于减少冲突的机会。
     2. 一种解决方案是，**分散操作热点**，
        - 1）比如 LongAdder，其核心思想是热点分离，将 value 分离成一个数组，在多线程访问时，通过 Hash 算法，将线程映射到数组的某个元素进行操作，避免都访问同一个点。
        - 2）在最终结果获取时，则对数组中所有元素进行求和即可。
        - 3）可见，LongAdder 是通过以空间换时间的方式，将原来的一个 value 值，拆分为分布式的多个 value 数组元素，从而减少了 CAS 时线程之间的高冲突，以提升性能。
     3. 另一种解决方案是，**使用队列削峰**，将发生 CAS 争用的线程，加入一个队列中排队，降低 CAS 争用的激烈程度，比如 JUC#AQS 抽象队列同步器。
   - 3）**会有 ABA 问题**，是指线程在进行 CAS 操作时，虽然发现某个数据仍然等于期望值，CAS 也能操作成功，但这个期望值，可能已经不是之前意思了，存在被别的线程修改过、然后又修改回来的风险，这就是 ABA 问题。举个例子，在操作某个链表尾结点时，虽然看到的还是那个尾结点，但 CAS 操作成功之前，很可能就已经被别的线程，在前面增加了几个其他结点，此时的 CAS 面对的链表，实际上已经不是当时认为的那个链表了，是有问题的。
     1. 解决方案是，使用增加版本号或者时间戳的比较，比如，每次在执行数据的修改操作时，都带上一个版本号，版本号一致，才可以执行修改操作，并对版本号执行加 1 操作，否则，执行失败。由于每次操作的版本号都会增加，不会减少，因此，不会再出现 ABA 的问题。
   - 4）**会有发生总线风暴的风险**，
     1. CPU 会通过 MESI 缓存一致性协议，保障变量的缓存一致性，不同的内核需要通过总线来回通信，产生缓存一致性流量，由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将会成为瓶颈，导致总线风暴的发生。
     2. 不过，总线风暴与 CPU 架构有关，并不是所有的 CPU 都会产生总线风暴，在 SMP CPU 架构上，当有很多线程同时执行 `lockcmpxchg` lock 前缀指令操作时，可能会产生总线风暴。
     3. 而 Java#CAS，恰恰会在发现 CPU 是多核 CPU 时，为 CAS 底层的 `cmpxchg` CPU 原子指令，添加上 `lockcmpxchg` lock 前缀，导致存在总线风暴的风险。
     4. 解决方案还是那些，分散热点、使用队列削峰，最大程度地减少了同时 CAS 的操作数量。

   => 另，其他辅助资料有（选讲），

   - 1）Symmetric Multi-Processor，SMP，对称多处理器，服务器中多个 CPU 对称工作，每个 CPU 访
     问内存地址所需时间相同，主要特征是共享，包含对 CPU、内存、I/O 等进行共享。所有的 CPU 会共享一条总线，靠此总线连接主存，每个核都有自己的高速缓存，各核相对于总线，呈对称分布。因此，被称为对称多处理器。
   - 2）缓存一致性协议，指在多 CPU 的系统中，为了保证各个 CPU 的高速缓存中数据的一致性，会实现缓存一致性协议，每个 CPU 通过嗅探在总线上传播的数据，来检查自己的高速缓存中的值是否过期，当 CPU 发现自己缓存行对应的主存地址被修改时，就会将当前 CPU 的缓存行设置成无效状态，当其他 CPU 对这个数据执行修改操作时，本 CPU 会重新从系统主存中，把数据读到自己的高速缓存中。最常见的实现就是 MESI 协议。
   - 3）MESI 协议，是 MSI 写入失效协议的扩展，要求在每个缓存行（64字节，高速缓存操作的基本单位），维护两个状态位（2bit），使得每个缓存行可能处于 M 被修改的、E 独占的、S 共享的和 I 无效的 4 种状态的其中之一，是一种基于过期机制的高速缓存一致性保障协议。

##### 3、总

=> 以上，就是我对 CAS 的一些理解，请问有什么细节需要补充的吗？

#### 5.1.2.1. volatile 关键字的实现原理？

##### 1、总

1. 使用 volatile 关键字修饰变量，能够保证该变量的内存可见性，以及禁止该变量相关的指令重排序，但不能保证该变量做复合操作的原子性。
2. 不过，讲清楚 volatile 原理之前，还要讲一下内存屏障和 JMM Java 内存模型。

##### 2、分

###### 1）硬件层面的内存屏障

1. 内存屏障，Memory Barrier，又称内存栅栏，Memory Fences，是一系列的 CPU 指令，是一项让 CPU 高速缓存内存可见的技术，也是一项保障跨 CPU 内核有序执行指令的技术。
2. 硬件层内存屏障，共分为三种：读屏障、写屏障和全屏障。
   - 1）读屏障：Load Barrier，在指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，强制重新从主存加载数据，同时，会告诉 CPU 和编译器，先于这个屏障的指令必须先执行。
   - 2）写屏障：Store Barrier，在指令后插入写屏障，可以在指令执行时，让高速缓存中的最新数据更新到主存，让其他线程可见，同时，会告诉CPU和编译器，后于这个屏障的指令必须后执行。
   - 3）全屏障：Full Barrier，又称为 StoreLoad Barriers，是一种全能型的屏障，具备读屏障和写屏障的能力。
3. 所以，硬件层内存屏障的作用：
   - 1）强制让高速缓存的数据失效：它会强制把高速缓存中的最新数据写回主存，让高速缓存中相应的脏数据失效，一旦完成写入，任何访问这个变量的线程将会得到最新的值。
   - 2）阻止屏障两侧的指令重排序：编译器和 CPU，可能为了使性能得到优化，而对指令重排序，但是插入一个硬件层的内存屏障，相当于告诉 CPU 和编译器，先于这个屏障的指令必须先执行，后于这个屏障的指令必须后执行。

=> 由于不同的物理 CPU 硬件，所提供的内存屏障指令的差异非常大，因此，JMM 定义了自己的一套相对独立的内存屏障指令，用于屏蔽不同硬件的差异性，JMM 会要求，JVM 要为不同的平台，生成相应的硬件层的内存屏障指令。

所以，为了解释 volatile 的禁止指令重排序，还需要讲一下 JMM 的内存屏障~

###### 2）JMM Java 内存模型

![1630043244494](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630043244494.png)

1. JMM，Java Memory Model，Java 内存模型，它不像 JVM 内存结构那样，为真实存在的运行实体，而是体现为一种规范和规则，这些规范定义了一个线程对共享变量写入时，是如何确保对另一个线程是可见的。

   - 1）为此，JMM 提供合理的禁用缓存、以及禁止重排序的方法，以解决可见性和有序性。
   - 2）同时，它屏蔽了各种硬件和操作系统的访问差异，保证 Java 程序在各种平台下，对内存的访问最终都是一致的。

2. JMM 规定，所有变量都存储在主存中（类似于物理内存），每个线程都有自己的工作内存（类似于CPU中的高速缓存）。工作内存保存了线程使用到的变量的拷贝副本，线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行，不同线程之间，无法直接访问彼此工作内存中的变量，要想访问，就只能通过主存来进行传递。

3. 在 JMM 中，还定义了一套，JMM 主存与工作内存之间交互的协议，即一个变量是如何从主存拷贝到工作内存的，又是如何从工作内存写入主存的，该协议包含 8 种操作，并且要求 JVM 的具体实现，必须保证其中每一种操作都是原子的、不可分割的。

   ![1630045226983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630045226983.png)

   | JMM 操作 | 作用对象 | 说明                                                         |
   | -------- | -------- | ------------------------------------------------------------ |
   | Read     | 主存     | 读取。把一个变量的值从主存传输到工作内存中，以便随后的Load操作使用。 |
   | Load     | 工作内存 | 载入。把Read操作从主存中得到的变量值，载入到工作内存的变量副本中（可以简单理解为CPU的高速缓存）。 |
   | Use      | 工作内存 | 使用。每当JVM遇到一个需要使用变量值的字节码指令时，都会执行Use操作，会把工作内存中的一个变量值传递给执行引擎。 |
   | Assign   | 工作内存 | 赋值。每当JVM遇到一个给变量赋值的字节码指令时，都会执行Assign操作，操作引擎通过Assign操作给工作内存的变量赋值。 |
   | Store    | 工作内存 | 存储。把工作内存的一个变量值传递到主存中，以便随后的Write操作使用。 |
   | Write    | 主存     | 写入。把Store操作从工作内存中得到的变量值，写入到主存的变量中。 |

4. 关于 JMM 内存屏障，由于不同 CPU 硬件实现内存屏障的方式不同，JMM 屏蔽了这种底层 CPU 硬件平台的差异，定义了不对应任何 CPU 的 JMM 逻辑层内存屏障，提供了自己的内存屏障指令，要求 JVM 编译器实现这些指令，由 JVM 在不同的硬件平台，生成对应的内存屏障机器码，禁止特定类型的编译器（不是所有的编译器重排序都要禁止）和 CPU 重排序，从而解决有序性问题。

5. JMM 内存屏障，主要有 Load 和 Store 两类：

   - Load Barrier：读屏障，在读指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，重新从主存加载数据。
   - Store Barrier：写屏障，在写指令后插入写屏障，可以在指令执行时，让写入缓存的最新数据写回主存。

6. 然后，在实际使用时，JMM 会对 Load Barrier 和 Store Barrier 两类屏障进行组合：

   - 1）LoadLoad：LL 屏障，在 Load2 要读取的数据被访问前，使用 LoadLoad 屏障，能保证 Load1 要读取的数据被读取完毕。

     ```java
     // LoadLoad屏障伪代码
     Load1；LoadLoad；Load2
     ```

   - 2）StoreStore：SS 屏障，在 Store2 以及后续写入操作执行前，使用 StoreStore 屏障，能保证 Store1 的写入结果对其他 CPU 可见。

     ```java
     // StoreStore屏障伪代码
     Store1；StoreStore；Store2
     ```

   - 3）LoadStore：LS 屏障，在 Store2 以及后续写入操作执行前，使用 LoadStore 屏障，能保证 Load1 要读取的数据被读取完毕。

     ```java
     // LoadStore屏障伪代码
     Load1；LoadStore；Store2
     ```

   - 4）StoreLoad：SL 屏障，该屏障是一个全能型屏障，由于兼具其他3个屏障的效果，因此开销是 4 种屏障中最大的。在 Load2 以及后续所有读取操作执行前，使用 StoreLoad 屏障，能保证 Store1 的写入对所有 CPU 可见。

     ```java
     // StoreLoad屏障伪代码
     Store1；StoreLoad；Load2
     ```

###### 3）volatile 底层原理

1. 再说回 volatile，使用 volatile 关键字修饰变量，能够保证该变量的内存可见性，以及禁止该变量相关的指令重排序，但不能保证该变量做复合操作的原子性。

2. 保证内存可见性的意思是，使用 volatile 修饰的变量，在变量值发生改变时，会立刻同步到主存，并使其他线程的变量副本失效，即一个线程修改了某个 volatile 变量的值，该值对其他线程立即可见，其原理为：

   - 1）使用 volatile 修饰的变量，它的 JMM read、load、use 操作都是连续出现的，每次使用变量时，都要从主存读取最新的变量值，替换私有内存的变量副本值。
   - 2）同时，assign、store、write 操作也都是连续出现的，每次对变量的改变，都会立马同步到主存中，从而保证它的读写的内存可见性。

3. 另外，在硬件层面，volatile 变量操作的汇编指令前，会多出一个 lock 前缀指令 `lock ADD` ，lock 前缀指令具有以下功能：

   - 1）将当前 CPU 缓存行数据，立即写回主存，在执行指令期间。
   - 2）失效其他 CPU 中相同地址的缓存行，修改回写操作要经过总线传播数据，其他 CPU 通过嗅探在总线上传播的数据，来检查自己缓存的值是否过期，一旦发现自己缓存行对应的数据被修改，就会将自己的缓存行设置为无效状态，强制重新从主存中把数据读到自己的缓存中。

   => 以上两点，可以说是从硬件层面实现了 volatile 的内存可见性。

   - 3）lock 前缀指令，还可以作为内存屏障，禁止指令重排序，避免多线程环境下，程序出现乱序执行的现象。

4. 禁止指令重排序的意思是，用 volatile 修饰的变量，JVM 在生成字节码时，会在指令序列中插入内存屏障，

   - 1）在每个 volatile 读操作后，插入一个 LoadLoad 屏障，以及一个 LoadStore 屏障，禁止后面的普通读、普通写、和前面的 volatile 读操作之间发生重排序。

     ![1630053036307](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630053036307.png)

   - 2）在每个 volatile 写操作前，插入一个 StoreStore 屏障，在写操作后，插入一个 StoreLoad 屏障，禁止前面的普通写、和后面的 volatile 写操作之间发生重排序，同时，禁止后面的普通读、和前面的 volatile 写操作之间发生重排序。

     ![1630052862174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630052862174.png)

   => 以上两点，实现了 volatile 的有序性。

5. 虽然 volatile 修饰的变量，其要求对变量的（read、load、use）以及（assign、store、write）必须是连续出现的，每次读取的变量可以是最新值，且可以强制刷新回主存，但是在不同 CPU 内核上并发执行的线程，还是有可能出现读取脏数据的。比如：

   ![1630118559462](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630118559462.png)

   - 1）假设有两个线程 A、B，分别运行在 Core1、Core2 上，此时有个 value，值为 0，线程 A、B 也都读取了 value 值到他们自己的工作内存中。
   - 2）现在，线程 A 将 value 改成了 1 之后，完成了 assign、store 操作，但在执行 write 指令之前，线程 A 的 CPU 时间片用完了，导致 write 操作没有执行，value=1 没有到达主存。
   - 3）由于线程 A 的 store 指令触发了写信号，导致线程 B 的缓存行过期，B 则重新从主存读取了 value 值，此时线程 A 的 write 操作还没有完成，所以，线程 B 读到的 value 值还是 0。
   - 4）在线程 B 执行完成所有操作之后，则将 value 改成 1，并写入主存中。
   - 5）然后，线程 A 的时间片重新拿到，重新执行 store 操作，将过期了的 1 写入主存。
   - 6）此时，A、B 两线程执行了 2 次 +1 操作，但最终结果只增加了 1，而不是 2。
   - 7）因此，对 volatile 变量的复合操作不具备原子性，本案例中的复合操作是读取 value，value + 1，写回 value。
   - 8）对于这种复合操作，其原子性解决方案是，使用锁，保证临界区互斥执行。

##### 3、总

=> 以上，就是我对 volatile 的一些理解，请问有什么细节需要补充的吗？

#### 5.1.2.2. 线程池的数据结构，实现原理，以及线程数如何选择？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 5.1.2.3. MySQL 主键索引、二级索引、联合索引查找数据的原理？

##### 1）主键索引数据查找原理

1. InnoDB#主键索引，使用的是聚蔟索引，如果创建的表没有主键，那么 InnoDB 会隐式定义一个主键，来作为聚蔟索引。
2. 聚蔟索引，叶子结点就是数据结点，将表数据和主键一起存储，数据的物理存放顺序与索引顺序一致，一张表只有一个聚蔟索引。
3. 聚蔟索引在查找数据时，只要根据搜索树的查找原则，小的查左边，大的查右边，定位到叶子节点即是数据，这个操作叫做回表。

##### 2）二级索引数据查找原理

1. 聚蔟索引的二级索引，其叶子结点不保存引用数据，而是保存行的主键值。
2. 然后，根据叶子节点的主键值，回表查找到数据。
3. 这种二级索引在 InnoDB 中比如有，普通索引 和 联合索引。

##### 3）联合索引数据查找原理

1. 联合索引，指在多个字段上创建的索引，数据查找原理需要遵循最左前缀原则。

2. 最左前缀原则，指的是索引按照最左优先的方式匹配索引，主要使用在联合索引中，联合索引的数据结构
   在 InnoDB 中是 B+Tree，它会按照第一个关键字、第二个关键字...顺序进行索引排列。

3. 如果查询的条件遵循了最左前缀原则，那么 MySQL 会：

   ![1648112848858](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648112848858.png)

   - 1）先根据第 1 个关键字，查找联合索引树。
   - 2）定位到索引树的叶子结点后，找出所有满足第 1 个关键字的叶子结点。
   - 3）第 1 个关键字的叶子结点确定后，如果这些叶子结点，对于第 2 个关键字是存在且是顺序的，那么 MySQL 则会使用二分查找的方式，查找这些叶子结点，相当于该索引继续匹配第 2 个关键字。
   - 4）如果这些叶子结点，对于第 2 个关键字来说，不存在或者是乱序的，那么就出现了索引失效，导致后面的条件，都无法继续走上该联合索引，而是根据之前选择的叶子结点的主键，进行回表查找。

#### 5.1.2.4. MySQL 联合索引失效原理？

联合索引失效场景，其原理都是因为，匹配到某个关键字的叶子结点时，不满足存在性或者顺序性：

1. 如果不是从索引的最左列开始查找，则无法使用该联合索引。
2. 不能在中间跳过索引中的某个列，这样的查询只能使用到联合索引的前几列。
3. 如果查询中有某个列的范围查询，那么该列右边的所有列，都无法使用该联合索引进行查找。

#### 5.1.2.5. MySQL 3 个二级索引好还是 1 个 3 字段的联合索引好？

1. 在应有的查询条件下，MySQL 面对 3 个二级索引，如果是 `and` 操作，则会使用性能最好的 1 个二级索引进行匹配，其他 2 个条件则会走索引下推优化（extra 会显示 `Using index condition`），或者走普通的 where 查询（extra 会显示 `Using Where`），而不是直接走它们的二级索引。
2. 如果是 `or` 或者 `union` 的操作，则有可能会走索引合并，type 会显示 `index_merge`，表示合并了 `or` 两侧字段的索引，性能来得比 `range` 好些。
3. 而如果面对相同的条件，建立起一个 3 字段的联合索引的话，那么有可能会根据最左前缀原则去匹配。
4. 因此，这两者到底谁性能更好，要看具体情况才能定夺，比如这些条件到底是什么，会不会引起索引失效，表的数据量有多大，以及 SQL 的结构是什么等。

#### 5.1.2.6. MySQL 二级索引和联合索引是不是建的越多越好？

1. 在 MySQL 中，创建索引的目的是，让索引过滤更多的行，快速定位记录，或者利用索引的有序性，对于那些不符合目的的，无需创建多余的索引。
2. 对于那些用作 where 条件的、参与分组的、参与排序的、参与去重的、参与联表的、或者是唯一的字段，一般会去创建索引。
3. 而对于那些更新多、查询少、不频繁 where 的、或者表数据少、字段列重复数据多的字段，一般都不用创建多余的索引，因为要么是字段用不到，要么是用了但不划算。
4. 无用的索引过多，会额外占据存储空间，所以，索引并不是建的越多越好，满足要求、够用就行。

#### 5.1.2.7. 介绍一下 B+ 树，以及 MySQL 为什么采用 B+ 树？

##### 1、总

MySQL 之所以采用 B+ 树，作为索引底层的数据结构，我认为是为了追求性能，以及满足范围查询。

##### 2、分

1. **如果采用 BST**，二叉查找树，虽然可以在 log（n）内查找到目标数据，但在最坏情况下，可能会退化成链表，查询的时间复杂度也退化成了 O（n），性能太慢，故放弃。

   ![1648116903919](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648116903919.png)

2. **如果采用 AVL**，平衡二叉搜索树，虽然能保证，每个结点的左子树和右子树的高度差不会超过 1，优化了 BST 退化成链表的问题，但在大规模数据存储的时候，AVL 会由于树高度过大，会导致每次查找只能找出 2 个结点装入内存，造成磁盘 I/O 读写过于频繁，导致效率低下，故也放弃。

   ![1648116960901](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648116960901.png)

3. **如果采用 HashMap**，哈希表，虽然可以实现在 O（1）内，查找到目标数据，但在数据量过大、散列算法不好时，会出现大量的哈希冲突，查询效率大幅度降低，且由于哈希的特性，不支持范围查找，只能做等值匹配，故也放弃。

   ![1648117079088](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117079088.png)

4. **如果采用 SkipListMap**，跳跃表，虽然可以以二分查找的方式，在 O（logn）内找到目标数据，但每次二分，都需要把一半的节点加载到内存，而在数据量大时，一半节点 MySQL 一页装不下，需要多次 I/O，效率也不理想，故也放弃。而 Redis 本身就是内存数据库，所以采用跳跃表是没什么问题的。

   ![1648117132681](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117132681.png)

5. **如果采用 B-Tree**，平衡多路搜索树，m 阶 B-Tree 每个节点都包含 data 数据、m - 1 个关键字、以及 m 个子节点引用，可以有效地降低数树的高度，大大减少查找的次数，性能得到了大幅提升。但由于 B-Tree 每个节点包含 data 数据，会使得一页内容装不下太多结点，磁盘 I/O 次数比较多，且每次范围查询时，都需要多次从头遍历 B-Tree，性能低下，故也放弃。

   ![1648117001612](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117001612.png)

6. **如果采用 B+Tree**，B+ 树，m 阶 B+ 树 非叶子节点包含 m 个关键字、m 个子节点引用，不包含 data 数据，可以使得每次 I/O 加载更多的节点到内存中，减少了 I/O 次数，对比 B-Tree 性能有提升，同时，叶子节点会冗余父结点的关键字，包含了全部的关键字，以及按照关键字大小， 顺序链接起来，构成一个有序双向链表，在做范围查找时，只需要在链表上顺序查找，而无需从头遍历整颗树，对比 B-Tree 性能得到了很大的提升，故 B+Tree 在做大量的磁盘数据查找，是非常适合的。

   ![1648117033116](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117033116.png)

##### 3、总

因此，MySQL 采用的 B+ 树，来作为索引底层的数据结构，而不是其他。

#### 5.1.2.8. 分布式 ID 的实现方案？

##### 1、总

1. 在分库分表环境中，由于表中数据同时存在不同数据库中，平时使用的自增主键 ID 将无用武之地，因为某个分区数据库自生成的 ID 无法保证全局唯一。
2. 因此，需要单独设计全局主键，来避免跨库主键重复的问题，我了解到的方案有：UUID、MyISAM ID 表、高可用 ID 服务器、Snowflake 分布式自增 ID 算法、以及美团的 Leaf 分布式 ID 生成系统。

##### 2、分

###### 1）UUID

UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8­4­4­4­12 的 36 个字符，比如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：方案最简单，且本地生成，性能高，没有网络耗时。
- **缺点**：
  1. 由于 UUID 非常长，会占用大量的存储空间。
  2. UUID 作为主键，建立索引和基于索引进行查询时，都会存在性能问题，在 InnoDB 下，UUID 的无序性会引起数据位置频繁变动，导致页分裂。

###### 2）MyISAM ID 表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();
```

- **概念**：
  1. `stub` 字段（存根）设置为**唯一索引**，同一 `stub` 值在 `sequence` 表中只有一条记录，支持同时给多张表生成全局 ID。
  2. 使用 MyISAM 存储引擎而不是 InnoDB，可以获取更高的性能，因为 MyISAM 使用的是表级锁，对表的读写是串行的，不用担心在并发时两次读取同一个 ID 值的问题。
  3. 使用 `REPLACE INTO + SELECT` 来获取自增 ID，保证两操作在同一事务内，它会先删除旧数据，再生成新数据，从而实现主键自增。
- **优点**：实现简单。
- **缺点**：
  1. 存在单点问题，且强依赖 DB，当 DB 异常时，会导致整个分布式系统都不可用。
  2. 虽然可以配置主从来增加可用性，但当主库挂了，主从切换时，数据一致性难以得到保证。
  3. 因此，整个系统的性能瓶颈，被限制在单台 MySQL 的读写性能上。

###### 3）高可用 ID 服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：Flickr（弗里克，雅虎的一个图片分享网站）团队使用的一种主键生成策略，与上面的 `sequence` 表方案类似，但可以更好地解决了单点故障和性能瓶颈的问题。

- **思想**：

  1. 建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 `sequence` 表用于记录当前全局 ID。
  2. 表中 ID 增长的**步长相同，等于库的数量，起始值依次错开**，这样能将 ID 的生成散列到各个数据库上，比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...）等等。

- **优点**：生成 ID 的压力，能够均匀分布在多台机器上，同时提高了系统的容错能力，当第一台出现了错误，可以自动切换到第二台机器，来获取 ID。

- **缺点**：

  1. 系统添加机器水平扩展时，需要停止原本正在运行的 ID 服务器，以**修改步长**。
  2. 每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。

- **优化方案 **：**批量获取 ID**。

  - 使用批量获取的方式，可以降低数据库的写压力，每次获取**一段**区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    - 1）比如，还是使用 2 台 DB 保证可用性，数据库中只存储当前的最大 ID。
    - 2）ID 生成服务，每次批量获取 6 个ID，可以先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从**号段缓存**中依次派发 0~5 的 ID。
    - 3）当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的ID。
    - 4）这样，数据库的压力降低为原来的 1/6。
  - **缺点**：ID 生成服务需要维护最大 ID 值，再下次生成 ID 时，需要告诉 DB M1、DB M2 各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

###### 4）Snowflake 分布式自增 ID 算法

Twitter 的 snowflake 算法，解决了分布式系统生成全局 ID 的需求，可以生成 64 位的 long 类型的数值。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

- **概念**：1 + 41 + 10 + 12  = 64位。
  1. 首先是，第 1 位不使用。
  2. 接下来是， 41 位的毫秒级时间戳，最大可以表示 **69年** 的时间。
  3. 然后是，5 位的 `datacenterId`，5位的 `workerId`，这 10 位长度，最多支持部署**1024 个节点**。
  4. 最后是，12 位是毫秒内的计数值，最大支持每个节点、每毫秒产生**4096 个 ID 序列**。
- **优点**：
  1. 毫秒数在高位，生成的 ID 整体上按时间趋势是**递增**的，还可以根据自身业务灵活分配 bit 位。
  2. 不依赖第三方系统，稳定、效率高，理论上 QPS 约为 409.6 w/s（2^12 * 1000 ms），且整个分布式系统中不会产生 ID 碰撞。
- **缺点**：强依赖于机器时钟，如果时钟回拨，则可能导致生成的 ID 重复。

###### 5）美团点评分布式ID生成系统 - Leaf

Leaf，服务美团点评公司内部产品，包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在 4 C 8 G 的机器上，QPS 能压测到近 5 w/s，TP 999 1ms，能够满足大部分的业务需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

**1、Leaf - segment ID 服务器方案：**

- **思想**：
  1. 获取 ID 时，向 proxy server 代理服务器批量获取 ID，每次获取一个 segment 号段（由 `step` 决定大小）的值。
  2. 用完之后，再去获取新的号段，可以大大减轻数据库的压力。
- **实现**：
  1. `biz_tag` 用来区分业务，`max_id` 表示该 `biz_tag` 目前所被分配的 ID 号段的最大值，`step` 表示每次分配的号段长度。
  2. 比如，`test_tag` 在第 1 台 Leaf 机器上是 1~1000 的号段，当这个号段用完时，会去加载另一个长度为step=1000 的号段，而如果另外机器的号段都没有更新的话，此时第 1 台机器会重新加载 3001~4000 的号段，同时，数据库对应的 `biz_tag` 这条数据的 `max_id` 会从 3000 被更新成 4000。
  3. 这样，各业务不同的发号需求用 `biz_tag` 字段来区分，每个 `biz-tag` 的 ID 相互隔离，互不影响，如果以后有性能要求，需要对数据库进行扩容时，则不用复杂的扩容操作，只需要对 `biz_tag` 分库分表即可。
  4. 而且，对比原来获取 ID 每次都需要写数据库，现在只需要把 `step` 设置得足够大，比如 1000，那么只有当 1000 个号被消耗完了之后，才会去重新读写一次数据库，此时读写数据库的频率从1  减小到了 **1 / step** 。
- **优点**：
  1. Leaf 服务可以很方便的进行**线性扩展**，性能完全能够支撑大多数业务场景。
  2. 生成的 ID 是**趋势递增**的 8 byte 的数字，满足上述数据库存储的主键要求。
  3. 容灾性高，Leaf 服务内部有**号段缓存**，即使 DB 宕机，短时间内，Leaf 仍能正常对外提供服务。
  4. 可以自定义 `max_id` 的大小，非常方便业务从原有的 ID 方式上**迁移**过来。
- **缺点**：
  1. **TP 999 数据波动大**：当号段使用完之后，还是会 hang 在更新数据库的 I/O 上，TP 999 数据会出现偶尔的尖刺。
  2. **高可用得不到保障**：DB 宕机会造成整个系统不可用。
  3. **生成的 ID 不够随机**：会泄露发号数量的信息，不太安全。

**2、双 buffer 优化方案：**

目的是，优化第 1 个缺点，当号段使用完、线程取号时阻塞的问题。

![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **背景**：
  1. Leaf 取号段的时机，是在号段消耗完时进行的，意味着号段临界点的 ID 下发时间，取决于下一次从 DB 取回号段的时间，并且在这期间，进来的请求也会因为 DB 号段没有取回来，导致线程阻塞。
  2. 假如 Leaf 服务取 DB 时，网络发生抖动，或者 DB 发生慢查询，就会导致整个系统的响应时间变慢。
- **思想**：
  1. 为了让 DB 取号段的过程能够做到无阻塞，不会在 DB 取号段时阻塞请求线程，可以让发号段消费到某个点时，就**异步**的把下一个号段加载到内存中，而不需要等到号段用尽时，才去更新号段。
- **实现**：
  1. 采用双 buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。
  2. 当前号段已下发 10% 时，如果下一个号段未更新，则**异步**另启一个更新线程去更新下一个号段。
  3. 当前号段全部下发完后，如果下个号段准备好了，则切换到下个号段为当前 segment 接着下发，循环往复。

**3、高可用容灾方案：**

目的是，解决第 2 个缺点，DB 宕机会造成整个系统不可用的问题。

![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

**DB 高可用方案**：

1. 采用 1 主 2 从的方式，同时分机房部署，Master 和 Slave 之间采用半同步复制的方式，进行数据同步，同时使用公司的 DBProxy（原 Atlas）数据库中间件，做主从切换。
2. 当然，这种方案在一些情况会退化成**异步模式**，甚至在非常极端情况下仍然会造成**数据不一致**的情况，但是出现的概率非常小。
3. 如果系统确实要保证 100% 的数据强一致，可以选择使用**类Paxos算法**，实现强一致 MySQL 的方案，但这样运维成本和精力都会相应的增加，应该需要根据实际情况进行选型。

**应用高可用方案**：

1. Leaf 服务分 IDC 部署，内部的服务化框架是 `MTthrift RPC`。
2. 服务调用时，根据负载均衡算法，优先调用同机房的 Leaf 服务。
3. 如果该 IDC 内，Leaf 服务不可用，则会选择其他机房的 Leaf 服务。
4. 同时，服务治理平台 `OCTO` ，还提供了针对服务的过载保护、一键截流、动态流量分配等服务保护措施。

**4、Leaf-snowflake 方案：**

目的是，优化第 3 个缺点，生成的 ID不够随机，会泄露发号数量信息，不太安全的问题。

![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

Leaf-snowflake 方案，完全沿用了 snowflake 方案的 bit 位设计，即是 `1+41+10+12` 的方式组装 ID 号。

1. 对于 `workerID` 的分配，当服务集群数量较小时，完全可以手动配置。
2. 但当 Leaf 服务规模较大时，动手配置成本太高，此时可以使用 ZK 持久顺序节点的特性，自动对 snowflake 节点配置 `wokerID`。

**对接 ZK 的步骤**：

1. 启动 Leaf-snowflake 服务时，会去连接 ZK，在 `leaf_forever` 父节点下，检查自己是否已经注册过，是否有该节点的持久化顺序子节点。
2. 如果有注册过，则直接取回自己的 `workerID`，启动服务。
3. 如果没有注册过，则在该节点下，创建一个持久化顺序节点，创建成功后，取回顺序号当做自己的 `workerID` 号，启动服务。
4. 除了每次会去 ZK 拿数据以外，也会在本机文件系统上，缓存一个 `workerID` 文件，当 ZK 出现问题且恰好 Leaf-snowflake 服务机器也需要重启时，还能保证服务正常启动，做到了对 ZK 的**弱依赖**，一定程度上提高了 SLA 。

![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

**解决 snowflake 时钟回退问题**：

由于 snowflake 强依赖机器时间，如果其发生了回拨，则可能会生成重复的 ID，解决方案为：

1. 首先，服务启动时，先检查自己是否写过 `ZK#leaf_forever` 节点。
   - 1）如果写过，则用自身系统时间与 `leaf_forever/#{self}` 节点记录时间做比较，且小于 `leaf_forever/​#{self}` 的时间，则认为当前机器时间发生了回拨，服务启动失败并报警。
   - 2）如果没写过，则证明是新服务节点，此时需要创建持久顺序节点 `leaf_forever/#{self}` ，并写入自身系统的时间。
2. 接下来，综合对比其余 Leaf 节点的系统时间，来判断自身系统时间是否准确，具体做法是：
   - 1）取 `leaf_temporary` 下的所有临时节点（**所有运行中的** Leaf-snowflake节点）的服务 IP+端口。
3. 然后，通过 RPC 请求，得到它们各自的系统时间，计算 `at = sum(time) / nodeSize`。
4. 如果计算结果 `at < 阈值`，认为当前系统时间准确，可以正常启动服务，同时写临时节点 `leaf_temporary/#{self}` ，每隔一段时间（3s），上报自身系统时间，并写入到 `leaf_forever/#{self}` 中，以维持租约。
5. 否则，则认为本机系统时间发生大步长的偏移，启动失败并报警。

##### 3、总

=> 以上，就是我对 分布式全局 ID 实现方案的一些理解，请问有什么细节需要补充的吗？

#### 5.1.2.9. MySQL 隐藏主键生成原理？

##### 1、总

1. 如果没有主动设置主键，就会选一个不允许为 NULL 的第一个唯一索引列作为主键列，并把它用作聚集索引。
2. 如果没有这样的索引，就会使用自增的、占 6 个字节的行号，来生成一个聚集索引，把它当做主键，这个行号可以使用 `select _rowid from ${table_name}` 进行查询。

##### 2、分

主键自增 / `AUTO_INCREMENT ` 原理：

1. 如果字段被定义为 `AUTO_INCREMENT`， 那么在插入一行数据时，该字段被指定为 0、null、或者没指定值，那么，就先获取自增锁，把这个表存好的 `AUTO_INCREMENT` 值（初始从 `auto_increment_offset` 开始）填到自增字段中。
   - 自增锁，不是一个事务锁，而是要看 `innodb_autoinc_lock_mode` 策略的配置（默认为 1），0 表示语句执行完才释放，1 表示普通语句申请完马上释放，批量插入语句则等到语句结束才释放，2 表示所有语句都会申请完马上释放。
2. 如果插入数据时，该字段指定了具体的值，则会直接使用语句里指定的值。
3. 如果这个值比当前 `AUTO_INCREMENT` 值小，那么自增值不变，否则，就需要修改 `AUTO_INCREMENT` 为该字段插入的值 + 1。注意，如果此时插入的主键值重复、或者其他原因，导致了事务回滚，被修改的 `AUTO_INCREMENT` 是不会重新减少回去的，所以，会出现自增值不连续的情况。
4. 接着往后，则会以 `auto_increment_increment` 为步长，持续叠加，或者像上面那样碰到大于 `AUTO_INCREMENT` 的、新插入的值然后 +1 并更新。

##### 3、总

=> 以上，就是我对 MySQL 隐藏主键生成原理 的一些理解，请问有什么细节需要补充的吗？

#### 5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？

##### 1、总

1. 事务，Transaction，是指访问、更新数据库数据一个程序执行单元，是逻辑上的一组操作，要么都执行，要么都不执行，其执行的结果，必须使数据库从一种一致性状态，变到另一种一致性状态。
2. 而 ACID 则是衡量事务的四个维度，分别是 A 原子性、C 一致性、I 隔离性、D 持久性。

##### 2、分

1. **原⼦性**： Atomicity， 指事务是最小的执行单位，不可再分割，整个事务中所有的操作，要么全部提交成功，要么全部失败回滚，强调的是事务操作的原子不可分割。
   - 1）在 MySQL 中，其实现原理是，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log，如果事务执行失败或调用了 `rollback`，导致事务进行了回滚，就可以根据 undo log 的内容，做与之前相反的操作，把 Buffer Pool 中修改了的数据，回滚到修改之前的样子，从而实现事务原子性。
2. **一致性**：Consistency， 指事务执行结束后，数据库的完整性约束不会被破坏，都是合法的数据状态，强调的是数据状态事务前后的一致性。
   - 1）一致性是事务追求的最终目标，原子性、持久性和隔离性都是为了保证数据库的一致性。
   - 2）其中，在 MySQL 中，实现一致性的措施包括：
     1. 数据库层面的保障：原子性、持久性和隔离性的保证，以及其他一些完整性约束，比如不允许向整型列插入字符串值，或者字符串长度不能超过列的限制等等。
     2. 应用层面的保障：比如，如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致，此时需要保证应用逻辑是符合一致性的。
3. **隔离性**： Isolation，指并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间的数据库是独⽴的，一个事务所做的修改，在最终提交之前，对其他事务是不可见的，强调的是事务间的数据操作互不影响。
   - 1）在 MySQL 中，其实现原理是，写写隔离，通过使用锁机制来保证，写读隔离，快照读使用 MVCC 来保证，当前读则使用锁机制l来保证。
4. **持久性**：Durability， 指事务被提交之后，它对数据库中的数据改变是持久的，即使数据库发⽣故障，也不应该对其有任何影响，强调的是事务后的数据会被永久保存。
   - 1）在 MySQL 中，其实现原理是，Buffer Pool 和 redo log。
   - 2）首先是 Buffer Pool，
     1. 为减少每次读写数据的磁盘 I/O，InnoDB 提供了 Buffer Pool 缓存，作为访问数据库的缓冲。
     2. 当从数据库读取数据时，InnoDB 会先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，才会从磁盘读取，然后放入 Buffer Pool 中。
     3. 当向数据库写入数据时，同样 InnoDB 也会先写入 Buffer Pool，Buffer Pool 中修改的数据，会定期刷新到磁盘中，这一过程称为刷脏。
     4. 优点是，大大提高了读写数据的效率。而缺点则是，如果 MySQL 宕机，Buffer Pool 中修改的数据还没有刷新到磁盘中，那么就会导致数据的丢失，无法保证事务的持久性。
   - 3）所以，InnoDB 引入了 redo log，来解决 Buffer Pool 的问题， 以保证事务的持久性：
     1. 这样，在修改 Buffer Pool 中的数据后，会再把数据写到 redo log 缓冲区中。
     2. 然后，根据 `innodb_flush_log_at_trx_commit` 来决定 redo log 的刷盘机制：
        - 1）0：表示当事务提交时，不会把 redo log 缓冲区的日志，同步到 redo log 磁盘文件中，而是要等待线程每秒的刷新，所以，不能保证全部写入成功。
        - 2）1：表示当事务提交时，会主动把 redo log 缓存区的日志，同步到 redo log 磁盘文件中，能够保证全部写入成功。
        - 3）2：表示当事务提交时，会异步把 redo log 缓存区的日志，同步到 redo log 磁盘文件中，也是不能保证全部写入成功的。
     3. 由于写 redo log 是追加操作，属于顺序 I/O，且刷回磁盘的只是被修改的部分，对比 Buffer Pool 刷脏的随机 I/O 以及全量刷脏，性能来得更高。
     4. 有了 redo log 磁盘文件后，当 MySQL 宕机了，重启时，就可以读取 redo log 中的数据，对数据库进行恢复，保证了事务的持久性。

##### 3、总

总结一下，undo log、redo log 和 bin log：

| 不同点   | undo log                                    | redo log                       | bin log                      |
| -------- | ------------------------------------------- | ------------------------------ | ---------------------------- |
| 名称     | 回滚日志                                    | 重做日志                       | 二进制日志                   |
| 存储内容 | 属于逻辑日志，内容为版本链需要的相关信息    | 属于物理日志，内容为数据页     | 逻辑日志，内容为一条条SQL    |
| 作用     | 是 MySQL 实现事务原子性和 MVCC 隔离性的基础 | 用于崩溃恢复，保证事务的持久性 | 用于时间点恢复，保证主从复制 |
| 实现层面 | 由 InnoDB 存储引擎实现                      | 由 InnoDB 存储引擎实现         | 由 MySQL 服务器实现          |
| 写入时机 | 事务提交前，当做数据合并到 redo log 中      | 事务提交前刷盘                 | 事务提交前刷盘               |

最后，再总结一下，事务读写数据到提交的整体流程为：

1. 事务读时，则加载缓存数据到 Buffer Pool 缓冲池。
2. 事务写时，先是记录数据旧值到 undo log 缓冲区中。
3. 然后，更新 Buffer Pool 中的内存数据。
4. 接着，把更新后的数据，写入到 redo log 缓冲区中。
5. 事务准备提交，则把 undo log 缓冲当做数据，一起写入 redo log 缓冲区中，然后 redo log 日志刷入磁盘。
6. 也是在此时，bin log 也写入磁盘。
7. bin log 写入磁盘后，还会写入 commit 标记到 redo log 磁盘文件中。
8. 最后，I/O 线程把 Buffer Pool 中修改的数据，定期刷脏到磁盘中，事务提交。
9. 如果要重启恢复，则先回放 redo log，生成数据到 Buffer Pool 内存中，然后从 redo log 中构造 undo page，做相反的操作，回滚掉被修改了的内存数据，以及使用 undo page 实现 MVCC。

![1648126170770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648126170770.png)

=> 以上，就是我对 MySQL 事务 ACID 实现原理的一些理解，请问有什么细节需要补充的吗？

#### 5.1.3.1. MySQL Buffer Pool 满了以后会怎么样？

##### 1、总

首先，要讲一下 Buffer Pool 是什么，

1. 实际上，MySQL 中的数据，最终都是要存放在磁盘文件上的。
2. 但是，在对 MySQL 执行增删改时，不可能直接更新磁盘上的数据，因为如果对磁盘进行随机读写操作，那速度相当的慢，随便一个大磁盘文件的随机读写操作，可能都要几百毫秒、数据库每秒也就只能处理几百个请求而已。
3.  所以，在对 MySQL 执行增删改时，主要都是针对内存里的 Buffer Pool 中的数据进行的，也就是实际上主要是对 MySQL 内存里的数据结构进行增删改，再配合 redo log、undo log、刷脏机制，确保事务的持久性和原子性。
4. 可见，Buffer Pool 是 MySQL 的一个内存组件，里面缓存了磁盘上的真实数据，在对 MySQL 执行的增删改时，其实都是对这个内存数据结构中的缓存数据进行的。

##### 2、分

然后就是，Buffer Pool 里存放了什么东西，

1. 实际上，MySQL 对数据抽象出了一个数据页的概念，把很多行数据放在了一个数据页里，也就是磁盘文件中会有很多数据页，每一页数据里存放了很多行数据。

2. 在要更新一行数据时，MySQL 会找到这行数据所在的数据页，然后从磁盘文件里，把这行数据所在的数据页，加载到 Buffer Pool 里，也就是说，Buffer Pool 中存放的是一个一个的数据页。

3. 默认情况下，磁盘中存放的一页数据页大小为 16 KB，而 Buffer Pool 中存放的一个一个的数据页，叫做缓存页，一个缓存页的大小，也是和磁盘上的一个数据页大小一一对应起来的，都是16KB。 

4. 对于每个缓存页，实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的，比如包含：这个数据页所属的表空间、数据页的编号、这个缓存页 在 Buffer Pool 中的地址等别的信息。每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。这种描述数据，相当于缓存页大小的 5% 左右，所以，Buffer Pool 实际上真正的最终大小会比设置的超出一些。因此，Buffer Pool 实际长如下这个样子：

   ![1648173791945](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648173791945.png)

接着就是，Buffer Pool 的工作流程，

1. 在执行 curd 时，MySQL 会不停地加载磁盘上的数据页到 Buffer Pool 的缓存页里来，再查询和更新缓存页里的数据，同时维护一系列的链表结构。
2. 然后，后台线程定时根据 lru 链表和 flush 链表，去把一批缓存页刷入磁盘释放掉这些缓存页，同时更新 free 链表。
3. 而如果执行 curd 时发现缓存页都满了，无法加载自己需要的数据页进缓存时，则会把 lru 链表冷数据区域的缓存页刷入磁盘，然后加载自己需要的数据页进来。

##### 3、总

最后就是，设置合理的 Buffer Pool 大小了，

1. 所以，设置合理的 Buffer Pool 大小，可以尽可能地保证 MySQL 高性能和高并发能力。
2. 通常来说，一般建议把 Buffer Pool 设置为机器内存的 50%~60% 左右，剩余的留给操作系统以及其他地方使用。比如，我们生产环境中的 MySQL 总内存是 128 GB，通过 `SELECT @@innodb_buffer_pool_size/1024/1024/1024;` 查到的是了 64 GB，大小是合理的。
3. 而如果要修改的话，可通过 `set global innodb_buffer_pool_size = ${字节数};` 来进行设置。

=> 以上，就是我对 MySQL Buffer Pool 的一些理解，请问有什么细节需要补充的吗？

#### 5.1.3.2. Redis 内存淘汰策略？

内存淘汰策略是指，当达到指定的 `maxmemory` 内存量时（默认为 0，代表没有限制），会根据不同的策略，选择不同的旧数据进行淘汰，可通过 `maxmemory-policy` 进行设置。

1. LRU，Least Recently Used，最近最少使用淘汰算法，用于淘汰最长时间没有被访问的旧数据。
2. LFU：Least Frequently Used，最不经常使用淘汰算法，用于淘汰在一段时间内访问次数最少的旧数据。

| 策略                      | 作用对象   | 客户端请求发现内存不足时                                     | 适用场景                                            |
| ------------------------- | ---------- | ------------------------------------------------------------ | --------------------------------------------------- |
| noeviction                | 全局 key   | 会返回错误                                                   | 常量字典，不能淘汰任何 key 时                       |
| allkeys-lru               | 全局 key   | 会先尝试删除 LRU key                                         | 热点缓存，需要淘汰非热点 key 时                     |
| volatile-lru              | 可过期 key | 会先尝试删除 LRU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 热点缓存，需要淘汰非热点 key，又需要保护永久 key 时 |
| allkeys-random            | 全局 key   | 会随机淘汰 key                                               | 需要以相同概率去淘汰 key 时                         |
| volatile-random           | 可过期 key | 会随机淘汰 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要以相同概率去淘汰 key ，又需要保护永久 key 时    |
| volatile-ttl              | 可过期 key | 会先尝试删除剩余 TTL 最短的 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要根据过期时间去淘汰 key 时                       |
| allkeys-lfu（Redis 4.0）  | 全局  key  | 会先尝试删除 LFU key                                         | 需要淘汰访问次数少的 key 时                         |
| volatile-lfu（Redis 4.0） | 可过期 key | 会先尝试删除 LFU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要淘汰访问次数少的 key，又需要保护永久 key 时     |

#### 5.1.3.3. Redis 过期策略？

##### 1、总

在 Redis 中，可以设置缓存 key 的过期时间，过期策略就是指，当 Redis 中缓存 key 过期了，Redis 是如何处理的。

##### 2、分

常见的过期策略，通常有以下三种：

1. 定时过期：每个设置过期时间的 key，都需要创建一个定时器，到过期时间就会立即清除。优点是，该策略可以立即清除过期的数据，对内存很友好。缺点是，会占用大量的 CPU 资源，去处理过期的数据，从而影响缓存的响应时间和吞吐量。
2. 惰性过期：只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。优点是，该策略可以最大化地节省 CPU 资源。缺点是，对内存非常不友好，在极端情况下，可能出现大量的过期 key 没有再次被访问，从而不会被清除，占用大量内存。
3. 定期过期：每隔一定的时间，会扫描 expires 字典中一定数量的 key，并清除其中已过期的 key。该策略是前两者的一个折中方案，通过调整定时扫描的时间间隔、以及每次扫描的限定耗时，在不同情况下，使得 CPU 和内存资源达到最优的平衡效果。 
   - expires 字典，会保存所有可过期 key 的过期时间数据，该字典 key 指向 Redis 集群键空间中的某个可过期 key 的指针，字典 value 是该可过期 key 用 UNIX 毫秒时间戳表示的过期时间。

##### 3、总

而 Redis 中，则是同时使用了后两种，即惰性过期 + 定期过期，这两种过期策略。

#### 5.1.3.4. Redis 常用数据结构，以及 ZSet 底层原理？

见《[1.2.1.5. Redis 数据结构？](#1.2.1.5. Redis 数据结构？)》。

#### 5.1.3.5. Spring AOP 的原理？

见《[4.1.1.5. Spring AOP 的原理？](#4.1.1.5. Spring AOP 的原理？)》。

#### 5.1.3.6. Spring @Transactional 原理？

见《[4.1.1.6. Spring @Transactional 原理？](#4.1.1.6. Spring @Transactional 原理？)》。

#### 5.2.1.1. 自我介绍，以及项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 5.2.1.2.  线程池调优？

见《[1.2.1.3. 线程池核心参数，以及选取原则？](#1.2.1.3. 线程池核心参数，以及选取原则？)》。

#### 5.2.1.3. Kafka 高可靠保证？

见《[1.1.1.7. Kafka 的高可靠保证？](#1.1.1.7. Kafka 的高可靠保证？)》。

#### 5.3.1.1. 自我介绍?

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 5.3.1.2. 目前公司的发版频率？

每周五一次。

#### 5.3.1.3. 代码发版质量保证？

![1652602355749](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652602355749.png)

1. 统一编码规范：
   - 1）一个项目或者一个企业，如果要下决心提高软件的质量，那么这份规范就是通向成为一个百年老店的车票，而没有买票就上车大多都不会有个好的结果。
   - 2）但是不管你的编码规范多么的美艳不可方物，它所起到的作用也只是预防、预防、还是预防。
2. 静态代码检测：
   - 1）代码的静态检测，主要指利用静态分析工具对代码进行特性分析，以便检查程序逻辑的各种缺陷和可疑的程序构造，主要是让开发人员对编译器发现不了的潜在错误进行分析，如无效的死循环，多余的变量等，同一指针被释放多次等。
   - 2）其目的是帮助我们尽可能早地，在产品上线前就发现代码中存在的问题并及时修复，将其消灭在萌芽状态，进而为后续工作节省大量的花在测试与调试上面的时间。
   - 3）bug 发现的越晚，修正的成本就越高，据权威部门统计，测试阶段修正bug的成本是编码阶段的约4倍的关系。
3. 单元测试：也就是对那些相当自信的地方不进行测试，而是只测那些有意义的、更容易出错的地方。
4. 持续集成：也就是合代码。
5. 代码评审与重构：
   - 1）以Code Review过程中每分钟出现“脏话”的个数来衡量代码的质量，wtfs / min。
   - 2）橡皮鸭程序调试法。

#### 6.1.1.1. Kafka 高可靠保证？

见《[1.1.1.7. Kafka 的高可靠保证？](#1.1.1.7. Kafka 的高可靠保证？)》。

#### 6.1.1.2. 如果一个 Broker 宕机了，还能保证高可靠吗？

还能保证高可靠，原因是，

1. 如果挂的是 Leader：
   - 1）当 Leader 宕机时，ZK 会向 Controller 发送选举新 Leader 的通知，Controller 会向所
     有 Broker 发送一个命令，通知 Leader 即将发生变化，Leader Replica 重新再平衡。
   - 2）然后，由于生产者上一次消息写入失败，会被定时器捞取出来，重新投递到新 Leader 上，即消息最终会被写入成功。
2. 如果挂的是 Follower：
   - 1）当 Follower 宕机时，如果在 `replica.lag.time.max.ms` 时间内，都没有重启完毕，没发出 fetch 请求，那么 Leader 会认为该 Follower 是死副本，会把它从 ISR 中剔除，然后消息照常写入到 Leader 上。
3. 因此，即使一个 Broker 宕机后，使用上一题的方案，还是能保证消息的可靠性投递的。

#### 6.1.1.3. 算法题 | 1T 字符串数字 ID，怎么在 2C4G 的机器上做去重并且排序？

见《[4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？](#4.1.2.5. 算法题 | 1T 的字符串数字 ID，怎么在一台 2C4G 的机器上去重？)》。

#### 6.1.1.4. Netty 有了解过吗？

##### 1、总

1. Netty 是一个基于 JAVA NIO 实现的高性能的、异步事件驱动的 NIO 框架，提供了对 TCP、UDP 和文件传输的支持。

2. 使用 Netty 实现通信的服务端步骤大致为：
   1. 先创建 2 个 NIO 线程组，一个专门用于网络事件的处理，接受客户端的连接，另一个则进行网络通信读写。
   2. 然后，创建一个 ServerBootStrap 对象，配置 Netty 的一些列参数，比如接受传出数据的缓存大小等等。
   3. 接着，创建一个实际处理数据的 ChannelInitializer 类，进行初始化的准备工作，比如设置接受传出数据的字符集、格式、实际处理数据的 ChannelHandler 等。
   4. 最后，绑定接口，执行同步阻塞方法，等待服务端启动即可。

   （客户端与服务端基本一致）。

3. Netty 之所以高性能，是因为采用了许多优秀的性能方案，比如 I/O 多路复用模型、NIO 模型、主从 Reactor 线程模型、以及零拷贝机制。

##### 2、分

###### 1）Linux I/O 多路复用模型

I/O multiplexing 就是我们说的 `select`、`poll` 和 `epoll`，有些地方也称这种 I/O 方式为事件驱动型 I/O event driven IO。

1. `select` / `epoll` 的好处就在于，单个 process 就可以同时处理**多个**网络连接的 I/O，其基本原理是，`select`、`poll` 、`epoll` 这些 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。
2. 当用户进程调用了 `select`，那么整个进程会被 block，同时，kernel 会“监视”所有 `select` 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。
3. 所以，I/O 多路复用的特点是，通过一种机制，让一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select` 函数就可以返回了。

![1646817566451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817566451.png)

###### 2）Java NIO 模型

NIO，同步非阻塞 I/O：

1. 服务器实现一个连接一个线程，即客户端发送的连接请求都会注册到多路复用器上。
2. 多路复用器轮询到连接有 I/O 请求时，才会启动一个线程进行处理。
3. 适用于连接数目多、且连接比较短（轻操作）的架构，比如聊天服务器，但编程比较复杂，所以才有了 Netty 框架来简化编程。

NIO vs BIO：

1. BIO 是阻塞的，NIO 是非阻塞的。
2. BIO 是面向流的，只能单向读写，NIO 是面向缓冲的, 可以双向读写。
3. 使用 BIO 做 Socket 连接时，由于单向读写，当没有数据时，会挂起当前线程，阻塞等待，为防止影响其它连接，需要为每个连接新建线程处理，然而系统资源是有限的，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗，因此，需要使用 NIO 进行 BIO 多路复用，使用一个线程来监听所有 Socket 连接，使用本线程或者其他线程处理连接。这就要讲到 Reactor 模式了。

###### 3）主从 Reactor 模式

1. 在高性能 I/O 设计中，有两个比较著名的模式，Reactor 和 Proactor 模式，Reactor 模式用于同步 I/O，而 Proactor 运用于异步 I/O 操作。
2. Reactor，又称之为响应器模式，在线程模型上，又分为单 Reactor 单线程模式、单 Reactor 多线程模式、以及主从 Reactor 多线程模式。

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，而 Netty 也正式采用了主从多线程模型。

###### 4）零拷贝机制

1. Netty 接收和发送的 ByteBuffer，底层采用 `DirectBuffers` 使用堆外内存进行 Socket 读写，无需进行字节缓冲区的二次拷贝。
2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
   方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
   Buffer。 
4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
   避免了传统通过循环 `write()` 方式导致的内存拷贝问题。

##### 3、总

Netty 正是主要基于以上几点的优化，大大简化了 NIO 编程，以及提高了 I/O 通信的性能。

=> 以上，就是我对 Nettty 的一些理解，请问有什么细节需要补充的吗？

#### 6.1.1.5. 自动打包有了解过吗？

有了解过，用的 Jenkis#Pipline 脚本，大致步骤如下：

```shell
node {
   # 1、先指定打包服务器的jdk、maven、git启动类，以及要拉取的代码分支、拉取到的代码的存放地址、打好包后的代码包地址、打包后要发送的目标服务器地址、存放路径等
   def mvnHome
   env.JAVA_HOME="/apps/soft/jdk/jdk1.8.0_201"
   def gitHome="/apps/soft/git"
   def codeHome="/apps/soft/code/cloud_qc/uat/cloud_qc/cloud-qc/"
   def targetHome="/apps/soft/code/cloud_qc/uat/cloud_qc/cloud-qc/domain/cloud-qc-app/"
   def deployHost="10.18.12.148";
   def deployPath="/apps/svr/cloud-qc/uat/backend/cloud-qc-app";
   def branch="cloud-back-dev";
   def artifactId="cloud-qc-app";
   
   dir("${codeHome}"){
   	   # 2、然后，进入第1阶段，使用git，拉取gitlab仓库中指定分支的代码
       stage('Pull Code') {
           // Run the maven build
           sh "'${gitHome}/bin/git' checkout ${branch}"
           sh "'${gitHome}/bin/git' pull"
           mvnHome="/apps/soft/Maven339"
           sh "${mvnHome}/bin/mvn clean"
       }
       # 3、接着，进入第2阶段，并使用maven，对拉取到的代码重新clean、install
       stage('Build Install') {
           // Run the maven build
           if (isUnix()) {
              sh "cd ${codeHome}"
              sh "'${mvnHome}/bin/mvn' -Dmaven.test.skip=true clean install"
           } else {
              echo "none build"
           }
       }
       # 4、再然后，进入第3阶段，使用scp命令，把打好的包发送到目标服务器中的指定地址
       stage('Transfer Jar') {
           // remote transfer
           if (isUnix()) {
              sh "ssh -o StrictHostKeyChecking=no -l apps ${deployHost} mkdir -p ${deployPath}"
              sh "scp ${targetHome}/target/${artifactId}.jar apps@${deployHost}:${deployPath}"
              echo "Transfer Jar Success"
           } else {
              echo "none transfer"
           }
       }
       # 5、最后，使用ssh命令，登录目标服务器，取到指定地址，启动已经写好的应用启动脚本，从而完成一次CI/CD流程（持续集成/持续交付）
       stage('Execute Remote Bash'){
            // sh "ssh -o StrictHostKeyChecking=no -l apps ${deployHost} 'export PATH=/apps/svr/java/jdk1.8.0_191/bin:$PATH; /apps/svr/cloud-qc/uat/backend/cloud-qc-app/server.sh restart' "
            sh "ssh -o StrictHostKeyChecking=no -l apps ${deployHost} 'export PATH=/apps/svr/java/jdk1.8.0_191/bin:$PATH; /apps/svr/cloud-qc/uat/backend/cloud-qc-app/server_skywalking.sh restart' "
            echo "Execute Remote Bash Success"
       }
   }
}
```

#### 6.1.1.6. 低代码平台，或者说代码生成器，有了解过吗，给你设计你怎么设计？

1. 低代码平台，顾名思义就是，把重复的框架代码，交给程序来实现，我们只需要编写核心的业务代码就好。
2. 实现的话，我认为分为 2 个方向。
3. 第一个方向是后端，先根据业务，设计好表，根据表生成对应的实体、mapper、service、controller，以及一些定制化的通用业务代码，这个可以使用 Spring#Freemarker 占位符的方式实现。
4. 第二个方向是前端，简单的页面，也可以采用后端的那种，根据表生成固有的样式，但复杂一些的前端的 UI 以及样式自定义代码，可以通过在界面拖拽的方式，以及样式调配，最终生成与界面视觉一样的代码，JS 代码则可以通过生成重复的框架代码，比如页面加载事件、按钮触发事件、业务通用事件等等。

=> 以上，就是我对实现低代码平台的一些理解，请问有什么细节需要补充的吗？

#### 6.1.1.7. 一张表每月一条记录实现员工日常打卡记录？

1. 先设计表，字段有：主键，员工号，年，月，打卡信息字段。
2. 其中，打卡信息字段是一个整数，其中每一位二进制位，都代表每一天的打卡信息，一个整型为 4 字节，32 bit，刚好可以存放一个月的打卡信息。
3. 假设从低到高为记录，如果一个员工 1 号没来，那么就要使用字段 或上 2^0，以让第 0 位标记为 1，如果一个员工 31 号没来，那么就要使用字段 或上 2^30，以让第 30 位标记为 1，这样，就可以实现用一个字段来记录下该员工一个月的打卡记录了。

#### 6.1.1.8. 怎么用程序模拟浏览器上的手工业务操作，且会经常掉线？

1. 先抓包获取参数，分析业务需要的内容，建立其业务模型。
2. 然后使用程序模拟人工发起连接，并进行相应的业务处理。
3. 如果还要防止时间长被剔除来，则可以通过捕捉异常后，更换 ip 地址或者 token，重新发起连接。

#### 7.1.1.1. CountDownLatch 和 AQS 讲一下？

##### 1、总

1. AbstractQueuedSychronizer，简称 AQS，抽象队列同步器，使用它可以简单、⾼效地构造出，依赖单个原子值表示同步状态的、以及先进先出（FIFO）等待队列的阻塞锁和相关同步器。
2. 支持独占模式（默认）和共享模式，在不同模式下，等待线程同享一个 FIFO 队列。当以独占模式获取时，其他线程尝试获取不会成功。当以共享模式获取时， 其他线程尝试获取可能会成功。
3. 同时，还定义了一个内部的 ConditionObject 类，用作 Lock#Condition 的实现。

##### 2、分

###### 1）AQS 核心思想

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630209724753.png?lastModify=1648205707)

1. 如果请求的共享资源空闲，则将当前请求资源的线程，设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
2. 如果请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待、以及被唤醒时进行锁分配的机制，而这个机制 AQS 是通过主等待队列来实现的，即将暂时获取不到锁的线程，加⼊到队列中。
3. 每当线程通过 AQS 获取锁失败时，线程将被封装成一个 Node 节点，通过 CAS 操作，插入到队列尾部。
4. 当有线程释放锁时，AQS 会尝试让队头的后继节点占用锁。

###### 2）AQS 主等待队列

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630238528789.png?lastModify=1648205707)

1. AQS 主等待队列，是一个自旋等待队列，基于双向链表实现，每个节点都充当一个特定的通知式的监视器。
2. 要入列，只需要将 Node 结点，通过 CAS 拼接到队列尾部即可。
3. 要出列，则需要设置该结点为 head 结点，在其 Release 同步状态后，后继结点将会收到信号，会尝试获取同步状态，成为在队列中的 head 结点，但并不能保证成功，因为还可能需要与新来的结点，进行非公平竞争。

###### 3）Node 结点的数据结构

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630208598316.png?lastModify=1648205707)

1. 持有一个 waitStatus 数值，
   - 1）`初始时 waitStatus = 0`：表示当前节点处于初始状态。
   - 2）`int CANCELLED = 1`：表示线程因为中断或者等待超时，需要从等待队列中取消等待。
   - 3）`int SIGNAL= -1`：表示后继节点处于等待状态，当前节点如果释放了同步资源或者被取消，需要通知唤醒后继节点，让后继节点的线程得以重新运行。
   - 4）`int CONDITION = -2`：表示线程在条件队列中阻塞，当其他线程调用了 `ConditionObject#signal()` 方法后，被阻塞的线程会从条件队列，转移到 AQS 主等待队列上，去参与排队竞争。
   - 5）`int PROPAGATE = -3`：表示共享状态会被无条件地传播下去，让后面的 N 个节点都进行工作，从而实现共享锁被 N 个线程同时持有。
2. 一个 thread 指针：表示当前结点的线程引用。
3. 一个 nextWaiter 指针：
   - 1）如果当前结点为条件等待队列的结点，那么该值应该指向条件队列的后继结点。
   - 2）如果当前结点为 AQS 主等待队列的结点，那么该值只是作为独占模式的标记 `Node EXCLUSIVE = null`，或者共享模式的标记 `Node SHARED = new Node()` 。
4. 一个 prev 指针：表示前驱结点，用来处理取消结点，如果一个结点被取消，那么它的后继，会往前找到一个未取消的前驱，并重新链接、以及判断前驱是否为头结点，以让后继结点执行一次尝试获取同步资源的操作。
5. 以及一个 next 指针：表示后继结点，用来实现阻塞与通知机制，在前驱结点释放同步资源后，通过 next 指针，来确定唤醒哪个线程。

###### 4）AQS 扩展原理

1. 在 AQS 中，维持了一个 `private volatile int state`，表示同步资源状态，作为同步器子类实现的共享资源状态。
2. 以及提供几个钩子方法，让同步器子类去扩展，默认抛出 UnsupportedOperationException 异常。
   - 1）`tryAcquire(int)`：独占锁钩子，尝试获取独占资源。若成功则返回 true，若失败则返回 false 。
   - 2）`tryRelease(int)`：独占锁钩子，尝试释放独占资源。若成功则返回 true，若失败则返回 false 。
   - 3）`tryAcquireShared(int)`：共享锁钩子，尝试获取共享资源。负数，表示获取失败；正数，表示成功，且有剩余资源；0，也表示成功，但代表没有剩余可用资源。
   - 4）`tryReleaseShared(int)`：共享锁钩子，尝试释放共享资源。若成功则返回 true，若失败则返回 false 。
   - 5）`isHeldExclusively()`：独占锁钩子，判断当前线程，是否正在独占资源。
3. 而 AQS 其他方法，则都是 final 类型，无法再被子类重写，从而抽象队列同步框架的封装与扩展。

###### 5）独占模式实现原理

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630209980487.png?lastModify=1648205707)

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210001133.png?lastModify=1648205707)

1. 独占模式下，`tryAcquire(int)` 钩子返回的是 boolean 值，其含义取决于实现类具体的语义。主要思路是，如果要实现独占，就要保证，在获取同步资源时，如果已经存在了独占线程，那么就要返回 false，如果没存在独占线程，则可以返回 true。

2. 而在获取同步资源失败的，则要生成 Node 结点，加入 AQS 主队列中，参与排队竞争，竞争失败的，则将前驱结点设置为 `int SIGNAL= -1` 状态，然后阻塞。

3. 在前驱结点释放同步资源后，由于被后继设置为了  `int SIGNAL= -1` 状态，所以会唤醒后继结点，重新参与AQS 竞争。

4. 源码解析 - 普通式获取原理：`acquire(int arg)`，

   - 1）调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源，如果获取成功，则直接返回即可。
   - 2）如果获取失败，则把当前线程，构建成独占模式的 Node 结点，通过 CAS+自旋的方式入队。
   - 3）入队成功后，则调用 `acquireQueued(final Node node, int arg)` 方法，自旋判断前驱是否为 head 头结点，如果是，则执行一次抢占同步资源的操作，抢占成功，则更新为 head 头结点（此时旧 head 结点脱钩将来会被 GC 掉），并返回 interrupted 中断标记（该方法唯一返回入口）。
   - 4）如果发现前驱不是 head 结点，或者抢占同步资源失败，则调用 `shouldParkAfterFailedAcquire(Node pred, Node node)` 方法，更新前驱为 `int SIGNAL= -1`，代表在该前驱释放同步资源成功后，需要唤醒当前线程。
   - 5）接着，使用 `LockSupport.park(this)` 来阻塞当前线程。
   - 6）最后，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，则检查线程中断状态，重新自旋判断前驱、抢占锁、或者继续阻塞。

5. 源码解析 - 可中断式获取原理：`acquireInterruptibly(int arg)`，对比普通式获取独占资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源前，会先检查线程是否被中断过，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占同步资源失败后，调用的是  `doAcquireInterruptibly()` 方法，来对结点进行入队。
   - 3）第三是，在自旋判断到前驱是否为 head 头结点，并成功抢占同步资源后，并不会返回任何值。
   - 4）最后是，在被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断了，则会立马抛出中断异常。

   => 可见，普通式获取返回的是中断标记，只能在方法调用返回后，才能做线程中断响应，而可中断式获取无任何返回值，是在方法调用过程中，做的线程中断响应，即抛出中断异常。这也正是两者之间最大的区别。

6. 源码解析 - 定时式获取原理：`tryAcquireNanos(int arg, long nanosTimeout)`，对比普通式获取独占资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源前，会先检查线程是否被中断过，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占同步资源失败后，调用 `doAcquireNanos(int arg, long nanosTimeout)` 方法来入队结点，并且根据当前系统纳秒时间，来计算剩余的过期时间。
   - 3）第三是接着，自旋判断到前驱为 head 头结点，并成功抢占同步资源后，会返回 true，代表在规定时间内，成功获取到了同步资源。
   - 4）第四是，如果前驱不为 head 头结点，或者抢锁同步资源失败，则会先根据当前系统纳秒时间，来计算剩余的过期时间，并且如果发现超过了定时时间，则会返回 false，代表未能在规定时间内，获取到同步资源。
   - 5）第五是，如果还没超过定时时间，则再调用 `LockSupport.parkNanos(this, nanosTimeout)` 来定时阻塞当前线程。
   - 6）最后是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，定时式获取与可中断式获取，最大的不同在于，有设置剩余等待时间，并且返回的 boolean 值，代表是否能够在规定时间内，获取到同步资源。

7. 源码解析 - 独占资源释放原理：`release(int arg)`，

   - 1）调用钩子方法 `tryRelease(int)`，尝试释放独占资源，如果释放失败，则直接返回 false 即可，代表释放失败。
   - 2）如果释放成功，则判断 head 头结点，如果 head 头结点为空，或者为独占脱钩，说明队列没有其他结点，则返回 true，代表释放成功。
   - 3）如果头结点为正常的业务结点，则还需要调用 `unparkSuccessor(head)` 方法，来唤醒后续排队的结点，唤醒后则返回 true，代表释放成功。
     1. 其中， `unparkSuccessor(head)` 方法，并不会更新后继为 head 头结点，而仅仅是更新头结点的waitStatus = 0、以及唤醒后继结点。
     2. 而更新 head 头结点、以及脱钩当前 head 头结点，是在后继获取同步资源成功后，才进行更新，这样可以保证由后继线程自己来确保成为头结点，比放在释放方法里更新要严谨一些。

###### 6）共享模式实现原理

1. 共享模式下，`tryAcquireShared(int)` 返回的是 int 值，其含义取决于实现类定义的语义。主要思路是，使用 `int PROPAGATE = -3`，来表示共享状态会被无条件地传播下去，让后面的 N 个节点都进行工作，从而实现共享锁被 N 个线程同时持有。

2. 其中，`int PROPAGATE = -3` 相当于一个占位的作用：
  - 1）如果结点不是最后一个获取到同步资源的，则状态为 `int PROPAGATE = -3` 。
  - 2）而如果结点是最后一个获取到同步资源的，则状态一开始为 0，不过很快就会在下一个结点进入阻塞前，设置为 `int SIGNAL= -1` 表示后继节点处于等待状态，当前节点如果释放了同步资源或者被取消，需要通知唤醒后继节点，让后继节点的线程得以重新运行。
  - 3）而当释放共享锁时，如果是 `int PROPAGATE = -3` 结点释放的，则无任何唤醒后继结点，如果是`int SIGNAL= -1` 结点释放的，则会唤醒后继结点，接着又会重复，一片非最后的 `int PROPAGATE = -3` 结点以及最后一个为  `int SIGNAL= -1` 的结点，然后前面的操作。

3. 源码解析 - 普通式获取原理：`acquireShared(int arg)`，对比普通独占获取资源方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取共享资源，如果获取到的数量大于等于 0，说明获取成功，直接返回即可。
   - 2）第二是，如果获取到的数量小于 0 时，说明获取失败，则需要调用 `doAcquireShared(int arg)` 方法，来入队结点，但此时结点的 nextWaiter 不再是为 null，而是 SHARED，代表为共享模式的结点。
   - 3）第三是，接着，自旋判断到前驱为 head 头结点，是的话则进行一次尝试获取共享资源操作。如果获取的数量大于等于 0，说明获取成功，则调用 `setHeadAndPropagate(Node node, int propagate)` 方法，更新当前结点为 head 头结点。再调用 `doReleaseShared()` 方法，设置当前结点为 `int PROPAGATE = -3`，表示下一个线程获取共享资源后，当前的共享状态需要被无条件地传播下去，以通知其他等待的线程尽快获取共享资源。共享状态传播完毕后，返回之前，需要判断当前线程是否有被中断，是的话则设置线程中断标志再返回。
   - 4）最后是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断，不会抛出中断异常，而是更新代码局部变量中的中断标志位为 true，待自旋获取同步资源成功后，设置线程中断标志位处理。

   => 可见，共享式获取与独占式获取，最大的不同在于，入队获取共享资源成功后，是先设置当前结点为 `int PROPAGATE = -3`，然后再释放掉共享资源，进行一个共享状态的传播。

4. 源码解析 - 可中断式获取原理：`acquireSharedInterruptibly(int arg)`，对比普通式获取共享资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取共享资源前，会先检查线程是否被中断过，如果是则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占失败一次后，调用的是 `doAcquireSharedInterruptibly()` 方法，来入队结点。
   - 3）第三是，接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是直接返回，没有任何返回值。
   - 4）第四是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，普通式获取返回的是中断标记，只能在方法调用返回后，才能做线程中断响应，而可中断式获取无任何返回值，是在方法调用过程中，做的线程中断响应，即抛出中断异常。这也正是两者之间最大的区别。

5. 源码解析 - 定时式获取原理：`tryAcquireSharedNanos(int arg, long nanosTimeout)`，对比普通式获取共享资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取同步资源前，会先检查线程是否被中断过，如果是则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占失败一次后，调用的是 `doAcquireSharedNanos(int arg, long nanosTimeout)` 方法，来入队结点，并且根据当前系统纳秒时间，来计算剩余过期时间，如果定时时间小于等于 0，则返回 false，代表未能在规定时间内获取到同步资源。
   - 3）第三是，自旋判断到前驱为 head 头结点，再尝试获取同步资源，获取成功并传播完毕后，返回之前并不会判断当前线程是否有被中断，而是返回 true，代表在规定时间内成功获取到了同步资源。
   - 4）第四是，如果前驱不为 head 头结点，或者抢占同步资源失败，则会继续根据当前系统纳秒时间，计算剩余过期时间，如果发现超过了定时时间，则会返回 false，代表未能在规定时间内获取到同步资源。
   - 5）第五是，如果最后前没超过定时时间，则调用的是 `LockSupport.parkNanos(this, nanosTimeout)` 来定时阻塞当前线程。
   - 6）最后是，被 `LockSupport.unpark(当前线程的实例)` 被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，定时式获取与可中断式获取，最大的不同在于，有设置剩余等待时间，并且返回的 boolean 值，代表是否能够在规定时间内，获取到同步资源。

6. 源码解析 - 共享资源释放原理：`releaseShared(int arg)`，对比独占资源释放方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquireShared(int)`，尝试释放共享资源，如果释放失败，则直接返回 false 即可，代表释放失败。
   - 2）第二是，如果释放成功，则判断 head 头结点，如果 head 头结点为 `int SIGNAL= -1` 结点，则需要调用 `unparkSuccessor(head)` 方法，来唤醒后续排队的结点，唤醒后则返回 true，代表释放成功。
   - 3）最后是，如果头结点不为 `int SIGNAL= -1` 结点，而是脱钩独占结点，则通过 CAS 更新它为 `int PROPAGATE = -3`，表示当前走的是共享释放，要做共享状态的传播，然后返回 true，代表释放成功。

   => 可见，共享式释放与独占式释放，最大的不同在于，如果做的不是唤醒后继，则要把当前结点标识为 `int PROPAGATE = -3`，表示走共享释放，做共享状态传播。

###### 7）AQS 条件队列

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630238750935.png?lastModify=1648205707)

1. 将条件队列之前，还要讲一下 Condition 接口，
   - 1）Condition，是 JUC 用来替代传统 `Object#wait()/notify()` 线程间通信与协作机制的新组件，其作用与 `Object#wait()/notify()` 相似，都会让一个线程等待某个条件，只有当该条件具备 `signal()/signalAll()` 方法被调用时，阻塞等待的线程才会被唤醒，重新去争夺锁。
   - 2）但不同的是，`Object#wait()/notify()` 由 JVM 底层实现，而 Condition 实现类，完全使用 Java 代码来实现。当需要进行线程间通信时，相比调用 `Object#wait()/notify()`，调用 `ConditionObject#await()/signal()` 这种方式实现起来更加高效。
2. 而 AQS 内部类的 ConditionObject 类，正是实现 Condition 接口的关键，
   - 1）每个 ConditionObject 对象，都维护了一个单独的 AQS 条件队列。
   - 2）AQS 条件队列是单向的，而 AQS 主等待队列是双向的，他们是聚合的关系。
   - 3）因此，在一个显式锁上，可以创建多个 AQS 条件队列，而 Java 内置锁，只有唯一的一个等待队列。
   - 4）AQS 条件队列，也使用了相同的 Node 结点，但额外维护了一个 nextWaiter 指针，在调用`ConditionObject#await()` 时，会把一个 ConditionObject 结点，插入到条件队列中，然后等到 `ConditionObject#signal()` 信号，该结点会被转移到 AQS 主等待队列中，去参与同步资源竞争，竞争失败的会被阻塞，然后依赖 AQS 排队与通知机制实现唤醒。

###### 8）条件等待与唤醒原理

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210049637.png?lastModify=1648205707)

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210030025.png?lastModify=1648205707)

1. ConditionObject 数据结构：
   - 1）firstWaiter：条件队列的头节点。
   - 2）lastWaiter：条件队列的尾节点。

2. 源码解析 - 条件等待原理：（类比于 `Object#wait()` 与 `Object#notify()/notifyAll()`）

   ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

   - 1）首先，会创建一个 Condition 类型的 Node 结点，即 Condition 结点，并放入条件队列的队尾。
   - 2）然后，调用 `release(int arg)` 方法释放所有独占资源。
     - 相当于 `Object#wait()` 释放内置锁资源。
   - 3）接着，判断 Condition 结点是否已经在主等待队列中，如果不是，则将当前线程阻塞，直到被调用 `doSignal()` 方法唤醒。
     - 相当于 `Object#wait()` 调用后，进入到 _WaitSet 等待队列中。
   - 4）如果被 `doSignal()` 放入了主等待队列（waitStatus 会被置为 0），并唤醒当前线程，则调用 `acquireQueued(final Node node, int arg)` 方法，获取独占资源，抢到则返回，没抢到则被 `LockSupport.part(this)` 给阻塞住，直到被 AQS 主等待队列的前驱唤醒。
     - 相当于 `Object#notify()/notifyAll()` 随机唤醒 _WaitSet 中的线程，并将它放入到 EntryList 候选竞争队列中。
   - 5）如果抢占到独占资源，  `acquireQueued(final Node node, int arg)` 方法返回，则先检查返回值，如果为 true，说明争抢期间发生了中断，则响应中断。
     - 相当于线程在 EntryList 中，竞争到锁资源，成为了 Owner Thread。

3. 源码解析 - 定时式条件等待原理：对比普通条件等待方法，该方法主要不同的地方在于：

   - 1）第一是，在创建 Condition 结点前，会先校验线程是否已中断，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，接着，会先根据系统纳秒时间，计算出超时时间，如果没有超时，则调用 `LockSupport.parkNanos(this, nanosTimeout)` 方法，来定时阻塞当前线程。
   - 3）第三是，如果发生了超时，则会将 Condition 结点，转移到 AQS 主等待队列中（waitStatus 会被置为 0），并退出 while 循环，调用 `acquireQueued(final Node node, int arg)` 去争抢同步资源，抢到则返回，没抢到则被 `LockSupport.part(this)` 给阻塞住，直到被 AQS 主等待队列的前驱唤醒。
   - 4）最后是，如果抢占到独占资源，  `acquireQueued(final Node node, int arg)` 方法返回，则先检查返回值，如果为 true，说明争抢期间发生了中断，则响应中断，要计算剩余的超时时间，并返回。

   => 可见，定时式条件等待与普通等待，最大的不同在于，定时等待会定时阻塞当前线程，发生超时或者被 `doSignal()` 唤醒，都会将 Condition 结点转移到 AQS 主等待队列、并退出 while 循环，还有的不同就是，定时等待会有返回值，表示剩余超时时间，而普通等待方法，则只会响应中断，没有任何返回值。

4. 源码解析 - 条件唤醒原理：

   - 1）先通过 CAS 的方式，将条件队列中的第一个 Condition 结点的 waitStatus 更新 0。
   - 2）然后，调用 `enq()` 方法，将结点转移到 AQS 主等待队列中，并设置前驱为 `int SIGNAL= -1`。
   - 3）最后，调用 `LockSupport.unpark(node.thread)` 唤醒 Condition 结点的线程，并返回 true，从而实现通知唤醒 Condition 结点的作用。
      - 相当于 `Object#notify()/notifyAll()` 随机唤醒 _WaitSet 中的线程，并将它放入到 EntryList 候选竞争队列中。

##### 3、总

基于 AQS 以上原理，JUC 中的典型实现有，

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630201659838.png?lastModify=1648205707)

###### 1）CountDownLatch

1. CountDownLatch，门闩，它允许一个或多个线程等待，直到一组操作执行完成后，才唤醒这些线程。
2. 它使用一个给定的计数值，进行初始化，调用 `await()` 方法可以使线程阻塞，直到计数被 `countDown()` 方法调用至零后，所有阻塞等待线程才会被唤醒，并且门闩使用一次后，任何 `await()` 再被调用时，会立即返回。
3. 因此，门闩计数无法被重置，是一个一次性的同步器，如果需要重置计数的实现，可以使用 CyclicBarrier。

它有几个核心方法，

1. 第一个是，构造方法，构造方法中，传入一个整数 n，作为 AQS 共享资源。
2. 第二个是， `await()` 方法，一般由主线程调用、并阻塞等待各工作线程签到完成，其实现原理为：
   - 1）底层调用了 AQS 的 `doAcquireSharedInterruptibly(arg)` 可中断式获取共享资源，该方法会先去调用钩子方法。
   - 2）由于 CountDownLatch#Sync 实现了 `tryAcquireShared(int)` 共享资源获取钩子，如果计数为 0，则返回 1，代表共享资源获取成功，则会传播式地唤醒一个又一个的线程，释放全部等待的线程。
   - 3）如果计数不为 0，则返回 -1，代表共享资源获取失败，则会阻塞所有调用的线程。
3. 第三个是，`countDown()` 方法，一般由子线程调用，表示当前线程工作已完成并签到一下，其实现原理为：
   - 1）底层调用了 AQS 的 `releaseShared(int arg)` 释放共享资源方法，该方法会先去调用钩子方法。
   - 2）由于 CountDownLatch#Sync 实现了 `tryReleaseShared(int)` 共享资源释放钩子，如果计数为 0，则返回 false，代表门闩已用完，不能重复使用。
   - 3）如果计数不为 0，则计数 -1，如果还没减到 0，则返回 false，代表当前线程还不是最后一个到达的线程，此时不会做任何唤醒操作。
   - 4）如果减到了 0，则返回 true，代表当前线程为最后一个到达的线程，然后回调 AQS 的 `doReleaseShared()` 方法，传播式唤醒所有等待线程。

###### 2）CyclicBarrier

1. CyclicBarrier，栅栏，它允许一组线程全部到达公共栅栏点后，执行一次指定栅栏任务，相对于 CountDownLatch，CyclicBarrier 的计数是可以被重置的，可以被重复使用。
2. 核心方法有 1 个，为 `await()` 方法，调用该方法的线程，在没符合条件时会阻塞住，直到栅栏条件达成后被唤醒。其实现原理为：
   - 1）先阻塞式获取 ReentrantLock 显示锁，获取到后，则获取分代实例 Generation，如果发现Generation 已经损坏，则抛出 BrokenBarrierException 异常。
   - 2）如果 Generation 还没损坏，则再检验当前线程的中断状态，如果发生了中断，则破坏当前 Generation，重置栅栏的参与线程数，并唤醒所有阻塞等待的线程。
   - 3）如果 Generation 还没损坏，且当前线程没被中断，说明当前线程达到了栅栏，因此栅栏的线程参与数 -1。
   - 4）如果计数减少到了 0，说明当前线程为最后一个到达栅栏的线程，如果有指定栅栏任务，则运行一次栅栏任务，然后生成下一代 Generation，重置栅栏的参与线程数，并唤醒所有阻塞等待的线程，并返回 0，代表当前线程到达栅栏的最后索引。
   - 5）如果计数还没减少到 0，则开始自旋，如果不需要超时，则调用 `Condiction#await()` 方法，阻塞当前线程，如果需要计时，且还没发生超时，则调用 `Condiction#awaitNanos()` 定时阻塞当前线程，因为这俩方法会释放显示锁的所有独占资源，以让其他线程能够顺利抢到显示锁。
   - 6）而在定时阻塞等待期间，任意一个线程发生了中断，则会破坏当前 Generation，唤醒所有阻塞等待的线程，并抛出异常。
   - 7）如果期间没发生中断，当前线程唤醒后，如果发现 Generation 已被破坏了，则抛出 BrokenBarrierException 异常，如果 Generation 没被破坏，但已被更新，说明最后一个线程确实到达了栅栏，则返回当前线程的到达索引。如果 Generation 没被破坏也没被更新，说明当前线程发生了等待超时，则破坏当前 Generation，唤醒所有阻塞等待线程，并抛出超时异常 TimeoutException。
   - 8）最后，释放 ReentrantLock 显示锁。

###### 3）ReentrantLock

1. ReentrantLock，Lock 接口的可重入、互斥锁实现，被成为显式锁，与使用 synchronized 具有基本相同的行为和语义，但功能更丰富，比如支持公平锁、定时式获取、锁持有检查等等。
2. 支持公平锁的意思是，在 ReentrantLock 构造时，传入 true，在锁争用时，锁会等待时间最长的线程获取到，可以避免线程饥饿问题，但会降低整体的吞吐量。

它的核心方法主要有 3 个。

1. 首先说下，非公平、阻塞式的抢锁原理：`NonfairSync#lock()`，
   - 1）先使用 CAS，尝试更新同步资源（这里代表的是锁次数） 为 1，只有锁次数为 0，才会更新成功，说明当前线程非公平地提前抢到了锁。
   - 2）如果没抢到，则调用 AQS 的 `acquire(int arg)` 方法，老老实实地走 AQS 排队流程。
   - 3）由于 ReentrantLock#NonfairSync 实现了 `tryAcquire(int acquires)` 钩子方法，该方法底层调用 `Sync#nonfairTryAcquire(int acquires)` 方法。
   - 4）`Sync#nonfairTryAcquire(int acquires)` 方法，可以为 ReentrantLock 提供公共的、非公平的、非阻塞的尝试获取独占资源功能，
     1. 首先，它获取锁次数，如果锁次数为 0，说明当前线程第一次抢锁，则 CAS 更新锁次数为 1，代表第一次就抢锁成功，并设置当前线程为独占线程，然后返回 true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做。
     2. 如果锁次数不为 0，但独占线程为当前线程，说明发生了锁重入，则累加锁次数 + 1，然后返回true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做。
     3. 如果锁次数不为 0，且独占线程也不为当前线程，则返回 false，代表独占资源获取失败，需要等待独占线程释放资源，AQS `acquire(int arg)` 方法回调，阻塞当前线程，从而实现 ReentrantLock 非公平、阻塞式地抢锁。
2. 然后就是，公平、阻塞式的抢锁原理：`FairSync#lock()`，对比非公平、阻塞式获取锁的方法，该方法不同的地方在于，
   - 1）第一是，它一开始没有使用 CAS 尝试获取锁次数，而是直接调用了 AQS 的 `acquire(int arg)` 方法，老老实实地走 AQS 排队流程。
   - 2）第二是，由于 ReentrantLock#FairSync 实现了 `tryAcquire(int acquires)` 钩子方法，该方法先获取锁次数，如果锁次数为 0，说明当前线程第一次抢锁，不同的是，它会先判断 AQS 主等待队列中，有没有存在其他排队的线程，如果不存在，才 CAS 更新锁次数为 1，代表第一次就抢锁成功，并设置当前线程为独占线程，然后返回 true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做，从而实现公平按排队、顺序抢锁的功能。
3. 最后就是，释放锁的原理：`ReentrantLock#unlock()`。
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ReentrantLock#Sync 实现了 `tryRelease(int acquires)` 钩子方法，为 NonfairSync 和 FairSync，提供释放独占资源的公共方法。
   - 2）该方法先通过当前锁次数 - 1，计算剩余锁次数。
   - 3）然后判断当前线程是否为独占线程，如果不是，则抛出 IllegalMonitorStateException 异常。
   - 4）如果是独占线程，则判断剩余锁次数是否为 0，是的话，则清空独占线程、重置锁次数，并返回 true，代表锁释放成功。
   - 5）如果剩余锁次数不是 0，则更新锁次数为剩余锁次数，即 -1，然后返回 false，代表锁仍被当前线程持有。

###### 4）ReentrantReadWriteLock

1. ReentrantReadWriteLock，读写锁，支持与 ReentrantLock 类似的语义，同样也支持公平和非公平、定时式获取、可重入等功能。
2. 但重入规则不同的是，只支持锁降级，不支持锁升级，即支持从写锁降为读锁，但不支持读锁升级为写锁。
3. 并且，只有写锁提供了 Condition 的支持，读锁并不支持。
4. 以及能够支持更高的读并发，适用于预期集合很大、读线程比写入线程多、读取时需要的开销大于写同步开销的场景。

它的核心方法主要有如下几个，分别是阻塞式获取非公平、公平写锁、非公平、公平读锁、释放写锁、释放读锁。

1. 首先，读写状态只使用了一个 int 整数来存储，高 16 位作为读次数，低 16 位作为写次数。
2. 然后就是，阻塞式获取非公平、公平写锁的原理：`WriteLock#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquire(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryAcquire(int acquires)` 钩子方法，为 NonfairSync 和 FairSync，提供获取独占资源的公共方法。
   - 2）`tryAcquire(int acquires)` 先获取整体的锁状态，以及写锁次数，如果写锁次数为 0，如果锁状态不为 0，且写锁次数为 0，或者独占线程不是当前线程，说明存在读锁（读写要互斥），或者存在别的写锁（写写互斥），则返回false，代表写锁获取失败。
   - 3）如果锁状态不为 0，但写锁次数为 0，且独占线程就是当前线程，说明为当前线程重入获取写锁，则低 16 位写锁次数 +1，然后更新锁状态，返回 true，代表写锁重入成功。
   - 4）如果锁状态为 0，说明不存在任何读锁和写锁，则要看 `writerShouldBlock()` 钩子怎么实现，这里用于控制非公平和公平的逻辑：
     1. 如果实现的是非公平写锁，则要看 `NonfairSync#writerShouldBlock()`，该方法的实现只是直接返回 false，认为写锁获取时，无需任何阻塞等待，因为实现的是非公平锁。
     2. 如果实现的是公平写锁，则要看 `FairSyncwriterShouldBlock()`，该方法的实现是，看 AQS 主等待队列 head 头结点是否存在后继线程，如果存在，则返回 true，代表公平地排队获取写锁，否则返回 false，代表没有线程在排队，可以作为第一个线程，获取到写锁。
   - 5）因此，上述方法回调后会这样走，通过 CAS，更新写锁次数 + 1，设置独占线程为当前线程，然后返回 true，代表写锁获取成功。
3. 接着就是，阻塞式获取非公平、公平读锁的原理：`ReadLock#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquireShared(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryAcquireShared(int unused)` 钩子方法，为 NonfairSync 和 FairSync，提供获取共享资源的公共方法。
   - 2）`tryAcquireShared(int unused)` 先获取整体的锁状态，以及读锁次数、写锁次数，如果写锁次数不为 0，且独占线程不是当前线程，则返回 -1，说明存在写锁，且写锁不是自己锁持有，代表读锁获取失败（读写互斥）。
   - 3）如果写锁次数为 0，或者独占线程就是当前线程，说明不存在写锁，或者当前线程正在持有写锁，可以获取读锁（锁降级），此时要看 `readerShouldBlock` 钩子怎么实现，这里用于控制非公平和公平的逻辑：
     1. 如果实现的是非公平锁，则要看 `NonfairSync#readerShouldBlock()`，该方法的实现是，看第一个后继结点是否为独占模式，如果是的话，则返回 true，认为如果后一位在申请写锁，下次就要先轮到写锁，即使当前是非公平获取读锁，也去 AQS 主等待队列中排队等待，如果否的话，则返回 false，认为后一个没有在申请写锁，就可以先非公平获取读锁，无需进入 AQS 主等待队列排队。
     2. 如果实现的是公平锁，则要看 `FairSync#readerShouldBlock()`，该方法的实现是，看 AQS 主等待队列 head 头结点是否存在后继线程，如果存在，则返回 true，代表公平地排队获取写锁，否则返回 false，代表没有线程在排队，可以作为第一个线程，获取到读锁。
   - 4）因此，上述方法回调后会这样走，如果获取读锁不需要被阻塞，则 CAS 更新高 16 位读锁次数 +1，然后看之前的读锁次数是否为 0，如果是的话，则认为当前线程是第一次获取读锁，则用 `firstReader` 标记好，如果是当前线程重入获取读锁，则更新一级缓存中的读锁次数 + 1，否则说明当前线程是在重入别人的读锁，则更新二级缓存中的读锁次数 + 1，然后返回 1，代表读锁获取成功，实现非公平获取读锁。
   - 5）如果获取读锁需要被阻塞，或者 CAS 更新高 16 位读锁次数 + 1失败，则调用 `fullTryAcquireShared(Thread current)` 开始走自旋更新，大体逻辑与不被阻塞的类似，都是为了更新 `firstReader` 第一次获取读锁标记、一级缓存、二级缓存中的读锁次数，不过不一样的是，如果自旋过程中发现存在别线程获取到了写锁，或者当前线程是在第一次重入别人的读锁，那么就需要返回 -1，代表读锁获取失败，需要进入到 AQS 主等待队列中排队，实现公平获取读锁。
4. 再然后就是，释放写锁的原理：`WriteLock#unlock()`，
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryRelease(int releases)` 钩子方法，为 NonfairSync 和 FairSync，提供释放独占资源的公共方法。
   - 2）`tryRelease(int releases)` 先判断独占线程是否为当前线程，如果不是的话，则抛出IllegalMonitorStateException 异常，代表不能释放别人的写锁。
   - 3）如果独占线程就是当前线程，则更新低 16 位的写锁次数 - 1，如果更新后的写锁次数为 0，说明写锁释放了，则清空独占线程、更新整体锁状态，然后返回 0，代表写锁释放成功，最后回调到 AQS 中，通知唤醒 AQS 主等待队列中的后继结点。
   - 4）如果更新后的写锁次数不为 0，说明写锁还被当前线程持有，则更新整体锁状态，然后返回剩余写锁次数，代表写锁仍未释放，最后回调到 AQS 中，但不通知唤醒 AQS 主等待队列中的后继结点，什么也不做。
5. 最后就是，释放读锁的原理：`ReadLock#unlock()`，
   - 1）该方法底层调用了 AQS 的 `releaseShared(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryReleaseShared(int unused)` 钩子方法，为 NonfairSync 和 FairSync，提供释放共享资源的公共方法。
   - 2）`tryReleaseShared(int unused)` 方法，先判断当前线程是否在释放自己的读锁，如果是第一次释放，则清空 `firstReader` 第一次读锁标记，如果是其他次释放，则更新一级缓存中的读锁次数 - 1，而如果不是在释放自己的读锁，则更新二级缓存中的读锁次数 - 1。
   - 3）然后开始自旋，先更新高 16 位的读锁次数 - 1，再 CAS 更新整体锁状态，更新失败的，则继续自旋，更新成功的，则返回剩余读锁次数是否为 0。
   - 4）如果是的话，则返回 true，代表读锁释放成功，最后回调到 AQS 中，传播式通知唤醒 AQS 主等待队列中的后继结点。
   - 5）如果不是的话，则返回 false，代表读锁释放失败，最后回调到 AQS 中，但不通知唤醒 AQS 主等待队列中的后继结点，什么也不做。

###### 5）Semaphore

1. Semaphore，计数信号量，它允许维护一组信号量许可，调用 `acquire()` 阻塞获取信号量许可，调用 `release()` 归还一个信号量许可，也支持非公平和公平模式，通常用于限制访问某些资源的线程数。
2. 当初始化为 1 个许可时，可用作互斥锁（二元信号量），但这种互斥锁与 ReentrantLock 显示锁不同，因为这种锁的许可，可以被其他线程释放掉，可以用作死锁的恢复。

它有几个主要的方法，

1. 首先是，构造方法，允许传入一个 int 整数，作为同步资源，在这里指的是信号量许可。
2. 然后就是，阻塞、非公平获取 n 个信号量许可的实现原理：`acquire(int permits)`，
   - 1）该方法底层调用了 AQS 的 `acquireSharedInterruptibly(int arg)` 方法，由 Semaphore#NonfairSync 实现了 `tryAcquireShared(int acquires)` 钩子方法，调用 Semaphore#Sync 的 `nonfairTryAcquireShared(int acquires)` 方法。
   - 2）`nonfairTryAcquireShared(int acquires)` 方法，会进行自旋，先获取剩余的信号量许可，然后扣减掉要获取的 n 个许可，判断扣减后的剩余许可是否小于 0，如果是的话，说明信号量许可不够了，回调到 AQS 中时，则需要去 AQS 主等待队列中排队。
   - 3）如果否的话，说明信号量许可还够，则尝试 CAS 更新信号量许可 - n，成功的话，则返回许可剩余数，代表许可获取成功，回调到 AQS 中时，无需进入 AQS 中排队，实现非公平获取信号量许可，如果 CAS 更新失败，则继续自旋。
3. 接着就是，阻塞、公平获取 n 个信号量许可的实现原理：`acquire(int permits)`，
   - 1）该方法底层调用了 AQS 的 `acquireSharedInterruptibly(int arg)` 方法，由 Semaphore#FairSync 实现了 `tryAcquireShared(int acquires)` 钩子方法。
   - 2） `tryAcquireShared(int acquires)` 方法，会进行自旋，与非公平获取不同的是，会先判断 AQS 主队列 head 头结点是否存在后继线程，如果存在，则返回-1，代表获取信号量许可失败，需要去 AQS 主等待队列中排队，实现公平式获取。
   - 3）如果不存在后继线程，则走与公平式获取相同的自旋逻辑。
4. 最后就是，释放 n 个信号量许可的实现原理：`release(int permits)`，
   - 1）该方法底层调用了 AQS 的 `releaseShared(int arg)` 方法，由 Semaphore#FairSync 实现了 `tryReleaseShared(int releases)` 钩子方法，为 NonfairSync 和 FairSync，提供释放共享资源的公共方法。
   - 2）`tryReleaseShared(int releases)` 方法，会进行自旋，先获取剩余的信号量许可，然后累加回这 n 个许可，判断累加后的剩余许可是否还小了，如果是则说明发生异常了，因为不能归还负的许可数，则抛出异常。
   - 3）如果剩余许可增加了，则 CAS 更新剩余信号量许可，更新失败的，继续自旋，更新成功的，则返回 true，回调到 AQS 中时，需要传播式通知唤醒后续结点，实现共享式传播信号量许可。

###### 6）ThreadPoolExecutor

1. Worker，线程池中的线程工人类，继承 AQS，实现了 Runnable 接口，实现了一个简单的、不可重入的、互斥的任务锁，在任务执行前，需要先获取独占锁，才能运行，运行完毕后释放，保证并发安全。

它有几个重要的方法，

1. 首先是，阻塞式获取独占锁原理：`ThreadPoolExecutor#Worker#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquire(int arg)` 方法，由 ThreadPoolExecutor#Worker 实现了 `tryAcquire(int unused)` 钩子方法。
   - 2）`tryAcquire(int unused)` 方法，会尝试通过 CAS 更新独占资源，如果更新成功，则设置独占线程为当前线程，然后返回 true，代表独占锁获取成功，回调到 AQS 中，无需进入主等待队列中排队。
   - 3）如果更新失败，则返回 false，代表独占锁获取失败，回调到 AQS 中，需要进入主等待队列中排队。
2. 最后就是，释放独占锁原理：`ThreadPoolExecutor#Worker#unlock()`，
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ThreadPoolExecutor#Worker 实现了 `tryRelease(int unused)` 钩子方法。
   - `tryRelease(int unused)` 方法，会清空独占线程、重置独占资源，并返回 true，代表独占锁获取成功（100% 成功），回调到 AQS 中，需要通知唤醒后继结点。

=> 以上，就是我对 AQS 的一些理解，请问有什么细节需要补充的吗？

#### 7.1.1.2. 分布式锁的实现方案？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 7.1.1.3. AOP 的实现原理？

见《[4.1.1.5. Spring AOP 的原理？](#4.1.1.5. Spring AOP 的原理？)》。

#### 7.1.1.4. 责任链模式的特点，以及与适配器模式的区别？

见《[3.2.1.8. 设计模式有了解哪些？线程池这种是什么设计模式？](#3.2.1.8. 设计模式有了解哪些？线程池这种是什么设计模式？)》。

#### 7.2.1.1. 项目亮点讲一下？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 7.2.1.2. Kafka 分区日志存储原理？

见《[3.2.1.3. RocketMQ、Kafka 底层文件原理？](#3.2.1.3. RocketMQ、Kafka 底层文件原理？)》。

#### 7.2.1.3. Kafka 有进行过调优吗？

##### 1）Server.properties 重要配置

| 属性                               | 释义                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| zookeeper.connect                  | 指明 Broker 要连接的 ZK 集群，多个节点用逗号分隔开，ZK 用于管理 Kafka集群的元数据，比如 Topic、Partition、Leader Partition、副本 Replicas 等 |
| listeners                          | 与客户端进行交互的端口，比如消息投递、消息创建，可结合 `listener.security.protocol.map` 指定具体传输的协议类型，比如有 PLAINTEXT 明文传输、SSL 加密传输等 |
| log.dirs                           | 日志存储路径，建议配置多个路径，因为多个不同磁盘的路径，Kafka 会在含有分区目录最少的文件夹下创建新的分区目录，一来可提高吞吐量，二来可提高磁盘的容错性 |
| log.retention.{hours\|minutes\|ms} | Broker 级别的日志留存寿命，默认为 hours=168                  |
| log.retenion.bytes                 | Broker 级别的日志留存大小，默认为 -1，表示没有限制           |
| message.max.bytes                  | Broker 级别的最大消息大小，默认为 976 KB                     |
| retention.ms                       | Topic 级别的日志留存寿命                                     |
| retention.bytes                    | Topic 级别的日志留存大小                                     |
| max.message.bytes                  | 消息级别的最大消息大小                                       |
| auto.create.topics.enable          | 是否允许自动创建 Topic，建议为 false                         |
| unclean.leader.election.enable     | 是否允许选举未完全同步的副本作为 Leader                      |
| auto.leader.rebalance.enable       | 是否允许一段时间后进行 Leader 重选举，重新更换 Leader，建议为 false |

##### 2）Producer 客户端重要配置

在请求完成之前，Producer 要求 Broker 返回 ACK 确认的策略， 同时也控制着所发送消息的持久性：

- **acks=0**：如果设置为 0，那么 Producer 不会 Leader Broker 的任何 ACK 确认，该消息记录会被将立即添加到 socket 缓冲区并视为已发送。
  - 在这种情况下，不能保证 Broker 已经收到记录，并且 Producer 配置的重试机制也会生效，为每个记录返回的偏移量将始终设置为 -1。
- **acks=1**：默认为 1，意味着 Leader Broker 会把记录写入其本地日志，然后做出 ACK 响应给 Producer，并不会等待所有 Follower 确认完。
  - 在这种情况下，如果 Leader Broker 在返回 ACK 确认后发生失败，Follower 被选举为新 Leader 时，由于该记录 Follower 还没完成同步，所以将导致丢失。
- **acks=all**：相当于 `ack=-1`，意味着 Leader Broker 将等待 ISR 中所有的 Broker 确认后才返回 ACK 响应给 Producer。
  - 这是最高的可用保证，只要至少有一个同步副本保持活动状态，该记录就不会丢失。 

| 属性                    | 释义                                                         |
| ----------------------- | ------------------------------------------------------------ |
| acks                    | Broker ACK 确认策略，默认为 1                                |
| max.request.size        | 用于限制 Producer 发送消息的最大值                           |
| retries                 | 重试次数，默认为 0                                           |
| retry.backoff.msretries | 重试间隔，默认为 100                                         |
| compression.type        | 消息的压缩方式，默认为 none，支持 gzip、snappy、lz4 压缩格式 |
| connections.max.idle.ms | 用于指定在多久之后关闭限制的连接，默认为 540000 ms（9 分钟） |
| linger.ms               | 用于指定 Producer 批发送之前，等待消息加入 ProducerBatch Deque 时间，默认为 0 |
| batch.size              | 指定累加多少条消息，才进行一次批发送                         |
| buffer.memeory          | Producer 缓冲待批发送消息的大小，默认为 32 MB                |
| receive.buffer.bytes    | 用于设置 Socket 接收消息缓冲区 SO_RECBUF 的大小，默认为 32 KB |
| send.buffer.bytes       | 用于设置 Socket 发送消息缓冲区 SO_SNDBUF 的大小，默认为 128 KB |
| request.timeout.ms      | 用于设置 Producer 等待请求响应的最长时间，默认为 3000 ms     |

##### 3）Consumer 客户端重要配置

- 当 Kafka 中没有初始偏移量时，比如偏移量数据已被删除，可以根据以下策略进行设置：
  1. **earliest**：自动将偏移量重置为最早的偏移量。
  2. **latest**：自动将偏移量重置为最新的偏移量。
  3. **none**：如果没有找到之前的偏移量，则向 Consumer 抛出异常。

| 属性                      | 释义                                             |
| ------------------------- | ------------------------------------------------ |
| fetch.min.bytes           | 一次拉取的最小数据量，默认为 1 B                 |
| fetch.max.bytes           | 一次拉取的最大数据量，默认为 50 MB               |
| max.partition.fetch.bytes | 一次拉取一个 Partition 的最大数据量，默认为 1 MB |
| fetch.max.wait.ms         | 拉取请求的最大延迟等待时间，默认为 500 ms        |
| max.poll.records          | 每次拉取的消息最大条数                           |
| auto.offset.reset         | 偏移量丢失处理策略，默认为 latest                |

#### 7.2.1.4. ZK 与 Redis 分布式锁的区别？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 7.2.1.5. 设计一个注解，实现对返回值（比如手机号码）进行脱敏，基于 Spring、Spring MVC 如何实现？

见《[1.1.1.5. SpringMVC 请求前改写 @RequestBody 参数？](#1.1.1.5. SpringMVC 请求前改写 @RequestBody 参数？)》- Controller AOP | 实现简单强大。

#### 7.2.1.6.  设置一个配置中心，以满足配置动态刷新的需求？

##### 1）消息中间件实现

1. 假设，配置是放在 GitHub 上，由于要满足动态刷新，所以配置中心服务端需要提供一个服务，来接收 GitHub 的钩子回调。
2. 回调时，调用配置中心服务端的业务逻辑，生成一条消息，丢到消息队列中，消息体存放的是，本次拉取最新配置的路由地址。
3. 这时，会被各个配置中心客户端进行消费，根据消息体中的路由，拉取最新的消息，替换掉本地缓存，并且销毁所有 RefreshScope 自定义作用域的 Bean。
4. @RefreshScope 是懒加载模式，是一个 FactoryBean 对象，在下次用到时，会先去本地缓存中获取，获取不到再重新去 Config Server 中加载，从而实现配置的动态刷新。

##### 2）ZK 实现

1. 假设，配置是放在 GitHub 上，由于要满足动态刷新，所以配置中心服务端需要提供一个服务，来接收 GitHub 的钩子回调。
2. 回调时，调用配置中心服务端的业务逻辑，修改 ZK 某一配置文件结点。
3. 此时，会被各个配置中心客户端监听到发生变化，从而拉取最新的配置，替换掉本地缓存，并且销毁所有 RefreshScope 自定义作用域的 Bean。
4. @RefreshScope 是懒加载模式，是一个 FactoryBean 对象，在下次用到时，会先去本地缓存中获取，获取不到再重新去 Config Server 中加载，从而实现配置的动态刷新。

#### 7.2.1.7. k8s 架构图？

见《[4.1.2.3. Docker 和 K8S 有了解过吗？](#4.1.2.3. Docker 和 K8S 有了解过吗？)》。

#### 7.2.1.8. 阻塞队列有哪些？

##### 1、总

1. BlockingQueue，阻塞队列，继承自 Queue 接口，除了 Queue 接口方法外，还提供了以下操作：在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。

2. BlockingQueue，是线程安全的，所有排队方法，使用了内部锁、或者其他并发控制的方式，来原子地实现其操作，它的方法一共 4 种形式：

   - 1）抛出异常。
   - 2）返回一个特殊值，{@code null} 或 {@code false}，具体取决于操作。
   - 3）无限期地阻塞当前线程，直到操作成功为止。
   - 4）阻塞等待指定的时间。

   |             | *Throws exception*         | *Special value*         | *Blocks*             | *Times out*                                                 |
   | ----------- | -------------------------- | ----------------------- | -------------------- | ----------------------------------------------------------- |
   | **Insert**  | {@link #add add(e)}        | {@link #offer offer(e)} | {@link #put put(e)}  | {@link #offer(Object, long, TimeUnit) offer(e, time, unit)} |
   | **Remove**  | {@link #remove remove()}   | {@link #poll poll()}    | {@link #take take()} | {@link #poll(long, TimeUnit) poll(time, unit)}              |
   | **Examine** | {@link #element element()} | {@link #peek peek()}    | *not applicable*     | *not applicable*                                            |

3. JDK 8 中，典型实现有：

   - 1）ArrayBlockingQueue，数组有界阻塞队列。
   - 2）LinkedBlockingQueue，链表有界阻塞队列。
   - 3）PriorityBlockingQueue，优先级无界阻塞队列。
   - 4）SynchronousQueue，无容量的同步阻塞队列。

##### 2、分

下面打算讲下几个重要实现的原理，

###### 1）ArrayBlockingQueue

1. ArrayBlockingQueue，数组有界阻塞队列，保存固定大小的数组，数组创建后，其容量无法被更改。
2. 元素从队尾进、队头出，在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。
3. 同时支持公平性设置，设置为 true，则代表使用公平策略，队列则严格按 FIFO 顺序添加、获取元素，可避免线程饥饿，但会降低吞吐量。

它的实现原理是，

1. 数据结构为，
   - 1）持有一个 `Object[] items` 数组来存储元素。
   - 2）持有一个 `int takeIndex` 、以及一个 `int putIndex`，表示最近获取、添加索引，每次获取、添加完元素之后，都会向前、向后更新它的值，由于是在显示锁控制的临界区内操作，所以是线程安全的。
   - 3）持有一个 `int count`，表示当前队列中的实际大小，每次获取、添加完元素之后，都会  -1 或者 +1，由于是在显示锁控制的临界区内操作，所以是线程安全的。
   - 4）持有一个 `ReentrantLock lock` 显式锁来控制独占访问以及公平策略。
   - 5）持有一个 `Condition notEmpty` 队列非满条件、以及一个 `Condition notFull` 队列非空条件，两条件都是由 lock 显式锁构造，遵守与 ReentrantLock 相同的公平性策略。
2. 然后就是，阻塞式添加元素方法的实现原理：`put(E e)`，
   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于数组容量大小，是的话，说明队列已经满了，不能再添加元素了，则调用 `notFull.await()`，释放当前线程独占的锁资源，阻塞等待非满条件的发生，即发生一次元素获取事件。
   - 3）如果队列还没满，或者非满条件已发生，当前线程重新抢到锁资源，则调用 `enqueue(E x)`，往数组中追加此元素，并更新实际大小 + 1，然后调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
   - 4）最后，释放显式锁。
3. 最后就是，阻塞式删除元素方法的实现原理：`take()`，
   - 1）与 `put(E e)` 方法相反，首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再获取元素了，则调用 `notEmpty.await()`，释放当前线程独占的锁资源，阻塞等待非空条件的发生，即发生一次元素添加事件。
   - 3）如果队列还没空，或者非空条件已发生，当前线程重新抢到锁资源，则调用 `dequeue()`，获取数组最近索引的元素，获取后再清空该位置，并更新实际大小 - 1，然后调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put(E e)` 方法线程。
   - 4）最后，释放显式锁，返回清空之前该位置的值。

###### 2）LinkedBlockingQueue

1. LinkedBlockingQueue，链表有界阻塞队列，容量未指定时，默认使用 `Integer＃MAX_VALUE`，可能会导致内存溢出的发生，所以一般在构造时都指定实际容量，防止队列存放过多的元素。
2. 元素从队尾进、队头出，在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。
3. 不支持公平性设置，只能使用非公平策略，同时，阻塞方法的实现原理也不同，理论上会比 ArrayBlockingQueue 拥有更高的吞吐量。

它的实现原理是，

1. 数据结构为，
   - 1）持有一个 `Node<E> head`、一个 `Node<E> last`  链表的头尾结点，以支持从尾添加从头获取元素。
   - 2）持有一个 `int capacity`，表示队列的容量边界，超过此容量后，再添加元素，则线程会阻塞等待非满条件的发生。
   - 3）持有一个 `AtomicInteger count = new AtomicInteger()`，表示当前队列的实际大小，通过 Atomic 原子类控制线程同步。
   - 4）持有一个 `ReentrantLock takeLock` take 锁、一个 `ReentrantLock putLock`，以分别控制排队的线程，提高吞吐量。
   - 5）持有一个 `Condition notEmpty = takeLock.newCondition()` 队列非满条件，以及一个 `Condition notFull = putLock.newCondition()` 队列非空条件，分别由 take 锁和 put 锁构造，同样也是非公平的策略。
2. 然后就是，阻塞式添加元素方法的实现原理：`put(E e)`，
   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占 put 锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 `capacity` 容量边界，是的话，说明队列已经满了，不能再添加元素了，则调用 `notFull.await()`，释放当前线程独占的 put 锁资源，阻塞等待非满条件的发生。
   - 3）如果队列还没满，或者非满条件已发生，当前线程重新抢到 put 锁资源，则调用 `enqueue(E x)`，往数组中追加此元素，并更新实际大小 + 1，然后如果添加之后，容量还没满，则调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put()` 方法线程。
     - 可见，这里非满条件通知，除了 take 线程会发生外，连其他的 put 线程也会发生，来发出通知，使得阻塞的 `put()` 方法线程，其等待时间更少，吞吐量来得更高。
   - 4）最后，释放 put 锁，再判断添加前容量是否为 0，是的话，说明添加之后队列不为空了，则获取独占 take 锁，获取失败，则当前线程会进入阻塞状态，获取成功，则会调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
3. 最后就是，阻塞式删除元素方法的实现原理：`take()`，
   - 1）与 `put(E e)` 方法相反，首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占 take 锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再获取元素了，则调用 `notEmpty.await()`，释放当前线程独占的 take 锁资源，阻塞等待非空条件的发生。
   - 3）如果队列没空，或者非空条件已发生，当前线程重新抢到 take 锁资源，则调用 `dequeue(E x)`，脱钩链头结点，并更新实际大小 - 1，然后如果删除之后，容量还没空，则调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
     - 可见，这里非空条件通知，除了 put 线程会发生外，连其他的 take 线程也会发生，来发出通知，使得阻塞的 `take()` 方法线程，其等待时间更少，吞吐量来得更高。
   - 4）最后，释放 take 锁，再判断添加前容量是否为 `capacity` 队列容量边界，是的话，说明删除之后队列不满了，则获取独占 put 锁，获取失败，则当前线程会进入阻塞状态，获取成功，则会调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put()` 方法线程，再返回脱钩出来的头结点的值。

###### 3）PriorityBlockingQueue

1. PriorityBlockingQueue，优先级无界阻塞队列，基于小顶堆实现，能够每次都按传入的 Comparator 比较器或者自然顺序，对元素以 O（logn）进行排序，因此，队头中的元素是比较器给出的最小结果元素，队尾则是最大的元素，相同的元素之间是不稳定的。

它的实现原理是，

1. 数据结构为，

   - 1）持有一个 `Object[] queue` 数组来存储元素。
   - 2）持有一个 `Comparator<? super E> comparator`，表示按指定的比较器，来进行小顶堆排序。
   - 3）持有一个 `int size`，表示当前队列中的实际大小。
   - 4）持有一个 `ReentrantLock lock` 显式锁来控制独占访问，采用的是非公平性策略。
   - 5）持有一个 `Condition notEmpty` 队列非满条件，由 lock 显式锁构造，采用的是非公平性策略。

2. 然后就是，小顶堆原理，

   - 1）最后一个非叶子结点，在数组中的序号 i = n / 2 - 1，n 为数组长度。
   - 2） 对于序号 i 的结点，其父结点序号 f = （i - 1）/ 2，左孩子序号 l = 2 * i + 1，右孩子序号 r = 2 * i + 2，如果有的话。
   - 3）小顶堆堆化：`heapify()`，
     1. 从最后一个非叶子结点 K 位置开始，从下到上，从右到左，每次遍历都对结点进行向下调整，一直遍历到根结点 queue[0] 后，queue[0] 就是数组中的最小值，即完成了数组的小顶堆堆化。
   - 4）小顶堆向下调整：`siftDownComparable(int k, T x, Object[] array, int n)`， k 为要调整的结点序号，x 为要调整的结点的值，array 为数组，n 为数组长度。
     1. 从 k 位置开始循环，比较 x、左、右孩子的值，交换最小者到堆顶，然后继续向下调整，直到调整到最后一个非叶子结点为止。
   - 5）小顶堆向上调整：`siftUpComparable(int k, T x, Object[] array)`，k 为要调整的结点序号，x 为要调整的结点的值，array 为数组。
     1. 从 k 的父结点 f = （k  - 1）/ 2 开始，比较 x、f 的值，交换大者到 k 位置，然后继续向上调整，直到调整到根结点位置。

   ![1625386699340](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625386699340.png)

3. 接着就是，阻塞式添加元素方法的实现原理：`put(E e)`，

   - 1）首先，会调用 `lock.lock()`，阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则判断当前队列中的实际大小，是否大于等于数组容量，是的话，说明队列满了，则调用 `tryGrow(Object[] array, int oldCap)`，进行数组扩容。
   - 3）如果没小于数组容量，说明队列还没满，则调用 `siftUpComparable(int k, T x, Object[] array)`，插入元素并向上调整小顶堆（大的放后面），然后实际大小 + 1，调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
   - 4）最后，释放独占锁。

4. 再然后就是，数组扩容原理：`tryGrow(Object[] array, int oldCap)`，

   - 1）首先，释放独占锁，获取自选锁 `allocationSpinLockOffset`，判断旧容量（当前数组大小），是否小于 64，如果是，则扩容为旧容量 * 2 倍 + 2，否则扩容为旧容量 * 1.5 倍。
   - 2）然后做容器最大值 `Integer.MAX_VALUE - 8` 校验，校验不通过则抛出异常，校验通过，则重新构建长度为新容量的数组，给中间变量 `Object[] newArray`。
   - 3）最后，释放自选锁，重新获取独占锁，赋值中间变量 newArray 给 `Object[] queue` 队列数组，然后调用 `System.arraycopy(array, 0, newArray, 0, oldCap)`，拷贝并移动旧数据到新数组中，再返回。

5. 最后就是，阻塞式删除元素方法的实现原理：`take()`，

   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再获取元素了，则调用 `notEmpty.await()`，释放当前线程独占锁资源，阻塞等待非空条件的发生。
   - 3）然后，再获取 queue[0] 数组的第一个元素，调用 `siftDownComparable(int k, T x, Object[] array, int n)` 对其进行向下调整，更新实际大小 - 1。
   - 4）最后，更新实际大小 - 1，释放独占锁，并返回第一个元素的值。

###### 4）SynchronousQueue

1. SynchronousQueue，无容量的同步阻塞队列，每个插入操作，需要等待另一个删除操作，以及每个删除操作，需要等待另一个插入操作。
2. 它支持可选的公平策略，默认为非公平，设置为 true，则代表使用公平策略，队列则按 FIFO 顺序添加、获取元素，可避免线程饥饿，但会降低吞吐量。

它的实现原理是，

1. 数据结构为，持有一个 `volatile Transferer<E> transferer`，内部类的实例引用，它有两个实现类，如果为非公平策略，则为栈结构，如果为公平策略，则为队列结构。

2. 栈结构的实现是，使用自旋锁提高吞吐量，如果只出现添加、或者删除其中一个操作，则会调用 `LockSupport.park(this)` 让其阻塞等待到另一个操作的出现，实现添加和删除方法两两配对、两两同步。由于栈是后进先出，也就是新来的，会比栈底更久的，更先得到配对响应，所以实现了非公平策略。

   ![1621954377695](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1621954377695.png)

3. 队列结构的实现是，使用自旋锁提高吞吐量，如果只出现添加、或者删除其中一个操作，则会调用 `LockSupport.park(this)` 让其阻塞等待到另一个操作的出现，实现添加和删除方法两两配对、两两同步。由于队列是先进先出的，所以另一个操作到来时，会去队头做匹配，从而让最久的先得到响应，所以实现了公平策略。

   ![1622033076546](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1622033076546.png)

##### 3、总

=> 以上，就是我对 BlockingQueue 的一些理解，请问有什么细节需要补充的吗？

#### 7.2.1.9. ArrayBlockingQueue 与 LinkedBlockingQueue 的异同，比如在锁的角度呢？

1. 相同点：都实现了 BlockingQueue 接口，都是有界的阻塞队列，在添加元素时，队列满了则会阻塞等待队列非满，在删除元素时，队列为空则会阻塞等待队列非空。
2. 不同点：
   - 1）**底层实现的数据结构不一样**，ArrayBlockingQueue 是基于数组实现的，而 LinkedBlockingQueue 是基于单向链表实现的。
   - 2）**构造方法不一样**，ArrayBlockingQueue 构造时必须设定容量边界，同时支持公平和非公平的排队策略，而 LinkedBlockingQueue 构造时可以不设定容量边界，默认为 `Integer.MAX_VALUE`，且仅支持非公平的排队策略。
   - 3）**条件通知机制不一样**，ArrayBlockingQueue 中的队列非满和非空条件，基于的都是同一把显式锁，非满只能被删除方法唤醒，非空只能被添加方法唤醒，而 LinkedBlockingQueue 中的队列非满条件，基于 put 锁实现，可以被添加、删除两个方法唤醒，队列非空条件，基于 take 锁实现，也可以被添加、删除两个方法唤醒，理论上吞吐量来得要比 ArrayBlockingQueue 的高。
   - 4）**队列实际大小统计不一样**，ArrayBlockingQueue 的实际大小，是通过持有一个 `int count` 成员变量，在独占锁的临界区内进行更新，而 LinkedBlockingQueue 的实际大小，是通过 `AtomicInteger count = new AtomicInteger()` 成员变量，利用 CAS 进行更新。

#### 7.2.2.0. 有参与过 JVM 调优吗，只有过 MAT 吗，OGLIB 有听过没？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 3、项目亮点 - 5）内存溢出排查 | MAT、POI、ArrayList、12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%。

#### 7.2.2.1. CMS 和 G1 有什么差别？

见《[4.1.1.8. 项目中的垃圾收集器用了哪些？](#4.1.1.8. 项目中的垃圾收集器用了哪些？)》。

#### 7.2.2.2. 反射的 API 里有哪些类？

![1648430396798](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648430396798.png)

| 类名                       | 接口 / 实现类 | 作用                                                         |
| -------------------------- | ------------- | ------------------------------------------------------------ |
| Type                       | 接口          | Java 所有类型的通用超接口，包括 GenericArrayType、ParameterizedType 和 TypeVariable 和 WildcardType |
| GenericArrayType           | 接口          | 表示一个数组类型，包括 ParameterizedType 和 TypeVariable     |
| ParameterizedType          | 接口          | 表示一个泛型类型                                             |
| TypeVariable               | 接口          | 表示各种类型变量的通用超接口                                 |
| WildcardType               | 接口          | 表示通配符表达式类型                                         |
| AnnotatedElement           | 接口          | 表示在类上的所有注解元素                                     |
| AnnotatedType              | 接口          | 表示注解类型，包括 AnnotatedArrayType、AnnotatedParameterizedType、AnnotatedTypeVariable 和 AnnotatedWildcardType |
| AnnotatedArrayType         | 接口          | 表示注解数组类型，包括 AnnotatedParameterizedType 和 AnnotatedTypeVariable |
| AnnotatedParameterizedType | 接口          | 表示注解泛型类型                                             |
| AnnotatedTypeVariable      | 接口          | 表示注解变量类型                                             |
| AnnotatedWildcardType      | 接口          | 表示注解通配符表达式类型                                     |
| GenericDeclaration         | 接口          | 表示声明类型变量的所有实体的通用接口，包括 Class、Constructor、Method 和 Method |
| Member                     | 接口          | 表示一个字段、方法、或者构造函数的标识信息                   |
| AccessibleObject           | 实现类        | 是 Field、Method 和 Constructor 对象的基类，提供了反射对象在使用时的访问保护 |
| Parameter                  | 实现类        | 表示方法参数，提供有关方法参数信息的获取方法，包括名称、修饰符、以及参数属性 |
| Executable                 | 抽象类        | Method 和 Constructor 对象的通用抽象基类                     |
| Field                      | 实现类        | 提供关于类或接口的某个字段的信息和动态访问，可以是一个静态字段或实例字段 |
| Constructor                | 实现类        | 提供关于类的某个构造函数的信息和访问权限                     |
| Method                     | 实现类        | 提供有关类或接口上的某个方法的信息和访问权限，可以是静态方法，也可以是实例方法或者抽象方法 |
| Modifier                   | 实现类        | 提供类和成员访问修饰符的获取方法                             |
| Array                      | 实现类        | 提供动态创建和访问 Java 数组的方法                           |
| InvocationHandler          | 接口          | 表示代理实例实现的处理程序接口                               |
| Proxy                      | 实现类        | 是由创建的所有动态代理类的超类，提供了创建动态代理类和实例的方法 |
| ReflectPermission          | 实现类        | 反射操作的权限类                                             |

#### 7.3.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 7.3.1.2. 为什么要离职？

1. 主要原因是，个人发展受限，想在市场上看看有没有更好的机会。
2. 比如说，这些年积累的很多技术经验，包括深度和广度上，拓展得不错，想要找到一个更好突出自己价值的平台。

#### 7.3.1.3. 根据已有的经验，谈谈你对未来 G 系统迭代方向的一些看法？

1. 项目管理方面：目前采用的 Git + Jenkins 做的 CI / CD 持续集成、持续交付，但容器化技术也越来越成熟，更适合微服务的部署和管理，更节省机器成本，所以，项目管理上可以从这角度进行迭代。
2. 平常开发方面：目前是一个大版本迭代后，才做的一次 Code Review，项目上也还是有挺多设计不够合理、不太符合高内聚的理念，所以，平常开发方面，可以改成一个小版本适当地进行一次 Code Review，以及适当地抽取通用接口、工具类，来让系统代码趋向高内聚，可以减少测试开发成本，避免重复造轮子。
3. 业务迭代方面：目前采购方 + 供方都是基于电脑端使用，由于采购方是企业用户，所以电脑端使用无可厚非，而对于供方，G 系统未来可以抽取出更简单的业务，向移动端靠拢，让系统更加便捷、容易使用。
4. 以上，就是我对未来迭代方向的一些看法~

#### 8.1.1.1. 项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 8.1.1.2. 谈一下你对微服务的一个理解？

见《[1.1.1.1. 项目上用到了 SpringCloud 哪些组件？](#1.1.1.1. 项目上用到了 SpringCloud 哪些组件？)》。

#### 8.1.1.3. G 系统分库分表方案是怎么设计的？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 8.1.1.4. 分布式锁的实现方案？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 8.2.1.1. 讲一下 Eureka 源码？

##### 1、总

![1638234417008](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638234417008.png)

1. 在传统应用组件间调用，是通过接口规范约束来实现的，从而实现不同模块间良好协作。
2. 但是在被拆分成微服务后，每个微服务实例的网络地址和数量都可能动态变化，导致使用原来硬编码地址的方式极不方便，因此，需要一个中心化的组件来进行服务的登记和管理。
3. Eureka，是 Spring Cloud 的一个基于 AP 模型的注册中心，支持服务注册、服务发现、服务调用、服务续约、服务剔除、服务自保、服务下线、集群高可用等功能。
4. 其实现包括 Server 端和 Client 端，Server 端可以作为一个公共的注册中心服务，为 Client 提供服务注册和服务发现的功能，维护自身的服务列表信息，Client 端又分为服务提供者和服务消费者，服务提供者通过注册自身的信息到 Server 端，方便消费者发现自己，服务消费者，通过服务发现，从 Server 端拉取服务列表，然后使用内置的负载均衡器，实现服务调用。

##### 2、分

###### 1）Eureka Server 启动原理

1. 首先，@EnableEurekaServer 会导入一个 `EurekaServerMarkerConfiguration`，这个配置类会加载 `Marker` 标志类。
2. 然后，Spring Boot 会自动装配 `EurekaServerAutoConfiguration`，只有存在 `Marker`  标志类时，Spring 才会去解析这个配置 Bean。由于`Marker`  标志类已被 @EnableEurekaServer 导入了，所以，该配置 Bean 会继续读取 `classpath:/eureka/server.properties`，往 IOC 注入注册表等 Bean 对象。
3. 接着，`DefaultLifecycleProcessor` 实现了 `LifecycleProcessor#onRefresh()` 生命周期回调接口，在 Spring 执行到 `AbstractApplicationContext#finishRefresh()` 时进行回调，该方法会启动一个异步线程，去初始化 Eureka Server 环境、上下文，以及读取 `eureka.server.evictionIntervalTimerInMs` （默认 60 s）， 启动一个定时任务 `EvictionTask`，执行**服务剔除**逻辑。

###### 2）Eureka Client 启动原理

1. 首先，Spring Boot 启动时，会自动装配 `EurekaClientAutoConfiguration` ，该配置 Bean 会装配一个 `EurekaClient`，并指定其 `shutdown()` 方法，实现**服务下线**。
2. 在构造 `EurekaClient` 时，会：
   - 1）读取 `eureka.instance.lease.renewalInterval` 续约周期（默认 30 s），创建 ` heartbeatExecutor` 线程池，启动 `HeartbeatThread` 线程任务，用于定时**服务续约**。
   - 2）读取 `eureka.client.refresh.interval` 服务列表拉取周期（默认 30 s），创建 ` cacheRefreshExecutor` 线程池，启动 `CacheRefreshThread` 线程任务，用于定时**服务发现**，刷新服务列表缓存。
   - 3）读取 `eureka.appinfo.initial.replicate.time` 注册延迟时间（默认 40 s），启动 `InstanceInfoReplicator` 线程任务，用于**服务注册**。

###### 3）服务注册原理

1. Eureka Client `InstanceInfoReplicator` 线程任务，延迟 ``eureka.appinfo.initial.replicate.time` （默认 40 s）后，调用 `discoveryClient.register()` 做服务注册。
2. 它会经过一些列的装饰者调用，包括 `SessionedEurekaHttpClient#execute ` 更新 session 时间、`RetryableEurekaHttpClient#execute ` 默认最大重试 3 次、`RedirectingEurekaHttpClient#execute` 重定向配置、`MetricsCollectingEurekaHttpClient#execute` 指标记录。
3. 最终，调用到 `AbstractJerseyEurekaHttpClient#register(InstanceInfo)` 方法，该方法正式发起 post请求 Eureka Server，进行服务注册。
4. Eureka Server `addInstance` 接口，收到 `apps/${服务名}` 后，先进行一系列校验，然后调用 `register(final InstanceInfo info, final boolean isReplication)` 方法，写入新实例到 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中，更新该实例的最后更新时间、清空读写二级缓存后，返回 204 给 Eureka Client，代表服务注册成功。

###### 4）服务发现原理

1. Eureka Client `CacheRefreshThread` 线程任务，会调用 `DiscoveryClient#refreshRegistry()` 方法，以 `eureka.client.refresh.interval` （默认 30）作为周期， 做定时服务发现。
2. 每次服务发现，分为增量拉取和全量拉取，如果强制配置、或者第一次拉取，则做全量拉取，否则走增量拉取，拉取完毕后更新服务列表缓存。
3. 全量拉取时，同样经历注册时的装饰者链调用，最终由 `AbstractJerseyEurekaHttpClient#getApplications()`，发起 `apps/` 请求到 Eureka Server。增量拉取时，同样也经历装饰者链调用，最终由 `AbstractJerseyEurekaHttpClient#getApplicationsInternal()`，发起 `apps/delta` 请求到 Eureka Server。
4. Eureka Server 先一级只读缓存中获取，获取不到则从二级读写缓存中获取，还获取不到则触发 `Guava Cache#load()` 方法，从 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中读取出来，并加载到二级缓存中，最后返回 200，表示服务列表获取成功。

###### 5）Eureka Server 服务列表缓存原理

![1648467823898](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648467823898.png)

1. 服务注册到注册中⼼后，服务实例信息存储在 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中。

2. Eureka 为了提⾼响应速度，做了两层的缓存结构优化，将 Client 需要的实例信息，直接缓
  存起来，在获取时直接从缓存中拿数据，然后响应给 Client。
3. 第⼀层缓存是， `ResponseCacheImpl#readOnlyCacheMap`，采⽤ ConcurrentHashMap 来存储数据，定时
  `eureka.server.responseCacheUpdateIntervalMs`（默认 30 s 一次） 与 `ResponseCacheImpl#readWriteCacheMap` 进⾏数据同步。
4. 第⼆层缓存是， `ResponseCacheImpl#readWriteCacheMap`，采⽤ Guava 来实现缓存，缓存过期时间 `eureka.server.responseCacheAutoExpirationInSeconds` （默认为 180 s），当服务下线、过期、注册、状态变更等操作，都会清除该缓存中的数据。
5. 如果两级缓存都无法查询，则会触发 Guava 缓存的加载 `CacheLoader#load()`，从 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表，读取数据到二级缓存中，再返回给 Client。
6. 对于 Eureka Client 的本地缓存，是通过 `CacheRefreshThread` 线程任务，以 `eureka.client.refresh.interval` （默认 30 s）作为周期，做定时服务发现时更新的。
7. 对于 Ribbon 缓存，是通过 `PollingServerListUpdater` 启动一个线程任务，以 `${服务名}.ribbon.serverListRefreshInterval`（默认 30 s）为周期，调用 `ServerListUpdater.UpdateAction#doUpdate()` 方法，从 Eureka Client 本地缓存中获取再更新。

###### 6）服务调用原理

1. Eureka 依赖与 Ribbon，在 Spring Boot 启动时，会启动装配一个 `RibbonEurekaAutoConfiguration`，该配置 Bean 会读取 Ribbon 配置，向 IoC 容器注入一个 `LoadBalancerClient` 对象。
2. 在调用 `loadBalancerClient.choose("eureka-client")` 发起初次服务调用时，会使用 `SpringClientFactory#getLoadBalancer("eureka-client"）` ，构造 `ILoadBalancer` 对象，触发 `RibbonClientConfiguration` 的注入，通过 `PollingServerListUpdater` 启动一个线程任务，以 `${服务名}.ribbon.serverListRefreshInterval`（默认 30 s）为周期，调用 `ServerListUpdater.UpdateAction#doUpdate()` 方法，从 Eureka Client 本地缓存中获取再更新。
3. 然后再选择从中服务列表缓存中，选择一个具体的实例，进行服务调用。

###### 7）服务续约原理

1. Eureka Client `HeartbeatThread` 线程任务，会调用 `DiscoveryClient#renew()`，以 `eureka.instance.lease.renewalInterval` 为续约周期（默认 30 s），做服务续约。
2. 它会调用 `registrationClient.sendHeartBeat()` 发送心跳包，经过一些列的装饰者链调用，最终调用到 `AbstractJerseyEurekaHttpClient#sendHeartBeat()` 方法，发起 `apps/service-name/host:service-name:ip` 请求、以及 `lastDirtyTimestamp` 到 Eureka Server，进行续约。
3. Eureka Server `renewLease` 接口，收到请求后，会执行服务续约，更新过去一分钟进行服务续约的数量、最后更新时间等信息，续约失败的，则返回 404，让客户端重新注册。
4. 续约成功的，先根据服务名获取 `registry` 服务列表中对应的租约实例，然后判断租约实例中的脏时间戳与传过来的 `lastDirtyTimestamp` 大小，如果传过来的大，说明客户端重启过，Eureka Server 的租约落后了，则返回 404，让客户端重新注册。
5. 如果传过来的小，说明收到的是集群同步请求，则返回当前租约实例的复制。

###### 8）服务剔除、服务自保原理

1. 在 Eureka Server 启动时，`AbstractApplicationContext#finishRefresh()` 进行回调，会启动一个异步线程，去初始化 Eureka Server 环境、上下文，以及读取 `eureka.server.evictionIntervalTimerInMs` （默认 60 s）， 启动一个定时任务 `EvictionTask`，调用 `evict(long additionalLeaseMs)` 方法，执行服务剔除逻辑。

2. 该方法会先判断能否执行服务剔除，如果 `eureka.server.enableSelfPreservation` 服务自保开关已关闭（默认打开），则直接返回 true，代表不启用服务自保，要做服务剔除操作，如果服务自保开关已打开，则要根据 `numberOfRenewsPerMinThreshold > 0 && getNumOfRenewsInLastMin() > 
   numberOfRenewsPerMinThreshold` ，即过去一分钟进行服务续约的数量，是否大于每分钟最少续约阈值，是的话则返回 true，代表不启用服务自保，要做服务剔除操作。

   ```java
   public abstract class AbstractInstanceRegistry implements InstanceRegistry {
       protected void updateRenewsPerMinThreshold() {
           // 每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
           this.numberOfRenewsPerMinThreshold = (int) 
   (this.expectedNumberOfClientsSendingRenews
                   * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds())
                   * serverConfig.getRenewalPercentThreshold());
       }
   }
   ```

3. 如果确定要做服务剔除了，则通过租约期望时间 =  `lastUpdateTimestamp + duration + additionalLeaseMs`（租约最后更新时间 + 租约持续时间默认 90 s + 补偿时间），如果租约期望时间小于当前时间，则认为租约已过期，然后将其收集起来。

4. 然后，随机抽取一个租约实例，从 `registry` 服务列表中删除，并清除 Guava Cache 二级读写缓存，随机剔除，可以使得该租约实例在整个 Eureka Server 集群中，剔除得比较离散，防止服务雪崩。

###### 9）服务下线原理

1. Spring Boot 启动时，会自动装配 `EurekaClientAutoConfiguration` ，该配置 Bean 会装配一个 `EurekaClient`，并指定其 `shutdown()` 方法，实现服务下线。
2. 该方法会销毁 `instanceInfoReplicator` 服务注册线程、`heartbeatExecutor` 服务续约线程、`cacheRefreshExecutor` 服务发现线程、以及 `scheduler` 调度定时器，调用 `unregister()`  发起取消服务注册请求。
3. 最终由 `AbstractJerseyEurekaHttpClient#cancel()` ，发起 `apps/service-name/host:service-name:port` 请求到 Eureka Server。
4. Eureka Server 的 `cancelLease()` 接口，收到服务取消注册请求后，调用 `PeerAwareInstanceRegistryImpl.cancel()` 方法，从 `registry` 服务列表中删除对应租约实例，并清除 Guava Cache 二级读写缓存，减少过去一分钟进行服务续约的数量，同步操作到 Eureka Server 集群的其他节点，最后返回 true，代表服务下线成功。

###### 10）Eureka Server 集群同步原理

1. Eureka Server 集群同步，有几个关键时机，
   - 1）第一是，Eureka Server `addInstance` 接口，在接收到客户端的**服务注册**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `addInstance` 接口。
   - 2）第二是，Eureka Server  `renewLease` 接口，在接收到客户端的**服务续约**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `renewLease` 接口。
   - 3）第二是，Eureka Server  `cancelLease` 接口，在接收到客户端的**服务下线**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `cancelLease` 接口。

##### 3、总

=> 以上，就是我对 Eureka 实现原理的一些理解，请问有什么细节需要补充的吗？

#### 8.2.1.2. 服务下线后，客户端会立马感应到吗？

不会立马感应到。

1. 首先，对于 Eureka 这种 AP 模型，数据是非强一致的，在服务提供者主动下线，或者被服务剔除后，Eureka Server 会把其从 `registry` 注册表中移除，以及作废 Guava Cache 二级缓存，但此时一级缓存需要等到 `eureka.server.responseCacheUpdateIntervalMs` （默认 30s）后，才能从二级缓存中获取，由于二级缓存没有，则触发 Guava Cache#load 方法，读取 `registry` 注册表，获取到最新的服务注册信息。
2. 同时，客户端的 Ribbbon 缓存，也需要等到 `xxxService.ribbon.serverListRefreshInterval` （默认 30s）后，才会定期更新。
3. 所以，Eureka AP 模型是无法让客户端实时感应到的。
4. 其次，如果对于 ZK 这种 CP 模型，即使服务端数据强一致，在服务注册信息发生变更时，触发 Watcher 机制，通知客户端，由于 TCP 传输需要花费一定的时间，在这传输到客户端缓存更新的情况下，很可能导致客户端去请求了旧的已下线的服务，也无法保证实时感知。
5. 可见，基于客户端实现的负载均衡算法，由于本地暂存了旧的服务列表，在更新期间导致的不一致性是不可避免的，因此，是无法实现实时感知的。
6. 而基于 CP 模型的服务端负载均衡，虽然可以解决这个问题，但又出现了新的问题，由于设计反向代理的转发，以及代理服务器在更新服务列表时，会出现一端时间不可用，这问题更严重，也不是个好方案。
7. 所以，服务下线，要保证客户端 100% 实时感知，在目前实现是比较困难的，因此，需要提供一种高可用的负载均衡算法，使得在服务下线时，客户端能够尽量不去调用它们，而是去调用还在线的服务，以提高系统可用性。

#### 8.2.1.3. 设计一个负载均衡算法，实现服务下线时，客户端能够实时感知？

1. 首先，注册中心采用 CP 模型，保证服务端层面的注册列表数据一致性。
2. 然后，客户端在第一次拉取到服务列表信息后，会注册监听器，在服务端的注册列表发生变更时，由注册中心主动通知客户端进行更新，这都与上面一样。
3. 不同的来了，客户端会对历史用过的服务实例，按照平均响应时间进行质量评分，时间越长，评分越低，发生过超时的会被评为 60 分以下，平均响应时间在 200 ms 以上会被评为 60 分 ~ 90 分，响应时间在 0 ms ~ 200 ms 的会被评为 90 分以上。质量评分在每次调用后，会进行更新，以保证 90 分以上的服务实例，能够一直维持高质量。
4. 客户端优先从高质量服务实例列表中（如果质量高的没有，则选择质量次高的），随机抽取一个实例进行调用，一来认为质量高的会一直质量高，发生服务下线的可能性不大，二来随机抽取，可以防止某个实例被过热调用。
5. 当然，即使是从质量好的服务，也会有宕机的时候，所以，在上面调用失败时，会将该实例打标为 60 分以下、从高质量实例列表中剔除，然后进行降级，降级时会重新选取一个高质量服务实例，重新发起调用，重试 n 次，当重试次数用完后，如果还没能调用成功，则根据配置的策略，走默认降级逻辑、或者抛出异常。
6. 从而，满足高可用负载均衡算法，在服务下线时，客户端能够尽量不去调用它们，而是去调用还在线的服务，以提高系统可用性。

#### 9.1.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 9.1.1.2. 业务数据一致性怎么保证的？

进销存销售出库 -> 条码扫码 -> 写条码暂存 -> 前端点击销售出库 -> 根据条码写订单 -> 检查库存 -> 写库存流水表 -> 扣减库存 -> 扣减成功，作废条码 -> http 推送 MES，记录接口日志 -> 推送失败的则一直推送 -> 超过次数则人工介入。

1. 其中，条码扫码和暂存属一个事务，写订单、写流水表、扣减库存属一个事务，推送 MES 作为一个事务。
2. 如果库存扣减成功，但推送 MES 失败，会出现数据不一致，此时可以通过定时重推的方式解决，推送内容为：库存组织编码、地台板、大箱、彩箱条码、以及扫码人、扫码时间等。
3. 而其接口日志中有订单编码、推送状态、请求体、响应体等字段。
4. 重复推送怎么办？MES 会根据地台板条码处理好的，比如处理过就不再处理了，因为一个地台板条码是全系统唯一的。

#### 9.1.1.3. 进销存库存结构？

1.  只有OEM代工库存是真实的，其他都是虚报的。
2. 而其他库存，在页面上的还有：生产库、成本库、成品库、不良品库、退货库、调拨入库等。
3. 相应的场景有：生产订单入库、成本中心入库、采购订单入库、退货入库、生产订单领料出库、成本中心出库、销售订单出库、复检出库、不良品出库、盘点差异、调拨出库等。

#### 9.1.1.4. 多租户怎么实现？

1. 供应商才是租户，美的是客户，也可以同时作为租户，美的用同一个账号登录，需要有角色区分，比如字段、租户客户映射表等。
2.  现阶段是用表字段来标识客户和租户，数据量大了的话，可以再做分库分表。

#### 9.1.1.5. 怎么解决分片上传包多余，导致网络利用浪费的问题？

1. 文件切割前，可以先去查一个缓存接口，拿到当前 MD5 最大的 chunk 分片号，存在了就不再切分上传了。
2. 也可以之前从索引位置处进行切分（比如 RandomAccessFile），再上传。

#### 9.1.1.6. 算法题 - leetcode 21. 合并有序链表？

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode mergeTwoLists(ListNode list1, ListNode list2) {
        if(list1 == null) {
            return list2;
        }
        if(list2 == null) {
            return list1;
        }

        ListNode head = new ListNode(), pre = head;
        while(list1 != null && list2 != null) {
            if(list1.val < list2.val) {
                pre.next = list1;
                list1 = list1.next;
                pre = pre.next;
            } else {
                pre.next = list2;
                list2 = list2.next;
                pre = pre.next;
            }
        }
        pre.next = list1 != null? list1 : list2;

        return head.next;
    }
}
```

#### 10.1.1.1. 自我介绍与项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 10.1.1.2. 线程池调优？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 线程池调优。

#### 10.1.1.3. MySQL 主从复制？

##### 1、总

MySQL 主从复制，其原理就是，把主节点的 bin log 日志，复制到从节点上执行一遍，从而达到主从数据一致的状态。

##### 2、分

###### 1）主从复制过程

![1631410904850](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631410904850.png)

1. 主节点的 bin log 线程，会在每个事务提交前，把操作记录刷入到 bin log 二进制日志文件中。
2. 如果从节点开启了主从同步后 `start slave`，则从节点的 I/O 线程，会负责从主节点上拉取其 bin log 内容，然后放在自己的 relay log 中继日志中。其中，如果从节点的读取进度已经跟上了主节点，则会进入睡眠状态，并等待主节点产生新的事件。
3. 同时，从节点还会另外开启一个 SQL 线程，把 relay log 中的语句，在从节点自身的机器上执行一遍，从而达到主从数据一致的状态。

###### 2）bin log 日志格式

bin log，binary log，是 MySQL 的二进制日志，也称归档日志，记录了 MySQL 数据库执行了更改的所有操作，包括 DDL `CREATE、ALTER、DROP TABLE` 、DML `INSERT、UPDATE、DELETE`，但不包括 DQL `SELECT、SHOW` 这类操作。

1. **statement**：基于 SQL 语句的复制模式，记录的是 SQL 本身的语句。

   - **优点**：无需记录每一行的数据，减少了 bin log 日志的大小，节省了主从复制时的 I/O，提高了性能。
   - **缺点**：
     - 1）主从环境不一致时，采用这种格式的 bin log 做主从复制，可能会发生数据不一致。
     - 2）主库中的慢 SQL，会在从库中也重新执行一遍，此时效率会比较低。

   ```sql
   -- 执行的DML
   delete from t where a>=4 and u_time<='2021-11-15' limit 1
   -- statement格式的bin log
   ues `test`;delete from t where a>=4 and u_time<='2021-11-15' limit 1
   ```

2. **row**：基于行的复制模式，记录的不是原 SQL 语句，而是替换成了对应的事件。

   - **优点**：
     - 1）由于记录的是数据行，主库是什么数据，从库就是什么数据，不会出现主从复制错误的情况，更能保证主从复制的一致性。
     - 2）同时，基于数据行的复制，即使遇到主库的慢 SQL，也不会在从库重新执行一次，此时效率较高。
   - **缺点**：所有修改过的数据都会被记录，会产生大量重复的日志内容，导致主从复制延迟变大。

   ```sql
   -- 执行的DML
   delete from t where a>=4 and u_time<='2021-11-15' limit 1
   -- row格式的bin log
   Table_map    |   table_id: 226(test.t)
   Delete_rows  |   table_id: 226 flags: STMT_END_F
   ```

3. **mixed**：基于 statement 和 row 的混合复制模式，一般语句的修改会使用 statement 格式来保存，但对于一些无法正确完成主从复制的函数，则采用 row 格式保存。

   - **优点**：日志文件比较小，数据准确性也较高。
   - **缺点**：还是有可能存在主从不一致的情况，且也存在从库重复执行慢 SQL 的情况。

=> MySQL 老版本（ 5.7.7 之前）默认使用的是 statement，而在 5.7.7 及更高版本中，默认值则是 row，而相比于准确性而言，性能优先级则可以更低一些，因为随着技术的发展，硬件性能将不再会是不可接受的瓶颈，所以推荐使用 row 格式。

###### 3）主从复制模式

1. **异步复制**：Asynchronous replication，MySQL 默认的复制模式，指在主节点执行完客户端事务提交后，会立即将结果返回给客户端，无需关心从库是否已经接收和处理。
   - **缺点**：主节点如果期间宕机了，已经提交的事务可能没有传到从节点上，如果此时强行将从节点提升为新的主节点，就可能导致主从数据不一致性。
2. **全同步复制**：Fully synchronous replication，指在主节点执行完客户端事务提交后，需要等待所有的从节点接收到并成功写入到 relay log 中，才返回给客户端。
   - **缺点**：由于需要等待全部的从节点接受和处理，所以性能将会受到严重的影响。
3. **半同步复制**：Semisynchronous replication，介于异步复制和全同步复制之间，指在主节点执行完客户端事务提交后，只需至少等待一个从节点接收到并成功写入到 relay log 后，就可以返回给客户端了。
   - **优点**：相对于异步复制，半同步复制提高了数据的一致性，相比全同步复制又很好地提高了性能。
   - **缺点**：但同时也会造成一定地程度地延迟，这个延迟至少是一个 TCP/IP 地往返时间，最好在低延迟网络中使用，否则会有可能退化为异步复制。

##### 3、总

主从数据一致性的原因有：

1. 人为地在从库写入，导致从库与主库的数据不一致。
   - **解决方案**：设置从库为只读模式。
2. bin log 使用了statement 格式 ，某些特定函数在复制过程中出现了问题，导致数据的不一致。
   - **解决方案**：使用 row 或者 mixed 的 bin log 格式。
3. 主从复制过程中，主库异常宕机了，数据还没及时同步到从库，主从切换导致的数据不一致。
   - **解决方案**：使用全同步复制，或者 MySQL 5.7 的半同步复制。
4. 主从复制有延时，在延时期间，应用程序读取了从库，读到了与主库不一致的数据。
   - **解决方案**：
     - 1）在缓存中记录哪些行发生过写的操作，来路由到底读主库，还是读从库，在新写入时先在主库中读。
     - 2）引入定期的主从数据校验，保证数据一致性。

#### 10.1.1.4. MySQL 覆盖索引原理？

见《[5.1.2.3. MySQL 主键索引、二级索引、联合索引查找数据的原理？](#5.1.2.3. MySQL 主键索引、二级索引、联合索引查找数据的原理？)》。

#### 10.1.1.5. MySQL  要查看索引具体的使用情况，怎么看？

答了Explain并解释了字段，应该是OPTIMIZER_TRACE

#### 10.1.1.6. Redis ZSet 底层实现原理？

见《[1.2.1.5. Redis 数据结构？](#1.2.1.5. Redis 数据结构？)》。

#### 10.1.1.7. 影响布隆过滤器的准确因子有哪些？

##### 1、总

Bloom filter，布隆过滤器，基础数据结构是一个 bitmap 位图，可以用来判断集合中一个元素一定不存在，或者可能存在。

##### 2、分

1. **优点**：运行快速、内存占用小。

2. **缺点**：

   - 1）对于元素的存在结果有误判，并且随着系统的不断运行，误判率会越来越高。
     - **解决方案**：定期重建布隆过滤器。
   - 2）元素一旦存进布隆过滤器中，删除则十分困难，因为可能会删掉其他元素的 bit 结果。
     - **解决方案**：使用额外的删除标记变量，进行逻辑删除。

3. **实现原理**：

   ![1632042655580](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632042655580.png)

   - 1）当一个元素被加入集合时，通过 K 个散列函数，把该元素映射成位图中的 K 个点，同时把这些点都置为 1。
   - 2）在检索时，只要看看这些点是不是都为 1，就可以知道该元素是否在集合中。
   - 3）如果这些点有任意一个为 0，则认为该元素一定不在。
   - 4）如果这些点都为 1，则该元素很可能存在，因为散列函数可能存在哈希冲突，所以布隆过滤器才会对结果有误判。

4. **使用方式**：

   | 实现方式      | 存储位置 | 优点                                   | 缺点                                                         |
   | ------------- | -------- | -------------------------------------- | ------------------------------------------------------------ |
   | Guava 实现    | JVM      | 可以减轻 Redis 内存与 I/O 的压力       | 应用有状态，水平复制麻烦，布隆过滤器重启即失效，也不支持大数据量的存储；本地缓存无分布式一致性可言，所以无法应用于分布式场景 |
   | Redisson 实现 | Redis    | 支持分布式场景、可以继续保持无状态应用 | 大量的布隆过滤器查询请求，会增加 Redis 的 I/O 压力，同时布隆过滤器也占用一定的 Redis 内存 |

5. **使用场景**：主要应用于大规模数据下，不需要精确过滤的场景，比如检查垃圾邮件地址、爬虫URL地址去重，以及开放转载权限（白名单）、视频不重复推送（黑名单）等解决缓存穿透的问题。

   - 1）开放转载权限（白名单）：

     ![1632043975276](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632043975276.png)

   - 视频不重复推送（黑名单）：

     ![1632044944582](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632044944582.png)

##### 3、总

因此，影响布隆过滤器的准确性的因素有：hash 函数的离散型、hash 函数的个数、bitmap 的容量、以及运行的时间长短等。

#### 10.1.1.8. 项目上用到的Redis高可用架构？

见《[3.2.2.1. Redis 哨兵模式和集群模式的区别？](#3.2.2.1. Redis 哨兵模式和集群模式的区别？)》。

#### 10.1.1.9. 数据库缓存双写一致性？

##### 1、总

1. 首先，从理论上来讲，给缓存设置**过期时间**，所有写操作以数据库的为准，对缓存操作只尽最大努力更新的话，如果数据库写成功，缓存更新失败，只要缓存到达了过期时间，那么后面的读请求自然会从数据库中，读取到新值，然后回填到缓存，是可以实现**最终一致性**的。
2. 而如果要给出不依赖过期时间方案的话，可以从更新/删除缓存的角度去思考，它们的大前提是，先读缓存，如果缓存没有，才从数据库读取：
   1. 先更新缓存，再更新数据库。（不可取，数据丢失）
   2. 先更新数据库，再更新缓存。（不可取，后者脏数据覆盖）
   3. 先删除缓存，再更新数据库。（不可取，延迟双删、异步双删依然不能保证一致性）
   4. 先更新数据库，再删除缓存。（可取，Cannal + MQ 实现业务解耦、以及最终一致性）

##### 2、分

###### 1）先更新缓存，再更新数据库 | 数据丢失

1. 这个方案会出现，同一个缓存被频繁写入，但还没来得及更新到数据库，造成数据丢失的问题。
2. 故，放弃。

###### 2）先更新数据库，再更新缓存 | 后者脏数据覆盖

1. 这个方案，也是有问题的，如果有请求 A 和请求 B 并发进行更新操作，那么就会出现：
   - （1）线程 A 更新了数据库。
   - （2）线程 B 更新了数据库。
   - （3）线程 B 更新了缓存。
   - （4）线程 A 更新了缓存。
2. 理论上，请求 A 更新缓存，应该比请求 B 更新缓存早才对，但是由于网络等原因，B 却比 A 更早更新了缓存，导致 A 最后才把脏数据刷到缓存中，造成数据不一致。
3. 故，放弃。

显然，删除缓存才是更好的选择。

###### 3）先删除缓存，再更新数据库 | 延迟双删、异步双删依然不能保证一致性

1. 这个方案，也还是有问题的，如果在请求 A 更新时，请求 B 并发查，会出现：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询，发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值填入缓存。
   - （4）请求 A 将新值写入数据库。
2. 上述情况就会导致不一致的情形出现，如果不给缓存设置过期时间，则该数据永远都是脏数据。
3. 此时，解决方案可以采用**延时双删**策略：
   - （1）先淘汰缓存。
   - （2）再写数据库（这两步和原来一样） 。
   - （3）关键来了，再**休眠** n 秒，然后淘汰缓存，这么做，可以把 n 秒内，所产生的缓存脏数据，再次删除掉。
4. 但是，这个 n 秒怎么确定，可以在写数据后，休眠的时间在读数据业务逻辑的耗时基础上，加几百 ms 即可，这么做的目的，就是确保读请求结束后，写请求可以删除读请求造成的缓存脏数据。
5. 然而，如果 MySQL 读写分离架构下，还是会出现不一致的情况：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 A 将数据写入数据库了。
   - （3）请求 B 查询缓存，发现缓存没有值，然后去从库查询，但是此时，还没有完成主从同步，因此，查询到的还是旧值。
   - （4）请求 B 将旧值写入缓存。
   - （5）数据库完成主从同步，从库变为新值 。
6. 上述情况也产生了数据不一致的现象，解决方法还是使用**延时双删**策略，只不过，休眠时间 n，需要在主从同步的延时时间基础上，加几百 ms，而不是读耗时加几百 ms。
7. 但是，采用这种同步淘汰策略，由于设计到阻塞休眠 n s，接口吞吐量将会降低很多，此时可以把第二次休眠后删除的步骤，改为**异步**的操作，即起一个线程做异步删除。这样，写请求就不用沉睡一段时间后才返回响应。
8. 如果采用**异步双删**，虽然保证了吞吐量，但第二次可能会**删除失败**，比如：
   - 为了方便，假设是单库。
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值写入缓存。
   - （4）请求 A 将新值写入数据库。
   - （5）请求 A 试图去删除，但由于某种原因失败了，导致缓存中一直存在 B 放入的旧值。
9. 这种情况下，如果第二次删除缓存失败，还是会出现后面缓存和数据库不一致的现象。
10. 所以，更新数据库前的缓存删除，起不到任何作用，一致性是由第二次缓存删除来保证的。
11. 故，放弃更新前缓存删除方案。

###### 4）先更新数据库，再删除缓存

1. 这种情况，也还是会存在并发问题：
   - （1）缓存刚好失效。
   - （2）请求 A 查询数据库，得一个旧值。
   - （3）请求 B 将新值写入数据库。
   - （4）请求 B 删除缓存。
   - （5）请求 A 将查到的旧值写入缓存。 
2. 上述情况，确实还是有脏数据，解决方案有：
   1. **过期时间**：给缓存设有效时间是一种方案。
   2. **异步删除**：采用上面的异步删除策略，保证读请求完成以后，再进行删除操作也可以，但同样，也存在缓存删除失败导致数据不一致的情况，此时可以提供一个**重试删除**机制即可解决。

##### 3、总

1. 因此，要保证数据库、缓存双写一致性的关键在于，**先更新数据库 + 再删除缓存 + 异步重试删除**，实现方案如下：

2. **方案一**：

   - （1）更新数据库后，再删除缓存。
   - （2）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （3）然后消费消息，获取到要删除的 key。
   - （5）接着根据 key 继续重试删除操作，直到成功。

   **缺点**：对业务线代码，造成了大量的侵入。

   ![1647257594150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257594150.png)

3. **方案二**： 启动一个订阅程序，去订阅数据库的 **binlog**，获得需要操作的数据，然后另起一个程序，获得这个订阅程序传来的数据，进行删除缓存操作。

   - （1）更新数据库数据。
   - （2）数据库则会把更新操作的信息，写入 binlog 日志当中。
   - （3）binlog 日志被订阅程序订阅到，则提取出所需要的数据以及 key。
     - 这个订阅 binlog 程序，在 MySQL 有现成的中间件（阿里# Canal），至于 Oracle 目前好像还没有现成的中间件。
   - （4）调用另一段非业务代码，获得 key。
   - （5）根据这个 key，尝试执行缓存删除操作。
   - （6）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （7）然后消费消息，获取到要删除的 key。
   - （8）接着根据 key 继续重试删除操作，直到成功。

   ![1647257612877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257612877.png)

=> 以上，就是我对数据库、缓存双写一致性的一些实现方案的理解，请问有什么细节需要补充的吗？

#### 10.1.2.0. 内存溢出？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》- 内存溢出排查。

#### 10.1.2.1. 关注响应时间，用什么垃圾收集器？

1. **关注响应时间**：选 ParNew + CMS、G1。
   - **原因**：多线程垃圾回收，收集效率高，STW 周期短，系统响应快。
2. **关注吞吐量**：选 Parallel Scavenge + Parallel Old。
   - **原因**：CPU 实际工作时长和垃圾回收时长可控，也就是吞吐量可控。
3. **其他细节**：见《[4.1.1.8. 项目中的垃圾收集器用了哪些？](#4.1.1.8. 项目中的垃圾收集器用了哪些？)》。

#### 10.1.2.2. 静态分派和动态分派？

1. **静态分派**，是指编译期间就知道了方法的具体实现类，比如 static 方法、方法的重载等等。
   - 1）JVM 会在【链接】的【解析】阶段，就把 class 的符号引用转换为了直接引用。
2. **动态分派**，是指编译期间还未知道实现类，是在运行时才确定的，比如方法重写、接口实现等等。
   - 1）JVM 会在【链接】（验证、准备、解析）阶段对各父类、子类的虚方法表进行初始化。
   - 2）如果子类没重写父类的方法，那么子类的虚方法表存放的就是父类方法的入口地址。
   - 3）如果子类重写了父类的方法，那么子类的虚方法表存放的则是子实现类的入口地址。
   - 4）在运行时，则根据实际类型，去查找虚方法表，得到对应的入口地址，从而实现多态。

#### 10.1.2.3. static 语句里的变量不能多态？

经过测试，静态方法不会被子类重写，非静态非Final方法才可以被子类重写。

#### 10.1.2.4. HashMap 的寻址方式有哪些？

Java#HashMap 的寻址方案：

1. key -> hashCode -> hashCode ^ hashCode >>> 16 = hash 值 -> hash 值取模 -> hash 索引 -> 查找桶头 -> 查找链表 / 红黑树 -> key1 == key2 || key1.equals(key2) -> Map.Entry 节点。 

理论层面的哈希表的寻址方案有：

1. 没冲突时，取模寻址。
2. 发生冲突时有，链地址法（拉链）、线性探测法（step=1）、二次线程探测法（step=n^2）、再哈希法（再哈希一次第一次的哈希结果）

#### 10.1.2.5. 算法题 - leetcode 53. 连续子数组的最大和？

```java
// 1、动态规划：时间100%，空间78%
class Solution {
    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        if(nums.length == 1) {
            return nums[0];
        }

        int max = nums[0], pre = nums[0];
        for(int i = 1; i < nums.length; i++) {
            pre = Math.max(nums[i] + pre, nums[i]);
            max = Math.max(max, pre);
        }

        return max;
    }
}

// 2、贪心优化：时间100%，空间96.50%
class Solution {
    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        if(nums.length == 1) {
            return nums[0];
        }

        int max = nums[0], pre = nums[0];
        for(int i = 1; i < nums.length; i++) {
            if(pre < 0) {
                pre = nums[i];
            } else {
                pre = pre + nums[i];
            }
            
            max = Math.max(max, pre);
        }

        return max;
    }
}
```

#### 10.2.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 10.2.1.2. 项目亮点？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 10.2.1.3. 为什么不用数仓来解决画像的统计工作？

1. 数据仓库，简称数仓，它集合了各业务系统的数据，比如金融业中的贷款业务、CRM、存款业务等维度的数据，适用于企业做数据分析、出报告、做决策，在有些公司也会作为各业务系统的数据来源。

2. 从逻辑上理解，数据库和数仓没有区别，都是通过数据库软件实现存放数据的地方，只不过从数据量来说，数据仓库要比数据库更庞大。

3. 它们之间最主要的区别在于，传统事务型数据库，比如 MySQL 用于做 OLTP 联机事务处理，例如交易事件的发生等，而数据仓库主要用于 OLAP 联机分析处理，例如出报表等。

4. **如果是简单的系统，比如初创时期，业务量少，用户和数据少**，几台服务器和几个MySQL组成的系统，就可以实现了，没必要上数仓。

5. 但当业务越做越多，用户和数据量很庞大，出报表需要跨集群关联多个系统的数据实现的话，那数仓还是很有必要的。

6. 数仓的出现，比如 Hive，可以很好的解决聚合、规范、版本控制、大数据查询时的性能保证这些问题，它通过数据抽取、数据转换、数据加载（ETL），将各个业务系统的数据整合落地到数仓中，规范化数据，方便在出报表做决策的时候获取数据。

7. 什么是 ETL？

   - 1）E：Extract，数据抽取，指把数据从数据源读取出来。
   - 2）T：Transform，数据转换，指数据的类型转换与脏数据清洗。
   - 3）L：Load，数据加载，指把处理后的数据加载到目标处，比如数据仓库中。

   ![1652622393263](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652622393263.png)

#### 10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？

1. **消息丢失**：生产者可靠性投递（业务表+消息表+失败重头+acks=-1/all）、broker 端（ISR 机制）、消费端手工 ACK + 重复消费失败消息。
2. **消息重复消费**：消费端幂等性消费（手工 ACK、全局唯一 ID 判断）。
3. **消息消费慢**：检查消费慢的原因，程序慢则优化程序，量大则增加分区、增加 Consumer、多线程消费、或者走临时存储方案。
4. **顺序消费**：单 partition + 单 Consumer、单 partition + 单 Consumer + 线程同步、单 partition + 多 Consumer + 进程同步、多 partition + 多 Consumer 一致性哈希。

#### 10.2.1.5. 如何通过学习，保证高并发以及新业务？

##### 1、总

1. 我不觉得一定要有高并发实际项目经验，才能做高并发，做好了其他准备，没有该经验的人上手也能做的很好。
2. 因为高并发本身并不是什么很深不可测的东西，一切的解决方案都来自于实际的业务场景，与其天天想着怎么获得高并发经验，不如去钻研底层知识，比如算法、缓存、多线程、并发、JVM、操作系统、网络、体系结构等。

##### 2、分

高并发解决方案关键点在于：

1. **数据库**：索引、SQL 调优、读写分离、分库分表。

2. **代码优化**：

   - 1）**高效算法**：当比例尺拉到足够大时，O（logn）几乎等于一条水平线，媲美于 O（1）。

     ![1652712213801](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652712213801.png)

   - 2）**池化**：内存持、线程池、连接池。
   - 3）**多线程**：并发编程。
   - 4）**无锁化编程**：CAS、volatile。
   - 5）**同步改异步**：异步处理。
   - 6）**批处理**：合并频繁的小请求。
   - 7）**零拷贝**：减少用户态与内核态的数据复制，比如 `mmap` 共享 kernel buffer 与 user buffer，以及`sendfile` linux 2.4 kernel buffer 直接拷贝到协议引擎，其 socket buffer 只存放带有数据位置和长度的文件描述符。
   - 8）**预处理和延后处理**：预处理（热点数据提前载入缓存）、延后处理（最终一致性、写时复制）。

3. **JVM**：GC 并不直接影响，而是可能会影响到系统的吞吐量，以及访问延时，间接影响了并发能力，比如垃圾回收器选型、内存大小配置等，不过近年来 java 和 go 的默认GC设置，已经很难成为系统的瓶颈了。

4. **缓存**：

   - **缓存分类**：本地缓存、分布式缓存。
   - **适用场景**：热点数据、读多写少。
   - **缓存更新策略**：Cache-Aside、Cache-As-SoR（Read Through、Write Through、Write Back）。

5. **消息队列**：系统解耦、异步处理、削峰填谷。

6. **高可用保证**：CAP 理论、BASE 理论、限流、熔断。

7. **其他**：高性能网关、CDN 静态资源加速、客户端请求优化。

##### 3、总

1. 一个后端程序员，最重要的技能是分布式系统设计，因为这是经验和知识的结合，而编程语言则是不重要的。
2. 综上，可以通过学习获取基础知识，解决不同的问题，不断收获经验，日复一日，逐渐成为高并发的大牛。

#### 11.1.1.1. 自我介绍

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.1.1.2. Kafka 分片广播式定时实现？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.1.1.3. 为什么用缓存型线程池？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.1.1.4. 线程数设置原则？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.1.1.5. 消息队列的作用？

系统解耦、异步处理、削峰填谷、蓄流压测。

#### 11.1.1.6. Kafka 和 RabbitMQ 的区别？

1. 语言上，RabbitMQ 使用 Erlang 语言实现，是 AMQP 协议的一种实现，Kafka 使用 Scala 语言实现，自行设计了一套基于 TCP 的二进制协议。 
2. 特性上，RabbitMQ 多交换机更灵活，基于 Erlang 交换机语言实现，延迟更短，Kafka 基于分区日志实现，并且做了很多优化，吞吐量更高。 
3. 高可用上，Rabbit 常用的是镜像模式，只有 Master 对外提供服务，Slave 只负责镜像备份，所以无限地横向扩容没有意义，Kafka 分区多副本的方式存储，分区相当于数据分片，使得横向扩容有意义，副本备份机制，使得支持高可用。
4. 持久化上，RabbitMQ 消息消费后会被删除，Kafka 消息是以日志的形式存储，根据偏移量消费，消费完后不会被立即删除。
5. 消息消费上，
   - 1）RabbitMQ 使用的是 push 模式，
     1. 优点是：Broker 主动做消息推送，实时性好，适合实时性要求高的场景。
     2. 缺点是：Broker 端需要维护消息的传输状态，以便在消息传递失败时，进行重试，以及 Consumer 端需要结合一个流控预取的策略，防止单个 Consumer 负担过重。
   - 2）Kafka 使用的是 pull 模式，
     1. 优点是：Consumer 根据消费偏移量，去 Broker 上批量拉取消息，支持更高的吞吐量，适合消费端消费能力不足的场景。
     2. 缺点是：Broker 端需要维护好每个消费偏移量，以便在 Consumer 重连后，还能支持继续拉取，以及 Consumer 端消息拉取的时间间隔难以控制，太短则会给 Broker 造成压力，太长则实时性又不好，解决方案则可以参考腾讯的 CXQ 长轮询的方式，能够缓解实时性的问题。
   - 3）RocketMQ 支持 push 和 pull 模式，但无论是那种模式，实现上都是 Consumer 到 Broker 进行拉取消息，
     1. push 模式：需要 Consumer 以长轮询的方式，不断地检查 Broker 有没有消息可拉取，优点跟上面一样，实时性好，适合实时性要求高的场景。
     2. 而 pull 模式：则是 Consumer 自己根据需要进行主动拉取，优点也是支持批量拉取消息，支持更高吞吐量。

#### 11.1.1.7. Kafka acks 的取值？

1. acks=0：Producer 不会等待任何 ACK 确认，发送成功会直接标记为消息已发送，不会等待 Leader Broker 和其他 Follower 的消息落盘成功。
2. acks=1：Producer 只需要等待 Leader broker 消息落盘成功返回的 ACK 确认，就可以把消息标记为已发送，不会等待其他 Follower 的消息落盘成功。
3. acks=-1/all：Producer 需要等待 Leader broker，以及 ISR 内的所有 Follower 的消息落盘成功返回的 ACK 确认，才把消息标记为已发送。

=> 前两种都无法保证消息不丢失，第三种则是最高的可用性保证，只要至少存在一个副本保持活动的状态，那消息就不会在这环节上丢失。

#### 11.1.1.8. 如果 Producer 需要等待的 ACK 数量，大于 Broker 的实际数量，会发生什么？

由于 `min.insync.replicas` 设定了 ISR 集合的最少数量，如果不满足，那么生产者将会引发 `NotEnoughReplicas` 或者 `NotEnoughReplicasAfterAppend` 异常。

#### 11.1.1.9. Spring 的核心思想？

##### 1、总

两个核心思想，IOC 和 AOP：

1. IOC，控制反转，指把⼿动创建对象的控制权，交由专门的容器来进行管理，比如 Spring 的 IOC 容器，可以降低对象替换的复杂性，减少组件之间的耦合度。Spring 的 IOC 容器的实现原理为：
   - 1）先准备一个基本的容器对象，包含一些 map 结构的集合，用来方便后续过程中存储具体的对象。
   - 2）然后，进行配置文件的读取工作，或者注解的解析工作，将需要创建的 bean 对象，都封装成 BeanDefinition 对象存储在容器中。
   - 3）容器将封装好了的 BeanDefinition 对象，通过反射的方式进行实例化，完成对象的实例化工作。
   - 4）进行对象属性的依赖注入工作，完成整个对象的创建，成为一个 bean 对象，存储在容器的 map 结构中。
   - 5）通过容器来获取对象，进行对象的获取和逻辑处理工作。
   - 6）同时，还提供了 Bean 的销毁操作，当对象不用，或者容器关闭时，将无用的对象进行销毁。
2. AOP，⾯向切⾯编程，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑封装起来，比如事务管理、⽇志管理、权限控制等，以便于减少系统的重复代码，降低模块间的耦合度，利于未来的可拓展性和可维护性。
   - 比如，日志管理的公共代码，可以抽象出一个**切面**，然后匹配**切点**，通过**动态代理**，将对**目标对象**（具体的业务对象）进行增强，也就是**织入**，在进行调用时，代理对象会根据**通知**类型，在对应的**连接点**，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

##### 2、分

![1645341206075](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645341206075.png)

另外，对于 Spring 来说，最重要最核心的莫过于 `AbstractApplicationContext#refresh()` 方法了，该方法分为 12 大步骤，体现了 Spring IOC 的具体实现原理：

1. `prepareRefresh()`：刷新前的预处理，比如激活标记位 active 和记录时间戳等。
2. `obtainRerefshBeanFactory()` ：获取 DefaultListableBeanFactory。
3. `prepareBeanFactory()`：做一些 BeanFactory 的准备工作，比如设置 BeanClassLoader 等。
4. `postProcessBeanFactory()`：调用 BeanFactory 子类的回调，比如给子类做扩展等。
5. `invokeBeanFactoryPostProcessors()`：BeanFactory 的后置处理器，以添加更多的 BeanDefinitions，比如 `ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry()`，它会去扫描@Configuration 下的 @PropertySource、@ComponentScan、@Import、@ImportResource 和 @Bean，然后加载成为 BeanDefinitions。
6. `registerBeanPostProcessors()`：实例化并注册 Bean 的初始化后置处理器。
7. `initMessageSource()`：实例化并注册 MessageSource 组件，用于做国际化多语言功能。
8. `initApplicationEventMulticaster()`：实例化并注册 ApplicationEvent 广播器，用于观察者模式。
9. `onRefresh()`：会回调到子类`ApplicationContext#onRefresh()` ，比如 SpringBoot 拉起 Tomcat 容器。
10. `registeListeners()`：注册监听器。
11. `finishBeanFactoryInitialization()`：实例化、属性赋值、初始化所有剩余的单例 Bean，以及在 Bean初始化前后，调用 `BeanPostProccessers#applyBeanPostProcessorsBefore/AfterInitialization()`。
    - 1）AOP 的实现原理，则正式在步骤中实现的，也就是说 AOP 实际只是在 IOC 整个流程中，新增的一个 BeanPostProcessor 扩展点而已。
    - 2）该扩展点叫做 `AbstractAutoProxyCreator`，它实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
    - 3）如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
    - 4）⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 ASM 框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。
12. `finishRefresh()`：完成最后的容器刷新工作，主要是调用 `LifecycleProcessors#onRefresh()`。

##### 3、总

=> 以上，就是我对 Spring 核心思想 的一些理解，请问有什么细节需要补充的吗？

#### 11.1.2.0. Spring 对于循环依赖是如何解决的？

##### 1、总

1. 循环依赖，指的是 Bean 之间的循环引用，也就是两个或者两个以上的 Bean，互相持有对方的引用，最终形成了依赖闭环，导致无法顺利启动应用，比如 A 依赖于B，B又依赖于A。
2. Spring 中的循环依赖场景，分为构造器注入和属性注入的循环依赖，解决循环依赖的手段也有 @Lazy 懒加载以及三级缓存，其中构造器注入的循环依赖是无法用三级缓存来解决的，此时则可以用 @Lazy 懒加载的方式，来解决这种三级缓存解决不了的循环依赖问题。

##### 2、分

###### 1）@Lazy 懒加载，解决循环依赖原理

1. 带有 @Lazy 标记属性的 Bean，Spring 启动 `doCreateBean()` 方法实例化 Bean 的过程中，在解决循环依赖 `DefaultListableBeanFactory#doResolveDependency()` 之前，会先调用到 `ContextAnnotationAutowireCandidateResolver#getLazyResolutionProxyIfNecessary()` 进行获取 @Lazy 的动态代理。
2. 该方法会先解析出 Bean 上的 @Lazy 注解，然后传入 `ContextAnnotationAutowireCandidateResolver#buildLazyResolutionProxy()` 方法生成虚假的代理对象。
3. 然后返回该对象，先不走原本解决循环依赖的 `DefaultListableBeanFactory#doResolveDependency()` 方法中。
4. 直到在这个 @Lazy 属性上的虚假代理对象被调用时，才会进入到它的 `TargetSource#getTarget()` 方法中，此时才会真正的去调用 `DefaultListableBeanFactory#doResolveDependency()` 方法，去解决循环依赖问题。
5. 而由于此时其依赖的 Bean 早就被初始化完毕了，可以轻松完成属性注入，从而完成循环依赖问题。

###### 2）三级缓存，解决循环依赖原理

![1645350673009](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645350673009.png)

Class A 依赖（这里是 @Autowire） Class B，Class B 又依赖（这里是 @Autowire） Class A，造成循环依赖，Spring 的解决方式是三级缓存，三级缓存其实就是三个 Map 集合，

1. **三级缓存**：叫做 `Map<String, ObjectFactory<?>> singletonFactories` 的集合，存放的是 BeanName-ObjecFactory 的键值对，ObjectFactory 是一个 `@FunctionalInterface` 接口，本质是在调用 `getEarlyBeanReference()` 方法，该方法可以获取 AOP 代理的空壳引用，即要么返回原对象，要么返回代理对象。在根据 BeanName 获取 Bean 时，如果一二级缓存都找不到，则会从这里获取。
2. **二级缓存**：叫做 `Map<String, Object> earlySingtonObjects` ，存放的是 BeanName-早期空壳的 Bean 对象的键值对，这种空壳的 Bean 对象，是通过调用三级缓存的 `getEarlyBeanReference()` 方法获得，用来解决为属性**注入动态代理对象**的循环依赖问题。在这层缓存存放完后，会删除以前的三级缓存，在根据 BeanName 获取 Bean 时，如果一级缓存找不到，则会从这里获取。 
3. **三级缓存**：叫做 `Map<String，Object> singletonObjects`，存放的是 BeanName-单例且属性已经填充完毕的 Bean 对象，在这层缓存存放完后，会删除以前的二三级缓存，根据 BeanName 获取 Bean 时，优先从这里获取。 

其**具体原理**为：

1. Class A 首先被实例化（一个空壳），实例化后立马放入三级缓存中。
2. 然后在 populateBean 填充 Class A 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class B name 调用 doGetBean 方法，获取 Class B 的实例。
3. 然后在 Class B 也被实例化（一个空壳），实例化后也立马放入三级缓存中。
4. 然后在 populateBean 填充 Class B 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class A name 调用 doGetBean 方法，获取 Class A 的实例。
5. 由于此时 A 已经在三级缓存中，所以取出 A 的 ObjectFactory 表达式并执行，获取到 Class A 实例的引用。
   - 1）其中要注意的是，这个表达式调用的 `getEarlyBeanReference(beanName, mbd, bean)` 方法，可以获取 AOP 代理的空壳引用，即该方法要么返回的是原对象，要么返回的是代理对象。
   - 2）如果返回的是代理对象，那么该代理对象 B'/A' 不会持有另外一个 A/B 的引用，而是持有 B/A 原对象的引用。
   - 3）再由原对象去持有 A/B 的引用，而 A/B 则持有代理对象的引用 B'/A'。
6. 获取到 Class A 实例的引用，设置到二级缓存中，删除 A 三级缓存，并返回给 Class B 注入。
7. 此时 Class B 已经解决了循环依赖 A 的问题，最后设置单例 Class B 到一级缓存中，删除 B 二三级缓存。
8. 由于此时 B 已经在一级缓存中，所以取出 B 实例引用，返回给 Class A 注入。
9. 此时 Class A 也解决了循环依赖 B 的问题，最后设置单例 Class A 到一级缓存中，删除 A 二三级缓存。
10. 最后，Class A、Class B 分别完成注入，也就是解决了循环依赖的问题。

##### 3、总

=> 以上，就是我对 Spring 解决循环依赖 的一些理解，请问有什么细节需要补充的吗？

#### 11.1.2.1. 谈谈微服务拆分的原则？

1. **拆分原则**：单一职责、拆分力度要结合业务进行拆分、独立部署。
2. **拆分经验**：
   - 1）高频、高并发的服务优先拆出来。
   - 2）把非链路的业务拆分出去，保卫好主链路。
   - 3）按领域模型来拆，比如用户前台和商家后台等。

#### 11.1.2.2. 设计题 - 两个Enum循环引用，启动报错吗？如果解决？

##### 1）问题描述

```java
/**
 * 循环依赖测试
 */
public class CircularDependencyTest {

    public static void main(String[] args) {
        System.err.println(EnumB.b1);// b1
        System.err.println(EnumB.b1.getA());// a1
        System.err.println(EnumA.a1.getB());// null
        System.err.println(EnumA.a1);// a1

        // 1、可见, JDK编译时, 碰到这种循环依赖的问题, 依然能启动, 但A枚举在构造时, 注入的B实例是个null, 因为此时B还没实例化好，然后A实例化好之后, 把引入赋值给B枚举, 所以就有了B#a1不为空, 但A#b1为空

        // 解决方案一：手动调用set方法进行属性注入 => 解决！
        // 解决方案二：Common哈希表映射 => 解决！
    }
}

/**
 * 枚举类A
 */
public enum EnumA {
    a1(EnumB.b1),

    ;

    EnumA(EnumB b) {
        this.b = b;
    }

    private EnumB b;

    public EnumB getB() {
        return b;
    }
}

/**
 * 枚举类B
 */
public enum EnumB {
    b1(EnumA.a1),

    ;

    EnumB(EnumA a) {
        this.a = a;
    }

    private EnumA a;

    public EnumA getA() {
        return a;
    }

    public void setA(EnumA a) {
        this.a = a;
    }
}
```

##### 2）解决方案一 | 手动调用 set() 方法

```java
/**
 * 解决枚举类循环依赖问题: 解决方案一：手动调用set方法进行属性注入
 */
public class Solution1 {

    public static void main(String[] args) {
        Solution1 solution1 = new Solution1();
        solution1.init();

        System.err.println(EnumBs.b1);// b1
        System.err.println(EnumBs.b1.getA());// a1
        System.err.println(EnumAs.a1.getB());// b1
        System.err.println(EnumAs.a1);// a1

        // 解决方案一：手动调用set方法进行属性注入, 解决!
    }

    private void init() {
        EnumAs.a1.setB(EnumBs.b1);
        EnumBs.b1.setA(EnumAs.a1);
    }
}

/**
 * 枚举类A Solution1
 */
public enum EnumAs {
    a1(),

    ;

    private EnumBs b;

    public EnumBs getB() {
        return b;
    }

    public void setB(EnumBs b) {
        this.b = b;
    }
}

/**
 * 枚举类B Solution1
 */
public enum EnumBs {
    b1(),

    ;

    private EnumAs a;

    public EnumAs getA() {
        return a;
    }

    public void setA(EnumAs a) {
        this.a = a;
    }
}
```

##### 3）解决方案二 | Common 哈希表映射

```java
/**
 * 解决枚举类循环依赖问题: 解决方案二：Common 哈希表映射
 */
public class Solution {

    public static void main(String[] args) {
        System.err.println(EnumBs3.b1);// b1
        System.err.println(Common.bMap.get(EnumBs3.b1));// a1
        System.err.println(EnumAs3.a1);// b1
        System.err.println(Common.aMap.get(EnumAs3.a1));// a1
    }
}

/**
 * 常量公共类 Solution2
 */
public class Common {

    public static final Map<EnumAs3, EnumBs3> aMap = new HashMap<EnumAs3, EnumBs3>() {{
        put(EnumAs3.a1, EnumBs3.b1);
    }};

    public static final Map<EnumBs3, EnumAs3> bMap = new HashMap<EnumBs3, EnumAs3>(){{
        put(EnumBs3.b1, EnumAs3.a1);
    }};
}

/**
 * 枚举类A Solution2
 */
public enum EnumAs3 {
    a1(),;
}

/**
 * 枚举类B Solution2
 */
public enum EnumBs3 {
    b1(),;
}
```

#### 11.1.2.3. 设计题 - Redis A(s1,s2,...,时间)，其中s1 > s2 > ... > 时间，如果做大数据量排序？

1. 先计算 score，可以设置 s1 = 2^n分，s2 = 2^(n-1) 分，...，时间为 2^0 分，来进行计算。
2. 然后，使用 ZSET 的数据结构，根据得分进行顺序存储。
3. 获取时，用 ZRANK 或者 ZREVRANK，按照排名，从小到大或者从大到小方式，进行分页获取，时间复杂度O（logn）。

#### 11.2.1.1. 自我介绍

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.2.1.2. xxl-job 高可靠以及定时原理？

##### 1）竞品对比

1. elastic-job 是无中心化的，通过 ZK 选举机制选出主节点，主节点挂了则会重新选举，所以 elastic-job 具有良好的扩展性、高可用和一致性，面对高并发复杂的业务，即使是在业务量大，服务器多的时候也能做好任务调度，尽可能的利用服务器的资源，但使用和运维具有一定的复杂性。
2. xxl-job 则是通过一个中心式的调度平台，调度多个执行器执行任务，调度中心通过 DB 锁，来保证集群分布式调度的一致性，这样扩展执行器会增大 DB 的压力，但是如果实际上这里数据库只是负责任务的调度执行。如果没有大量的执行器的话和任务的情况，是不会造成数据库压力的。实际上大部分公司任务数，执行器并不多(虽然面试经常会问一些高并发的问题)。
3. 相对来说，xxl-job 中心式的调度平台轻量级，开箱即用，操作简易，上手快，与 SpringBoot 有非常好的集成，而且监控界面就集成在调度中心，界面又简洁，对于企业维护起来成本不高，还有失败的邮件告警等等。这就使很多企业选择 xxl-job 做调度平台。

##### 2）工作原理

![1652417852026](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652417852026.png)

1. 任务执行器根据配置的调度中心的地址，启动注册线程向调度中心的执行器管理发起自动注册。执行器管理中保存着注册执行器，后续会根据这个注册信息给执行器下发任务。
2. 如果此时有需要执行的任务，任务管理模块会根据执行器管理中注册的执行器信息，向任务执行器下发任务。任务执行器中的任务执行服务接受到任务以后会将任务发送到待执行任务的队列中，队列中的任务会由执行线程 JobHandler 依次获取并且执行。这里会维护一个任务执行的线程池，池中就是一个个 JobHandler 线程，它们是执行任务的主力军。
3. JobHandler 执行器基于线程池执行任务，并把执行结果放入执行结果队列中，同时会把执行日志写入任务日志文件中，以供日志查询。然后通知毁掉线程，告知任务执行完毕，回调线程会通知调度中心的监控运维模块，任务执行完毕。
4. 用户可以在调度中心查看任务日志，其过程是通过发送日志查询请求给任务执行器中的日志服务，然后查询任务日志文件实现的。

##### 3）执行器重复调度问题

1. **并发情况下**：通过mysql悲观锁实现分布式锁（for update语句）;
2. **任务阻塞或调度密集情况下**：结合 单机路由策略（如：第一台、一致性哈希） + 阻塞策略（如：单机串行、丢弃后续调度）来规避

##### 4）高可用原理

1. 调度中心集群 + HA + 负载均衡
2. 执行器集群 + 向调度中心注册 + 故障转移 + 路由策略

##### 5）Cron 表达式原理

1. cron 解释。
2. ScheduledThreadPoolExecutor：线程定时轮询 + 时间小根堆工作队列 + cron 时间匹配。

#### 11.2.1.3. 还有没有不用锁的方案？

可以参考 Kafka 消费者组的 Consumer Rebalance 的 `Join` 和 `Sync` + 日志分区分配方案 （RangeAssignor：默认，简单相除；RoundRobinAssignor：排序 + 轮训；StickyAssignor：粘性分配）。

#### 11.2.1.4. 那 RabbitMQ 的TTL队列原理？

1. **TTL 消息**：TTL，Time to Live，指消息或者队列的生存时间，即过期时间，超过过期时间后，消息仍未被消费，则会被 RabbitMQ 删除。
2. **TTL 队列**：RabbitMQ 支持 TTL 队列，从消息入队开始计算，只要超过了队列的超时时间配置，那么消息会自动被删除。
3. **延迟消息**：就是消息投递到 Broker 后，Broker 会经过根据设定的延迟时间后，才把消息真正的投递到目标的业务 Exchange 中。
   - 方案一，TTL 消息 + 单个等待队列 + 死信队列：设置消息 TTL ，然后把等待队列中已过期的死信，投递到目标的业务 Exchange 中，此时该 Exchange 扮演者 DLX 的角色。
   - 方案二，TTL 消息 + 多个等待队列 + 死信队列：类似于方案一，不过不同的是，需要创建多个等待队列，并在队列本身上设置 TTL，比如 1、5 和 15 分钟等，然后根据 TTL 投递消息到不同的等待队列中。
   - 方案三，NServiceBus：基于方案二的思路，使用级联 Topic，通过死信配置和 Topic 路由链接在一起。创建多个延迟级别，其中每个级别负责自己的固定 2 的幂次的延迟时间（28 个级别的延迟时间），
     比如级别 1 为 1 分钟，级别 2 为 2 分钟，级别 3 为 4 分钟，级别 4 为 8 分钟等。然后使用二进制样式的路由规则 与 RoutingKey ，在延迟队列之间移动消息（最多 27 次的路由交换），从而实现消息延迟投递。

另外，Kafka 不支持延迟消息。

#### 11.2.1.5. Kafka 生产端可靠性投递如何保证？

1. **生产端丢数据**：生产消息可以通过 Comfirm 机制解决，消息状态打标 + 消息落库 + ack=all + 定时重发
   （ retries + retry.backoff.msretries ） + 人工介入/失败补偿 。
2. **MQ 丢数据**：Broker 使用 ISR 副本机制保证高可用。
3. **消费端丢数据**：可以关闭自动提交offset功能 enable.auto.commit=false ，在消费完成后才提交
   offset。

#### 11.2.1.6. 消费端幂等性消费保证？

1.  **数据库主键去重**：消费这个消息做数据库的 insert 操作时，可以给这个消息做一个主键，那么就算出现
   重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
   - **局限**：并发时会导致大量的插入失败，浪费性能。
2.  **更新操作天然幂等**：消费这个消息做 Redis 的 set 操作时，无需做任何处理，因为无论 set 几次结果都
  是一样的。
  - **优点**： set 操作天然幂等，无需做任何处理。
3.  **全局唯一 ID**：如果以上两种情况都不适合，那么可以准备一个第三方介质，用来做消费记录，以 Redis 为
  例，给消息分配一个全局唯一 ID，只要消费过该消息，可以吧 ID-Message 以 K-V 形式写入 Redis，当消
  费者开始消费前，需要先去 Redis 中查询有没消费记录，如果没有则消费，否则放弃消费。
  - **局限**：**仅仅使用这种方案还是有可能重复消费的**，因为当线程并发查询消费记录时，可能会导致并发通过消费记录的校验，从而重复创建订单。
4.  **全局唯一ID + 数据库主键去重**：由于高并发解决方案是不能加锁的，而仅仅使用全局唯一 ID，或者数据库
  主键去重，都是有幂等性缺陷的，因此，最终的解决方案是使用 **全局唯一ID + 数据库主键去重** ，利用消
  费记录校验来挡住大部分请求，利用**数据库主键兜底**剩余通过校验的并发请求，从而保证幂等性消费。
  - **优点**：简单有效。

#### 11.2.1.7. 如果保证消息全局唯一，ID唯一不代表消息唯一？

1. 对于定时任务来说，触发过了就不会再触发了，不会出现上述情况，再次触发已经不是原来那次定时了。
2. 对于普通业务来说，比如订单创建，同一笔订单更不可能重复创建。

#### 11.2.1.8. 你们项目怎么做分库分表？

采购接收表，按年度+月度做分表

#### 11.2.1.9. 10 亿用户，怎么做分库分表？

32库(id%32) + 32表(id/32%32) + 500w数据 => 32 * 32 * 5000000 = 51亿

```java
// 重写sharding-jdbc的PreciseShardingAlgorithm#doSharding(databaseNames/tableNames)方法

// 对于非数值型的ID，需要先求hashCode，而对于数值型ID则直接计算就好，但要保证是正数
String id = "T20190822000702";
long a = Math.abs(id.hashCode());

// 不溢出情况下取模: a % (2^n) 等价于 a & (2^n - 1) => 即 a % 2^5 等价于 a & (2^5 - 1)
// 不溢出情况下除法: a / (2^n) 等价于 a >> n => 即 a / 2^5 等价于 a >> 5
// 即：低5位作为库号，次低5位作为表号
```

#### 11.2.2.0. 如果 1000 亿呢，怎么做分库分表？

1. 64库(id%64) + 64表(id/64%64) + 500w数据 => 64 * 64 * 5000000 = 204亿。
2. 128库(id%128) + 128表(id/128%128) + 500w数据 => 128 * 128 * 5000000 = 819亿，如果采用256表，则有1638亿。
3. 256库(id%256) + 256表(id/256%256) + 500w数据 => 256 * 256 * 5000000 = 3276亿。

#### 11.2.2.1. 10 亿到 1000 亿怎么做扩容？

```java
/*
* => 因此, 如果扩容2倍, 从原来的32库32表, 扩容为64库64表:
*      1) 会导致从原来库取最后5位, 表取次后5位, 更新为库取最后6位, 表取次后6位
*      2) 也就是曾经 abs_hashCode 在 2^5 位置为1的, 则需要变动库号, 为0的则不需要变动
*      3) 同理, 曾经 abs_hashCode 在 2^5、2^6、2^7、2^8、2^9、2^10、2^11 位置为1的, 则需要变动表号, 为0的则不需要变动
*      4) 综上所述, 发生扩容后, 库号要更改的记录占以前模过的记录的1/6 * 1/2 =1/12, 表号要更改的记录占占以前模过的记录的 1/2
*/
```

#### 11.2.2.2. 那如何做动态扩容？

双写（新老写库）**不中断**迁移：
1. **新数据 canal + 双写**：线上系统里所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改（双写）。
2. **老数据根据更新时间同步**：系统部署以后，还需要跑程序读老库数据写新库，写的时候需要判断 updateTime。
3. **同步完毕，则改用新库即可**：直至两个库的数据完全一致，最后重新部署分库分表的代码即可。

#### 11.2.2.3. 算法题 - leetcode146. 如何实现LRU缓存？

##### 1）LinkedHashMap 暴力解法

- **思路**：利用 LinkedHashMap 已经实现了的 LRU 结构（访问后移回链表末尾，新增后判断是否超出了最大容量，如果超出则删除最久没被访问的元素），其中要注意的细节有：
  1. 初始化时，要保证初始容量不会发生扩容。
  2. 初始化时，要把 accessOrder 改为 true，代表访问时需要把最近访问的 Entry 放回链表末尾。
  3. 初始化时，要重写 `removeEldestEntry(Map.Entry<K,V>)` 方法， 使新增元素之后能够回调删除方法。
  4. 获取元素时，要判断是否已经被删除了，如果已经被删除了，则返回 -1，避免空指针异常。
- **结论**：时间，41ms，98.99%，空间，108.4mb，47.86%，由于使用的是 JDK 实现的 LinkedHashMap，性能自然是十分高的，但面试要求的应该不只是这点，还需要自己把底层也实现出来~

```java
class LRUCache {

    private int maxSize;
    private Map<Integer, Integer> map;

    public LRUCache(int capacity) {
        this.maxSize = capacity;
        this.map = new LinkedHashMap<Integer, Integer>(
           // 相除是为了保证顶格初始容量, 使其对于maxSize不会再扩容了 => 取大于等于临界值的最小值
            (int) Math.ceil(capacity / 0.75f), 0.75f, true) {
            protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
                return map.size() > maxSize;
            }
        };
    }
    
    public int get(int key) {
        Integer res = map.get(key);
        return res != null? res : -1;
    }
    
    public void put(int key, int value) {
        map.put(key, value);
    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */
```

##### 2）双向链表法

- **思路**：通过双向链表+哈希表模拟实现 LinkedHashMap，即分为 4 种情况：
  1. 新增元素：新增后，节点需要移动至链表末尾，代表最近被访问过，共有 2 种情况，分为新增的是第一个节点，以及新增的不是第一个节点。
  2. 替换元素值：替换节点值后，节点需要移动至链表末尾，代表最近被访问过，共有 3 种情况，分为替换的是头节点、替换的是未节点，以及替换的是中间节点。
  3. 获取元素值：获取节点值后，节点需要移动至链表末尾，代表最近被访问过，共有 2 种情况，分为节点不存在，以及节点存在。
  4. 删除元素：新增节点后，如果当前哈希表的大小 > 最大大小，那么就要触发 LRU 淘汰机制，淘汰最久没被访问过的元素，即把链表表头的元素脱离链表。
- **结论**：时间，49ms，41.69%，空间，111.6mb，29.18%，效率自然就没 JDK 实现的 LinkedHashMap 的高，面试应该到这里就可以了吧~

```java
class LRUCache {

    class Element {
        private Integer value;
        private Element pre;
        private Element next;

        Element(Integer value) {
            this.value = value;
        }
    }

    private int maxSize;
    private Map<Integer, Integer> dataMap;
    private Map<Integer, Element> elementMap;
    private Element head;
    private Element tail;

    public LRUCache(int capacity) {
        this.maxSize = capacity;
        this.dataMap = new HashMap<>((int) Math.ceil(capacity / 0.75f), 0.75f);
        this.elementMap = new HashMap<>((int) Math.ceil(capacity / 0.75f), 0.75f);
    }

    public int get(int key) {
        Integer res = dataMap.get(key);
        if(res == null) {
            return -1;
        }

        // 链接元素到链表末尾
        Element element = elementMap.get(key);
        link2Last(element);

        return res;
    }

    public void put(int key, int value) {
        Element element = elementMap.get(key);

        // 已存在的, 则链接元素到链表末尾
        if(element != null) {
            dataMap.put(key, value);
            link2Last(element);
        }
        // 新增的, 则新增元素到链表末尾
        else {
            element = new Element(key);
            elementMap.put(key, element);
            dataMap.put(key, value);
            nextLast(element);
            
            // 删除头节点
            if(removeEldestEntry()) {
                Element eldest = unlinkFirst();
                elementMap.remove(eldest.value);
                dataMap.remove(eldest.value);
            }
        }
    }

    private boolean removeEldestEntry() {
        return dataMap.size() > maxSize;
    }

    private Element unlinkFirst() {
        Element eldest = head;
        Element next = head.next;
        head.next = null;
        head = next;
        head.pre = null;
        return eldest;
    }

    private void nextLast(Element element) {
        // 如果为第一个节点
        if(head == null) {
            head = tail = element;
            return;
        }

        // 如果不为第一个节点
        tail.next = element;
        element.pre = tail;
        tail = element;
    }

    private void link2Last(Element element) {
        // 如果为头节点
        if(element == head) {
            if(element == tail) {
                return;
            } else {
                head.next.pre = null;
                head = head.next;
                element.pre = tail;
                tail.next = element;
                element.next = null;
                tail = element;
                return;
            }
        }

        // 如果为末尾节点
        if(element == tail) {
            return;
        }

        // 如果为中间节点
        Element pre = element.pre;
        tail.next = element;
        element.pre = tail;
        pre.next = element.next;
        element.next.pre = pre;
        tail = element;
    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */
```

#### 11.2.2.4. 为什么初始容量设置为maxSize/0.75f？

为了不想让它扩容，因为设定了这个 map 的阈值就是 maxSize(capacity * 0.75 = maxSize，所以是阈值)，碰到maxSize 不是扩容，而是发生节点的淘汰。

#### 11.2.2.5. LinkedHashMap的底层原理？

1. 继承自 HashMap，实现原理都差不多，也就是散列表 + 链表 + 红黑树 + 双向链表实现。
2. 双向链表，是通过在 Map.Entry 之间，还维护了 before 和 after 指针，访问或者添加的 Entry 成为热数据，然后移动到链尾，最久没被访问的 Entry 成为冷数据，保留到链头，在发生条目淘汰时，则从链头进行删除，从而实现最近最久未访问的淘汰策略。

#### 11.3.1.1. 自我介绍?

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 11.3.1.2. 你对学生和工作后身份转变的一个理解？

参加工作以后，我觉得有以下几点不同：

1. 学生时，用到的技术比较表面，工作后，用的技术既要知其然，也要知其所以然，这就要求不断得去深入到源码和架构原理层面，去理解技术本身，从而给出高质量的代码和设计。
2. 学生时，新技术学习比较偏理论，工作后，新技术学习，除了理论，还要注重实践，然后就是解决问题，再沉淀出经验，接着再学习新的技术，周而复始。
3. 然后就是解决方案，学生时，什么都有标准答案，但工作就不一定有标准答案了，只有更好的解决方案，需要根据不同的场景，做不同的分析和设计。
4. 最后就是一些软技能了，除了技术，也要关重人际关系的维护，做好团队合作，与他人建立好的沟通，比如理解 PM 的业务需求等。

=> 以上，就是我对 学生和工作 两者的一些比较，我觉得这些差异比较大、比较重要点~

#### 11.3.1.3. 你觉得你们那边人际关系怎么样？

对比实习时的广州公司，这边人更加懂得包容、体谅、合作，然后团队合作的效率也更高。

#### 11.3.1.4. 你们项目的 QPS 大概有多少？

1. 企业端，用户量 5w 多，平常 QPS 1k~2k，月底年底对供方考核时，高峰会有 1w 多。
2. 供应商端，用户量  10 w 多，日均 QPS 7~8w 左右，供方主要去走送货、送样单等业务。

#### 11.3.1.5. 从架构和性能方面，谈谈你对后台的一个理解？

见《[10.2.1.5. 如何通过学习，保证高并发以及新业务？](#10.2.1.5. 如何通过学习，保证高并发以及新业务？)》。

#### 11.3.1.6. 算法题 - leetcode 53. 连续子数组的最大和？

```java
// 1、动态规划：时间100%，空间78%
class Solution {
    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        if(nums.length == 1) {
            return nums[0];
        }

        int max = nums[0], pre = nums[0];
        for(int i = 1; i < nums.length; i++) {
            pre = Math.max(nums[i] + pre, nums[i]);
            max = Math.max(max, pre);
        }

        return max;
    }
}

// 2、贪心优化：时间100%，空间96.50%
class Solution {
    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        if(nums.length == 1) {
            return nums[0];
        }

        int max = nums[0], pre = nums[0];
        for(int i = 1; i < nums.length; i++) {
            if(pre < 0) {
                pre = nums[i];
            } else {
                pre = pre + nums[i];
            }
            
            max = Math.max(max, pre);
        }

        return max;
    }
}
```

#### 11.3.1.7. 算法题 - leetcode 53 变种. 打印连续子数组最大和的元素？

借鉴于 leetcode 53 的贪心算法进行改进，创建一个额外的 sbs 数组，来记录遍历到当前 i 索引时，把目前最大的组合放到对应的 sbs[i] 上，这样，如果能知道最大的子数组结尾索引是啥，就可以去 sbs 中取出来打印了~

```java
public class Solution {

    // 结果组合为： 1 4 -3 4 
    // 和结果: 6
    public static void main(String[] args) {
        Solution solution = new Solution();
        System.out.println("和结果: " + solution.solution(new int[]{
                1, 4, -3, 4, -5
        }));
    }

    private int solution(int[] nums) {
        if (nums == null || nums.length == 0) {
            System.out.println("-1");
            return 0;
        }
        if (nums.length == 1) {
            System.out.println(nums[0]);
            return nums[0];
        }

        StringBuilder[] sbs = new StringBuilder[nums.length];
        sbs[0] = new StringBuilder().append(nums[0]).append(" ");

        int max = nums[0], pre = nums[0], maxi = 0;
        for (int i = 1; i < nums.length; i++) {
            if (pre < 0) {
                pre = nums[i];
                sbs[i] = new StringBuilder().append(nums[i]).append(" ");
            } else {
                pre = pre + nums[i];
                sbs[i] = new StringBuilder(sbs[i - 1]).append(nums[i]).append(" ");
            }
            if (max < pre) {
                max = pre;
                maxi = i;
            }
        }

        System.out.println("结果组合为： " + sbs[maxi].toString());
        return max;
    }
}
```

#### 11.4.1.1. 你是怎么看待前几轮面试的？

一面注重基础，二面注重架构，三面注重团队和商业模式。

#### 11.4.1.2. 你一毕业在来到了美的这边，请问是什么原因要决定离职呢？

个人发展，个人原因。

#### 11.4.1.3. 请问是什么个人原因呢？

女朋友在广州希音。

#### 11.4.1.4. 反问-具体的地铁口就不说了吧，请问为什么要问这个？

番禺广场附近，开车 1 h 40 min 左右。

#### 11.4.1.5. 你平常作息情况怎么样？

b1、b2 班，下班八九点才走，下班回家学习，早上看半个钟文章再上班。

#### 11.4.1.6. 反问 - bigo 也分 A、B 班？

说是 A 早上 9 点，B 班早上10 点，自由安排，可动态调整。

#### 11.4.1.7. 你最近两年的绩效情况是怎么样的？

都是 B，正常情况，但毕业那会拿了 A 年度和 S 半年度绩效。

#### 11.4.1.8. 为什么最近两年是 B，之前是 A 和 S 呢？

近两年花了更多的个人时间去学习，而刚毕业那会加班比较多。

#### 11.4.1.9. 学习后工作效率提升了，做的东西是一样的吗？

不是，学之前和学之后的视角和思考角度也变得不一样了。

#### 11.4.2.0. 身边的同事朋友是怎么评价你的？

前一年说是加班狂魔，近两年说是卷王。

#### 11.4.2.1. 不加班也算卷王吗？

卷不是加班那种卷，是下班回家还继续学习那种卷，HR还笑了，哈哈~~~

#### 11.4.2.2. 你手上有拿到其他 offer 吗？

有，希音 23k * 14、平安19 * 18、十方融海 22k * 14、字节周四四面。

#### 11.4.2.3. 如果字节和 bigo 给的都是你满意的，那你会去哪？

肯定是 bigo 啊，一来是字节要学 golang 风险大，二来女朋友在广州，溢价率不高的话就不考虑了。

#### 11.4.2.4. 好的，那等你字节那边确定好了，我们在启动薪酬流程，怎么样？

好的。

#### 11.4.2.5. 反问 - 请问是必须等到那边确定好了，才启动薪酬流程吗？

那倒不是，随时你都可以启动，但启动了招聘流程就不再继续了，害，为了填坑面完字节再说吧~

#### 12.1.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.1.1.2. HashMap 底层实现原理？

重要参数（散列表容量、实际大小、阈值、负载因子）、散列原理、get()原理、put()原理、扩容原理()、remove()原理、红黑树性质、左旋右旋、红黑树插入、红黑树删除。

见《[3.2.1.5. HashMap 底层原理？](#3.2.1.5. HashMap 底层原理？)》。

#### 12.1.1.3. JDK 为什么用红黑树，不用完全 AVL 树？

1. 在 AVL 树中，从根到任何叶子的最短路径，和最长路径之间的差异最多为 1。
2. 在红黑树中，由于 2-3-4 树把红结点放了下来，使得最短和最初的路径差异可以是 2 倍，这样可以少很多左旋、右旋的操作，从而提升效率。

#### 12.1.1.4. hashCode 与 equals 方法的关系？

1. hashCode 是求对象的哈希值，equals 是比较两对象是否相等，默认比的是两对象的内存地址，在对象没用在哈希表中时，可以认为两者没什么关系。
2. 但如果用在了哈希表中，由于 hashMap 是根据 hashCode 去计算哈希索引，再去判断桶头或者链上的对象是否 equals。
3. 所以，可以把 hashCode 看作 y 轴，equals 看作 x 轴，两者的关系看作是二次函数 y=x^2，即相同 y 轴的 hashCode，其 x 轴的 equals 一定相同，但相同 x 轴的 equals，其 y 轴的 hashCode 却不一定相等，
4. 因此，为了避免 HashSet 在做去重时出现误判，如果重写了 equals，那必须也重写 hashCode 方法，不然就会出现明明两个对象 equals 了，但仍然不能去重，其原因正是因为 hashCode 不相等，导致 Entry 放在了不同的桶上。

#### 12.1.1.5. static 和 final 的关系？

1. **static**：可以修饰属性和方法
   - 1）修饰属性：代表类级别属性，所有对象共享一份，随着类的加载而加载，只加载一次，先于对象的创建。可以使用类名直接调用。
   - 2）修饰方法：随着类的加载而加载。
   - 3）可以使用类名直接调用。
   - 4）在静态方法中，只能调用静态的成员，以及不可以使用 this。
2. **final**：最要用于变量、方法、类。
   - 1）修饰变量：如果变量是基本数据类型，则其数值一旦在初始化后就不能更改了。如果是引用类型的变量，则其在初始化后就不能更改指向的对象了。
   - 2）修饰方法：锁定方法，防止任何继承类重写其含义（类中所有的 private 方法都隐式地指定为了 final 修饰）。
   - 3）修饰类：表明这个类不能被继承，其中该类中的所有成员、方法都会被隐式地指定为 final 修饰。另外，要使一个类不能被继承，除了 final 关键字外，还可以私有化构造器（不能继承内部类）。
3. 在 JVM 层面，会在类加载的【链接-准备】阶段，就会对 static 的静态变量赋零值，对于 final + static 修饰的静态常量赋予用户指定的值，然后在类加载的【初始化】阶段，则会调用 <cinit> 方法，收集类中所有的静态变量的赋值动作、静态块顺序合并起来并执行，叫做类的构造，去赋予那些 static 非 final 修饰的静态变量为用户指定的值。

#### 12.1.1.6. static 方法能被继承吗？

见《[10.1.2.2. 静态分派和动态分派？](#10.1.2.2. 静态分派和动态分派？)》。

#### 12.1.1.7. TCP 的可靠性保证？

##### 1、总

1. TCP 主要通过确认应答和超时重传机制、检验和、滑动窗口控制、流量控制以及拥塞控制等方式，实现数据的可靠性传输。
2. 注意，是没有*流量窗口*这一说法的，是利用**滑动窗口**实现的流量控制（**rwnd 通知窗口**）。

##### 2、分

###### 1）确认应答和超时重传机制

发送方通过对字节流的每个字节，进行顺序标号并发送，接收方需要对接收到的数据给出确认，如果在规定的时间内（不超过 0.5 s），发送方没有收到确认应答，则需要重传已发送的报文段。

1. **TCP 首部 - 序号**：占 4 个字节，范围 [0，2^32  - 1]，使用 mod 2^32 运算，n 序号表示第 n 字节，共可表示 2^40 位（4GB）数据。
2. **TCP 首部 - 确认号**：占 4 个字节，表示期望收到对方下一个报文段的第一个数据字节的序号。若确认号 = N，则表明到序号 N-1 为止的所有数据都已正确收到。
3. **TCP 首部 - 确认 ACK**：占 1 位，仅当 ACK = 1 时确认号有效，TCP 规定，在连接建立后，所有传送的报文都必须把 ACK 置为 1。

###### 2）检验和

![1620126724402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620126724402.png)

1. 发送方取12 位 TPC 伪首部 + TCP首部 + TCP 报文段数据部分，对其 16 位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
2. 接收方取 12 位 TPC 伪首部 + TCP 首部（此时检验和已经不是全 0 了）+ TCP 报文段数据部分，对其 16 位字使用**二进制反码求和运算**，当无差错时，结果应为全 1，否则就表明有差错出现。
3. 通过检验和的方式，接收方可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方则需要重新发送报文段。

###### 3）以字节为单位的滑动窗口控制

![1620130103782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130103782.png)

1. 发送窗口，里面的序号表示允许发送的序号，后沿后面部分表示已发送且已收到的确认，前沿前面部分表示不允许发送。后沿变化有两种可能即不动（没有收到新的确认）和前移（收到了新的确认）。前沿通常是不断向前的，但也可能不动（收到通知窗口变小），还有可能向后收缩（不推荐）。
2. 在没有收到接收方确认的情况下，发送方可以连续把窗口内的数据都发送出去，凡是已经发送过的数据，在未收到确认之前，都必须暂时保留在窗口内，以便在超时重传时使用。这样可以提高超时重传机制下的发送效率和信道利用率。
3. 而接收窗口，则后沿部分表示已经发送过确认，已经交付主机了，不需要再保留这些数据，窗口内的需要是允许接收的。

###### 4）利用滑动窗口实现的流量控制

![1620130650215](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130650215.png)

用于控制发送方速率不要太快，要让接收方来得及接收，是点对点通信量的控制，是个端对端的问题（接收端控制发送端）。

1. rwnd，receiver window，即通知窗口，发送方的发送窗口不能超过接收方给出的接收窗口数值。
2. 持续计时器，persistence timer，收到零窗口通知时开启，时间到期后，会发送一个零窗口探测报文段（仅携带 1 字节的数据），对方在这个探测报文段给出现在窗口值，如果仍然是零，则还会重新设置持续计时器。以解决零窗口互相等待问题。

###### 5）拥塞控制

![1620132158175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620132158175.png)

用于防止过多的数据注入到网络中，避免网络中的路由器和链路过载。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的因素。

1. cwnd，congestion window，**拥塞窗口**，发送方维持的一个状态变量，大小取决于网络的拥塞程度，并且动态变化。因此，**发送方窗口上限值 = Min[rwnd，cwnd]**。
2. **慢开始门限**，ssthresh，如果 cwnd < ssthresh，则走慢开始算法，如果 cwnd > ssthresh，则走拥塞避免算法。
3. **慢开始算法**，slow-start，先发送小字节探测一下（2 ~ 4 个 SMSS），由小到大逐渐增大拥塞窗口，在每收到一个对新的报文段的确认后，就可以把拥塞窗口 cwnd 增多一个 SMSS 数值，其中 △cwnd = min[N，SMSS]，N 指原先未被确认的，但现在刚刚收到确认的字节数，SMSS，指的是 Sender Maximum Segment Size，最大报文段。
4. **拥塞避免算法**，congestion avoidance，cwnd 缓慢增大，每经过 1 个往返时间 RTT 只把 cwnd + 1，不像慢开始阶段那样指数规律增长，而是按线性规律增长增长，如果网络出现了超时，发送方判断为网络拥塞，需要调整 ssthresh 为原来的一半，同时 cwnd 设置为1，重新进入**慢开始阶段**。
5. **快重传**，fast retransmit，接收方没收到某报文段时，需要立即返回 3 个缺失报文段的重复确认给发送方，发送方只要一收到 3 个重复确认，则认为接收方确实没有收到该报文段，则进行重传，而不会误认为是网络拥塞。
6. **快恢复算法**，fast recovery，发送方知道只是丢失个别报文段后，不启动慢开始算法，而是执行快恢复算法，调整 ssthresh 为 cwnd / 2 ，同时设置 cwnd = ssthresh，并执行**拥塞避免算法**。

##### 3、总

=> 以上，就是我对 TCP 可靠性保证 的一些理解，请问有什么细节需要补充的吗？

#### 12.1.1.8. 滑动窗口、流量窗口、拥塞窗口的区别？

1. **流量控制**：
   - 1）是端到端的问题，也即是接收端控制发送端，目的是用于控制发送方速率不要太快，要让接收方来得及接收。
   - 2）发生在传输层，利用滑动窗口机制，可以很轻松的实现流控。
   - 3）接收方会通过 rwnd 通知窗口，告诉发送方的发送窗口，不能大于这个给出的窗口大小。
2. **拥塞控制**：
   - 1）是一个全局性的过程，涉及所有主机、路由器以及其他降低网络性能的有关因素。
   - 2）发生在网络层，其目的是防止过多的数据注入到网络中，避免网络中的路由器和链路过载。
   - 3）其拥塞窗口是取决于网络的拥堵程度，会使得发送窗口的上限值 = MIN（ cwnd 拥塞窗口大小，rwnd 通知窗口大小）。

#### 12.1.1.9. 介绍一下你项目上死锁是怎么解决的？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.1.2.0. 你项目上 MySQL 的隔离级别？

可重复读

##### 1）事务并发问题

1. **脏读**：Drity Read，指两个事务并发执行，事务 A 已更新某一份数据，事务 B 读取同一份数据，出于某种原因，事务 A 回滚了更新的操作，导致事务 B 读取的数据不正确。
   - 1）**产生原因**：事务 A 读取了事务 B 中未提交的数据。
   - 2）**特点**：违背了隔离性。
2. **不可重复读**：Non-repeatable read，指两个事务并发执行，事务 A 前后两次查询的结果不一样（行内容发生了变更）。
   - 1）**产生原因**：事务 A 前后两次查询有间隔，期间内，被事务 B 修改并提交了事务。
   - 2）**特点**：相比脏读的区别是，不可重复读是读取另一事务提交的数据，这种现象是正常的，是由于事务的隔离级造成的，但是在某些特别的情况下也是不允许的。 
3. **幻读**：Phantom Read，指两个事务并发执行，事务 A 前后两次查询的结果不一样（出现了幻行，导致行数量发生了变更）。
   - 1）**产生原因**：事务 A 前后两次查询有间隔，期间内，被事务 B 新增数据并提交了事务，比如事务 A 查询了几行数据，而事务 B 并发插入了新的几行数据，事务 A 在接下来的查询中，会发现有几行数据是它先前所没有的。
   - 2）**特点**：和不可重复读一样，都是读取了另外一个事务的数据，不同的是不可重复读查询的是同一条数据，而幻读则是针对批量的数据，或者说不可重复读是 A 读取了 B 的更新数据，幻读则是 A 读取了 B 的新增数据。

##### 2）MySQL 锁分类

当数据库发生并发事务时，需要锁机制来保证访问的次序，以满足事务的隔离性，最终保证数据的一致性。

按照角度的不同，可有以下几种分类：

###### 悲观锁和乐观锁

从事务进入临界区前是否锁住同步资源的角度来分：

1. **悲观锁**：先锁再用。
   - 1）就是悲观思想，事务每次进入临界区操作数据时，都认为别的事务会修改，所以，事务每次在读写数据时都会上锁，锁住同步资源，这样其他事务需要读写这个数据时就会阻塞，一直等到拿到锁。
   - 2）适用于写多读少的场景，遇到高并发写时性能高，比如 MySQL 的排他锁。
2. **乐观锁**：用时检查。
   - 1）是一种乐观的思想，事务每次去拿数据时，都认为别的事务不会修改，所以不会上锁，但是，在更新时会判断一下，在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号然后加锁的操作（比较跟上一次的版本号，如果一样就加锁成功，如果失败，就重复读-比较-写操作）。
   - 2）适用于读多写少的场景，遇到高并发写时性能低，MySQL 的乐观锁可以通过 Version + SQL 判断来实现。

###### 排他锁和共享锁

按照锁定资源的方式来分：

InnoDB 中，表锁和行锁都支持共享锁 S 和排他锁 X。

1. **共享锁**：LOCK_S，简称 S 锁，即读锁，如果加在同一资源上，读锁不会阻塞，而是允许另外一把读锁的获取，也就是读读之间允许并发，但读写互斥。

   - 1）**表锁加锁方式**：

     ```sql
     SET autocommit=0;
     LOCK TABLES t2 READ ...;
     ... do something with tables t2 here ...
     COMMIT;
     UNLOCK TABLES;
     ```

   - 2）**行锁加锁方式**：select … lock in share mode。

2. **排他锁**：LOCK_X，简称 X 锁，即写锁，如果加在同一资源上，写锁会阻塞另外一把写锁或者读锁的获取，也就是写写互斥，读写也互斥。

   - 1）**表锁加锁方式**：

     ```sql
     SET autocommit=0;
     LOCK TABLES t1 WRITE ...;
     ... do something with tables t1 here ...
     COMMIT;
     UNLOCK TABLES;
     ```

   - 2）**行锁加锁方式**：select … for update。

###### 表级锁、行级锁和页级锁

按照锁定资源的粒度来分：

1. **表级锁**：

   - 1）LOCK_TABLE，Mysql 中锁定粒度最大的一种锁，对当前操作的整张表加锁，其锁定粒度最大，触发锁冲突的概率最高，并发度也就最低。
   - 2）但由于是一次性锁定所有资源，所以只使用表级锁不会出现死锁 。
   - 3）在 MySQL Server 层和存储引擎 InnoDB 层都有做实现，所以 MyISAM 和 InnoDB 引擎都支持表级锁。
   - 4）在执行某些 DDL 时，会对整个表加锁，也可以手动执行 `LOCK TALBES table_name [READ | WRITE]` 加表级锁。

   **意向锁**：

   - 1）Intention Locks，是一种特殊的表级锁，是为了协调行级锁和表级锁的关系，让 InnoDB 支持多粒度的锁能共存而设计的。
   - 2）取得行的共享锁或者排他锁之前，需要先取得表级的意向共享锁 IS，或者意向排他锁 IX，两者都是 MySQL 自动添加和释放的，整个过程无需人工干预。
     - 1）**意向共享锁**：LOCK_IS，IS，事务有意向对表中某些行加 S 锁，在请求 S 锁前，要先获得 IS 锁。
     - 2）**意向排他锁**：LOCK_IX，IX，事务有意向对表中某些行加 X 锁，在请求 X 锁前，要先获得 IX 锁。
   - 3）主要是用来辅助表级和行级锁的冲突判断，因为 InnoDB 支持行级锁，如果没有意向锁，则判断表级锁和行级锁冲突时，需要遍历表上的所有行级锁，但有了意向锁，则只需要判断表上是否存在意向锁，就可以知道是否存在行级锁了。这也正式为什么意向锁时表级锁的原因~

   - 4）意向锁兼容性，是指当事务 A 对某个数据范围（行级或表级）上了“某锁”后，另一个事务 B 能否在这个数据范围中继续上“某锁"。可见，意向锁与意向锁之间、读锁与意向锁之间互相兼容，写锁与其他锁之间都不兼容。

     | 互斥性       | 共享锁（S） | 排它锁（X） | 意向共享锁IS | 意向排他锁IX |
     | ------------ | ----------- | ----------- | ------------ | ------------ |
     | 共享锁（S）  | ✅           | ❌           | ✅            | ❌            |
     | 排它锁（X）  | ❌           | ❌           | ❌            | ❌            |
     | 意向共享锁IS | ✅           | ❌           | ✅            | ✅            |
     | 意向排他锁IX | ❌           | ❌           | ✅            | ✅            |

   **自增锁**：

   - 1）LOCK_AUTO_INC，是一种特殊的表级锁，如果一个表的某个行具有 `AUTO_INCREMENT` 的列，则一个事务在插入记录到这个表时，会先获得自增锁。
   - 2）其他自增锁详情，见《[5.1.2.9. MySQL 隐藏主键生成原理？](#5.1.2.9. MySQL 隐藏主键生成原理？)》。

2. **行级锁**：

   - 1）LOCK_REC，Mysql 中锁定粒度最小的一种锁，只针对当前操作的行进行加锁，能大大减少并发操作的冲突，其锁定粒度最小，并发度最高，但开销也最大，且可能会出现死锁。
   - 2）InnoDB 默认支持行级锁，`update`、`delete`、`insert`、`select ... lock in share mode` 或者`select ... for update` 当前读，都会加行级锁。
   - 3）行级锁逻辑可以看作，是作用于索引，还是作用在索引间隙之上，作用在索引上，又可以再分为主键索引和非主键索引。如果作用在主键索引，那么 MySQL 只会锁住这个主键索引；而如果作用在非主键索引，那么 MySQL 会先锁住这个非主键索引，再回表锁住对应的主键索引。
   - 4）因此，在不同的语句、不同的事务隔离级下、不同的索引类型下，行级锁会表现为不同的形式：记录锁、间隙锁、临键锁和插入意向锁。

   **记录锁**：

   - 1）LOCK_REC_NOT_GAP，对索引加锁，锁定的是某个具体的索引，锁定后，其他事务不能修改或者删除该加锁项。

   - 2）当 SQL 按照**唯一性索引**（主键索引、或者唯一索引），进行当前读时，同时查询条件为**等值匹配且数据也存在**时，则该 SQL 语句加的是记录锁。

     ![1652929282079](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652929282079.png)

   **间隙锁**：

   - 1）LOCK_GAP，对索引间隙加锁，锁定的是索引之间的间隙，不包含索引本身，是一个左开右开的区间，锁定后，其他事务不能在索引间内插入新的记录，可以防止幻读。

   - 2）当 SQL 按照**任意索引**（主键索引、唯一索引、或者普通索引），进行当前读时，如果**查询的数据不存在**，则该 SQL 语句加的是间隙锁。

   - 3）其中，InnoDB 会为每个数据页，生成两个虚拟的行记录，用来限定记录的边界：Infimum Record 和 Supremum Record，Infimum 是比该页中任何记录都要小的值，而 Supremum 是比该页中最大记录还要大的值。当查询的值，比当前已有记录最大值 max 还大时，则锁定的是（max，Supremum）之间的间隙，反之则是（Infimum，min）之间的间隙。

   - 4）间隙锁与间隙锁之间可以共存，其目的都是防止其他事务往间隙中插入新的记录，防止幻读的发生，所以，一个事务的间隙锁，是不会去阻止另一个事务在同一个区间上另一个间隙锁的。

     ![1652929520489](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652929520489.png)

   **临键锁**：

   - 1）LOCK_ORDINARY，对索引+索引间隙加锁，锁定的是索引本身以及索引之间的间隙，是一个左开右闭区间，即记录锁和间隙锁的结合，可以防止幻读的发生。

   - 2）当 SQL 在进行**普通索引等值查询**的当前读，或者**任意索引范围查询**的当前读时，如果同时还匹配到数据，则会为匹配到的行和间隙加上临键锁，锁定的是 （向左寻找的第一个小于查询条件的值，向右寻找的第一个大于查询条件的值] 的区间。

   - 3）不过要注意的是，如果查询条件没有走上索引时，那么 InnoDB 会尝试给全表每一条记录，都加上临键锁，其效果相当于锁表了，相当于上升为表级锁。

     ![1652930384882](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1652930384882.png)

   **插入意向锁**：

   - 1）LOCK_INSERT_INTENTION，是一种间隙锁形式的意向锁，在真正执行 `insert` 操作之前设置，当执行插入操作时，总会检查当前插入的区间，是否存在间隙锁/临键锁，是的话，则判定间隙锁/临键锁，和插入意向锁冲突，此时当前插入操作就需要等待，起到了防止幻读发生的作用。
   - 2）而由于插入意向锁是一种意向锁，只表示一种意向，所以插入意向锁之间不会发生冲突，多个插入操作同时插入同一个间隙时，无需互相等待。
   - 3）此外，`insert` 语句在执行插入前，会先在间隙中，加入插入意向锁，如果是唯一性索引（主键索引、唯一索引），还会进行 Duplicate key 重复键判断，如果存在相同的键，则还会该记录上设置一个共享锁，要注意的是，在多个操作同时获得共享锁后插入同一行时，会发生死锁！

3. **页级锁**：

   - 1）MySQL 中锁定粒度介于行级锁和表级锁之间的一种锁。
   - 2）由于表级锁速度快，但冲突多，行级锁冲突少，但速度慢，因此设计了折衷的页级，一次锁定相邻的一页记录，其开销、加锁时间和锁定粒度、并发度，都界于表锁和行锁之间，也会出现死锁。

###### MySQL 死锁排查

1. 死锁，是指两个或多个事务，在同一资源上互相占用，并请求锁定对方的资源，从而导致恶性循环的现象。

2. 由于使用表级锁时，需要一次性申请全部所需表的锁，所以只使用表锁的情况下不会出现死锁，因此，一般出现死锁的情况都是行锁。

3. InnoDB 有死锁探测机制，在申请锁时，都会先进行死锁判断，采用深度优先搜索算法，如果在搜索过程中，发现有环的存在，就说明发生了死锁，同时，为了避免死锁检测开销过大，如果搜索深度超过了 200（`LOCK_MAX_DEPTH_IN_DEADLOCK_CHECK`），同样也认为发生了死锁。

   ```sql
   show engine innodb status
   -- LATEST DETECTED DEADLOCK：最近探测到的死锁，排查到发生死锁
   ```

4. 常见的死锁解决/避免/减少方法有：

   - 1）在出现死锁时，InnoDB 会选择一个回滚代价比较小的事务（持有最少行级排他锁事务）进行回滚。
   - 2）如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。
   - 3）如果业务允许，可以把大事务拆小，减少死锁产生概率，因为大事务持有锁的时间更长，更容易出现死锁。
   - 4）同一个事务中，尽量提前一次锁定全部所需的资源，减少死锁产生概率。
   - 5）对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁，来减少死锁产生的概率。
   - 6）为表添加合理的索引，减少死锁产生概率，因为在 RR 级别下，如果不走索引，InnoDB 会为表中的每一行记录加上临键锁，相当于锁表了。
   - 7）尽量少用 `select ... for update` 和 `select ... lock in share mode` 当前读，减少死锁产生概率，因为虽然看起来只是在行上加记录锁，但由于间隙锁和临键锁的存在，锁住的可能不止一条记录。

##### 3）事务隔离级别

| 事务隔离级别 | 存在的事务并发问题     |
| ------------ | ---------------------- |
| 读未提交     | 脏读、幻读、不可重复读 |
| 读已提交     | 幻读、不可重复读       |
| 可重复读     | 幻读                   |
| 串行化       | 没有事务并发问题       |

1. **读未提交**：READ UNCOMMITTED，是最低的事务隔离级别，事务可以读取到其他事务未提交的数据，可能会导致脏读、不可重复读和幻读。
   - **实现方法**：只有当前读，在读取数据时，不加共享锁，不会与修改数据时上的排他锁冲突。

- **读已提交**：RC，READ COMMITTED，也叫不可重复读，事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的，是大多数据库的默认事务隔离级别（比如 Oracle），可以防止脏读，但还是可能会导致不可重复读和幻读。

  - 1）**实现方法 - 当前读**：读操作加共享锁，但在语句执行完以后，立马就释放了共享锁。
    - 不可重复读的原因：共享锁的持有时间是语句级别，语句执行完后释放锁，会使得其执行的记录在第二次读之前被修改过，导致事务前后对该记录做的两次查询结果不一致，产生不可重复读。
  - 2）**实现方法 - 快照读**：MVCC，Read View 以 select 为单位，每次 select 都会生成一个 Read View，事务根据这个 Read View 做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - 不可重复读的原因：由于 Read View 是以 select 为单位，每次 select 都会生成一个 Read View，两者可见性判断的结果可能不一样，能看到的版本也就不一样，从而可能导致事务前后两次查询别人版本的结果不一致，产生不可重复读。

- **可重复读**：RR，REPEATABLE READ，事务对同⼀字段的多次读取结果都是⼀致的，除非数据是被事务本身所修改，是 MySQL 默认的事务隔离级别，可以防止脏读和不可重复读，但还是可能会导致幻读。

  - 1）**实现方法 - 当前读**：读操作加共享锁，且在事务提交之前，不会释放共享锁，必须等待事务执行完毕以后，才释放共享锁。
    - 解决不可重读：使用事务级别的共享锁，可以使得在整个事务内，所读的记录都持有共享锁，不会被其他事务所更改，解决了不可重复读。
    - 解决幻读：出现幻读的语句一般是范围查找，如果走了索引，那么 MySQL 会使用临键锁，向左扫到第一个比给定参数小的值，向右扫到第一个比给定参数大的值， 然后以此为界，构建一个左开右闭的区间， 锁住整个区间内的数据，此时会阻止所有往该间隙插入数据的操作。而如果没走索引，那么 MySQL 会为表中每一行上临键锁，相当于锁住了整张表，也是会阻止数据的插入，因此解决了幻读的问题。
  - 2）**实现方法 - 快照读**：MVCC，Read View 以事务为单位，每个事务只会生成一个 Read View，事务根据这个 Read View 做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - 解决不可重复读与幻读：由于 Read View 以事务为单位，每个事务只会生成一个 Read View，事务前后的快照读只对应同一份 Read View，可见性判断一致，能看到的版本一致，因此整个事务过程中查询别人版本的结果一致，避免了不可重复读与幻读的发生。

  => 因此，在 MySQL 中，RR 可重复读隔离级别下，是没有事务并发问题的。

  |        | RC                                    | RR                         |
  | ------ | ------------------------------------- | -------------------------- |
  | 实现   | 多条查询语句会创建多个不同的 ReadView | 仅需要一个版本的 ReadView  |
  | 粒度   | 语句级读一致性                        | 事务级读一致性             |
  | 准确性 | 每次语句执行时间点的数据              | 第一条语句执行时间点的数据 |

- **串行化**：SERIALIZABLE，是最高的隔离级别，通过强制事务串行执行，所有的事务依次逐个执⾏，事务之间完全不存在互相⼲扰，解决了所有事务并发问题，即脏读、不可重复读和幻读。

  - **实现方法**：InnoDB 会隐式转换所有 `select` 语句为 `select ... lock in share mode`，即加上共享锁，使得读操作阻塞其他写操作，读写无法并发，只能串行执行事务，从而保证严格的一致性。由于可能导致大量的超时和锁争用的问题，所以在实际中很少使用。

#### 12.1.2.1. 谈下你对 MySQL 事务的理解？

见《[5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？](#5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？)》。

#### 12.1.2.2. 直接写磁盘为什么不好？

随机频繁写会移动磁盘，且属于系统调用 `fsync`，需要从用户态切换到内核态。

#### 12.1.2.3. redo log 和 bin log 的区别？

见《[5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？](#5.1.3.0. MySQL 事务 ACID 特性，以及实现原理？)》。

#### 12.1.2.4. redo log 提交了之后，bin log 写失败会怎么样？

redo log 分为两阶段提交：

1. 首先式 prepare 阶段，刷入 redo log 到磁盘，然后等待 bin log 刷入磁盘，bin log 刷入磁盘后，会返回commit 标记给 redo log，让 redo log 进行 commit 阶段的提交。
2. 如果 bin log 写入失败，那么 commit 阶段如果发现 bin log 不存在，则回滚事务。
3. 如果 bin log 写入成功，但 redo log commit 失败，这时仍然继续提交事务，不会进行回滚，因为 MySQL 认为数据时完整的，无需进行回滚。

![1653121717627](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1653121717627.png)

#### 12.1.2.5. 平常是怎么做 sql 调优的，以及 explain 主要看哪些点？

##### 1、总

1. Druid 管理后台，或者跑一次接口，抓取目标 SQL。
2. 使用 explain 关键字，分析 SQL 性能问题。详情见《[4.1.2.1. 讲一下 SQL Explain？](#4.1.2.1. 讲一下 SQL Explain？)》。
3. 解决问题。

##### 2、分

SQL 语句的调优原理：

###### 1）JOIN 语句优化 

根据 JOIN 原理和每种 JOIN 的算法分析可得出，JOIN 联接查询的成本开销占大头的是，驱动表记录数 * 单次访问被驱动表的成本，所以应该为重点优化这两个部分：

1. **尽量减少驱动表的记录数**：
   - 1）小表驱动大表：一般无需人工考虑，MySQL 优化器会自动选择最优的执行方式，另外可以使用STRAIGHT_JOIN 可以指定左右表顺序，使其不被优化器优化。
   - 2）尽量使用过滤条件先减少驱动表的记录数：如果有 where 条件，应当要能够使用索引，并尽可能地减少驱动表的数据量。
2. **对被驱动表的访问成本尽可能降低**：
   - 1）尽量在被驱动表的联接列上建立索引：主键、唯一索引最优，其次是非唯一的二级索引，这样就可以使用 eq_ref 或 ref 的索引匹配类型来访问被驱动表，从而降低访问被驱动表的成本。要注意的是，join 字段的类型需要保持一致，以避免索引失效。
   - 2）合理设置 join_buffer 大小：如果被驱动表的 join 字段用不了索引，且内存较为充足，可以考虑把join_buffer 设置得大一些，以减少被驱动表的扫描次数，提高查询性能。
   - 3）尽量减少联接过程读取的总记录数：经验之谈，如果能控制扫描驱动表和被驱动表的行数在百万条以内，效率还是可以接受的。
3. **参与 Join 的表不要太多**：
   - 1）对于 NLJ 的算法实现，参与 Join 的驱动表越多，循环嵌套也就越多，导致访问被驱动表的次数也越多，性能自然就不会太高。
   - 2）再者，参与 Join 的表过多，会导致 SQL 变得复杂和臃肿，不利于后期调优和维护。
   - 3）在阿里变成规约中建议，参与 Join 的表不能超过 3 张，如果业务确实需要关联这么多表，可以抽取到应用层去实现，避免在 SQL 中 Join 过多的表。

=> 记关联过程中，驱动表读取的记录数为 RN，被驱动表读取的记录数为 SN，则其开销统计为：

| 开销统计                      | SNLJ         | INLJ/BKA                     | BNLJ                                      | CHJ                                       |
| ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- | ----------------------------------------- |
| 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         | 1                                         |
| 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 | RN * used_col_size / join_buffer_size + 1 |
| 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               | RN + SN * I                               |
| Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   | SN / I                                    |
| 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         | 0                                         |

###### 2）GROUP BY 语句优化

如果 GROUP BY 使用了临时表，则要想办法走上索引，即用上**松散索引扫描或者紧凑索引扫描**，尽量避免临时表。

| 扫描模式         | 原理                                                         | 使用规则                             | Extra标识                | 性能 |
| ---------------- | ------------------------------------------------------------ | ------------------------------------ | ------------------------ | ---- |
| Loose Index Scan | 松散索引扫描，无需扫描所有满足条件的索引键，即可返回结果     | 优先尝试使用                         | Using index for group-by | 最好 |
| Tight index Scan | 紧凑索引扫描，需要扫描所有满足条件的索引键，才可返回结果     | 使用不了松散索引扫描时，才会尝试使用 | Using index              | 次好 |
| Temporary table  | MySQL 会读取需要的数据，创建一个临时表，用临时表实现 GROUP BY 操作 | 使用不了紧凑索引扫描时，才会使用     | Using temporary          | 最差 |

###### 3）DISTINCT 语句优化

DSITINCT，本质上就是在 GROUP BY 操作之后，每组只取 1 条数据而已，优化方案同 Group By 语句。

###### 4）ORDER BY 语句优化

|          | 场景                                  | 标志                                      |
| -------- | ------------------------------------- | ----------------------------------------- |
| 全表扫描 | 当 MySQL 优化器发现全表扫描开销更低时 | 此时 Explain#Extra 会显示 Using File Sort |
| 索引排序 | 当 MySQL 优化器发现走索引开销更低时   | 此时 Explain#Extra 没有 Using File Sort   |

1. **使用索引**：最好的做法是，利用索引的有序性，让 MySQL 跳过 filesort 排序过程，以避免排序。
2. **优化 filesort**：如果发生了 filesort，并且没有办法避免时，则需要想办法优化 filesort。
   - 1）**调大 sort_buffer_size**：设置较大的 sort buffer，可以减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
     - 当 OPTIMIZER_TRACE#filesort_summary#num_initial_chunks_spilled_to_disk 过大时，说明产生的临时文件过多，归并次数也就越多，此时可以调大 sort buffer，以减少临时文件的产生，提升性能。
   - 2）**调大 read_rnd_buffer_size**：设置较大的 MRR 排序缓存区，可以接收更多来自 MRR 接口排序好的主键 ID，从而让一次顺序 I/O 返回更多的结果。
   - 3）**调小 max_sort_length**：如果排序字段超长，减少取值的字段长度，可以减少 sort buffer 的占用，减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
   - 4）**设置合理的 max_length_for_sort_data**：一般不建议随意调整。
     1. 因为如果设置得过大，MySQL 则会认为有足够的缓存容纳全部字段，使得各种排序 SQL 都走上**全字段排序**，从而导致大量的内存占用，当还发生写临时文件时，又会占用大量的硬盘。
     2. 如果设置得太小，MySQL 则会认为没有足够的缓存容纳全部字段，使得各种排序 SQL 都走上 **rowid 排序**，由于 rowid 排序需要走上两次 I/O，并且会有随机 I/O 的发生，所以导致各种排序 SQL 性能都比较低下。

| 变量                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| sort_buffer_size         | 指定 sort_buffer 的大小                                      |
| read_rnd_buffer_size     | 默认 256K，MRR 接口主键 ID 排序后的缓存区大小                |
| max_sort_length          | 指定排序时，排序字段最多取多少字节                           |
| max_length_for_sort_data | 当 order by 中出现的字段总长度小于 max_length_for_sort_data 时，MySQL 会使用全字段排序；否则，MySQL 会使用 rowid 排序。 |

###### 5）LIMIT 语句优化

1. **使用覆盖索引**：可在只返回索引字段的场合下，让全表扫描 ALL 提升到全索引树扫描 Index。

   - **缺点**：只能返回单个字段。

   ```sql
   -- 方案1：覆盖索引 (108ms)
   explain
   select emp_no
   from employees
   limit 300000,10;
   ```

2. **使用覆盖索引 + Join**：这种方式会先走一次方案 1，不过由于方案一为全索引数扫描 Index，满足了 BNLJ 的使用场景，因此可以使用覆盖索引 + Join 的方式，来获取深度分页的全字段查询结果。

   - **分析**：此时联接算法为 BNLJ，由于t比较小，MySQL 会使用 t 为驱动表，然后把 t 的查询结果存进 join_buffer，接着 e 表一次性将 join_buffer 的结果进行匹配，由于联接字段是 e 的覆盖索引，可以在索引树上直接返回，不会产生大量的随机 I/O，因此这种优化方式还是可以接受的。

   ```sql
   -- 方案2：覆盖索引+join(109ms)
   select *
   from employees e
            inner join
        (select emp_no from employees limit 300000,10) t
        using (emp_no);
   ```

3. **覆盖索引 + 子查询**：这种方式也是先需要走一次方案 1，先查询达到深度分页最小的 emp_no，再利用索引的有序性，往后再找 10 条记录。

   - **分析**：利用了索引的有序性。

   ```sql
   -- 方案3：覆盖索引+子查询（126ms）
   select *
   from employees
   where emp_no >=
         (select emp_no from employees limit 300000,1)
   limit 10;
   ```

4. **范围查询**：

   - **优点**：扫描的行数永远只有 10 行，性能次优。
   - **缺点**：需要先获取上一页最大的 emp_no。

   ```sql
   select *
   from employees
   where emp_no > #{last_max_emp_no}
   limit 10;
   ```

5. **起始主键值 + 结束主键值**：

   - **优点**：扫描的行数永远只有 10 行，且只在主键索引上查询，性能最优。
   - **缺点**：需要先获取上一页最后一行的主键值。

   ```sql
   -- 方案5：如果能获得起始主键值 & 结束主键值
   select *
   from employees
   where emp_no between 20000 and 20010;
   ```

###### 6）COUNT 语句优化

如果没有特殊要求，一般建议使用count（*）就好。

1. 当没有非主键索引时，会使用主键索引。
2. 如果存在非主键索引的话，会使用非主键索引。
   - 1）这是因为，InnoDB 的非主键索引叶子结点存储的是索引 + 主键，而主键索引存储的是主键+表数据。
   - 2）在 MySQL#count 时，如果使用非主键索引，可以比使用主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。
3. 如果存在多个非主键索引，会使用一个最小的非主键索引。
   - 1）同理，如果使用 key_len 小的非主键索引，可以比使用 key_len 大的非主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。

| 形式              | 性能上的区别                                                 | 业务上的区别                                   |
| ----------------- | ------------------------------------------------------------ | ---------------------------------------------- |
| count（业务字段） | 如果该字段存在索引，则会走上索引；否则只能全表扫描           | 只会对该字段进行统计，会排除字段值为NULL的行   |
| count（*）        | 与count（1）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键；InnDB >= 8.0.13，对于无条件count（*）做了优化 | 与count（1）没有区别，不会排除字段值为NULL的行 |
| count（1）        | 与count（*）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键 | 与count（*）没有区别，不会排除字段值为NULL的行 |

##### 3、总

=> 以上，就是我对 SQL 调优 的一些理解，请问有什么细节需要补充的吗？

#### 12.1.2.6. 算法题 - leetcode 159. 至多包含两个不同字符的最长子串？

##### 1）滑动窗口法 | O（n）

- **思路**：
  1. 建立只能存储两种元素的滑动窗口，然后从左到右遍历原数组，判断是否可加入滑动窗口，分为 3 种情况：
     - 1）小于2个时，直接进队。
     - 2）大于等于 2 个时, 则判断是否可以进队。
     - 3）不可进队，则先出队。
  2. 其中，还需要一张哈希表，来记录每种元素在滑动窗口内出现的次数，以实现在元素次数为 0 时出队。
- **结论**：时间，34 ms，64.94%，空间，42.6 mb，8.42%，时间上，由于最坏情况下，需要遍历 n - 1 长数组，然后在添加最后一个元素需要移出 n - 2 个元素，此时时间复杂度为 O（n - 1 + n - 2 )，空间上，由于需要一个 n 长的队列，n 长的哈希表，所以额外空间复杂度为 O（2 * n）。

```java
import java.util.HashMap;
import java.util.LinkedList;
class Solution {
    public int lengthOfLongestSubstringTwoDistinct(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }
        if(s.length() <= 2) {
            return s.length();
        }

        char[] chars = s.toCharArray();
        LinkedList<Character> deque = new LinkedList<>();
        HashMap<Character, Integer> map = new HashMap<>();

        deque.offerLast(chars[0]);
        map.put(chars[0], map.getOrDefault(chars[0], 0) + 1);

        deque.offerLast(chars[1]);
        map.put(chars[1], map.getOrDefault(chars[1], 0) + 1);

        int max = deque.size();
        for (int i = 2; i < chars.length; i++) {
            // 小于2个时, 直接进队
            if(map.size() < 2) {
                deque.offerLast(chars[i]);
                map.put(chars[i], map.getOrDefault(chars[i], 0) + 1);
            }
            // 大于等于2个时, 则判断是否可以进队
            else if (map.containsKey(chars[i])) {
                deque.offerLast(chars[i]);
                map.put(chars[i], map.get(chars[i]) + 1);
            }
            // 不可进队, 则先出队
            else {
                while (map.size() >= 2) {
                    Character c = deque.pollFirst();
                    Integer count = map.get(c);
                    if(count == 1) {
                        map.remove(c);
                    } else {
                        map.put(c, count - 1);
                    }
                }

                deque.offerLast(chars[i]);
                map.put(chars[i], map.getOrDefault(chars[i], 0) + 1);
            }

            max = Math.max(deque.size(), max);
        }

        return max;
    }
}
```

#### 12.2.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.2.1.2. 为什么要用 Kafka？

因为 Kafka 的吞吐量、性能高，其高性能原理为：

1. **利用 Partition 实现并行处理**：并行处理可以提升速度，因为多个人搬砖肯定比一个人搬得快。

   - 1）**集群优势**：每个 Topic 都包含一个或多个 Partition，不同 Partition 可以位于不同 Broker 节点，因此，可以充分利用集群优势，实现机器间的并行处理。
   - 2）**多磁盘优势**：另外，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个 Broker 节点，也可通过配置，让不同 Partition 落于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

2. **顺序写磁盘**：在许多的开源框架，比如 Kafka、HBase，都通过追加写，即顺序写磁盘的方式，来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。

   - 顺序写性能高的原因：机械硬盘的连续读写性能很好，但随机读写性能很差，主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。

3. **Page Cache 空中接力**：

   - 1）**对于读操作**：可直接在 Page Cache 内进行，避免了对底层磁盘的操作，提高了读性能。如果消费和生产速度相当，甚至不需要通过物理磁盘，而是直接通过 Page Cache 进行交换数据。
   - 2）**对于写操作**：
     1. Broker 收到数据后，写磁盘只是暂时把数据存在 Page Cache 中，然后交由操作系统来统一**异步**写到磁盘中，减少了 Broker 访问磁盘的次数，提高了写性能。
     2. 另外，根据 I/O 调度算法， I/O Scheduler 会把连续的小块写，组装成大块的物理写，同时会尝试将一些写操作重新按顺序排好，减少磁盘头的移动时间，进一步提高了写性能。
   - 3）**Page Cache 的局限**：写磁盘只是把数据写入 Page Cache，并不保证数据一定完全写入磁盘，虽然 Kafka 进程重启时，Page Cache 仍然可用。但如果在机器宕机时，则可能会由于 Page Cache 内的数据未写入磁盘，从而导致数据的丢失。解决方案有：
     1. **副本机制**：这种丢失只发生在机器断电等，造成操作系统不工作的场景里，可以由 Kafka Replication 机制去解决。
     2. **强制刷脏**：Kafka 提供了 `flush.messages` 和 `flush.ms` 两个参数，可以把 Page Cache 中的数据强制 Flush 到磁盘中，但是 Kafka 并不建议使用，这是因为如果为了保证这写情况下的数据不丢失，而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。

4. **零拷贝优化**：

   - 1）**使用 mmap**：减少读取网络数据时的 2 次用户态的数据拷贝。

     ![1634181981080](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634181981080.png)

   - 2）**使用 sendfile**：减少读取磁盘文件时的 2 次用户态数据拷贝，以及 1 次 socket 内核缓冲区到 NIC buffer 的数据拷贝。

     ![1634190319687](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634190319687.png)

5. **消息批处理**：在很多情况下，系统瓶颈并不是 CPU 或磁盘，而是网络 I/O，所以，Kafka 的客户端和 Broker 还会在通过网络发送数据之前，在一个 Batch 中累积多条记录（包括读和写）再批次发送，分摊数据包网络往返的开销，使用更大的数据包提高带宽的利用率。

6. **数据压缩后传输**：数据压缩，一般都和批处理作为优化手段配套使用，Producer 可将数据压缩后再传输给 Broker，可以减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4，可通过 `compression.type` 配置。

#### 12.2.1.3. Kafka 是推还是拉？拉有什么好处和坏处？

见《[11.1.1.6. Kafka 和 RabbitMQ 的区别？](#11.1.1.6. Kafka 和 RabbitMQ 的区别？)》。

#### 12.2.1.4. Kafka 如果实现消息顺序消费？

见《[10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？](#10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？)》。

#### 12.2.1.5. Zookeeper 做的分布式锁有什么缺点？

见《[1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？](#1.2.1.4. 分布式锁的实现方案，以及红锁的缺点？)》。

#### 12.2.1.6. Zookeeper 分布式锁从 CAP 的角度进行回答？

1. Zookeeper 遵循的是 CP，抛弃了 A，即抛弃了可用性，也就是在极端环境下，ZooKeeper 可能会丢弃一些请求，此时客户端需要重新请求，或者阻塞等待才能获得结果。
2. 在使用 ZooKeeper 获取服务列表时，当 Leader 节点因为网络故障与其他节点失去联系时，剩余节点会重新进行 Leader 选举。
3. 其中，选举 Leader 的时间太长，30 ~ 120s，且选举期间整个 ZK 集群都不可用，这就导致了在选举期间注册服务的瘫痪，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。
4. 所以说，ZooKeeper 是不能保证服务可用性的。

#### 12.2.1.7. Zookeeper 主节点宕机后，还能保证服务响应吗？

1. 根据 ZAB 一致性算法，ZK Leader 宕机后，会出现短暂的服务不响应的时间，去做一致性同步的工作。
2. ZAB 有两种模式，它们分别是恢复模式（选主）和广播模式（同步）：
   - **1）恢复模式（选主）**：
     1. 当服务启动，或者在领导者崩溃后，ZAB 就进入了恢复模式。
     2. 当领导者被选举出来，且大多数 Follower 完成了和 Leader 的状态同步以后，恢复模式就结束了。
     3. ZK 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的，系统默认的选举算法为 fast paxos。
   - **2）广播模式（同步）**：保证了 Leader 和 Follower 具有相同的系统状态。
     1. 选完 Leader 以后，ZK 就进入状态同步过程。
     2. Leader 等待 server 连接。
     3. Follower 连接 Leader，将**最大的** ZXID（全局递增的事务 ID）发送给 Leader。
     4. Leader 根据 Follower 的 ZXID 确定同步点。
     5. 完成同步后，通知 Follower 已经成为 `uptodate` 状态。
     6. Follower 收到 `uptodate` 消息后，则又可以重新接受 client 的请求，继续进行服务了。

#### 12.2.1.8. Zookeeper 主节点选举过程的不可用，有什么手段可以继续优化吗？

由 ZAB 分布式一致性算法决定的，不能避免。

#### 12.2.1.9. 设计题 - 实现一个懒加载的、线程安全的单例模式？

3 种写法，双重检查锁实现、静态内部类实现、内部枚举类实现，其中双重检查锁实现的单例会被反射破坏，静态内部类和内部枚举类实现的单例不会被反射破坏

```java
// 1、双重检查锁实现
class ByDoubleCheckLock {

    private static volatile Object instance;

    public static Object getInstance() {
        if (instance == null) {
            synchronized (ByDoubleCheckLock.class) {
                if (instance == null) {
                    instance = new Object();
                }
            }
        }
        return instance;
    }
}

// 2、静态内部类实现
class ByStaticInnerClass {

    private static class Holder {
        private static final Object instance = new Object();
    }

    public static Object getInstance() {
        return Holder.instance;
    }
}

// 3、内部枚举类实现
class ByInnerEnum {

    private enum SingletonEnum {
        INSTANCE(new Object()),;

        private Object singleton;

        SingletonEnum(Object singleton) {
            this.singleton = singleton;
        }
    }

    public static Object getInstance() {
        return SingletonEnum.INSTANCE.singleton;
    }
}
```

#### 12.2.2.0. 讲一下你对 synchronized 的理解？

见《[3.1.1.1. sychrozied 锁升级流程？](#3.1.1.1. sychrozied 锁升级流程？)》。

#### 12.2.2.1. 算法题 - leetcode162. 数组中，找出任意一个峰值元素的索引？

##### 1）极值法 | O（n）

- **思路**：从左到右遍历数组，碰到前一个大于后一个的，则认为前一个是极大值，返回前者的索引。
- **结论**：时间，0ms，100%，空间，40.7mb，62.79%，时间上，最坏情况下需要遍历 n 长的数组，所以时间复杂度为 O（n），空间上，没有使用额外变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int findPeakElement(int[] nums) {
        if(nums == null || nums.length < 2) {
            return 0;
        }

        for(int i = 1; i < nums.length; i++) {
            if(nums[i - 1] > nums[i]) {
                return i - 1;
            }
        }

        return nums.length - 1;
    }
}
```

##### 2）二分查找法 | O（logn）

- **思路**：
  1. 如果大的在右边，则二分继续往右找。
  2. 如果大的在左边，则二分继续往左找。
  3. 如果 mid 局部最大, 则返回 mid 索引。
- **结论**：时间，0ms，100%，空间，40.6 mb，88.77%，时间上，由于每次都二分，丢弃一半的元素，所以时间复杂度为 O（logn），空间上，由于采用了递归，栈深度最大为 O（logn），所以额外空间复杂度为 O（logn）。

```java
class Solution {
    public int findPeakElement(int[] nums) {
        if(nums == null || nums.length < 2) {
            return 0;
        }

        return f(nums, 0, nums.length - 1);
    }

    private int f(int[] nums, int l, int r) {
        if(l >= r) {
            return r;
        }

        int mid = l + ((r - l) / 2);

        // 如果大的在右边, 则二分继续往右找
        if(mid + 1 < nums.length && nums[mid] < nums[mid + 1]) {
            return f(nums, mid + 1, r);
        } 
        // 如果大的在左边, 则二分继续往左找
        else if(mid - 1 > -1 && nums[mid] < nums[mid - 1]) {
            return f(nums, l, mid - 1);
        } 
        // 如果mid局部最大, 则返回mid
        else {
            return mid;
        }
    }
}
```

#### 12.2.2.2. 算法题 - 从日志中的 100 亿个关键词，找出最热的 100 个？

1. bitmap：不行，散列会冲突。
2. 大文件分片，次数作为文件夹名称也不行，找不到上一次的次数是啥。
3. top k 小根堆，可以，节点存关键词的值和次数，不断交换堆头出去。

=> 在所有内容都可以加载到内存的小数组上，可以直接使用排序，但对于 100 亿大数据量这种情况，就不能直接排序了，此时需要手写堆，做流式处理。

##### 大根堆法 | O（n * logn）

- **思路**：父节点 = (i - 1) / 2，左孩子 = i * 2 + 1，右孩子 = i * 2 + 2，向上调整直到 0 位置的根节点，向下调整直到没有孩子节点，期间不断比较当前节点的值与父节点、或者最大的孩子节点的值，目的是把大的交换到堆顶，从而保持大根堆的性质。
- **结论**：时间，6ms，69.48，空间，50.5mb，23.00%，时间上，由于每次调整堆需要 O（logn），最多要调整 n 次，所以时间复杂度为 O（n * logn），空间上，由于 heap 是需要返回给题目的数组，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] smallestK(int[] arr, int k) {
        if(arr == null || arr.length == 0 || k == 0) {
            return new int[0];
        }
        if(arr.length < k) {
            return arr;
        }

        // 初始化大根堆
        int[] heap = new int[k];
        for(int i = 0; i < k; i++) {
            heap[i] = arr[i];
            siftUp(heap, i);
        }

        // 比较、加入大根堆
        for(int i = k; i < arr.length; i++) {
            if(arr[i] < heap[0]) {
                heap[0] = arr[i];
                siftDown(heap, k, 0);
            }
        }

        return heap;
    }

    // 向上调整大根堆
    private void siftUp(int[] heap, int i) {
        while(i > 0) {
            int k = (i - 1) >>> 1;
            if(heap[i] > heap[k]) {
                swap(heap, i, k);
            }
            i = k;
        }
    }

    // 向下调整大根堆
    private void siftDown(int[] heap, int size, int i) {
        int half = size >>> 1;
        while(i < half) {
            int k = (i << 1) + 1;
            int maxi = k + 1 < size && heap[k + 1] > heap[k]? k + 1 : k;
            if(heap[maxi] > heap[i]) {
                swap(heap, i, maxi);
            }
            i = maxi;
        }
    }

    private void swap(int[] arr, int from, int to) {
        int tmp = arr[to];
        arr[to] = arr[from];
        arr[from] = tmp;
    }
}
```

#### 12.2.2.3. 小根堆和大根堆的区别？

小根堆堆顶是最小的，大根堆堆顶是最大的。

#### 12.2.2.4. 小根堆，加入一个节点，是如何做调整的？

1. 一般是在末尾添加，这时需要不断地与父节点比较，小的则交换上去，这叫做向上调整。
2. 下不在末尾添加节点时，需要先向下调整，与孩子节点到叶子节点比较，把大的换下去，然后在向上调整，不断地与父节点比较，小的则换上去。
3. 这里 top k 算法，应该是替换掉小根堆的堆顶，然后再向下调整，因为其堆顶的次数刚好是排第 10 的关键词。

#### 12.3.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.3.1.2. 找一个模块讲下？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.3.1.3. Kafka 如何保证可靠性？

见《[10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？](#10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？)》。

#### 12.3.1.4. kafka 消息是顺序的吗？

见《[10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？](#10.2.1.4. 消息丢失、消息重复消费、消息消费慢、顺序消息如何保证？)》。

#### 12.3.1.5. 算法题 - leetcode 121. 买卖股票的最佳时机？

##### 1）暴力解法 | O（n^2）

- **思路**：
  1. 根据题意，只能买卖一次，所以只要保证买在最低点，卖在最高点，且最低点在最高点之前即可。
  2. 这样可以设计一个 f（start）的函数，来表示 [start...end]天内买卖股票能够得到的最大利润，其中买入点就是 start，而卖出点由最大利润来决定。
  3. 然后循环判断出最大的买入点，即可得到最大的利润。
- **结论**：执行超时，由于每次比较都没研究子过程的数据状态，所以浪费了很多次的计算，因此还可以继续优化。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < prices.length; i++) {
            max = Math.max(max, f(prices, i));
        }

        return max;
    }

    // f表示[start...end]天内买卖股票能够得到的最大利润
    private int f(int[] prices, int start) {
        if(start < 0 || start >= prices.length) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = start; i < prices.length; i++) {
            max = Math.max(max, prices[i] - prices[start]);
        }

        return max;
    }
}
```

##### 2）极值法 | O（n）

- **思路**：
  1. 从左到右遍历，每次找到极小值则记录起来，用于与后面的股票价格相比，得出的最大利润则是答案。
  2. 其中，如果遇到极小值是比之前的更小，此时算利润的话是为负数，肯定不是最大值，所以只更新掉替换之前极小值即可，无需计算利润。
- **结论**：时间，2ms，88.95%，空间，51mb，90.14%， 是数学的求极值问题，所以用暴力递归 -> 记忆化搜索 -> 动态规划是想不出来的！

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }

        int max_profit = 0, min_price = Integer.MAX_VALUE, profit;
        for(int i = 0; i < prices.length; i++) {
            if(prices[i] < min_price) {
                min_price = prices[i];
            } else {
                max_profit = Math.max(max_profit, prices[i] - min_price);
            }
        }

        return max_profit;
    }
}
```

#### 12.3.1.6. 算法题 - leetcode-122. 买卖股票的最佳时机 II？

##### 1）暴力递归 | O（4 * n）

- **思路**：
  1. 指定一个 f（isBuy，start）函数，代表从 start 开始买入，获得的最大收入是多少。然后就要分情况讨论了：
  2. 当 isBuy == 1，说明是买入：
     - 1）如果 start 是最后一天，那么就返回 0，代表不能再买入，也不会有额外的收入了。
     - 2）如果 start 是非最后一天，那么就有两种情况，要么当天买入，要么后面再买入，返回最大值返回上一层就好。
  3. 当 isBuy == 0，说明是卖出：
     - 1）如果 start 是最后一天，那么就返回当前价格作为收入，代表今天就要卖出了，不卖出就不会有收入了。
     - 2）如果 start 是非最后一天，那么就有两种情况，要么当天卖出，要么后面再卖出，返回最大值返回上一层就好。
- **结论**：时间，执行超时，时间上，由于最多情况下需要调用 4 次 f（isBuy，start）函数，即来回遍历 4 次数组，所以时间复杂度为 O（4 * n），空间上，由于是二元参数，其栈深度最大为 2 * n 长，所以额外空间复杂度为 O（2 * n）。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }
        
        return f(prices, 1, 0);
    }

    // f代表从start天开始买入, 获得的最大收入是多少
    private int f(int[] prices, int isBuy, int start) {
        // 最后一天
        if(start == prices.length - 1) {
            return isBuy == 1? 0 : prices[start];
        }

        // 非最后一天
        // 买入
        if(isBuy == 1) {
            return Math.max(
                // 当天买入
                -prices[start] + f(prices, 0, start + 1),
                // 后面再买入
                f(prices, 1, start + 1)
            );
        }
        // 卖出
        else {
            return Math.max(
                // 当天卖出
                prices[start] + f(prices, 1, start + 1),
                // 后面再卖出
                f(prices, 0, start + 1)
            );
        }
    }
}
```

##### 2）记忆化搜索 | O（2 * n）

- **思路**：在暴力递归的基础上，增加 dp 二维数组缓存，如果发现缓存中存在，则返回缓存中的数据，如果发现缓存中不存在，则根据暴力递归去判断，得出的结果先设置到缓存中，再返回上一层。
- **结论**：时间，3ms，24.25%，空间，45.2mb，5.15%，时间上，由于最多只需要遍历 2 * 1 次数组，所以时间复杂度为 O（2 * n），空间上，由于是二元参数，其栈深度最大为 2 * n 长，所以额外空间复杂度为 O（2 * n）。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }
        
        int[][] dp = new int[2][prices.length];
        Arrays.fill(dp[0], -1);
        Arrays.fill(dp[1], -1);

        return f(prices, dp, 1, 0);
    }

    // f代表从start天开始买入, 获得的最大收入是多少
    private int f(int[] prices, int[][] dp, int isBuy, int start) {
        // 最后一天
        if(start == prices.length - 1) {
            return isBuy == 1? 0 : prices[start];
        }
        if(dp[isBuy][start] != -1) {
            return dp[isBuy][start];
        }

        // 非最后一天
        // 买入
        if(isBuy == 1) {
            dp[isBuy][start] = Math.max(
                // 当天买入
                -prices[start] + f(prices, dp, 0, start + 1),
                // 后面再买入
                f(prices, dp, 1, start + 1)
            );
            return dp[isBuy][start];
        }
        // 卖出
        else {
            dp[isBuy][start] = Math.max(
                // 当天卖出
                prices[start] + f(prices, dp, 1, start + 1),
                // 后面再卖出
                f(prices, dp, 0, start + 1)
            );
            return dp[isBuy][start];
        }
    }
}
```

##### 3）严格表结构优化 | O（n）

- **思路**：在记忆化搜索的基础上，分析表结构的依赖关系，发现是前者依赖后者，所以就需要先初始化好最后一位，然后从后往前进行初始化，最后返回第一位买入的 dp 值即可。
- **结论**：时间，2ms，32.26%，空间，41.4mb，34.13%，时间上，由于只需要遍历一次数组，所以时间复杂度为 O（n），空间上，由于使用了一张二维表，所以额外空间复杂度为 O（2 * n）。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }
        
        int len = prices.length;
        int[][] dp = new int[2][len];
        
        // 最后一天买
        dp[1][len - 1] = 0;
        // 最后一天卖
        dp[0][len - 1] = prices[len - 1];

        // 设置dp数组
        for(int start = len - 2; start > -1; start--) {
            // 买入
            dp[1][start] = Math.max(
                // 当天买入
                -prices[start] + dp[0][start + 1],
                // 后面再买入
                dp[1][start + 1]
            );
            
            // 卖出
            dp[0][start] = Math.max(
                // 当天卖出
                prices[start] + dp[1][start + 1],
                // 后面再卖出
                dp[0][start + 1]
            );
        }

        return dp[1][0];
    }
}
```

##### 2）极值法 | O（n）

- **思路**：只要当天比前一天的价格要高，那么就买入前一天的股票，并在当前天卖出。
- **局限**：这种做法对比现实，是拥有这超前的预知能力，买到了过去的股票，所以总能保持不亏，达到最大的利润。
- **结论**：时间，1ms，82.25%，空间，41.3mb，40.60%，时间上，由于只需要遍历一次数组，所以时间复杂度为 O（n），空间上，由于只是用了额外的几个有限变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }

        int profit = 0;
        for(int i = 1; i < prices.length; i++) {
            if(prices[i] > prices[i - 1]) {
                profit += prices[i] - prices[i - 1];
            }
        }

        return profit;
    }
}
```

#### 12.3.1.7. 你最近有在学什么吗？

Golang 和大数据。

1. **Golang**，是谷歌支持的开源编程语言，内置并发和强大的标准库，可以说是 21 世纪的 C 语言，适用于大规模构建快速、可靠和高效的软件。
2. **大数据**，big data，或者称为巨量资料，指的是所涉及的资料量规模巨大，无法透过主流软件工具，在合理时间内达到撷取、管理、处理、整理成为帮助企业经营决策更积极目的的资讯。

#### 12.3.1.8. 线程和协程的关系？

##### 1）协程的概念

1. 协程，又被称为轻量级纤程、微线程、纤程，运行在线程之上，但并没有增加线程的数量，只是在线程的基础上，通过分时复用的方式，运行多个协程，可以认为是线程里不同的函数，在这些函数之间，则可以互相快速切换。
2. 同时，这种上下文切换只发生在用户态上，无需陷入内核，其切换的代价比线程从用户态到内核态的代价要小，所以，协程可以支持更高的并发。

##### 2）用户态线程 & 内核态线程

1. 线程，可以继续划分为，用户线程和内核线程，但是 CPU 并不知道用户线程的存在，在它的视野里，只有一个内核线程，所以，用户态线程必须绑定一个内核线程。
2. 基于这种概念，协程则对应的是用户线程，线程则对应的是内核线程，同时，一个协程需要绑定一个线程才能运行。

![1653445271399](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1653445271399.png)

##### 3）Goroutine GMP 模型

1. 为了解决多个协程绑定一个，或者多个线程，Go 使用了 Goroutine GMP 模型，让一组可复用的协程，运行一组线程之上，即使协程发生阻塞，同线程的其他协程，也可以转移到其他可运行的线程上，继续被调度。

2. Goroutine **主要概念**：

   ![1653445686497](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1653445686497.png)

   - 1）**G**：Goroutine，即 Go 协程，每个 `go` 关键字，都会创建一个协程。
   - 2）**M**：Machine，即工作线程，在 Go 中，线程是运行 G 的实体。
   - 3）**P**：Processor，处理器，是 Go 中定义的一个概念，并不是指 CPU，包含运行 Go 代码的必要资源，有调度 G 的能力。
   - 4）**全局队列**：存放等待运行的、空闲的 G。
   - 5）**本地队列**：指 P 的本地队列，与全局队列类型，也是存放等待运行的、空闲的 G，但存的数量有限，不超过 256 个。在新建 G 时，G 会优先加入到本地队列中，如果本地队列满了，则会把一半的 G 移动到全局队列中。
   - 6）**P 列表**：
     1. 所有的 P 都会在程序启动时创建，并保存在数组中，其中最多只创建 ` $GOMAXPROCS` 环境配置的个数。
     2. M 与 P 的数量没有绝对关系，一个 M 阻塞，P 会去创建或者切换另一个 M，所以，即使 P 的默认数量为 1，也有可能创建出很多个 M。
   - 7）**Goroutine 调度器**：会把可运行的 G 分配到工作线程上，目的是为了复用线程，避免频繁地创建和销毁线程。其调度策略为：
     1. 如果本地队列不为空，则 M 优先从本地队列中获取 G 来运行。
     2. 如果本地队列为空，但全局队列不为空，则 M 会去全局队列获取 G 来运行。
     3. 如果全局队列也为空，则 M 会从其他 P 的本地队列中，窃取 G 来运行。
     4. 如果执行期间，G 发生了系统调用，或者需要阻塞时，则 M 会绑定这个 G，然后记住这个 P，把 P 释放出去，让给其他空闲的 M 做 P 绑定。
     5. 当系统调用或者阻塞完毕后，M 会优先寻找之前记住的 P 进行绑定，如果由于 P 非空闲导致了绑定失败，则 M 会去 P 列表中，获取新的空闲 P 进行绑定，然后把 G 放入到这个 P 的本地队列。如果获取不到 P，那么这个 G 会被放入全局队列，同时 M 就变成休眠状态，加入到空闲线程中。

   => P 存在的意义：

   1. 如果没有 P，不同的 G 在不同的 M 上并发运行，可能都需向系统申请资源，比如堆内存，由于资源是全局的，则会由于资源竞争，造成很多系统性能损耗。
   2. 如果有了 P，让 P 去管理 G ，M 要想运行 G，就必须先与一个 P 绑定，然后才能运行 P 上的 G的话，P 就可以预先申请一些系统资源作为本地资源，G 需要时则向自己的 P 申请，就无需锁保护了，如果不够用时，则再向全局申请，且 P 在从全局拿时会多拿一些，以供后面高效的使用。
   3. 所以，P 的存在解耦了 G 和 M，当 M 执行的 G 被阻塞时，P 可以绑定到其他 M 上，继续使用本地资源，执行其他 G，提升并发性能。

3. Goroutine **工作原理**：

   ![1653447936778](D:\Users\yaocs2\AppData\Roaming\Typora\typora-user-images\1653447936778.png)

   1. 通过 `go` 关键字，创建一个 Goroutine。
   2. 新建的 G 会优先保存到本地队列中，如果本地队列已满，则会保存到全局队列中。
   3. M 会从本地队列获取一个可运行的 G 来执行，如果本地队列为空，但全局队列不为空，则会去全局队列获取 G 来运行，而如果全局队列也为空，则 M 会从其他 P 的本地队列中，窃取 G 来运行。
   4. M 调度执行 G。
   5. 如果执行期间，G 发生了系统调用，或者需要阻塞时，则 M 会绑定这个 G，然后记住这个 P，把 P 释放出去，让给其他空闲的 M 做 P 绑定。
   6. 当系统调用或者阻塞完毕后，M 会优先寻找之前记住的 P 进行绑定，如果由于 P 非空闲导致了绑定失败，则 M 会去 P 列表中，获取新的空闲 P 进行绑定，然后把 G 放入到这个 P 的本地队列。如果获取不到 P，那么这个 G 会被放入全局队列，同时 M 就变成休眠状态，加入到空闲线程中。

##### 4）协程总结

1. 当协程调用了一个阻塞 I/O 操作时，操作系统会让线程进入阻塞状态，使得与当前线程绑定的协程，都会陷入阻塞，而得不到调度。
2. 所以，在协程中，尽量不要调用阻塞式 I/O 的方法，比如打印、读取文件、操作 Socket 等，除非改为异步式 I/O，发挥协程的最大威力，或者采用协程与 I/O 多路复用的方式，多个 G 复用更少数量的 m，减少线程的创建。

#### 12.3.1.9. 反问 - 文档的一致性算法？

说有做实现的，不用我们管。

#### 12.3.2.0. 反问 - 岗位的具体职责？

说对文档的增删改查，以及业务处理。

#### 12.3.2.1. 反问 - 文档的落表原理？

说是 bin log 的方式存储，然后并发时处理好分布式事务的问题。

#### 12.4.1.1. 自我介绍？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.1.2. 算法题 - 扑克牌逆序？

```java
/**
 *
 * 你手上有一副扑克牌
 *
 * 第一步, 把牌顶的一张从左到右顺序放到桌子上
 * 第二步, 把牌顶的一张加入牌组最底部
 * 重复第一、第二步
 *
 * 假设最终放到桌子上的扑克牌序列为：K, Q, J, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1
 * 请你还原你原来手上的扑克牌顺序是怎么样的
 */
public class Solution {

    public static void main(String[] args) {
        String[] targets = new String[] {
                "K", "Q", "J", "10", "9", "8", "7", "6", "5", "4", "3", "2", "1"
        };
        Solution solution = new Solution();
        LinkedList<String> res = solution.solution(targets);
        if(res != null) {
            for (String s : res) {
                System.out.print(s + " ");
            }
        }
    }

    private LinkedList<String> solution(String[] targets) {
        if(targets == null || targets.length == 0) {
            return null;
        }

        LinkedList<String> targetQueue = new LinkedList<>();
        LinkedList<String> srcQueue = new LinkedList<>();
        for (String target : targets) {
            targetQueue.offerLast(target);
        }

        while (!targetQueue.isEmpty()) {
            if(!srcQueue.isEmpty()) {
                srcQueue.offerFirst(srcQueue.pollLast());
            }
            srcQueue.offerFirst(targetQueue.pollLast());
        }

        return srcQueue;
    }
}
```

#### 12.4.1.3. 大文件分片上传怎么做的？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.1.4. 为什么选用 FastDFS？

##### 1）分布式文件系统

![1647397927726](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647397927726.png)

1. 随着文件数据的越来越多，通过 tomcat 或者 nginx 虚拟化的静态资源文件，在单一的一个服务器内已经存不下了，如果用多个节点存存储又不利于管理和维护，所以，需要一个系统来管理多台计算机节点上的文件数据，这个系统就是分布式文件系统。
2. 分布式文件系统，是一个允许文件，通过网络在多台节点上分享的文件系统，多台计算机节点，共同组成一个整体，为用户提供更大的文件存储空间。
3. 优点是：
   - 1）海量文件数据存储。
   - 2）文件数据高可用（冗余备份）。
   - 3）读写性能好和支持负载均衡。

##### 2）Fast DFS

1. Fast DFS，是一个开源的轻量级的分布式文件系统，用于对文件进行管理，包括：文件存储、文件同步、文件上传、文件下载等。
2. 解决了大容量存储和负载均衡的问题，特别适合以文件为载体的在线服务，比如相册网站、视频网站等。

#### 12.4.1.5. 那为什么不选其他的呢，你还知道 FastDFS 有哪些竞品吗？

1. **HDFS**：Hadoop 的默认存储方式，主要解决并行计算中大数据存储的问题，采用分块存储技术，适用于**大文件存储**。
2. **Fast DFS**：主要是为文件上传和下载提供在线服务，支持负载均衡和动态扩容，适用于**中小文件存储**，比如用户头像、小视频等。
3. **第三方存储**：阿里云的 OSS、腾讯云的 CFS，优点是解决了 Fast DFS 的运维复杂问题，但缺点是数据存在第三方，且第三方需要收费。

#### 12.4.1.6. 讲一下数据库死锁，你是怎么解决的？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.1.7. 讲一下你这个线程池的调优？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.1.8. 讲一下线程池的调优原则？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.1.9. 讲一下你这个微服务拆分？

见《[2.1.1.1. 项目自我介绍？](#2.1.1.1. 项目自我介绍？)》。

#### 12.4.2.0. 你们的微服务上线过程是怎么样的？

停机上线。

#### 12.4.2.1. 那有没有不停机的方案？

灰度发布：

1. 通过修改 Nginx 集群的反向代理配置，比如从 10%，到 20%，等等，逐步引导流量反向代理到微服务集群。
2. 同时就不能用 Gateway 服务网关了，这时需要结合 Feign 拦截器，增加集群内流量标识，下沉 filter 过滤逻辑到每个服务实例中。

#### 12.4.2.2. 反问 - 为什么加面四面？

说了不知道，应该是交叉面。

#### 12.4.2.3. 反问 - 交叉面是换部门了吗？

说了没有换，只是不同组而已。

#### 12.4.2.4. 反问 - 那面试通过了之后是取您这边新组吗？

说了应该不会去他那组。

#### 12.4.2.5. 反问 - 飞书文档 OT 一致性协同算法是自研的，还是调包的？

说了是自研的。

#### 12.4.2.6. 反问 - 这个岗位主要负责哪些内容？

说了word、excel、wiki等不同的域，具体的遮遮掩掩的没细说2.

#### 12.4.2.7. 反问-飞书文档产品为什么需要 1w 多个开发？

说了是公司机密。

#### 12.4.2.8. 反问 - 飞书文档的商业模式？

说了有企业端运营，也有 Sass 化收费。

