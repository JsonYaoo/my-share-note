## 十七、背背佳

| 维度     | 背熟部分                                                     |
| -------- | ------------------------------------------------------------ |
| 项目     | 自我介绍、项目细节、项目亮点                                 |
| 网络基础 | TCP、UDP、网络七层模型、HTTP 、Cookie、Session、HTTPS        |
| 加解密   | 消息摘要、对称加密、非对称加密、数字签名                     |
| 操作系统 | 进程、线程、核心态、用户态、死锁                             |
| 设计模式 | 单一职责、里氏替换、依赖倒置、接口隔离、迪米特、开闭、动态代理 |
| Java     | ArrayList、HashMap、ConcurrentHashMap、ThreadLocal、ThreadPoolExecutor、Queue、Synchronized、CAS、Volatile、AQS 原理、JDK 新特性、Lambda |
| Spring   | IOC 原理、Spring 启动原理、SpringBoot  自动装配、Spring MVC 原理、AOP 原理、Spring @Transactional 原理、Eureka 原理、Feign 拦截原理 |
| Dubbo    | 核心组件、架构图、Provider 服务注册原理、Consumer 服务引用原理、调用原理 |
| MyBatis  | 查询原理、插件原理                                           |
| Netty    | epoll、I/O 多路复用、NIO、主从 Reactor、零拷贝机制           |
| JVM      | 运行时数据区、类加载、双亲委派、垃圾回收算法、垃圾收集器、性能调优 |
| MySQL    | 锁、事务 ACID、MVCC、索引 B+ 树、Explain、SQL 调优、主从复制、分库分表 |
| Redis    | 常用数据结构、布隆过滤器、事务 ACID、过期策略、淘汰策略、分布式锁、RDB、AOF、高可用架构、数据库缓存双写一致性 |
| 消息队列 | 生产端可靠性投递、消费端幂等性消费、高可用架构、Kafka 日志存储原理 |
| 云原生   | Docker 架构图、K8S 架构图                                    |
| 分布式   | CAP、BASE、分布式事务、分布式 ID、分布式限流、分布式会话、分布式一致性算法、分布式搜索 |

### 1> 项目

#### 1、自我介绍

面试官你好，我叫姚超松，2019 毕业于广东工业大学，读的是电子信息工程专业，毕业秋招到了美的集团 - 美云智数事业部 - 供应链部门。

1. 首先是，推广 SRM 到比亚迪，我主要是负责交付单模块的全栈开发，以及造过一些轮子，比如：
   - 1）一是，分片上传文件，实现广告类交付单视频材料的断点续传。
   - 2）二是，对接一个邮件队列，实现异步邮件的投递。
   - 3）三是，为团队搭建了一个代码发布平台，中间还解决过 CPU 占比 95% 的问题。
2. 第二块是，SASS 产品的研发，前期主要是负责品质云的业务开发，后期用了 SpringCloud 拆分出 4 个微服务，来降低负载、提高系统可用性，除了这些，中间印象比较深的还有：
   - 1）一是，通过 SQL 调优，提效条码出库接口 96%，解决超时的问题。
   - 2）二是，通过细节的对比，定位出 BUG 并解决，然后用分布式锁，做单点定时的方式兜底，紧急解决了成品出货不了，导致仓库堆积的问题。
3. 第三块是，集团的 GSRM 研发，这个系统是在 19 年从 EBS 给重构过来的，拆了 20 几个微服务，数据库分了 8 主 8 从，某些表又做了水平的拆分，我主要做了几件事：
   - 1）一是，采用线程池并发方式查询，结合 Redis 缓存热点数据、异步收集接口日志，提效给 PLM 提供的配套接口 52%，最后压测可以顶住单机 2500 左右的并发。
   - 2）二是，用 Kafka 解耦，实现分片广播式定时，用比如责任链、享元等设计模式组织代码，高效、优雅地生成供应商画像，使得生成时间从 3 h 32 min，降低到只要 8 min 18 s。
   - 3）还有就是实际生产过程中，碰到的几类事故问题的解决，比如线程池调优、数据库死锁分析、内存溢出调优这些。

=> 以上，就是我的一些资料，请问有什么细节需要补充吗？

#### 2、项目细节

##### 1）GSRMC

1. **微服务模块**：

   | 模块名 | 模块业务 | 备注                                                         |
   | ------ | -------- | ------------------------------------------------------------ |
   | BASE   | 基础数据 | 字典、物料、采购分类、研发分类等主数据                       |
   | POS    | 生命周期 | 寻源、资质审查、现场评审、供方生效、信息变更、黑名单管理、质保金管理、供方退出、失效等供应商主数据 |
   | PERF   | 考核绩效 | 供方送货不合格、交期、品质、服务考核 -> 考核会影响绩效（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | QUO    | 比例管理 | 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配比例（也叫配额） -> ERP根据比例决定供货数量 |
   | BID    | 集采招标 | BID 招标定价，给物料定价 -> 一揽子价格                       |
   | PRICE  | 价格管理 | 生效之后，研发工程师在 PLM 分解POM，核价员估价，给定价做参考、线下定价以及BID 招标定价，给物料定价 -> 一揽子价格 |
   | CON    | 电子合同 | 电子合同模块，签署框架协议，合作时要遵守的规则               |
   | -      | -        | 还有ESB 交易数据、JOBS/TASK 定时任务、MIP 审批流程、SYNC 数据同步、INDEX 指标工作台等非核心业务模块 |

2. **主要业务流程**：

   1. 研发工程师在 PLM 根据业务，创建新物料 ITEM，跟 SRM 的采购分类进行关联。
   2. 然后选定采购分类和需求图纸等信息，在供应商库中做**寻源匹配**。
   3. 寻源完毕后，送样到供应商 GSC 进行初步**估价**。
   4. 然后 SRM 根据**资质**和价格进行筛选。
   5. 筛选通过后，PLM 进行试用，SRM 对供应商生产环境进行**现场评审**。
   6. 评审通过后生成供应商品类 ASL，此后就可以按照比例进行批量供货了。
   7. 其中， SRM 可以对供方送货不合格、交期、品质、服务等进行考核 -> 考核会影响**绩效**（品质、成本、综合水平绩效） -> 绩效影响分级 -> 绩效（大头）与分级影响比例（QUO） -> 也可按规则分配**比例**（也叫配额） -> ERP根据比例决定供货数量。
   8. 送货完毕后，SRM 需要对品类进行**核价**，包括招标转定价、意向价、直接定价、线下议价等方式。
   9. 最后走价格审批，把价格同步到 ERP，每月 25 号对上个月进行结算。

   => 总的来说，SRM 就是负责供应商从生到死的生命周期管理，以及物料价格和供货数量管理，也就是寻源到生效、需求到生产、定价到付款三个方向的业务。

3. **主要用到的技术组件**：

   | 组件                    | 作用                                                         | 部署           |
   | ----------------------- | ------------------------------------------------------------ | -------------- |
   | Vue + I-View            | 前端                                                         | 8 Apache       |
   |                         | 负载均衡                                                     | F5、Nginx      |
   | SpringCloud             | Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Zipkin 做链路追踪，Config 做配置中心、Stream+Bus 做消息驱动 | 126 应用服务器 |
   | Sharding JDBC + MyBatis | Sharding JDBC 分表，MyBatis ORM 映射                         | 126 应用服务器 |
   | MySQL                   | 数据库                                                       | 8 主 8 从      |
   | MongoDB                 | 文档数据库                                                   | 3 主备         |
   | Redis、Redisson         | 缓存中间件                                                   | 3 主备 + 哨兵  |
   | Kafka、ZK               | 消息中间件                                                   | 3 集群架构     |

4. **分表与分片规则的设置**：

   | 分表                   | 数据量     | 表注释             | 数据库 | 分片规则               |
   | ---------------------- | ---------- | ------------------ | ------ | ---------------------- |
   | srm_sys_items_submeter | 3280.19 w+ | 物料表             | BASE   | ${organization_code}   |
   | srm_sys_item_cates_sub | 1613.38 w+ | 物料采购分类关系表 | BASE   | ${organization_code}   |
   | srm_sys_item_keycs     | 2153.11w+  | 物料研发分类关系表 | BASE   | ${organization_code}   |
   | srm_po_receive_det     | 3.0813 E+  | 采购接收表         | PRICE  | ${period_month / year} |
   | srm_po_line_locations  | 1.0220 E+  | 一揽子价格表       | PRICE  | ${bu_code}             |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 126 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块           | 数量              | CPU           | 内存               | 硬盘  |
   | -------------- | ----------------- | ------------- | ------------------ | ----- |
   | 前端 Apache    | 8                 | 4 C           | 16 G               | 50 G  |
   | Eureka         | 3                 | 1 C           | 1 G                | 10 G  |
   | BASE           | 13                | 8 C           | 16 G               | 100 G |
   | POS            | 19                | 8 C           | 16 G               | 100 G |
   | PERF           | 7                 | 8 C           | 16 G               | 100 G |
   | QUO            | 6                 | 8 C           | 16 G               | 100 G |
   | BID            | 3                 | 8 C           | 16 G               | 100 G |
   | PRICE          | 13                | 8 C           | 16 G               | 100 G |
   | CON            | 6                 | 8 C           | 16 G               | 100 G |
   | ESB            | 5                 | 8 C           | 16 G               | 100 G |
   | JOBS           | 9                 | 8 C           | 16 G               | 100 G |
   | TASK           | 5                 | 8 C           | 16 G               | 100 G |
   | MIP            | 4                 | 8 C           | 16 G               | 100 G |
   | SYNC           | 5                 | 8 C           | 16 G               | 100 G |
   | INDEX          | 3                 | 8 C           | 16 G               | 100 G |
   | 其他模块       | 25                | 8 C           | 16 G               | 100 G |
   | MySQL          | 16（8 主 8 从）   | 32 C          | 128 G              | 3 T   |
   | MongoDB        | 3                 | 8 C           | 16 G               | 500 G |
   | Redis          | 3                 | 8 C           | 32 G               | 100 G |
   | Kafka          | 3                 | 8 C           | 16 G               | 100 G |
   | 报表导出 OSS   | 文件数： 500 / 天 | 数据量：10 G  | 增长量：300 M / 天 | -     |
   | 供应商附件 OSS | 文件数：10 w / 年 | 数据量：200 G | 增长量：200 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

   `gc.log`：

   ![1648004562016](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648004562016.png)

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2）云化项目

1. **微服务模块**：（品质云）

   | 模块名 | 模块业务     | 备注                                                |
   | ------ | ------------ | --------------------------------------------------- |
   | BASE   | 基础数据模块 | 字典、IDM 用户、权限、系统附件、企业、客户、组织等  |
   | OEM    | 代工生产模块 | OEM 供方成品下线、抽检、出库等                      |
   | APP    | 综合模块     | SPC 过程检验，PQC  半成品检验、OQC 成品出货检验等   |
   | JOBS   | 定时任务模块 | 包括数据中台、PSI、QMS、GSC、GSRM、MES 等的数据同步 |

2. **品质云主要业务流程**：

   1. 供方原材料上线，MES 进行来料检测后，会走到各制程工序。
   2. 在每个制程工序的 CTQ 品质关键点上，会进行相应的 SPC 过程检验。
   3. 然后，还在工序的检验岗位上，进行对应的 PQC 半成品检验。
   4. 最后，在成品准备入库出货前，则进行 OQC 成品出货检验。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，还需要进行对应的彩箱、大箱、地台板条码的绑定操作后，才能进行后面的入库出货操作。

   => 总的来说，品质云就是实时管控供方生产的**品质质量**。

3. **进销存云主要业务流程**：

   1. 接收到 GSC 供应商门户 的采购订单，就在进销存为供方生成对应的销售订单。
   2. 然后根据物料 BOM 信息，生成后续的生产订单。
   3. 在生产前，获取原材料时，可以直接在原材料仓进行扣减，也可以发起原材料的采购订单，进行补充原材料。
   4. 在生产完工后，会创建生产入库单，把成品送入成品仓，更新供方成品库存。
   5. 其中，对于 OEM 供应商，由于是代工生产，成品下线时，品质会把彩箱、大箱条码传入进销存，进销存再做对应的地台板绑定、销售出库、以及推送物流平台。

   => 总的来说，进销存就是用来实时管控供方的**库存情况**。

4. **数据中台主要业务流程**：数据中台，主要承担物料、ASL、寻源品质进销存的一些统计工作。

5. **主要用到的技术组件**：

   | 组件             | 作用                                                         | 部署         |
   | ---------------- | ------------------------------------------------------------ | ------------ |
   | Vue + Element UI | 前端                                                         | 8 Nginx      |
   |                  | 负载均衡                                                     | F5、Nginx    |
   | SpringCloud      | 微服务拆分后，Eureka 做服务注册，Feign 做服务通信，Ribbon 做负载均衡，Sleuth+Skywalking+ELK 做链路追踪，Config 做配置中心，Gateway 做服务网关 | 应用服务器   |
   | SpringBoot       | 微服务拆分前，还是单体应用                                   | 3 应用服务器 |
   | MyBatis          | MyBatis ORM 映射                                             | 3 应用服务器 |
   | MySQL            | 数据库                                                       | 1主          |
   | Redis、Jedis     | 缓存中间件                                                   | 3 主 3从集群 |

6. **表数据量**：

   | 分表                        | 数据量    | 表注释         | 系统 | 分片规则               |
   | --------------------------- | --------- | -------------- | ---- | ---------------------- |
   | qc_oem_order_line           | 1200 w+   | 成品下线表     | QC   | 手工按日期分片备份旧表 |
   | qc_oqc_item_standard_value  | 1500 w+   | 物料抽检标准表 | QC   | 手工按日期分片备份旧表 |
   | oem_external_mes_colorcode  | 722.26 w+ | MES 条码表     | QC   | 无分片                 |
   | psi_base_packing_relation   | 315.28 w+ | 箱包关系表     | PSI  | 无分片                 |
   | psi_prd_pallet_box_relation | 250.03 w+ | 板箱关系表     | PSI  | 无分片                 |
   | psi_base_barcode            | 314.67 w+ | 下线条码表     | PSI  | 无分片                 |
   | psi_sales_stock_out         | 840.58 w+ | 销售出库表     | PSI  | 无分片                 |
   | cloud_gsrm_item             | 38.61 w+  | 物料表         | DC   | 无分片                 |
   | cloud_gsrm_asl              | 31.63 w+  | ASL 物料表     | DC   | 无分片                 |
   | mcc_company_info            | 1321      | 企业统计表     | DC   | 无分片                 |
   | mcc_deliver_receive_sum     | 2.24 w+   | 企业下线出库表 | DC   | 无分片                 |
   | mcc_order_quotation_sum     | 342       | 企业寻源报价表 | DC   | 无分片                 |

7. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 14 个服务。
   - **数据库**：监控显示，16 C、64 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 3                | 4 C          | 16 G              | 50 G  |
   | Eureka           | 3                | 1 C          | 1 G               | 10 G  |
   | BASE             | 3                | 8 C          | 16 G              | 100 G |
   | APP              | 3                | 8 C          | 16 G              | 100 G |
   | OEM              | 3                | 8 C          | 16 G              | 100 G |
   | JOBS             | 2                | 8 C          | 16 G              | 100 G |
   | MySQL            | 1 主             | 16 C         | 64 G              | 3 T   |
   | Redis            | 6                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

8. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

##### 3）比亚迪 SRM

1. **微服务模块**：

   | 模块名 | 模块业务       | 备注               |
   | ------ | -------------- | ------------------ |
   | APP    | 前端控制器模块 | Controller，6 台   |
   | MID    | 业务处理模块   | Service，7 台      |
   | RPORT  | 报表模块       | 报表导出，6 台     |
   | NGINX  | 前端模块       | WEX5、Jquery，2 台 |

2. **主要业务流程**：

   1. 定时同步云平台 SAP 需要的基础信息，比如采购订单、采购金额、采购数量等到 SRM，按照履行模板和规则，生成相应的履行计划和付款计划。
   2. 通过履行计划触发，生成交付、验收、结算对应节点的订单与待办信息，通知对应的责任人进行审批或者验收。
   3. 通过迁移线下交付单到线上，完成各类的无纸化交付，交付单审批通过后，会推进下一个节点的履行计划和付款计划。
   4. 通过付款计划触发，生成发货款、到货款、调试款、验收款、上线款、完工款等多种款项的待办，通知对应的责任人进行审批或者结算。

   => 总的来说，就是通过交付单推进履行计划和付款计划，来数字化线下供方结算与付款流程。

3. **主要用到的技术组件**：

   | 组件                | 作用             | 部署          |
   | ------------------- | ---------------- | ------------- |
   | JQuery + Element UI | 前端             | 2 Nginx       |
   |                     | 负载均衡         | 2 Nginx       |
   | Spring MVC + Tomcat | 后端应用         | 19 应用服务器 |
   | MyBatis             | MyBatis ORM 映射 | 19 应用服务器 |
   | Oracle              | 数据库           | 1 主          |
   | Redis、Jedis        | 缓存中间件       | 3 主备 + 哨兵 |
   | RabbitMQ            | 消息中间件       | 3 镜像集群    |

4. **表数据量**：

   | 分表          | 数据量     | 表注释              | 系统   | 分片规则 |
   | ------------- | ---------- | ------------------- | ------ | -------- |
   | SAP_CDHDR     | 6.39 E+    | PO 单增量表         | 云平台 | 无需分片 |
   | SAP_EKPO      | 4019.80 w+ | PO 行表             | 云平台 | 无需分片 |
   | SAP_ZMMSSBM03 | 1544.27 w+ | PO 描述表           | 云平台 | 无需分片 |
   | SAP_EKKO      | 1147.68 w+ | PO 币种表           | 云平台 | 无需分片 |
   | SAP_ZEKKO     | 965.70 w+  | PO 寻源表           | 云平台 | 无需分片 |
   | PR / PO       | 1948.13 w+ | 采购需求 / 采购订单 | SRM    | 无需分片 |

5. **服务器（虚拟机）的配置**：

   - **微服务**：基本每个虚机部署 2~3 个模块，平常 CPU 10%，内存 60%，所以一共注册了 21 个服务。
   - **数据库**：监控显示，32 C、128 G、3 T，平均响应时间 15ms，平均 30% CPU 利用率，内存利用率 75%。

   | 模块             | 数量             | CPU          | 内存              | 硬盘  |
   | ---------------- | ---------------- | ------------ | ----------------- | ----- |
   | 前端 Nginx       | 2                | 4 C          | 16 G              | 50 G  |
   | APP              | 6                | 8 C          | 16 G              | 100 G |
   | MID              | 7                | 8 C          | 16 G              | 100 G |
   | RPORT            | 6                | 8 C          | 16 G              | 100 G |
   | Oracle           | 1                | 32 C         | 128 G             | 3 T   |
   | Redis            | 3                | 8 C          | 16 G              | 100 G |
   | 文件存储 FASTDFS | 文件数：1 w / 年 | 数据量：20 G | 增长量：20 G / 年 | -     |

6. **应用的 JVM 参数**：

   ```bash
   -Xmx1000m -Xms1000m -Xss256k -Dgen_data_center_id=0 -Dgen_machine_id=2
   ```

   单体时，翻车更改为：

   ```bash
   -Xmx5000m -Xms5000m -Xmn1000m ...
   ```

#### 3、项目亮点

| 系统       | 亮点清单          | 关键词                                                       |
| ---------- | ----------------- | ------------------------------------------------------------ |
| GSRMC      | PLM 配套接口      | Around 切面注解、Kafka + MongoDB 、MD5  + AES、多线程 + Future、Redis、Jmeter |
|            | 供应商画像同步    | 缓存型线程池、工厂 + 建造者 + 责任链、EsJob + Kafka + MongoDB、线程池调优 |
|            | 线程池调优        | 线程池源码、调优原则                                         |
|            | 死锁问题排查      | 意向锁、间隙锁、可重复读、并发                               |
|            | 内存溢出排查      | MAT、POI、ArrayList                                          |
| Sass 产品  | 条码销售出库      | Druid 监控、SQL 调优、Redis                                  |
|            | 品质云微服务拆分  | SpringCloud                                                  |
|            | 校验失败问题      | 分布式锁、QMS Client Json 对比、问题排查                     |
| 比亚迪 SRM | 大文件上传        | FastDFS、Redis List                                          |
|            | 邮件发送组件      | 线程池 + RabbitMQ + 定时任务                                 |
|            | 发版平台 CPU 过高 | Tomcat Manager、ELK、CPU 95%                                 |

STAR 法则，是情境（Situation）、任务（Task）、行动（Action）、结果（Result）四项的缩写，是一种讲述自己故事的方式，或者说，是一个清晰、条理的作文模板，合理熟练运用该法则，可以轻松的描述事情的逻辑方式，表现出分析与问题的逻辑性、条理性和逻辑性。

1. Situation：情境，本次事件是在什么情况下发生的。
2. Task：任务，在本次事件中，主要负责什么任务。
3. Action：行动，在本次事件中，针对这些情况的分析，采用了什么样的行动。
4. Result：结果，本次事件最后的结果是怎么样的，以及学到了什么。

| 举例 | 内容（大一辩论比赛获得冠军）                                 |
| ---- | ------------------------------------------------------------ |
| S    | 系里一共有 5 支队伍，实例...，我们小组...                    |
| T    | 熟悉辩论流程，掌握辩论技巧，获得系冠军                       |
| A    | 自己主动整理资料，组织小组学习流程，编制训练题，小组训练，根据每个人的特点，分配任务（要尽量详细，包括当中遇到的困难是什么，怎么解决的） |
| R    | 获得系辩论赛冠军                                             |

##### 1）PLM 配套接口 | 分表、并发、Redis

1. **背景 Situation**：供应链体系管理专员反馈，他们在 PLM 建送样申请单时，由于物料配套没有**自动匹配**，导致经常选错配套人员，然后就要撤回、修改、重新提交，影响业务流程效率。

2. **任务 Task**：所以他们希望在 PLM 上，根据物料就可以**自动匹配** SRM 品类分工中的**配套专员信息**，方便他们走业务流程。

3. **行动 Action**：

   1. 接口的实现逻辑大体是这样的，根据 ITEM_CODE + ORG_CODE 找对应分表的采购分类，找不到就根据 ITEM_CODE 找全部库存组织分表的采购分类，再找不到的话就认为要去查物料试用表了，以当前作为试用 P 编码找到对应转正后的编码，然后重走一遍上面逻辑，找到后就合并按照 BU_CODE + 特征名称 + 特征值 + 研发分类 ID，查找研发分类中的采购分类，然后根据采购分类查找品类分工表中的配套人员信息，去重后返回即可。

      ![1644903196224](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644903196224.png)

   2. 接口实现比较复杂，其中需要优化的点有：

      - 1）第一，接口日志要做统一的收集。
      - 2）第二，接口要做安全性校验。
      - 3）第三，接口要查询所有的库存组织的采购分类分表。
      - 4）第四，接口需要频繁按照 ORG_CODE 查找 BU_CODE。

4. **结果 Result**：所以我当时优化的手段就是：

   - 1）第一，写了一个 Around 类型的切面注解，对公共的日志收集逻辑进行了提取，然后把收集到的日志投递到 Kafka 中，再由消费者插入到 MongoDB，这种做法的好处是，使得日志收集逻辑解耦了业务代码，同时异步收集的话经过测试，对比同步插入还有一定的性能提升。
   - 2）第二，安全性校验这边统一采用的是 MD5 对整个请求体生成摘要，SRM 需要重新生成一遍，然后与传过来的比对是否一致，一致才认为请求体没被修改过，然后再根据缓存中的 AES 秘钥进行解密，得到真正的请求 JSON 串。
   - 3）第三，使用线程池多线程并发的方式，查询每个采购分类分表，通过 FutureTask 监听汇总所有的采购分类编码，对比串行查询有一定的性能提升。
   - 4）第四，由于 ORG_CODE 与 BU_CODE 是那些不怎么会改变的数据，所以通过使用了 Redis 对这些关系进行了远端缓存（使用 Guava Cache 重启可能会导致缓存雪崩，且数据量过大还会占用应用内存，本身也才 2 G，所以放 Redis 中，虽然增多了一次 I/O 这也是可以接受的），使得多次请求只会获取一次库存事业部关系，对比批量查询时有一定的性能提升。 

##### 2）供应商画像同步 | 架构、设计模式、Kafka

1. **背景 Situation**：
   1. 业务方需要一个页面，可观地展示出供应商各维度的一个画像，包括抬头展示它的**基本信息**，词云浓缩它的**肖像标签**，动画展示它自美的引入以后所走的一些**历程**，对接天眼查展示对应它的一些企业经营风险，柱状图展示它历年的**招投标**、**红黄牌**以及**采购金额**的数量，折线图展示它历年的**考核**和**绩效**的趋势，饼图展示它的**分级**和**供货编码**的占比情况，用来横向、纵向辅助对比找出优质供方。
   2. 允许数据延迟，可以每隔 15 天同步一次。
2. **任务 Task**：这样，要做的东西就有，在 TASK 模块的定时任务触发时，要一一查找每家供应商的 POS 供方生命周期库的基本信息、红黄牌、获奖以及供货编码信息，查找 BID 招标库的历年招标信息，查找 PERF 考核绩效库的历年考核、绩效以及分级信息，查找 PRICE 价格库的采购金额信息，对接天眼查找告警风险，最后再根据规则组装出要展示的肖像标签。
3. **行动 Action**：当时有几种方案，
   - 1）第一种就是，1 个定时器，负责同步所有供应商的上述所有维度的信息，优点是实现简单，不用做其他的架构设计，缺点是如果同步实现的话一个事务完成所有工作，任意一处异常则全局回滚，如果异步实现的话，由于是单点触发定时任务，还是会有单台机器负担过重的问题。
   - 2）第二种就是，10 个定时器，每个定时器只负责同步所有供应商的某个维度的信息，优点是可以分为 10 台机器分别触发定时，避免了单台机器负担过重，缺点是一个定时器一个事务，还是会出现任意一处一处则全局回滚，以及定时器过多，管理麻烦。
   - 3）第三种就是，1 个定时器 + 分布式消费，定时器只负责找出要生成画像的供应商编码，封装成消息，扔到 Kafka 上，自己不负责画像的生成，而是交给消费者去进行处理，消费者每次消费一个消息，相当于生成一个供应商的画像，这样做的好处就是，定时逻辑和画像生成逻辑解耦，1 个定时器即可完成任务，要管理维护的地方少，然后就是，画像生成的效率取决于 Partition 和机器的数量，能够充分利用集群多实例部署的优点，还有就是，即使某次供应商画像生成失败了，可以不进行手工 ACK，下次再从 Kafka 里拿消息出来进行重复消费即可。
4. **结果 Result**：所以，当时就采用了第三种方案，在实现时又有几个优化点：
   - 1）第一就是，还是没能解决由于一个供应商所有维度处于同一个事务，出现异常时的全局回滚问题，解决方案就是，通过线程池的方式异步实现，每个线程一个事务，只完成一个维度的信息同步，这样即使某个回滚了也不影响全局。
   - 2）第二就是，由于一共有 10 个维度的信息要同步，就需要 10 个 Callable 任务给线程去执行，所以就抽象了公共的接口。
   - 3）第三就是，由于任务较多，所以就采用了工厂 + 建造者 + 责任链来串联式地组织任务，而且到了后期，由于是责任链的组织方式，就可以根据业务组合出很多种画像的同步方案出来，体现了灵活性。
   - 4）第四就是，由于任务与任务间，经常有重复的信息要查询，所以就对这个接口分为了同步式实现和异步式实现的抽象类，业务只需要继承抽象类实现对应的业务即可，同步式实现主要是为了在一开始给执行链设置公共上下文，避免重复查询，异步式实现则是交给线程池去执行，在要拿那些”重复“信息时只需要去上下文中获取即可。
   - 5）第五就是，某次消费异常，也就是执行链中某个节点异常，其堆栈信息需要对其进行合理记录，方便后面排查问题，解决方案就是，通过如果有任务异常后，那么就收集放到执行链上下文中，返回时再统一地打包成对象，存放到 MongoDB 上。
   - 6）最后，这样设计和实现，用 Kafka + 线程池，保证了分布式高性能消费，用 Kafka + 异常时不手工 ACK 来重复生成画像，保证可靠性，用 MongoDB 记录异常日志，保证异常排查的便捷性。

##### 3）线程池调优 | 线程池、源码、调优

1. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
2. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
3. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的，但改成一次切换又可以了，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
4. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 0，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
5. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。

##### 4）死锁问题排查 | 间隙锁、可重复读、并发

1. **背景 Situation**：在现场评审优化了一版上线后，DBA 反馈说，POS 数据库因为有大量死锁，导致数据库不断地重启，并且也把问题的 SQL 给发了出来，是一条删除语句导致的：

   ```sql
   DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3;
   ```

2. **任务 Task**：然后我们很快就定位到代码，找到了以下逻辑：方法传入一个 `List<DTO>`，先是获取第一行的  locale_review_id `${localeReviewId}`，对满足 locale_review_id= `${localeReviewId}` 的都进行删除，完成删除后，再批量插入 locale_review_id= `${localeReviewId}` 的 `List<DTO>` 数据：

   ```java
   int flag=0;
   Long localeReviewId=new Long("1");
   for (AuditEvidenceDto auditEvidenceDto : list) {
       if (auditEvidenceDto.getEvidenceId()!=null){
           flag=1;
           localeReviewId=auditEvidenceDto.getLocaleReviewId();
       }
   }
   HashMap<String,Object>params =new HashMap<>();
   if (flag==1){
       params.put("localeReviewId",localeReviewId);
       params.put("categoryCode",list.get(0).getCategoryCode());
       params.put("reviewType",list.get(0).getReviewType());
       auditEvidenceService.deleteFlag(params);
   }
   if(!"Y".equals(list.get(0).getAttribute1())){
       list.sort(Comparator.comparing(AuditEvidenceDto::getFileType));
       auditEvidenceService.batchInsertAuditEvidence(list);
   
   }
   ```

3. **行动 Action**：

   1. 对于这种写法，首先，在代码里做业务逻辑操作，肯定是不对的，当时事态紧急，也没有做过多的分析，最直接的解决思路就是，找到对应的同事，让他把 Controller  `delete` 和 `insert` 操作都放入一个 Service 中，用同一个事务管理，做一个紧急发版看下能否解决。

   2. 发了新版后，好像问题是解决了，但是结合 `show engine innodb status`，就分析出在并发场景下，还是会死锁的问题，步骤是：

      1. 先在表中先插入几条数据，然后给 locale_review_id 加普通索引（而在表全新，且没有数据时，有没有索引都会加一个行 X 锁，然后也会出现下面的情况）。
      2. 然后，事务 1 对 locale_review_id=3 的记录进行删除，则会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁。
      3. 同理，事务 2 再对 locale_review_id=3 的记录进行删除，也会先获取一个表级的 IX 锁，然后由于记录不存在，而对 （负无穷，13）、（13，正无穷）上一个间隙锁，由于间隙锁不冲突，所以事务 2 不会等待。
      4. 接着，事务 1 再插入  locale_review_id=3 的记录时，由于已经存在事务 2 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
         - 在插入行之前，会设置一种称为**插入意图的间隙锁**，表示插入的意图，即如果插入到同一索引间隙中的多个事务未插入到间隙内的同一位置，则它们无需相互等待，是不冲突的。
         - 而如果发生重复键错误，则会在重复索引记录上设置**共享锁**，并且如果另一个会话已经拥有排他锁，那么如果有多个会话尝试插入同一行，则使用共享锁可能会导致**死锁**，比如说后面分析的那种情况。
      5. 同理，事务 2 再插入  locale_review_id=3 的记录时，由于已经存在事务 1 的间隙锁，所以需要等待它释放，才能获取到插入意图的间隙锁。
      6. 此时，就发生了死锁，即事务 1 持有间隙锁，同时等待事务 2 的间隙锁，事务 2 也持有间隙锁，同时等待事务 1 的间隙锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 2 的事务，让事务 1 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      ```sql
      -- 使得 show engine innodb status; 能展示锁的信息
      set GLOBAL innodb_status_output_locks=ON;
      -- 查看事务锁持有情况
      show engine innodb status;
      ```

      | 步骤 | 事务 1                                                       | 事务 2                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |
      | 3    |                                                              | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |
      | 4    | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 5    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); |
      | 6    |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    | 插入成功                                                     |                                                              |

   3. 所以，这种方案也不是万全之策，然后我们重新考虑新的方案，其思路是打算先把一开始的死锁给复现出来，再做解决方案的分析。

   4. 不久后，场景就被模拟出来了，那是 `delete` + `insert` 在不同事务中导致死锁的发生，具体的步骤是：

      1. 事务 1 执行删除，但未提交，由于 locale_review_id=3 的记录已经存在，所以在 locale_review_id=3 行上了排他锁，此时该行的主键 ID 也是等于 3，即 ID=3。
      2. 然后，事务 2 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 2 进入等待。
      3. 同理，事务 3 打算插入 ID=3 的记录，由于 ID=3 的记录已经存在，发生了主键重复错误，所以需要请求 ID=3 行的共享锁，而又由于 ID=3 行上存在排他锁，所以事务 3 也进入等待。
      4. 接着，事务 1 提交，ID=3 的行记录被标记为删除状态（这些标识为删除状态的记录，会后续由后台的 Purge 操作进行物理删除，但是，此时还是会在索引中存放一段时间），ID=3 上的排他锁被释放。
      5. 然后，事务 2、3 就成功抢到了共享锁，打算执行插入操作，由于已经存在事务 3 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 2 进入等待。
      6. 同理，由于已经存在事务 2 的共享锁，所以需要等待它释放，才能获取到插入意图的间隙锁，事务 3 也进入等待。
      7. 此时，就发生了死锁，即事务 2 持有共享锁，同时等待事务 3 的共享锁，事务 3 也持有共享锁，同时等待事务 2 的共享锁，如果没有外力作用，它们都将无法推进下去，而在 MySQL 5.6.26 上模拟则是，自动回滚了事务 3 的事务，让事务 2 顺利得推进下去，成功插入 locale_review_id=3 的记录。

      | 步骤 | 事务 1                                                       | 事务 2                                                       | 事务 3                                                       |
      | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
      | 1    | SET AUTOCOMMIT = 0; START TRANSACTION;                       | SET AUTOCOMMIT = 0; TRANSACTION;                             | SET AUTOCOMMIT = 0; START TRANSACTION;                       |
      | 2    | DELETE FROM srm_reiew_audit_evidence WHERE locale_review_id = 3 AND REVIEW_TYPE = 3; |                                                              |                                                              |
      | 3    |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |                                                              |
      | 4    |                                                              |                                                              | INSERT INTO test.srm_reiew_audit_evidence (EVIDENCE_ID, locale_review_id, FILE_TYPE,...) VALUES (3, 3, '3'...); 等待中 |
      | 5    | COMMIT;                                                      |                                                              |                                                              |
      | 6    |                                                              |                                                              | DEAD LOCK；Auto Roll Back                                    |
      | 7    |                                                              | 插入成功                                                     |                                                              |

   5. 面对以上的分析情况，解决方案有两个，第一个方案是，在后面批量插入前，先把 ID 给置为 NULL，利用自增机制去设置 ID，避免两个 `insert` 语句同时插入同一个位置，但问题是，`delete` 在释放排他锁后，两个 `insert` 语句都会执行成功，会比正确结果多出来一条记录，所以此方案放弃。

   6. 第二个方案是，把 `delete` + `insert` 的操作，转换为 `update` 操作，则可以避免上述死锁的发生，通过。

4. **结果 Result**：最后我们就是通过第二个方案，把这段有问题的代码，又重新优化了一遍，解决了这种死锁的问题。

##### 5）内存溢出排查 | MAT、POI、ArrayList

1. **背景 Situation**：生产的一台 POS 服务器宕机了，由于配置了 `-XX:+HeapDumpOnOutOfMemoryError`，所以崩溃时导出了对应的 hprof 文件。

2. **任务 Task**：导入 hprof 到 MAT，分析应用崩溃的原因。 

3. **行动 Action**：

   1. MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，一个 Tomcat 的线程使用了 78.58% 的堆大小，共 1.2 GB。

      ![1646412309344](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646412309344.png)

      ![1646413204478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413204478.png)

   2. 然后，查看 List Objects -> with outgoing references，观察一个占据了 22.68% 内存的 ArrayList 的保留集，发现它引用了 27.69 w 个元素，估计是某个 SQL 查了太多元素导致。

      ![1646413486175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413486175.png)

   3. 所以，就继续查看堆栈信息，定位问题代码，是一个 Service 实现类的 `setData()` 方法。

      ![1646413368891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413368891.png)

   4. 原来，是调用了 Controller 的 `downloadItemDailyCapacityTemplate()` 方法，看了下业务含义，大概的意思是，在导出日常产能预测模板时，由于把产能表每日信息的查询结果，放入到了上面所说的那个 27.69 w 个元素的 ArrayList 中，然后再遍历这个列表，调用 POI#API 在内存中生成 excel，但由于堆内存只配置了 `-Xmx=2048m`，所以导致了内存溢出！

      ![1646413877943](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646413877943.png)

4. **结果 Result**：因此，解决方案是，持有这么大的 ArrayList 时，不应该把 excel 还写入内存中，而是遍历过程中，先把 excel 一点一点写入到磁盘，释放掉这个 ArrayList 后，再读取磁盘的 excel 文件的字节流，写入到 response 输出流中，或者直接扩大堆内存大小 `-Xmx=4096m `，从而解决堆内存溢出的问题。 

##### 6）自研 @DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源

1. **背景 Situation**：生产 JOBS 模块，采购金额汇总导出接口报错：同一线程不允许切换数据源读写类型，定位到报错的代码位置，发生在 `@DataSource` 自研注解，的管理器 `DataSourceClusterManager` 中的一个段逻辑代码上：

   ```java
   private static final ThreadLocal<DataSourceThreadInfo> dataNodeInfo = new ThreadLocal();
   
   public static void set(String nodeName, boolean readOnly) {
       if (StringUtils.isBlank(nodeName)) {
           nodeName = getDefaultNode();
           if (StringUtils.isBlank(nodeName)) {
               throw new RuntimeException("系统未配置缺省数据节点");
           }
       }
   
       DataSourceThreadInfo nodeInfo = (DataSourceThreadInfo)dataNodeInfo.get();
       if (nodeInfo != null) {
           if (!StringUtils.equals(nodeName, nodeInfo.getNodeName())) {
               throw new RuntimeException("同一线程不允许切换数据源");
           } else if (readOnly != nodeInfo.isReadOnly()) {
               throw new RuntimeException("同一线程不允许切换数据源读写类型");
           }
       } else {
           dataNodeInfo.set(new DataSourceThreadInfo(nodeName, readOnly));
       }
   }
   ```

2. **任务 Task**：分析逻辑代码就可以知道，是因为在设置注解属性 `readOnly` 时，发现和已有的 `readOnly` 不等，比如 `true != false`，然后就想到是存储这些属性的 `ThreadLocal` 变量，在上一次使用完的线程，没清除掉这些变量，就被下一个接口复用了，从而导致的问题发生，经过各种实验，也证明了确实是这个原因。

3. **行动 Action**：

   1. 至于问题的解决，首先还是看发生问题的业务代码，它把一些查询封装成了 Lambda 表达式，然后调用了数据源切换工具类的方法，丢给线程池去执行。

   2. 问题就在于这个 Lambda 表达式中，比如先调用 `DataSourceThreadInfo.set("srmpos"，true)`，然后调用 mapper 接口查询数据库，最后在却没有在释放掉线程本地变量，导致另一个接口复用这个线程时设置 `DataSourceThreadInfo.set("srmpos"，false)` 报错。

   3. 然后，查找了整个系统这些问题代码，发现很多都没作释放的，此时最好的方案要么是 AOP，要么是代理。

   4. AOP 的话，由于没有很好的一个切点表达式，因为如果只找那些打了 `@DataSource` 注解的 service 或者 mapper，那么就会漏掉一些直接 `DataSourceThreadInfo.set(..)` 设置的，这也正是为什么之前配了 `DataSourceAfterAspect` 切面，还是会发生这个问题的原因所在，所以这个方案放弃。

      ```java
      @Aspect
      @Component
      @Order(0)
      public class DataSourceAfterAspect {
          /**
           * 数据源处理完后清理
           * @param joinPoint
           */
         @After("@within(com.midea.mcomponent.mybatisplus.datasource.DataSource) || @annotation(com.midea.mcomponent.mybatisplus.datasource.DataSource)")
          public void after(JoinPoint joinPoint) {
              DataSourceClusterManager.clean();
          }
      }
      ```

   5. 代理的话，可以在切换工具类的 `queryMethod.query(params)` 方法调用后，通过在 `finally` 中实现线程本地变量的释放。

      ```java
      //  baseNode 数据源 线程池
      public static <V> Future<V> executeSrmBaseQuery(QueryMethod<V> queryMethod, Object... params) {
          return executeSrmBase.submit(() -> {
              try {
                  return queryMethod.query(params);
              } finally {
                  DataSourceClusterManager.clean();
              }
          });
      }
      ```

4. **结果 Result**：最终，发版测试，没问题后上线，最终解决问题。

##### 7）条码销售出库 | 索引调优、生产问题

1. **背景 Situation**：OEM 供应商反馈，系统响应扫码速度过慢，专门用手机计时，记录延迟有 4.55 s，扫码枪扫完一整板的货，系统才开始对异常条码报错，导致如果一板出现问题条码的话，就需要这一整板重新扫过，才能找出问题条码，影响了供方出货的效率。

2. **任务 Task**：当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，根据视频中的操作速度，大概是 4~5 个 / 1s，所以也就是并发数为 5 * 2 = 10 的 QPS，分摊到 3 台服务器的话，每台服务器需要让接口满足 300 ms 以下的延迟，因此，在不增加服务器的情况下，尽量让接口的延迟足够低。

3. **行动 Action**：根据供方提供的截图，找到对应的接口，然后在测试环境模拟跑一遍接口，把接口路过的 SQL 日志都收集起来，统一分析，最终发现有几处索引是没有添加的，分别是：

   1. **psi_base_barcode**：条码表，314.67w+，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 1000 ms 左右，优化后 Druid SQL 监控显示 35 ms 左右。

      ```sql
      -- 1）彩箱条码信息表
      -- a. 已是主键，加索引没提升
      ALTER TABLE psi_base_barcode ADD INDEX psi_base_barcode_n3(OEM_REPORT_ID);
      -- b. 已是主键，加索引没提升
      ALTER TABLE psi_base_barcode ADD INDEX psi_base_barcode_n1(OEM_REPORT_NO);
      -- c. 联合主键，加索引有提升：提效96.51%
      ALTER TABLE psi_base_barcode ADD INDEX psi_base_barcode_n2(CUS_COMPANY_CODE, PRODUCT_CODE);
      ```

   2. **psi_base_packing_relation**：箱包关系表，315.28w，16 c 64 G MySQL， 优化前 Druid SQL 监控【执行时间】显示 950 ms 左右，优化后 Druid SQL 监控显示 32 ms 左右。

      ```sql
      -- 1、判断条码箱包关系：增加索引【CARTON_BARCODE】有提升95.08%
      SELECT RELATION_ID, LAST_UPDATED_BY, CREATED_BY_IP, LAST_UPDATED_BY_IP, LAST_UPDATE_DATE, CREATION_DATE, VERSION, ORG_ID, DELETE_FLAG, CREATED_BY, COLOR_BOX_AMOUNT, CARTON_BARCODE, BARCODE
      FROM psi_base_packing_relation
      WHERE (CARTON_BARCODE = '331100007920401110191W');
      
      -- 2、判断条码是否为1包1条码：增加索引【BARCODE】有提升95.08%
      SELECT RELATION_ID, LAST_UPDATED_BY, CREATED_BY_IP, LAST_UPDATED_BY_IP, LAST_UPDATE_DATE, CREATION_DATE, VERSION, ORG_ID, DELETE_FLAG, CREATED_BY, COLOR_BOX_AMOUNT, CARTON_BARCODE, BARCODE
      FROM psi_base_packing_relation
      WHERE (BARCODE = '331100007920401110191W' AND COLOR_BOX_AMOUNT = 1);
      ```

   3. **psi_sales_stock_out**：已出库条码表，840.58w，16 c 64 G MySQL，优化前 Druid SQL 监控【执行时间】显示  2290ms 左右，优化后 Druid SQL 监控显示 40 ms 左右。

      ```sql
      -- 4、判断条码是否已出库：增加【CARTON_BARCODE】和【BARCODE】索引提升98.25%
      SELECT COUNT(1)
      FROM psi_sales_stock_out
      WHERE (CARTON_BARCODE = '331100007920401110191W' OR BARCODE = '331100007920401110191W');
      
      -- Add Index： explain => index_merge，Using union(psi_sales_stock_out_n1,psi_sales_stock_out_n2); Using where
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n1(CARTON_BARCODE);
      ALTER TABLE psi_sales_stock_out ADD INDEX psi_sales_stock_out_n2(BARCODE);
      ```

4. **结果 Result**：最终通过使用 Druid 监控，发现关键 SQL 的耗时已经满足要求了，psi_base_barcode 提效 96.51%，psi_base_packing_relation 提效 95.08%，psi_sales_stock_out 提效 98.25%。

##### 8）品质云微服务拆分 | 微服务、架构、设计

1. **背景 Situation**：

   1. 当时，OEM 供方有 2 个，日班和夜班一共有 2 条产线，不能停线的那种，此时如果品质这块有新需求要发，就需要工厂停线，等我们发版、验证通过了才能继续生产，对于大家来说其实都不好。
   2. 而且，由于是单体， OEM 生产功能与其他零部件供方的 SPC、PQC、OQC 的代码统统在一块，导致系统的负载比较高，常常是能看到 3 台服务器，每台 CPU 和内存都过 60%，有时遇到生产高峰以及定时器触发的话，会出现半夜电话报障说，应用宕机了，需要紧急重启的情况。

2. **任务 Task**：所以出于上面说的诉求，以及加上对未来供方不断上线，当时就规划了对各单体云，进行微服务拆分，共用一个注册中心和配置中心，其中就由我来负责品质云的微服务落地。

3. **行动 Action**：

   1. 我这边拆了 4 个业务模块（2 个月左右），分别是 BASE 基础数据模块，主要是一些字典、用户权限、企业、客户、组织等基础业务。
   2. OEM 代工生产模块，也就是上面所说的主要诉求点，包括成品下线、抽检、出库等业务，把这块生产线相关的业务剥离出去，可以做针对性的优化以及灵活的发版处理。
   3. 而剩余的其他业务，都统统放 APP 综合模块，与单体时的业务基本保持不变，主要是零部件供应商的 SPC 过程检验、PQC 半成品检验、OQC 成品出货检验等业务。
   4. JOBS 定时任务模块，则是后来继续剥离的一个模块，剥离这个模块可以保证生产高峰期时，在夜间也能平滑运行，不会受到大量定时器触发，导致的负载突然增高的影响，主要是一些与外围系统数据同步等业务的处理。

4. **结果 Result**：中间遇到的难点有：

   - 1）**服务的依赖边界问题**：

     1. 在拆分时，一开始我是直接把下线扫码、抽检、出库给拆开，SPC、PQC、OQC 也都拆开，然后就发现拆得粒度过小，出现了很多相互的依赖调用，就又要去考虑，如何代价尽可能小地，去避免带来新的分布式事务和性能问题。
     2. 而最后，是根据业务诉求，以及拆分后的风险与成本的评估，才认为最好的方案应该是，下线扫码、抽检、出库这三个生产线相关的业务合回一个 OEM 模块，其他的 SPC、PQC、OQC 等不是本次诉求的业务又合回一个 APP 模块。

   - 2）**Feign 远程调用时，遇到的响应结果被统一包装的问题**：

     1. 一开始单体时的系统，是有对响应结果做 `Result` 统一包装的，其原理是实现了 `HandlerMethodReturnValueHandler#handleReturnValue()` 方法，这是在 `invocableMethod.invokeForRequest()` 方法处理完 Handler Method 并拿到结果后，调用 `this.returnValueHandlers.handleReturnValue` 对返回结果进行的一个后置处理。

        ```java
        // 统一包装
        public class ResponseBodyWrapperHandler implements HandlerMethodReturnValueHandler {
        	@Override
        	public void handleReturnValue(Object returnValue,
        			MethodParameter returnType, ModelAndViewContainer mavContainer,
        			NativeWebRequest webRequest) throws Exception {
        		_logger.info("return data is " + returnValue);
        		if (returnValue instanceof Void) {
        			returnValue = Result.DefaultSuccessResult;
        		} else {
        			if (!(returnValue instanceof Result)) {
        				returnValue = Result.build(true, ResultCode.SUCCESS_CODE, "", returnValue);
        			}
        		}
        		handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);
        	}
        }
        ```

     2. 这个包装主要是为了打印原始的响应结果，以及自定义 `retCode` 响应码和 `retMsg` 响应语，但在使用 Feign 调用后，就出现，如果使用那边 Controller 的方法返回值类型，作为这边 Fegin 接口的返回值类型，则收到的就只是一个 null，因为中间做了一层 `Result` 的包装，此时需要对其进行解码，解码的话是实现了 `feign.codec.Decoder#decode()` 方法，通过注入并使用`com.fasterxml.jackson.databind.ObjectMapper` 进行读取 body 并修改，从而实现包装的统一解码工作，避免了在业务代码中，写过多的包装解码代码。

        ```java
        // 自定义Feign解码器
        @Component
        class FeignResultDecoder implements Decoder {
        
            @Autowired
            private ObjectMapper objectMapper;
        
            @Override
            public Object decode(Response response, Type type) throws IOException, DecodeException, FeignException {
                if (response.body() == null)
                    throw new DecodeException(response.status(),  "接口没有返回有效的数据, url: " + response.request().url(), response.request());
        
                // 解析body, 得到统一包装Result实例
                Result result = objectMapper.readValue(Util.toString(response.body().asReader(Util.UTF_8)), Result.class);
                if (ResultCode.ERROR_CODE.equals(result.getRetCode()))
                    throw new DecodeException(response.status(), "接口返回错误: " + result.getRetMsg() + ", url: " + response.request().url(), response.request());
        
                // 重新解析Result#data实例并返回
                return objectMapper.readValue(objectMapper.writeValueAsString(result.getData()), TypeFactory.defaultInstance().constructType(type));
            }
        }
        ```

   - 3）**网关路由问题**：由于主要是后端进行的微服务拆分，前端基本保持不变，所以就需要在收到请求后，对原始 url 进行截断，找到对应的关键字进行服务路由，当时采用的是 Gateway 做了服务网关，其好处就是高性能、对开发友好，只需要在代码中更改路由规则即可 、以及对接注册中心，服务地址不需要经常在网关上配来配去。

   - 4）**过滤器问题**：单体时的过滤器是实现 `javax` 包下的 `Filter` 类来实现的，主要是对一些 token 做校验、给上下文设置当前用户信息等操作，但由于 Feign 调用使用的是 HTTP 请求，也会经过这一层层的 `Filter` 校验，在有了服务网关后，就在网关上做了前置的过滤，主要是实现 `GatewayFilter` 和 `GlobalFilter` 接口来完成对应的过滤，这样，服务间调用就无需走那一层层的 `Filter` 校验了，只需要在网关中被校验一次即可，从而保证远程调用时的性能问题。

##### 9）token 校验失败问题 | 分布式锁、QMS Client Json 对比、问题排查

1. **背景 Situation**：OQC 零部件供方在成品出货报告新建完毕后，需要把报告推送给 QMS，在接口联调时没有问题，但放到生产上就偶尔能推得过去，偶尔推不过去，导致供方有些成品无法继续出货，货物堆在了仓库外面，需要马上解决这个问题。
2. **任务 Task**：
   1. 根据日志记录，推不过去的原因是，品质这边的客户端，收到了 QMS 的一个异常返回结果 `token校验失败`，这就很奇怪了，token 如果校验失败的话，那么为什么有时候能够成功呢，不应该一直都是失败的吗？
   2. 然后就翻了日志，与 QMS 收到的 token 进行比对，发现确实是 token 的问题。
   3. 这个 token 呢，是根据 DTO 对象转成 json 字符串后，使用内存中 QMS 的一个序列号 `appSec` 进行 MD5 加盐，生成摘要而得到的，由于其他参数都是写"死"的，也就是问题出在，用于生成摘要的 DTO 对象与传输过去的 DTO 对象不一致！
3. **行动 Action**：
   1. 然后，我扒出了有问题的推送报文，与 QMS 收到的报文进行对比，用了在线 Json 比对工具 `www.bejson.com`，结果放入后就明显看到，QMS 收到了多余的 `NULL串` ，从而造成两边生成的 token 不同。
   2. 果然，看回代码就发现，发送给 QMS 的 json 串和用于生成摘要的 json 串的生成逻辑不一样，前者是交给 `forest.httpClient` 做 json 转换，而后者是直接用了 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 和 `ObjectMapper#writeValueAsString()` 做的生成。
   3. 在这个工具类里，ObjectMapper 实例作为成员变量，如果先调 ``ObjectMapper#writeValueAsString()` 填充好了 NULL 序列化器，那么这个 ObjectMapper 每次都会输出 `NULL串` ，而如果先调的是 `objectMapper#setSerializationInclusion(JsonInclude.Include.NON_NULL)` 设置了普通序列化器，那么这个 ObjectMapper 每次都不会输出 `NULL串`，这也是为什么 token 时对时不对的原因所在。
   4. 所以，解决方法就是，在工具类中分开两者的使用，持有一个生成 `NULL串` 的 ObjectMapper，再持有一个生成正常串的 ObjectMapper，在生成 token 时使用后者，从而解决 token 不正确的问题。
4. **结果 Result**：最后，再使用分布式锁做一个单点定时，每隔 3 分钟把推送失败的报告重新推送过去，并设置 3 次的最大重推次数，保证这个推送接口的可靠性，和业务的连续性。

##### 10）大文件上传 | FastDFS、Redis List

1. **背景 Situation**：在建广告类交付单时，要求上传大视频，以让审批人去浏览理解当前交付的广告内容。

2. **任务 Task**：当时系统文件存储用的是 FastDFS，主要是用来存储中小文件，比如用户头像、图片、附件等内容，对文件大小也是做了 200 M 的限制，当时如果要实现大视频的话，一来文件接收上限要放宽，违反了组件用来上传小文件的约定，二来，会有大文件不能续点上传的问题，所以最直接的思路就是，对上传过来的文件进行分片上传，接收到所有分片后再合并成进行大文件存储，具体的做法是：

3. **行动 Action**：

   1. 前端方面，用的是 WebUploader 组件对文件进行分片，其原理是，在获取到文件后，先计算它的一个 MD5 文件摘要，然后对其按照每 200 M 作为一个 chunk 分片，并使用序号顺序标记每个 chunk，再调用后端提供的一个接口进行上传。
   2. 后端这边，接口则接收文件名、文件 MD5 摘要值、有无分片、最大分片号、当前分片号、MultipartFile，以及一些其他辅助信息，接收到后，先是用 MD5 判断当前这个大文件是否曾经上传过，如果上传过就不再处理了，再判断 MD5 + 分片号是否存在了，存在则不再处理了，从而解决即使分片报文重复，或者前一次中断然后本次重新上传的问题，实现续点上传。
   3. 然后，调用框架 API 保存好分片，这个框架主要是对FastDFS 做了封装，把文件存到特定的位置，然后返回文件存储对象的元数据。
   4. 接着，把【分片号 + 文件ID 】顺序放入用的 MD5 值做 key 的 Redis List 中。
   5. 最后，在收到最后一个分片时，则取出 Redis 中的所有【分片号 + 文件ID 】，对分片号做一次排序，从而解决分片不按顺序到达的问题，再顺序合并所有分片成为一个大文件，调用框架 API 保存好这个大文件，拿到它的元数据存储到文件关系表中，这样，下次在下载时，则可以根据文件 ID 找到当时的元数据，再去拿存储服务器上对应路径下的大文件即可，从而完成一次大视频文件的上传和下载。

4. **结果 Result**：总的来说，就是用了 WebUploader 前端组件进行文件分片，后端则是共用同一个接口，先对分片进行缓存，然后再顺序合并成大文件，解决大文件续点上传的问题。

   ![1646294342544](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294342544.png)

   ![1646294375795](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646294375795.png)

##### 11）邮件发送组件 | 设计、RabbitMQ

1. **背景 Situation**：交付单触发待办提醒时，需要发送邮件通知对应的责任人进行处理，此时需要对接比亚迪的一个邮件服务器，进行邮件发送。
2. **任务 Task**：由于邮件发送不需要非常的及时，所以就采用了异步发送的发送，以提高性能。
3. **行动 Action**：
   1. 当时采用的方案是异步发送，接口把邮件对象丢给线程池，就返回响应客户端其他信息了，再由子线程去把邮件落库。
   2. 然后定时触发，捞取对应未发送和发送失败的邮件，进行批量发送，直连式地把消息发送到一个 `SCC_COMMON_EXCHANGE` 的 `SCC_MAIL_QUEUE` 的队列中，在收到 Broker ACK Confirm 后，则标记为发送成功，否则继续被下轮定时器触发捞取出来重新发送。
   3. 最后，由比亚迪那边的消费者进行消费，发送到邮件服务器中，完成异步邮件发送。
4. **结果 Result**：基于上述的方案，我封装了一个异步邮件发送工具类，在每次遇到需要异步发送邮件时，则调用那个工具类的对应方法即可，既方便，又解耦了业务代码，然后还拥有不错的性能。

##### 12）发版平台 CPU 占用过高 | Tomcat Manager、ELK、CPU 95%

1. **背景 Situation**：我们团队这次的迭代，需要在云平台开发几个接口，然后在和 SRM 联调测试时，为了不用等比亚迪 SAP 测试环境的发版窗口，就需要有我们自己的一个云平台测试环境，方便快速发版快速验证。

2. **任务 Task**：那时由我负责来负责搭建，但由于是在内网环境进行开发，访问不了外网，就拉取不到 Jenkins 的依赖，当然也没有云原生这些基础设施，所以采取了 Tomcat Manager + ELK 部署的方式来发版，前者是 Tomcat 的后台，可以开发完代码后导出 war 包，然后在浏览器上把 war 包进行上传部署，后者是用于在 Kibana 上观察接口的异常日志。

3. **行动 Action**：

   1. 就这样，一个简单易用的发版平台就搭建好了，不过没几天问题就来了，我们发现每一次上传 war 包到启动完成，所花的时间好像都会比上一次的要久，最后一次 war 包上传则是浏览器一直在转了。

   2. 当时为了不阻塞测试进度，就到发版平台的服务器上看，先是使用 `top` 命令看到 118243 的 Tomcat 进程，居然占用了 95.3% 的 `%CPU`：

      ![1646305025603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305025603.png)

   3. 然后使用 `top -Hp 118243 ` ，查看 Tomcat 进程的所有线程，发现最高的一个线程 `118332` 占用了 73.3% `%CPU`：

      ![1646305182797](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305182797.png)

   4. 然后使用 `printf %x 118332`，获取对应的 16 进制线程号，用于后面的 jstack 文件搜索：

      ![1646305395917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305395917.png)

   5. 然后就是 `jstack -l 118243 > thread-dump.txt `，导出对应 `118243` 进程的线程快照，打开搜索对应的 `1ef96` 16 进制线程号（这个是当时真实的线程号，上面是后期模拟的） ，就定位到了一堆 `ParallelGC` 线程，原来是 GC 太多而导致的 CPU 飚高，那么为什么一个发版的 Tomcat，会有这么多 GC 线程呢？会不会是项目代码哪里写的有问题啊？

      ![1646305627751](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646305627751.png)

   6. 然后我就使用 `jmap -dump:format=b,file=heap-dump.hproft 118243`，以 `hprof` 格式导出 `118243`  Tomcat 进程的堆内存快照，再导入到 MAT -> Leak Suspects 做内存泄露分析，然后就得到了怀疑报告：说，有 18 个 `ParallelWebappClassLoader`  共占据了 44.61% 堆空间，咦？为什么要 18 个这种类加载器呢？

      ![1646306496272](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306496272.png)

      ![1646306148994](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646306148994.png)

   7. 然后我就想起 Tomcat 的类加载过程，是打破了双亲委派机制的：

      1. **ext -> bootstarp模型**：保证了 JRE 核心类库不会被重复加载，满足了加载JVM共同类库的需求。
      2. **ext -> webapp模型**：实现了每个 web 应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离的需求。
      3. **webapp -> share -> common模型**：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了加载其他共同类库的需求。

      ![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

   8. 也就是一个 `ParallelWebappClassLoader` 对应一个 Web App 项目，但用来发版的 Tomcat 应该就只有一个项目呀，所以我就怀疑应该是每次发版没把上一版的项目卸载掉所导致的。

4. **结果 Result**：所以我就让组内的成员，大家在下次发版前，先用 Tomcat Manager 把上一个项目卸载掉，再发新的 war 包上去，这样做了后，就没碰到过这样的情况出现了，应该算是蒙对了吧~哈哈

### 2> 网络基础

#### 1.1. TCP 和 UDP 的差别？

- **TCP**，传输控制协议，是一种**面向连接的、面向字节流的、可靠的全双工传输层通信协议**，由于其首部最大长度能够达到 60 字节，所以传输效率较 UDP 的低，常用的通信协议有 HTTP、TELNET、SMTP 和 FTP 等。
- **UDP**，用户数据报协议，是一种**无连接的、面向数据报的、不可靠的传输层协议**，为应用程序提供了一种无需建立连接，就可以发送封装好了的 IP 数据包 的方法，由于其首部最大长度只有 8 个字节，所以传输效率较 TCP 的高，常用的通信协议有 DNS、RIP、DHCP 等。

#### 1.2. TCP 是如何保证可靠性传输的？

1. **确认应答和超时重传机制**：发送方发完数据后，需要等待接收方的确认应答，如果没有在规定时间内，得到该应答，那么就会重传对应报文段。

2. **检验和**：

   1. 发送方发送前，会先进行 TCP伪首部 + TCP 首部 + TCP 数据部分的二进制反码求和运算，取反后再设置到首部中的检验和字段。
   2. 接收方收到后，也会进行 TCP 伪首部 + TCP 首部 + TCP 数据部分的二进制反码求和运算，由于此时首部中的检验和字段不为空，如果求出的结果不全为 1，那么说明报文段出现了问题，则直接将其丢弃，让发送方重新发送该报文段。

3. **滑动窗口**：

   1. 发送方的发送窗口后沿，代表已发送且已被确认的数据，此时发送窗口前移，而发送窗口内的数据代表已发送且未被确认的数据，此时发送窗口保持不变。
   2. 接口方的接收窗口后沿，代表已接收的数据，此时接收窗口前移，而接收窗口内的数据代表未接收的数据，此时接收窗口保持不变。

4. **流量控制**：发送方的发送窗口不能大于接收方返回的最大接收窗口值。

5. **拥塞控制**：

   ![1645235241181](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645235241181.png)

   1. 分为慢开始、拥塞避免、快重传和快恢复，其具体原理为，发送方有一个慢开始门限和一个拥塞窗口参数：
   2. 如果慢开始门限小于拥塞窗口，则使用慢开始算法，此时拥塞窗口大小呈指数式增长。
   3. 如果拥塞窗口大小增长达到了慢开始门限，则使用拥塞避免算法，此时拥塞窗口大小呈线性增长。
   4. 如果遇到网络超时，则设置慢开始门限为原来的 1/2，并且设置拥塞窗口大小为 1，重新执行慢开始算法。
   5. 如果没有遇到网络超时，但连续收到接收方的同一个报文段的 3 个未确认的 ACK，则认为该报文确实发生了丢失，则进行重传，并设置慢开始门限为原来的 1/2，并且设置拥塞窗口大小等于慢开始门限，重新执行拥塞避免算法。

#### 1.3. 什么是 TCP 三次握手？

![1645244135614](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645244135614.png)

1. 服务端创建 TCP 进程控制块，进入 LISTEN 监听状态，等待客户端连接。
2. 客户端创建 TCP 进程控制块，准备发起 TCP 连接。
3. 第一次握手，客户端发起 SYN=1，SYN 同步号=x 的连接请求报文段给服务端，随后进入 SYN-SENT 同步发送状态。
4. 第二次握手，服务端收到客户端的连接请求报文段后，响应 ACK=1，ACK 确认号= x+1，同时携带服务端的连接请求报文段 SYN=1，SYN 同步号=y 的确认报文段给客户端，随后进入 SYN-RECV 同步接收状态。
5. 第三次握手，客户端收到服务端的确认报文段后，响应 ACK=1，ACK  确认号= y+1 的确认报文段给服务端，随后进入 ESTABLISHED 连接已完成状态，此时客户端到服务端方向的 TCP 连接已建立。
6. 服务端收到客户端的确认报文段后，也进入 ESTABLISHED 连接已完成状态，此时服务端到客户端方向的 TCP 连接也已建立，也就是一个全双工的 TCP 通信通道已完成建立。

#### 1.4. 为什么 TCP 需要三次握手？

1. 这是因为如果使用 TCP 两次握手，那么只能保证客户端到服务端方向的连接完成建立，而服务端方向到客户端方向的连接没能未完成建立。
2. 而如果使用 TCP 三次握手，那么就能保证一个全双工的 TCP 通信通道完成建立，使得发收双发同时具备发送和接收数据的能力。
3. 同时，对于已失效的报文段突然又传回给服务端的情况，即第一次握手是无效的，服务端返回的第二次握手也是无效的，客户端在收到这种无效的第二次握手后，就不会再发起第三次握手了，也就避免了多余连接的建立， 避免了资源的浪费。

#### 1.5. 什么是 TCP 四次挥手？

![1645244152507](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645244152507.png)

1. 客户端停止发送数据，准比关闭 TCP 连接。
2. 第一次挥手，客户端发起 FIN=1，FIN 终止号=u 的连接释放报文段给服务端，随后进入 FIN-WAIT1 终止等待1状态。
3. 第二次挥手，服务端收到客户端的连接释放请求后，则通知上层应用程序做好连接释放的准备，然后响应客户端 ACK=1，ACK 确认号=u+1，序列号=v 的确认报文段，随后进入 CLOSE-WAIT 关闭等待状态，而客户端在收到服务端的确认报文段后，会进入 FIN-WAIT2 终止等待2 状态，此时，客户端到服务端方向的 TCP 连接已经被释放。
4. 第三次挥手，由于服务端上层应用程序准备释放需要一定的时间开销，所以服务端还需要发起一个 ACK=1，ACK 确认号=u+1，FIN=1，FIN 终止号=w 的连接释放报文段给客户端，随后进入 LAST-ACK 最终确认状态。
5. 第四次挥手，客户端收到服务端的连接释放报文段后，则响应 ACK=1，ACK 确认号=w+1，序列号=u+1 的确认报文段给服务端，随后进入 TIME-WAIT 时间等待状态，服务端收到客户端的确认报文段后，则进入 CLOSE 关闭状态，但此时服务端到客户端方向的 TCP 连接仍未被释放，因为客户端还需要再等待 2 倍的 MSL 最大报文段寿命后，才能进入 CLOSE 状态，最终关闭该方向的 TCP 连接，完成一次 TCP 连接的释放过程。

#### 1.6. 为什么 TCP 需要四次挥手？

这是因为，前两次的挥手用于保证释放客户端到服务端方向的 TCP 连接，而后两次的挥手，用于保证释放服务端的客户端方向的 TCP 连接，所以需要四次挥手。

#### 1.7. 为什么最后客户端还需要等待 2 倍的 MSL？

1. 这是为了保证客户端能够接收到服务端 ACK+FIN 的连接释放请求报文，以及服务端能够收到客户端的确认报文，保证了服务端到客户端方向的 TCP 连接能够完成关闭。
2. 同时，对于已失效的报文段又重新回到了服务端的情况，即第一次握手是无效的，服务端返回的第二次握手也是无效的，客户单在收到这种无效的第二次握手时，就不会再发起第三次握手了，也就避免了多余连接的建立，避免了资源的浪费。

#### 1.8. TCP拆包、粘包？原因？解决方法？

- **TCP拆包**：

  - **概念**：如果要发送的数据包过大，就会被拆分成多个TCP报文分开传输，即**一个完整的包可能会被TCP拆分成多个包进行发送**。
  - **直接原因**：
    - 应用程序写入的数据大于套接字缓冲区的大小。
    - TCP报文段的数据部分长度大于MSS(536字节)，导致在IP层传输被分解成多个短的数据报片。
  - **根本原因**：网络层所收到上层交付的数据报长度，超过**数据链路层MTU（最大传送单元，默认1500字节）**，需要把过长的数据报进行IP分片处理。

- **TCP粘包**：

  - **概念**：**多个小的包可能会被TCP封装成一个大的数据包发送**。
  - **直接原因**：
    - 应用程序写入的数据小于套接字缓冲区的大小
    - 接收方不及时读取套接字缓冲区数据
  - **根本原因**：
    - **发送方原因**：TCP默认使用**Nagle算法**（通过减少必须发送包的个数，来增加网络软件系统的效率），即TCP会收集多个小分组，在一个确认到来时才一起发送，导致可能在发送方出现粘包问题。
    - **接收方原因**：TCP将接收到的数据包保存在接收缓存里，如果TCP接收数据包到缓存的速度，大于应用程序从缓存中读取数据包的数据，那么多个包就会被缓存起来，而应用程序就有可能读取到多个首尾相连粘在一起的包。
    - **TCP原因**：TCP是**面向字节流**的协议，报文格式不像UDP那样有专门的长度字段来记录实际报文的长度，交付上层的数据没有边界，导致粘包的发生。

- **解决方法**：

  最本质的原因在于**接收方无法分辨消息与消息之间的边界在哪**，因此，思路就是，通过某种方案给出边界。

  - **消息定长，空格补位**：每个消息的大小都一样，接收方只要累计接收数据，直到数据等到一个定长的指就将它作为一个消息。
  - **包尾加特殊字符作为边界**：比如FTP协议就是在包尾加上\r\n标记作为边界的。但问题在于通信双方要约定在数据正文中，不出现该特殊字符，否则会误判为消息的边界。
  - **包首部记录包体长度**：每个包首部至少包含数据包的长度，这样接收方可以通过读取包首部的长度字段，就知道每一个包的实际长度。

#### 1.9. OSI与TCP/IP模型？

![1620196369515](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620196369515.png)

> OSI七层体系协议结构概念请求、理论完整，但既复杂又不使用。
>
> TCP/IP四层体系结构使用更为广泛。
>
> 五层协议体系结构总和了OSI和TCP/IP的优点，为介绍网络原理而设计出来的。

- OSI七层模型：物理层、数据链路层、网络层、运输层、会话层、表示层、应用层
- TCP/IP四层模型：网络接口层、网际层、运输层、应用层
- 五层协议模型：物理层、数据链路层、网络层、运输层、应用层
  - **物理层**：physical layer，以**比特**为单位，负责在发送双方**传送1和0**。
  - **数据链路层**：data link layer，以**帧**为单位，负责在两个相邻结点之间的链路上**传送帧**，包括控制信息（如同步信息、地址信息、差错控制等）。
  - **网络层**：network layer，以**IP数据报**为单位，负责为在分组交换网上的不同主机提供**通信服务**。在发送数据时，把运输层产生的报文或用户数据报封装成IP数据报进行传送。
  - **运输层**：transport layer，TCP以**报文段**为单位，UDP以**用户数据报**为单位，负责向两台主机中进程之间的通信提供**通用的数据传输服务**。
  - **应用层**：application layer，以**报文**为单位，负责通过应用进程之间的交互来完成**特定网络应用**。

#### 2.0. 常见的网络服务分层示例

| 分层       | 示例                                |
| ---------- | ----------------------------------- |
| 物理层     | 中继器、集线器                      |
| 数据链路层 | 网卡、网桥、交换机                  |
| 网络层     | 路由器、防火墙、ARP、IP、ICMP、IGMP |
| 运输层     | TCP、UDP                            |
| 应用层     | HTTP、SMTP、DNS、FTP                |

- **ARP**：Address Resolution Protocol，地址解析协议，从网络层使用的IP地址，解析出在数据链路层使用的硬件地址。
- **ICMP**：Internet Control Message Protocol，网际控制报文协议，允许主机或路由器报告差错情况和提供有关异常情况的报告，可以更有效地转发IP数据报，提高交付成功的机会。
- **IGMP**：Internet Group Management Protocol，网际组管理协议，让连接在本地局域网上的多播路由器**知道**本局域网上是否有主机（即主机中的某个进程）参加或退出了某个多播组。

#### 2.1. HTTP 是什么？

HTTP，hypertext Transfer Protocol，超长文本传输协议，是一个**通常运行在TCP之上的**应用层协议，定义了浏览器怎么向万维网服务器请求万维网文档以及服务器怎么把文档传送给浏览器。

- **事务**：指一系列的信息交换是一个不可分割的整体，即要么所有的信息交换都完成，要么一次交换都不进行。
- **无连接**：指通信双方在交换HTTP报文之前不需要先建立HTTP连接。
- **无状态**：指同一个客户第二次访问同一个服务器上的页面时，服务器的响应与第一次访问时的相同（假设不会更新）。

#### 2.2. HTTP协议/1.0/1.1/2.0？

- **HTTP/1.0**：
  - **概述**：每一个请求建立一个TCP连接，请求完成后立马断开连接（**短连接**）。
  - **缺点**：
    - **连接无法复用**，每次请求都要经历三次握手和慢启动，导致在并发量大的情况下服务器的压力负担大，以及带宽无法被充分利用。
- **HTTP/1.1**：
  - **概述：**多个http请求可以复用一个TCP连接，使用Connection Header（close/keep-alive）来区分**短/长连接**。服务器按照FIFO原则来处理不同请求。
  - **缺点**：在同一时间，针对同一域名下的请求有一定的限制，超过限制数目的请求会被阻塞。
- **HTTP/2.0**：
  - **概述**：**多路复用**（二进制帧的设计）允许同时通过单一的连接发起多重的请求-响应信息，可以很容易地去实现并行地在同一个TCP连接上双向交换信息，而不用依赖建立多个TCP连接。
  - **缺点**：普及速度慢，与HTTP1.1并存。

#### 2.3. HTTP 请求报文有哪些方法？

| 方法    | 描述                                                     |
| ------- | -------------------------------------------------------- |
| GET     | 向特定资源发送请求，查询数据并返回实体                   |
| POST    | 向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |
| PUT     | 向服务器上传新的内容                                     |
| HEAD    | 类似于GET请求，返回的响应中没有具体的内容，用于获取报头  |
| DELETE  | 请求服务器删除特定的资源                                 |
| OPTIONS | 可以用来向服务器发送请求，来测试服务器的功能特性         |
| TRACE   | 回显服务器收到的请求，用于测试或者诊断                   |
| CONNECT | 用于代理服务器                                           |

#### **2.4. Get和Post请求区别**？

|          | GET                                                          | POST                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 可见性   | 数据在URL中，所有人可见                                      | 数据不会显示在URL中                                          |
| 安全性   | 发送的数据是URL的一部分，安全性较差                          | 参数不会被保存在浏览器历史或者web服务器日志中，安全性较好    |
| 数据长度 | 受限制，最大2KB=2^10字节                                     | 无限制                                                       |
| 编码类型 | application/x-www-form-urlencoded                            | multipart/form-data                                          |
| 缓存     | 能被缓存，会保存在浏览器的浏览记录中，URL能够被作作为书签保存 | 不能被缓存                                                   |
| 意义     | 用于向特定资源发送请求，查询数据并返回实体                   | 用于向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |

#### 2.5. HTTP常见响应状态码？

> 1xx表示通知信息，如请求收到了或者正在进行处理。
>
> 2xx表示成功，如已接受或已知道。
>
> 3xx表示重定向，如要完成请求还必须采取进一步的行动。
>
> 4xx表示客户的差错，如请求中有错误的语法或者不能完车。
>
> 5xx表示服务器的差错，如服务器失效无法完成请求。

- 100：Continue，继续，客户端应继续请求。
- 200：OK，请求成功，一般用于GET和POST请求。
- 301：Move Permanently，资源永久重定向。
- 302：Found，资源暂时重定向。
- 400：Bad Request，客户端请求的语法错误，服务器无法理解。
- 403：Forbidden，服务器理解客户端的请求，但是拒绝执行此请求。
- 404：Not Found，服务器无法根据客户端的请求找到资源。
- 500：Internal Sever Error，服务器内容错误，无法完成请求。
- 502：Bad Gateway，作为**网关或者代理服务器**尝试执行请求时，从远程服务器中接收到了无效的响应。

#### 2.6. 重定向与转发的区别？

|            | 重定向（Redirect）                                     | 转发（Forward）                                   |
| ---------- | ------------------------------------------------------ | ------------------------------------------------- |
| 地址栏路径 | 发生变化                                               | 不变                                              |
| 其他站点   | 可以访问其他站点（服务器）的资源                       | 只能访问当前服务器下的资源                        |
| 请求的次数 | 是两次请求，不能使用Request域对象来共享数据            | 是同一次请求，共享同一个Request域对象             |
| 效率       | 速度慢                                                 | 速度快                                            |
| 执行主体   | web容器，在同一个web容器中转发，对于客户端来说是透明的 | 客户端，服务器返回302状态码，客户端执行重定向操作 |

#### 2.7. Cookie与Session的区别？

|          | Cookie                                                       | Session                                                      |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 共同点   | 用来跟踪浏览器用户身份                                       | 用来跟踪浏览器用户身份                                       |
| 位置     | 保存在客户端（浏览器）                                       | 保存在服务端                                                 |
| 安全性   | 不是很安全，可以分析本地的Cookie进行欺骗                     | 较安全                                                       |
| 作用     | 一般用来保存信息                                             | 记录用户的状态                                               |
| 产生机制 | 服务器通过设置响应头提示浏览器生成或者直接使用客户端脚本产生，然后请求时可以发送给服务器 | 客户端请求时，一般服务器会创建JSessionId标识，存放session值到散列表中 |

#### 2.8. 在浏览器输入URL再回车确认后发生了什么？

URL判断、DNS查询、TCP连接、浏览器发起HTTP请求、服务器处理并响应HTTP请求、浏览器渲染页面

| 过程              | 过程                                                         | 使用的协议 |
| ----------------- | ------------------------------------------------------------ | ---------- |
| 1、URL判断        | 浏览器判断URL是否合法                                        | 无         |
| 2、DNS查询        | 浏览器查找DNS得到域名对应的IP地址，查找过程：浏览器缓存 -> 操作系统缓存 -> 路由器缓存 -> DNS缓存 -> 域名服务器 | DNS        |
| 3、TCP连接        | 根据IP地址与端口建立TCP连接                                  | TCP        |
| 4、HTTP请求       | 浏览器向服务器发送HTTP请求                                   | HTTP       |
| 5、响应HTTP请求   | 服务器处理并响应HTTP请求                                     | HTTP       |
| 6、浏览器渲染页面 | 浏览器接收HTTP响应并渲染页面                                 | 无         |

#### 2.9. HTTP请求与响应报文格式？

![1620215152917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620215152917.png)

- **开始行**：用于区分是请求报文还是响应报文。在请求报文中的开始行叫做**请求行**，在响应报文中的开始行叫**状态行**。开始行的**三个字段都以空格隔开**，最后的“CR”与"LF”分别代表"回车"和“换行”。
  - 请求报文：方法、URL、版本
  - 响应报文：版本、状态码、短语
- **首部行**：用来说明浏览器、服务器或者主体的一些信息，可以有好几行，也可以不用。每一个首部行都以CRLF结尾。在整个首部行结束时，**还有一空行将首部行和实体主体分开**。
- **实体主体**：请求包体或者响应包体。

#### 3.0. 讲一下为什么要用 Https？

##### 1、总

1. Https，Hyper Text  Transfer Protocol over SecureSocket Layer，是以安全为目标的 Http 通道，在 Http 的基础上，通过传输加密、以及身份认证，保证了传输过程的安全性。
2. Https 在证书验证阶段，使用的是安全性高的非对称加密。在内容传输阶段，使用的是速度快的对称加密，
   - 对称加密：双方持有相同的密钥，加密速度快。典型的对称加密算法有，AES 和 DES。
   - 非对称加密：密钥成对出现（私钥和公钥），加密速度慢。私钥只有自己知道，不在网络中传输。公钥可以公开，A 使用 B 公钥加密后传输给 B，B 可以使用 B 的私钥解密得到原始内容。典型的非对称加密算法有，RSA 和 DSA。

##### 2、分

其执行原理为，

1. **发起请求阶段**：首先，客户端将它所支持的算法列表，和一个用作产生密钥的随机数 1，发送给服务器。
2. **返回证书阶段**：然后，服务器从算法列表中，选择一种算法，并将它和一份包含服务器公钥的证书（即数字签名）、以及随机数 2 ，返回给客户端。
3. **证书验证阶段**：
   - 1）客户端对服务器的证书进行验证，抽取服务器给的公钥，生成一个 `pre_master_secret` 随机密码串，再使用服务器公钥，通过非对称加密，得到预主密钥，然后把它发送给服务器。
   - 2）接着，再根据预主密钥、随机数 1、随机数 2，独立计算出 MAC 密钥，作为接下来的会话密钥。
4. **服务器解密阶段**：服务器通过服务器私钥，对客户端发送过来的加密信息进行解密，得到预主密钥，与随机数1、随机数2，独立计算出 MAC 密钥，也作为接下来的会话密钥。
5. **客户端发起测试阶段**：客户端将握手消息，使用会话密钥，对称加密得到 MAC 值，发送给服务器，验证服务器，能否正常接受客户端加密后的信息。
6. **服务器响应测试阶段**：同理，服务器收到后，使用会话密钥，对称加密得到 MAC 值，返回给客户端，验证客户端，能否正常接受服务器加密后的信息。
7. **连接完成阶段**：如果客户端能够接受，则再返回确认报文，SSL 层建立完成，可以开始 Https 对称加密传输了。

##### 3、总

最后，总结一下，Https 与 Http 的主要区别为：

| HTTP                           | HTTPS                                         |
| ------------------------------ | --------------------------------------------- |
| 默认端口 80                    | 默认端口 443                                  |
| URL 以 http:// 开头            | URL 以 https:// 开头                          |
| 明文传输、数据未加密、安全性差 | 传输过程 SSL 加密、安全性好、需要用到 CA 证书 |
| 消耗资源少、响应速度快         | 消耗资源多、响应速度慢                        |

=> 以上，就是我对 Https 的一些理解，请问有什么细节需要补充的吗？

### 3> 加解密

#### 1.1. 常见签名与加密相关用语？

##### 1. 转义

转义字符能使其开头的序列具有不同于普通字符数列的语义。常见作用有：

- 如果不进行转义就可能与语法规定的某些**内容产生混淆**，所以某些内容需要转义。如Java的转义字符"\\"，用来区分字符串中，哪些是分割符，哪些是字符本身。
- 字符引用，用于转义键盘录入的字符，如字符串中的回车符和换行符，使其不可见，从而更容易表达其他内容。

##### 2. 编码解码

编码是采用一种新的载体来表示前一个载体所表达的信息，本质上是信息形式的转换，并没有保密的作用（因为编解码算法是公开的），目的是将信息转换成统一的格式，方便在不同系统中传输。

eg：信息 -> 编码 -> 二进制 -> 解码 -> 信息

*如果解码之后无法正确还原原来所表达的信息，此时就出现了**乱码**。通常是因为选用的解码和编码方式不同所导致的。*

常见编码类型有：

- **文本文件编码**：
  - 作用：将文本内容编码为**二进制数据**，以实现二进制数据进行存储或者传输的目的。
  - 相关技术：ASCII（1字节）、ISO8859-1、GBK（汉字2字节）、GBK2312、UTF-8（汉字0到4字节）、UTF-16、UTF-32等。
- **可打印字符编码**：
  - 作用：将二进制数据编码为**可打印的字符**，以实现通过可打印字符的形式进行存储或者传输的目的。
  - 场景：Web场景（图片）、公钥证书、电子邮件附件等（因为ASCII码128~255字符不可见，不方便路由传输）。
  - 相关技术：HEX、Base64等。
    - HEX：16进制字符，只有字母A~F，4位一组。
    - Base64：a-zA-Z0-9+=，64个字符，6位一组，再对照ASCII码表。

![1620302838656](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620302838656.png)

```java
        // 1、编码技术: 很多消息摘要、加解密算法都是针对二进制的
        try {
            // Base64编码: Q0FG => 6位一组, 3 * 8 = 4 * 6, 压缩率比HEX高, 可能会出现+、=符号
            String base64Str = Base64.getEncoder().encodeToString("CAF".getBytes("ASCII"));
            System.err.println(base64Str);

            // Base64解码: CAF
            String base64Org = new String(Base64.getDecoder().decode(base64Str), "ASCII");
            System.err.println(base64Org);
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }
```

- **URL编码**：
  - 作用：通过使用安全的字符去表示不安全字符从而达到适合传输的目的。
  - 场景：作为URL参数时：中文、空格、&、？、=

##### 3. 消息摘要

- 作用：为了校验**信息的完整性**，保证信息在传输过程中不被篡改。
- 场景：校验密码是否正确、校验下载文件是否完整无损。
- 相关技术：MD5（32字符16字节定长）、SHA、SHA256等。
- 特点：无法逆推、（优秀的Hash算法）结果定长、碰撞率低、相同输入相同输出、不同输入输出千差万别。
- 缺点：简单的摘要可通过穷举、撞库的方式得到原文，因此需要加盐增加算法的安全度。

```java
        // 2、消息摘要: 16字节, MD5、SHA, 哈希的算法, 单向的不能逆推, 优秀的哈希产生的结果是定长的, 碰撞率比较低, 少量Hash就千差万别
        // 作用: 用于验证原消息是否有改变、不同输入不同输出、相同输入相同输出、在数字签名中可以用来证明消息没被别人篡改过
        String input = "hello world";

        // MD5国内一般都使用HEX格式编码, 但事实上Base64也可
        System.err.println(MD5(input));// HEX是一个字符占4位, 16个字节, 共32个字符 => 5EB63BBBE01EEED093CB22BB8F5ACDC3
        System.err.println(MD5(MD5(input) + "加盐"));// MD5加盐(随机字符串), 极大加强安全性: 1FEED1AECF760C313879517FA3A8F2B6
        System.err.println(SHA1(input));// HEX是一个字符占4位, 20个字节, 共40个字符 => 2AAE6C35C94FCFB415DBE95F408B9CE91EE846ED
        System.err.println(SHA256(input));// HEX是一个字符占4位, 32个字节, 共64个字符 => B94D27B9934D3E08A52E52D7DA7DABFAC484EFE37A5380EE9088F7ACE2EFCDE9
```

```java
// MD5消息摘要
    public static String MD5(String str) {
        try {
            MessageDigest md5 = MessageDigest.getInstance("MD5");// 算法类型
            md5.update(str.getBytes("UTF-8"));// 字符集
            byte[] digest = md5.digest();// MD5范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA1不太安全
    public static String SHA1(String str) {
        try {
            MessageDigest SHA1 = MessageDigest.getInstance("SHA");
            SHA1.update(str.getBytes("UTF-8"));
            byte[] digest = SHA1.digest();// SHA1范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA256比较安全
    public static String SHA256(String str) {
        try {
            MessageDigest SHA256 = MessageDigest.getInstance("SHA-256");
            SHA256.update(str.getBytes("UTF-8"));
            byte[] digest = SHA256.digest();// SHA256范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }
```

##### 4. 加密解密

对原来的明文按照某种算法进行处理，使其成为不可读的一段代码，即密文。

- 作用：保护数据不被非法人窃取、阅读，保证发送**消息的保密性**。

- 算法类型：

  - **对称加密**：
    - 概念：加密和解密时使用的**密钥是同一个**，因此又称为共享密钥加密算法。
    - 优点：算法公开、计算量小、速度快、效率高。
    - 缺点：发送双发使用相同的密钥，密钥容易泄露，安全性较弱。
    - 相关技术：DES（速度快、容易被破解）、AES（难以被破解）等。
  - **非对称加密**：
    - 概念：加密和解密使用**不同的密钥**，包含一个公开密钥（公钥）和一个私有密钥（私钥），因此又称为公开密钥加密算法。
    - 优点：密钥成对出现，且私钥存在传输泄露的风险，大大增加了安全性。
    - 缺点：算法复杂，速度远远低于对称加密算法、不适用于数据量较大的场景。
    - 相关技术：RSA等。

  *注意点：算法类型、字符集、使用哪个密钥、编码类型*

```java
        // 3、加密算法: RSA跨平台, 不推荐使用JAVA方式(PKCS8)来生成私钥和公钥, 推荐用OPEN SSL(Git Hub)方式生成(PKCS1 | PKCS8)
        //      1) 对称加密: 收发双方约定同一个Key, Key被劫持了就不安全了
        //      2) 非对称加密: 收发双发约定一对Key, 只把一半在网上流传, 另一半不流传
        // RSA非对称加密默认使用Base64格式编码
        String publicKeyStr = "MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDTse/HAlvTdgaUn4uCFiC6o++G\n" +
                "SPQ9XN3DjBOyitzOO0atlTG68KZnhEoUMZGJ2grKgWu49xjV8XY+8AUziAZfFJ5g\n" +
                "LXN/e9QuJ+yLm7hPfEmOAZorGLLxUV1ms266RqD9V9l2UJGlmVqo4ZV9pRnbxW8a\n" +
                "7sh2iR/2pIM5p3atiwIDAQAB";
        String privateKeyStr = "MIICdwIBADANBgkqhkiG9w0BAQEFAASCAmEwggJdAgEAAoGBANOx78cCW9N2BpSf\n" +
                "i4IWILqj74ZI9D1c3cOME7KK3M47Rq2VMbrwpmeEShQxkYnaCsqBa7j3GNXxdj7w\n" +
                "BTOIBl8UnmAtc3971C4n7IubuE98SY4BmisYsvFRXWazbrpGoP1X2XZQkaWZWqjh\n" +
                "lX2lGdvFbxruyHaJH/akgzmndq2LAgMBAAECgYEAgKkZeNNXKdsGvteEu4hlVeoC\n" +
                "zpOSVaUWZx3Abvf0oSbnmuIdOme+SxXczA8gTC8H9fHYna8YGhdJ7ZCFKL+YVqA3\n" +
                "y3ytx3VPcUR/DIexfsUKTQwxWbmwFOXjimHd1EOWglhP16jX+JqJdcYO8WUDaYJY\n" +
                "fII+52w4IBqXQzV0ROECQQDsjP6eVx+ocT3vPWKuO4k68xNIbJYv0rI6OUirq+iW\n" +
                "fEyt+qQg46p7cVcwjVy+smTEOcALljGp3qvBF+c9cEgbAkEA5RnFOnG4OWfEkzPF\n" +
                "bJPqZ49E59Yt6Gh0EC163IzFtirB/GMumrT70Gs1vItrZb8iYuhaK1uZB0lJLJPB\n" +
                "ppdnUQJBAKVa2hHtbR/eKSE3k+efjoo6qNwTq9i6PAQfTwFSJkArm55yepDTFLU9\n" +
                "wWkbKB3VrkLM68Yts4G/Oei8wNRdzMkCQE6LwE/iTzv3NLEXLdek+teYihJGHyUw\n" +
                "MqKdRSM6bEqhbDKguoi2BiOVri2/SwnuNtbcPJXi6JtT5++NlPYNsJECQAsU+Ama\n" +
                "zDNyx8oq/s/JmB/jk6HmNMUaujsBd4N3yvO9awaLEgeghD02lIa0smd9qgqLVhm8\n" +
                "rl0xPQV91p5pcFU=";

        // 如果不采用读文件的, 需要手动清理IDE加的"\n"
        publicKeyStr = publicKeyStr.replace("\n", "");
        privateKeyStr = privateKeyStr.replace("\n", "");

        String rsaEncryptStr = rsaEncrypt(input, toPublicKey(publicKeyStr));
        System.err.println(rsaEncryptStr);// UdYxJbZirWPDAHhIaTLA4q6jrdh0MWNu+OFZaAP5rZqvR9Vzynl53uyUe6OisyRxHS++q8EnHu6hEaFGdJNimuZ99yo0Lpq8AxudlUd7j9JvFd2EmAo+phA1KnC+SHn1BOF6qYVymhjxnsWnB2IHACIcFhWcHinC7txSVjZHQo0=
        String rsaDecryptStr = rsaDECRYPT(rsaEncryptStr, toPrivateKey(privateKeyStr));
        System.err.println(rsaDecryptStr);// hello world
```

```java
// Java生成RSA非对称加密公钥对象
    public static PublicKey toPublicKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(bytes);// 公钥统一标准X509编码
            return keyFactory.generatePublic(x509EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java生成RSA非对称加密私钥对象
    public static PrivateKey toPrivateKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(bytes);// JAVA私钥只能读PKCS8格式
            return keyFactory.generatePrivate(pkcs8EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

   // RSA非对称加密
    public static String rsaEncrypt(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.ENCRYPT_MODE, key);// 加密模式
            byte[] bytes = str.getBytes("UTF-8");// 字符集
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // RSA通常使用Base64编码
            return Base64.getEncoder().encodeToString(doFinal);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        }

        return null;
    }

    // RSA非对称解密
    public static String rsaDECRYPT(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.DECRYPT_MODE, key);// 解密模式
            byte[] bytes = Base64.getDecoder().decode(str);// RSA通常使用Base64编码
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // 这里采用UAT-8字符集
            return new String(doFinal,"UTF-8");
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }

        return null;
    }
```

##### 5. 数字签名

- 作用：身份认证发送方，具有消息的不可抵赖性，同时保证消息的完整性。
- 相关技术：消息摘要算法 + 加密解密算法。

```java
        // 4、数字签名: 散列+加密 = 消息摘要 + 非对称加密
        //      1) 证明消息没被别人篡改过 => 消息摘要
        //      2) 证明确实是发送方发过来的 => 非对称加密, 使用自己的私钥加密消息
        String sign = rsaSign(toPrivateKey(privateKeyStr), input);
        System.err.println(sign);// PDhFYAx3FSIajHFYwP35PInipQxmFA/qtuCJXPALOoUf2nZlIC3Xt9qfSK/hovhhXBIuOSReTnKLCHDuvXJ0rfNVC1SqO4yYl5PXeiHgOjUj18VLxKyId0H9Z4+L47Uhb3JSsNv+X8trE6Q4dDj29xjVeVEBkfsKYdqjc8QxSPQ=
        boolean res = rsaVerifySign(toPublicKey(publicKeyStr), input, sign);
        System.err.println(res);// true
```

```java
    // Java利用MD5WithRSA实现数字签名, 一定要用自己的私钥进行数字签名
    public static String rsaSign(PrivateKey privateKey, String str) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initSign(privateKey);// 初始化私钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] sign = signature.sign();// 数字签名范围到此为止
            return Base64.getEncoder().encodeToString(sign);// 通常数字签名使用Base64编码
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java利用MD5WithRSA实现数字验签, 一定要用对方的公钥进行验签
    public static boolean rsaVerifySign(PublicKey publicKey, String str, String sign) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initVerify(publicKey);// 初始化公钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] bytes = Base64.getDecoder().decode(sign);// 通常数字签名使用Base64编码
            return signature.verify(bytes);// 数字验签范围到此为止
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return false;
    }
```

#### 1.2. 数字签名与数据加密的区别？

- **数字签名**：

![1620308002223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620308002223.png)

1. 发送方先使用Hash函数对将要发送的明文生成**消息摘要**。
2. 发送方使用**自己的私钥**签名消息摘要，生成**已签名的消息摘要**。
3. 发送方把将要发送的**明文**和**已签名的消息摘要**，一起发送给接收方。
4. 接收方再使用**发送方的公钥**对收到的**已签名的消息摘要**进行验证，验证通过可以得到原始的消息摘要。此步验证了**发送方的身份**。
5. 接收方使用相同的Hash函数对收到的**明文**生成**消息摘要**，与解密出来的消息摘要进行比对，判断两者是否一致。此步验证了**消息的完整性**。

- **数据加密**：

（基于大质数分解数学原理的非对称加密，一般大的数值对作为私钥，小的数值对作为公钥）

![1620305224976](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305224976.png)

![1620305447877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305447877.png)

1. 发送方先生成一个**对称密钥**，使用此密钥将对称加密将要发送的明文，生成密文。
2. 发送方使用**接收方的公钥**非对称加密上述生成的**对称密钥**，生成加密后的密钥。
3. 发送者将**密文**与**加密后的密钥**（*成为数字信封*），一起发送给接收方。
4. 接收者使用**自己的私钥**解密加密后的密钥得到原始的**对称密钥**，再用该对称密钥解密密文，得到真正的明文。

- **数字签名与数据加密的区别**：（共同点：都使用了公开密钥体系）

|                    | 数字签名                                                     | 数据加密                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 加密方式（发送时） | 使用发送方的私钥                                             | 使用接收方的公钥                                             |
| 解密方式（接收时） | 使用发送方的公钥                                             | 使用接收方的私钥                                             |
| 映射关系           | 一对多，只有拥有私钥的才能代表发送，任何拥有公钥的人都可以解密 | 多对一，任何拥有公钥的人都可以加密发送，只有拥有私钥的才能解密成功 |
| 使用的算法         | 非对称加密                                                   | 对称加密明文、非对称加密**对称密钥**                         |
| 作用               | 保证发送的消息的**完整性、身份认证和不可抵赖性**             | 发送的消息的**保密性**                                       |

### 4> 操作系统

#### 1.1. CPU、内存、外存、操作系统、应用程序、进程、线程、协程、管程、超线程？

在计算机中：

- **CPU**：是核心的硬件资源，承担所有的计算任务。
- **内存**：承担运行时数据的保存任务。
- **外存**：承担数据外部永久存储的任务，如硬盘等。
- **操作系统**：统领计算任务的调度、资源的分配。
- **应用程序**：是存放在硬盘中的可执行文件，主要包括代码指令和数据，以进程的形式运行于操作系统之上，享受操作系统提供的服务。
- **进程**：是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。
- **线程**：指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。
- **协程**：是一种比线程更加轻量级的存在，一个线程可以拥有多个协程，协程没有增加线程数量，只是在线程的
  基础之上通过**分用复用**的方式运行多个协程。
- **管程**：是管理共享变量以及对共享变量的操作过程，以让它们支持并发，是一种**进程同步互斥工具**。
- **超线程**：指**在单核CPU上可以并发AB两个线程**，如果AB资源不冲突，则AB两个线程就可以并发执行；而如果AB都在访问同一个资源，那么只能等前一个线程执行完，后一个线程才能执行。

#### 1.2. 详细介绍进程的结构？

进程是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。

一般来说，一个进程由**程序段**、**数据段**和**进程控制块**三部分组成。在进程内部，代码段和数据段有自己的独立地址空间，不同进程的地址空间是相互隔离的。

- **程序段**：一般称为代码段，是进程的程序指令在内存中的位置，包含需要执行的指令集合。
- **数据段**：是进程操作数据在内存中的位置，包含需要操作的数据集合。
- **程序控制块**：Program Control Block，PCB，包含进程的描述信息和控制信息，是进程存在的唯一标志。
  - **进程的描述信息**：主要包括：
    - **进程ID**：是唯一的，代表进程的身份。
    - **进程状态**：比如运行、就绪、阻塞；
    - **进程优先级**：是进程调度的重要依据。
  - **进程的调度信息**：主要包括：
    - **程序起始地址**：即程序第一行指令的内存地址，是从这里开始程序的执行。
    - **通信信息**：进程间通信时的消息队列。
  - **进程的资源信息**：主要包括：
    - **内存信息**：内存占用情况和内存管理所用的数据结构。
    - **I/O设备信息**：所用的I/O设备编号及相应的数据结构。
    - **文件句柄**：所打开文件的信息。
  - **进程上下文**：
    - 即**进程的环境**，主要包括**执行时各种CPU寄存器的值**、**当前程序计数器（PC）的值**以及**各种栈的值**等。
    - 在操作系统切换进程时，当前进程被迫让出CPU，当前进程的上下文就保存在PCB结构中，供下次恢复运行时使用。

![1629615113218](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615113218.png)

#### 1.3. 详细介绍线程的结构？

为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，进程内部演进出了并发调度的诉求，于是就发明了线程。

线程指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。

一个标准的线程主要由**线程描述信息**、**程序计数器（ProgramCounter，PC）**和**栈内存**三部分组成。

- **线程描述信息**：也即线程的基本信息，主要包括：
  - **线程ID**：Thread ID，线程标识符，是线程的唯一标识，同一个进程内不同线程的ID不会重复。
  - **线程名称**：主要是方便用户识别，用户可以指定线程的名字，如果没有指定，系统就会自动分配一个名称。
  - **线程优先级**：表示线程调度的优先级，优先级越高，获得CPU的执行机会就越大。
  - **线程状态**：表示当前线程的执行状态，为新建、就绪、运行、阻塞、结束等状态中的一种。
  - **其他信息**：比如是否为守护线程等。
- **程序计数器**：记录着线程下一条指令的代码段内存地址。
- **栈内存**：
  - 是代码段中局部变量的存储空间，为线程所独立拥有，在线程之间不共享。
  - 在JDK 1.8中，每个线程在创建时默认被分配**1MB**大小的栈内存，其中栈内存和堆内存不同，栈内存不受垃圾回收器管理。
    - 在Java中，执行程序流程的重要单位是“**方法**”，而栈内存的分配单位是“**栈帧**”（或者叫“方法帧”）。
    - 方法的每一次执行都需要为其分配一个栈帧（方法帧），栈帧主要保存该方法中的局部变量、方法的返回地址以及其他方法的相关信息。
    - 当线程的执行流程进入方法时，JVM就会为方法分配一个对应的栈帧压入栈内存；当线程的执行流程跳出方法时，JVM就从栈内存弹出该方法的栈帧，此时方法帧的局部变量的内存空间就会被回收。
    - 由于栈帧（方法帧）的操作是后进先出的模式，这也是标准的栈操作模式，因此**存放方法帧的内存也被叫作栈内存**。

![1629615141818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615141818.png)

#### 1.4. 线程上下文切换？

- **线程上下文**：是指某一时刻**CPU寄存器**和**程序计数器**的内容，CPU通过时间片分配算法来循环执行线程，由于CPU时间片非常短，因此CPU需要通过不停地切换上下文以执行不同的线程。
- **上下文切换**：在当前任务执行完CPU时间片切换到另一个任务之前，操作系统会先保存该任务的状态（包括程序计数器、虚拟机栈中每个栈帧的信息），以便下次再切换回这个任务时，可以再加载这个任务的状态。这种**任务从保存到再加载的过程就是一次上下文切换**。
- **线程上下文切换的开销**：
  - **直接消耗**：指CPU寄存器需要保存和加载、系统调度器的代码需要执行、TLB实例需要重新加载等。
  - **间接消耗**：指多核的CPU高速缓存之间需要共享数据，间接对程序造成影响。
- **线程上线文切换的场景**：
  - **抢占式**：一般跟锁竞争有关，可以减少锁争用，来减少线程上下文切换。
    - **线程的CPU时间片已用完**：当前执行线程（任务）的**CPU时间片用完**之后，CPU会调度下一个线程。
  - **时间片轮转**：一般跟时间片有关，可以减少线程数，来减少线程上下文切换。
    - **线程被挂起**：比如调用了Thread#sleep、Thread#yield、Object#wait、LockSupport#park、synchronized、lock、阻塞式I/O等方法后。
- **如何减少线程上下文切换**：
  - **合理使用线程**：合理设置线程数目，避免创建不必要的线程，既可以最大化利用CPU，又可以减少线程切换的开销。
    - **高并发，低耗时的情况，**建议减少线程数。
    - **低并发，高耗时的情况**，建议增加线程数。
    - **高并发高耗时，**需要分析任务类型、增加排队、加大线程数等。
  - **减少锁争用**：通过设计算法来减少争抢锁的概率，比如JDK 7 ConcurrentHashMap中的**分段锁**，将ConcurrentHashMap分为多个段，每个段有自己的哈希表，线程只需要获取某段的分段锁，就可以操作该段的哈希表。这样保证线程安全的同时，还可以减少锁的争用，从而减少线程的上下文切换。
  - **无锁并发编程**：如CAS算法，通过自旋+CAS，不需要加锁也可以实现线程安全，其实现有Atomic包下的原子类、JDK 8 ConcurrentHashMap等。
  - 使用协程：通过线程的分用复用，在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

#### 1.5. 进程与线程的区别？

|              | 线程                                                         | 进程                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 目的不同     | 为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，满足进程内部并发调度的诉求 | 用于将程序装入内存，运行程序的指令                           |
| 概念不同     | 线程是“进程代码段”的一次顺序执行流程，是CPU调度的最小单位    | 进程是程序的一次启动执行，是操作系统分配资源的最小单位，一个进程由一个或多个线程组成，一个进程至少有一个线程 |
| 共享空间不同 | 各线程之间共享进程的方法区内存、堆内存、系统资源（文件句柄、系统信号等） | 进程之间是相互独立的，但进程内部的各个线程之间并不完全独立   |
| 切换速度不同 | 线程上下文切换快                                             | 进程上下文切换慢                                             |

#### 1.6. 进程的状态？

- **背景**：进程是程序的一次执行，在这个执行过程中，有时进程正在被CPU处理，有时又需要等待CPU服务，其状态会有各种变化。**为了方便对各个进程的管理**，操作系统需要将进程合理地划分为几种状态。
- **进程的几种状态**：
  - **创建态**：New，进程正在被创建，操作系统为进程分配资源、初始化PCB。
  - **就绪态**：Ready，进程已经具备运行条件，但由于没有空闲CPU，而暂时不能运行。
    - 进程处于就绪态，代表已经拥有了除处理机之外所有需要的资源，一旦获得处理机，即可立即进入运行态开始运行，即**万事俱备，只欠CPU**。
  - **运行态**：Running，进程占有CPU，并在CPU上运行。
    - 注意，单机处理机环境下，每时刻最多只有一个进程处于运行态；而双核环境下，可以同时有两个进程处于运行态。
  - **阻塞态**：Waiting/Blocked，又称等待态，进程因申请某一资源没有被分配，或者等待某一事件而暂时不能运行。
    - 比如等待操作系统分配打印机、等待读磁盘操作的结果。CPU是计算机中最昂贵的部件，为了提高CPU的利用率，需要先将其他进程需要的资源分配到位，才能得到CPU的服务。
  - **终止态**：Terminated，进程运行结束，或者由于bug导致进程无法继续执行下去（比如数组越界错误，此时需要撤销进程），此时进程需要从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。

#### 1.7. 进程状态的转换？

- **创建态 -> 就绪态**：系统完成创建进程相关的工作。
- **就绪态 -> 运行态**：进程被CPU调度。
- **运行态 -> 就绪态**：进程被分配的CPU时间片到了，或者CPU被其他高优先级进程抢占了。
- **运行态 -> 阻塞态**：等待系统资源分配，或者等待某事件的发生，属于进程的**主动行为**。
- **阻塞态 -> 就绪态**：系统资源已分配到位，或者等待的事件已发生，属于进程的**被动行为**。
  - 注意，不能由阻塞态直接转换为运行态，因为需要等待CPU的调度。
  - 也不能由就绪态直接转换为阻塞态，因为进入阻塞态是进程的主动请求，必然需要进程在运行时才能发出这种请求。
- **运行态 -> 终止态**：进程运行结束，或者运行过程中遇到不可修复的错误。

![1629536288202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629536288202.png)

#### 1.8. Java线程状态与状态切换？

Java线程的生命周期，即Java线程状态，线程在某时刻只能处于一种状态。注意！这些状态只为JVM虚拟机状态，不代表任何操作系统的线程状态。

- **NEW**：新建状态**（对应进程创建态）**，处于该状态的线程尚未启动。
  - new Thread（...）创建了线程，但未调用start（）启动线程时。
- **RUNNABLE**：可执行状态，该状态包含操作系统进程的就绪、运行两种状态。
  - **Ready**：就绪状态**（对应进程就绪态）**，仅仅代表当前线程具备运行的资格，如果线程没有被操作系统的调度程序挑选中，则会永远处于就绪状态。
    - Thread#start（）、线程的CPU时间片用完、Thread#sleep（long）、线程抢到对象锁（Object Monitor）、Thread#yield（）。
  - **Running**：运行状态**（对应进程运行态）**，调用Thread#run（）方法不一定会马上被并发执行，在线程获取了CPU时间片之后，才真正启动并发执行，此时线程进入运行状态。
- **BLOCKED**：阻塞状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且在线程抢到锁或者等待事件发生后，会回到就绪状态。
  - 线程阻塞等待锁、阻塞式I/O操作。
- **WAITING**：等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且需要被其他线程**显式地唤醒**，才会回到就绪状态。
  - 调用无时限的Object#wait（）、Thread#join（）、LockSupport#park（）时。
- **TIMED_WAITING**：限时等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且如果指定时间内没有被唤醒，限时等待的线程会被**系统自动唤醒**，会回到就绪状态。
  - Thread#sleep（long）、Object#wait（long）、LockSupport#park Nanos（long）、LockSupport#parkUntil（long）、Thread#join（long）。
  - 因此，对应进程状态可得出结论：进入BLOCKED状态、WAITING状态、TIMED_WAITING状态的线程，都会让出CPU的使用权，在处于等待或者阻塞状态的线程被唤醒后，才会回到就绪状态，然后需要重新获取CPU时间片才能接着运行。
- **TERMINATED**：
  - 终止状态**（对应进程终止态）**，也叫死亡状态，处于RUNNABLE状态的线程，在**Thread#run（）方法执行完成之后**，就会变成该状态。
  - 当然，如果在Thread#run（）方法执行过程中，发生了**运行时异常**而没有被捕获，Thread#run（）方法将被异常终止，线程也会变成该状态。

![1629615205233](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615205233.png)

#### 1.9. 进程间的通信方式？

1. **管道**：亲缘关系使用无名管道，非亲缘关系使用有名管道，遵循FIFO，是**半双工**通信方式，数据只能单向流动。
   - 无名管道：pipe，管道是一种半双工的通信方式，数据只能单向流动，且只能在具有亲缘关系的进程间使用（如父子进程）。
   - 高级管道：popen，指在当前程序进程中启动另一个程序进程，把其当做是当前程序进程的子进程。
   - 有名管道：named pipe，同样是半双工，但允许无亲缘关系进程间通信。
2. **信号**：signal，信号是一种比较复杂的通信方式，用于**通知接收进程某个事情已经发送了**。比如用户调用kill命令将信号发送给其他进程。
3. **消息队列**：message queue，消息队列即消息的链表， 存放在内核中并由消息队列标识符标识，克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等特点。
4. **共享内存**：shared memory，共享内存就是映射一段能被其他进程所访问的内存。
   - 这段共享内存由一个进程创建，多个进程都可以直接读写，是**最快的IPC方式**，是针对其他进程间通信方式运行效率低而专门设计的。
   - 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。
5. **信号量**，semophore，信号量是一个计数器，用于控制多个进程对共享资源的访问，常作为**进程间以及同一进程不同线程之间的同步手段**。
6. **套接字**：socket，与其他通信机制不同，它是通信双方的一种约定，用于**不同机器间的进程通信**。

#### 2.0. 线程通信？

线程的通信，指当多个线程共同操作共享的资源时，线程间通过某种方式互相告知自己的状态，以避免无效的资源争夺。

- 等待 - 通知：Java中使用普遍的线程间通信方式，指的是一个线程A调用了同步对象的wait()方法进入等待状态，而另一线程B调用了同步对象的notify()或者notifyAll()方法通知等待线程，当线程A收到通知后，重新进入就绪状态，准备开始执行。
  - 线程间的通信需要借助同步对象（Object）的监视器来完成，Object对象的wait()、notify()方法就如开关信号，用于完成等待方和通知方之间的通信。
- 共享内存：见进程通信。
- 管道流：见进程通信。

#### 2.1. Java 线程同步方式？

##### 1、总

1. 线程同步，指当有一个线程对内存进行操作时，其他线程都不可以对这个内存进行操作，直到此线程完成操作后，其他线程才能对这个内存进行操作。
2. 在 Java 中，实现线程同步的基础是，操作系统的 mutex 互斥锁、volatile 保证内存可见性和 CAS 比较交换，从上层表现形式来看，可以划分为以下几种同步方式：

##### 2、分

1. **锁式**：指的是，互斥访问同步代码块，拿到互斥量的线程进行同步代码块执行，拿不到互斥量的线程则进入阻塞状态，比如 synchronized 内置锁、Lock 接口的实现类比如 ReentrantLock 重入锁、ReentrantReadWriteLock 读写锁。
2. **事件通知式**：指的是，通过事件通知来协调线程，安全地访问同一块内存，阻塞后的线程需要等待其他线程来唤醒，比如 Object#wait()、notify()、notifyAll()，LockSupport#park()、unpark()，Lock.Condition#await()、signal()。
3. **资源控制式**：指的是，通过控制资源数量，来决定线程是否能够访问临界区或者内存，拿到资源的则可以访问，拿不到的则进入阻塞或者排队等待，比如 Semaphore 信号量。
4. **排队等待式**：指的是，通过队列来实现线程的有序访问，比如 AQS CLH 自旋锁队列、BlockingQueue 阻塞队列。

##### 3、总

以上，就是我对 Java 线程同步方式的一个理解，请问有什么细节需要补充的吗？

#### 2.2. 核心态与用户态？

> 特权指令是拥有特殊权限的指令，用于调用系统函数或系统软件等。比如内存清理、重置时钟、分配系统资源、修改虚存段表和页表、修改用户访问权限等。
>
> 非特权指令是普通权限的指令，在程序执行时都可以调用。

核心态与用户态是两种处理器状态：

- **核心态（Kernel Mode）**：
  - 当程序运行在0特权级时（RING0~3），称之为运行在**核心态**。RING0是最高的特权级。
  - 运行操作系统程序（**内核程序**），可以**执行特权指令和执行非特权指令**。CPU可以访问内存的所有数据，包括外围设备等硬件资源。
  - 处于核心态时，进程能访问所有的内存和对象，且所占有的处理器不允许被抢占。
- **用户态（User Mode）**：
  - 当程序运行在3级特权级时（RING0~3），称之为运行在**用户态**，RING3是最低的特权级，是普通用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。
  - 运行**应用程序**，只能执行**非特权指令**。只能**受限地**访问内存。
  - 处于用户态时，进程所能访问的内存空间和对象受到限制，其所占有的处理器可能被抢占。

#### 2.3. 为什么要有核心态和用户态？

- 由于特权指令权限重大，如果使用不当将会导致整个系统崩溃，为了**保证系统安全**，这类指令只能用于操作系统或者其他系统软件，不直接提供给用户使用，所以CPU状态区分为核心态和用户态：
  - 特权指令必须在核心态执行，且内核态可以使用全部指令。
  - 用户态只能使用非特权指令，当用户态下使用特权指令时，将产生中断以阻止用户使用特权指令。

#### 2.4. 用户态与核心态之间的切换？

- **用户态 -> 核心态**：通过**中断**实现，且**中断是用户态到核心态的唯一途径**。
  - *这里的中断指的是广义的中断，包括异常和狭义的中断。*
  - 因为发生中断意味着需要操作系统介入，开展管理工作，而操作系统的管理工作（如进程切换、分配I/O设备等）需要使用特权指令，所以CPU需要从用户态转为核心态。**中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。**
- **核心态 -> 用户态**：通过执行一个特权指令，将程序状态字（PSW）标志位设置为用户态即可。

#### 2.5. 死锁的条件与解决方式？

> 哲学家进餐问题：每位哲学家都在等待自己右边的人放下筷子，即这些哲学家进程都因等待筷子资源而被阻塞，这就是发生了死锁。

- **死锁**：指在并发环境，**各进程因竞争资源而造成的一种互相等待对方手里资源**，导致各进程都阻塞，无法向前推进的现象。发生死锁后，若无外力干涉，这些进程都将无法向前推进。

- **死锁产生的必要条件**：产生死锁必须**同时满足**以下四个条件，只要其中任一条件不成立，死锁就不会发生。

  - **互斥条件**：进程对所分配的**资源不允许其他进程访问**，若其他进程访问该资源，只能等待至占有该资源的进程释放该资源。
  - **不剥夺条件**：进程所获得的资源在未使用完之前，**不可被剥夺**，只能主动释放。
  - **请求和保持条件**：进程获得一定的资源后，又对其他资源发出请求，且由于互斥条件进入阻塞状态后，还对自己占有的资源**保持不放**。
  - **循环等待条件**：存在一种**进程资源的循环等待链**，链中的每一个进程占有的资源被下一个进程所等待。
    - 注意！发生死锁时一定有循环等待，但发生循环等待时未必发生死锁（循环等待是死锁的必要不充分条件）。但如果系统中每类资源都只有一个，那循环等待则是死锁的充分必要条件。

- **死锁场景**：**对不可剥夺资源的不合理分配，可能会导致死锁。**

  - 对系统资源的竞争：各进程对不可剥夺资源的竞争可能引起死锁（如打印机），而对可剥夺资源的竞争是不会引起死锁的（如CPU）。
  - 进程推进顺序非法：请求和释放资源的顺序不当从而导致死锁。

- **死锁的处理策略**：

  - **预防死锁**：是**不允许死锁发生的静态策略**，破坏死锁的四个必要条件中的某一个。

    - **破坏互斥条件**：
      - 操作系统层面：采用SPOOLING技术，指操作系统用于把独占设备在逻辑上改造成共享设备。
      - 缺点：并不是所有的资源都可以改造成可共享使用的资源。很多时候都无法破坏互斥条件。
      - **Java层面**：乐观锁，比如 CAS。
    - **破坏不可剥夺条件**：
      - 操作系统层面：进程请求不到其他资源时，必须立即释放保持的所有资源，或者考虑进程优先级强行剥夺想要的资源。
      - 缺点：实现比较复杂、释放资源可能会造成进程前一阶段的工作失效、反复申请和释放资源会增加系统开销，降低系统吞吐量、方案一可能会导致进程饥饿的发生。
      - **Java层面**：悲观锁，比如 synchronized、ReentrantLock。
    - **破坏请求和保持条件**：
      - 操作系统层面：采用**静态分配方式**，进程运行需要一次申请完所有需要的资源，未满足则不能投入运行。一旦运行后，资源一直归它所有，且它不会再请求其他资源。
      - 缺点：资源利用率极低、可能会导致别的进程发生饥饿。
      - **Java层面**：数据库deadLock超时，即数据库通过锁定等待超时解决死锁。
    - **破坏循环等待条件**：
      - 操作系统层面：采用**顺序资源分配方式**，对系统该资源编号，规定每个进程必须按编号递增的顺序请求资源，对于编号相同的资源会一次申请完。
      - 缺点：不方便增加新的设备、实际使用资源的顺序可能和编号递增顺序不一致，可能会导致资源浪费、用户变成麻烦。

  - **避免死锁**：是**不允许死锁发生的动态策略**，避免系统进入**不安全状态**。

    - **安全序列**：指如果系统按照这种序列分配资源，每个进程都能顺利完成（安全序列可能有多个）。此时系统为**安全状态**，一定不会发生死锁。而如果分配资源后，系统中找不出任何一个安全序列，则系统进入了**不安全状态**，意味着之后可能发生死锁。

    - **银行家算法**：在资源分配之前先预判本次分配是否会导致系统进入不安全状态，从而决定是否答应该分配的请求，用于**避免死锁**。

      - 实现思路：保证优先分配资源给进程后，进程能够顺利执行完并归还资源，确保是安全状态。
      - 实现方法：Max矩阵、Allocation矩阵、Need矩阵、Available数组、Request数组、预判计算、回溯资源。

      ![1620737316076](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737316076.png)

  - **死锁的检测和解除**：**允许死锁发生**，系统负责检测出死锁并解除。

    - 死锁的检测：

      - 数据结构：两种结点（进程结点、资源结点），两种边（请求边、分配边）。
      - 算法思想：最终能消除所有变，则称这个图是可完全被简化的，此时一定没有发生死锁（相当于找到了一个安全序列）。反之，如果**最终不能消除所有边，那么此时就发生了死锁（死锁定理）**。
      - 实现方法：找到孤点进程（有向边相连以及不阻塞的进程）、简化边、继续简化...

      ![1620737385049](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737385049.png)

    - **死锁的解除**：

      - 死锁的进程：用死锁检测算法化简资源分配图后，还连着边的那些进程才是死锁进程。
      - **主要方法有**：
        - **资源剥夺法**：**挂起（暂时放到外存上）某些死锁进程，并抢占它的资源**，将这些资源分配给其他死锁的进程。
          - 缺点：需要防止进程挂起过久导致出现饥饿问题。
        - **撤销进程法**：又称**终止进程法**，强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。
          - 缺点：虽然实现简单，但付出的代价是很大的。
        - **进程回退法**：让一个或者多个死锁进程回退到足以避免死锁的地步。
          - 缺点：操作系统需要记录进程的历史记录，设置还原点。
      - **考虑的维度**：进程优先级低的、执行时间少的、距离完成时间较久的、持有资源多的、批处理式的死锁进程。 

#### 2.6. 死锁、饥饿、死循环？

- **死锁**：指各进程互相等待对方手里资源，导致各进程都阻塞，无法向前推进的现象。比如哲学家进餐问题。

- **饥饿**：指由于长期得不到想要的资源，某进程无法向前推进的现象。比如短进程优先（SPF）算法，会导致长进程饥饿问题。

- **死循环**：指某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序员故意设计的。

  |          | 死锁                                                         | 饥饿                                                         | 死循环                                 |
  | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------- |
  | 共同点   | 都是进程无法向前顺利推进的现象                               | -                                                            | -                                      |
  | 进程数量 | 至少有两个或者两个以上的进程                                 | 可能只有一个进程                                             | 可能只有一个进程                       |
  | 进程状态 | 一定处于阻塞状态                                             | 可能是阻塞状态（长期得不到I/O设备），也可能是就绪状态（长期得不到处理机） | 可以是运行状态                         |
  | 原因     | 由于**操作系统**分配资源策略不合理导致的（各进程互相等待对方手里的资源） | 由于**操作系统**分配资源策略不合理导致的                     | 由代码逻辑错误导致的（**管理者问题**） |

### 5> 设计模式

#### 1.1. 六大原则

|              | 总结                                                     |
| ------------ | -------------------------------------------------------- |
| 单一职责原则 | 实现类要职责单一                                         |
| 里氏替换原则 | 不要破坏继承体系                                         |
| 依赖倒置原则 | 要面向接口编程                                           |
| 接口隔离原则 | 设计接口时要精简单一                                     |
| 迪米特法则   | 要减少对其他类的直接依赖、减少类对外暴露的方法，降低耦合 |
| 开放原则     | 要对扩展开放，对修改关闭                                 |

##### 1. 单一职责原则

- 概念：**一个类只负责一项职责**，不要存在本职责外导致类发生变更的原因。
- 问题由来：如果类T负责两个不同的职责P1和P2，当职责P1需求发生改变修改T时，可能会导致P2功能发生故障。
- 原因分析：出现了职责扩散。
- 解决方案：
  - 根据P1和P2职责，划分为类1和类2。
  - 在职责扩散到无法控制之前，对代码进行部分重构。
- 优点：
  - 可以降低类的复杂度，一个类只负责一项职责，逻辑简单清晰。
  - 可提高类的可读性和系统的可维护性。
  - 减少需求变更时对其他功能的影响，减少出现的风险。
- 总结：
  - 只有逻辑足够简单，才可以在代码级别上违反单一职责原则。
  - 只有类中方法数量足够少，才可以在方法级别上违反单一职责原则。
  - 模块化的程序设计以及在员工工作安排上面，都适合单一职责原则。

##### 2. 里氏替换原则

- 概念：子类可以扩展父类的功能，但不能改变父类原有的功能；子类可以替换父类，但方法或者行为不能发生改变。即**子类可以扩展父类的功能，但不能改变父类原有的功能**。
- 问题由来：子类B在扩展新功能时，有可能会导致父类原有的功能发生故障。
- 原因分析：继承的弊端，会给程序代理侵入性，使得程序的可移植性减低，增加了对象的耦合性。
- 解决方案：
  - 类B扩展新功能时，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。
  - 如果子类对父类实现的方法进行修改，会对整个继承体系造成破坏，当子类要修改时，必须考虑所有的子类。并且，如果修改了父类，那么所有的子类功能可能都会发生故障。
- 优点：如果不遵循里氏替换原则，一开始程序可能是好好的，但是在之后的迭代过程中，代码出现问题的几率会大大增加，尤其当另外一个人接手项目之后。
- 总结：
  - 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。
  - 子类中可以增加自己独特的方法。
  - 当子类的方法重载父类的方法时，方法的前置条件（形参）要比父类方法更宽松。
  - 当子类的方法实现父类的抽象方法时，方法的后置条件（返回值）要比父类更严格。

##### 3. 依赖倒置原则

- 概念：**高层模块不能依赖底层模块**，二者都应该依赖其抽象；**抽象不应该依赖细节**，细节应该依赖抽象。
- 问题由来：类A（高层模块）本来依赖类B（低层模块），但现在要修改类A依赖类C（低层模块），修改程序时可能会导致不必要的风险。
- 解决方案：将类A改为依赖接口T，而类B和类C分别实现接口T，此时**类A可以通过接口T，间接访问类B和类C，大打降低了修改类A的几率**。
- 总结：
  - 相对于细节的多变性，抽象的东西要稳定得多。依赖倒置原则的核心思想是面向接口编程，通过使用接口或者抽象类来制定好规范和契约，不用去涉及任何具体的操作，将展开细节的任务交给实现类去完成，以达到解耦的目的。
  - 低层模块尽量都要有接口或者抽象类，高层模块尽量通过接口或者抽象类的形式访问低层模块。
  - 使用抽象类时，要遵循里氏替换原则。

4. 接口隔离原则

- 概念：客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖都应该建立在**最小的接口**上面。
- 问题由来：类A通过接口T依赖了类B和类D，但类D不是类A想要依赖的。
- 解决方案：将臃肿的接口T拆分为独立的Tb和Td接口，类A只需要依赖Tb即可。
- 优点：提高内聚，减少对外交互，用最少的方法完成最多的事情。
- 总结：
  - 尽量细化接口，建立单一接口，使得接口中的方法尽量少。但要有限度，过小则会导致接口数量过多，增加复杂度。
  - 为单个类建立专用的接口，不要包含太多。依赖几个专用的接口要比依赖一个综合的接口灵活得多，即可以提高系统的灵活性和可维护性。
  - 为依赖接口的类定制服务，只暴露给调用类需要的方法，建立最小的依赖关系。
- 区别单一职责：
  - 单一职责注重的是职责；接口隔离注重的是接口依赖的隔离。
  - 单一职责约束的是实现类，其次才是接口和方法，针对的是程序中的实现细节；接口隔离约束的是接口，针对的是抽象和整体框架的构建。

##### 5. 迪米特法则

- 概念：又称**最少知道原则**，要求一个对象应该对其他对象有最少的了解。
- 优点：降低类之间的耦合，每个类尽量减少对其他类的依赖，尽量减少对外暴露的方法，使得功能模块独立，低耦合。
- 总结：
  - 减少对其他类的依赖，只通过成员变量、方法的输入输出参数来对类进行注入，减少方法体内部类的直接使用。
  - 减少类对外暴露的方法。
  - 虽然遵循迪米特法则可以避免和非直接的类通信，但如果要通信，则必然会通过一个中介发生联系，而过分地使用迪米特法则，会产生大量的中介和中间传递类，导致系统复杂度变高。

##### 6. 开闭原则

- 概念：软件中的对象（类、模块、函数等）应该**对于扩展是开放的，对与修改是关闭的**。
- 问题由来：对软件原有代码进行修改时，可能会将错误引入原本已经测试过的代码中，破坏原有系统。
- 解决方案：当软件需求发生变化时，尽量通过扩展实体的行为实现需求变化，而不是通过修改原有的代码来应对变化。

#### 1.2. 设计模式有了解哪些？线程池这种是什么设计模式？

##### 1、总

我了解过单例、工厂、建造者、观察者、装饰者、代理、责任链这几个常用的设计模式。

##### 2、分

1. **单例**：某个类只能生成一个实例，该实例被全局访问，比如 Spring 容器一级缓存里的单例池。

   - 实现方式：饿汉式、懒汉式、**双重检查锁、静态内部类、枚举类**等多种实现方式。

2. **工厂**：工厂中最简单实用的模式，简单工厂模式，可以理解为是不同工厂模式的一个特殊实现，比如 Spring 中的 BeanFactory、ApplicationContext。

   实现方式：

   - 简单工厂，是由一个工厂同一个方法来创建多个产品实例。
   - 工厂方法，则是对工厂做了抽象，做到一个产品一个工厂。
   - 抽象工厂，则是一个工厂提供多个创建接口，分别创建不同的产品实例。

3. **建造者**：可以将一个复杂对象的构造与他的表示分离，使同样的构建过程可以创建不同的表示，比如 SpringCloud 中的 FeignClientBuilder。

   - 建造者关注的是组装过程，类似于组装车间，工厂关注的是创建过程，类似于生产车间。

4. **观察者**：在被观察者本身的状态改变时，主动发出通知，呼叫各观察者所提供的方法走对应的实现，比如 Spring 中的各种 ApplicationContextEvent 和 ApplicationListener，Dubbo 中的 InvokerListener、ExporterListener。

5. **装饰者**：通过创建一个包装对象，也就是用包裹真实的对象，在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能，比如 JDK#I/O 中的处理流和节点流 。

6. **代理**：为其他对象提供一种代理，在前后织入业务代理，以增强原始对象，比如 JDK 动态代理，Spring AOP 中的 CGLIB 动态代理，Dubbo 中的 Javassist 动态代理。

   - 静态代理：静态代理，是由程序员创建或者工具生成代理类的源码，再在编译生成代理类。所谓静态，也就是程序运行前就已经存在代理类的字节码文件，这时代理类和委托了类的关系在运行前就确定了。
   - 动态代理：动态代理在实现阶段不用关心代理类，而在运行阶段才指定哪一个对象。

7. **责任链**：通过持有下一个实现类的引用，进行链式调用，比如 Web 中的 Filter、Spring Cloud 中的 GatewayFilter、Dubbo 中的 ProtocolFilterWrapper。

8. **适配器**：定义一个包装类，用来包装不兼容接口的对象，把一个类的接口，转换成所期待的另一种接口，从而使原本接口不匹配、无法工作的两个类能够一起工作，比如 Dubbo 中的 LoggerAdapter 用于适配各日志组件、Spring MVC 中的 HandlerAdapter 用于适配各种不同的处理器。

##### 3、总

1. 线程池这种属于享元模式。
2. 享元模式，Flyweight Pattern，会尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象，主要用于减少创建对象的数量，以减少内存占用和提高性能。
3. 比如还有数据库连接池、Http 连接池等。

=> 以上，就是我对 设计模式 的一些理解，请问有什么细节需要补充的吗？

#### 1.3. 动态代理实现原理，如果给你实现的话你会怎么做？

##### 1、总

对于我阅读过源码的动态代理有，JDK 动态代理和 CGLIB 动态代理。

##### 2、分

###### 1）JDK 动态代理

1. **条件**：JDK 动态代理，需要提供接口。
2. **使用方式**：
   - 1）实现 `InvocationHandler` 接口，并重写 `invoke()`，在反射调用前后，编写需要代理的业务逻辑。
   - 2）通过 `Proxy.newProxyInstance(..)` 方法，来获取动态代理对象，其**方法参数**有：
     - `ClassLoader loader`：动态代理类的类加载器，一般取原委托类的类加载器。
     - `Class<?>[] interfaces`：原委托类实现的接口 Class 对象数组。
     - `InvocationHandler`：动态代理处理程序，在调用动态代理类的增强方法时，会触发回调到它的 `invoke()` 方法。
3. **实现原理**：
   - 1）`newProxyInstance()` 通过反射，生成含有接口方法的 `$Proxy0` 代理类，`$Proxy0` 继承了 `Proxy` 类。
   - 2）在 `$Proxy0` 的构造方法中，会先调用父类的构造方法，让 `Proxy` 父类持有 `InvocationHandler` 实现类的引用。
   - 3）最后，该代理对象的所有方法，都会转发调用到，父类持有的 `InvocationHandler#invoke()` 方法。
   - 4）`InvocationHandler#invoke()`：该方法会传入原始方法的 Method 对象，用于反射调用原始方法。
   - 5）这样，只需要在反射调用前后，编写需要代理的业务逻辑，即可增强原始方法，实现动态代理。

```java
public interface MessageService { 
    void sendMessage(); 
}

public class MessageServiceImpl implements MessageService {
    public void sendMessage() {
        System.out.println("MessageServiceImpl.sendMessage"); 
    } 
}

public class JdkProxy<T> implements InvocationHandler {

    T target;

    public T getProxy(T target) {
        this.target = target;

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理拦截开始！");
        Object result =  method.invoke(target, args);
        System.out.println("JDK动态代理拦截结束！");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        JdkProxy<MessageService> jdkProxy = new JdkProxy();
        MessageService messageService = jdkProxy.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

###### 2）CGLIB 动态代理

1. **条件**：CGLIB 动态代理，无需提供接口，即可实现，当然，也可以代理有接口的原委托类。
2. **使用方式**：
   - 1）实现一个 `MethodInterceptor`：代理方法调用时，会被转发到该类的 `intercept()` 方法。
   - 2）构建 `net.sf.cglib.proxy.Enhacner`：通过 `setSuperClass(Class)` 指定原委托类，`setCallback(Class)` 指定当前 `MethodInterceptor` 实现类 。
   - 3）最后，通过调用 `(T) enhancer.create()` 方法，获取代理对象。
3. **实现原理**：
   - 1）利用 ASM 开源包，通过修改原委托类 Class 文件的字节码，生成子类，覆盖原委托类的方法，并在覆盖方法中实现了增强。
   - 2）在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理。

```java
public class PlayService {
    public void play() {
        System.out.println("PlayService.play");
    }
}

public class CglibProxy<T> implements MethodInterceptor {

    T target;

    public T getProxy(T target) {
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return (T) enhancer.create();
    }

    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理拦截开始!");
        Object result = methodProxy.invokeSuper(o, objects);
        System.out.println("CGLIB动态代理拦截结束!");
        return result;
    }
}

public class Executer {
    public static void main(String[] args) {
        CglibProxy<PlayService> cglibProxy = new CglibProxy();
        
        // 测试代理无接口服务类
        PlayService playService = cglibProxy.getProxy(new PlayService());
        playService.play();
		
        // 测试代理有接口服务类
        CglibProxy<MessageService> cglibProxy1 = new CglibProxy(); 
        MessageService messageService = cglibProxy1.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}
```

##### 3、总

因此，总的来说，

1. JDK 动态代理，是在调用代理类方法时，通过调用 `InvocationHandler#invoke()`，再反射调用原始方法，从而实现动态代理，属于反射调用，会存在一定的性能花销。
2. CGLIB 动态代理，是在调用代理类方法时，通过调用 `MethodInterceptor#invoke()` ，然后根据方法签名索引，去代理类的 FastClass 中，找到对应的方法，在该方法调用时，又会去调用父类（原委托类）的原始方法，从而实现动态代理，属于父类方法调用，在初次调用时，由于需要生成 FastClass，效率会比较低，但在 FastClass 生成后，往后访问由于不用涉及反射调用，此时性能花销非常小。

=> 以上，就是我对 动态代理 的一些理解，CGLIB 动态代理类生成的具体细节也不太记得了~

### 6> Java

#### 1.1. List 与 Set 的区别？

**相同点**：存储元素、接口继承自 Collection 接口、支持泛型。

**不同点**：

1. **List**，有序列表，使用此接口，用户可以通过索引，精确控制列表中每个元素的插入位置，以及访问对应位置的元素，典型实现有 ArrayList、LinkedList、CopyOnWriteArrayList、Vector 和 以及继承自 Vector 的 Stack。
2. **Set**，不包含重复元素的集合，最多包含一个 NULL 元素，典型实现有 HashSet 和 LinkedHashSet，底层都是基于散列表实现的。

#### 1.2. ArrayList 扩容机制？

##### 1、总

1. ArrayList 是一个基于数组的、非线程安全的 List 接口实现类，它允许添加 NULL 元素，支持对元素进行快速随机访问，适合随机查找和遍历，不适合大量插入和删除。
2. 默认初始容量为 10，当数组容量不够时，会触发扩容机制，扩大到原来容量的 1.5 倍，然后将原来数组的数据，通过 `System.arraycopy(..)` 复制到新数组中。
3. 当从 ArrayList 的中间位置，进行插入或者删除元素时，需要对数组进行复制、移动，代价较高。

2、分

1. 元素获取原理：直接根据索引，获取数组中对应的元素，时间复杂度为 O（1）。
2. 元素添加原理：模拟实际大小 + 1，判断是否需要扩容，然后在末尾添加元素，或者先通过 `System.arraycopy(..)` 把索引及其右边的元素，复制到索引右边去，以腾出索引位置添加新元素。
3. ArrayList 扩容机制：模拟实际大小 + 1，通过与当前容量判断，大于的，则需要触发扩容机制，扩容为原来容量的 1.5 倍，然后通过 `System.arraycopy(..)` 复制到新数组中。
4. 元素删除原理：直接根据索引，或者从头找到第一个 equals 的元素，然后删除，删除之后，需要扣减实际大小，以及通过 `System.arraycopy(..)` 把索引右边的元素，复制到索引这个位置来，以避免出现空位置浪费存储空间。

###### 3、总

=> 以上，就是我对 ArrayList 的一些理解，请问有什么细节需要补充的吗？

#### 1.3. ArrayList 与 LinkedList 的区别？

##### 1、总

1. LinkedList，是一个基于双向链表的、非线程安全的 List 接口实现类，它允许添加 NULL 元素，适合数据的动态插入和删除。
2. 使用它，可以直接操作表头、表尾元素，由于实现了 List、Queue、Deque 接口，以及提供 Stack#API，可以把它，当作有序列表、队列、双端队列、以及栈来使用，非常多功能。

##### 2、分

1. 元素获取原理：由于是基于双向链表实现，所以不能直接根据索引进行查找，而是要从头、或者从尾开始挨个遍历查找，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾获取元素，时间复杂度为 O（1）。
2. 元素添加原理：同理，由于是基于双向链表实现，所以不能直接根据索引进行添加，而是要从头、或者从尾开始挨个遍历，找到对应的位置后，才能进行元素添加，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾添加元素，时间复杂度为 O（1），添加元素时，处理好前后指针关系即可。
3. Linked 扩容机制：由于是基于双向链表实现，理论上不存在达到容器边界这种情况，所以也无需扩容，只需要连接前后指针即可。
4. 元素删除原理：同理，由于是基于双向链表实现，所以不能直接根据索引进行删除，而是要从头、或者从尾开始挨个遍历，找到对应的元素后，才能进行元素删除，时间复杂度为 O（n），由于还实现了双端队列和栈的 API，所以还可以直接从链头和链尾删除元素，时间复杂度为 O（1），删除元素时，处理好前后指针关系即可。

##### 3、总

=> 以上，就是我对 LinkedList 的一些理解，请问有什么细节需要补充的吗？

总的来说，ArrayList 和 LinkedList 的**区别**有：

|                 | ArrayList                                                    | LinkedList                                                   |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 提供的 API 不同 | 只提供了 List#API                                            | 除了提供 List#API 外，还提供 Queue、Deque、以及 Stack#API    |
| 数据结构不同    | 是基于数组实现的                                             | 是基于双向链表实现的                                         |
| 扩容机制不同    | 默认初始容量为 10，每次扩容到原来容量的 1.5 倍               | 无需初始容量，也无需扩容机制，只需要处理好前后的指针关系即可 |
| 适用场景不同    | 适合随机查找和遍历元素，不适合大量元素的插入和删除，因为要涉及大数组的拷贝 | 适合动态插入和删除元素，不适合元素的随机访问，因为每次都需要从头、或者从尾遍历链表 |

#### 1.4. 如何保证 List 的线程安全？

1. 在 List#API 外，使用同步锁，来保证线程安全。
2. 直接使用 `Collections#SynchronizedList`，底层原理是，通过持有传入的 List 引用，以及 `mutex` 对象锁，使用 synchronized 关键字来修饰 List 方法，从而包装成线程安全的 List 实现类。
3. 使用 Vector 实现类，它是一个可增长的数组，默认初始容量为 10，每次扩容为原来容量的 2 倍，底层原理是，通过每个 API 方法都使用 synchronized 关键字来修饰，从而保证线程安全。
4. 使用 CopyOnWriteArrayList，它是一个写时复制、读操作无需加锁、写时加锁复制、只保证数据最终一致性，无法保证实时性的、线程安全的 List 实现类。

#### 1.5. HashMap 底层原理？

##### 1、总

HashMap，是 Map 接口的散列表非线程安全形式的实现，可以允许 null 值和 null 键，但不保证元素的顺序，在散列均匀的情况下，`get()/put()/remove()` 方法时间复杂度都是 O（1），当发生哈希冲突时，是通过拉链法来解决，在 JDK 7 中是通过数组 + 链表来实现，在 JDK 8 中是通过数组 + 链表 + 红黑树来实现。

其中，它有几个**重要的参数**：

1. `table.length`：当前散列表的桶容量，初始时默认为 16。

2. `size`：当前 HashMap 的实际大小，等于 Entry 条目总数。

3. `threshold`：HashMap 的阈值，当实际大小超过阈值时，HashMap 会发生扩容为 2 倍的桶容量和阈值，在 JDK 8 中，初始化时 = 默认负载因子 0.75f * 默认桶容量 16 = 12，扩容后超过 Integer.MAX_VALUE 时，等于扩容后的容量 * 设定的负载因子，在 JDK 7 中，初始化和扩容时，都 = 设定的负载因子 * 桶容量。

4. `loadFactor`：HashMap 的负载因子，由于会涉及 HashMap 阈值的计算，所以它是 HashMap 桶容量满意程度的表现，初始时默认为 0.75f，

   - 如果负载因子大于 0.75f，虽然会减少空间的开销，在 JDK 7 中，会导致阈值变大，扩容次数减少，桶拉链变长，增加查找的成本。
   - 如果负载因子小于 0.75f，则会让阈值变小，增加了扩容次数，增大空间的开销，不过好处在于，可以让哈希冲突减少，桶拉链变短，查找效率提高。

   => 所以，0.75f 的负载因子，是 JDK 对 HashMap 在时间和空间成本之间，做的一个很好的权衡取舍。

##### 2、分

在 JDK 8 中，

1. **散列原理**：

   - 1） Key 需要先传入 `hash（Object）` 扰动函数，将 HashCode 右移 16 位，从而混合 HashCode 的高位和低位，加大低位的随机性，减少哈希碰撞发生的概率，是一种性能、效用和质量的折衷方案。
     - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查找效率。
     - HashCode 右移 16 位，使得高位能被利用起来，保证了效用性。
     - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。
   - 2）`（n - 1） & hash` 计算哈希索引，相当于 `hash % n` 取模计算，n 指散列表当前的桶容量，hash 指获取 key#hashCode 扰动后的结果。
     1. 之所以**要取模计算**，不能直接使用 HashCode 作为索引的原因是，hashCode 为 int 类型，范围为[-2^32，2^32 - 1]，如果散列表数组与 HashCode 一一对应，那么就需要 40 亿的空间，明显在内存中是放不下的，所以 hashCode 是不能直接作为数组索引的。而如果使用 hashCode 对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组，也还能利用上 hashCode。
     2. 1）之所以要 n 散列表的桶容量，要取为 **n 的 2 幂次**，原因之一是为了，让 HashMap 在取模计算时，能够通过 n-1，来获得取低位掩码，然后通过低位掩码与扰动后的 hash 值进行一次与运算，即可得到该 hash 值，在散列表数组中的索引。
     3. 2）而另外一个原因是，为了让 HashMap 在扩容时，可通过旧 hash 值与低位掩码相与，只移动少部分与结果高位为 1 的条目，其他条目无需移动，减少了扩容时要搬运的条目数量，减少扩容时间。

2. **条目获取原理**：2 个常用的顶层 API 方法 `get()/getOrDefault()`，都依赖于 `getNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果桶 p 不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的节点，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果 p 没有 next 节点，则返回 null，代表 HashMap 中不存在对应的结点。
     3. 否则，说明 p 节点有 next 节点，如果 p 为红黑树结点，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。
     4. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，直接返回即可，如果找不到，则返回 null，代表 HashMap 中不存在对应的结点。

3. **条目添加原理**：3 个常用的顶层 API 方法 `put()/putIfAbsent()/putAll()`，都依赖于 `putVal()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果 p 桶为 null，则直接 new Node 放到该桶即可。
   - 3）如果 p 桶不为 null，则要分为 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     2. 否则，说明在桶头没找到对应的节点，如果桶头结点 p 为红黑树结点，则使用 `TreeNode#putTreeVal()` 添加 key：value 条目。
     3. 如果 p 为普通链表结点，则遍历 p 桶链表，遍历过程中，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent 为 false，则发生值替换，直接返回即可。
     4. 如果遍历 p 桶链表，没找到对应的结点，则在链尾 new Node 一个结点，且添加后，判断如果当前链表至少有 8 个结点，则调用 `HashMap#treeBin()` 将当前桶链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#HashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）如果发生的不是值替换，则更新修改模数，以及 HashMap 的实际大小，如果实际大小大于阈值，则还需要调用 `resize（）` 进行扩容并转移结点。
   - 5）最后返回 null，代表条目插入成功。

4. **扩容原理**：

   - 1）在添加条目后，判断到实际大小大于阈值时，则会触发 HashMap 的扩容操作。
   - 2）扩容前，正常情况下是，让容量 * 2，阈值 * 2 作为新容量和新阈值，而如果阈值超出了 Integer.MAX_VALUE，则新阈值会被设置为新容量 * 设定的负载因子。
   - 3）然后，根据新容量，创建新数组作为新的散列表： `(Node<K,V>[])new Node[newCap]` 。
   - 4）接着，从头遍历旧的散列表数组，挨个判断桶头节点，或者桶链表：
     1. 如果桶 j 只有一个元素，则重新计算哈希索引，转移元素到新表即可。
     2. 如果桶 j 为红黑树，则调用红黑树的 `TreeNode#split()` 方法，可通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，然后分别判断 lo、hi 链表长度小于等于 6，则退化成普通链表，否则树化为红黑树。这也正是 n 之所以要为 2 幂次的其中一个原因。
     3. 如果桶 j 为普通链表，则通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引。

5. **条目删除原理**：2 个常用的顶层 API 方法 `remove(Object)/remove(Object, Object)`，都依赖于`removeNode()` 方法，其步骤为：

   - 1）`hash（key）` 计算出 key 的 hash 值，`(n - 1) & hash` 计算出哈希索引，`tab[i]` 得到哈希索引对应散列表的桶 p。
   - 2）如果桶 p 为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 3）如果 p 桶不为 null，则分 4 种情况判断：
     1. 如果桶头结点 p#hash 值相等，且 key 值相等或者 key 对象 equals，说明 p 就是要找的结点，则将 p 引用赋值给 node 引用，待后面做删除操作。
     2. 否则，如果 p 节点有 next 节点，且为红黑树结点的话，则根据 hash 和 key  调用  `TreeNode#getTreeNode()` 获取对应的节点，并将其引用赋值给 node 引用，待后面做删除操作。
     3. 如果 p 为普通结点，则遍历 p 链表，如果找到 p#hash 值相等，且 key 值相等或者 key 对象 equals的结点，并将其引用赋值给 node 引用，待后面做删除操作。
     4. 如果找不到，则设置 node 引用为 null。
   - 4）如果 node 引用为 null，则返回 null，代表 HashMap 中不存在对应的结点。
   - 5）如果 node 引用不为 null，说明找到了对应的结点，如果此时 matchValue 为 true，则还要判断 value 对象是否 equals，分为 3 种情况判断：
     1. 如果 node 为红黑树结点，则调用 `TreeNode#removeTreeNode()` 删除节点。
     2. 如果 node 为普通结点，且作为桶头，则脱钩 node 节点，并更新 node 后继作为新的桶头。
     3. 如果 node 为普通结点，也不为桶头，则链接它的前驱和后继，脱钩 node 节点。
   - 6）最后，如果脱钩 node 节点成功，则更新修改模数、实际大小，返回 node 节点引用。

6. **红黑树 TreeNode 节点性质**：

   - **性质 1**：红黑树的结点要么是红色，要么是黑色。
   - **性质 2**：红黑树的根结点是黑色的。
   - **性质 3**：红黑树的叶子结点（nil）都是黑色的。
   - **性质 4**：红黑树的红色结点必须有两个黑色结点。
     - 推论：从根结点到每个叶子结点的所有路径上，不可能存在两个连续的红色结点。
   - **性质5**：红黑树是黑色平衡的，即从根结点到每个叶子结点的所有路径中，所经过的黑色结点数都是一样的。
     - 推论：如果一个结点右黑色的子结点，那么该结点一定是有两个孩子结点，因为必须有另一半才能保证该结点黑色平衡。

7. **红黑树旋转原理**：目的是，为了在结点的添加和删除后，避免子树高度发生变化，通过调整树结构，来保证树重新达到平衡。

   - **左旋**：口诀，**左右左右右**，即以 x 结点作为旋转点进行**左**旋，旋转后，x 的**右**结点 p 成为 x 的父结点，p 原本的**左**结点成为 x 结点的**右**结点，p 原本的**右**结点保持不变。
   - **右旋**：口诀，**右左右左左**，即以 x 结点作为旋转点进行**右**旋，旋转后，x 的**左**结点p成为x的父结点，p 原本的**右**结点成为 x 结点的**左**结点，p 原本的**左**结点保持不变。

8. **红黑树节点获取原理**：`getTreeNode（int，Object）`

   - 1）根据 hash 值和 key 值，从根结点开始查找红黑树结点，小于等于 0 的，说明 x 应该在左边，大于 0 的，说明 x 应该在右边。
   - 2）直到找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，说明该结点就是要找的结点，则直接返回即可。
   - 3）如果找不到，则返回 null，代表没找到对应的结点。

9. **红黑树节点插入原理**：`putTreeVal（HashMap，Node，int，K，V）`

   - 1）从根结点遍历比较待插入结点 x 的 hash 值，小于等于 0 的，说明 x 应该在左边，大于 0 的说明
     x 应该在右边。
   - 2）找到合适位置后（叶子结点），构建 TreeNode 结点，维护 x 与父结点、prev 前驱结点、next 后继结点的关系。
   - 3）插入后，再平衡红黑树，返回 null，表示插入成功。

   其中，插入后，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：

   - 1）为空结点新增：x 插入后，将成为一个 2 结点，插入前，树为 null，插入后， x 需要变黑色，作为根结点，明显在 HashMap 中，不可能会有这种情况，因为链表长度至少要为 8。
   - 2）合并到 2 结点：x 插入后，将成为一个 3 结点，插入前，2 结点为黑色，插入后无论是（上黑下左红 |  上黑下右红）, 都符合 3 结点要求，因此无需调整。
   - 3）合并到 3 结点中：x 插入后，将成为一个 4 结点，插入前，为 3 结点（上黑下左红 |  上黑下右红），插入后，成为 4 结点（黑红红），其中，根据 x 插入位置的不同，又分为 6 种情况：
     1. x 插入后，为左三(中左 左*) 黑红 红，不符合红黑树定义，需要调整，则中 1 右旋，中 1 变红，左 1 变黑。
     2. x 插入后，为(中左右*)  黑红红，其实就相当于左三，如果对父结点进行左旋，就可得到左三 ，不符合红黑树定义，需要调整，则左 1 左旋（得到左三），中 1 右旋，中 1 变红，新左变黑。
     3. x 插入后，为右三(中 右右*) 黑红红，不符合红黑树定义，需要调整，则中 1 左旋，中 1 变红，右 1 变黑。
     4. x 插入后，为(中 右左*) 黑红红，其实就相当于右三，如果对父结点进行右旋，就可得到右三，不符合红黑树定义，需要调整，则右 1 右旋（得到右三），中 1 左旋，中 1 变红，新右变黑。
     5. x 插入后，为(中左 右*) 黑红 红，符合红黑树定义，因此无需调整。
     6. x 插入后，为(中左* 右) 黑红 红，符合红黑树定义，因此也无需调整。
   - 4）合并到 4 结点中：x 插入后，成为一个裂变状态即升元，插入前，为 4 结点（黑红红），插入后，4 结点需要颜色反转，爷结点成为新的 x 结点，继续下一轮的向上调整，其中，根据 x 插入的位置不同，分为 4 种情况：
     1. x 插入后，为(中左左* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红， 右 1 变黑，中看作为“插入结点”，继续向上调整。
     2. x 插入后，为(中左右* 右) 黑红红 红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 保持为红，右 2 变黑，中看作为“插入结点”，继续向上调整。
     3. x 插入后，为(中左 右左*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，左 2 保持为红，右 1 变黑，中看作为“插入结点”，继续向上调整。
     4. x 插入后，为(中左 右右*) 黑红 红红，不符合红黑树定义，需要调整，则中变红，左 1 变黑，右 1 变黑，右 2 保持为红，中看作为“插入结点”，继续向上调整。

10. **红黑树节点删除原理**：`removeTreeNode（HashMap，Node，boolean）`

   - 1）首选，由于红黑树是一种自平衡的二叉搜索树，而二叉搜索树删除，本质上就是找前驱，或者后继结点来替代删除。

   - 2）如果要删除的结点，是叶子结点，则直接删除即可（肯定是黑色），不过由于是黑色，打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 3）如果要删除的结点，只有 1 个孩子结点，则使用孩子节点进行替代，然后删除"替代"的孩子节点，由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   - 4）如果要删除的结点，有 2 个孩子结点，则需要找到后继进行替代，然后删除"替代节点"，其中，"替代节点"删除时又要分为 2 种情况：

     1. 如果替代结点，没有孩子结点，说明为 2-3-4 树的 2 结点，则直接选择为"替代结点"进行删除。
     2. 如果替代结点，有孩子结点，且孩子结点为替代方向（后继方向），说明所在的结点为 2-3-4 树的 3 结点或者 4 结点，则选择孩子结点作为"替代结点"进行删除。

     由于可能打破了黑色平衡，所以删除后还需要平衡红黑树。

   => 其中，删除时，平衡红黑树的原理，要分析 2-3-4 树，分为 4 种情况：`balanceDeletion（TreeNode，TreeNode）` 。

   - 1）x 自己搞得定：

     1. 自己搞得定的意思是，可以在 2-3-4 树节点内部，自己处理完毕，不会影响其他节点的结构。
     2. 对应的情况为，x 要么为 3 结点，要么为 4 结点中的红结点，则直接置黑，返回 x 用作删除即可，因为红节点不会打破黑色平衡。

   - 2）x 自己搞不定，但兄弟搞得定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟搞得定的意思是，兄弟结点存在多余的子结点，即兄弟结点为 3 结点或者 4 结点，这样，x 的父结点，就可以借出结点下来合并到 x 结点，兄弟结点再借出结点合并到父结点，就可以顺利删除 x 了，同时 2-3-4 树的结构还可以保持不变。
     3. 但是，前提是 x 的兄弟结点是真正的兄弟结点，即为黑色的结点，如果为红色的结点，说明其只是父结点（3结点）的红结点，此时还需要对父结点进行旋转，以保证 x 有真正的兄弟结点。

     此时，根据情况又分为 3 种情况：比如 x 为左边时，右边情况同理。

     1. 兄弟结点为 3 结点，同时有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右孩子，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点），xpr 借出去的结点颜色为 xp 借出去的结点颜色，xp 借出去的结点颜色一定要为黑色（相当于3结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。
     2. 兄弟结点为 3 结点，但没有右节点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 没右孩子，不能直接对父结点进行左旋，所以，这是一个临时情况，需要对 xpr 进行右旋，转换为有右孩子的情况一，再做一的相同处理即可。
     3. 兄弟结点为 4 结点，x 在左子树一方，x 的兄弟结点 xpr 为右子树，如果 xpr 有右，则可以顺利地对父结点 xp 进行左旋。左旋后，在 2-3-4 树结构看来，xp 作为 xpr 的左孩子（相当于父结点借出去一个结点，合并到 x 结点），xpr 作为 xp 的父亲（相当于兄弟结点借出去一个结点，合并到父结点，而且还多借出左孩子合并到 x 结点中，这里选择借出 2 个结点，可以进一步减少花销），xpr 合并到父结点的颜色为 xp 借出去的结点颜色（而借出去的左孩子本来为红色所以不用变），xp 借出去的结点颜色一定要为黑色（相当于 4 结点），xpr 剩余结点一定要为黑色（相当于叶子结点），然后返回 x 用作删除即可。

   - 3）x 自己搞不定，并且兄弟也搞不定：

     1. 自己搞不定的意思是，自身结点为黑结点，如果直接删除，会导致父结点所在的树黑色不平衡。
     2. 兄弟也搞不定的意思是，兄弟结点也为黑结点，没有多余的子结点，如果直接删除 x，则会导致叔结点所在路径多了一个黑色结点，造成黑色不平衡。
     3. 这种情况是，兄弟结点为 2 结点，为了让 x 能够顺利删除，兄弟结点需要置红（自损），这样 x 在删除后，x 父结点所在树还是黑色平衡的。
     4. 但是，如果 x 父结点为黑色，x 爷结点所在树则不黑色平衡了，因为父结点这边少了一个黑色结点，所以，父结点的叔结点要也要被置红。
     5. 因此，需要一路向上自损，直到碰到任意一个终止条件，即可结束自损：
        - **向上碰到根结点**：经过一路置红叔结点，直到循环到根结点时（因为上面已经没有父节点了），则代表自损完毕，此时整棵树都是黑色平衡的了（都减少了一个黑色结点）。
        - **向上碰到红结点**：如果碰到红色结点，只需要把该结点置黑，无需再置红叔结点了，相当于在父结点这边子树补回了一个黑色结点，不影响这边子树的黑色结点数目，整棵树还是黑色平衡的。

11. **链表树化成红黑树**：`HashMap#treeifyBin()`

    - 1）先判断桶容量，是否大于等于 64，如果不是，则调用 `resize()` 扩容即可。
    - 2）如果确实大于等于 64，则先挨个维护每个桶的链表，为双向无环链表。
    - 3）接着，调用 `TreeNode#treeify` 树化该链表成为红黑树，其步骤为：
      1. 取桶头结点作为根结点，置黑。
      2. 然后遍历桶链表，比较根结点 hash 值与当前遍历结点的 hash 值，小于等于的，则继续遍历左子树，大于的，则遍历右子树，然后插入当前遍历结点到对应的位置，再平衡红黑树。
    - 4）直到散列表所有桶、每个桶的链表结点遍历完毕，再返回。

12. **红黑树退化成普通链表**：`untreeify（HashMap）`

    - 1）遍历桶链表，重新构建为 `next=null` 的 Node 结点。
    - 2）再重新维护每个它的 next 指针。
    - 3）直到遍历结束，最后返回链头指针 hd 即可。

##### 3、总

相对于 JDK 7#HashMap，JDK 8 主要优化了以下 3 点：

1. **引用红黑树**：避免链表过长影响查找效率，同时还可以保证插入性能。
2. **`resize()` 扩容优化** 以及**头插法改成尾插法** ：取消了 rehash 操作，通过旧 hash 值与低位掩码相与，高位为 0 的条目构成 lo 链表，为 1 的条目构成 hi 链表，lo 链表桶位置保持不动，hi 链表位置移动 `oldCap` 索引，以及由于头插法会使得结点转移后节点倒序，改用头插法改成尾插法，可以保证转移后，链表结点的相对顺序不变，从而解决了并发情况下扩容导致的死循环问题。

但 HashMap 仍是非线程安全的，并发下添加结点，可能会造成数据丢失，而线程安全的 Map 使用方式有：

1. **在 HashMap API 外层使用锁，**来保证线程安全。
2. **使用 Collections 内部类 SynchronizedMap**：底层原理是，通过持有传入的 Map 引用，以及 `mutex` 对象锁，使用 synchronized 关键字来修饰 Map 方法，从而包装成线程安全的 Map 实现类。
3. **使用 HashTable**：散列表线程安全的实现类，默认初始容量 11，默认负载因子 0.75f，不允许为 null 键和null 值，底层通过使用 synchronized 关键字修饰方法，来保证线程安全，所以效率低下。
4. **使用 ConcurrentHashMap**：支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可以在保持并发可读的同时，还能最小化锁争用。

=> 以上，就是我对 HashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 1.6. ConcurrentHashMap 底层原理？

##### 1、总

ConcurrentHashMap，支持更高并发更新与查询的散列表线程安全的实现类，默认初始容量和负载因子与 HashMap 一样，但不允许为 null 键和 null 值，可在保持并发可读的同时，还能最小化锁争用。

其中，它有几个**重要的参数**：

1. `table`：当前正在使用的散列表，volatile 修饰，具有并发可见性。
2. `nextTable`：并发扩容时，持有的另外一个散列表，volatile 修饰，具有并发可见性。
3. `sizeCtl`：ConcurrentHashMap 的控制变量，volatile 修饰，具有并发可见性，提供 `SIZECTL` 通过 CAS 进行原子性更新。
   - 1）在构造函数中为（1.5 倍指定容量 + 1，或者指定容量 / 负载因子）的最小 2 幂次。
   - 2）当分布式计数统计结果，大于 `sizeCtl` 时，则触发并发扩容机制，高 16 位为扩容标记，低 16 位为并发扩容线程数（步长为 1，然后再每有一个线程参与协助扩容则 +1）。
   - 3）在扩容完成后，等于 0.75f * 旧表桶容量，作为下一次扩容的阈值判断条件。

几种重要的**结点类型**：

1. `Node`：实现 Map.Entry，是 ConcurrentHashMap 中最普通的链表结点，拥有 hash、key、val、next 成员变量，是其他类型结点的父类，其中 val 和 next 使用 volatile 修饰，保证了并发可见性。
2. `TreeNode`：继承 Node 结点，是 ConcurrentHashMap 中的红黑树结点，在 Node 结点的基础上，还维护了parent、left、right、red 红黑树成员变量。
3. `TreeBins`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中红黑树的桶头结点，hash 值为-2，持有红黑树根结点root 指针和链头 first 指针，不保存键和值。
   - 2）同时还维护了读写锁，强迫写线程必须等待所有读线程完成后，才能进行红黑树结点操作。
   - 3）当读时不存在并发写线程，使用 root 指针走红黑树遍历方式查找结点，当读时存在并发写线程，使用first 指针走链表遍历方式去查找结点。
4. `ForwardingNode`：
   - 1）继承 Node 结点，是 ConcurrentHashMap 中的转发结点，hash 值为 -1，持有 nextTable 引用，没有键和值。
   - 2）在线程协助转移结点到新表后，会在旧表原位置维护一个 `Forwarding` 结点，以标识旧表正在发生扩容操作，让下一个线程碰到时，可以协助进行转移旧表结点。

##### 2、分

在 JDK 8 中，

1. **散列原理**：原理与 HashMap 类似，但不同的地方在于，HashMap 的扰动函数叫 `hash(Object)`，而 ConcurrentHashMap 的扰动函数叫 `spread（Object）` 。

2. **条目获取原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）`getOrDefault()`，依赖于 `get()` 方法，其中 val 和 next 使用 volatile 修饰，保证线程可见性，所以，`get()` 方法可以不加锁地照常遍历，而在读红黑树时，由于并发更新需要涉及到旋转，所以有写时会走链表方式去读，在树方式读时，不能并发下对红黑树进行写。
   - 2）因此，可与 `put()` 和 `remove()` 等更新方法同时执行，但反映的只是，最近完成更新的结果，并发检索可能只反映出部分条目的更新。

3. **条目添加原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p 为null，new Node 以后是通过 CAS 的方式放入到散列表中的。
   - 2）然后，如果桶 p 不为 null，还要判断是否为 `Forwardding` 节点（p#hash = -2），如果是的话，则当前线程要参与协助扩容。
   - 3）然后，如果桶 p 也不为 `Forwardding` 节点，那么还会对其加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果桶 p#hash 值小于 0，说明 p 为红黑树，则使用 `TreeBin#putTreeVal()` 添加 key：value 条目。
     2. 如果桶 p#hash 值大于等于 0，说明为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，如果此时 onlyIfAbsent为false，则发生值替换，直接返回即可。
     3. 如果没找到对应的结点，则在链尾直接 new Node 一个结点。
     4. 如果添加后，当前链表至少有 8 个结点，则调用 `ConcurrentHashMap#treeBin()`，将当前链表，树化成一棵红黑树，其中，`treeBin()` 还会判断散列表容量，是否大于等于最小树化容量 64。
     5. 所以，JDK 8#ConcurrentHashMap 中，树化为红黑树的条件为，链表长度大于等于 8，且桶容量大于等于 64。
   - 4）最后，如果发生的不是值替换，而是条目插入，还要并发分布式计数，然后判断是否需要扩容，要的话则发起扩容。，返回 null，代表结点插入成功。

4. **条目删除原理**：其原理与 HashMap 类似，但不同的地方在于，ConcurrentHashMap 的获取方法是线程安全的，其并发安全原理为：

   - 1）如果根据哈希索引得到的桶 p，为 `Forwardding` 节点，则当前线程要参与协助扩容。
   - 2）如果 p 不为 `Forwardding` 结点，则会对 p 进行加 synchronized 锁，再做类似于 HashMap 那样，分为情况判断：
     1. 如果 p#hash 小于 0，说明 p 为红黑树，则调用 `TreeNode#getTreeNode()`，来获取 hash 和 key 对应的结点，调用 `TreeNode#removeTreeNode()` 删除该结点。
     2. 如果 p#hash 值大于等于0，说明它为普通链表结点，则遍历 p 链表，如果找到 hash 值相等，且 key 值相等或者 key 对象 equals 的结点，则脱钩该结点。
     3. 如果没找到对应的结点，则返回 null，代表 ConcurrentHashMap 不存在对应的结点。
   - 3）最后，如果脱钩结点成功，则还要并发分布式计数，返回旧值，代表删除成功。

5. **分布式计数相关变量**：

   - 1）`baseCount`：分布式计数基数，volatile 修饰，具有并发可见性，提供 `BASECOUNT` 通过 CAS 进行原子性更新。
   - 2）`counterCells`：分布计数单元格数组，volatile 修饰，具有并发可见性，提供 `CELLVALUE` 通过 CAS 进行原子性更新。
   - 3）`cellsBusy`：分布式计数单元格繁忙标记，volatile 修饰，具有并发可见性，提供 `CELLSBUSY` 通过 CAS 进行原子性更新。

   => 在要获取 ConcurrentHashMap 实际大小 `sumCount()`  时，可以通过 `baseCount` + 累加 `counterCells` 数组所有格子的值，得到一个瞬时的累加和作为实际大小。

6. **并发分布式计数原理**：在 `putVal()` 和 `removeNode()` 方法更新玩后，还需要并发叠加 `x=1/-1`，叠加成功后，获取瞬时的累加和作为实际大小，用于扩容判断，其步骤为：

   - 1）先尝试在 `baseCount` 叠加 x，如果叠加成功，则继续做扩容判断。
   - 2）如果 `baseCount` 叠加 x 失败，则根据当前线程随机值 `h=ThreadLocalRandom.getProbe()`，尝试在 `CounterCell[h * (n-1)]` 叠加 x，如果叠加成功，则做扩容判断。
   - 3）如果 `CountCell` 叠加 x 失败，则调用 `fullAddCount()` 自旋 + CAS 竞争添加 x 到 `CounterCell[] as` 中。

7. **并发扩容原理**：

   - 1）如果 `sumCount()` 获取到的瞬时累加和，大于 `sizeCtl` ，说明需要扩容，则启动扩容机制，调用 `resizeStamp（n）` 生成扩容标记 `rs`，保证扩容过程不会被重复启动。
   - 2）如果 rs 大于等于 0，说明散列表还没被扩容，则 CAS 更新 `sizeCtrl=(rs << RESIZE_STAMP_SHIFT) + 2)`，更新成功后，rs 为一个负数，再第一次调用 `transfer(tab, null)`，开始扩容创建 2 倍旧表容量的 nextTab，并开始转移旧表结点到新表。
   - 3）如果 rs 小于 0，说明散列表正在被其他线程扩容，则 CAS 更新并发扩容线程数 `sizeCtrl=sc+1`，更新成功后调用 `transfer(tab, nt)`，加入扩容一起转移旧表结点到新表。
   - 4）其中，在某个桶结点被转移后，会在旧表中留下一个 `Forwardding` 节点，其他线程在调用`put()/remove()` 时，如果遇到这种节点，则会根据它持有的 `nextTab`，参与协助扩容。
   - 5）最后，`transfer()` 中会根据 `(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT` 来判断，当前转移线程是否为最后一个扩容线程，如果是的话，则会提交新散列表，正式把 `nextTab` 设置为 `table`，然后设置 `sizeCtl` 为 0.75f * 旧表桶容量（作为下一次扩容的阈值判断条件）才返回，返回后还要自旋判断一次是否需要再次扩容，防止并发情况下桶容量又不够的情况。

8. **红黑树线程安全原理**：

   - 1）ConcurrentHashMap 的红黑树过程与 HashMap 类似，但不同的地方在于，由于并发更新时，红黑树可能会涉及到旋转，TreeBin 维护了一个读写锁，在调用 `TreeBin#putTreeVal()` 或者 `TreeBin#removeTreeNode()` 方法时，即使外层有获取可重入锁 synchronized，在操作红黑树之前，也要调用 `lockRoot()`，调用完成后再 `unlockRoot()`，保证写时走链式读，走树读时不能写。
   - 2）其原理如下：
     1. TreeBin 持有 lockState 属性，值有读、等待写、以及写状态（WRITER=1，WAITER=2，READER=4，读/写状态可与等待状态结合）。
     2. 调用 `lockRoot()` 时，CAS 竞争更新 lockState 为 `WRITER`，竞争成功，说明当前线程持有写锁成功，可以继续做红黑树操作，操作完后 `unlockRoot` 释放写锁，置 lockState 为 0。
     3. 竞争失败，则调用 `contendedLock()` 继续争抢写锁，争抢不到则会进入阻塞状态，直到所有调用`TreeBin#find(int，Object)` 的线程，都调用完毕后，才会被唤醒，然后重新争抢写锁。

##### 3、总

相对于 JDK 7#ConcurrentHashMap，JDK 8 主要优化了以下 3 点：

1. **数据结构**：取消 Segment[] + HashEntry[] + 链表的数据结构，改用 Node[] + 链表 + 红黑树的数据结构，提升查找效率。
2. **线程安全方式**：取消了 Segment#ReentrantLock 分段锁保证线程安全的方式，改用 Node + CAS 自旋锁+ synchronized 锁定桶结点 + TreeBin 读写锁的方式，来保证并发安全，进一步提高并发量。
3. **扩容方式**：取消了获取锁再做计数 + 扩容的方式，改用释放 synchronized 同步锁，利用 CAS 自旋锁 + 并发分布式计数 + 并发扩容的方式，支持更高的并发更新与查询。

=> 以上，就是我对 ConcurrentHashMap 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 1.7. 红黑树性能稳定吗？

经过大量实验证明，红黑树可以保证，在最好甚至最坏情况下，所有操作（插入/删除/查找等）的时间复杂度，都是对数级别 O（logN），无论插入顺序如何，红黑树都是接近完美平衡的，其操作成本（包括旋转和变色），比 BST 降低 40% 左右。

![1647876146340](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647876146340.png)

=> 因此，红黑树性能是稳定的，任何时间复杂度都为 O（logn）级别。

#### 1.8. ThreadLocal 底层原理？

##### 1、总

1. ThreadLocal，线程本地变量，可以将某个变量放到对象中，使该变量在每个线程中都有专属的引用，不会出现一个线程读取时，被另一个线程修改的现象，从而保证线程安全访问。
2. ThreadLocal，用作**线程隔离**，是解决线程安全问题一个较好的方案，比直接使用同步机制（如 synchronized）解决更简单、更方便、更高效，因为避免了加同步锁带来的性能损失，大大提升了并发性的性能，比如，数据库连接、Session 管理等。
3. 另外，根据 ThreadLocal 的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到，从而可以方便地实现**跨函数的数据传递**，避免通过参数传递数据带来的高耦合。

##### 2、分

其**线程隔离原理**为：

1. ThreadLocal 内部定义了一个静态的  `ThreadLocalMap`，在线程第一次调用 `get()/set()` 方法时，会被构造出来，并由 Thread 实例持有该引用。
2. 然后，ThreadLocal 实例作为 `ThreadLocalMap` 的 Key，也就是只要传入所需的 ThreadLocal 变量的引用，就可以获取到保存在 `ThreadLocalMap` 中对应的值。
3. 从而保证每个线程，即使在获取同一个 `ThreadLocal ` 变量的值时，也能保证值是互相隔离的。

TheadLocalMap#Entry 定义为**弱键的好处**：

1. 比如，线程 t 调用一个 `funcA()` 方法，新建了一个 ThreadLocal 实例 local，然后调用 `local.set()` 方法设置一个 100 后，调用 `local.get()` 方法去获取值。

   ```java
   public void funcA() {
       ThreadLocal<Integer> local = new ThreadLocal<>();
       local.set(100);
       local.get();
   }
   ```

2. 此时的内存结构是，local 被线程 t 强引用，在 `set()` 调用后，线程 t#ThreadLocalMap，会新建一个 Entry 实例，其 Key 以弱引用的方式包装，`WeakReference` 指向 ThreadLocal 实例。

3. 当线程 t 执行完 `funcA()` 方法后，该方法的栈帧会被销毁，栈帧中的 `local` 强引用则会被回收，但如果线程 t 还在继续调用其他方式时，则会导致 t#ThreadLocalMap 中对应的 Entry.Key 引用，还指向 ThreadLocal 实例。

4. 如果 Entry#Key 引用是**强引用**的话，那么就会导致 Key 引用指向的 ThreadLocal 实例以及对应的 Value 值，都不能被 GC 回收，造成内存泄漏的发生。

5. 如果 Entry#Key 引用是**弱引用**的话，那么在下次 GC 发生时就会，使那些没有被其他强引用指向、仅被Entry#Key 所指向的 ThreadLocal 实例被顺利回收，在 Entry#Key 引用被回收之后，其 Entry#Key 被设置 null，在后续调用 `get()/set()/remove()` 时，ThreadLocalMap 的内部代码就会清除这些 Key 为 null 的 Entry，从而释放对应的内存，避免内存泄露的发生。

**内存泄露**发生的场景：

1. 然而，即使 ThreadLocalMap#Entry 的 Key 被设置为弱键，可以避免内存泄露的发生，但是，如果 ThreadLocal  使用不当的话，还是可能会出现内存泄露。
2. 第一种情况是，**Entry.value 导致的内存泄露**：
   - 1）在`set()` 方法调用后， 假设没 调用 ` get()` 方法，就退出这个  `funA()` 方法，`local` 局部变量被回收后，t#ThreadLocalMap 的 Entry#key 被设置 null。
   - 2）然后，线程 t 继续运行，没有被销毁，也没有调用过任何 `get()/set()/remove()` 方法，导致那一整个 key 为 null 的 Entry 都不会被回收， 导致 Entry.value 内存泄露的发生。
   - 3）这种现象很容易，发生在线程池中的 Thread 实例中，解决方法是， 只要后续存在任何一个 `get()/set()/remove()` 方法被调用，就会触发 Key为 null 的 Entry 的清理工作，释放掉对应的 Entry 内存，解决 Entry.value 内存泄露的问题。
3. 而第二种情况则是，**static、final 修饰 ThreadLocal 导致的内存泄露**：
   - 1）首先，ThreadLocal 实例被 static 修饰，可以保证每个线程操作这个 ThreadLocal，作为 ThreadLocalMap Entry#key 时，都会共享一份地址空间，节省内存的使用。
   - 2）其次，使用 final 修饰，可以确保 ThreadLocal 实例的唯一性，防止使用过程中发生动态变更。
   - 3）此时，由于修饰后的 ThreadLocal 会以单例的形式存在，一直被 GC Root 强引用，导致引用该 ThreadLocal 实例的 ThreadLocalMap，它的 Entry#Key 在 Thread t 实例的生命周期内，始终会保持为非 null。
   - 4）这样，该 Entry 就不能被 ThreadLocal 自动清空掉，导致其 Value 所指向的对象，一直被 Entry 强引用，于是这个对象就在该线程 t 的生命周期内，一直不会被释放掉，导致内存泄漏的发生。
   - 5）所以，在使用完 static、final 修饰的 ThreadLocal 实例后，要及时调用 `remove()` 来进行显式地释放掉。

##### 3、总

1. 综上，虽然使用 ThreadLocal 可以轻量级地保证变量的线程隔离。

2. 但如果使用不当，就容易发生内存泄漏，如果我们在 ThreadLocal 使用完毕后，及时调用 `remove()` 方法，就可简单、有效地避免这些内存泄漏的情况发生。

   => 这里可以讲一下这个实际案例《[1> 项目](#1> 项目)》- 3、项目亮点 - 6）自研 @DataSource 注解，ThreadLocal 没及时释放的问题 | 线程池、ThreadLocal、数据源。

3. 以上，就是我对 ThreadLocal 底层原理 的一个理解，请问有什么细节需要补充的吗？

#### 1.9. 线程池核心参数，以及选取原则？

##### 1、总

对于这个问题，我打算从线程池的概念、线程复用原理、线程淘汰原理、构造参数、数据结构、生命周期、工作原理和调优原则这几个方面进行回答。

##### 2、分

1. **线程池的概念**：线程池，ThreadPoolExecutor，允许使用多个线程之一，来执行每个提交的任务，通过**线程复用**，来降低线程创建和销毁所带来的开销，同时任务到达时，可以无需等待线程的创建就能立即执行，从而提高任务的处理速度。

2. **线程复用原理**：通过设计一个**任务队列**，来承放并缓冲更多的执行任务，使得**本已存在的线程**，在处理完它们手上的任务后，可以立马从任务队列的**另一端取出执行任务**，接着继续往下执行，周而复始，从而不用每次都构建一个新的线程再执行，实现线程复用。

3. **线程池的构造参数**：但是，这种线程复用太过于简单暴力，为了让线程池稳定可控，还需要其他参数进行优化：

   - 考虑到，那些本已存在的线程应该有个上限，就需要指定一个 `corePoolSize` 核心线程数，核心线程的意思就是，默认情况下没有保活时间，不会被回收，在不超 `corePoolSize` 上限且收到新任务时会被创建。
   - 考虑到，在任务过多，核心线程处理不过来的情况，就需要指定一个 `maximumPoolSize` 最大线程数。
   - 考虑到，在任务峰值过后，非核心线程可能会空闲一段时间，但仍然占据系统资源的情况，就需要指定一个 `keepAliveTime` 非核心线程的最大空闲时间以及 `TimeUnit` 时间单位。
     - 这也是**线程淘汰**的原理所在，如果在从任务队列中取任务的时间，超过了指定的 `keepAliveTime` 还没取到任务，则可以认为队列中没有多余的任务了，也就是轮训任务队列的这个线程空闲了 `keepAliveTime` 这么久的时间，那么就要对这个线程进行淘汰处理，以节省系统资源。
   - 考虑到，任务需要装入任务队列，就需要指定一个 `BlockingQueue` 阻塞队列接口的具体实现。
   - 考虑到，在构建核心或者非核心线程时，可能需要对线程本身进行一些，比如线程名称等参数设置的情况，就需要指定一个 `ThreadFactory` 的具体实现。
   - 考虑到，任务队列和最大线程都超上限，即线程池超负载时，任务还源源不断到来的情况，就需要指定一种 `RejectedExecutionHandler` 的具体实现，来执行相应的拒绝策略逻辑。

4. **线程池的数据结构**：

   - 根据以上分析，可以容易得到，如果构建一个好点的线程池，就至少需要持有核心线程数、最大线程数、非核心线程的最大空闲时间、任务队列、线程工厂、拒绝策略程序的引用。
   - 另外，JDK 在实现方面，还抽象了一个 `Worker` 类，通过使用 `Worker` 自己持有的 `Thread` 实例，在轮训任务队列时进行任务消费。
   - 同时还持有了一个 `AtomicInteger` 原子类型的 `ctl  ` 线程池控制位，来管理线程池的生命周期及有效线程的数量。

5. **线程池的生命周期**：线程池控制位 ctl，JDK 把 Integer 的高 3 位作为**线程池的状态**，低 29 位作为**有效线程的数量**，前者一个存在 5 种状态，规定：

   - **-1 为 RUNNING 运行态**，此状态下能够接收新提交的任务，同时还能处理任务队列中的任务。
   - **0 为 SHUTDOWN 关闭态**，此状态下不会再接受新提交的任务，但还可以继续处理任务队列中的任务。
   - **1 为 STOP 停止态**，此状态下不会再接收新提交的任务，也不能继续处理任务队列中的任务，并且还会尝试中断正在处理任务的线程。
   - **2 为 TIDYING 整理态**，此状态下所有的线程都已终止了，此时有效工作数量为 0。
   - **3 为 TERMINATED 终止态**，在 TIDYING 整理态回调完 `terminated()` 钩子函数以后，会进行此状态。

   ![1645968027493](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645968027493.png)

6. **线程池的工作原理**：

   1. 首先根据线程控制位 `ctl`，判断当前有效线程数是否小于设定的核心线程数，如果是小于，那么就可以把当前任务作为首个任务 `firstTask`，去**创建核心线程**并执行任务。
   2. 如果发现超出了核心线程数，或者并发下核心线程创建失败了，那么就在检查完线程池还在运行状态后，就尝试**把任务投递到任务队列中**。
   3. 如果任务投递成功，则还要做线程池状态的双重检查，防止线程池突然被关闭，如果发现线程池确实不再是运行态了，那么就需要把刚才投递成功的任务给取出来，再**执行拒绝策略程序**；而如果发现还是运行态，则视有效线程数量是否为 0，来决定是否需要**补充非核心线程**，以保证任务队列中的任务不会永远停留在内存中。
      1. 注意这里**补充非核心线程**的操作，它可以保证 `corePoolSize=0 & maximumPoolSize > 0` 且任务队列还没达到上限时，仍能生成 1 个非核心线程去消费任务队列，避免队列内存溢出的发生，关于这里的细节就可以说说我们的一段生产事故了~
      2. 我们系统某个模块中常常需要使用别的模块的数据源，比如在 POS 模块中需要去查询 PRICE 库，此时，由于主线程默认绑定的是 POS 数据源，要想使用 PRICE 数据源的话，就需要开辟子线程去做切换，所以就为每个模块抽象了数据源切换的工具类。
      3. 由于正常都是调用一次切换方法，也就是把 Lambda 表达式提交给线程池，主线程再去做 `FutureTask.get()` 的监听，拿到结果后返回，这是正常情况，因此我们一开始也没怎么留意。
      4. 但问题就来了，有一次某段代码对连续进行了两次的切换，就发现接口超时，以及往后的切换都超时了，那时排查了很久，最后在这个切换工具类里看到，生产上跑的参数为 `corePoolSize=0、maximumPoolSize=32、workQueue=LinkedBlockingQueue`，按照原理，本以为是错误的配置，会导致任务都阻塞在队列中直到 OOM 发生的。
      5. 但没发版前一次切换是可以的，这就很奇怪了，然后就去研究源码，发现刚才上面所说的那段**补充非核心线程**的逻辑，也就是即使 `corePoolSize=0`，只要最大线程数不为 0，那么还是会保证至少创建一个线程去消费任务队列的，所以切换一次就可以拿到任务的运行结果。
      6. 那么为什么切换两次就不行了呢？这是因为，在第一次切换时，是主线程在做 `FutureTask.get()`，阻塞的是主线程，而如果还做一次连续切换，那么就会导致线程池中仅有的 1 个线程也做了 `FutureTask.get()`，从而进入了阻塞，但线程池认为有效线程数还是 1，所以新任务进来也不会去创建新线程消费，会直到 OOM 的发生为止~
      7. 最后，更正了合理的构造参数 `corePoolSize=Runtime.getRuntime().availableProcessors() + 1`，`maximumPoolSize=2 * Runtime.getRuntime().availableProcessors()`，`keepAliveTime=120s`，`LinkedBlockingQueue=1024` 保证不会发生内存溢出，`Google#ThreadFactoryBuilder`来设构建线程工厂、在线程创建时设定名称前缀和递增线程号，`RejectedExecutionHandler=CallerRunsPolicy` 保证任务不丢失，同时设置 `allowCoreThreadTimeOut=true` 允许核心线程空闲时也会被回收。
   4. 如果任务投递失败了，则**尝试补充非核心线程**，如果因为线程池不是为运行态，或者超出了最大核心线程数，导致非核心线程补充失败的话，那么就需要**执行拒绝策略程序**，因为此时要么是 SHUTDOWN 关闭状态不能接受新任务了，要么就是任务队列满了需要拒绝添加新任务了。

   ![1645967491556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645967491556.png)

7. **线程池的调优原则**：

   - **线程池大小的设置**：需要先确定任务的类型，分为 CPU 密集型、IO 密集型以及混合型的任务：

     | 类型       | 概念                                                         | 目的                                                         | 合理的经验公式                                               |
     | ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
     | CPU 密集型 | 任务需要大量的运算，中间没有阻塞，CPU 一直全速运行           | 需要尽可能少的线程数量，以减少线程上下切换的次数，提高 CPU 的利用率 | CPU 核数 + 1                                                 |
     | IO 密集型  | 任务大量时间都花在 IO 的阻塞上，希望 CPU 尽可能去调度其他任务，而不是在等待阻塞的线程、浪费 CPU 资源，所以需要更多的线程数以供 CPU 调度 | 需要尽可能多的线程数，但过多的线程也会带来过多的上下文切换   | CPU 核数 * 2                                                 |
     | 混合型     | 既有 CPU 密集型的特点，又有 IO 密集型的特点                  | 需要看平均线程等待时间，和平均线程运行时间，来决定对应的线程数，可通过 Github#PoolSize Calculator 工具类进行粗略的计算 | CPU 核心数 * 目标 CPU 利用率 * （1 + 平均线程等待时间 / 平均线程运行时间），可见，平均线程等待时间越长，平均线程运行时间越短，则需要的线程就越多 |

     => 但这些只是经验公式，最优的参数还需要根据实际环境不断压测、调优才能得到。

   - **任务队列的设置**：控制任务队列容量，实际上就是在考量**内存占用**和**任务的排队策略**，常用的阻塞队列实现有：

     | 实现类              | 特性                                                         | 排队策略 | 优点                                                         | 缺点                                                         |
     | ------------------- | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
     | SynchronousQueue    | 无界同步队列，容量为 0，不存储任何元素，每个插入操作都会阻塞等到另一个线程进行相应的删除操作才会恢复（利用 CAS 自旋 + LockSupport 方式实现阻塞） | 直接交接 | 最小的内存花销                                               | 当任务到达速度大于处理速度时，如果搭配无界池，可能会出现无限线程增长的问题 |
     | LinkedBlockingQueue | 单向链表有界阻塞队列，容量可选，空参构造时为 Integer.MAX_VALUE，相当于无界队列 | 容量可选 | 核心线程繁忙时，任务会在队列中排队，适合用于平滑瞬间爆发的流量 | 如果任务到达速度大于处理速度，可能会导致任务队列元素无限增长，占用较大的内存花销 |
     | ArrayBlockingQueue  | 数组有界阻塞队列，初始时必须先指定容量大小，一旦指定，就不能再修改了 | 有界队列 | 与最大线程数一起使用，可以防止资源被耗尽                     | 任务队列初始化好了后，就难以再动态的调整和控制了             |

   - **拒绝策略程序的设置**：当线程池被关闭，或者任务队列和线程都已经饱和时，新提交的任务会走到拒绝策略程序的处理逻辑中，默认的拒绝策略程序都是定义在 ThreadPoolExecutor 的内部类中：

     | 实现类              | 特性                                                         | 适用场景                                                     |
     | ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
     | AbortPolicy         | 默认的拒绝策略程序，在任务被拒绝时，会抛出 RejectedExecutionException 异常 | 可以阻止系统正常运行下去                                     |
     | CallerRunsPolicy    | 调用 Runnable#run，当前主线程会自己去运行任务                | 不会造成任务的丢失，可以让线程池有一定的缓冲时间             |
     | DiscardPolicy       | 任务会被简单的丢弃掉                                         | 允许任务丢失时，这是最好的一种丢弃策略                       |
     | DiscardOldestPolicy | 丢弃任务队列头部的任务，然后重新执行一开始的工作流程         | 会丢弃最老的一个任务，也就是可能马上就被执行的任务，然后重新提交当前任务 |

##### 3、总

以上，就是我对线程池核心参数及原理的一个理解，请问有什么细节需要补充的吗？

#### 2.0. 阻塞队列有哪些？

##### 1、总

1. BlockingQueue，阻塞队列，继承自 Queue 接口，除了 Queue 接口方法外，还提供了以下操作：在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。

2. BlockingQueue，是线程安全的，所有排队方法，使用了内部锁、或者其他并发控制的方式，来原子地实现其操作，它的方法一共 4 种形式：

   - 1）抛出异常。
   - 2）返回一个特殊值，{@code null} 或 {@code false}，具体取决于操作。
   - 3）无限期地阻塞当前线程，直到操作成功为止。
   - 4）阻塞等待指定的时间。

   |             | *Throws exception*         | *Special value*         | *Blocks*             | *Times out*                                                 |
   | ----------- | -------------------------- | ----------------------- | -------------------- | ----------------------------------------------------------- |
   | **Insert**  | {@link #add add(e)}        | {@link #offer offer(e)} | {@link #put put(e)}  | {@link #offer(Object, long, TimeUnit) offer(e, time, unit)} |
   | **Remove**  | {@link #remove remove()}   | {@link #poll poll()}    | {@link #take take()} | {@link #poll(long, TimeUnit) poll(time, unit)}              |
   | **Examine** | {@link #element element()} | {@link #peek peek()}    | *not applicable*     | *not applicable*                                            |

3. JDK 8 中，典型实现有：

   - 1）ArrayBlockingQueue，数组有界阻塞队列。
   - 2）LinkedBlockingQueue，链表有界阻塞队列。
   - 3）PriorityBlockingQueue，优先级无界阻塞队列。
   - 4）SynchronousQueue，无容量的同步阻塞队列。

##### 2、分

下面打算讲下几个重要实现的原理，

###### 1）ArrayBlockingQueue

1. ArrayBlockingQueue，数组有界阻塞队列，保存固定大小的数组，数组创建后，其容量无法被更改。
2. 元素从队尾进、队头出，在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。
3. 同时支持公平性设置，设置为 true，则代表使用公平策略，队列则严格按 FIFO 顺序添加、获取元素，可避免线程饥饿，但会降低吞吐量。

它的实现原理是，

1. 数据结构为，
   - 1）持有一个 `Object[] items` 数组来存储元素。
   - 2）持有一个 `int takeIndex` 、以及一个 `int putIndex`，表示最近删除、添加索引，每次删除、添加完元素之后，都会向前、向后更新它的值，由于是在显示锁控制的临界区内操作，所以是线程安全的。
   - 3）持有一个 `int count`，表示当前队列中的实际大小，每次删除、添加完元素之后，都会  -1 或者 +1，由于是在显示锁控制的临界区内操作，所以是线程安全的。
   - 4）持有一个 `ReentrantLock lock` 显式锁来控制独占访问以及公平策略。
   - 5）持有一个 `Condition notEmpty` 队列非满条件、以及一个 `Condition notFull` 队列非空条件，两条件都是由 lock 显式锁构造，遵守与 ReentrantLock 相同的公平性策略。
2. 然后就是，阻塞式添加元素方法的实现原理：`put(E e)`，
   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于数组容量大小，是的话，说明队列已经满了，不能再添加元素了，则调用 `notFull.await()`，释放当前线程独占的锁资源，阻塞等待非满条件的发生，即发生一次元素获取事件。
   - 3）如果队列还没满，或者非满条件已发生，当前线程重新抢到锁资源，则调用 `enqueue(E x)`，往数组中追加此元素，并更新实际大小 + 1，然后调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
   - 4）最后，释放显式锁。
3. 最后就是，阻塞式删除元素方法的实现原理：`take()`，
   - 1）与 `put(E e)` 方法相反，首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再获取元素了，则调用 `notEmpty.await()`，释放当前线程独占的锁资源，阻塞等待非空条件的发生，即发生一次元素添加事件。
   - 3）如果队列还没空，或者非空条件已发生，当前线程重新抢到锁资源，则调用 `dequeue()`，获取数组最近索引的元素，获取后再清空该位置，并更新实际大小 - 1，然后调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put(E e)` 方法线程。
   - 4）最后，释放显式锁，返回清空之前该位置的值。

###### 2）LinkedBlockingQueue

1. LinkedBlockingQueue，链表有界阻塞队列，容量未指定时，默认使用 `Integer＃MAX_VALUE`，可能会导致内存溢出的发生，所以一般在构造时都指定实际容量，防止队列存放过多的元素。
2. 元素从队尾进、队头出，在添加元素时，队列满了则阻塞等待队列非满，在删除元素时，队列为空则阻塞等待队列非空。
3. 不支持公平性设置，只能使用非公平策略，同时，阻塞方法的实现原理也不同，理论上会比 ArrayBlockingQueue 拥有更高的吞吐量。

它的实现原理是，

1. 数据结构为，
   - 1）持有一个 `Node<E> head`、一个 `Node<E> last`  链表的头尾结点，以支持从尾添加从头获取元素。
   - 2）持有一个 `int capacity`，表示队列的容量边界，超过此容量后，再添加元素，则线程会阻塞等待非满条件的发生。
   - 3）持有一个 `AtomicInteger count = new AtomicInteger()`，表示当前队列的实际大小，通过 Atomic 原子类控制线程同步。
   - 4）持有一个 `ReentrantLock takeLock` take 锁、一个 `ReentrantLock putLock` put 锁，以分别控制排队的线程，提高吞吐量。
   - 5）持有一个 `Condition notEmpty = takeLock.newCondition()` 队列非空条件，以及一个 `Condition notFull = putLock.newCondition()` 队列非满条件，分别由 take 锁和 put 锁构造，同样也是非公平的策略。
2. 然后就是，阻塞式添加元素方法的实现原理：`put(E e)`，
   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占 put 锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 `capacity` 容量边界，是的话，说明队列已经满了，不能再添加元素了，则调用 `notFull.await()`，释放当前线程独占的 put 锁资源，阻塞等待非满条件的发生。
   - 3）如果队列还没满，或者非满条件已发生，当前线程重新抢到 put 锁资源，则调用 `enqueue(E x)`，往数组中追加此元素，并更新实际大小 + 1，然后如果添加之后，容量还没满，则调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put()` 方法线程。
     - 可见，这里非满条件通知，除了 take 线程会发生外，连其他的 put 线程也会发生，来发出通知，使得阻塞的 `put()` 方法线程，其等待时间更少，吞吐量来得更高。
   - 4）最后，释放 put 锁，再判断添加前容量是否为 0，是的话，说明添加之后队列不为空了，则获取独占 take 锁，获取失败，则当前线程会进入阻塞状态，获取成功，则会调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
3. 最后就是，阻塞式删除元素方法的实现原理：`take()`，
   - 1）与 `put(E e)` 方法相反，首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占 take 锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则再去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再获取元素了，则调用 `notEmpty.await()`，释放当前线程独占的 take 锁资源，阻塞等待非空条件的发生。
   - 3）如果队列没空，或者非空条件已发生，当前线程重新抢到 take 锁资源，则调用 `dequeue(E x)`，脱钩链头结点，并更新实际大小 - 1，然后如果删除之后，容量还没空，则调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
     - 可见，这里非空条件通知，除了 put 线程会发生外，连其他的 take 线程也会发生，来发出通知，使得阻塞的 `take()` 方法线程，其等待时间更少，吞吐量来得更高。
   - 4）最后，释放 take 锁，再判断添加前容量是否为 `capacity` 队列容量边界，是的话，说明删除之后队列不满了，则获取独占 put 锁，获取失败，则当前线程会进入阻塞状态，获取成功，则会调用 `notFull.signal()`，通知非满事件已发生，唤醒正在阻塞的 `put()` 方法线程，再返回脱钩出来的头结点的值。

###### 3）PriorityBlockingQueue

1. PriorityBlockingQueue，优先级无界阻塞队列，基于小顶堆实现，能够每次都按传入的 Comparator 比较器或者自然顺序，对元素以 O（logn）进行排序，因此，队头中的元素是比较器给出的最小结果元素，队尾则是最大的元素，相同的元素之间是不稳定的。

它的实现原理是，

1. 数据结构为，

   - 1）持有一个 `Object[] queue` 数组来存储元素。
   - 2）持有一个 `Comparator<? super E> comparator`，表示按指定的比较器，来进行小顶堆排序。
   - 3）持有一个 `int size`，表示当前队列中的实际大小。
   - 4）持有一个 `ReentrantLock lock` 显式锁来控制独占访问，采用的是非公平性策略。
   - 5）持有一个 `Condition notEmpty` 队列非满条件，由 lock 显式锁构造，采用的是非公平性策略。

2. 然后就是，小顶堆原理，

   - 1）最后一个非叶子结点，在数组中的序号 i = n / 2 - 1，n 为数组长度。
   - 2） 对于序号 i 的结点，其父结点序号 f = （i - 1）/ 2，左孩子序号 l = 2 * i + 1，右孩子序号 r = 2 * i + 2，如果有的话。
   - 3）小顶堆堆化：`heapify()`，
     1. 从最后一个非叶子结点 K 位置开始，从下到上，从右到左，每次遍历都对结点进行向下调整，一直遍历到根结点 queue[0] 后，queue[0] 就是数组中的最小值，即完成了数组的小顶堆堆化。
   - 4）小顶堆向下调整：`siftDownComparable(int k, T x, Object[] array, int n)`， k 为要调整的结点序号，x 为要调整的结点的值，array 为数组，n 为数组长度。
     1. 从 k 位置开始循环，比较 x、左、右孩子的值，交换最小者到堆顶，然后继续向下调整，直到调整到最后一个非叶子结点为止。
   - 5）小顶堆向上调整：`siftUpComparable(int k, T x, Object[] array)`，k 为要调整的结点序号，x 为要调整的结点的值，array 为数组。
     1. 从 k 的父结点 f = （k  - 1）/ 2 开始，比较 x、f 的值，交换大者到 k 位置，然后继续向上调整，直到调整到根结点位置。

   ![1625386699340](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625386699340.png)

3. 接着就是，阻塞式添加元素方法的实现原理：`put(E e)`，

   - 1）首先，会调用 `lock.lock()`，阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则判断当前队列中的实际大小，是否大于等于数组容量，是的话，说明队列满了，则调用 `tryGrow(Object[] array, int oldCap)`，进行数组扩容。
   - 3）如果没小于数组容量，说明队列还没满，则调用 `siftUpComparable(int k, T x, Object[] array)`，插入元素并向上调整小顶堆（大的放后面），然后实际大小 + 1，调用 `notEmpty.signal()`，通知非空事件已发生，唤醒正在阻塞的 `take()` 方法线程。
   - 4）最后，释放独占锁。

4. 再然后就是，数组扩容原理：`tryGrow(Object[] array, int oldCap)`，

   - 1）首先，释放独占锁，获取自选锁 `allocationSpinLockOffset`，判断旧容量（当前数组大小），是否小于 64，如果是，则扩容为旧容量 * 2 倍 + 2，否则扩容为旧容量 * 1.5 倍。
   - 2）然后做容器最大值 `Integer.MAX_VALUE - 8` 校验，校验不通过则抛出异常，校验通过，则重新构建长度为新容量的数组，给中间变量 `Object[] newArray`。
   - 3）最后，释放自选锁，重新获取独占锁，赋值中间变量 newArray 给 `Object[] queue` 队列数组，然后调用 `System.arraycopy(array, 0, newArray, 0, oldCap)`，拷贝并移动旧数据到新数组中，再返回。

5. 最后就是，阻塞式删除元素方法的实现原理：`take()`，

   - 1）首先，会调用 `lock.lockInterruptibly()`，可中断、阻塞式获取独占锁，获取失败，当前线程会进入阻塞状态。
   - 2）获取成功，则去判断实际大小，是否已经等于 0，是的话，说明队列已经空了，不能再删除元素了，则调用 `notEmpty.await()`，释放当前线程独占锁资源，阻塞等待非空条件的发生。
   - 3）然后，再获取 queue[0] 数组的第一个元素，调用 `siftDownComparable(int k, T x, Object[] array, int n)` 对其进行向下调整，更新实际大小 - 1。
   - 4）最后，更新实际大小 - 1，释放独占锁，并返回第一个元素的值。

###### 4）SynchronousQueue

1. SynchronousQueue，无容量的同步阻塞队列，每个插入操作，需要等待另一个删除操作，以及每个删除操作，需要等待另一个插入操作。
2. 它支持可选的公平策略，默认为非公平，设置为 true，则代表使用公平策略，队列则按 FIFO 顺序添加、删除元素，可避免线程饥饿，但会降低吞吐量。

它的实现原理是，

1. 数据结构为，持有一个 `volatile Transferer<E> transferer`，内部类的实例引用，它有两个实现类，如果为非公平策略，则为栈结构，如果为公平策略，则为队列结构。

2. 栈结构的实现是，使用自旋锁提高吞吐量，如果只出现添加、或者删除其中一个操作，则会调用 `LockSupport.park(this)` 让其阻塞等待到另一个操作的出现，实现添加和删除方法两两配对、两两同步。由于栈是后进先出，也就是新来的，会比栈底更久的，更先得到配对响应，所以实现了非公平策略。

   ![1621954377695](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1621954377695.png)

3. 队列结构的实现是，使用自旋锁提高吞吐量，如果只出现添加、或者删除其中一个操作，则会调用 `LockSupport.park(this)` 让其阻塞等待到另一个操作的出现，实现添加和删除方法两两配对、两两同步。由于队列是先进先出的，所以另一个操作到来时，会去队头做匹配，从而让最久的先得到响应，所以实现了公平策略。

   ![1622033076546](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1622033076546.png)

##### 3、总

=> 以上，就是我对 BlockingQueue 的一些理解，请问有什么细节需要补充的吗？

#### 2.1. ArrayBlockingQueue 与 LinkedBlockingQueue 的异同，比如在锁的角度呢？

1. 相同点：都实现了 BlockingQueue 接口，都是有界的阻塞队列，在添加元素时，队列满了则会阻塞等待队列非满，在删除元素时，队列为空则会阻塞等待队列非空。
2. 不同点：
   - 1）**底层实现的数据结构不一样**，ArrayBlockingQueue 是基于数组实现的，而 LinkedBlockingQueue 是基于单向链表实现的。
   - 2）**构造方法不一样**，ArrayBlockingQueue 构造时必须设定容量边界，同时支持公平和非公平的排队策略，而 LinkedBlockingQueue 构造时可以不设定容量边界，默认为 `Integer.MAX_VALUE`，且仅支持非公平的排队策略。
   - 3）**条件通知机制不一样**，ArrayBlockingQueue 中的队列非满和非空条件，基于的都是同一把显式锁，非满只能被删除方法唤醒，非空只能被添加方法唤醒，而 LinkedBlockingQueue 中的队列非满条件，基于 put 锁实现，可以被添加、删除两个方法唤醒，队列非空条件，基于 take 锁实现，也可以被添加、删除两个方法唤醒，理论上吞吐量来得要比 ArrayBlockingQueue 的高。
   - 4）**队列实际大小统计不一样**，ArrayBlockingQueue 的实际大小，是通过持有一个 `int count` 成员变量，在独占锁的临界区内进行更新，而 LinkedBlockingQueue 的实际大小，是通过 `AtomicInteger count = new AtomicInteger()` 成员变量，利用 CAS 进行更新。

#### 2.2. sychrozied 锁升级流程？

##### 1、总

sychrozied 锁状态一共有 4 种，级别由低到高分别为：无锁、偏向锁、轻量级锁和重量级锁。

1. 在 JDK 1.6 之前，sychrozied  锁是一个重量级锁，效率比较低下。
2. 在 JDK 1.6 之后，为了提高锁的获取和释放效率，就对 synchronized 的实现进行了优化，引入了偏向锁和轻量级锁。
3. 从此 synchronized 锁就有了以上 4 种状态，并且它们会随着竞争的情况逐渐升级，但不可降级。

对于 sychrozied  优化后的，锁执行过程总结如下：

![1629617805708](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617805708.png)

![1629617826584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617826584.png)

1. **确认是否为可偏向状态**：线程抢锁时，JVM 首先检测内置锁对象 Mark Word 中的 biased_lock（偏向锁标识）是否设置成 1，lock（锁标志位）是否为 01，如果都满足，则确认内置锁对象为**可偏向状态**。
2. **确认线程 ID**：在内置锁对象确认为可偏向状态后， JVM 会检查 Mark Word 中的线程 ID 是否为抢锁线程的 ID。
3. **同线程 ID，直接执行临界区代码**：如果是，则表示抢锁线程处于偏向锁状态，然后抢锁线程快速获得锁，开始执行临界区代码。
4. **竞争锁成功，升级为偏向锁**：如果 Mark Word 中的线程 ID 并未指向抢锁线程，则通过 CAS 操作去竞争锁。
   - 如果竞争成功，则将 Mark Word 中的线程 ID 设置为抢锁线程，偏向标志位设置为 1，锁标志位设置为 01，然后执行临界区代码，此时内置锁对象为**偏向锁状态**。
5. **发生锁竞争失败，偏向锁升级为轻量级锁**：如果 CAS 操作竞争失败，说明发生了竞争，此时 JVM 会去检查原先持有锁的线程是否存活。
   - 如果原线程已经死亡，则设置 Mark Word 为抢到锁的线程 ID，内置锁继续保持为偏向锁。
   - 如果原线程没有死亡，且其堆栈中存在该 sychrozied 锁的所记录，则需要撤销偏向锁，进而升级为**轻量级锁**（继续由原持有锁线程持有）。
6. **其他线程继续 CAS 竞争，以获取轻量级锁**：如果仍然有其他线程继续竞争轻量级锁，则在 JVM 将在替换锁对象 Mark Word 中的 ptr_to_lock_record 过程中，使用 CAS 替换为抢锁线程的锁记录指针。
   - 如果替换成功，则代表抢锁线程获得了**轻量级锁**。
   - 如果替换失败，表明存在其他线程竞争锁，则 JVM 接着尝试使用 CAS + 自旋方式来替换。
     - 如果替换成功，代表抢锁成功，则锁对象继续保持为**轻量级锁状态**。
7. **CAS + 自旋失败，轻量级锁升级为重量级锁**：如果 CAS + 自旋替换失败，即超过了最大自旋次数，轻量级锁则升级为重量级锁，此后等待锁的线程都需要进入**阻塞状态**。

=> 总的来说：

1. **偏向锁**是在没有发生锁争用的情况下使用的。
2. 一旦有了第二个线程争用锁，偏向锁则会升级为**轻量级锁**。
3. 如果锁争用很激烈，轻量级锁的 CAS + 自旋到达自旋阈值后，轻量级锁则会升级为**重量级锁**。

##### 2、分

###### 1）无锁

![1629597556442](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597556442.png)

无锁，即无线程竞争，在 java 对象刚创建时，还没有任何线程来竞争，对象处于无锁状态，此时，偏向标志位为0，锁状态标志位为 01。

###### 2）偏向锁

![1629597869808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597869808.png)

偏向锁，是指一段同步代码，一直被同一个线程所访问，偏向锁状态下的 Mark Word，会记录 synchronized 锁偏爱的线程 ID，从而让 synchronized 锁认定该线程为“熟人”，从而该线程可以自动获取锁，降低获取锁的代价。

- **主要解决无竞争下的锁性能问题**：由于线程 ID 被记录在锁对象的 Mark Word 中（CAS设置），以后该线程获取锁时，只需要判断一下线程 ID 和标志位，就可以直接进入同步块，连 CAS 操作都不需要，省去了大量有关锁申请的操作，消除了无锁竞争情况下的同步原语，从而提高了程序的性能。
- **偏向锁的膨胀**：
  1. 如果偏向锁已经被 A 占据，一旦有第二个线程 B 来争抢这个对象，由于偏向锁不会主动释放，所以 B 看到的 synchronized 锁是偏向状态，表明已经存在了竞争，则 JVM 会去检查原来持有该对象锁的占有线程A 是否依然存活。
  2. 如果发现 A 已经挂了，则将锁对象变为无锁状态，然后重新偏向 B 线程。
  3. 如果发现 A 依然存活，则会进一步检查 A 的调用堆栈是否有锁记录持有该偏向锁。
  4. 如果存在锁记录，表明原来的线程 A 仍然在使用该偏向锁，即 A 和 B 此时发生了锁竞争，则 JVM 会撤销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。
- **偏向锁的撤销**：如果锁对象经常被多个线程竞争，那么偏向锁就是多余的，并且撤销偏向锁的过程也会带来一些性能开销。
  1. 在一个安全点停止拥有锁的线程。
  2. 遍历线程的栈帧，检查是否存在锁记录，如果存在，则需要清空锁记录（锁记录是线程私有的，每个线程都有自己的一份锁记录），使其变为无锁状态，并修复锁记录指向的 Mark Word，清除其线程 ID。
  3. 将当前锁升级为轻量级锁。
  4. 唤醒当前线程。
- **偏向锁的撤销条件**：
  - 多个线程竞争偏向锁。
  - 调用偏向锁对象的 `hashCode（）`方法，或者 `System.identityHashCode（）`方法，计算对象的HashCode 之后，将哈希码放置到了 Mark Word 中，synchronized 锁变成无锁状态，偏向锁会被撤销。

=> 经验表明，大部分情况下，一个同步代码块的线程都是同一个线程，总体来说，使用偏向锁带来的好处大于偏向锁撤销和膨胀带来的代价。如果某些临界区存在两个，或者两个以上的线程竞争，偏向锁反而会降低性能，此时可以在启动 JVM 时，把偏向锁的默认功能关闭。

###### 3）轻量级锁

![1629598045639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629598045639.png)

轻量级锁，也被成为非阻塞同步锁、或者叫乐观锁，是指当锁处于偏向锁，又被另一个线程企图抢占时，偏向锁就会升级为轻量级锁，而企图抢占的线程会通过自旋的形式尝试获取锁，不会阻塞抢锁线程，以提高性能，其中，哪个线程先占有锁对象，锁对象的 Mark Word 就会指向哪个线程栈帧中的锁记录。

- **引入轻量级锁的主要目的**：在多线程竞争不激烈的情况下，通过 CAS 机制竞争锁，减少重量级锁产生的性能损耗，尽可能不动用操作系统层面的互斥锁，在应用层面上通过自旋来解决线程同步的问题。

  - **自旋原理**：如果持有锁的线程能在很短时间内释放锁资源，竞争等待锁的线程则不需要进行内核态和用户态的切换进入阻塞状态，它们只需要 CPU 自旋，等待持有锁的线程释放锁后即可立即获取锁，避免了用户线程和内核切换的消耗，从而提高性能。
  - **自旋锁分类**：
    - **普通自旋锁**：指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。
      - JDK 1.6 的轻量级锁使用的是普通自旋锁，需要使用 `-XX：+UseSpinning` 选项手工开启。
      - 默认情况下，自旋次数为 10 次，可以通过 `-XX：PreBlockSpin` 选项来进行更改。
      - 然而，线程自旋需要消耗 CPU，如果一直获取不到锁，那么线程也不能一直占用 CPU 自旋做无用功，因此需要设定一个自旋等待的最大时间。
    - **适应性自旋锁**：
      - JVM 对于自旋周期的选择，JDK 1.7 引入了适应性自旋锁（自动开启），指的是自旋的时间不是固定式的，而是由前一次在同一个锁上的自旋时间，以及锁的拥有者状态来决定的，解决的是锁竞争时间不确定的问题，使得竞争程度趋于稳定。
      - **自旋成功了则下次自旋的次数就会更多**：如果抢锁线程在同一个锁对象上之前成功获得过锁（竞争力强，适合竞争），JVM 则会认为这次自旋很可能再次成功，此次允许自旋等待持续相对更长的时间。
      - **自旋失败了则下次自旋的次数就会减少**：如果对于某个锁，抢锁线程很少成功获得过（竞争力弱，不适合竞争），JVM 则减少自旋时间甚至省略自旋过程，以避免浪费 CPU 资源。

- **轻量级锁的抢占过程**：

  1. 在抢锁线程进入临界区之前，如果该 synchronized 锁没有被锁定，JVM 首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前 Mark Word 的拷贝。

     ![1629601733727](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629601733727.png)

  2. 然后，抢锁线程将使用 CAS 自旋操作，尝试将内置锁对象头的 Mark Word 的 ptr_to_lock_record（锁记录指针），更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，这个线程就拥有了对象锁。

  3. 接着，JVM 将 Mark Word 中的 lock 标记位改为 00，代表该内置锁对象处于轻量级锁状态。

  4. 抢锁成功之后，JVM 会将 Mark Word 中原来的锁对象信息（如哈希码等），保存在抢锁线程锁记录中的Displaced Mark Word 字段中，再将抢锁线程中锁记录的 owner 指针指向锁对象。

     ![1629602512221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629602512221.png)

- **轻量级锁的膨胀**：

  - 如果临界区代码执行耗时较长，在其执行期间，其他线程都在原地 CAS + 自旋等待替换ptr_to_lock_record，导致一直空耗 CPU，带来很大的性能损耗。
  - 而轻量级锁的本意，是为了减少多线程进入操作系统层面互斥锁的概率，并不是要替代其互斥锁。
  - 因此，在内置锁争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁实现的重量级锁。

###### 4）重量级锁

![1629599089661](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629599089661.png)

重量级锁，也称为同步锁，是指当锁处于轻量级锁，如果持有锁的线程执行的时间，超过了自旋等待的最大时间仍然没有释放锁，自旋等待锁的线程不会一直自旋下去，而是会进入阻塞状态，该锁也膨胀为重量级锁。

- 锁对象的 Mark Word 会再次发生变化，指向一个监视器对象，该监视器对象会用集合的形式来登记和管理排队的线程。

  - **监视器**：是一个同步工具，相当于一个许可证，拿到许可证的线程即可进入临界区进行操作，没有拿到的则需要阻塞等待。在 JVM 中，每个对象都关联一个监视器，监视器和对象一起创建、销毁，保证同一时间只有一个线程可以访问被保护的临界区代码。监视器也可以说是同步机制，主要特点是：
    - **同步**：监视器所保护的临界区代码互斥地执行，一个监视器是一个运行许可，任一线程进入临界区代码都需要获得这个许可，离开时会把许可归还。
    - **协作**：监视器提供 Signal 机制，允许正持有许可的线程，暂时放弃许可进入阻塞等待状态，等待其他线程发送 Signal 去唤醒；其他拥有许可的线程可以发送 Signal，唤醒正在阻塞等待的线程，让它可以重新获得许可并启动执行。

- 重量级锁通过监视器的方式，保障了任何时间，只允许一个线程通过受到监视器保护的临界区代码。在Hotspot 虚拟机中，监视器由 C++ 类 ObjectMonitor 实现：

  ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

  - **_recursions**：线程的重入次数。
  - **_owner**：标识拥有该 Monitor 的线程，即获得锁的线程。
  - **cxq**：竞争队列，所有请求锁的线程首先会被放入这个竞争队列中。cxq 由 Node 及其 next 指针逻辑构成（单向链表），并不存在一个队列的数据结构，只是一个虚拟队列：
    1. 在线程进入 cxq 前，抢锁线程会先尝试通过 CAS 自旋获取锁，如果获取不到，则会进入 cxq 队列，显然抢锁操作这对于那些已经进入了 cxq 队列的线程是不公平的，因此 synchronized 同步块所使用的重量级锁是**非公平锁**。
    2. 每次新加入的 Node 会在 cxq 的队头进行，通过 CAS 改变第一个结点的指针为新增结点，同时设置新增结点的 next 指向后续结点。
    3. 从 cxq 取出元素时，会从队尾获取。由于只有 owner 线程才能从队尾取出元素，即线程出列操作无争用，因此 cxq 是无锁结构。
  - **_EntryList**： 候选竞争队列，在 owner 线程释放锁时，JVM 会从 cxq 中迁移线程到 EntryList 中，然后指定 EntryList 中的某个线程（一般为 Head），为 OnDeck Thread（Ready Thread），因此 EntryList 中的线程，是作为候选竞争线程而存在的。
    - **OnDeck Thread**：
      - JVM 不直接把锁传递给 Owner Thread，而是还要让 OnDeck Thread 与后来的新抢锁线程竞争抢锁，虽然牺牲了一些公平性，但极大提升了系统的吞吐量。
      - OnDeck Thread 获取到锁资源后，就会变为 Owner Thread，而没获得锁的 Thread 则会依然留在 EntryList 中。
  - **_WaitSet**：等待队列，某个拥有 ObjectMonitor 的线程（owner 线程），在调用 Object.wait（）方法之后将被阻塞，然后该线程将被放置在 _WaitSet 链表中，直到某个时刻通过 Object.notify（）或者Object.notifyAll（）唤醒后，该线程才会重新进入 EntryList 中继续候选竞争锁。

- **重量级锁性能低**：重量级锁使用了操作系统底层的互斥锁（Mutex Lock），会导致线程在用户态和内核态之间的频繁切换，从而带来较大的性能损耗。

  - 处于 cxq、EntryList、WaitSet 中的线程都处于阻塞状态，线程的阻塞或者唤醒，都需要操作系统来帮忙。比如在 Linux 内核中采用 pthread_mutex_lock 系统调用（互斥锁）来实现，因此，进程需要从用户态切换到内核态。
  - 进程从用户态切换到内核态，这种切换需要消耗很多时间，有可能比用户执行代码的时间还要长，而由于轻量级锁使用 CAS 进行自旋抢锁，都处于用户态下，进程不存在用户态和内核态之间的切换，因此轻量级锁开销较小，而重量级锁使用了 Linux 内核态下的互斥锁，会造成较大的性能开销。

##### 3、总

适用场景总结：

| 锁       | 优点                                                         | 缺点                                             | 适用场景                                 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------ | ---------------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比，仅存在纳秒级的差距 | 如果线程间存在锁竞争，则会带来额外的锁撤销消耗   | 适用于只有一个线程访问临界区的场景       |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 抢不到锁竞争的线程会使用CAS 自旋等待，会消耗 CPU | 锁占用时间很短，追求响应时间，但吞吐量低 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗 CPU                             | 使用系统互斥锁，线程阻塞，响应时间缓慢           | 吞吐量高，追求吞吐量，但锁占用时间较长   |

=> 以上，就是我对 sychrozied 的一个理解，请问有什么细节需要补充的吗？

#### 2.3. CAS 的缺点，以及什么是总线风暴？

##### 1、总

1. CAS，CompareAndSwap，比较并交换，一种乐观锁的实现方式，是一种无锁算法，该算法关键依赖两个值，分别是期望值和新值，底层 CPU 利用原子操作，判断期望值是否还等于旧值，只有等于才会赋新值，否则就不做更新操作，而是继续自旋、继续比较。
2. 在 JDK 中，常常用到的地方有，ConcurrentHashMap、Atomic 原子类、FutureTask、synchronized 轻量级锁、ReentrantLock 显式锁、以及 AQS 等。

##### 2、分

1. 实现原理为，在操作系统层面，CAS 是一条 CPU `cmpxchg` 的原子指令，由于该指令具备原子性，所以，在使用 CAS 操作数据时，并不会造成数据不一致的问题。

2. 使用 CAS 进行无锁编程的步骤大致为：

   - 1）获得字段的期望值（oldValue）。
   - 2）计算出需要替换的新值（newValue）。
   - 3）然后，通过 CAS，尝试将新值（newValue）放入对应的内存地址中。
   - 4）如果 CAS 失败，就重复第（1）步到第（2）步，一直到CAS成功，这种重复就叫做 CAS 自旋。

3. 其**优点**是，性能开销小，

   - 1）由于 CAS 是处于用户态下 CPU 指令级的原子操作，所以，在用于线程同步时，线程也无需进入阻塞态，没有用户态与内核态之间的切换，性能开销较小。
   - 2）而 synchronized 重量级锁，涉及操作系统内核态下互斥锁的使用，线程的阻塞和唤醒，都需要在用户态和内核态间的切换，导致开销大、性能低下。
   - 3）然后就有了 synchronized  轻量级锁，使用 CAS 进行自旋抢锁优化，由于一直处于用户态下，所以，轻量级锁的开销是比较小。

4. 而其**缺点**则是，

   - 1）**只能保证单个变量的原子性**，当对一个变量执行操作时，可以使用 CAS 自旋的方式，来保证其原子性，但是，如果面对多个变量的操作时，CAS 就无法保证操作的原子性了。
     1. 解决方案是，把多个变量，合并成一个变量来操作。
   - 2）**空耗CPU资源**，在高并发场景下，大量的 CAS 做空自旋，会浪费很多 CPU 资源。
     1. 优化思路是，当并发修改的线程很少，冲突出现的机会很少时，自旋的次数很少，CAS 的性能会很高，而当并发修改的线程很多，冲突出现的机会很多时，自旋的次数很多，CAS 的性能则大大降低，所以，提升 CAS 无锁编程效率，关键在于减少冲突的机会。
     2. 一种解决方案是，**分散操作热点**，
        - 1）比如 LongAdder，其核心思想是热点分离，将 value 分离成一个数组，在多线程访问时，通过 Hash 算法，将线程映射到数组的某个元素进行操作，避免都访问同一个点。
        - 2）在最终结果获取时，则对数组中所有元素进行求和即可。
        - 3）可见，LongAdder 是通过以空间换时间的方式，将原来的一个 value 值，拆分为分布式的多个 value 数组元素，从而减少了 CAS 时线程之间的高冲突，以提升性能。
     3. 另一种解决方案是，**使用队列削峰**，将发生 CAS 争用的线程，加入一个队列中排队，降低 CAS 争用的激烈程度，比如 JUC#AQS 抽象队列同步器。
   - 3）**会有 ABA 问题**，是指线程在进行 CAS 操作时，虽然发现某个数据仍然等于期望值，CAS 也能操作成功，但这个期望值，可能已经不是之前意思了，存在被别的线程修改过、然后又修改回来的风险，这就是 ABA 问题。举个例子，在操作某个链表尾结点时，虽然看到的还是那个尾结点，但 CAS 操作成功之前，很可能就已经被别的线程，在前面增加了几个其他结点，此时的 CAS 面对的链表，实际上已经不是当时认为的那个链表了，是有问题的。
     1. 解决方案是，使用增加版本号或者时间戳的比较，比如，每次在执行数据的修改操作时，都带上一个版本号，版本号一致，才可以执行修改操作，并对版本号执行加 1 操作，否则，执行失败。由于每次操作的版本号都会增加，不会减少，因此，不会再出现 ABA 的问题。
   - 4）**会有发生总线风暴的风险**，
     1. CPU 会通过 MESI 缓存一致性协议，保障变量的缓存一致性，不同的内核需要通过总线来回通信，产生缓存一致性流量，由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将会成为瓶颈，导致总线风暴的发生。
     2. 不过，总线风暴与 CPU 架构有关，并不是所有的 CPU 都会产生总线风暴，在 SMP CPU 架构上，当有很多线程同时执行 `lockcmpxchg` lock 前缀指令操作时，可能会产生总线风暴。
     3. 而 Java#CAS，恰恰会在发现 CPU 是多核 CPU 时，为 CAS 底层的 `cmpxchg` CPU 原子指令，添加上 `lockcmpxchg` lock 前缀，导致存在总线风暴的风险。
     4. 解决方案还是那些，分散热点、使用队列削峰，最大程度地减少了同时 CAS 的操作数量。

   => 另，其他辅助资料有（选讲），

   - 1）Symmetric Multi-Processor，SMP，对称多处理器，服务器中多个 CPU 对称工作，每个 CPU 访问内存地址所需时间相同，主要特征是共享，包含对 CPU、内存、I/O 等进行共享。所有的 CPU 会共享一条总线，靠此总线连接主存，每个核都有自己的高速缓存，各核相对于总线，呈对称分布。因此，被称为对称多处理器。
   - 2）缓存一致性协议，指在多 CPU 的系统中，为了保证各个 CPU 的高速缓存中数据的一致性，会实现缓存一致性协议，每个 CPU 通过嗅探在总线上传播的数据，来检查自己的高速缓存中的值是否过期，当 CPU 发现自己缓存行对应的主存地址被修改时，就会将当前 CPU 的缓存行设置成无效状态，当其他 CPU 对这个数据执行修改操作时，本 CPU 会重新从系统主存中，把数据读到自己的高速缓存中。最常见的实现就是 MESI 协议。
   - 3）MESI 协议，是 MSI 写入失效协议的扩展，要求在每个缓存行（64字节，高速缓存操作的基本单位），维护两个状态位（2bit），使得每个缓存行可能处于 M 被修改的、E 独占的、S 共享的和 I 无效的 4 种状态的其中之一，是一种基于过期机制的高速缓存一致性保障协议。

##### 3、总

=> 以上，就是我对 CAS 的一些理解，请问有什么细节需要补充的吗？

#### 2.4. volatile 关键字的实现原理？

##### 1、总

1. 使用 volatile 关键字修饰变量，能够保证该变量的内存可见性，以及禁止该变量相关的指令重排序，但不能保证该变量做复合操作的原子性。
2. 不过，讲清楚 volatile 原理之前，还要讲一下内存屏障和 JMM Java 内存模型。

##### 2、分

###### 1）硬件层面的内存屏障

1. 内存屏障，Memory Barrier，又称内存栅栏，Memory Fences，是一系列的 CPU 指令，是一项让 CPU 高速缓存内存可见的技术，也是一项保障跨 CPU 内核有序执行指令的技术。
2. 硬件层内存屏障，共分为三种：读屏障、写屏障和全屏障。
   - 1）读屏障：Load Barrier，在指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，强制重新从主存加载数据，同时，会告诉 CPU 和编译器，先于这个屏障的指令必须先执行。
   - 2）写屏障：Store Barrier，在指令后插入写屏障，可以在指令执行时，让高速缓存中的最新数据更新到主存，让其他线程可见，同时，会告诉 CPU 和编译器，后于这个屏障的指令必须后执行。
   - 3）全屏障：Full Barrier，又称为 StoreLoad Barriers，是一种全能型的屏障，具备读屏障和写屏障的能力。
3. 所以，硬件层内存屏障的作用：
   - 1）强制让高速缓存的数据失效：它会强制把高速缓存中的最新数据写回主存，让高速缓存中相应的脏数据失效，一旦完成写入，任何访问这个变量的线程将会得到最新的值。
   - 2）阻止屏障两侧的指令重排序：编译器和 CPU，可能为了使性能得到优化，而对指令重排序，但是插入一个硬件层的内存屏障，相当于告诉 CPU 和编译器，先于这个屏障的指令必须先执行，后于这个屏障的指令必须后执行。

=> 由于不同的物理 CPU 硬件，所提供的内存屏障指令的差异非常大，因此，JMM 定义了自己的一套相对独立的内存屏障指令，用于屏蔽不同硬件的差异性，JMM 会要求，JVM 要为不同的平台，生成相应的硬件层的内存屏障指令。

所以，为了解释 volatile 的禁止指令重排序，还需要讲一下 JMM 的内存屏障~

###### 2）JMM Java 内存模型

![1630043244494](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630043244494.png)

1. JMM，Java Memory Model，Java 内存模型，它不像 JVM 内存结构那样，为真实存在的运行实体，而是体现为一种规范和规则，这些规范定义了一个线程对共享变量写入时，是如何确保对另一个线程是可见的。

   - 1）为此，JMM 提供合理的禁用缓存、以及禁止重排序的方法，以解决可见性和有序性。
   - 2）同时，它屏蔽了各种硬件和操作系统的访问差异，保证 Java 程序在各种平台下，对内存的访问最终都是一致的。

2. JMM 规定，所有变量都存储在主存中（类似于物理内存），每个线程都有自己的工作内存（类似于CPU中的高速缓存）。工作内存保存了线程使用到的变量的拷贝副本，线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行，不同线程之间，无法直接访问彼此工作内存中的变量，要想访问，就只能通过主存来进行传递。

3. 在 JMM 中，还定义了一套，JMM 主存与工作内存之间交互的协议，即一个变量是如何从主存拷贝到工作内存的，又是如何从工作内存写入主存的，该协议包含 8 种操作，并且要求 JVM 的具体实现，必须保证其中每一种操作都是原子的、不可分割的。

   ![1630045226983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630045226983.png)

   | JMM 操作 | 作用对象 | 说明                                                         |
   | -------- | -------- | ------------------------------------------------------------ |
   | Read     | 主存     | 读取。把一个变量的值从主存传输到工作内存中，以便随后的Load操作使用。 |
   | Load     | 工作内存 | 载入。把Read操作从主存中得到的变量值，载入到工作内存的变量副本中（可以简单理解为CPU的高速缓存）。 |
   | Use      | 工作内存 | 使用。每当JVM遇到一个需要使用变量值的字节码指令时，都会执行Use操作，会把工作内存中的一个变量值传递给执行引擎。 |
   | Assign   | 工作内存 | 赋值。每当JVM遇到一个给变量赋值的字节码指令时，都会执行Assign操作，操作引擎通过Assign操作给工作内存的变量赋值。 |
   | Store    | 工作内存 | 存储。把工作内存的一个变量值传递到主存中，以便随后的Write操作使用。 |
   | Write    | 主存     | 写入。把Store操作从工作内存中得到的变量值，写入到主存的变量中。 |
   | Lock     | 主存     | 锁定。把一个变量标识为某个线程独占的状态。                   |
   | Unlock   | 主存     | 解锁。把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 |

4. 关于 JMM 内存屏障，由于不同 CPU 硬件实现内存屏障的方式不同，JMM 屏蔽了这种底层 CPU 硬件平台的差异，定义了不对应任何 CPU 的 JMM 逻辑层内存屏障，提供了自己的内存屏障指令，要求 JVM 编译器实现这些指令，由 JVM 在不同的硬件平台，生成对应的内存屏障机器码，禁止特定类型的编译器（不是所有的编译器重排序都要禁止）和 CPU 重排序，从而解决有序性问题。

5. JMM 内存屏障，主要有 Load 和 Store 两类：

   - Load Barrier：读屏障，在读指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，重新从主存加载数据。
   - Store Barrier：写屏障，在写指令后插入写屏障，可以在指令执行时，让写入缓存的最新数据写回主存。

6. 然后，在实际使用时，JMM 会对 Load Barrier 和 Store Barrier 两类屏障进行组合：

   - 1）LoadLoad：LL 屏障，在 Load2 要读取的数据被访问前，使用 LoadLoad 屏障，能保证 Load1 要读取的数据被读取完毕。

     ```java
     // LoadLoad屏障伪代码
     Load1；LoadLoad；Load2
     ```

   - 2）StoreStore：SS 屏障，在 Store2 以及后续写入操作执行前，使用 StoreStore 屏障，能保证 Store1 的写入结果对其他 CPU 可见。

     ```java
     // StoreStore屏障伪代码
     Store1；StoreStore；Store2
     ```

   - 3）LoadStore：LS 屏障，在 Store2 以及后续写入操作执行前，使用 LoadStore 屏障，能保证 Load1 要读取的数据被读取完毕。

     ```java
     // LoadStore屏障伪代码
     Load1；LoadStore；Store2
     ```

   - 4）StoreLoad：SL 屏障，该屏障是一个全能型屏障，由于兼具其他3个屏障的效果，因此开销是 4 种屏障中最大的。在 Load2 以及后续所有读取操作执行前，使用 StoreLoad 屏障，能保证 Store1 的写入对所有 CPU 可见。

     ```java
     // StoreLoad屏障伪代码
     Store1；StoreLoad；Load2
     ```

###### 3）volatile 底层原理

1. 再说回 volatile，使用 volatile 关键字修饰变量，能够保证该变量的内存可见性，以及禁止该变量相关的指令重排序，但不能保证该变量做复合操作的原子性。

2. 保证内存可见性的意思是，使用 volatile 修饰的变量，在变量值发生改变时，会立刻同步到主存，并使其他线程的变量副本失效，即一个线程修改了某个 volatile 变量的值，该值对其他线程立即可见，其原理为：

   - 1）使用 volatile 修饰的变量，它的 JMM read、load、use 操作都是连续出现的，每次使用变量时，都要从主存读取最新的变量值，替换私有内存的变量副本值。
   - 2）同时，assign、store、write 操作也都是连续出现的，每次对变量的改变，都会立马同步到主存中，从而保证它的读写的内存可见性。

3. 另外，在硬件层面，volatile 变量操作的汇编指令前，会多出一个 lock 前缀指令 `lock ADD` ，lock 前缀指令具有以下功能：

   - 1）将当前 CPU 缓存行数据，立即写回主存，在执行指令期间。
   - 2）失效其他 CPU 中相同地址的缓存行，修改回写操作要经过总线传播数据，其他 CPU 通过嗅探在总线上传播的数据，来检查自己缓存的值是否过期，一旦发现自己缓存行对应的数据被修改，就会将自己的缓存行设置为无效状态，强制重新从主存中把数据读到自己的缓存中。

   => 以上两点，可以说是从硬件层面实现了 volatile 的内存可见性。

   - 3）lock 前缀指令，还可以作为内存屏障，禁止指令重排序，避免多线程环境下，程序出现乱序执行的现象。

4. 禁止指令重排序的意思是，用 volatile 修饰的变量，JVM 在生成字节码时，会在指令序列中插入内存屏障，

   - 1）在每个 volatile 读操作后，插入一个 LoadLoad 屏障，以及一个 LoadStore 屏障，禁止后面的普通读、普通写、和前面的 volatile 读操作之间发生重排序。

     ![1630053036307](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630053036307.png)

   - 2）在每个 volatile 写操作前，插入一个 StoreStore 屏障，在写操作后，插入一个 StoreLoad 屏障，禁止前面的普通写、和后面的 volatile 写操作之间发生重排序，同时，禁止后面的普通读、和前面的 volatile 写操作之间发生重排序。

     ![1630052862174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630052862174.png)

   => 以上两点，实现了 volatile 的有序性。

5. 虽然 volatile 修饰的变量，其要求对变量的（read、load、use）以及（assign、store、write）必须是连续出现的，每次读取的变量可以是最新值，且可以强制刷新回主存，但是在不同 CPU 内核上并发执行的线程，还是有可能出现读取脏数据的。比如：

   ![1630118559462](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630118559462.png)

   - 1）假设有两个线程 A、B，分别运行在 Core1、Core2 上，此时有个 value，值为 0，线程 A、B 也都读取了 value 值到他们自己的工作内存中。
   - 2）现在，线程 A 将 value 改成了 1 之后，完成了 assign、store 操作，但在执行 write 指令之前，线程 A 的 CPU 时间片用完了，导致 write 操作没有执行，value=1 没有到达主存。
   - 3）由于线程 A 的 store 指令触发了写信号，导致线程 B 的缓存行过期，B 则重新从主存读取了 value 值，此时线程 A 的 write 操作还没有完成，所以，线程 B 读到的 value 值还是 0。
   - 4）在线程 B 执行完成所有操作之后，则将 value 改成 1，并写入主存中。
   - 5）然后，线程 A 的时间片重新拿到，重新执行 store 操作，将过期了的 1 写入主存。
   - 6）此时，A、B 两线程执行了 2 次 +1 操作，但最终结果只增加了 1，而不是 2。
   - 7）因此，对 volatile 变量的复合操作不具备原子性，本案例中的复合操作是读取 value，value + 1，写回 value。
   - 8）对于这种复合操作，其原子性解决方案是，使用锁，保证临界区互斥执行。

##### 3、总

=> 以上，就是我对 volatile 的一些理解，请问有什么细节需要补充的吗？

#### 2.5. CountDownLatch 和 AQS 讲一下？

##### 1、总

1. AbstractQueuedSychronizer，简称 AQS，抽象队列同步器，使用它可以简单、⾼效地构造出，依赖单个原子值表示同步状态的、以及先进先出（FIFO）等待队列的阻塞锁和相关同步器。
2. 支持独占模式（默认）和共享模式，在不同模式下，等待线程同享一个 FIFO 队列。当以独占模式获取时，其他线程尝试获取不会成功。当以共享模式获取时， 其他线程尝试获取可能会成功。
3. 同时，还定义了一个内部的 ConditionObject 类，用作 Lock#Condition 的实现。

##### 2、分

###### 1）AQS 核心思想

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630209724753.png?lastModify=1648205707)

1. 如果请求的共享资源空闲，则将当前请求资源的线程，设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
2. 如果请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待、以及被唤醒时进行锁分配的机制，而这个机制 AQS 是通过主等待队列来实现的，即将暂时获取不到锁的线程，加⼊到队列中。
3. 每当线程通过 AQS 获取锁失败时，线程将被封装成一个 Node 节点，通过 CAS 操作，插入到队列尾部。
4. 当有线程释放锁时，AQS 会尝试让队头的后继节点占用锁。

###### 2）AQS 主等待队列

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630238528789.png?lastModify=1648205707)

1. AQS 主等待队列，是一个自旋等待队列，基于双向链表实现，每个节点都充当一个特定的通知式的监视器。
2. 要入列，只需要将 Node 结点，通过 CAS 拼接到队列尾部即可。
3. 要出列，则需要设置该结点为 head 结点，在其 Release 同步状态后，后继结点将会收到信号，会尝试获取同步状态，成为在队列中的 head 结点，但并不能保证成功，因为还可能需要与新来的结点，进行非公平竞争。

###### 3）Node 结点的数据结构

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630208598316.png?lastModify=1648205707)

1. 持有一个 waitStatus 数值，
   - 1）`初始时 waitStatus = 0`：表示当前节点处于初始状态。
   - 2）`int CANCELLED = 1`：表示线程因为中断或者等待超时，需要从等待队列中取消等待。
   - 3）`int SIGNAL = -1`：表示后继节点处于等待状态，当前节点如果释放了同步资源或者被取消，需要通知唤醒后继节点，让后继节点的线程得以重新运行。
   - 4）`int CONDITION = -2`：表示线程在条件队列中阻塞，当其他线程调用了 `ConditionObject#signal()` 方法后，被阻塞的线程会从条件队列，转移到 AQS 主等待队列上，去参与排队竞争。
   - 5）`int PROPAGATE = -3`：表示共享状态会被无条件地传播下去，让后面的 N 个节点都进行工作，从而实现共享锁被 N 个线程同时持有。
2. 一个 thread 指针：表示当前结点的线程引用。
3. 一个 nextWaiter 指针：
   - 1）如果当前结点为条件等待队列的结点，那么该值应该指向条件队列的后继结点。
   - 2）如果当前结点为 AQS 主等待队列的结点，那么该值只是作为独占模式的标记 `Node EXCLUSIVE = null`，或者共享模式的标记 `Node SHARED = new Node()` 。
4. 一个 prev 指针：表示前驱结点，用来处理取消结点，如果一个结点被取消，那么它的后继，会往前找到一个未取消的前驱，并重新链接、以及判断前驱是否为头结点，以让后继结点执行一次尝试获取同步资源的操作。
5. 以及一个 next 指针：表示后继结点，用来实现阻塞与通知机制，在前驱结点释放同步资源后，通过 next 指针，来确定唤醒哪个线程。

###### 4）AQS 扩展原理

1. 在 AQS 中，维持了一个 `private volatile int state`，表示同步资源状态，作为同步器子类实现的共享资源状态。
2. 以及提供几个钩子方法，让同步器子类去扩展，默认抛出 UnsupportedOperationException 异常。
   - 1）`tryAcquire(int)`：独占锁钩子，尝试获取独占资源。若成功则返回 true，若失败则返回 false 。
   - 2）`tryRelease(int)`：独占锁钩子，尝试释放独占资源。若成功则返回 true，若失败则返回 false 。
   - 3）`tryAcquireShared(int)`：共享锁钩子，尝试获取共享资源。负数，表示获取失败；正数，表示成功，且有剩余资源；0，也表示成功，但代表没有剩余可用资源。
   - 4）`tryReleaseShared(int)`：共享锁钩子，尝试释放共享资源。若成功则返回 true，若失败则返回 false 。
   - 5）`isHeldExclusively()`：独占锁钩子，判断当前线程，是否正在独占资源。
3. 而 AQS 其他方法，则都是 final 类型，无法再被子类重写，从而抽象队列同步框架的封装与扩展。

###### 5）独占模式实现原理

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630209980487.png?lastModify=1648205707)

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210001133.png?lastModify=1648205707)

1. 独占模式下，`tryAcquire(int)` 钩子返回的是 boolean 值，其含义取决于实现类具体的语义。主要思路是，如果要实现独占，就要保证，在获取同步资源时，如果已经存在了独占线程，那么就要返回 false，如果没存在独占线程，则可以返回 true。

2. 而在获取同步资源失败的，则要生成 Node 结点，加入 AQS 主队列中，参与排队竞争，竞争失败的，则将前驱结点设置为 `int SIGNAL= -1` 状态，然后阻塞。

3. 在前驱结点释放同步资源后，由于被后继设置为了  `int SIGNAL= -1` 状态，所以会唤醒后继结点，重新参与AQS 竞争。

4. 源码解析 - 普通式获取原理：`acquire(int arg)`，

   - 1）调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源，如果获取成功，则直接返回即可。
   - 2）如果获取失败，则把当前线程，构建成独占模式的 Node 结点，通过 CAS + 自旋的方式入队。
   - 3）入队成功后，则调用 `acquireQueued(final Node node, int arg)` 方法，自旋判断前驱是否为 head 头结点，如果是，则执行一次抢占同步资源的操作，抢占成功，则更新为 head 头结点（此时旧 head 结点脱钩将来会被 GC 掉），并返回 interrupted 中断标记（该方法唯一返回入口）。
   - 4）如果发现前驱不是 head 结点，或者抢占同步资源失败，则调用 `shouldParkAfterFailedAcquire(Node pred, Node node)` 方法，更新前驱为 `int SIGNAL= -1`，代表在该前驱释放同步资源成功后，需要唤醒当前线程。
   - 5）接着，使用 `LockSupport.park(this)` 来阻塞当前线程。
   - 6）最后，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，则检查线程中断状态，重新自旋判断前驱、抢占锁、或者继续阻塞。

5. 源码解析 - 可中断式获取原理：`acquireInterruptibly(int arg)`，对比普通式获取独占资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源前，会先检查线程是否被中断过，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占同步资源失败后，调用的是  `doAcquireInterruptibly()` 方法，来对结点进行入队。
   - 3）第三是，在自旋判断到前驱是否为 head 头结点，并成功抢占同步资源后，并不会返回任何值。
   - 4）最后是，在被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断了，则会立马抛出中断异常。

   => 可见，普通式获取返回的是中断标记，只能在方法调用返回后，才能做线程中断响应，而可中断式获取无任何返回值，是在方法调用过程中，做的线程中断响应，即抛出中断异常。这也正是两者之间最大的区别。

6. 源码解析 - 定时式获取原理：`tryAcquireNanos(int arg, long nanosTimeout)`，对比普通式获取独占资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquire(int)`，尝试以独占模式获取同步资源前，会先检查线程是否被中断过，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占同步资源失败后，调用 `doAcquireNanos(int arg, long nanosTimeout)` 方法来入队结点，并且根据当前系统纳秒时间，来计算剩余的过期时间。
   - 3）第三是接着，自旋判断到前驱为 head 头结点，并成功抢占同步资源后，会返回 true，代表在规定时间内，成功获取到了同步资源。
   - 4）第四是，如果前驱不为 head 头结点，或者抢锁同步资源失败，则会先根据当前系统纳秒时间，来计算剩余的过期时间，并且如果发现超过了定时时间，则会返回 false，代表未能在规定时间内，获取到同步资源。
   - 5）第五是，如果还没超过定时时间，则再调用 `LockSupport.parkNanos(this, nanosTimeout)` 来定时阻塞当前线程。
   - 6）最后是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，定时式获取与可中断式获取，最大的不同在于，有设置剩余等待时间，并且返回的 boolean 值，代表是否能够在规定时间内，获取到同步资源。

7. 源码解析 - 独占资源释放原理：`release(int arg)`，

   - 1）调用钩子方法 `tryRelease(int)`，尝试释放独占资源，如果释放失败，则直接返回 false 即可，代表释放失败。
   - 2）如果释放成功，则判断 head 头结点，如果 head 头结点为空，或者为独占脱钩，说明队列没有其他结点，则返回 true，代表释放成功。
   - 3）如果头结点为正常的业务结点，则还需要调用 `unparkSuccessor(head)` 方法，来唤醒后续排队的结点，唤醒后则返回 true，代表释放成功。
     1. 其中， `unparkSuccessor(head)` 方法，并不会更新后继为 head 头结点，而仅仅是更新头结点的waitStatus = 0、以及唤醒后继结点。
     2. 而更新 head 头结点、以及脱钩当前 head 头结点，是在后继获取同步资源成功后，才进行更新，这样可以保证由后继线程自己来确保成为头结点，比放在释放方法里更新要严谨一些。

**6）共享模式实现原理：**

1. 共享模式下，`tryAcquireShared(int)` 返回的是 int 值，其含义取决于实现类定义的语义。主要思路是，使用 `int PROPAGATE = -3`，来表示共享状态会被无条件地传播下去，让后面的 N 个节点都进行工作，从而实现共享锁被 N 个线程同时持有。

2. 其中，`int PROPAGATE = -3` 相当于一个占位的作用：

   - 1）如果结点不是最后一个获取到同步资源的，则状态为 `int PROPAGATE = -3` 。
   - 2）而如果结点是最后一个获取到同步资源的，则状态一开始为 `int PROPAGATE = -3`，不过很快就会在下一个结点进入阻塞前，设置为 `int SIGNAL= -1` 表示后继节点处于等待状态，当前节点如果释放了同步资源或者被取消，需要通知唤醒后继节点，让后继节点的线程得以重新运行。
   - 3）而当释放共享锁时，如果是 `int PROPAGATE = -3` 结点释放的，则无任何唤醒后继结点，如果是 `int SIGNAL= -1` 结点释放的，则会唤醒后继结点，接着又会重复，一片非最后的 `int PROPAGATE = -3` 结点以及最后一个为  `int SIGNAL= -1` 的结点，然后前面的操作。

3. 源码解析 - 普通式获取原理：`acquireShared(int arg)`，对比普通独占获取资源方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取共享资源，如果获取到的数量大于等于 0，说明获取成功，直接返回即可。
   - 2）第二是，如果获取到的数量小于 0 时，说明获取失败，则需要调用 `doAcquireShared(int arg)` 方法，来入队结点，但此时结点的 nextWaiter 不再是为 null，而是 SHARED，代表为共享模式的结点。
   - 3）第三是，接着，自旋判断到前驱为 head 头结点，是的话则进行一次尝试获取共享资源操作。如果获取的数量大于等于 0，说明获取成功，则调用 `setHeadAndPropagate(Node node, int propagate)` 方法，更新当前结点为 head 头结点。再调用 `doReleaseShared()` 方法，设置当前结点为 `int PROPAGATE = -3`，表示下一个线程获取共享资源后，当前的共享状态需要被无条件地传播下去，以通知其他等待的线程尽快获取共享资源。共享状态传播完毕后，返回之前，需要判断当前线程是否有被中断，是的话则设置线程中断标志再返回。
   - 4）最后是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程的中断状态，如果发现线程已被中断，不会抛出中断异常，而是更新代码局部变量中的中断标志位为 true，待自旋获取同步资源成功后，设置线程中断标志位处理。

   => 可见，共享式获取与独占式获取，最大的不同在于，入队获取共享资源成功后，是先设置当前结点为 `int PROPAGATE = -3`，然后再释放掉共享资源，进行一个共享状态的传播。

4. 源码解析 - 可中断式获取原理：`acquireSharedInterruptibly(int arg)`，对比普通式获取共享资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取共享资源前，会先检查线程是否被中断过，如果是则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占失败一次后，调用的是 `doAcquireSharedInterruptibly()` 方法，来入队结点。
   - 3）第三是，接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是直接返回，没有任何返回值。
   - 4）第四是，被 `LockSupport.unpark(当前线程的实例)` 唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，普通式获取返回的是中断标记，只能在方法调用返回后，才能做线程中断响应，而可中断式获取无任何返回值，是在方法调用过程中，做的线程中断响应，即抛出中断异常。这也正是两者之间最大的区别。

5. 源码解析 - 定时式获取原理：`tryAcquireSharedNanos(int arg, long nanosTimeout)`，对比普通式获取共享资源的方法，该方法主要不同的地方在于，

   - 1）第一是，调用 `tryAcquireShared(int)` 钩子方法，尝试获取同步资源前，会先检查线程是否被中断过，如果是则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，在抢占失败一次后，调用的是 `doAcquireSharedNanos(int arg, long nanosTimeout)` 方法，来入队结点，并且根据当前系统纳秒时间，来计算剩余过期时间，如果定时时间小于等于 0，则返回 false，代表未能在规定时间内获取到同步资源。
   - 3）第三是，自旋判断到前驱为 head 头结点，再尝试获取同步资源，获取成功并传播完毕后，返回之前并不会判断当前线程是否有被中断，而是返回 true，代表在规定时间内成功获取到了同步资源。
   - 4）第四是，如果前驱不为 head 头结点，或者抢占同步资源失败，则会继续根据当前系统纳秒时间，计算剩余过期时间，如果发现超过了定时时间，则会返回 false，代表未能在规定时间内获取到同步资源。
   - 5）第五是，如果最后前没超过定时时间，则调用的是 `LockSupport.parkNanos(this, nanosTimeout)` 来定时阻塞当前线程。
   - 6）最后是，被 `LockSupport.unpark(当前线程的实例)` 被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

   => 可见，定时式获取与可中断式获取，最大的不同在于，有设置剩余等待时间，并且返回的 boolean 值，代表是否能够在规定时间内，获取到同步资源。

6. 源码解析 - 共享资源释放原理：`releaseShared(int arg)`，对比独占资源释放方法，该方法主要不同的地方在于，

   - 1）第一是，调用钩子方法 `tryAcquireShared(int)`，尝试释放共享资源，如果释放失败，则直接返回 false 即可，代表释放失败。
   - 2）第二是，如果释放成功，则判断 head 头结点，如果 head 头结点为 `int SIGNAL= -1` 结点，则需要调用 `unparkSuccessor(head)` 方法，来唤醒后续排队的结点，唤醒后则返回 true，代表释放成功。
   - 3）最后是，如果头结点不为 `int SIGNAL= -1` 结点，而是脱钩独占结点，则通过 CAS 更新它为 `int PROPAGATE = -3`，表示当前走的是共享释放，要做共享状态的传播，然后返回 true，代表释放成功。

   => 可见，共享式释放与独占式释放，最大的不同在于，如果做的不是唤醒后继，则要把当前结点标识为 `int PROPAGATE = -3`，表示走共享释放，做共享状态传播。

###### 7）AQS 条件队列

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630238750935.png?lastModify=1648205707)

1. 讲条件队列之前，还要讲一下 Condition 接口，
   - 1）Condition，是 JUC 用来替代传统 `Object#wait()/notify()` 线程间通信与协作机制的新组件，其作用与 `Object#wait()/notify()` 相似，都会让一个线程等待某个条件，只有当该条件具备 `signal()/signalAll()` 方法被调用时，阻塞等待的线程才会被唤醒，重新去争夺锁。
   - 2）但不同的是，`Object#wait()/notify()` 由 JVM 底层实现，而 Condition 实现类，则完全是使用 Java 代码来实现，除了阻塞的底层是用了 `LockSupport#park()`。当需要进行线程间通信时，相比调用 `Object#wait()/notify()`，调用 `ConditionObject#await()/signal()` 这种方式实现起来更加高效。
2. 而 AQS 内部类 ConditionObject，正是 Condition 接口的实现，
   - 1）每个 ConditionObject 对象，都维护了一个单独的 AQS 条件队列。
   - 2）AQS 条件队列是单向的，而 AQS 主等待队列是双向的，他们是聚合的关系。
   - 3）因此，在一个显式锁上，可以创建多个 AQS 条件队列，而 Java 内置锁，只有唯一的一个等待队列。
   - 4）AQS 条件队列，也使用了相同的 Node 结点，但额外维护了一个 nextWaiter 指针，在调用`ConditionObject#await()` 时，会把一个 ConditionObject 结点，插入到条件队列中，然后等到 `ConditionObject#signal()` 信号，该结点会被转移到 AQS 主等待队列中，去参与同步资源竞争，竞争失败的会被阻塞，然后依赖 AQS 排队与通知机制实现唤醒。

###### 8）条件等待与唤醒原理

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210049637.png?lastModify=1648205707)

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630210030025.png?lastModify=1648205707)

1. ConditionObject 数据结构：

   - 1）firstWaiter：条件队列的头节点。
   - 2）lastWaiter：条件队列的尾节点。

2. 源码解析 - 条件等待原理：（类比于 `Object#wait()` 与 `Object#notify()/notifyAll()`）

   ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

   - 1）首先，会创建一个 Condition 类型的 Node 结点，即 Condition 结点，并放入条件队列的队尾。
   - 2）然后，调用 `release(int arg)` 方法释放所有独占资源。
     - 相当于 `Object#wait()` 释放内置锁资源。
   - 3）接着，判断 Condition 结点是否已经在主等待队列中，如果不是，则将当前线程阻塞，直到被调用 `doSignal()` 方法唤醒。
     - 相当于 `Object#wait()` 调用后，进入到 _WaitSet 等待队列中。
   - 4）如果被 `doSignal()` 放入了主等待队列（waitStatus 会被置为 0），并唤醒当前线程，则调用 `acquireQueued(final Node node, int arg)` 方法，获取独占资源，抢到则返回，没抢到则被 `LockSupport.part(this)` 给阻塞住，直到被 AQS 主等待队列的前驱唤醒。
     - 相当于 `Object#notify()/notifyAll()` 随机唤醒 _WaitSet 中的线程，并将它放入到 EntryList 候选竞争队列中。
   - 5）如果抢占到独占资源，  `acquireQueued(final Node node, int arg)` 方法返回，则先检查返回值，如果为 true，说明争抢期间发生了中断，则响应中断。
     - 相当于线程在 EntryList 中，竞争到锁资源，成为了 Owner Thread。

3. 源码解析 - 定时式条件等待原理：对比普通条件等待方法，该方法主要不同的地方在于：

   - 1）第一是，在创建 Condition 结点前，会先校验线程是否已中断，如果是，则会提前抛出中断异常，阻止继续往下执行。
   - 2）第二是，接着，会先根据系统纳秒时间，计算出超时时间，如果没有超时，则调用 `LockSupport.parkNanos(this, nanosTimeout)` 方法，来定时阻塞当前线程。
   - 3）第三是，如果发生了超时，则会将 Condition 结点，转移到 AQS 主等待队列中（waitStatus 会被置为 0），并退出 while 循环，调用 `acquireQueued(final Node node, int arg)` 去争抢同步资源，抢到则返回，没抢到则被 `LockSupport.part(this)` 给阻塞住，直到被 AQS 主等待队列的前驱唤醒。
   - 4）最后是，如果抢占到独占资源，  `acquireQueued(final Node node, int arg)` 方法返回，则先检查返回值，如果为 true，说明争抢期间发生了中断，则响应中断，要计算剩余的超时时间，并返回。

   => 可见，定时式条件等待与普通等待，最大的不同在于，定时等待会定时阻塞当前线程，发生超时或者被 `doSignal()` 唤醒，都会将 Condition 结点转移到 AQS 主等待队列、并退出 while 循环，还有的不同就是，定时等待会有返回值，表示剩余超时时间，而普通等待方法，则只会响应中断，没有任何返回值。

4. 源码解析 - 条件唤醒原理：

   - 1）先通过 CAS 的方式，将条件队列中的第一个 Condition 结点的 waitStatus 更新 0。
   - 2）然后，调用 `enq()` 方法，将结点转移到 AQS 主等待队列中，并设置前驱为 `int SIGNAL= -1`。
   - 3）最后，调用 `LockSupport.unpark(node.thread)` 唤醒 Condition 结点的线程，并返回 true，从而实现通知唤醒 Condition 结点的作用。
     - 相当于 `Object#notify()/notifyAll()` 随机唤醒 _WaitSet 中的线程，并将它放入到 EntryList 候选竞争队列中。

##### 3、总

基于 AQS 以上原理，JUC 中的典型实现有，

![img](file://D:/MyData/yaocs2/AppData/Roaming/Typora/typora-user-images/1630201659838.png?lastModify=1648205707)

###### 1）CountDownLatch

1. CountDownLatch，门闩，它允许一个或多个线程等待，直到一组操作执行完成后，才唤醒这些线程。
2. 它使用一个给定的计数值，进行初始化，调用 `await()` 方法可以使线程阻塞，直到计数被 `countDown()` 方法调用至零后，所有阻塞等待线程才会被唤醒，并且门闩使用一次后，任何 `await()` 再被调用时，会立即返回。
3. 因此，门闩计数无法被重置，是一个一次性的同步器，如果需要重置计数的实现，可以使用 CyclicBarrier。

它有几个核心方法，

1. 第一个是，构造方法，构造方法中，传入一个整数 n，作为 AQS 共享资源。
2. 第二个是， `await()` 方法，一般由主线程调用、并阻塞等待各工作线程签到完成，其实现原理为：
   - 1）底层调用了 AQS 的 `doAcquireSharedInterruptibly(arg)` 可中断式获取共享资源，该方法会先去调用钩子方法。
   - 2）由于 CountDownLatch#Sync 实现了 `tryAcquireShared(int)` 共享资源获取钩子，如果计数为 0，则返回 1，代表共享资源获取成功，则会传播式地唤醒一个又一个的线程，释放全部等待的线程。
   - 3）如果计数不为 0，则返回 -1，代表共享资源获取失败，则会阻塞所有调用的线程。
3. 第三个是，`countDown()` 方法，一般由子线程调用，表示当前线程工作已完成并签到一下，其实现原理为：
   - 1）底层调用了 AQS 的 `releaseShared(int arg)` 释放共享资源方法，该方法会先去调用钩子方法。
   - 2）由于 CountDownLatch#Sync 实现了 `tryReleaseShared(int)` 共享资源释放钩子，如果计数为 0，则返回 false，代表门闩已用完，不能重复使用。
   - 3）如果计数不为 0，则计数 -1，如果还没减到 0，则返回 false，代表当前线程还不是最后一个到达的线程，此时不会做任何唤醒操作。
   - 4）如果减到了 0，则返回 true，代表当前线程为最后一个到达的线程，然后回调 AQS 的 `doReleaseShared()` 方法，传播式唤醒所有等待线程。

###### 2）CyclicBarrier

1. CyclicBarrier，栅栏，它允许一组线程全部到达公共栅栏点后，执行一次指定栅栏任务，相对于 CountDownLatch，CyclicBarrier 的计数是可以被重置的，可以被重复使用。
2. 核心方法有 1 个，为 `await()` 方法，调用该方法的线程，在没符合条件时会阻塞住，直到栅栏条件达成后被唤醒。其实现原理为：
   - 1）先阻塞式获取 ReentrantLock 显示锁，获取到后，则获取分代实例 Generation，如果发现Generation 已经损坏，则抛出 BrokenBarrierException 异常。
   - 2）如果 Generation 还没损坏，则再检验当前线程的中断状态，如果发生了中断，则破坏当前 Generation，重置栅栏的参与线程数，并唤醒所有阻塞等待的线程。
   - 3）如果 Generation 还没损坏，且当前线程没被中断，说明当前线程达到了栅栏，因此栅栏的线程参与数 -1。
   - 4）如果计数减少到了 0，说明当前线程为最后一个到达栅栏的线程，如果有指定栅栏任务，则运行一次栅栏任务，然后生成下一代 Generation，重置栅栏的参与线程数，并唤醒所有阻塞等待的线程，并返回 0，代表当前线程到达栅栏的最后索引。
   - 5）如果计数还没减少到 0，则开始自旋，如果不需要超时，则调用 `Condiction#await()` 方法，阻塞当前线程，如果需要计时，且还没发生超时，则调用 `Condiction#awaitNanos()` 定时阻塞当前线程，因为这俩方法会释放显示锁的所有独占资源，以让其他线程能够顺利抢到显示锁。
   - 6）而在定时阻塞等待期间，任意一个线程发生了中断，则会破坏当前 Generation，唤醒所有阻塞等待的线程，并抛出异常。
   - 7）如果期间没发生中断，当前线程唤醒后，如果发现 Generation 已被破坏了，则抛出 BrokenBarrierException 异常，如果 Generation 没被破坏，但已被更新，说明最后一个线程确实到达了栅栏，则返回当前线程的到达索引。如果 Generation 没被破坏也没被更新，说明当前线程发生了等待超时，则破坏当前 Generation，唤醒所有阻塞等待线程，并抛出超时异常 TimeoutException。
   - 8）最后，释放 ReentrantLock 显示锁。

###### 3）ReentrantLock

1. ReentrantLock，Lock 接口的可重入、互斥锁实现，被称为显式锁，与使用 synchronized 具有基本相同的行为和语义，但功能更丰富，比如支持公平锁、定时式获取、锁持有检查等等。
2. 支持公平锁的意思是，在 ReentrantLock 构造时，传入 true，在锁争用时，锁会被等待时间最长的线程获取到，可以避免线程饥饿问题，但会降低整体的吞吐量。

它的核心方法主要有 3 个。

1. 首先说下，非公平、阻塞式的抢锁原理：`NonfairSync#lock()`，
   - 1）先使用 CAS，尝试更新同步资源（这里代表的是锁次数） 为 1，只有锁次数为 0，才会更新成功，说明当前线程非公平地提前抢到了锁。
   - 2）如果没抢到，则调用 AQS 的 `acquire(int arg)` 方法，老老实实地走 AQS 排队流程。
   - 3）由于 ReentrantLock#NonfairSync 实现了 `tryAcquire(int acquires)` 钩子方法，该方法底层调用 `Sync#nonfairTryAcquire(int acquires)` 方法。
   - 4）`Sync#nonfairTryAcquire(int acquires)` 方法，可以为 ReentrantLock 提供公共的、非公平的、非阻塞的尝试获取独占资源功能，
     1. 首先，它获取锁次数，如果锁次数为 0，说明当前线程第一次抢锁，则 CAS 更新锁次数为 1，代表第一次就抢锁成功，并设置当前线程为独占线程，然后返回 true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做。
     2. 如果锁次数不为 0，但独占线程为当前线程，说明发生了锁重入，则累加锁次数 + 1，然后返回true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做。
     3. 如果锁次数不为 0，且独占线程也不为当前线程，则返回 false，代表独占资源获取失败，需要等待独占线程释放资源，AQS `acquire(int arg)` 方法回调，阻塞当前线程，从而实现 ReentrantLock 非公平、阻塞式地抢锁。
2. 然后就是，公平、阻塞式的抢锁原理：`FairSync#lock()`，对比非公平、阻塞式获取锁的方法，该方法不同的地方在于，
   - 1）第一是，它一开始没有使用 CAS 尝试获取锁次数，而是直接调用了 AQS 的 `acquire(int arg)` 方法，老老实实地走 AQS 排队流程。
   - 2）第二是，由于 ReentrantLock#FairSync 实现了 `tryAcquire(int acquires)` 钩子方法，该方法先获取锁次数，如果锁次数为 0，说明当前线程第一次抢锁，不同的是，它会先判断 AQS 主等待队列中，有没有存在其他排队的线程，如果不存在，才 CAS 更新锁次数为 1，代表第一次就抢锁成功，并设置当前线程为独占线程，然后返回 true，代表获取独占资源成功，AQS `acquire(int arg)` 方法回调，则什么也不做，从而实现公平按排队、顺序抢锁的功能。
3. 最后就是，释放锁的原理：`ReentrantLock#unlock()`。
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ReentrantLock#Sync 实现了 `tryRelease(int acquires)` 钩子方法，为 NonfairSync 和 FairSync，提供释放独占资源的公共方法。
   - 2）该方法先通过当前锁次数 - 1，计算剩余锁次数。
   - 3）然后判断当前线程是否为独占线程，如果不是，则抛出 IllegalMonitorStateException 异常。
   - 4）如果是独占线程，则判断剩余锁次数是否为 0，是的话，则清空独占线程、重置锁次数，并返回 true，代表锁释放成功。
   - 5）如果剩余锁次数不是 0，则更新锁次数为剩余锁次数，即 -1，然后返回 false，代表锁仍被当前线程持有。

###### 4）ReentrantReadWriteLock

1. ReentrantReadWriteLock，读写锁，支持与 ReentrantLock 类似的语义，同样也支持公平和非公平、定时式获取、可重入等功能。
2. 但重入规则不同的是，只支持锁降级，不支持锁升级，即支持从写锁降为读锁，但不支持读锁升级为写锁。
3. 并且，只有写锁提供了 Condition 的支持，读锁并不支持。
4. 以及能够支持更高的读并发，适用于预期集合很大、读线程比写入线程多、读取时需要的开销大于写同步开销的场景。

它的核心方法主要有如下几个，分别是阻塞式获取非公平、公平写锁，非公平、公平读锁，释放写锁，释放读锁。

1. 首先，读写状态只使用了一个 int 整数来存储，高 16 位作为读次数，低 16 位作为写次数。
2. 然后就是，阻塞式获取非公平、公平写锁的原理：`WriteLock#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquire(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryAcquire(int acquires)` 钩子方法，为 NonfairSync 和 FairSync，提供获取独占资源的公共方法。
   - 2）`tryAcquire(int acquires)` 先获取整体的锁状态，以及写锁次数，如果锁状态不为 0，且写锁次数为 0，或者独占线程不是当前线程，说明存在读锁（读写要互斥），或者存在别的写锁（写写互斥），则返回 false，代表写锁获取失败。
   - 3）如果锁状态不为 0，但写锁次数不为 0，且独占线程就是当前线程，说明为当前线程重入获取写锁，则低 16 位写锁次数 +1，然后更新锁状态，返回 true，代表写锁重入成功。
   - 4）如果锁状态为 0，说明不存在任何读锁和写锁，则要看 `writerShouldBlock()` 钩子怎么实现，这里用于控制非公平和公平的逻辑：
     1. 如果实现的是非公平写锁，则要看 `NonfairSync#writerShouldBlock()`，该方法的实现只是直接返回 false，认为写锁获取时，无需任何阻塞等待，因为实现的是非公平锁。
     2. 如果实现的是公平写锁，则要看 `FairSyncwriterShouldBlock()`，该方法的实现是，看 AQS 主等待队列 head 头结点是否存在后继线程，如果存在，则返回 true，代表公平地排队获取写锁，否则返回 false，代表没有线程在排队，可以作为第一个线程，获取到写锁。
   - 5）因此，上述方法回调后会这样走，通过 CAS，更新写锁次数 + 1，设置独占线程为当前线程，然后返回 true，代表写锁获取成功。
3. 接着就是，阻塞式获取非公平、公平读锁的原理：`ReadLock#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquireShared(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryAcquireShared(int unused)` 钩子方法，为 NonfairSync 和 FairSync，提供获取共享资源的公共方法。
   - 2）`tryAcquireShared(int unused)` 先获取整体的锁状态，以及读锁次数、写锁次数，如果写锁次数不为 0，且独占线程不是当前线程，则返回 -1，说明存在写锁，且写锁不是自己锁持有，代表读锁获取失败（读写互斥）。
   - 3）如果写锁次数为 0，或者独占线程就是当前线程，说明不存在写锁，或者当前线程正在持有写锁，可以获取读锁（锁降级），此时要看 `readerShouldBlock` 钩子怎么实现，这里用于控制非公平和公平的逻辑：
     1. 如果实现的是非公平锁，则要看 `NonfairSync#readerShouldBlock()`，该方法的实现是，看第一个后继结点是否为独占模式，如果是的话，则返回 true，认为如果后一位在申请写锁，下次就要先轮到写锁，即使当前是非公平获取读锁，也去 AQS 主等待队列中排队等待，如果否的话，则返回 false，认为后一个没有在申请写锁，就可以先非公平获取读锁，无需进入 AQS 主等待队列排队。
     2. 如果实现的是公平锁，则要看 `FairSync#readerShouldBlock()`，该方法的实现是，看 AQS 主等待队列 head 头结点是否存在后继线程，如果存在，则返回 true，代表公平地排队获取读锁，否则返回 false，代表没有线程在排队，可以作为第一个线程，获取到读锁。
   - 4）因此，上述方法回调后会这样走，如果获取读锁不需要被阻塞，则 CAS 更新高 16 位读锁次数 +1，然后看之前的读锁次数是否为 0，如果是的话，则认为当前线程是第一次获取读锁，则用 `firstReader` 标记好，如果是当前线程重入获取读锁，则更新一级缓存中的读锁次数 + 1，否则说明当前线程是在重入别人的读锁，则更新二级缓存中的读锁次数 + 1，然后返回 1，代表读锁获取成功，实现非公平获取读锁。
   - 5）如果获取读锁需要被阻塞，或者 CAS 更新高 16 位读锁次数 + 1失败，则调用 `fullTryAcquireShared(Thread current)` 开始走自旋更新，大体逻辑与不被阻塞的类似，都是为了更新 `firstReader` 第一次获取读锁标记、一级缓存、二级缓存中的读锁次数，不过不一样的是，如果自旋过程中发现存在别线程获取到了写锁，或者当前线程是在第一次重入别人的读锁，那么就需要返回 -1，代表读锁获取失败，需要进入到 AQS 主等待队列中排队，实现公平获取读锁。
4. 再然后就是，释放写锁的原理：`WriteLock#unlock()`，
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryRelease(int releases)` 钩子方法，为 NonfairSync 和 FairSync，提供释放独占资源的公共方法。
   - 2）`tryRelease(int releases)` 先判断独占线程是否为当前线程，如果不是的话，则抛出IllegalMonitorStateException 异常，代表不能释放别人的写锁。
   - 3）如果独占线程就是当前线程，则更新低 16 位的写锁次数 - 1，如果更新后的写锁次数为 0，说明写锁释放了，则清空独占线程、更新整体锁状态，然后返回 0，代表写锁释放成功，最后回调到 AQS 中，通知唤醒 AQS 主等待队列中的后继结点。
   - 4）如果更新后的写锁次数不为 0，说明写锁还被当前线程持有，则更新整体锁状态，然后返回剩余写锁次数，代表写锁仍未释放，最后回调到 AQS 中，但不通知唤醒 AQS 主等待队列中的后继结点，什么也不做。
5. 最后就是，释放读锁的原理：`ReadLock#unlock()`，
   - 1）该方法底层调用了 AQS 的 `releaseShared(int arg)` 方法，由 ReentrantReadWriteLock#Sync 实现了 `tryReleaseShared(int unused)` 钩子方法，为 NonfairSync 和 FairSync，提供释放共享资源的公共方法。
   - 2）`tryReleaseShared(int unused)` 方法，先判断当前线程是否在释放自己的读锁，如果是第一次释放，则清空 `firstReader` 第一次读锁标记，如果是其他次释放，则更新一级缓存中的读锁次数 - 1，而如果不是在释放自己的读锁，则更新二级缓存中的读锁次数 - 1。
   - 3）然后开始自旋，先更新高 16 位的读锁次数 - 1，再 CAS 更新整体锁状态，更新失败的，则继续自旋，更新成功的，则返回剩余读锁次数是否为 0。
   - 4）如果是的话，则返回 true，代表读锁释放成功，最后回调到 AQS 中，传播式通知唤醒 AQS 主等待队列中的后继结点。
   - 5）如果不是的话，则返回 false，代表读锁释放失败，最后回调到 AQS 中，但不通知唤醒 AQS 主等待队列中的后继结点，什么也不做。

###### 5）Semaphore

1. Semaphore，计数信号量，它允许维护一组信号量许可，调用 `acquire()` 阻塞获取信号量许可，调用 `release()` 归还一个信号量许可，也支持非公平和公平模式，通常用于限制访问某些资源的线程数。
2. 当初始化为 1 个许可时，可用作互斥锁（二元信号量），但这种互斥锁与 ReentrantLock 显示锁不同，因为这种锁的许可，可以被其他线程释放掉，可以用作死锁的恢复。

它有几个主要的方法，

1. 首先是，构造方法，允许传入一个 int 整数，作为同步资源，在这里指的是信号量许可。
2. 然后就是，阻塞、非公平获取 n 个信号量许可的实现原理：`acquire(int permits)`，
   - 1）该方法底层调用了 AQS 的 `acquireSharedInterruptibly(int arg)` 方法，由 Semaphore#NonfairSync 实现了 `tryAcquireShared(int acquires)` 钩子方法，调用 Semaphore#Sync 的 `nonfairTryAcquireShared(int acquires)` 方法。
   - 2）`nonfairTryAcquireShared(int acquires)` 方法，会进行自旋，先获取剩余的信号量许可，然后扣减掉要获取的 n 个许可，判断扣减后的剩余许可是否小于 0，如果是的话，说明信号量许可不够了，回调到 AQS 中时，则需要去 AQS 主等待队列中排队。
   - 3）如果否的话，说明信号量许可还够，则尝试 CAS 更新信号量许可 - n，成功的话，则返回许可剩余数，代表许可获取成功，回调到 AQS 中时，无需进入 AQS 中排队，实现非公平获取信号量许可，如果 CAS 更新失败，则继续自旋。
3. 接着就是，阻塞、公平获取 n 个信号量许可的实现原理：`acquire(int permits)`，
   - 1）该方法底层调用了 AQS 的 `acquireSharedInterruptibly(int arg)` 方法，由 Semaphore#FairSync 实现了 `tryAcquireShared(int acquires)` 钩子方法。
   - 2） `tryAcquireShared(int acquires)` 方法，会进行自旋，与非公平获取不同的是，会先判断 AQS 主队列 head 头结点是否存在后继线程，如果存在，则返回-1，代表获取信号量许可失败，需要去 AQS 主等待队列中排队，实现公平式获取。
   - 3）如果不存在后继线程，则走与公平式获取相同的自旋逻辑。
4. 最后就是，释放 n 个信号量许可的实现原理：`release(int permits)`，
   - 1）该方法底层调用了 AQS 的 `releaseShared(int arg)` 方法，由 Semaphore#FairSync 实现了 `tryReleaseShared(int releases)` 钩子方法，为 NonfairSync 和 FairSync，提供释放共享资源的公共方法。
   - 2）`tryReleaseShared(int releases)` 方法，会进行自旋，先获取剩余的信号量许可，然后累加回这 n 个许可，判断累加后的剩余许可是否还小了，如果是则说明发生异常了，因为不能归还负的许可数，则抛出异常。
   - 3）如果剩余许可增加了，则 CAS 更新剩余信号量许可，更新失败的，继续自旋，更新成功的，则返回 true，回调到 AQS 中时，需要传播式通知唤醒后续结点，实现共享式传播信号量许可。

###### 6）ThreadPoolExecutor

1. Worker，线程池中的线程工人类，继承 AQS，实现了 Runnable 接口，实现了一个简单的、不可重入的、互斥的任务锁，在任务执行前，需要先获取独占锁，才能运行，运行完毕后释放，保证并发安全。

它有几个重要的方法，

1. 首先是，阻塞式获取独占锁原理：`ThreadPoolExecutor#Worker#lock()`，
   - 1）该方法底层调用了 AQS 的 `acquire(int arg)` 方法，由 ThreadPoolExecutor#Worker 实现了 `tryAcquire(int unused)` 钩子方法。
   - 2）`tryAcquire(int unused)` 方法，会尝试通过 CAS 更新独占资源，如果更新成功，则设置独占线程为当前线程，然后返回 true，代表独占锁获取成功，回调到 AQS 中，无需进入主等待队列中排队。
   - 3）如果更新失败，则返回 false，代表独占锁获取失败，回调到 AQS 中，需要进入主等待队列中排队。
2. 最后就是，释放独占锁原理：`ThreadPoolExecutor#Worker#unlock()`，
   - 1）该方法底层调用了 AQS 的 `release(int arg)` 方法，由 ThreadPoolExecutor#Worker 实现了 `tryRelease(int unused)` 钩子方法。
   - `tryRelease(int unused)` 方法，会清空独占线程、重置独占资源，并返回 true，代表独占锁获取成功（100% 成功），回调到 AQS 中，需要通知唤醒后继结点。

=> 以上，就是我对 AQS 的一些理解，请问有什么细节需要补充的吗？

#### 2.6. JDK 的新特性、新 JVM？

| JDK 版本 | 新特性                                                       |
| -------- | ------------------------------------------------------------ |
| JDK 5    | 自动拆装箱、 Foreach 循环、枚举类、泛型、JUC                 |
| JDK 6    | 对脚本语言 Ruby、Groovvy、JS 的支持                          |
| JDK 7    | switch 支持 String，开始转移永久代，静态变量、字符串常量池转移到了堆中 |
| JDK 8    | 函数式接口，Lambda 表达式，Stream API、接口支持 default 方法、HashMap 和 ConcurrentHasMap 性能提升、元空间完全取代永久代 |
| JDK 9    | 集合添加 List.of(xxx, xxx) 等工厂方法 、接口支持 private 方法，默认使用 G1垃圾收集器 |
| JDK 10   | G1 多线程并行 Full GC，降低 G1 STW 时间                      |
| JDK 11   | 新增 ZGC，比 G1 更细粒度的内存管理，采用并行回收策略         |
| JDK 12   | 新增 Shenandoah GC 算法、优化 G1 将垃圾分为强制部分和可选部分，强制部分会被回收，可选部分可能不会被回收，提高 GC 效率 |
| JDK 13   | ZGC 优化，将标记长时间空闲的堆内存返还给操作系统，只要保证堆大小不会小于 -Xms 即可 |
| JDK 14   | 删除 CMS 、弃用  Parallel Scavenge + SerialOld 的 GC 组合、将 ZGC 应用到 MacOS 和 Win 中 |
| JDK 15   | 新增隐藏类、密封类（避免抽象类被滥用）                       |
| JDK 16   | ZGC 性能优化，此版本相当于是对 JDK 14 和 15 的一些特性进行了正式的引入 |
| JDK 17   | 正式引入密封类 sealed class，限制抽象类的实现                |

#### 2.7. JDK 8 VS JDK 7？

| JDK 8 新特性                          | 解释                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| 函数式接口，Lambda 表达式，Stream API | 在需要一个函数，但又不想费神去命名一个函数时使用，也就是匿名函数，同时，还可以把函数作为参数，传递进某个方法中 |
| 接口支持 default 方法                 | 接口的默认实现                                               |
| 元空间完全取代永久代                  | 元空间使用本地内存，永久代使用 JVM 内存，从而根本上解决了永久代溢出的问题 |
| HashMap 性能提升                      | 拉链 >= 8 && 桶容量 >= 64 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、扩容时无需重新 rehash，只需要分高低位转移链表即可、改用尾插法解决并发插入时的 CPU 100% 问题 |
| ConcurrentHasMap 性能提升             | 拉链 >= 8 && 桶容量 >= 64 时会准换为红黑树，<= 6 时转换为链表、弃用哈希种子、Node+CAS+synchronzied+TreeBin 读写锁，替换掉 Segment+HashEntry+ ReentrantLock 分段锁、采用 CAS+synchronzied 实现渐进式并发扩容 |

#### 2.8. JDK 8 函数式接口的实现原理？

##### 1、总

1. 函数式接口，指**有且只有一个抽象方法的接口**，接口中的 static 方法、default 方法、Object 方法都不算抽象方法，且有个专门的注解 `@FunctionInterface`，但它不是必须的，如果接口符合以上函数式编程的语义，那么加不加这个注解都不影响，加上只是为了编译器进行检查而已，但如果不符合语义，又加上了该注解，那么编译器则会报错。
2. 有且只有一个抽象方法的原因是，由于函数式接口 ` () -> {} ` 的写法，主要是为了简化代码，相当于是一个**匿名内部类的匿名函数**，如果有多个抽象方法，编译器则不知道是重写哪个方法了，所以只能有且只有一个抽象方法。

##### 2、分

在 JDK 8 中，函数式接口主要分为 4 类，分别是**供给型、消费型、断言型和方法型**，其中它们的方法又可以和定义的 default 方法进行**连用**。

| 接口           | 方法               | 说明                                          |
| -------------- | ------------------ | --------------------------------------------- |
| Supplier< T >  | T get();           | 供给型，无参，返回的一个泛型结果              |
| Consumer< T >  | void accept(T t);  | 消费型，传入一个泛型对象，但没有返回值        |
| Predicate< T > | boolean test(T t); | 断言型，传入一个泛型对象，但返回 boolean 类型 |
| Function< T >  | R apply(T t);      | 方法型，传入一个泛型对象，返回另一个泛型结果  |

##### 3、总

以上就是我对 JDK 8 函数式接口的理解，它是 Lambda 表达式和 Stream API 的基础，使用这种方式来编码，既简洁又高效。

### 7> Spring

#### 1.1. 说说你对 IoC 的理解？

1. **IoC**，Inversion of Control，控制反转，是⼀种设计思想，指将原本在程序中⼿动创建对象的控制权，交由专门的容器来进行管理，比如 Spring，而 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 
2. **IoC 容器**，是 Spring ⽤来实现 IoC 的载体， 实际上就是个 Map（key，value）键值对，其中存放的是各种对象，将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注⼊。
   - **DI**：Dependancy Injection，依赖注入，站在容器的角度，将对象创建依赖的其他对象，注入到该对象中。
3. 也就是，**IoC 容器**像⼀个⼯⼚，当需要创建⼀个对象时，只需要配置好配置⽂件或者注解即可，不⽤考虑对象是如何被创建出来的，这样可以很⼤程度上简化应⽤的开发，把应⽤从复杂的依赖关系中解放出来。 

#### 1.2. Spring IOC 容器的实现原理？

1. 先准备一个基本的容器对象，包含一些 map 结构的集合，用来方便后续过程中存储具体的对象。
2. 进行配置文件的读取工作，或者注解的解析工作，将需要创建的 bean 对象，都封装成 BeanDefinition 对象存储在容器中。
3. 容器将封装好了的 BeanDefinition 对象，通过反射的方式进行实例化，完成对象的实例化工作。
4. 进行对象属性的依赖注入工作，完成整个对象的创建，成为一个 bean 对象，存储在容器的 map 结构中。
5. 通过容器来获取对象，进行对象的获取和逻辑处理工作。
6. 提供销毁操作，当对象不用，或者容器关闭时，将无用的对象进行销毁。

#### 1.3. Spring 启动流程原理？

![1645341206075](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645341206075.png)

```java
public abstract class AbstractApplicationContext extends DefaultResourceLoader
implements ConfigurableApplicationContext {
	@Override
    public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) {
        // 1：刷新前的预处理，包括一些scanner缓存清空、标志位active激活、时间戳记录等 
        prepareRefresh();
        // 2: 获取DefaultListableBeanFactory
        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
        // 3: 做一些BeanFactory的准备工作，包括设置classLoader、注册environment、systemProperties、systemEnvironment单例等
        prepareBeanFactory(beanFactory);
        try {
                // 4: 允许一些上下文子类在BeanFactory完成准备工作后，做一些后置的处理工作
                postProcessBeanFactory(beanFactory);
                // 5: 实例化并顺序执行BeanFactoryProcessor，以在实例化Bean之前，添加更多的BeanDefinition，其中核心的是ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry去扫描解析所有@Configuration下的@PropertySource、@ComponentScan、@Import、@ImportResource、@Bean，并加载成为BeanDefinitions
                invokeBeanFactoryPostProcessors(beanFactory);
                // 6: 实例化并注册所有的BeanPostProcessor，但没有执行，要在Bean初始化前/后再执行
                registerBeanPostProcessors(beanFactory);
                // 7: 实例化并注册MessageSource组件，用于做国际化功能、消息绑定、消息解析等
                initMessageSource();
                // 8: 实例化并注册事件多播器，用于观察者模式
                initApplicationEventMulticaster();
                // 9: 允许一些上下文子类，在容器刷新时自定义逻辑 
                onRefresh();
                // 10: 注册ApplicationListener
                registerListeners();
                // 11： 实例化所有剩下非懒加载的单例Bean，并完成它们的初始化和依赖注入，通过遍历所有beanNames，然后挨个判断走FactoryBean的流程，还是走BeanFactory的流程，其中主要步骤总结起来分为3步，分别是NewInstance实例化、Populate属性赋值、Initialization初始化。其中，在Bean实例化前/后，还会执行一堆的BeanFactoryProcessor
                finishBeanFactoryInitialization(beanFactory);
                // 12: 完成上下文的刷新，主要是调用LifecycleProcessor#onRefresh()方法
                finishRefresh();
            }
        ...
	}
}
```

#### 1.4. Spring 是如何解决循环依赖的？

- **概念**：循环依赖，其实就是 Bean 的循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成依赖闭环，比如 A 依赖于B，B又依赖于A。

- **Spring中循环依赖场景有**: 

  1. prototype 原型 bean 的循环依赖。
  2. 构造器注入的循环依赖（构造器注入）。
  3. Field 属性注入的循环依赖（set注入）。

  => 其中，**构造器的循环依赖**问题无法解决，在解决属性循环依赖，也可以使用**懒加载**，而 Spring 采用的是**提前暴露对象**的方式来解决的。

- **懒加载 @Lazy 解决循环依赖问题**：

  1. Spring 启动时，会把所有的 bean 信息，包括 XML 和注解解析转化成 Spring 能够识别的 BeanDefinition 存到 HashMap 里，供后面初始化时使用。
  2. 然后对每个 BeanDefinition 进行处理，普通 Bean 初始化是在容器启动初始化阶段执行的，而被 `lazy-init=true` 修饰的 bean，则是在从容器里第一次进行 `context.getBean()` 时才会被触发，而此时其依赖的普通 Bean 早就被初始化完毕了，所以可以解决正常情况下的属性注入的循环依赖问题。 

- **三级缓存解决循环依赖问题**：

  ![1645350673009](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645350673009.png)

  Class A 依赖（这里是 @Autowire） Class B，Class B 又依赖（这里是 @Autowire） Class A，造成循环依赖，Spring 的解决方式是**三级缓存**：

  1. Class A 首先被实例化（一个空壳），实例化后立马放入三级缓存中。
  2. 然后在 populateBean 填充 Class A 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class B name 调用 doGetBean 方法，获取 Class B 的实例。
  3. 然后在 Class B 也被实例化（一个空壳），实例化后也立马放入三级缓存中。
  4. 然后在 populateBean 填充 Class B 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class A name 调用 doGetBean 方法，获取 Class A 的实例。
  5. 由于此时 A 已经在三级缓存中，所以取出 A 的 ObjectFactory 表达式并执行，获取到 Class A 实例的引用。
     - 其中要注意的是，这个表达式调用的 `getEarlyBeanReference(beanName, mbd, bean)` 方法，可以获取 AOP 代理的空壳引用，即该方法要么返回的是原对象，要么返回的是代理对象，如果返回的是代理对象，那么该代理对象 B'/A' 不会持有另外一个 A/B 的引用，而是**持有 B/A 原对象的引用**，再由原对象去持有 A/B 的引用，而 A/B 则持有代理对象的引用 B'/A'。
  6. 获取到 Class A 实例的引用，设置到二级缓存中，删除 A 三级缓存，并返回给 Class B 注入。
  7. 此时 Class B 已经解决了循环依赖 A 的问题，最后设置单例 Class B 到一级缓存中，删除 B 二三级缓存。
  8. 由于此时 B 已经在一级缓存中，所以取出 B 实例引用，返回给 Class A 注入。
  9. 此时 Class A 也解决了循环依赖 B 的问题，最后设置单例 Class A 到一级缓存中，删除 A 二三级缓存。

  => 最后，Class A、Class B 分别完成注入，也就是解决了循环依赖的问题。

#### 1.5. SpringBoot 自动装配和自定义 starter？

##### 1、总

Starter 是什么：

1. Starter 就是一个 jar 包，写一个 @Configuration 的配置类，把这些 Bean 的定义都包含在其中，然后在 Starter 包下的 `META-INF/spring.factories` 中写入该配置类，SpringBoot 程序在启动时，就会按照约定来加载该配置类。
2. 开发人员只需要将相应的 Starter 包依赖进应用中，然后进行相关的属性配置，就可以进行代码开发，而不需要再单独对 Bean 进行配置。

##### 2、分

原理：

1. 当启动 SpringBoot 应用时，会先创建 SpringApplication 的对象，在对象的构造方法中，会进行某些参数的初始化工作，最主要的是判断当前应用的类型（比如 Servlet 类型），以及通过 SPI 的方式加载整个应用的 `spring.factories` 文件中的初始化器和监听器的 Class。
2. SpringApplication 对象创建完成之后，开始执行 `run()` 方法，来完成整个启动，启动过程中最主要的有两个方法，第一个叫做 `prepareContext()`，第二个叫做 `refreshContext()`，在这两个步骤中完成了自动装配的核心功能，而其他方法的处理逻辑包含了上下文对象的创建、Banner 的打印、异常报告期的准备等各个准备工作，方便后续来进行调用。
3. 在 `prepareContext()` 方法中，主要完成了对上下文对象的初始化工作，包括比如 `Enviroment`对象属性值的设置，在整个过程中，有一个非常重要的方法 `load()`，`load()` 主要完成一件事，那就是将**启动类**作为BeanDefinition 注册到 Registry 中，方便后续在进行 BeanFactoryPostProcessor 调用执行时，找到对应的启动类来完成 `@SpringBootApplication` 和 `@EnableAutoConfiguration` 等注解的解析工作。
4. 在 `refreshContext()` 方法中，会进行整个容器的刷新过程，会调用 Spring 中的启动流程，即`AbstractApplicationContext#refresh()`，有 13 个关键方法，来完成整个 Spring 应用的启动，其中会调用 `invokeBeanFactoryPostProcessor()` 方法，主要是对`ConfigurationClassPostProcessor` 的处理，会先调用实现 `BeanDefinitionRegistryPostProcessor` 接口的 `postProcessBeanDefinitionRegistry()` 方法，然后再调用自己实现的 `postProcessBeanFactory()` 方法，处理各种包括 @PropertySource、@ComponentScan、@Import、@ImportResource、@Bean 等注解。
5. 其中，在解析 @Import 注解时，会有一个 `getImports()` 的方法，会从**启动类**开始递归解析注解，把所有包含 @Import 注解都收集到，然后在 `processImport()` 方法中，对 Import 导入的类进行分类，这里主要起识别作用的是 `ImportSelect` 的实现类  `AutoConfigurationImportSelect`，来调用 `selectImports()` 方法使用 SPI 的方式，来获取并加载 `spring.factories` 中的 `EnableAutoConfiguration` 自动装配配置类的 Class，完成自动装配。
6. 接着，还调用子类上下文 `ServletWebServerApplicationContext#onRefresh` 方法，来拉起嵌入式的 Tomcat 容器。
7. 最后，就是实例化 Bean，即 `finishBeanFactoryInitialization()` 方法，主要是实例化所有剩下非懒加载的单例 Bean，并完成它们的初始化和依赖注入，通过遍历所有 beanNames，然后挨个判断是走 FactoryBean 的流程，还是走 BeanFactory 的流程，其中主要步骤总结起来分为 3 步，分别是 NewInstance 实例化、Populate 属性赋值 和 Initialization 初始化，从而完成自动装配配置 Bean 的注入。其中，在Bean实例化前/后，还会执行一堆的BeanFactoryProcessor。

##### 3、总

自定义 Starter：

1. 创建 Starter 项目，定义 Starter 需要的 Properties 配置类，比如数据库连接信息等。
2. 然后编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean。
3. 编写 `META-INF/spring.factories` 文件，以让 SpringBoot 在启动时加载自动配置类。
4. 然后在项目中，引入自定义 Starter 的 Maven 依赖，增加对应的配置值后，然后即可直接使用。

#### 1.6. Spring MVC 拦截器和过滤器的区别？

##### 1、总

拦截器 HandlerInterceptor，过滤器 Filter，虽然可以对请求进行一定处理，但：

1. **实现人不同**：HandlerInterceptor 属于 Spring#Web 包下，Filter 属于 Tomcat#javax 包下。
2. **配置方式不同**：HandlerInterceptor 在 Spring#WebMvcConfigurer 中配置，而 Filter 在 web.xml 中配置。
3. **处理时机不同**：HandlerInterceptor 作用更强大，方法处理前的拦截、处理后的拦截、返回前的拦截，而 Filter 则是在进入 DispatcherServlet 前进行一定的请求过滤处理。

##### 2、分

![1645947452956](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645947452956.png)

Spring MVC 客户端请求的生命周期管理：

1. **Filter#doFilter** 执行链过滤客户端请求。
2. DispatcherServlet，表示中心控制器，在客户端发出请求后，经过 Web 容器（比如 Tomcat）后，会打到 DispatcherServlet 上，并由其来处理请求。
3. HandlerMapping，表示处理器映射，DispatcherServlet 收到请求后，会调用 HandlerMapping，HandlerMapping 会根据请求 url 去查找对应的 Handler，即一个 Handler Method 对象，指的是 url 对应 Controller 中的对应方法。
4. HandlerExecutionChain，表示处理器执行链，Handler 解析完 url  后，会返回一个处理器执行链给DispatcherServlet，其中就包括一堆 HandlerInterceptor。
5. HandlerAdapter，表示处理器适配器，DispatcherServlet 会按照规则去匹配对应的 HandlerAdapter。
6. 再由对应的 Handler Method 去处理请求，其中就包括调用去执行我们编写的 Controller 业务逻辑。
   - 但在执行前，会先调用 **HandlerInterceptor#preHandle** 进行  handler 方法处理前的拦截。
7. Controller 代理对象，则会去访问数据库，填充好模型后，再把 ModelAndView 返回给 HandlerAdapter。
   - 其中，在 HandlerAdpater#resolveArgments 时，HttpMessageConverter读取完 body 前/后，可以对 **RequestBodyAdvice#beforeBodyRead/afterBodyRead** 进行回调，从而改写 body。
   - 而我们平常使用的 @ResponseBoday 的方法，返回的 ModelAndView 为空，也就是不会返回视图给客户端，而是经过 `RequestResponseBodyMethodProcessor`，把 JSON 串写入到 Response 的 Body 中。
8. HandlerAdapter 收到后，再将 ModelAndView  传递给 DispatcherServlet。
9. DispatcherServlet 收到后，则调用视图解析器 ViewResolver，来解析 ModelAndView。
10. ViewResolver 会解析逻辑视图名，根据逻辑的 View 找到实例的 View，并返回给 DispatcherServlet。
11. DispatcherServlet 收到后，则根据 ViewResolver 解析出的 View，调用对应的实际视图，结合 Model 进行渲染。
    - 但在执行前，会先调用 **HandlerInterceptor#postHandle** 进行 handler 方法处理后的拦截。
12. 最后，DispatcherServlet 再将渲染后的 View 作为结果，响应给客户端。
    - 在执行后，返回结果前，会调用 **HandlerInterceptor#afterCompletion** 进行响应前的拦截。

##### 3、总

以上，就是我对 Spring MVC 拦截器和过滤器的一个理解，请问有什么细节需要补充的吗？

#### 1.7. Spring AOP 的原理？

##### 1、总

AOP，Aspect-Oriented Programming，⾯向切⾯编程，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑，或者责任封装起来（比如事务管理、⽇志管理、权限控制等），以便于减少系统的重复代码，降低模块间的耦合度，有利于未来的可拓展性和可维护性。

##### 2、分

1. AOP 有 **7 个核心概念**：

   - 1）**切面**：Aspect，指对哪些方法进行拦截处理的横切关注点，可能会横切多个对象，比如 Spring 的事务管理， 在 Spring AOP 中，切面可以在普通类中以 `@Aspect` 注解来实现。
   - 2）**连接点**：Join point，指在程序执行过程中某个特定的点，比如某个方法调用的时间点，或者处理异常的时间点，在 Spring AOP 中，一个连接点代表一个方法的执行。
   - 3）**通知**：Advice，在切面的某个特定的连接点上执行的动作，通知有多种类型，包括 `around`， `before`， 和 `after` 等等。
   - 4）**切点**：Pointcut，匹配连接点的断言，通知会在满足这个切点的连接点上运行，比如 AOP 去执行某个特定名称的方法。
   - 5）**目标对象**：Target object，被一个或者多个切面所通知的对象，也被称作被通知的业务对象。
   - 6）**织入**：Weaving，把切面连接到目标对象上，并创建一个代理对象的过程。
   - 7）**AOP 代理**：AOP proxy，AOP 框架创建的对象，用来实现切面契约，包括通知方法执行等功能，在Spring 中，AOP 代理可以是 JDK 动态代理，或者是 CGLIB 动态代理。

   => 比如日志管理的公共代码，可以抽象出一个**切面**，然后匹配**切点**，通过动态代理，将对**目标对象**（具体的业务对象）进行增强，在进行调用时，代理对象会根据**通知**类型，在对应的**连接点**，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

2. **实现原理**：

   - 1）Spring AOP 是基于动态代理实现的，是 IoC 的一个扩展功能，是在 IoC 整个流程中新增的一个 BeanPostProcessor（`AbstractAutoProxyCreator`）扩展点而已。
   - 2）`AbstractAutoProxyCreator` 实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
   - 3）如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
   - 4）⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 ASM 框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。

##### 3、总

=> 以上，就是我对 Spring AOP 的一些理解，请问有什么细节需要补充的吗？

#### 1.8. Spring @Transactional 原理？

##### 1、总

`@Transactional`，是 Spring 中事务传播配置的注解，可通过 `@EnableTransactionManagement` 启用事务传播特性，其中，Spring 事务传播属性分为以下几种：

| 属性                     | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| REQUIRED（默认属性）     | 如果存在一个事务，则支持**当前事务**，如果没有事务，则开启一个**新的事务** |
| MANDATORY                | 支持**当前事务**，如果当前没有事务，就**抛出异常**           |
| NEVER                    | 以**非事务**方式执行，如果当前存在事务，则**抛出异常**       |
| NOT_SUPPORTED            | 以**非事务**方式执行操作，如果当前存在事务，就把当前事务**挂起** |
| REQUIRES_NEW（相互独立） | **新建事务**，如果当前存在事务，把当前**事务挂起**，内外两个事务相互独立，互不影响，当外层事务失败时，并不会回滚内层事务所做的动作，而内层事务操作失败时，也不会引起外层事务的回滚 |
| SUPPORTS                 | 支持**当前事务**，如果当前没有事务，就以**非事务**方式执行   |
| NESTED（局部回滚）       | 支持**当前事务**，新增 Savepoint 点，与当前事务**同步提交或回滚**。嵌套事务一个非常重要的概念，就是内层事务依赖于外层事务，当外层事务失败时，会回滚内层事务所做的动作，而内层事务操作失败时，并不会引起外层事务的回滚 |

##### 2、分

其**实现原理**为：

1. Spring 的事务是由 AOP 来实现的，首先按照 AOP 的整套流程来执行具体的操作逻辑，使用 `InfrastructureAdvisorAutoProxyCreator` （AbstractAutoProxyCreator 的子类）来生成具体的代理对象。
2. 然后通过一个 `TransactionInterceptor` 来实现，在调用 `JdkDynamicAopProxy#invoke(proxy, method, args)` 方法时，则代理到 `TransactionInterceptor`  实现的具体逻辑中。
3. 在调用代理方法时，会先做准备工作，解析各个方法上事务相关的属性，根据具体的属性来判断是否开始新事务。
4. 当需要开启事务时，则获取数据库连接，关闭自动提交功能，开启事务。
5. 然后执行原始业务逻辑。
6. 如果在执行过程中发生异常，那么会通过 `completeTransactionAfterThrowing(..)` 来完成事务的回滚操作，回滚的具体逻辑是通过 `doRollBack(..)` 方法来实现的，实现的时候也是要先获取链接对象，再通过连接对象来回滚。
7. 而如果执行过程中，没有任何意外情况的发生，那么通过 `commitTransactionAfterReturning(..)` 来完成事务的提交操作，提交的具体逻辑是通过 `doCommit(..)` 方法来实现的，实现的时候也要获取链接，通过链接对象来提交。
8. 当事务执行完毕之后，需要通过 `cleanupTransactionInfo(..)` 来清除相关的事务信息。 

##### 3、总

因此，在平常使用过程中，应该留心以下**注意事项**：

1. 事务函数中不要处理耗时任务，会导致长期占有数据库连接。
2. 事务函数中不要处理无关业务，防止产生异常导致事务回滚。
3. 一些 Spring 事务传播**失效场景**有：
   - 1）Bean 对象没有被 Spring 容器所管理。
   - 2）调用方法的访问修饰符不是 public。
   - 3）数据源没有配置事务管理器。
   - 4）数据库不支持事务。
   - 5）异常被捕获，所以没有回滚。

=> 以上，就是我对 Spring @Transactional 的一些理解，请问有什么细节需要补充的吗？

#### 1.9. 讲一下 Eureka 源码？

##### 1、总

![1638234417008](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638234417008.png)

1. 在传统应用组件间调用，是通过接口规范约束来实现的，从而实现不同模块间良好协作。
2. 但是在被拆分成微服务后，每个微服务实例的网络地址和数量都可能动态变化，导致使用原来硬编码地址的方式极不方便，因此，需要一个中心化的组件来进行服务的登记和管理。
3. Eureka，是 Spring Cloud 的一个基于 AP 模型的注册中心，支持服务注册、服务发现、服务调用、服务续约、服务剔除、服务自保、服务下线、集群高可用等功能。
4. 其实现包括 Server 端和 Client 端，Server 端可以作为一个公共的注册中心服务，为 Client 提供服务注册和服务发现的功能，维护自身的服务列表信息，Client 端又分为服务提供者和服务消费者，服务提供者通过注册自身的信息到 Server 端，方便消费者发现自己，服务消费者，通过服务发现，从 Server 端拉取服务列表，然后使用内置的负载均衡器，实现服务调用。

##### 2、分

###### 1）Eureka Server 启动原理

1. 首先，@EnableEurekaServer 会导入一个 `EurekaServerMarkerConfiguration`，这个配置类会加载 `Marker` 标志类。
2. 然后，Spring Boot 会自动装配 `EurekaServerAutoConfiguration`，只有存在 `Marker`  标志类时，Spring 才会去解析这个配置 Bean。由于`Marker`  标志类已被 @EnableEurekaServer 导入了，所以，该配置 Bean 会继续读取 `classpath:/eureka/server.properties`，往 IOC 注入注册表等 Bean 对象。
3. 接着，`DefaultLifecycleProcessor` 实现了 `LifecycleProcessor#onRefresh()` 生命周期回调接口，在 Spring 执行到 `AbstractApplicationContext#finishRefresh()` 时进行回调，该方法会启动一个异步线程，去初始化 Eureka Server 环境、上下文，以及读取 `eureka.server.evictionIntervalTimerInMs` （默认 60 s）， 启动一个定时任务 `EvictionTask`，执行**服务剔除**逻辑。

###### 2）Eureka Client 启动原理

1. 首先，Spring Boot 启动时，会自动装配 `EurekaClientAutoConfiguration` ，该配置 Bean 会装配一个 `EurekaClient`，并指定其 `shutdown()` 方法，实现**服务下线**。
2. 在构造 `EurekaClient` 时，会：
   - 1）读取 `eureka.instance.lease.renewalInterval` 续约周期（默认 30 s），创建 ` heartbeatExecutor` 线程池，启动 `HeartbeatThread` 线程任务，用于定时**服务续约**。
   - 2）读取 `eureka.client.refresh.interval` 服务列表拉取周期（默认 30 s），创建 ` cacheRefreshExecutor` 线程池，启动 `CacheRefreshThread` 线程任务，用于定时**服务发现**，刷新服务列表缓存。
   - 3）读取 `eureka.appinfo.initial.replicate.time` 注册延迟时间（默认 40 s），启动 `InstanceInfoReplicator` 线程任务，用于**服务注册**。

###### 3）服务注册原理

1. Eureka Client `InstanceInfoReplicator` 线程任务，延迟 `eureka.appinfo.initial.replicate.time` （默认 40 s）后，调用 `discoveryClient.register()` 做服务注册。
2. 它会经过一些列的装饰者调用，包括 `SessionedEurekaHttpClient#execute ` 更新 session 时间、`RetryableEurekaHttpClient#execute ` 默认最大重试 3 次、`RedirectingEurekaHttpClient#execute` 重定向配置、`MetricsCollectingEurekaHttpClient#execute` 指标记录。
3. 最终，调用到 `AbstractJerseyEurekaHttpClient#register(InstanceInfo)` 方法，该方法正式发起 post请求 Eureka Server，进行服务注册。
4. Eureka Server `addInstance` 接口，收到 `apps/${服务名}` 后，先进行一系列校验，然后调用 `register(final InstanceInfo info, final boolean isReplication)` 方法，写入新实例到 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中，更新该实例的最后更新时间、清空读写二级缓存后，返回 204 给 Eureka Client，代表服务注册成功。

###### 4）服务发现原理

1. Eureka Client `CacheRefreshThread` 线程任务，会调用 `DiscoveryClient#refreshRegistry()` 方法，以 `eureka.client.refresh.interval` （默认 30s）作为周期， 做定时服务发现。
2. 每次服务发现，分为增量拉取和全量拉取，如果强制配置、或者第一次拉取，则做全量拉取，否则走增量拉取，拉取完毕后更新服务列表缓存。
3. 全量拉取时，同样经历注册时的装饰者链调用，最终由 `AbstractJerseyEurekaHttpClient#getApplications()`，发起 `apps/` 请求到 Eureka Server。增量拉取时，同样也经历装饰者链调用，最终由 `AbstractJerseyEurekaHttpClient#getApplicationsInternal()`，发起 `apps/delta` 请求到 Eureka Server。
4. Eureka Server 先一级只读缓存中获取，获取不到则从二级读写缓存中获取，还获取不到则触发 `Guava Cache#load()` 方法，从 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中读取出来，并加载到二级缓存中，最后返回 200，表示服务列表获取成功。

###### 5）Eureka Server 服务列表缓存原理

![1648467823898](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648467823898.png)

1. 服务注册到注册中⼼后，服务实例信息存储在 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表中。
2. Eureka 为了提⾼响应速度，做了两层的缓存结构优化，将 Client 需要的实例信息，直接缓
   存起来，在获取时直接从缓存中拿数据，然后响应给 Client。
3. 第⼀层缓存是， `ResponseCacheImpl#readOnlyCacheMap`，采⽤ ConcurrentHashMap 来存储数据，定时
   `eureka.server.responseCacheUpdateIntervalMs`（默认 30 s 一次） 与 `ResponseCacheImpl#readWriteCacheMap` 进⾏数据同步。
4. 第⼆层缓存是， `ResponseCacheImpl#readWriteCacheMap`，采⽤ Guava 来实现缓存，缓存过期时间 `eureka.server.responseCacheAutoExpirationInSeconds` （默认为 180 s），当服务下线、过期、注册、状态变更等操作，都会清除该缓存中的数据。
5. 如果两级缓存都无法查询，则会触发 Guava Cache 的加载 `CacheLoader#load()`，从 `ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry` 注册表，读取数据到二级缓存中，再返回给 Client。
6. 对于 Eureka Client 的本地缓存，是通过 `CacheRefreshThread` 线程任务，以 `eureka.client.refresh.interval` （默认 30 s）作为周期，做定时服务发现时更新的。
7. 对于 Ribbon 缓存，是通过 `PollingServerListUpdater` 启动一个线程任务，以 `${服务名}.ribbon.serverListRefreshInterval`（默认 30 s）为周期，调用 `ServerListUpdater.UpdateAction#doUpdate()` 方法，从 Eureka Client 本地缓存中获取再更新。

###### 6）服务调用原理

1. Eureka 依赖于 Ribbon，在 Spring Boot 启动时，会启动装配一个 `RibbonEurekaAutoConfiguration`，该配置 Bean 会读取 Ribbon 配置，向 IoC 容器注入一个 `LoadBalancerClient` 对象。
2. 在调用 `loadBalancerClient.choose("eureka-client")` 发起初次服务调用时，会使用 `SpringClientFactory#getLoadBalancer("eureka-client"）` ，构造 `ILoadBalancer` 对象，触发 `RibbonClientConfiguration` 的注入，通过 `PollingServerListUpdater` 启动一个线程任务，以 `${服务名}.ribbon.serverListRefreshInterval`（默认 30 s）为周期，调用 `ServerListUpdater.UpdateAction#doUpdate()` 方法，从 Eureka Client 本地缓存中获取再更新。
3. 然后再选择从中服务列表缓存中，选择一个具体的实例，进行服务调用。

###### 7）服务续约原理

1. Eureka Client `HeartbeatThread` 线程任务，会调用 `DiscoveryClient#renew()`，以 `eureka.instance.lease.renewalInterval` 为续约周期（默认 30 s），做服务续约。
2. 它会调用 `registrationClient.sendHeartBeat()` 发送心跳包，经过一些列的装饰者链调用，最终调用到 `AbstractJerseyEurekaHttpClient#sendHeartBeat()` 方法，发起 `apps/service-name/host:service-name:ip` 请求、以及 `lastDirtyTimestamp` 到 Eureka Server，进行续约。
3. Eureka Server `renewLease` 接口，收到请求后，会执行服务续约，更新过去一分钟进行服务续约的数量、最后更新时间等信息，续约失败的，则返回 404，让客户端重新注册。
4. 续约成功的，先根据服务名获取 `registry` 服务列表中对应的租约实例，然后判断租约实例中的脏时间戳与传过来的 `lastDirtyTimestamp` 大小，如果传过来的大，说明客户端重启过，Eureka Server 的租约落后了，则返回 404，让客户端重新注册。
5. 如果传过来的小，说明收到的是集群同步请求，则返回当前租约实例的复制。

###### 8）服务剔除、服务自保原理

1. 在 Eureka Server 启动时，`AbstractApplicationContext#finishRefresh()` 进行回调，会启动一个异步线程，去初始化 Eureka Server 环境、上下文，以及读取 `eureka.server.evictionIntervalTimerInMs` （默认 60 s）， 启动一个定时任务 `EvictionTask`，调用 `evict(long additionalLeaseMs)` 方法，执行服务剔除逻辑。

2. 该方法会先判断能否执行服务剔除，如果 `eureka.server.enableSelfPreservation` 服务自保开关已关闭（默认打开），则直接返回 true，代表不启用服务自保，要做服务剔除操作，如果服务自保开关已打开，则要根据 `numberOfRenewsPerMinThreshold > 0 && getNumOfRenewsInLastMin() > 
   numberOfRenewsPerMinThreshold` ，即过去一分钟进行服务续约的数量，是否大于每分钟最少续约阈值，是的话则返回 true，代表不启用服务自保，要做服务剔除操作。

   ```java
   public abstract class AbstractInstanceRegistry implements InstanceRegistry {
       protected void updateRenewsPerMinThreshold() {
           // 每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
           this.numberOfRenewsPerMinThreshold = (int) 
   (this.expectedNumberOfClientsSendingRenews
                   * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds())
                   * serverConfig.getRenewalPercentThreshold());
       }
   }
   ```

3. 如果确定要做服务剔除了，则通过租约期望时间 =  `lastUpdateTimestamp + duration + additionalLeaseMs`（租约最后更新时间 + 租约持续时间默认 90 s + 补偿时间），如果租约期望时间小于当前时间，则认为租约已过期，然后将其收集起来。

4. 然后，随机抽取一个租约实例，从 `registry` 服务列表中删除，并清除 Guava Cache 二级读写缓存，随机剔除，可以使得该租约实例在整个 Eureka Server 集群中，剔除得比较离散，防止服务雪崩。

###### 9）服务下线原理

1. Spring Boot 启动时，会自动装配 `EurekaClientAutoConfiguration` ，该配置 Bean 会装配一个 `EurekaClient`，并指定其 `shutdown()` 方法，实现服务下线。
2. 该方法会销毁 `instanceInfoReplicator` 服务注册线程、`heartbeatExecutor` 服务续约线程、`cacheRefreshExecutor` 服务发现线程、以及 `scheduler` 调度定时器，调用 `unregister()`  发起取消服务注册请求。
3. 最终由 `AbstractJerseyEurekaHttpClient#cancel()` ，发起 `apps/service-name/host:service-name:port` 请求到 Eureka Server。
4. Eureka Server 的 `cancelLease()` 接口，收到服务取消注册请求后，调用 `PeerAwareInstanceRegistryImpl.cancel()` 方法，从 `registry` 服务列表中删除对应租约实例，并清除 Guava Cache 二级读写缓存，减少过去一分钟进行服务续约的数量，同步操作到 Eureka Server 集群的其他节点，最后返回 true，代表服务下线成功。

###### 10）Eureka Server 集群同步原理

1. Eureka Server 集群同步，有几个关键时机，
   - 1）第一是，Eureka Server `addInstance` 接口，在接收到客户端的**服务注册**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `addInstance` 接口。
   - 2）第二是，Eureka Server  `renewLease` 接口，在接收到客户端的**服务续约**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `renewLease` 接口。
   - 3）第三是，Eureka Server  `cancelLease` 接口，在接收到客户端的**服务下线**请求时，当前 Eureka Server 会发送相同的请求，到其他 Eureka Server `cancelLease` 接口。

##### 3、总

=> 以上，就是我对 Eureka 实现原理的一些理解，请问有什么细节需要补充的吗？

#### 2.0. 服务下线后，客户端会立马感应到吗？

不会立马感应到。

1. 首先，对于 Eureka 这种 AP 模型，数据是非强一致的，在服务提供者主动下线，或者被服务剔除后，Eureka Server 会把其从 `registry` 注册表中移除，以及作废 Guava Cache 二级缓存，但此时一级缓存需要等到 `eureka.server.responseCacheUpdateIntervalMs` （默认 30s）后，才能从二级缓存中获取，由于二级缓存没有，则触发 Guava Cache#load 方法，读取 `registry` 注册表，获取到最新的服务注册信息。
2. 同时，客户端的 Ribbbon 缓存，也需要等到 `xxxService.ribbon.serverListRefreshInterval` （默认 30s）后，才会定期更新。
3. 所以，Eureka AP 模型是无法让客户端实时感应到的。
4. 其次，如果对于 ZK 这种 CP 模型，即使服务端数据强一致，在服务注册信息发生变更时，触发 Watcher 机制，通知客户端，由于 TCP 传输需要花费一定的时间，在这传输到客户端缓存更新的情况下，很可能导致客户端去请求了旧的已下线的服务，也无法保证实时感知。
5. 可见，基于客户端实现的负载均衡算法，由于本地暂存了旧的服务列表，在更新期间导致的不一致性是不可避免的，因此，是无法实现实时感知的。
6. 而基于 CP 模型的服务端负载均衡，虽然可以解决这个问题，但又出现了新的问题，由于设计反向代理的转发，以及代理服务器在更新服务列表时，会出现一段时间不可用，这问题更严重，也不是个好方案。
7. 所以，服务下线，要保证客户端 100% 实时感知，在目前实现是比较困难的，因此，需要提供一种高可用的负载均衡算法，使得在服务下线时，客户端能够尽量不去调用它们，而是去调用还在线的服务，以提高系统可用性。

#### 2.1. 设计一个负载均衡算法，实现服务下线时，客户端能够实时感知？

1. 首先，注册中心采用 CP 模型，保证服务端层面的注册列表数据一致性。
2. 然后，客户端在第一次拉取到服务列表信息后，会注册监听器，在服务端的注册列表发生变更时，由注册中心主动通知客户端进行更新，这都与上面一样。
3. 不同的来了，客户端会对历史用过的服务实例，按照平均响应时间进行质量评分，时间越长，评分越低，发生过超时的会被评为 60 分以下，平均响应时间在 200 ms 以上会被评为 60 分 ~ 90 分，响应时间在 0 ms ~ 200 ms 的会被评为 90 分以上。质量评分在每次调用后，会进行更新，以保证 90 分以上的服务实例，能够一直维持高质量。
4. 客户端优先从高质量服务实例列表中（如果质量高的没有，则选择质量次高的），随机抽取一个实例进行调用，一来认为质量高的会一直质量高，发生服务下线的可能性不大，二来随机抽取，可以防止某个实例被过热调用。
5. 当然，即使是从质量好的服务，也会有宕机的时候，所以，在上面调用失败时，会将该实例打标为 60 分以下、从高质量实例列表中剔除，然后进行降级，降级时会重新选取一个高质量服务实例，重新发起调用，重试 n 次，当重试次数用完后，如果还没能调用成功，则根据配置的策略，走默认降级逻辑、或者抛出异常。
6. 从而，满足高可用负载均衡算法，在服务下线时，客户端能够尽量不去调用它们，而是去调用还在线的服务，以提高系统可用性。

#### 2.2. 如何在 Feign 调用时增强一下 Header？

关键字：RequestInterceptor#apply()、RequestTemplate、ThreadLocal。

##### 1、总

可以实现 `RequestInterceptor#apply()` 方法，该方法会传入一个 `RequestTemplate`，然后从上下文，比如 `ThreadLocal` 中取出需要增强的属性，然后设置到 `RequestTemplate#header` 中即可，比如这样：

```java
@Component
@Slf4j
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate requestTemplate) {
        // Member User信息
        MemberUser memberUser = GlobalMemberContext.getMemberUser();
        if(memberUser != null){
            try {
                requestTemplate.header(ProjectConstant.MEMBER_USER_INFO, URLEncoder.encode(JSON.toJSONString(memberUser), Charsets.UTF_8.name()));
            } catch (UnsupportedEncodingException e) {
                log.info("member user编码失败");
            }
        }
    }
}
```

##### 2、分

其中，Feign 的底层原理是这样的，

- **注入原理**：
  1. 由于 SpringBootApplication 上打了 @EnableFeignClients 注解，所以会回调注解导入的 **ImportBeanDefinitionRegistrar**#registerBeanDefinitions 方法，该方法可以扫描并注册 FeignClient。
  2. 其中注册 FeignClient 时， 会在 BeanDefinitionRegistry 中添加 FeignClientFactoryBean#beanDefinition。
  3. 由于 FeignClientFactoryBean 实现了 FactoryBean 接口，所以在对应的 FeignClient 被注入时，则会调用 **FactoryBean#getObject** 方法。
  4. 然后该 FeignClientFactoryBean#getObject 方法在构造 Feign.Builder 时，获取到容器中所有打了 @Component 注解，且实现 **RequestInterceptors** 接口的拦截器，然后注入到 Feign.Builder#requestInterceptors 属性中。
  5. 接着就是使用 Feign.Builder 来构建 LoadBalancer 的动态代理，返回对应的动态代理对象。

```java
Map<String, RequestInterceptor> requestInterceptors = context
				.getInstances(this.contextId, RequestInterceptor.class);
if (requestInterceptors != null) {
    builder.requestInterceptors(requestInterceptors.values());
}
```

- **执行原理**：
  1. 当业务方法调用注入的 FeignClient 实例对应的接口方法时，则会触发 JDK 动态代理，回调到 **InvocationHandler** 的 invoke 方法。
  2. 在 invoke 方法中，会去遍历所有的 **requestInterceptors**，并执行他们的 **apply** 方法，从而实现 Header 的增强。

```java
final class SynchronousMethodHandler implements MethodHandler {
    @Override
    public Object invoke(Object[] argv) throws Throwable {
        ...
        return executeAndDecode(template, options);
    }
    
    Object executeAndDecode(RequestTemplate template, Options options) throws Throwable {
    	Request request = targetRequest(template);
        ...
    }
    
  	Request targetRequest(RequestTemplate template) {
    	for (RequestInterceptor interceptor : requestInterceptors) {
      		interceptor.apply(template);
    	}
    	return target.apply(template);
  	}
}
```

##### 3、总

以上，就是我对 Feign Client 的一个理解，请问有什么细节需要补充的吗？

### 8> Dubbo

#### 1.1. 什么是 Dubbo 核心组件？

![1636292050935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636292050935.png)

##### 节点角色

| 节点      | 角色                                 |
| --------- | ------------------------------------ |
| Container | 服务运行容器                         |
| Provider  | 暴露服务的服务提供方                 |
| Registry  | 服务注册与发现的注册中心             |
| Consumer  | 调用远程服务的服务消费方             |
| Monitor   | 统计服务调用次数和调用时间的监控中心 |

##### 调用关系

1. 服务容器负责启动、加载、运⾏服务提供者。
2. 服务提供者在启动时，向注册中⼼注册⾃⼰提供的服务。
3. 服务消费者在启动时，向注册中⼼订阅⾃⼰所需的服务。
4. 注册中⼼返回服务提供者地址列表给消费者，如果有变更，注册中⼼将会基于⻓连接推送变更数据给消费者。
5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选⼀台服务提供者进⾏调⽤，如果调⽤失败，再选另⼀台调⽤。
6. 服务消费者和提供者，在内存中累计调⽤次数和调⽤时间，定时每分钟发送⼀次统计数据到监控中⼼。

#### 1.2. Dubbo 提供者、消费者服务启动原理？

![1636607155860](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636607155860.png)

##### 1、总

1. 首先是 Dubbo 与 Spring 的融合原理，基于 dubbo.jar 内的 `META-INF/spring.handlers` 配置，Spring 在遇到 Dubbo XML 配置的名称空间 `http\://dubbo.apache.org/schema/dubbo` 时，会回调 `DubboNamespaceHandler` 。
2. 基于 dubbo.jar 内的 `META-INF/spring.schemas` 配置，Spring 在遇到 Dubbo XML 配置的名称空间`http\://dubbo.apache.org/schema/dubbo/dubbo.xsd` 时，定义了 Dubbo XML 的标签语法，所有 dubbo 的标签，都统一用 `DubboNamespaceHandler#DubboBeanDefinitionParser` 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。
3. Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent` 回调时，或者 Consumer 在接口注入 `FactoryBean#getObject` 时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 Dubbo#URL，然后将 Dubbo#URL 传给 Protocol 扩展点，基于扩展点的 SPI 机制，根据 Dubbo#URL 的协议头，进行不同协议的服务暴露或者引用。

##### 2、分

###### 1）Provider 服务发布原理

1. `ServiceConfig` 在 XML 解析后，拿到对外提供实现类 `XML#ref` 配置。
2. 然后，Provider 在 `ApplicationListener<ContextRefreshedEvent>#onApplicationEvent()` 回调时，通过 `ProxyFactory#getInvoker()` 为 `XML#ref` ，生成一个 interfaceClass 的 javasist 动态代理 Wrapper 包装类 Invoker 实例，可以动态代理调用 `XML#ref` 实现类的方法，到这一步就完成了具体实现类到 `Invoker` 的转化。
3. 接下来，就是 `Invoker` 转换到 `Exporter` 的过程，是服务暴露的关键过程，其转换分为两种类型：
   - 1）**暴露本地服务**：
     1. 指服务暴露和引用都在同一个 JVM 里，自己调用自己接口，没必要进行远程通信。
     2. 会调用 `InjvmProtocol#export()` 把 invoker 转换为 `InjvmExporter`，并存进 exporters 缓存中。
     3. 调用则是获取 exporters 缓存中的 `InjvmExporter`，进行一个普通的动态代理到实现类的方法。
   - 2）**暴露远程服务**：
     1. 指服务暴露给远程客户端IP和端口号，以实现远程通信。
     2. 会调用 `DubboProtocol#export()`  把 invoker 转换为 `DubboExporter`，然后打开 Netty 服务器暴露服务，并存进 exporters 缓存中。
     3. 然后调用 `RegistryProtocol#register()`，使用 Curator 客户端建立 ZK 连接，注册 provider 持久化结点、当前服务的非持久化结点、configurators 非持久化结点，并设置监听器，当配置发生变更时，则会回调监听器的 `notify()` 方法，来修改 invoker 信息。
     4. 处理调用请求则是通过 `Netty#channelRead()` 方法，当有数据请求时，则调用 handler 和线程池进行接收、处理，最终获取缓存中的 `DubboExporter`，动态代理到实现类的方法。

![1637067703250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637067703250.png)

###### 2）Consumer 服务引用原理

1. Consumer 在接口注入 `FactoryBean#getObject()` 时，调用 `Protocol#refer()`生成 `Invoker` 实例，是服务消费的关键，其分类 3 种类型：
   - **本地服务引用**：如果为本地暴露服务，则 `InjvmProtocol` 生成本地执行的 `InjvmInvoker` 。
   - **直连服务引用**：如果为直连服务，则 `DubboProtocol` 创建 Netty 客户端，连接 url 服务，构建 `DubboInvoker` 。
   - **远程服务引用**：
     1. 如果为非直连的远程服务引用，则会调用 `RegistryProtocol` 进行 Consumer 注册到 ZK 并订阅，拉取相关 url 和 配置信息，当有发生变更时，则触发监听器的回调函数，调用 `DubboProtocol#refer()` 生成 `DubboInvoker` ，并加入集群，最后默认伪装返回一个 `FailoverClusterInvoker`。
2. 最后利用动态代理，把 `Invoker` 转换为客户端需要的接口实现类。
3. 当应用对代理对象进行方法调用时，则是动态代理到对应 `Invoker#invoke` 方法，调用本地方法或者发起远程请求。

![1637149757299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637149757299.png)

###### 3）Consumer 远程调用 Provider 原理

1. 消费方使用的接口动态代理实现类 proxy，调用其对应的 `Invoker`，发起真正的远程服务调用。

2. 而提供方的实现类，则会被封装成为一个 `AbstractProxyInvoker` ，然后生成一个 `Exporter` ，当服务提供方收到一个请求后，则会找到对应的 `Exporter` 实例，并调用它所对应的 `AbstractProxyInvoker` 实例，从而真正调用了服务提供者的代码。

3. 整个**消费方调用提供方**的调用链架构如下：

   ![1637150417647](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637150417647.png)

   1. **服务引用**：通过 Javassist 反向代理，代理调用 InvokerInvocationHandler#invoke 方法。
   2. **服务本地调用、降级、缓存**。
   3. **集群容错与负载均衡**：非 mock Invoker 筛选，Invoker 目录查找，根据容错策略、负载均衡策略，挑选唯一的 Invoker。
   4. **服务过滤链、监听器、包装类 SPI 扩展**。
   5. **服务协议**：根据协议，使用不同的 Invoker 调用不同的网络传输底层。
   6. **网络传输**：抽象 Netty、Mina 等统一接口，把消息序列化后发送到网络，传输给 Server 端。
   7. **消息接收与异步处理**：Server 端接收到消息后，经过反序列化后，交由线程池异步处理。
   8. **服务协议**：根据协议，选择不同的 Exporter 进行调用。
   9. **服务过滤链、监听器、包装类 SPI 扩展**。
   10. **服务调用**：最后调用真正的接口实现类，得到方法执行结果。

4. 而**提供方响应消费方**的顺序为：

   1. **服务响应**：在得到方法执行结果后，通过网络传输底层，序列化后发送响应报文给客户端。
   2. **结果接收**：客户端接收到响应报文后，交由线程池异步处理程序，经过反序列化后塞回到 Future 对象中，完成一次服务调用。

##### 3、总

以上，就是我对 Dubbo Provider 和 Consumer 启动过程以及远程调用过程的一个理解，请问有什么细节需要补充的吗？

#### 1.3. Dubbo 配置的注意点有哪些？

##### 1、Provider 多配置 Consumer 参数

1. 作为服务提供⽅，自己⽐消费⽅更清楚服务的这些接口参数的取值，比如超时时间、重试次数、负载均衡策略等。
2. 由于配置覆盖策略存在，在 Provider 端配置后，Consumer 端不配置则会使⽤ Provider 端配置，即 Provider 配置可以作为 Consumer 的缺省值。
3. 而如果 Provider 不配置，Consumer 也不直接配置，则会使⽤ Consumer 端的全局设置，这对于 Provider 是不可控的，并且往往是不合理的。
4. 因此，Provider 端尽量多配置、完善这些接口参数，让 Provider 实现者⼀开始就思考 Provider 端的服务特点和服务质量等问题。

![1636882183556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636882183556.png)

##### 2、Provider 合理配置性能参数

比如，**threads**（服务线程池⼤⼩）、**executes**（服务提供者并发请求的上限）。

##### 3、服务使用固定端口

使⽤固定端⼝来暴露服务，不要使⽤随机端⼝，这样在注册中⼼推送延迟的情况下，消费端仍然能够通过缓存列表，调⽤到原地址+原端口的服务，保证调⽤成功。

##### 4、推荐使用 XML 进行配置

XML 配置优先级高于 properties 和 yml，且标签的配置方式更加容易阅读和理解。

##### 5、应用配置负责人参数

配置 `dubbo:application#owner` 负责人参数，这些可以在运维平台上看到，以便于在发现问题时，找到对应服务负责⼈。

### 9> MyBatis

#### 1.1. MyBatis SqlSession 执行流程？

见《p6+MyBatis篇 - MyBatis SqlSession 执行流程？》。

#### 1.2. Mybatis 是如何进行分页的？分页插件的原理是什么？

1. Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的**内存分页**，而非物理分页，可以在 sql 内直接书写带有物理分页的参数，来完成物理分页功能，也可以使用分页插件来完成物理分页。
2. 分页插件的基本原理是，使用 Mybatis 提供的插件接口，实现自定义插件，在插件的拦截方法内，拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。
3. 比如，`select * from student`，拦截 sql 后重写为 `select t.* from (select * from student) t limit 0, 10`，从而完成插件分页的功能。

#### 1.3. Mybatis 插件运行原理，以及如何编写一个插件？

1. Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这4种接口的插件。
2. Mybatis 使用 JDK 动态代理，为需要拦截的接口生成代理对象，以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 `InvocationHandler#invoke()` 方法，拦截那些指定需要拦截的方法。
3. 具体做法为，实现 `Mybatis#Interceptor#intercept()` 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法，最后在配置文件中，配置所编写的插件即可。

### 10> Netty

#### 1.1. epoll 详解，以及与 select 的区别？

##### 1、总

1. `select`、`poll`、`epoll` 都是 Linux 为 I/O 多路复用模型提供的函数。
2. 其中，I/O多路复用，是指可以通过一种机制，让一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

##### 2、分

###### 1）select

```c++
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

1. `select` 函数监视的文件描述符分 3 类，分别是 `readfds`、`writefds` 和 `exceptfds`。
2. 调用后，`select` 函数会阻塞，直到有描述符就绪（比如有数据 可读、可写、或者有 except），或者超时（`timeout` 指定等待时间，如果立即返回设为 null 即可），则函数返回。
3. 当 `select` 函数返回后，可以通过遍历 `fdset` ，来找到就绪的描述符。

- **优点**：`select` 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
- **缺点**：`select` 的一个缺点是，单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义，甚至重新编译内核的方式来提升这一限制，但是这样也会造成效率的降低。

###### 2）poll

```c++
int poll (struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

- **特点**：
  1. 不同与 `select` 使用三个位图来表示三个 `fdset` 的方式，`poll` 只使用一个 `pollfd` 的指针来实现。
  2. `pollfd` 结构包含了要监视的 event，和 发生的 event，不再使用 `select` “参数-值” 的传递方式。
  3. 同时，`pollfd` 并没有最大数量限制，但数量过大后性能也还是会下降。 
  4. 和 `select` 函数一样，`poll` 返回后，需要轮询 `pollfd` 来获取就绪的描述符。
- **缺点**：
  1. 从上面看，`select` 和 `poll` 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。
  2. 事实上，同时连接的大量客户端，在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

###### 3）epoll

`epoll` 是在 Linux 2.6 内核中提出的，是之前的 `select` 和`poll` 的增强版本。

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

1. 在 `select` / `poll` 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描。
2. 而 `epoll` 事先通过 `epoll_ctl()` 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 `callback` 的回调机制，迅速激活这个文件描述符，当进程调用 `epoll_wait()` 时便得到通知，从而去掉了对文件描述符的遍历操作。

- **优点**：
  1. **监视的描述符数量不受限制**：`epoll` 所支持的 fd 上限，是最大可以打开文件的数目，这个数字一般远大于 2048。比如，在 1GB 内存的机器上大约为 10 万左右，具体数目可以 `cat /proc/sys/fs/file-max` 察看，一般来说这个数目和系统内存关系很大。
     - `select` 的最大缺点就是，进程打开的 fd 是有数量限制的，这对于连接数量比较大的服务器来说，根本不能满足。
  2. **I/O 效率不会随着监视 fd 的数量的增长而下降**：`epoll` 不同于 `select` 和 `poll` 轮询的方式，而是通过每个 fd 定义的回调函数来实现的，只有就绪的 fd 才会执行回调函数。
- **局限**：如果没有大量的 idle -connection 或者 dead-connection，`epoll` 的效率并不会比 `select` / `poll` 高很多，但是当遇到大量的 idle- connection，就会发现 `epoll` 的效率大大高于 `select` / `poll`。

##### 3、总

以上，就是我对 select、poll、epoll 的一个理解，请问有什么细节需要补充的吗？

#### 1.2. Netty 采用了哪种 I/O 多路复用模式？

##### 1、总

1. Netty 采用的是 Reactor 模式，应用于同步 I/O 的操作。
2. 然后， Reactor 根据实现方式的不同，其线层模型又分为 3 种，分别是单 Reactor 单线程模式、单 Reactor 多线程模式、主从 Reactor 多线程模式，其中，Netty 采用的是主从 Reactor 多线程模式。

##### 2、分

首先是 I/O 设计模式，分为 Reactor 模式和 Proactor 模式，

###### 1）Reactor 模式

Reactor 模式，应用于同步 I/O 场景，以 read 操作为例，Reactor 中的具体步骤为：

1. 应用程序注册 `读就绪` 事件和相关联的事件处理器。
2. 事件分离器等待事件的发生。
3. 当发生 `读就绪` 事件时，事件分离器调用第一步注册的事件处理器。
4. 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理。

![1646831826891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831826891.png)

**Reactor 优点**：

1. 响应快，可以不必被单个同步时间所阻塞，可以最大程度地避免复杂了多线程及同步问题，以及多线程 / 进程切换的开销。
2. 扩展性好，可以方便的通过增加 Reactor 实例个数，来充分利用 CPU 资源。
3. 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

###### 2）Proactor 模式

Reactor 和 Proactor 模式的主要区别就是，真正的读取和写入操作是由谁来完成的，Reactor 中需要应用程序自己读取或者写入数据，而 Proactor 模式中，应用程序不需要进行实际的读写过程，只需要从缓存区读取或者写入即可，操作系统会写入缓存区或者从缓存区读取并写入到真正的 I/O 设备中。

Proactor 模式 read 操作过程为：

1. 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注 `读取就绪` 事件，而是关注 `读完成` 事件，这是区别于 Reactor 的关键点 1。
2. 事件分离器等待 `读完成` 事件。
3. 在事件分离器等待 `读完成` 时，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中，这是区别于 Reactor 的关键点 2，在 Proactor 中，应用程序**需要传递缓存区**。
4. 事件分离器捕获到 `读完成` 事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
5. 而 Proactor 中的 write 操作和 read 操作类似，即感兴趣的事件是 `写完成` 事件。

![1646831843451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831843451.png)

###### 3）单 Reactor 单线程模式

然后，就是 Reactor 第一种线程模型，单 Reactor 单线程模式，

![1646831937063](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831937063.png)

1. `selector.select()` 是多路复用模型 NIO#API ，可以实现一个阻塞对象监听多路的连接请求。
2. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后通过 `dispatch()` 进行分发。
3. 如果是建立连接请求事件，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理连接完成后的后续业务处理。
4. 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应。
5. `Handler` 会完成 `read()` -> `doBusiness()` 业务处理 -> `send()` 一个完整的业务流程。

- **优点**：服务器使用一个线程，通过多路复用搞定所有 I/O 操作（包括连接、读、写等），编码简单，清晰明了，但如果客户端连接数量较多，将无法支撑。
- **缺点**：
  1. **性能问题**：只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上业务时，整个进程无法处理其它连接事件，容易导致性能瓶颈。
  2. **可靠性问题**：线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

###### 4）单 Reactor 多线程模式

![1646889343446](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889343446.png)

1. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后，通过 `dispatch()` 进行分发。
2. 如果是建立连接请求，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理完成连接后的各种事件。
3. 如果不是连接请求，则由 `Reactor` 对象分发调用连接对应的 `Handler` 来处理。
4. 此时，`Handler` 只负责读取和响应事件，不做具体的业务处理，通过 `read()` 读取数据后，会分发给后面的 `Worker` 线程池的某个线程进行处理业务。
5. `Worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `Handler`。
6. `Handler` 收到线程池处理完的结果后，通过 `send()` 将结果返回给 Client。

- **优点**：可以充分利用多核 CPU 的处理能力。
- **缺点**：
  1. 多线程在需要数据共享时，可能实现比较复杂。
  2. Reactor 单线程处理完所有的监听、连接、读、写事件，在高并发场景下，容易出现性能瓶颈。

###### 5）主从 Reactor 多线程模式

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

##### 3、总

因此，总结的话，Reactor 模式线程模型可以比喻为，

| Reactor 线程模型    | 比喻                                           | 优点                                                         | 缺点                           |
| ------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------ |
| 单 Reactor 单线程   | 前台接待员和服务员都是同一个人，全程为顾客服务 | 主线程负责所有的连接、读写、业务处理，编程简单               | 性能问题、可靠性问题           |
| 单 Reactor 多线程   | 1 个前台接待员，多个服务员，接待员只负责接待   | 主线程负责所有的连接、读写，Worker 负责业务处理              | 高并发场景下，容易出现性能瓶颈 |
| 主从 Reactor 多线程 | 多个前台接待员，多个服务生                     | MainReactor 负责连接、SubReactor 负责读写、Worker 负责业务处理，充分发挥多核 CPU 的优势，满足高并发场景 | 编程复杂                       |

=> 以上，就是我对 Netty 多路复用模式 的一个理解，请问有什么细节需要补充的吗？

#### 1.3. Netty 有了解过吗？

##### 1、总

1. Netty 是一个基于 JAVA NIO 实现的、高性能的、异步事件驱动框架，提供了对 TCP、UDP 和文件传输的支持。

2. 使用 Netty 实现通信的服务端步骤大致为：

   1. 先创建 2 个 NIO 线程组，一个专门用于网络事件的处理，接受客户端的连接，另一个则进行网络通信读写。
   2. 然后，创建一个 ServerBootStrap 对象，配置 Netty 的一系列参数，比如接受传出数据的缓存大小等等。
   3. 接着，创建一个实际处理数据的 ChannelInitializer 类，进行初始化的准备工作，比如设置接收、响应数据的字符集、格式、实际处理数据的 ChannelHandler 等。
   4. 最后，绑定接口，执行同步阻塞方法，等待服务端启动即可。

   （客户端与服务端基本一致）。

3. Netty 之所以高性能，是因为采用了许多优秀的性能方案，比如 I/O 多路复用模型、NIO 模型、主从 Reactor 线程模型、以及零拷贝机制。

##### 2、分

###### 1）Linux I/O 多路复用模型

I/O multiplexing 就是我们说的 `select`、`poll` 和 `epoll`，有些地方也称这种 I/O 方式为事件驱动型 I/O event driven IO。

1. `select` / `epoll` 的好处就在于，单个 process 就可以同时处理多个网络连接的 I/O。
2. 其基本原理是，当用户进程调用了 `select()`，那么整个进程会被 block，同时，kernel 会“监视”所有 `select()` 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回，此时，用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。
3. 所以，I/O 多路复用的特点是，通过一种机制，让一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select` 函数就可以返回了。

![1646817566451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817566451.png)

###### 2）Java NIO 模型

NIO，同步非阻塞 I/O：

1. 服务器实现一个连接一个线程，即客户端发送的连接请求都会注册到多路复用器上。
2. 多路复用器轮询到连接有 I/O 请求时，才会启动一个线程进行处理。
3. 适用于连接数目多、且连接比较短（轻操作）的架构，比如聊天服务器，但编程比较复杂，所以才有了 Netty 框架来简化编程。

NIO vs BIO：

1. BIO 是阻塞的，NIO 是非阻塞的。
2. BIO 是面向流的，只能单向读写，NIO 是面向缓冲的，可以双向读写。
3. 使用 BIO 做 Socket 连接时，由于单向读写，当没有数据时，会挂起当前线程，阻塞等待，为防止影响其它连接，需要为每个连接新建线程处理，然而系统资源是有限的，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗，因此，需要使用 NIO 进行 BIO 多路复用，使用一个线程来监听所有 Socket 连接，使用本线程或者其他线程处理连接。这就要讲到 Reactor 模式了。

###### 3）主从 Reactor 模式

1. 在高性能 I/O 设计中，有两个比较著名的模式，Reactor 和 Proactor 模式，Reactor 模式用于同步 I/O，而 Proactor 运用于异步 I/O 操作。
2. Reactor，又称之为响应器模式，在线程模型上，又分为单 Reactor 单线程模式、单 Reactor 多线程模式、以及主从 Reactor 多线程模式。

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，而 Netty 也正式采用了主从多线程模型。

###### 4）零拷贝机制

1. Netty 接收和发送的 ByteBuffer，底层采用 `DirectBuffers` 使用堆外内存进行 Socket 读写，无需进行字节缓冲区的二次拷贝。
2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
   方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
   Buffer。 
4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
   避免了传统通过循环 `write()` 方式导致的内存拷贝问题。

##### 3、总

Netty 正是主要基于以上几点的优化，大大简化了 NIO 编程，以及提高了 I/O 通信的性能。

=> 以上，就是我对 Nettty 的一些理解，请问有什么细节需要补充的吗？

### 11> JVM

#### 1.1. 详细介绍类加载机制？

![1625975271139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625975271139.png)

程序主动使用某个类时，如果这个类还未被加载到内存中，则JVM会通过**加载、链接、初始化**3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时也把这个3个步骤统称为**类加载或类初始化**。

1. **加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。
   - 加载过程需要**类加载器**参与。类加载器，可以从不同来源加载类的二进制数据，比如：本地Class文件、Jar包Class文件、网络Class文件等等。
   - Java类加载器由JVM提供，是所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。
   - 除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。
   - Java的类加载是动态的，不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类完全加载到JVM中。至于其他类，则**在需要的时候才加载**（为了节省内存开销）。
     - **隐式加载**：程序在运行过程中，当碰到通过new 方式生成对象时，将会隐式调用类装载器，加载对应的类到JVM中。
     - **显式加载**：通过class.forname（）反射方法，显式加载需要的类。
2. **链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：
   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
     - 文件验证：是否以0xCAFEBABE开头、版本号是否合理等。
     - 元数据验证：是否有父类、是否继承了final类、非抽象类是否实现了所有抽象方法等。
     - 字节码验证：运行检查、栈数据类型和操作码的操作参数是否吻合（不能大于栈空间）、跳转指令是否指向合理的位置。
     - 符号引用验证：常量池中描述的类是否存在、访问的方法或字段是否存在且有足够的权限。
     - 可使用**-Xverify:none**关闭验证：比如提高IDEA的启动速度。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。
   - 实际上，JVM不一定完全按照类加载机制顺序执行，比如解析操作有可能会发生在初始化操作之后。
3. **初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。
   - 执行< clinit >方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。
     - 初始化的顺序和源文件中的顺序一致。
     - 子类的< clinit >被调用前，会先调用父类的< clinit >。
     - JVM会保证clinit方法的线程安全性。
   - 即执行顺序为：JVMTest5静态块 -> super静态块 -> Sub静态块 -> Super构造块 -> Super构造方法 -> Sub构造块 -> Sub构造方法。
     - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
     - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
     - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

```java
// JVMTest5不用被实例化，所以不会调用JVMTest5的构造块和构造方法
public class JVMTest5 {
    static {
        System.out.println("JVMTest5静态块");
    }

    {
        System.out.println("JVMTest5构造块");
    }

    public JVMTest5() {
        System.out.println("JVMTest5构造方法");
    }

    public static void main(String[] args) {
        new Sub();
    }
}

class Super {
    static {
        System.out.println("Super静态块");
    }

    public Super() {
        System.out.println("Super构造方法");
    }

    {
        System.out.println("Super构造块");
    }
}

class Sub extends Super {
    static {
        System.out.println("Sub静态块");
    }

    public Sub() {
        System.out.println("Sub构造方法");
    }

    {
        System.out.println("Sub构造块");
    }
}
```

#### 1.2. 什么是类加载器？类加载器有哪些？

![1625986988156](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625986988156.png)

**类加载器**，是能够实现通过类的全限定名，获取该类的二进制字节流的**代码块**。JVM提供了3种类加载器，启动类加载器、扩展类加载器、系统类加载器（也叫应用类加载器），以及用户自定义的类加载器（其父类为应用类加载器）。

- **启动类加载器**：Bootstrap ClassLoader，该类加载使用C++实现，其引用为null，无法被java程序直接引用。用于加载Java核心类库，即负责把**/lib**目录下或者**-Xbootclasspath**参数指定路径下的Jar包加载到内存中。
  - 注意，JVM是按照文件名识别加载Jar包，如rt.jar，如果文件名不被虚拟机识别，即使把Jar包丢到lib目录下也是没有作用的。
  - 处于安全考虑，启动类加载器只能加载包名为java、javax、sun等开头的类。
- **扩展类加载器**：ExtClassLoader，由Java实现，父类加载器为启动类加载器（持有为null的parent引用，并不是真正的继承关系）。用于加载 Java 的扩展库，即负责把**/lib/ext**目录下或者**-Djava.ext.dir**参数指定路径下的类库加载到内存中。
  - 开发者可以直接使用标准的扩展类加载器。
- **系统类加载器**：AppClassLoader，也叫应用类加载器，由Java实现，父类加载器为ExtClassLoader（持有ExtClassLoader的parent引用，并不是真正的继承关系）。用于加载一般的Java 应用类，即负责把**java -classpath**或者**-D java.class.path**指定路径下的类库加载到内存中。
  - 一般情况下，系统类加载器是程序中默认的类加载器。
  - 开发者可以直接使用应用类加载器，可以通过**ClassLoader.getSystemClassLoader（）**来获取。
- **用户自定义的类加载器**：用户可以通过继承 java.lang.ClassLoader类的方式，来自定义自己的加载器。
  - 应用场景：
    - 加密编译后的class字节码 ->  自定义ClassLoader -> 加载该class时解密字节码。
    - 自定义ClassLoader，加载时从非标准来源加载字节码：比如数据库、网络上。

#### 1.3. 什么是双亲委派机制？

##### 概念

加载器之间存在着"父子关系"（区别于Java里的继承），子加载器保存着父加载器的引用。

1. 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回。
2. 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到，则解析或者返回。
3. 如果找不到，才会交还子加载器加载目标类，查找逻辑交由子加载器实现。

##### 实现原理

- **java.lang.ClassLoader**：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法。
- **loadClass（String，boolean）**：类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找。
- **findClass（String）**：加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用**defineClass（String，Resource）**方法生成Class对象。
- **resolveClass（Class<?>）**： 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值。
- **defineClass（String，Resource）**：在Java堆区生成Class对象。

```java
// java.lang.ClassLoader#loadClass：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法
public abstract class ClassLoader {
    
    // 类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            // 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回
            Class<?> c = findLoadedClass(name);// native方法
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    // 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到则解析或者返回
                    if (parent != null) {
                        c = parent.loadClass(name, false);
                    } 
                    // 交由启动类加载器加载
                    else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }

            // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
            if (resolve) {
                resolveClass(c);
            }

            // 返回class
            return c;
        }
    }
    protected final Class<?> findLoadedClass(String name) {
        if (!checkName(name))
            return null;
        return findLoadedClass0(name);
    }
    private native final Class<?> findLoadedClass0(String name);
    
    // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
    private native void resolveClass0(Class<?> c);

    // 加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用defineClass(String，Resource)方法生成Class对象
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
}
```

##### 双亲委派模型好处

- 此机制保证了Java核心类库被优先加载，避免了用户编写的类动态替换Java核心类的错误，使得Java程序能够稳定运⾏。
- 同时也避免了类的重复加载，使用双亲委派模型，JVM能够根据**类的完整类名+ClassLoader实例对象**来区分不同的类。如果不使⽤双亲委派模型，⽽是每个类加载器⾃⼰加载的话，会出现⼀些问题。⽐如编写⼀个称为 java.lang.Object 类的话，在程序运⾏的时候，系统会有多个不同的Object 类，此时会出现Object类的选择问题。

##### 双亲委派模型局限

1. SPI接口，Service Provider Interface，允许第三方为其提供实现，如JDBC、JNDI等 。
2. SPI接口属于Java核心类库，由启动类加载器加载（rt.jar），而SPI的第三方代码则是作为Java应用所依赖的Jar中（Classpath下）。
3. 其中SPI接口中的代码经常需要加载具体的第三方实现类，并调用其相关方法，此时由于双亲委派模型的存在，启动类加载器无法直接加载SPI实现类，也无法反向委托给系统类加载器加载，从而让JDK SPI机制产生了问题。

##### 打破双亲委派模型

如果不想打破双亲委派模型，则只需要重写findClass方法即可；如果想打破双亲委派模型，则需要重写整个loadClass方法。

###### 线程上下文类加载器

- **背景**：由于双亲委派模型存在SPI局限，需要一种特殊的类加载器来加载第三方类库，此时线程上下文加载器是个很好的选择。
- **线程上线文类加载器**：是从JDK 1.2开始引入的，可以通过java.lang.Thread#getContextClassLoader（）和setContextClassLoader（ClassLoader）方法来获取和设置线程的上下文类加载器。如果没有手动设置，则线程将会继承父线程的上下文类加载器，默认为系统类加载器，即在线程中运行的代码可以通过此类来加载Classpath下的类和资源。
- **打破双亲委派**：从图中可以看到，启动类加载器委派线程上下文加载器，把jdbc.jar中的实现类加载到内存中以便SPI相关类使用，因此打破了双亲委派模型，使得Java类加载更加灵活。

![1625996283343](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625996283343.png)

- **实现原理**：
  - contextClassLoader是在ClassLoader.SystemClassLoaderAction#run（）方法进行了赋值，其中构造了**java.system.class.loader**加载器实例（实际上为AppClassLoader？），并持有当前加载器的parent作为其父加载器。
  - 接着，ClassLoader.SystemClassLoaderAction#run（）方法通过Thread#setContextClassLoader（ClassLoader）设置到当前线程的实例变量中，从而使得当前Thread实例持有contextClassLoader的引用。
  - 最后，java.sql.DriverManager在调用sevice.loader（Driver.class）时，jdbc.jar中在META-INF/sevice/java.sql.Driver配置的**com.mysql.cj.jdbc.Driver**，就会在java.util.ServiceLoader#load（Class）方法调用Thread.currentThread().getContextClassLoader()时进行类加载，从而达到SPI的目的。
  - 可以看出虽然java.util.ServiceLoader是rt.jat包的核心类库，由启动类加载器加载，但通过Thread.currentThread().getContextClassLoader()确实加载到了第三方包下的com.mysql.cj.jdbc.Driver，因此线程上下文类加载器可以打破双亲委派模型。

```java
// java.sql.DriverManager，启动类加载器加载
public class DriverManager {
 	static {
        loadInitialDrivers();
        println("JDBC DriverManager initialized");
    }
    
    private static void loadInitialDrivers() {
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                // SPI加载
                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
                Iterator<Driver> driversIterator = loadedDrivers.iterator();
            }
            ...
        }
    }      
}    


// java.util.ServiceLoader，启动类加载器加载
public final class ServiceLoader<S>implements Iterable<S> {  
    // SPI加载: 获取当前线程上下文类加载器进行SPI加载，从而打破了双亲委派模型
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    ...
}
```

###### Tomcat类加载机制

- **背景**：
  - a. 一个web容器可能要部署两个或者多个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，因此要保证每一个应用程序的类库都是**独立、相互隔离**的。
  - b. 同一个web容器中的**相同类库的相同版本**可以共享，否则会有**重复的类被加载进JVM**。
  - c. **web容器也有自己的类库**，不能和应用程序的类库混淆，基于安全考虑，需要相互隔离。
  - d. Jsp文件也是要编译成class文件的，web容器需要支持在**Jsp**文件修改后，可以实现**HostSwap（热替换）**的功能。

![1626065847576](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626065847576.png)

- **类加载器逻辑关系**：

  Common、Catalina、Shared类加载器（本质上是URLClassLoader）分别加载/common/、/server/、/shared/路径下的Class，但在Tomcat6后已经统一合并到了/lib目录下了。

  - **CommonClassLoader**：Tomcat最基本的类加载器，加载对应路径中的Class，可**以被Tomcat容器本身以及各个webapp访问**。
  - **CatalinaClassLoader**：Tomcat容器私有的类加载器，加载对应路径中的class，**对于webapp不可见**。
  - **SharedClassLoader**：各个webapp共享的类加载器，加载对应路径中的class，**对于所有webapp可见，但对于Tomcat容器不可见**。
  - **WebappClassLoader**：各个webapp私有的类加载器，每一个webapp对应一个WebAppClassLoader实例，加载路径中的class，**只对当前webapp可见**。
  - **JasperClassLoader**：
    - 每一个Jsp文件对应一个JasperClassLoader实例，**加载范围仅仅是这个Jsp文件所编译出来的那一个Class文件**。
    - JasperClassLoad出现的目的就是为了被丢弃，当Web容器检测到Jsp文件被修改时，会替换掉目前的JasperClassLoader实例，并通过重新建立一个新的JasperClassLoader实例来实现JSP文件的HostSwap（热替换）功能。

![1626066067882](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626066067882.png)

![1626090586657](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090586657.png)

- **类加载流程**：`WebappClassLoaderBase#loadClass(String, boolean)` 流程：

1. 先查找 Tomcat 缓存，如果找得到，则返回 Tomcat 缓存中的 Class 对象。
2. 如果 Tomcat 缓存中找不到，则查找 JVM 缓存，如果找得到，则返回 JVM 缓存中的 Class 对象。
3. 如果 JVM 缓存中也找不到，则会尝试走 Tomcat#系统类加载器，加载 Tomcat#Classpath 目录下的 jar 包，以及走正常的 `app 系统类 -> ext 扩展类 -> bootstrap 启动类` 双亲委派机制，保证 JRE 核心类库、以及 tomcat 私有类库不会被重复加载。
4. 如果走正常双亲委派机制加载不到，且指定了 `delegateLoad`，即需要先委托父类加载，则先调用父类加载器加载 `share web共享 -> common 全部共享-> app 系统类 -> ext 扩展类 -> bootstrap 启动类`，如果找不到，才调用本地的 `findClass(String)`，搜索 webapp 本地类库 `WEB-INF/classes` 、以及 `WEB-INF/lib`，找到则返回，找不到则抛出 ClassNotFoundException 异常。
5. 如果走正常双亲委派机制加载不到，也没有指定 `delegateLoad`，即不需要先委托父类加载），则调用本地的 `findClass(String)`，搜索 webapp 本地类库 `WEB-INF/classes` 、以及 `WEB-INF/lib`，如果找不到，才调用父类加载器加载 `share web共享 -> common 全部共享-> app 系统类 -> ext 扩展类 -> bootstrap 启动类`，找到则返回，找不到则抛出 ClassNotFoundException 异常。

![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

- **总结**：可以看到，Tomcat#WebappClassLoaderBase的类加载机制，是打破了双亲委派模型的：
  - 1）先尝试 app -> ext -> bootstarp 模型：保证了 JRE 核心类库不会被重复加载，满足了背景 b 加载 JVM 共同类库的需求，以及背景 c 加载 tomcat 私有类库的需求。
  - 2） `delegateLoad` = false 时，ext -> webapp 模型：实现了每个 web 应用只加载自己的类库 `WEB-INF/classes` 、以及 `WEB-INF/lib`，从而实现了应用间的类库隔离，满足了背景 a 的需求。
  - 3）webapp -> share -> common 模型：实现了所有 web 应用之间、web 与 Tomcat 之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了背景 b 加载其他共同类库的需求。
  - 4）Jsp -> webapp：通过在 jsp 修改后，卸载再生成新的 Jsp 类加载器，重新加载新生成的 Jsp class，从而实现 Jsp HostSwap 热替换功能，满足了背景 d 的需求。

#### 1.4. 详细介绍创建一个对象的步骤？

**步骤：类加载检查、类加载（加载、链接、初始化）、分配内存、初始化零值、设置对象头、执行init方法**

1. **类加载检查** ：当JVM遇到new指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。

2. **类加载 - 加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。

3. **类加载 - 链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：

   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。

4. **类加载 - 初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。

   - 执行clinit 方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。

5. **分配内存**：在确定对象需要创建后，接下来JVM将为对象分配内存，分配⽅式有 **“指针碰撞”** 和 **“空闲列表”** 两种，在分配内存的过程中，需要注意使用的是哪一种垃圾收集算法，因为垃圾收集算法的不同会导致内存块是否规整，从而影响到分配内存的方式是使用指针碰撞还是使用空闲列表。

   - 在进行内存分配的时候，如果使用的是指针碰撞方法，还需要注意并发情况下，内存的分配是否是线程安全的。一般使用**加同步块**的方式和**线程私有分配缓存区**这两种方式解决线程安全的问题。

6. **初始化零值**：对象内存分配完成后，JVM需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的**实例字段**在Java代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。

7. **设置对象头**： 初始化零值完成之后，JVM要对对象进⾏必要的设置，比如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息将存放在对象头中。另外，根据JVM当前运⾏状态的不同，比如是否启⽤偏向锁等，对象头会有不同的设置⽅式。

   - **对象头主要包括两部分**：用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）以及类型指针（即对象指向该类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例）。

   ![1626822381182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626822381182.png)

8. **执⾏init⽅法**： 从JVM的视⻆来看，⼀个新的对象已经产⽣了，但从Java程序的视⻆来看， init⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏new指令之后会接着执⾏init⽅法，这样⼀个真正可⽤的对象才算产⽣出来。

   - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
   - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
   - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

#### 1.5. 对象内存分配过程？

![1626823040622](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626823040622.png)

1. 对象首先尝试栈上分配，如果栈上分配成功，则直接在栈上分配对象。
   - **栈上分配**指的是，在通过**逃逸分析**确定对象不会被外部访问后，并且**对象足够的小**，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。
2. 如果不能在栈上分配，且**对象也足够的小**，则尝试TLAB分配，如果TLAB分配成功，则直接在TLAB分配对象。
   - **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配**小对象**，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
3. 如果也不能在TLAB分配（大部分对象），则对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
4. 然而，**新建的对象不一定直接分配到Eden区**：如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
5. 同时还要注意的是，**由于JVM有动态年龄判定机制，对象不一定要达到年龄才能进入老年代**：
   - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

#### 1.6. JDK 8 的内存分布情况，年轻代和老年代默认的比值，以及 Eden 区的比值，以及为什么？

##### 1、总

![1647941457503](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941457503.png)

JVM 在执行 Java 程序的过程中，会把它所管理的内存区域，划分为同 JVM 生命周期的线程共享区域（方法区和堆区），以及生命周期随着线程启动而建立、随着线程结束而销毁的非线程共享区域（程序计数器、虚拟机栈和本地方法栈）。

##### 2、分

###### 1）程序计数器

1. Program Counter Register，非线程共享，是 JVM 当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，从而实现分支、循环、跳转、异常处理、线程恢复等基础功能。
2. 出现的原因是：
   - 1）由于 JVM 多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，线程是最小的执行单位，没有“记忆”功能，只负责去干。
   - 2）为了在线程切换后，能恢复到正确的执行位置，需要记住原线程下一条要执行的指令的位置，此时，每条线程就需要有一个独立存储、互不影响、内存不共享的程序计数器。

###### 2）虚拟机栈

![1647941408114](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647941408114.png)

1. 每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致，其内存空间只包含基础数据类型的局部变量、以及对象引用。

2. 虚拟机栈的单位是栈帧，在每个方法执行时，都会创建一个栈帧压入虚拟机栈中，在方法执行完毕或者发生异常，对应的栈帧则会从虚拟机栈中出栈。

3. 其中，每个栈帧都存放着局部变量表、操作数栈、动态链接和方法返回地址，还有一些附加信息。

   - 1）**局部变量表**：

     1. 是一组变量值的存储空间，用于存放方法参数，和方法内部定义的局部变量。
     2. 存放了编译期可知的各种基本数据类型 `boolean、byte、char、short、int、float、long、double`（对包装类型则在栈中保存其引用地址，在堆中保存值）、以及对象引用。
     3. 其内存空间，在编译期间完成分配，所以，在方法在运行之前，其内存空间是固定的，运行期间也不会发生改变。

   - 2）**操作数栈**：

     1. 用于保存计算过程中的中间结果，同时作为计算过程中变量临时的存储空间。
     2. 操作数栈在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈和出栈操作。

     ```java
     public class Test {
         public void add() {
             int a = 15;
             int b = 1;
             int c = a + b;
         }
     }
     ```

     => 以上过程，其操作数栈与局部变量表的**交互顺序**为：

     1. 15 入栈：操作数栈写入数据。
     2. 15 出栈：操作数栈提取数据到局部变量表。
     3. 1 入栈：操作数栈写入数据。
     4. 1 出栈：操作数栈提取数据到局部变量表。
     5. 15 入栈：加载局部变量表变量 15。
     6. 1入栈：加载局部变量表变量 1。
     7. `iadd`：执行相加 15 + 1 指令。
     8. 16 出栈：操作数栈提取结果到局部变量表。
     9. `return`：如果返回值为void，则当前栈帧出栈即可；如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中。

   - 3）**动态链接**：

     1. 每个栈帧都包含一个，指向运行时常量池中，当前栈帧所属的方法引用，持有这个引用是为了支持方法在调用过程中的动态链接（Dynamic Linking）。
     2. Class 文件的常量池中，存在大量的符号引用，这些符号引用一部分会在类加载阶段，或者第一次使用时转化为直接引用，这种转化成为静态连接。
     3. 而另一部分则在每一次运行期间都转化为直接引用，这部分称为动态连接。

   - 4）**方法返回地址**：

     1. 指向下一条字节码指令的地址，方法正常退出时，PC 计数器会记录其返回地址，保存在栈帧中。
     2. 而在方法异常退出时，返回地址，则要通过异常处理器表来确定，栈帧中不会保存这部分的信息。

   - 5）**附加信息**：虚拟机规范还允许一些的实现，可以增加一些规范里没有描述的信息到栈帧中，比如，与调试相关的信息等。

###### 3）本地方法栈

1. 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是用来服务 Java 方法的，而本地方法栈，则是用来服务虚拟机调用 Native 方法的。

###### 4）堆区

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

1. Java Heap，线程共享，在 JVM 启动时创建，是 Java 虚拟机中内存最大的一块，专门用来保存对象，几乎所有对象、以及数组的内存都在堆上分配。
2. 对象在堆中分配好以后，会在栈中保存一个 4 字节的实例，用来指向对象堆内存地址，定位对应的对象在堆中的位置，便于找到该对象，因此，操作实例，实际上是通过实例指针间接操作对象。
   - 另外，`ClassA a = new ClassA()`，a 叫做实例，而不能说成 a 对象，因为实例在栈上，对象在堆中。
   - 以及，在开启逃逸分析后，某些未逃逸的对象，也可以通过标量替换的方式在栈上分配。
3. 栈中的数据，和堆中的数据销毁并不是同步的，方法一旦结束，栈中的局部变量会立即销毁，而堆中的对象不一定会销毁，可能有其他变量也指向了该对象，一直等到没有变量指向该对象，它才有可能被垃圾回收掉。
4. 同时，堆是垃圾回收 GC 的主要场所，从内存回收角度来看，可以分为新生代和老年代，默认 `-XX：+NewRatio=2`，即老年代：新生代的值为 `2：1`，原因是，由于 Survivor 区采用的是复制算法，内存利用率不高，如果设置得过大，则会导致内存浪费严重。
5. 对于新生代又可以分为 Eden 区（伊甸园）、Survivor 区（存活区），默认 `-XX：SurvivorRatio=8`，即 Eden 区：Survivor 区的值为 `8：2`，原因是，大部分对象生命周期活不到存活区。
6. Survivor 区又分为 Surviver0（From Survivor）和 Survivor1（To Survivor），默认比值为 `1：1`，原因是，存活区使用的是复制算法。
7. 堆中还有个概念，叫做 TLAB：Thread Local Allocation Buffer，线程私有分配缓存区，是一块线程专用的内存分配区域，JVM 会为每个线程分配一块 TLAB 区域，实质占用的是 Eden 区的空间（分配独享、使用共享），用于给每个线程往自己的 TLAB 中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
   - 1）优点 - 加速对象分配：
     1. 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM 底层采用 CAS + 失败重试的方式来做同步处理。
     2. 如果多线程竞争非常激烈，那么在堆中分配对象性能是非常差的。
     3. 因此，JVM 设计了 TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
   - 2）缺点 - 大的对象无法分配：由于 TLAB 空间比较小，所以大的对象无法在 TLAB 分配，此时只能直接分配到其他堆空间中。

###### 5）方法区

![1647944132277](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647944132277.png)

1. Methed Area，别名 Non-Heap 非堆，线程共享，是 JVM 规范中定义的一个**逻辑概念**，用于存储已被虚拟机加载的类信息、常量、静态变量、以及即时编译后的代码，具体放在哪里，不同的实现可能会放在不同的地方。
2. 在 JDK 8 HotSpot 中，方法区存储空间分为堆和元空间，类信息（类版本、字段、方法、接口、父类等描述信息、静态常量池）、运行时常量池放在元空间中，静态变量、字符串常量池放在了堆中。
3. 讲到元空间，就要先讲一下永久代了：
   - 1）永久代，是 Hotspot 虚拟机特有的概念，是方法区的一种实现，主要存放类信息、常量等方法区内容。
   - 2）在 JDK 6 中，方法区中包含的数据，除了 JIT 编译生成的代码外（存放在native memory的CodeCache区域），其他都存放在永久代中。
   - 3）而移除永久代的工作，是从 JDK 7 开始的，但并没完全移除，比如符号引用转移到了本地内存中，字面量（见字符串常量池）、类的静态变量（class statics）转移到了堆中。
   - 4）在 Java 8 中，永久代就彻底被移除，取而代之的是，另一块与堆不相连的本地内存，叫做元空间（Metaspace）中，此时 `‑XX:MaxPermSize` 失去了意义，取而代之的是 `-XX：MaxMetaspaceSize `。
4. 再回到元空间：它是在 JDK 8 以后，用于替代永久代，存储类的元数据信息，存放的地方并不在 JVM 虚拟机中，而是在本地内存中，其大小仅受本地内存的限制，从而解决了永久代容易溢出的问题。
5. 再回到方法区，在 JDK8 以后，元空间替代了永久代，使得方法区与堆存在了交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是 class 文件里的常量池，未加载前并不占用内存。
   - 1）**静态常量池**：也叫 class 文件常量池，即 class 文件中的常量池，占用 class 文件绝大部分空间，主要存放：
     1. 字面量，相当于 Java 语言层面常量的概念，如文本字符串、final 修饰的变量。
     2. 符号引用，属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
   - 2）**运行时常量池**：当 class 文件加载到内存后，JVM 会将静态常量池中的内容，存放到运行时常量池中，这就是我们常说的常量池，主要存放：
     1. 编译期间产生的字面量和符号引用。
     2. 运行时常量池具有动态性，并非只能通过 class 文件常量池进入，运行期间也可以将新的常量放入池中。
   - 3）**字符串常量池**：可以理解为，运行时常量池中分出来的字符串部分，当类加载到内存时，字符串会存到字符串常量池里。
     1. `String#intern()` 方法，native方法，返回规范的字符串，底层调用 `equals()` 会先判断常量池是否有存在的字符串，如果没有，则会将字符串加入常量池。
     2. 程序运行时，除非手动向常量池中添加常量，比如调用 `String#intern()` 方法，否则 JVM 不会自动添加常量到字符串常量池中。
     3. 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量，则会加入常量池，如果是变量，由于地址不能确定，所以在不调用 `String#intern()` 时，是并不会加入常量池的。

##### 3、总

=> 以上，就是我对 JDK 8 运行时数据区 的一些理解，请问有什么细节需要补充的吗？

#### 1.7. Java垃圾回收机制？

- **背景**：
  - 在Java中，程序员是**不需要显式去释放一个对象的内存**的，而是由虚拟机自行执行。
  - 在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫描那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。
- **使用场景原则**：
  - **内存要求**：内存不够，则需要想办法提高对象的回收率，以多回收一些对象，从而腾出更多的内存。
  - **CPU要求**：CPU不够，则需要降低垃圾回收频率，让CPU多去执行业务，而不是垃圾回收。
- **垃圾回收的区域**：虚拟机栈、本地方法栈和程序计数器是线程独享的，是随着线程的创建而创建的，随着线程的销毁而销毁的， 是不需要考虑垃圾回收的；而堆和方法区是线程共享的，需要关注垃圾回收。
  - **堆**：是垃圾回收的主要区域，用于回收创建的对象。
  - **方法区**：用于回收废弃的常量以及不需要的类。
- **回收时机**：由对象存活算法决定。

#### 1.8. 对象存活算法？

##### 引用计数法

通过对象的引用计数器，来判断该对象是否被引用，比如有对象引用就+1，其引用失效就-1，当为0时，则代表该对象没有被引用。

- **优缺点**：实现简单，判断效率高；但无法解决对象循环引用的问题，**目前Java并不使用该算法**。

![1626436324696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436324696.png)

##### 可达性分析

以**根对象（GC Roots）**作为起点向下搜索，走过的路径被称为**引用链**（Reference Chain），如果某个对象到根对象之间没有引用链相连，则认为该对象是不可达的，是可以被回收的。**Java使用的是该存活算法**。

- **根对象**包括：
  - 虚拟机栈（栈帧中的局部变量表）中Reference对象所引用的对象。
  - 方法区中类的静态属性（static）Reference对象所引用的对象。
  - 方法区中常量（final）Reference对象所引用的对象。
  - 本地方法栈中JNI（即Native方法）Reference对象所引用的对象。

![1626436445717](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436445717.png)

- **可达性分析完整流程**：注意，一个对象即使不可达，也不一定会被回收，还要继续判断有无必要执行析构函数**finalize（）**方法，如果方法里面重新建立了与根对象之间的引用链，则不会去回收，否则还是会被回收。
  - **两次标记过程**：
    - 第一次标记不在“关系网”中的对象。
    - 第二次先判断该对象有没有实现finalize（）方法，如果没有实现，则直接判断该对象可回收；如果实现了，则会先放在一个队列中，并由JVM建立的一个低优先级的线程去执行它，随后会进行第二次的小规模标记，而在这次被标记的对象就会真正地被回收了。
  - **使用建议**：
    - 避免使用finalize（）方法，操作不当可能会导致问题。
    - finalize（）方法优先级低，什么时候会被调用也无法确定，因为什么时候发生GC是不确定的。
    - 建议使用try...catch...finally来代替finalzie（）方法。

![1626437028531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437028531.png)

#### 1.9. JVM垃圾回收算法

分为**基础垃圾回收算法**（标记清除算法、标记整理算法和复制算法）和**综合垃圾回收算法**（分代搜集算法和增量算法）。

##### 基础 - 标记清除算法

- **优缺点**：实现简单；但存在内存碎片，影响对象的内存分配速度，在极端情况下需要遍历整个内存链表。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 再清理掉要回收的对象。

![1626437545225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437545225.png)

##### 基础 - 标记整理算法

也叫标记压缩算法。

- **优缺点**：无内存碎片；但由于整理需要计算和时间整理对象到一端，存在CPU和时间的开销。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 然后把所有存活对象压缩到内存的一端。
3. 再清理掉边界外的所有空间。

![1626437785184](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437785184.png)

##### 基础 - 复制算法

- **优缺点**：性能好（无需标记所有对象，只需找出存活的并移动即可），无内存碎片；但内存利用率低，最多才达到50%。
- **算法流程**：

1. 把内存分为两块，每次只使用其中一块。
2. 通过可达性分析，将存活的对象复制到另一块未使用的内存中，然后清除掉正在使用的那块内存中的所有对象。
3. 最后交换两块内存块的角色，等待下次回收重复执行上述操作。

![1626437874675](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437874675.png)

##### 综合 - 分代收集算法

- **概念**：

  - 各种商业虚拟机堆内存的垃圾收集基本上都采用了分代收集算法。
  - 根据对象的存活周期，把内存分为多个区域，**不同区域使用不同的回收算法**来回收对象，以提升整体性能。
  - 堆是垃圾回收的主要区域，其内存可以划分为以下区域：

  ![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **垃圾回收类型**：

  - **新生代回收**：Minor GC或者Young GC
  - **老年代回收**：Major GC，执行Major GC往往伴随一次Minor GC，所以**Major GC  ≈ Full GC**。
  - **清理整个堆**：Full GC = Major GC + Minor GC。

- **对象内存分配过程**：

  - **典型模型**：
    - **回收新生代使用复制算法**，因此新生代需要有两块内存（Eden区和Survivor区，8：2），Survivor区也有两块内存（From Survivor和To Survivor，1：1）。
      1. 对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。
      2. 而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。
      3. 对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
    - **回收老年代使用标记清除或者标记整理算法**，老年代：新生代，默认内存大小比值为2：1。
  - **新建的对象不一定直接分配到Eden区**：
    - 如果对象大于-XX：PretenureSizeThreshold（默认为0，表示所有对象都优先在Eden区分配），则会直接分配到老年代。
    - 如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
  - **对象不一定要达到年龄才能进入老年代**：
    - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

- **触发垃圾回收的条件**：

  - **新生代Minor GC**：Eden区空间不足时。
  - **老年代/Full GC**：
    - **老年代空间不足**：没有足够空间，或者内存碎片过多导致没有足够的连续空间去分配对象。
    - **元空间不足**：方法区的元空间不足也会触发Full GC。
    - **显示调用System.gc（）**：该方法的作用是建议垃圾回收器执行垃圾回收，会触发Full GC，可以使用-XX：+DisableExplicitGC参数忽略System.gc（）的调用。

- **分代收集算法的好处**：

  - **更有效的清除不再需要的对象**：对于生命周期比较短的对象，在新生代就会被回收掉了。
  - **提升了垃圾回收的效率**：如果不做分代处理，每次回收需要扫描整个堆的对象，而分代回收则需要扫描新生代或者老年代就可以了。

- **分代收集算法的调优原则**：

  - **合理设置Survivor区的大小，避免内存浪费**：因为Survivor区的内存利用率不高，如果设置得过大，则会导致内存浪费严重。
  - **让GC尽量发生在Minor GC级别，尽量减少Full GC的发生**。

| JVM参数                        | 默认值 | 说明                                                         |
| ------------------------------ | ------ | ------------------------------------------------------------ |
| -XX：+NewRatio=？              | 2      | 老年代：新生代的内存大小比值                                 |
| -XX：SurvivorRatio=？          | 8      | Eden区：Survivor区的内存大小比值                             |
| -XX：PretenureSizeThreshold=？ | 0      | 分配到老年代的对象大小阈值，为0表示不做限制，所有对象都优先在Eden区分配 |
| -Xms                           | -      | 初始堆内存大小                                               |
| -Xmx                           | -      | 最大堆内存大小                                               |
| -Xmn                           | -      | 新生代大小                                                   |
| -XX：+DisableExplicitGC        | 开启   | 忽略掉System.gc（）的调用                                    |
| -XX：NewSize=？                | -      | 新生代初始内存大小                                           |
| -XX：MaxNewSize=？             | -      | 新生代最大内存                                               |

##### 综合 - 增量算法

每次只收集一小片区域内存的垃圾，从而减少系统的停顿时间，见G1收集器的实现。

#### 2.0. 项目中的垃圾收集器用了哪些？

##### 1、总

1. 由于 JVM 启动参数没配置具体的垃圾收集器，所以使用的是默认的垃圾收集器。

   ```shell
   nohup java -Duser.timezone=Asia/Shanghai 
   -Xms2048m -Xmx2048m 
   -XX:OnOutOfMemoryError="sh kkp.sh" 
   -XX:+HeapDumpOnOutOfMemoryError
   -XX:+PrintGCDetails -Xloggc:/apps/svr/srmpos/logs/gc.log
   -Dsun.net.inetaddr.ttl=30 -Dsun.net.inetaddr.negative.ttl=10   
   -jar srm-pos-2.0.0-SNAPSHOT.jar 
   --spring.cloud.bootstrap.location=/apps/svr/srmpos/bootstrap.yml 
   -Xbootclasspath/a:/apps/svr/srmpos/: > /apps/svr/srmpos/logs/srmpos_$(date +%Y-%m-%d).log &
   
   # kkp.sh
   pids=`ps -ef|grep srm-pos|grep -v grep|awk '{print $2}'`
   if [ "$pids" != "" ]; then
    echo "kill -9 $pids"
    kill -9 $pids
   fi
   ```

2. 这时可以去看 gc.log 中的抬头，打印出来的是 `-XX:+UseParallelGC` ，即 `Parallel Scavenge` + `Parallel Old` 的组合。

   ```shell
   OpenJDK 64-Bit Server VM (25.232-b09) for linux-amd64 JRE (1.8.0_232-b09), built on Oct 22 2019 16:14:06 by "mockbuild" with gcc 4.8.5 20150623 (Red Hat 4.8.5-39)
   
   Memory: 4k page, physical 16268352k(6193040k free), swap 8388604k(8089872k free)
   
   CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=2147483648 -XX:MaxHeapSize=2147483648 -XX:OnOutOfMemoryError=sh kkp.sh -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
   
   1.626: [GC (Metadata GC Threshold) [PSYoungGen: 241412K->16509K(611840K)] 241412K->16517K(2010112K), 0.0255457 secs] [Times: user=0.03 sys=0.01, real=0.03 secs] 
   
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

JDK 中有如下的垃圾收集器（挑着讲）：

![1648022290125](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022290125.png)

###### 1）新生代 - Serial 收集器 | 单线程

![1648022517445](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022517445.png)

1. 最基本的、发展历史最悠久的收集器，采用的是复制算法。
2. 其特点是，单线程，可以专心做垃圾回收，不存在与其他线程的交互开销，效率较高，但收集过程全程 Stop The World。
3. 只适用于客户端程序、或者嵌入式低性能的单核机器。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用复制算法，执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 2）新生代 - ParNew 收集器 | 多线程并行

![1648022570986](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022570986.png)

1. 相当于 Serial 收集器的多线程版本，采用的也是复制算法，收集过程全程也是 Stop The World。
2. 可使用 `-XX：ParallelGCThreads`，来设置并行线程数，一般设置为 CPU 核心数。
3. 主要用来和 CMS 收集器配合使用。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，回收完毕后，用户线程继续运行。

###### 3）新生代 - Parallel  Scavenge 收集器 | 多线程并行

![1648022746240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648022746240.png)

1. 也叫吞吐量优先收集器，也是多线程并行的垃圾收集器，采用的也是复制算法。
2. 其特点是：
   - 1）可以通过配置，以达到一个可控制的吞吐量：
     1. `-XX：MaxGCPauseMillis`：设置后，JVM 将尽力控制垃圾收集时的最大的停顿时间。
     2. `-XX：GCTimeRatio`：用于设置吞吐量的大小，取值为 0~100，设置后，JVM 将花费不超过 `1 + / （1+n）` 的时间，去做垃圾收集。
   - 2）支持自适应 GC：
     1. 可使用 `-XX：+UseAdptiveSizePolicy` 启用，启用后，将无需再手动设置 `-Xmn、-XX：SurvivorRatio` 等参数，虚拟机会根据系统的运行状况，收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。
     2. 可见，Parallel  Scavenge 收集器存在着一定的智能性。
3. 适用于比较注重吞吐量的场景。
4. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用复制算法，并行执行新生代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 4）老年代 - Serial Old 收集器 | 单线程

![1648023100553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023100553.png)

1. 也叫串行的老年代收集器，相当于 Serial 收集器的老年代版本，采用的算法是标记整理算法。
2. 和 Serial、ParNew、Parallel Scavenge 三个新生代收集器，都可以形成配合。
3. 在 CMS 收集器出现故障时，则会使用 Serial Old 收集器作为备用。
4. 执行过程为，用户线程到保存点暂停，然后 GC 线程采用标记整理算法，执行老年代垃圾回收，回收完毕后，用户线程继续运行。

###### 5）老年代 - Parallel Old 收集器 | 多线程并行

![1648023323242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648023323242.png)

1. 相当于 Parallel Scavenge 的老年代版本，采用的是标记整理算法，只能和 Parallel Scavenge 新生代收集器配合使用。
2. 与 Parallel Scavenge 一样，适用于关注吞吐量的场景。
3. 执行过程为，用户线程到保存点暂停，然后多个 GC 线程采用标记整理算法，并行执行老年代垃圾回收，同时支持自适应 GC，回收完毕后，用户线程继续运行。

###### 6）老年代 - CMS 收集器 | 多线程并发

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

1. CMS，Concurrent Mark Sweep，并发标记清除收集器，可以与用户线程同时工作，采用的是标记清除算法，而 Serial Old、Parallel Scavenge 采用的都是标记整理算法。

2. 优点是，CMS 的 Stop The World 时间比较短，大多过程都是并发执行的，只有初始标记和重新标记，存在者 Stop The World，其他阶段都是并发执行的。

3. 缺点是：

   - 1）**会存在内存碎片**：这也是最令人诟病的地方，这是因为 CMS 采用的是标记清除算法，会导致内存碎片的产生。
     1. 可使用 `UseCMSCompactAtFullCollection`（默认打开），在每次 Full GC 完成后，进行内存碎片的整理。
     2. 也可使用 `CMSFullGCsBeforeCompaction`（默认为0），在进行几次 Full GC 后，就进行一次内存碎片的整理。
   - 2）无法处理浮动垃圾：由于并发清除阶段，用户线程在并发执行，可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而 CMS 是无法在本次 GC 清理掉这些浮动垃圾的，需要留到下次 GC 才能清理掉。
   - 3）不能等到老年代几乎满了才开始收集：
     1. 如果 CMS 执行期间，预留的老年代内存，不能满足用户程序的需要，则会出现一次 Concurrent Mode  Failure 异常，会导致 JVM 改用备用的 Serial Old 收集器，去收集老年代的垃圾，从而导致更长的 Stop The World。
     2. 因此，必须为老年代预留足够的内存给用户线程使用，可使用 `CMSInitiatingOccupancyFraction`（默认68%），来设置老年代占比达到多少后，才会触发 CMS 垃圾回收。
   - 4）CPU 资源比较敏感，并发执行阶段会导致应用吞吐量的降低：由于垃圾收集线程也需要占用一定的 CPU 资源，与业务线程一起去争抢 CPU 时间片，影响业务线程的执行效率，降低应用的吞吐量。

4. 适用于希望系统停顿时间短，响应速度快的场景，比如各种服务端应用。

5. 执行过程为：

   - 1）**初始标记**：initial  mark，标记那些 GC Roots 能直接关联到的对象，此时能够标记到的对象会比较少m。执行期间，存在 Stop The World，但由于标记的对象比较少，所以 STW 的时间也是比较短的。

   - 2）**并发标记**：concurrent mark，找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程，和用户线程并发执行，不存在 Stop The World。

   - 3）**并发预清理**：concurrent-preclean，是一个不一定会执行的阶段，可通过 `-XX：-CMSPrecleaningEnabled`（默认打开），关闭并发预清理阶段，本阶段，JVM 会重新标记那些在并发标记阶段期间，引用被更新了的对象，比如某些新晋升到老年代的对象，从而减少后面重新标记阶段的工作量。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

   - 4）**并发可中止的预清理阶段**：concurrent-abortable-preclean，也是不一定会执行的阶段，使用该阶段的前提条件是，当 Eden 使用量大于 `CMSScheduleRemarkEdenSizeThreshold` 阈值时（默认2M）才会执行，工作内容与并发预清理阶段是一样的。执行期间，垃圾收集线程和用户线程并发执行，也不存在 Stop The World。

     1. 本阶段的主要作用是，允许用户能够控制预清理阶段的结束时机。
     2. 比如，可用 `CMSMaxAbortablePrecleanTime`（默认 5 秒）进行设置扫描时长。
     3. 再如，可用 `CMSScheduleRemarkEdenPenetration` 设置（默认 50%），当 Eden 使用占比达到多大，就结束本阶段。

   - 5）**重新标记**：remark，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象，错误地标记成为了死亡，则可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World，一般来说，本阶段所花费的时间，会比初始标记阶段的要长一些，但会比并发标记阶段的短一些。

   - 6）**并发清除**：concurrent sweep，会基于标记结果，清除掉要前面标记出来、需要清除的垃圾，不做整理，所以会存在内存碎片。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

     那么为什么是并发清除，而不是并发整理？

     1. 因为本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     2. 如果是并发整理，则既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，实现起来会变得非常困难，还容易出错，而采用并发清除，就变得容易了许多。
     3. 因此，这里是并发清除，而不是并发整理。

   - 7）**并发重置**：concurrent reset，清理本次 GC 的上下文信息，为下一次 GC 做准备。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。

###### 7）新生代&老年代 - G1 收集器 | 多线程并发

![1648024834453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648024834453.png)

1. Garbge First，是一款价值优先、既可以用在新生代、又可以用在老年代（即整个堆内存）的垃圾收集器，由于采用的是复制算法，所以无内存碎片的问题。

2. 而其革命性的变化在于：

   - 1）它将整个堆，划分成了若干个大小相等的区域，每个区域叫一个 Region，这个 Region 可通过 `-XX：G1HeapRegionSize` 来指定，取值范围为 1M~32M ，且必须为 2 的幂次。
   - 2）在 G1 中，一共分为 4 类 Region，分别为 Eden Region 伊甸园、Survivor Region 存活区、Old Region 老年代、Humongous Region 存储大对象，同一代对象可能是不连续的，而超过 Humongous Region 大小一半的特大对象，则会被分配到连续的 Humongous Region 里面。
   - 3）然后，G1 会去跟踪每个 Region 里面的垃圾堆积的价值大小，即回收一个 Region 能够获取到多大的剩余空间。
   - 4）最后，构建一个优先列表，根据允许的收集时间，优先回收价值高的 Region，即回收后能够得到更大空间的 Region，以获得更高的垃圾收集效率。

3. 主要用来替换 CMS，适用于占用内存较大（6G 以上）的应用。

   - 1）> JDK 8 都可以使用 G1（如果内存 <= 6G，建议使用 CMS，如果内存 > 6G，可以考虑使用 G1），而 CMS 则从 JDK 9 开始就被废弃了。

4. 执行过程为：

   1、**Young GC**：与之前的 Minor GC 差不多，采用的都是复制算法，只不过回收的单位是 Region 而已。

   - 1）当所有 Eden Region 都满了时，会触发 Young GC，Eden Region 里面所有的存活对象，都会转移到Survivor Region 里面去。
   - 2）而原先在 Survivor Region 中存活的对象，则会转移到新的 Survivor Region 中，或者晋升到 Old Region 中。
   - 3）然后，空闲的 Region 则会被放入空闲的列表中，等待下次被使用。

   2、**Mixed GC**：

   ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

   - 1）最能体现 G1 的设计思想，与 CMS 过程类似，但采用的是复制算法。
   - 2）在老年代大小，占整个堆的百分比达到 `-XX：InitiatingHeapOccupancyPercent` 时（默认 45%），则会触发 Mixed GC。
   - 3）Mixed GC 会回收所有的 Young Region，同时根据收集时间与回收价值回收部分的 Old Region。

   对于**执行过程**，除了并发标记是并发执行外，其他阶段都需要 Stop The World，但由于每次只回收部分的 Region，所以整体 Stop The World 的时间是可控的。

   - 1）**初始标记**：Initial Marking，与 CMS 初始标记类似，都是标记 GC Roots 能直接关联到的对象。执行期间，存在 Stop The World，不过由于标记的对象比较少，所以 STW 的时间比较短。
   - 2）**并发标记**：Concurrent Marking，也与 CMS 并发标记类似，都是找出所有 GC Roots 能够关联到的对象。执行期间，垃圾收集线程和用户线程并发执行，不存在 Stop The World。
   - 3）**最终标记**：Final Marking，也与 CMS 重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。如果不做修正，那么在并发标记期间，错误地把已经死亡了的对象，标记为了存活，则会导致部分垃圾不被回收，而如果把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。执行期间，存在 Stop The World。
   - 4）**筛选回收**：Live Data Counting and Evaluation，会对各个 Region 的回收价值与成本，进行排序，根据用户所期望的停顿时间 `MaxGCPauseMillis`，来制定回收计划，以选择回收某些 Region。执行期间，存在 Stop The World。
     1. 回收过程，采用的是复制算法，因此无内存碎片产生。
     2. 首先，G1 会选择一系列 Region 构成一个回收集。
     3. 接着，G1 会把决定要回收的 Region 中的存活对象，复制一个空的 Region 中。
     4. 最后，再删除掉需要回收的 Region。

   3、**Full  GC**：

   - 1）当 G1 在复制对象时，发现内存不够，或者无法分配足够内存，比如特大对象没有足够连续的 Humongous Region 可分配时，则会触发 Full GC。
   - 2）一旦触发 Full GC，在 Full GC 模式下，使用的是类似于 Serial Old 的垃圾回收，将出现长时间的 Stop The World。

5. 调优原则 => 因此，使用 G1 时，应该尽量减少 Full GC 的发生，让其只停留在 Young GC，或者 Mixed GC 的模式上进行垃圾回收。

   - 1）**增加预留的内存**：可加大 `-XX：G1ReserveRercent` ，默认为堆的 10%。
   - 2）**更早地进行回收垃圾**：可降低 `-XX：InitiatingHeapOccupancyPercent`（默认 45%），降低老年代大小，占整个堆的百分比的阈值，提早触发 Mixed GC。
   - 3）**增加并发阶段使用的线程数**：可增大 `-XX：ConcGCThreads`，让更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

##### 3、总

最后，选择垃圾收集器，不能纸上谈兵，要根据实际情况选择。

1. 桌面端应用、是单核的，可以使用 `Serial + Serial Old`。
2. Web 应用，追求吞吐量高的，可以使用 `Parallel Scavenge + Parallel Old`。
3. Web 应用，追求低延迟的，可以使用 `ParNew + CMS`、或者 G1。

=> 以上，就是我对 JVM 垃圾收集器 的一些理解，请问有什么细节需要补充的吗？

#### 2.1. 线上怎么确定是老年代还是年轻代的 GC 时间过长？

##### 1、总

查看方式有：

1. 看 Skywalking：

   ![1648027659855](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648027659855.png)

2. 用 `jstat` 监控统计命令：

   ```shell
   # 查看remote.domain机器上，40496进程，垃圾收集相关的统计信息摘要（每隔1秒采样1次）
   jstat -gcutil 40496@remote.domain 1000
   
   # option参数解释：
   -class    :：显示类加载器的统计信息
   -gcutil    ：垃圾回收统计概述
   -gc        ：垃圾回收堆的行为统计
   -gcnew     ：新生代行为统计
   -gcold     ：年老代和永生代行为统计
   -gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计
   ```

3. 看 gc.log，手动计算所花时间：

   ```shell
   # PSYoungGen：指 Parallel Scavenge，ParOldGen：指 Parallel Old
   1.652: [Full GC (Metadata GC Threshold) [PSYoungGen: 16509K->0K(611840K)] [ParOldGen: 8K->15950K(1398272K)] 16517K->15950K(2010112K), [Metaspace: 20697K->20697K(1069056K)], 0.0707538 secs] [Times: user=0.09 sys=0.01, real=0.07 secs] 
   ```

##### 2、分

Minor/Young GC 时间过长原因：

1. **存活对象的标注时间过长**：
   - 1）比如重载了 `Object#finalize()` 方法，会导致标记 Final Reference 耗时过长。
   - 2）或者 `String#intern()` 方法使用不当，导致 GC 扫描 StringTable 时间过长。
   - 3）可以通过配置 `-XX:+PrintReferenceGC` ，显示 GC 处理在 Reference 时的耗时。
2. **对象生命周期变长**：
   - 1）比如本地缓存使用不当，积累了太多存活对象，其中，它们还可能晋升到老年代，增长 FullGC 时间。
   - 2）或者锁竞争严重，导致线程阻塞，引起局部变量的生命周期变长。

Major/Full GC 时间过长原因：

1. **长生命周期的对象多**：过多的全局变量或者静态变量等，会导致标记和复制过程的耗时增加。

##### 3、总

=> 以上，就是我对 GC 时间过长调优 的一些理解，请问有什么细节需要补充的吗？

### 12> MySQL

#### 1.1. MySQL 主键索引、二级索引、联合索引查找数据的原理？

##### 1）主键索引数据查找原理

1. InnoDB#主键索引，使用的是聚蔟索引，如果创建的表没有主键，那么 InnoDB 会隐式定义一个主键，来作为聚蔟索引。
2. 聚蔟索引，叶子结点就是数据结点，将表数据和主键一起存储，数据的物理存放顺序与索引顺序一致，一张表只有一个聚蔟索引。
3. 聚蔟索引在查找数据时，只要根据搜索树的查找原则，小的查左边，大的查右边，定位到叶子节点即是数据，这个操作叫做回表。

##### 2）二级索引数据查找原理

1. 聚蔟索引的二级索引，其叶子结点不保存引用数据，而是保存行的主键值。
2. 然后，根据叶子节点的主键值，回表查找到数据。
3. 这种二级索引在 InnoDB 中比如有，普通索引 和 联合索引。

##### 3）联合索引数据查找原理

1. 联合索引，指在多个字段上创建的索引，数据查找原理需要遵循最左前缀原则。

2. 最左前缀原则，指的是索引按照最左优先的方式匹配索引，主要使用在联合索引中，联合索引的数据结构
   在 InnoDB 中是 B+Tree，它会按照第一个关键字、第二个关键字...顺序进行索引排列。

3. 如果查询的条件遵循了最左前缀原则，那么 MySQL 会：

   ![1648112848858](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648112848858.png)

   - 1）先根据第 1 个关键字，查找联合索引树。
   - 2）定位到索引树的叶子结点后，找出所有满足第 1 个关键字的叶子结点。
   - 3）第 1 个关键字的叶子结点确定后，如果这些叶子结点，对于第 2 个关键字是存在且是顺序的，那么 MySQL 则会使用二分查找的方式，查找这些叶子结点，相当于该索引继续匹配第 2 个关键字。
   - 4）如果这些叶子结点，对于第 2 个关键字来说，不存在或者是乱序的，那么就出现了索引失效，导致后面的条件，都无法继续走上该联合索引，而是根据之前选择的叶子结点的主键，进行回表查找。

#### 1.2. MySQL 联合索引失效原理？

联合索引失效场景，其原理都是因为，匹配到某个关键字的叶子结点时，不满足存在性或者顺序性：

1. 如果不是从索引的最左列开始查找，则无法使用该联合索引。
2. 不能在中间跳过索引中的某个列，这样的查询只能使用到联合索引的前几列。
3. 如果查询中有某个列的范围查询，那么该列右边的所有列，都无法使用该联合索引进行查找。

#### 1.3. MySQL 3 个二级索引好还是 1 个 3 字段的联合索引好？

1. 在应有的查询条件下，MySQL 面对 3 个二级索引，如果是 `and` 操作，则会使用性能最好的 1 个二级索引进行匹配，其他 2 个条件则会走索引下推优化（extra 会显示 `Using index condition`），或者走普通的 where 查询（extra 会显示 `Using Where`），而不是直接走它们的二级索引。
2. 如果是 `or` 或者 `union` 的操作，则有可能会走索引合并，type 会显示 `index_merge`，表示合并了 `or` 两侧字段的索引，性能来得比 `range` 好些。
3. 而如果面对相同的条件，建立起一个 3 字段的联合索引的话，那么有可能会根据最左前缀原则去匹配。
4. 因此，这两者到底谁性能更好，要看具体情况才能定夺，比如这些条件到底是什么，会不会引起索引失效，表的数据量有多大，以及 SQL 的结构是什么等。

#### 1.4. MySQL 二级索引和联合索引是不是建的越多越好？

1. 在 MySQL 中，创建索引的目的是，让索引过滤更多的行，快速定位记录，或者利用索引的有序性，对于那些不符合目的的，无需创建多余的索引。
2. 对于那些用作 where 条件的、参与分组的、参与排序的、参与去重的、参与联表的、或者是唯一的字段，一般会去创建索引。
3. 而对于那些更新多、查询少、不频繁 where 的、或者表数据少、字段列重复数据多的字段，一般都不用创建多余的索引，因为要么是字段用不到，要么是用了但不划算。
4. 无用的索引过多，会额外占据存储空间，所以，索引并不是建的越多越好，满足要求、够用就行。

#### 1.5. 介绍一下 B+ 树，以及 MySQL 为什么采用 B+ 树？

##### 1、总

MySQL 之所以采用 B+ 树，作为索引底层的数据结构，我认为是为了追求性能，以及满足范围查询。

##### 2、分

1. **如果采用 BST**，二叉查找树，虽然可以在 log（n）内查找到目标数据，但在最坏情况下，可能会退化成链表，查询的时间复杂度也退化成了 O（n），性能太慢，故放弃。

   ![1648116903919](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648116903919.png)

2. **如果采用 AVL**，平衡二叉搜索树，虽然能保证，每个结点的左子树和右子树的高度差不会超过 1，优化了 BST 退化成链表的问题，但在大规模数据存储的时候，AVL 会由于树高度过大，会导致每次查找只能找出 2 个结点装入内存，造成磁盘 I/O 读写过于频繁，导致效率低下，故也放弃。

   ![1648116960901](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648116960901.png)

3. **如果采用 HashMap**，哈希表，虽然可以实现在 O（1）内，查找到目标数据，但在数据量过大、散列算法不好时，会出现大量的哈希冲突，查询效率大幅度降低，且由于哈希的特性，不支持范围查找，只能做等值匹配，故也放弃。

   ![1648117079088](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117079088.png)

4. **如果采用 SkipListMap**，跳跃表，虽然可以以二分查找的方式，在 O（logn）内找到目标数据，但需要把全部节点加载到内存，在数据量大时，MySQL 一页装不下，则需要多次 I/O，效率不理想，故也放弃。而 Redis 本身就是内存数据库，所以采用跳跃表是没什么问题的。

   ![1648117132681](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117132681.png)

5. **如果采用 B-Tree**，平衡多路搜索树，m 阶 B-Tree 每个节点都包含 data 数据、m - 1 个关键字、以及 m 个子节点引用，可以有效地降低数树的高度，大大减少查找的次数，性能得到了大幅提升。但由于 B-Tree 每个节点包含 data 数据，会使得一页内容装不下太多结点，磁盘 I/O 次数比较多，且每次范围查询时，都需要多次从头遍历 B-Tree，性能低下，故也放弃。

   ![1648117001612](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117001612.png)

6. **如果采用 B+Tree**，B+ 树，m 阶 B+ 树 非叶子节点包含 m 个关键字、m 个子节点引用，不包含 data 数据，可以使得每次 I/O 加载更多的节点到内存中，减少了 I/O 次数，对比 B-Tree 性能有提升，同时，叶子节点会冗余父结点的关键字，包含了全部的关键字，以及按照关键字大小， 顺序链接起来，构成一个有序双向链表，在做范围查找时，只需要在链表上顺序查找，而无需从头遍历整颗树，对比 B-Tree 性能得到了很大的提升，故 B+Tree 在做大量的磁盘数据查找，是非常适合的。

   ![1648117033116](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648117033116.png)

##### 3、总

因此，MySQL 采用的 B+ 树，来作为索引底层的数据结构，而不是其他。

#### 1.6. MySQL 隐藏主键生成原理？

##### 1、总

1. 如果没有主动设置主键，就会选一个不允许为 NULL 的第一个唯一索引列作为主键列，并把它用作聚集索引。
2. 如果没有这样的索引，就会使用自增的、占 6 个字节的行号，来生成一个聚集索引，把它当做主键，这个行号可以使用 `select _rowid from ${table_name}` 进行查询。

##### 2、分

主键自增 / `AUTO_INCREMENT ` 原理：

1. 如果字段被定义为 `AUTO_INCREMENT`， 那么在插入一行数据时，该字段被指定为 0、null、或者没指定值，那么，就先获取自增锁，把这个表存好的 `AUTO_INCREMENT` 值（初始从 `auto_increment_offset` 开始）填到自增字段中。
   - 自增锁，不是一个事务锁，而是要看 `innodb_autoinc_lock_mode` 策略的配置（默认为 1），0 表示语句执行完才释放，1 表示普通语句申请完马上释放，批量插入语句则等到语句结束才释放，2 表示所有语句都会申请完马上释放。
2. 如果插入数据时，该字段指定了具体的值，则会直接使用语句里指定的值。
3. 如果这个值比当前 `AUTO_INCREMENT` 值小，那么自增值不变，否则，就需要修改 `AUTO_INCREMENT` 为该字段插入的值 + 1。注意，如果此时插入的主键值重复、或者其他原因，导致了事务回滚，被修改的 `AUTO_INCREMENT` 是不会重新减少回去的，所以，会出现自增值不连续的情况。
4. 接着往后，则会以 `auto_increment_increment` 为步长，持续叠加，或者像上面那样碰到大于 `AUTO_INCREMENT` 的、新插入的值然后 +1 并更新。

##### 3、总

=> 以上，就是我对 MySQL 隐藏主键生成原理 的一些理解，请问有什么细节需要补充的吗？

#### 1.7. MySQL 事务 ACID 特性，以及实现原理？

##### 1、总

1. 事务，Transaction，是指访问、更新数据库数据一个程序执行单元，是逻辑上的一组操作，要么都执行，要么都不执行，其执行的结果，必须使数据库从一种一致性状态，变到另一种一致性状态。
2. 而 ACID 则是衡量事务的四个维度，分别是 A 原子性、C 一致性、I 隔离性、D 持久性。

##### 2、分

1. **原⼦性**： Atomicity， 指事务是最小的执行单位，不可再分割，整个事务中所有的操作，要么全部提交成功，要么全部失败回滚，强调的是事务操作的原子不可分割。
   - 1）在 MySQL 中，其实现原理是，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log，如果事务执行失败或调用了 `rollback`，导致事务进行了回滚，就可以根据 undo log 的内容，做与之前相反的操作，把 Buffer Pool 中修改了的数据，回滚到修改之前的样子，从而实现事务原子性。
2. **一致性**：Consistency， 指事务执行结束后，数据库的完整性约束不会被破坏，都是合法的数据状态，强调的是数据状态事务前后的一致性。
   - 1）一致性是事务追求的最终目标，原子性、持久性和隔离性都是为了保证数据库的一致性。
   - 2）其中，在 MySQL 中，实现一致性的措施包括：
     1. 数据库层面的保障：原子性、持久性和隔离性的保证，以及其他一些完整性约束，比如不允许向整型列插入字符串值，或者字符串长度不能超过列的限制等等。
     2. 应用层面的保障：比如，如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致，此时需要保证应用逻辑是符合一致性的。
3. **隔离性**： Isolation，指并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间的数据库是独⽴的，一个事务所做的修改，在最终提交之前，对其他事务是不可见的，强调的是事务间的数据操作互不影响。
   - 1）在 MySQL 中，其实现原理是，写写隔离，通过使用锁机制来保证，写读隔离，快照读使用 MVCC 来保证，当前读则使用锁机制来保证。
4. **持久性**：Durability， 指事务被提交之后，它对数据库中的数据改变是持久的，即使数据库发⽣故障，也不应该对其有任何影响，强调的是事务后的数据会被永久保存。
   - 1）在 MySQL 中，其实现原理是，Buffer Pool 和 redo log。
   - 2）首先是 Buffer Pool，
     1. 为减少每次读写数据的磁盘 I/O，InnoDB 提供了 Buffer Pool 缓存，作为访问数据库的缓冲。
     2. 当从数据库读取数据时，InnoDB 会先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，才会从磁盘读取，然后放入 Buffer Pool 中。
     3. 当向数据库写入数据时，同样 InnoDB 也会先写入 Buffer Pool，Buffer Pool 中修改的数据，会定期刷新到磁盘中，这一过程称为刷脏。
     4. 优点是，大大提高了读写数据的效率。而缺点则是，如果 MySQL 宕机，Buffer Pool 中修改的数据还没有刷新到磁盘中，那么就会导致数据的丢失，无法保证事务的持久性。
   - 3）所以，InnoDB 引入了 redo log，来解决 Buffer Pool 的问题， 以保证事务的持久性：
     1. 这样，在修改 Buffer Pool 中的数据后，会再把数据写到 redo log 缓冲区中。
     2. 然后，根据 `innodb_flush_log_at_trx_commit` 来决定 redo log 的刷盘机制：
        - 1）0：表示当事务提交时，不会把 redo log 缓冲区的日志，同步到 redo log 磁盘文件中，而是要等待线程每秒的刷新，所以，不能保证全部写入成功。
        - 2）1：表示当事务提交时，会主动把 redo log 缓存区的日志，同步到 redo log 磁盘文件中，能够保证全部写入成功。
        - 3）2：表示当事务提交时，会异步把 redo log 缓存区的日志，同步到 redo log 磁盘文件中，也是不能保证全部写入成功的。
     3. 由于写 redo log 是追加操作，属于顺序 I/O，且刷回磁盘的只是被修改的部分，对比 Buffer Pool 刷脏的随机 I/O 以及全量刷脏，性能来得更高。
     4. 有了 redo log 磁盘文件后，当 MySQL 宕机了，重启时，就可以读取 redo log 中的数据，对数据进行恢复，保证了事务的持久性。

##### 3、总

总结一下，undo log、redo log 和 bin log：

| 不同点   | undo log                                    | redo log                       | bin log                      |
| -------- | ------------------------------------------- | ------------------------------ | ---------------------------- |
| 名称     | 回滚日志                                    | 重做日志                       | 二进制日志                   |
| 存储内容 | 属于逻辑日志，内容为版本链需要的相关信息    | 属于物理日志，内容为数据页     | 逻辑日志，内容为一条条SQL    |
| 作用     | 是 MySQL 实现事务原子性和 MVCC 隔离性的基础 | 用于崩溃恢复，保证事务的持久性 | 用于时间点恢复，保证主从复制 |
| 实现层面 | 由 InnoDB 存储引擎实现                      | 由 InnoDB 存储引擎实现         | 由 MySQL 服务器实现          |
| 写入时机 | 事务提交前，当做数据合并到 redo log 中      | 事务提交前刷盘                 | 事务提交前刷盘               |

最后，再总结一下，事务读写数据到提交的整体流程为：

1. 事务读时，则加载缓存数据到 Buffer Pool 缓冲池。
2. 事务写时，先是记录数据旧值到 undo log 缓冲区中。
3. 然后，更新 Buffer Pool 中的内存数据。
4. 接着，把更新后的数据，写入到 redo log 缓冲区中。
5. 事务准备提交，则把 undo log 缓冲当做数据，一起写入 redo log 缓冲区中，然后 redo log 日志刷入磁盘。
6. 也是在此时，bin log 也写入磁盘。
7. bin log 写入磁盘后，还会写入 commit 标记到 redo log 磁盘文件中。
8. 最后，I/O 线程把 Buffer Pool 中修改的数据，定期刷脏到磁盘中，事务提交。
9. 如果要重启恢复，则先回放 redo log，生成数据到 Buffer Pool 内存中，然后从 redo log 中构造 undo page，做相反的操作，回滚掉被修改了的内存数据，以及使用 undo page 实现 MVCC。

![1648126170770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648126170770.png)

=> 以上，就是我对 MySQL 事务 ACID 实现原理的一些理解，请问有什么细节需要补充的吗？

#### 1.8. MySQL Buffer Pool 满了以后会怎么样？

##### 1、总

首先，要讲一下 Buffer Pool 是什么，

1. 实际上，MySQL 中的数据，最终都是要存放在磁盘文件上的。
2. 但是，在对 MySQL 执行增删改时，不可能直接更新磁盘上的数据，因为如果对磁盘进行随机读写操作，那速度相当的慢，随便一个大磁盘文件的随机读写操作，可能都要几百毫秒、数据库每秒也就只能处理几百个请求而已。
3. 所以，在对 MySQL 执行增删改时，主要都是针对内存里的 Buffer Pool 中的数据进行的，也就是实际上主要是对 MySQL 内存里的数据结构进行增删改，再配合 redo log、undo log、刷脏机制，确保事务的持久性和原子性。
4. 可见，Buffer Pool 是 MySQL 的一个内存组件，里面缓存了磁盘上的真实数据，在对 MySQL 执行的增删改时，其实都是对这个内存数据结构中的缓存数据进行的。

##### 2、分

然后就是，Buffer Pool 里存放了什么东西，

1. 实际上，MySQL 对数据抽象出了一个数据页的概念，把很多行数据放在了一个数据页里，也就是磁盘文件中会有很多数据页，每一页数据里存放了很多行数据。

2. 在要更新一行数据时，MySQL 会找到这行数据所在的数据页，然后从磁盘文件里，把这行数据所在的数据页，加载到 Buffer Pool 里，也就是说，Buffer Pool 中存放的是一个一个的数据页。

3. 默认情况下，磁盘中存放的一页数据页大小为 16 KB，而 Buffer Pool 中存放的一个一个的数据页，叫做缓存页，一个缓存页的大小，也是和磁盘上的一个数据页大小一一对应起来的，都是16KB。 

4. 对于每个缓存页，实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的，比如包含：这个数据页所属的表空间、数据页的编号、这个缓存页 在 Buffer Pool 中的地址等别的信息。每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。这种描述数据，相当于缓存页大小的 5% 左右，所以，Buffer Pool 实际上真正的最终大小会比设置的超出一些。因此，Buffer Pool 实际长如下这个样子：

   ![1648173791945](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1648173791945.png)

接着就是，Buffer Pool 的工作流程，

1. 在执行 curd 时，MySQL 会不停地加载磁盘上的数据页到 Buffer Pool 的缓存页里来，再查询和更新缓存页里的数据，同时维护一系列的链表结构。
2. 然后，后台线程定时根据 lru 链表和 flush 链表，去把一批缓存页刷入磁盘释放掉这些缓存页，同时更新 free 链表。
3. 而如果执行 curd 时发现缓存页都满了，无法加载自己需要的数据页进缓存时，则会把 lru 链表冷数据区域的缓存页刷入磁盘，然后加载自己需要的数据页进来。

##### 3、总

最后就是，设置合理的 Buffer Pool 大小了，

1. 所以，设置合理的 Buffer Pool 大小，可以尽可能地保证 MySQL 高性能和高并发能力。
2. 通常来说，一般建议把 Buffer Pool 设置为机器内存的 50%~60% 左右，剩余的留给操作系统以及其他地方使用。比如，我们生产环境中的 MySQL 总内存是 128 GB，通过 `SELECT @@innodb_buffer_pool_size/1024/1024/1024;` 查到的是了 64 GB，大小是合理的。
3. 而如果要修改的话，可通过 `set global innodb_buffer_pool_size = ${字节数};` 来进行设置。

=> 以上，就是我对 MySQL Buffer Pool 的一些理解，请问有什么细节需要补充的吗？

#### 1.9. MySQL锁分类？

见《p6+MySQL篇 - MySQL锁分类》。

#### 2.0. MySQL MVCC？

##### 1、总

MVCC，Multi-Version Concurrency Control，多版本并发控制，可以实现数据库读写冲突时的无锁并发访问，可以做到在读时不阻塞写，写时不阻塞读，提高了数据库并发的读写性能，同时还可以解决 MySQL 不可重复读、幻读等事务并发问题。

##### 2、分

1. 首先，需要讲一下 MySQL 中的当前读和快照读：

   - 1）**当前读**：非 MVCC 实现，读取的是记录的最新版本，读取时，要保证其他并发事务不能修改当前记录，因此会对读取的记录进行加锁。
     - 举例：select lock in share mode（共享锁）, select for update（排他锁），update、insert、delete（排他锁）、串行化事务隔离级别等。
   - 2）**快照读**：MySQL 实现 MVCC 模型的中一个具体的非阻塞读功能，可以避免读时的加锁操作，从而降低开销、提高并发性能，但快照读可能读到的不一定是数据的最新版本，而是之前的历史版本，但前提是，事务使用非串行化的隔离级别，否则串行化级别下的快照读会退化成当前读。
     - 举例：不加锁的 select。

2. 然后就是实现原理，MySQL 是由 undo log + 版本链 + Read View 来实现 MVCC 的：

3. 第一个是 **undo log**，回滚日志，属于逻辑日志，记录的是 sql 执行相关的信息，是 MySQL 中事务原子性和隔离性实现的基础，其实现原理是：

   - 1）在 MySQL InnoDB 中，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log。
   - 2）如果事务执行失败或调用了 rollback，导致事务需要回滚时，就可以根据 undo log 的内容做与之前相反的工作，把数据回滚到修改之前的样子，以实现事务原子性操作。
   - 3）对于每个 insert，回滚时会执行 delete。对于每个 delete，回滚时会执行 insert。对于每个 update，回滚时会执行一个相反的 update，把数据改回去。
   - 4）而 MVCC 则是采用 undo log 来记录旧版本，链首为最新的旧记录，链尾为最早的旧记录。

4. 第二个是**版本链**，在 InnoDB 中，每次修改版本都会在版本链中记录，通过 undo log + trix_id + roll_pointer 来实现，undo log 原理如上所说，

   ![1630673126935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630673126935.png)

   - 1）**trx_id**：当前版本的事务ID，用来存储每次对某条记录进行修改时的事务ID，其中事务 ID 则是，当每个事务开启时，都会被分配一个ID，而这个ID是递增的，因此越新的事务其ID值越大。
   - 2）**roll_pointer**：回滚指针，由于每次对记录修改时，都会把老版本写入到 undo 日志中，使用回滚指针 roll_pointer 来指向这条记录上一个版本的位置，通过它来获得上一个版本的记录信息，其中，插入操作的 undo 日志是没有 roll_pointer 的，因为它没有老版本。

5. 第三个是 Read View，它是事务进行快照读操作时产生的读视图，是数据库当前的一个快照，记录了系统当前活跃事务ID 集合（即还没有提交的事务 ID），用来做可见性判断，即当某个事务执行快照读时，会对该记录创建一个Read View 读视图， 并把它作为条件，来判断当前事务能够看到哪个版本的数据，其中可能是当前版本的数据，也有可能是该行记录 undo log 里面某个版本的老数据，具体原理如下：

   ![1630674963257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630674963257.png)

   1. **trx_id == creator_trx_id**：可以访问这个版本，这个版本的事务 ID 等于当前创建 Read View的事务 ID，即自己能够读到自己的版本。
   2. **trx_id < min_trx_id**：可以访问这个版本，这个版本的事务 ID 小于最小活跃事务 ID，说明这个版本已经被提交过了，对于当前做可见性判断的事务来说，是可以看见的。
   3. **trx_id > max_trx_id**：不可以访问这个版本，这个版本的事务 ID 大于下一个事务 ID，说明这个版本记录是在该 Read View 生成之后产生的，已经超出了版本链范围，而快照读只能读取版本链中的版本，因此该版本对于当前做可见性判断的事务来说，是不应该看见的。
   4. **min_trx_id <= trx_id <= max_trx_id**：
      - 如果这个版本的事务 ID 为 m_ids 中的某个值，则不可以访问这个版本的，因为m_ids 都是活跃的、还没提交的事务，说明该版本记录还没有提交，对于当前做可见性判断的事务来说，是不应该看见的。
      - 如果这个版本的事务 ID 不为 m_ids 中的某个值，则可以访问这个版本，因为没在 m_ids 里，又小于等于 max_trx_id，说明该版本记录已提交了，对于当前做可见性判断的事务来说，是可以看见的。

   => 因此，可见性判断总的来说就是，要当前事务能看到的版本应该是自己创建的或者已经提交了的，这也是实现 MVCC 的原理所在。

##### 3、总

以上，就是我对 MySQL MVCC 的一个理解，请问有什么细节需要补充的吗？

#### 2.1. 事务并发问题？

- **脏读**：Drity Read，指两个事务并发执行，事务A已更新某一份数据，事务B读取同一份数据，出于某种原因，事务A回滚了更新的操作，导致事务B读取的数据不正确。
  - **产生原因**：事务A读取了事务B中**未提交的数据**。
  - **特点**：违背了隔离性。
- **不可重复读**：Non-repeatable read，指两个事务并发执行，事务A前后两次查询的结果不一样（**行内容发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**修改并提交了事务**。
  - **特点**：相比脏读的区别是，不可重复读是读取另一事务提交的数据。这种现象是正常的，是由于事务的隔离级造成的，但是在在某些特别的情况下也是不允许的。 
- **幻读**：Phantom Read，指两个事务并发执行，事务A前后两次查询的结果不一样（**出现了幻行，导致行数量发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**新增数据并提交了事务**，比如事务A查询了几行数据，而事务B并发插入了新的几行数据，事务A在接下来的查询中，会发现有几行数据是它先前所没有的。
  - **特点**：和不可重复读一样，都是读取了另外一个事务的数据，不同的是不可重复读查询的是同一条数据，而幻读则是针对批量的数据，或者说**不可重复读是A读取了B的更新数据，幻读是A读取了B的新增数据**。

#### 2.2. 事务隔离级别？

| 事务隔离级别 | 存在的事务并发问题     |
| ------------ | ---------------------- |
| 读未提交     | 脏读、幻读、不可重复读 |
| 读已提交     | 幻读、不可重复读       |
| 可重复读     | 幻读                   |
| 串行化       | 没有事务并发问题       |

- **读未提交**：READ UNCOMMITTED，是最低的事务隔离级别，事务可以读取到其他事务未提交的数据，可能会导致脏读、不可重复读和幻读。

  - **当前读**：读取数据**不需要加共享锁**，这样就不会与修改的数据上的排他锁冲突了。

- **读已提交**：RC，READ COMMITTED，也叫不可重复读，事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的，是大多数据库的默认事务隔离级别（**比如Oracle**），可以阻⽌脏读，但还是可能会导致不可重复读和幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在语句执行完以后释放共享锁**。
  - **快照读**：MVCC
    - **Read View以select为单位**，每次select都会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **不可重复读的原因**：由于Read View以select为单位，每次select都会生成一个Read View，两者的可见性判断的结果可能不一样，能看到的版本也就不一样，从而可能导致事务前后两次的**查询别人版本的结果**不一致，产生不可重复读。

- **可重复读**：RR，REPEATABLE READ，事务对同⼀字段的**多次读取的结果都是⼀致的**，除⾮数据是被事务本身所修改，是**MySQL的默认事务隔离级别**，可以阻⽌脏读和不可重复读，但还是可能会导致幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在事务提交之前并不释放共享锁**，也就是必须等待事务执行完毕以后，才释放共享锁。
    - **解决幻读的方式**：
      - **使用间隙锁**：MySQL默认开启间隙锁，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。
      - **使用MVCC快照读**：快照读基于Read View来实现，每个事务对应一个Read View，解决了幻读的问题。
      - **升级到串行化隔离级别**：把隔离级别设置成SERIALIZABLE，但这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多，实际中很少用到。
  - **快照读**：MVCC
    - **Read View以事务为单位**，每个事务只会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **解决不可重复读、幻读的问题**：由于Read View以事务为单位，每个事务只会生成一个Read View，事务前后的快照读只对应同一份Read View，可见性判断一致，能看到的版本一致，因此整个事务过程中**查询别人版本的结果**一致，避免了不可重复读、幻读的发生，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。

  |        | RC                                   | RR                         |
  | ------ | ------------------------------------ | -------------------------- |
  | 实现   | 多条查询语句会创建多个不同的ReadView | 仅需要一个版本的ReadView   |
  | 粒度   | 语句级读一致性                       | 事务级读一致性             |
  | 准确性 | 每次语句执行时间点的数据             | 第一条语句执行时间点的数据 |

- **串行化**：SERIALIZABLE，是最高的隔离级别，通过强制事务串行执行，所有的事务依次逐个执⾏，事务之间完全不存在互相⼲扰，解决了幻读的问题，即阻止了所有的事务并发问题，包括脏读、不可重复读和幻读。

  - **当前读**：**锁定整个范围的键**，并一直持有锁，直到事务完成，可能导致大量的超时和锁争用的问题，实际中很少使用。

#### 2.3. 讲一下 SQL Explain？

##### 1、总

1. 使用 EXPLAIN 关键字，可以模拟优化器执行 SQL 语句，分析查询 SQL 语句的性能瓶颈。
2. 在 select 语句之前增加 explain 关键字，MySQL 就会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是真正去执行 SQL。

##### 2、分

Explain 结果字段有如下几个：

| Explain 结果字段 | json 名称     | 含义                                                         |
| ---------------- | ------------- | ------------------------------------------------------------ |
| **id**           | select_id     | 该语句的唯一标识，id 越大，越先执行，相同 id 的，从上到下执行 |
| select_type      | 无            | 查询类型                                                     |
| table            | table_name    | 表名                                                         |
| partitions       | partitions    | 匹配的分区                                                   |
| **type**         | access_tpye   | 联接类型                                                     |
| possible_keys    | possible_keys | 可能的索引选择                                               |
| key              | key           | 实际选择的索引                                               |
| **key_len**      | key_length    | 索引的长度                                                   |
| ref              | ref           | 索引的哪一列被引用了                                         |
| **rows**         | rows          | 估计要扫描的行                                               |
| filtered         | filtered      | 表示符合查询条件的数据百分比                                 |
| **extra**        | 没有          | 附加信息                                                     |

其中，影响性能的字段主要有：

###### 1）type | 连接类型

type 有以下几种取值，性能从好到坏：

| 连接类型        | 含义                                                         | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| system          | 该表只有一行，相当于系统表                                   | system是const的特例                                          |
| const           | 针对主键或者唯一索引的等值查询，最多返回一行数据             | 查询速度非常快                                               |
| eq_ref          | 当使用了索引的全部组成部分，并且索引是**主键或者非空唯一索引**才会发生 | 性能仅次于system和const                                      |
| ref             | 当满足索引的最左前缀规则，或者索引**不是主键也不是唯一索引**时才会发生 | 如果索引只匹配到少量的行，则性能也是不错的                   |
| fulltext        | 全文索引                                                     | 使用MyISAM存储引擎才有                                       |
| ref_or_null     | 该类型类似于ref，但MySQL会额外搜索哪些行包含NULL，           | SELECT * FROM ref_table WHERE key_col = expr OR key_col IS NULL； |
| index_merge     | 该类型表示使用了索引合并优化，表示一个查询里面用到了多个索引 | -                                                            |
| unique_subquery | 该类型和eq_ref类型，但使用了**IN查询**，且**子查询是主键或者唯一索引** | value IN (SLECT id FROM single_talbe WHERE expr)             |
| index_subquery  | 和unique_subquery类型，只是**子查询使用的是非唯一索引**      | value IN (SELECT key_col FROM single_table WHERE other_expr) |
| range           | 范围扫描，表示检索了指定范围的行，主要用于有限制的索引扫描   | 常见的有，BETWEEN、>、>=、<、<=、IS NULL、<=>、LIKE、IN      |
| index           | 全索引扫描，和ALL类型，只不过index是全盘扫描了索引的数据     | 当查询仅使用索引中的一部分列时，会使用该类型，有两种触发场景：1）覆盖索引，比ALL快，此时只扫描索引数，Extra列为Using Index；2）全表扫描，同ALL，此时会回表查询数据，Extra列不会出现Using Index； |
| ALL             | 全表扫描                                                     | 性能最差                                                     |

###### 2）key_len | 索引的字段长度

1. 索引字段长度，当字段允许为 NULL 时，key_len 会比不允许为 NULL 的大 1 个字节。
2. 长度越短，一页就能装更多的 B+ 树节点，磁盘 I/O 次数就越少，性能就越高。

###### 3）rows | 估算的扫描行数

MySQL 估算会扫描的行数，数值越小，性能越高。

###### 4）extra | 查询的附加信息

用于展示有关本次查询的附加信息，重要的取值有：

| 附件信息                                                     | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Using filesort**                                           | 当Query中包含ORDER BY操作，而且无法利用索引完成排序操作时，MySQL Query Optimizer不得不选择相应的排序算法来实现。在数据较少时，从内存排序，否则从磁盘排序。 其中，Explain不会显式地告诉客户端用哪种排序。 |
| **Using Index**                                              | 仅使用索引树中的检索列信息，不必进行其他查找以读取实际行，当查询仅使用属于单个索引的列时，会使用此策略 |
| **Using index condition**                                    | 使用索引下推时出现，表示先按条件过滤索引，过滤完索引后，找到符合索引条件的数据行，随后用WHERE子句中的其他非索引条件，去过滤这些数据行。 |
| **Using index for group-by**                                 | 数据访问和Using Index一样，所需数据只需要读取索引，当Query中使用GROUP BY或者DISTINCT子句时，如果所有分组字段也在索引中，该信息就会出现 |
| Using join buffer（Block Nested Loop），Using join Buffer（Batched Key  Access） | 使用Block Nested Loop或者Batched Key  Access算法来提高join的性能 |
| Using MRR                                                    | 使用了Muti-Range Read优化策略                                |
| Using sort_union（..），Using union（..），Using intersect（..） | 这些提示索引扫描如何合并为index_merge连接类型                |
| **Using temporary**                                          | 为了解决该查询，MySQL创建了一个临时表来保存结果，如果查询包含不同列的GROUP BY和ORDER BY子句，通常会发生这种情况。 |
| **Using Where**                                              | 如果不是读取表的所有数据，或者不仅仅通过索引就可以获取所有需要的数据时，则会出现该值 |

##### 3、总

=> 以上，就是我对 SQL Explain 的一些理解，请问有什么细节需要补充的吗？

#### 2.4. MySQL SQL语句调优？

见《p6+MySQL篇 - MySQL SQL语句调优？》。

#### 2.5. MySQL主从复制？

见《p6+MySQL篇 - MySQL主从复制？》。

#### 2.6. MySQL分库分表？

见《p6+MySQL篇 - MySQL分库分表？》。

### 13> Redis

#### 1.1. Redis 数据结构？

##### 1、总

对于这个问题，我打算先介绍 Redis 对象 `RedisObject`，

1. 其数据结构包含一个 4 字节的 `type` 对象类型属性，分为 STRING、HASH、LIST、SET 和 ZSET。
2. 一个 4 字节的 `encoding` 对象编码属性，包括 INT、EMBSTR、RAW、HT、LINKEDLIST、ZIPLIST、INTSET 和 SKIPLIST。
3. 以及一个 `ptr` piont 指针，指向底层实现的数据结构。

然后我再按照上面所说的对象类型（String、Hash、List、Set、ZSet）按顺序进行介绍。

##### 2、分

###### 1）String

1. 首先是 String，常见的 API 有， SET、SET NX EX、GET、APPEND、STRLEN、SETRANGE、GETRANGE、MSET、MGET、INCRBY、DECRBY 等命令，适合存储帖子、评论、热点数据等缓存，其底层的数据结构分为 3 种编码，分别为 INT、EMBSTR 和 RAW：

2. **INT**：只能存储 long 类型的整数，`ptr` 指针指向对应的整数值。

   ![1631946982581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631946982581.png)

3. **EMBSTR**：（< 3.2 版本时）在字符串值小于等于 39 字节时会使用此编码，其优点是，它是对 `SDS` 的一个小优化，通过将 `RedisObject` 对象头和 `SDS` 存放在一起，采用**连续空间保存**，只需要一次内存分配，避免了它们各自进行空间分配，提高了字符串的内存分配效率，同时还可以减少内存碎片和 `ptr` 指针的占用，节约内存，提高空间的利用率。

   - `SDS`：是 Redis 自己实现一个字符串数据结构，通过持有 `len` 来标识字符串长度，`free` 来记录空闲字符的个数，`buf` 则指向真实的字符数组，能够在 O（1）内获取字符串长度，具有空间预分配、惰性释放内存，以减少分配次数的特点。
   - **缺点**：EMBSTR 是**只读**的形式，要修改时，只能转换为 RAW 编码，才能进行修改。

   ![1631878253168](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878253168.png)

4. **RAW**：（< 3.2 版本时）在字符串值大于 39 字节时会使用此编码，`ptr` 指针指向一个 `SDS` 数据结构，也就是以 `SDS` 的形式存储，主要为了解决长度计算和追击字符效率的问题。

   ![1631947051873](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631947051873.png)

###### 2）Hash

1. 然后就是 Hash，常见的 API 有，HSET、HGET、HEXSITS、HDEL、HLEN、 HSTRLEN、HINCRBY、HMSET、HMGET、HKEYS、HVALUES 等命令，适合存储结构化的对象数据，其底层的数据结构分为 ZIPLIST 和 HT。

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 HASH 取值时，可以通过**向后或者向前遍历**找到对应的键和值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631950146881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950146881.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631950298985](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950298985.png)

###### 3）List

1. 接着就是 List，常见的 API 有：LPUSH、LPOP、RPUSH、RPOP、LREM、LINSERT、LSET、LINDEX、LRANGE、LTRIM、BLPOP、BRPOP、RPOPLPUSH、BRPOPLPUSH，适合用作评论列表、商品列表、发布与订阅等功能，其底层的数据结构分为 ZIPLIST、LINKEDLIST 和 QUICKLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 512 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 LIST 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631952569099](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952569099.png)

3. **LINKEDLIST**：双向链表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，它是 Redis 自己实现的一条双向链表，包含头节点、尾结点、前驱和后继，可以很方便的进行向后或者向前遍历，同时持有 `len` 长度计数器，可以 O（1）内获取到 LIST 的长度 。

   - **缺点**：每个节点都有自己的前后指针，指针这部分所占用的内存较多，且每个节点是单独进行内存分配，当节点过多时，造成的内存碎片会比较多，影响内存管理的效率。

   ![1631952812216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952812216.png)

4. **QUICKLIST**：快速列表，大于 3.2 版本后，LIST 统一采用此格式进行存储，是 ZIPLIST 和 LINKEDLIST 的混合体，它将 LINKEDLIST 按段切分，每一段使用 ZIPLIST 来紧凑存储，多个 ZIPLIST 之间使用双向指针串接起来，缓解了 LINKEDLIST 指针内存浪费和内存碎片多的问题，同时解决 ZIPLIST 数据量过大时导致的性能变差问题。

   - **缺点**：ZIPLIST 节点太小的话（比如只存 1 个元素时），快速列表会退化成普通的链表，起不到应有的节省内存的作用，而 ZIPLIST 节点太大的话（比如只有一个 ZIPLIST 节点时），快速列表会退化成压缩列表，还是会出现数据量过大时导致的性能变差问题。
   - 因此，快速列表内部默认定义的单个 ZIPLIST 节点大小为 `8k 字节`，可以由参数 `list-max-ziplist-size` 来控制，其作用是，在分配结点时，如果发现当前 ZIPLIST 节点超过了这个大小，则会重新分配一个 ZIPLIST 节点。

   ![1631953074136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631953074136.png)

###### 4）Set

1. 再然后就是 Set，常见的 API 有：SADD、SPOP、SREM、SRANGMEMBER、SISMEMBER、SCARD、SMEMBERS、SINTER、SINTERSTORE、SUNION、SUNIONSTORE、SDIFF、SDIFFSTORE，适合用于求交集、并集、差集，比如朋友关系，其底层的数据结构分为 INTSET 和 HT 编码。 

2. **INTSET**：整数集合，（< 3.2 版本时）只存储 long 范围内的整数值，且在元素个数 < 512 个时会使用此编码，持有对应整数的编码类型 `encoding` 总是使用容纳数字的**最小编码进行存储**，以节约内存、集合元素数量 `length` 可以在 O（1） 内获取到对应长度、以及元素使用数组  `contents`  来进行**连续存储**，可以减少内存碎片和指针内存的占用，以节约内存。

   - **缺点**：编码类型只能升级不能降级，在大数字删除后，整数集合还是会使用大类型存储小数字，造成空间的浪费。

   ![1631954240528](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954240528.png)

3. **HT**：哈希表，（< 3.2 版本时）在元素大小大于等于 64 字节，或者元素个数大于等于 512 个时会使用此编码，基于 2 张哈希表实现，使用拉链法解决哈希冲突，相对于 Java#HashMap，其特点在于，除了在负载因子大于等于 1  （没有执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）或者 5 （执行 `BGSAVE` 或者 `BGREWARITEAOF` 时）发生 2 倍实际使用长度的扩容外，还会在负载因子小于 0.1 时发生 1 倍实际使用长度的缩容， 并且采用的是渐进式的 `rehash` 机制，即定时执行，或者在客户端每次增删改查操作完成后，让其进行一次 `rehash` 操作，把 ht[0] 对应 `rehashindex` 位置的值搬 ht[1] 上，然后 `rehashIndex+1`，这样避免了集中式扩容带来的性能压力。

   - **缺点**：在 `rehash` 期间，需要同时持有两张哈希表，对内存占用稍大，如果本身内存都不足时，突然的 `rehash` 会使得 Redis 执行缓存淘汰策略，抛弃大量的 Key。

   ![1631954355626](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954355626.png)

###### 5）ZSet

1. 最后就是 ZSet，常见的 API 有：ZADD、ZREM、ZSCORE、ZINCRBY、ZRNAGE（指定偏移，score 从小到大，分数相等，则再按值顺序排序）、 ZRERANGE（指定偏移，score 从大到小，分数相等，则再按值逆序排序）、ZRNAGEBYSOCRE（指定分数）、 ZRERANGEBYSOCRE（指定分数）、ZRANK、ZRERANK、ZCARD、ZCOUNT（区间个数统计） 等命令，可以在去重后进行排序，适合排名的场景，其底层的数据结构分为 ZIPLIST、SKIPLIST 编码。 

2. **ZIPLIST**：压缩列表，（< 3.2 版本时）在元素大小小于 64 字节且元素个数少于 **128** 个时会使用此编码，由数组实现，通过 `zlbytes` 记录列表总字节数、`zltail_offset` 记录最后一个节点的偏移量快速定位结尾、`zllength` 记录列表元素个数、`entries` 数组存储列表节点、`zlen` 标志列表结束，以及每个`entry` 节点都持有前一个节点的长度 `prevlous_entry_length`，在 ZSet 取值时，可以通过**向后或者向前遍历**找到对应的值，其优点是由于内存是连续的，可以减少很多内存碎片和指针内存的占用，进而**节约内存**。

   - **缺点**：ZIPLIST 存在级联更新的问题，由于 `prevlous_entry_length` 存储的长度取决于前一个节点的长度，当前一个节点大于 254 字节时，这个值会从 1 字节变为 5 字节，从而导致后面值可能也会发生变更的连锁反应，此时的时间复杂度非常差为 O（n^2），但好在这种大范围的级联更新出现的概率并不大。

   ![1631954526032](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954526032.png)

3. **SKIPLIST**：（< 3.2 版本时）在元素大小大于等于 64 字节且元素个数大于等于 **128** 个时会使用此编码，由跳跃表 + 哈希表来实现，通过在有序链表上维护每级 25% 概率生成的索引，从而达到 O（logn）访问元素的目的，通过累加查找路径中的 `SPAN` 跨度，来计算当前节点所处的排名，通过哈希表存储跳跃表节点，以实现在 O（1）内完成根据名称找到对应的得分。

   - **缺点**：由于新节点插入的 LEVEL 是随机的，导致老节点的查找路径可能发生变化，**缓存友好性不如**红黑树，而红黑树则是插入新节点后，大部分老节点仍然处于原查找路径上。
   - **为什么 Redis#ZSet 使用跳跃表而不是红黑树**？
     1. **范围查找效率高**：
        1. 对于 `ZRANGE` 和 `ZREVRANGE` 命令的范围查找，如果使用哈希表，则只能做单值查找，不适合做范围查找。
        2. 如果使用红黑树，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]，效率低且实现复杂。
        3. 而使用 skiplilst 只需要 O（logn）定位头尾结点，然后遍历链表即可，简单又高效。
     2. **内存占用少**：Redis skiplist 索引的默认生成概率为 25%，即每个结点平均只包含 **1.33** 个指针，内存占用比红黑树的 2 个指针要少。
     3. **实现与调试容易**：使用 skiplist 比红黑树更容易实现与调试。

   ![1631955510770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955510770.png)

##### 3、总

以上就是我对 Redis 常用数据结构的一些理解，请问还有什么细节需要补充的吗？

#### 1.2. Redis Bitmap与布隆过滤器？

《见 p6+Redis篇 - Redis Bitmap与布隆过滤器？》。

#### 1.3. Redis事务？

《见 p6+Redis篇 - Redis事务？》。

#### 1.4. Redis 内存淘汰策略？

内存淘汰策略是指，当达到指定的 `maxmemory` 内存量时（默认为 0，代表没有限制），会根据不同的策略，选择不同的旧数据进行淘汰，可通过 `maxmemory-policy` 进行设置。

1. LRU，Least Recently Used，最近最少使用淘汰算法，用于淘汰最长时间没有被访问的旧数据。
2. LFU：Least Frequently Used，最不经常使用淘汰算法，用于淘汰在一段时间内访问次数最少的旧数据。

| 策略                      | 作用对象   | 客户端请求发现内存不足时                                     | 适用场景                                            |
| ------------------------- | ---------- | ------------------------------------------------------------ | --------------------------------------------------- |
| noeviction                | 全局 key   | 会返回错误                                                   | 常量字典，不能淘汰任何 key 时                       |
| allkeys-lru               | 全局 key   | 会先尝试删除 LRU key                                         | 热点缓存，需要淘汰非热点 key 时                     |
| volatile-lru              | 可过期 key | 会先尝试删除 LRU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 热点缓存，需要淘汰非热点 key，又需要保护永久 key 时 |
| allkeys-random            | 全局 key   | 会随机淘汰 key                                               | 需要以相同概率去淘汰 key 时                         |
| volatile-random           | 可过期 key | 会随机淘汰 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要以相同概率去淘汰 key ，又需要保护永久 key 时    |
| volatile-ttl              | 可过期 key | 会先尝试删除剩余 TTL 最短的 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要根据过期时间去淘汰 key 时                       |
| allkeys-lfu（Redis 4.0）  | 全局  key  | 会先尝试删除 LFU key                                         | 需要淘汰访问次数少的 key 时                         |
| volatile-lfu（Redis 4.0） | 可过期 key | 会先尝试删除 LFU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要淘汰访问次数少的 key，又需要保护永久 key 时     |

#### 1.5. Redis 过期策略？

##### 1、总

在 Redis 中，可以设置缓存 key 的过期时间，过期策略就是指，当 Redis 中缓存 key 过期了，Redis 是如何处理的。

##### 2、分

常见的过期策略，通常有以下三种：

1. 定时过期：每个设置过期时间的 key，都需要创建一个定时器，到过期时间就会立即清除。优点是，该策略可以立即清除过期的数据，对内存很友好。缺点是，会占用大量的 CPU 资源，去处理过期的数据，从而影响缓存的响应时间和吞吐量。
2. 惰性过期：只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。优点是，该策略可以最大化地节省 CPU 资源。缺点是，对内存非常不友好，在极端情况下，可能出现大量的过期 key 没有再次被访问，从而不会被清除，占用大量内存。
3. 定期过期：每隔一定的时间，会扫描 expires 字典中一定数量的 key，并清除其中已过期的 key。该策略是前两者的一个折中方案，通过调整定时扫描的时间间隔、以及每次扫描的限定耗时，在不同情况下，使得 CPU 和内存资源达到最优的平衡效果。 
   - expires 字典，会保存所有可过期 key 的过期时间数据，该字典 key 指向 Redis 集群键空间中的某个可过期 key 的指针，字典 value 是该可过期 key 用 UNIX 毫秒时间戳表示的过期时间。

##### 3、总

而 Redis 中，则是同时使用了后两种，即惰性过期 + 定期过期，这两种过期策略。

#### 1.6. 分布式锁的实现方案，以及红锁的缺点？

##### 1、总

分布式锁指的是，在不同的系统或者同一个系统的不同主机之间，共享访问某个资源时，用来互斥地防止彼此干扰保证一致性的锁实现，其实现方式有：

- **基于数据库实现**：通过乐观锁，或者唯一索引实现。
- **基于分布式缓存实现**： 典型的有，通过 Redis 实现。
- **基于分布式一致性算法实现**：典型的有，通过 ZK 实现。

##### 2、分

###### 1）基于数据库实现 | 负担大

- **基于乐观锁实现**：原理是，固定一个版本号，带上版本号更新，更新成功的，代表获取锁成功，更新失败的，代表获取锁失败，释放锁则需要把该版本号还原回去。
- **基于唯一索引实现**：原理是，在表上建立唯一索引，当想要获得锁时，向表中插入一条记录，释放锁时则删除这条记录。
  - **缺点**：
    1. **锁没有失效时间**，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
    2. **不可重入**，同一线程在没有释放锁之前无法再获取到锁。

###### 2）基于分布式缓存实现 | 锁失效

- **基于 Redis 单机实现**：使用 `SET NX EX` 指令加锁，保证**原子性**地给锁设置**过期时间，防止死锁**，使用 LUA 脚本 `redis.call` 指令，保证 key 值判断与删除键指令原子性执行，防止由于 STW 时间过长，锁被其他进程误删。

  - **缺点**：会出现由于**时钟漂移** 或者 任务执行时间过长，导致的锁被提前释放的问题。

- **基于 Redisson 实现**：它是一个 Redis 的客户端，其分布式锁的实现原理是，让获得锁的线程开启一个定时守护线程，每隔 expireTime / 3 的时间就去检查一下，该线程持有的锁是否还存在，如果存在，则对锁的过期时间重新设置为 expireTime，完成守护线程对**锁的续约**，防止锁由于过期提前释放。

  - **缺点**：这些只是在 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 是**异步复制**的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下，发生了故障转移，那么其他客户端上的线程依然可以获取到锁，丧失了锁的安全性。

- **基于 RedLock 算法实现**：红锁算法的原理是，

  1. 先获取当前时间 `t1`，然后按顺序依次尝试从 n 个 Redis 实例，使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁的失效时间 `expire`，还应该设置超时时间 `timeout`，且这个超时时间 **<** 锁的失效时间 `expire` ，这样可以避免 Redis 已经挂掉的情况下，客户端不用一直等待响应结果，而是尽快地去尝试另外一个 Redis 实例来获取锁。
  2. 客户端通过使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从过半数（N/2+1 个）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` **<** 锁失效时间 `expire` 时，锁才算获取成功，如果获取到了锁，那么 key 的真正有效时间 `real_expire` 等于锁失效时间 `expire` **减去**锁花费的总时间 `T`。
  3. 如果获取锁失败，客户端则应该在所有的 Redis 实例上使用 **Lua 脚本进行解锁**，原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端到服务器的通信是正常的，但反方向却是有问题的，虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功，因此，释放锁时，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起解锁请求。

  - **缺点**：
    1. **性能过重**：使用 RedLock 需要维护那么多的 Redis 实例，提升了系统的维护成本。
    2. **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生回调，则会导致它持有的锁提前过期释放，还是不能保证锁的安全性，这个是基于时间来实现自动释放的分布式锁，都无法解决的问题。

###### 3）基于分布式一致性算法实现 | 强一致

基于 ZK 实现：可以利用**顺序临时节点**的特性，结点在创建时，会自动在结点名后加一个数字后缀，以保证有序，同时，如果客户端连接失效，则还会立即删除结点，再利用 **watcher 监视器**的特性，注册某个结点的监视器，当节点状态发生改变时，watcher 被触发时，ZK 会向客户端发送一条通知。其分布式锁的实现原理是，

1. 创建一个锁目录 lock，希望获得锁的线程 A 在 lock 目录下，将创建**顺序临时结点**。
2. A 先获取锁目录下所有的子结点，判断是否存在序号比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则线程 A 获得锁。
3. 当另外一个线程 B 获取锁时，判断到 B 自己不是最小的结点，存在有更小的线程 A 结点，则设置  watcher 监听器，只监听比自己**次小**的结点 A。
4. 当线程 A 处理完业务后，会删除结点 A，释放掉分布式锁，然后线程 B 监听到节点状态变更事件后，判断自己已经是最小的结点了，则成功获得锁。

##### 3、总

以上就是我对分布式锁一些实现方案的理解，总结一下就是，

- **基于数据库实现**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：但这样会增加数据库的负担。
- **基于分布式缓存实现**：
  - **优点**：属于 AP 模型，性能高，实现起来较为方便，在允许偶发性的锁失效情况发生，不影响系统正常使用时，可以采用分布式缓存来实现锁。
  - **缺点**：通过过期时间实现的锁超时机制不是十分可靠，当业务必须要数据的**强一致性**，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下，就不能使用分布式缓存来实现锁了，此时可以使用 CP 模型来实现，比如 Zookeeper。
- **基于分布式一致性算法实现**：
  - **优点**：不依靠过期时间来释放锁，可靠性高，当系统要求高可靠性时，可以采用分布式一致性算法来实现锁。
  - **缺点**：性能比不上分布式缓存实现的锁，因为 ZK 需要频繁的创建和删除结点。

#### 1.7. Redis持久化？

《见 p6+Redis篇 - Redis持久化？》。

#### 1.8. Redis 哨兵模式和集群模式的区别？

##### 1、总

Redis 支持三种集群架构，分别是主从模式、哨兵模式、集群模式。

##### 2、分

###### 1）主从模式 | 无高可用、简单

讲哨兵模式之前，就需要先介绍一下主从模式~

![1632299571516](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632299571516.png)

1. **是什么**：

   - 1）只是简单地使用了主从复制，一个 Master 可以有多个 Slave，Slave 也可以有自己的 Slave。
   - 2）默认使用异步复制， Slave 会以每秒 1 次的频率，向 Master 报告当前复制流的处理进度。
   - 3）复制时，不会阻塞 Master，即使是正在进行初次同步， Master 也可以继续处理命令请求，也不会阻塞 Slave，即使 Slave 正在进行初次同步， 也可以使用旧版本的数据集来处理命令查询。
   - 4）同时，还支持读写分离模式，Master 负责读写，Slave 只负责读。

2. **怎么配置**：

   ```shell
   # Slave方参数
   # 1、配置主从复制Master的IP+端口
   slaveof <masterip> <masterport>
   # 2、如果Master通过requirepass配置密码，则Slave也需要进行相应的配置
   masterauth <master-password>
   # 3、默认允许，Slave初次同步未完成时，继续使用旧数据来响应客户端，配置no会阻塞初次同步期间的所有请求
   slave-serve-stale-data yes
   # 4、默认开启读写分离，Slave只能读取数据，不能写入数据
   slave-read-only yes
   
   # Master方参数
   # 5、默认关闭无磁盘化复制，Master磁盘不生成RDB文件，直接通过网络同步给Slave
   repl-diskless-sync no
   # 6、默认为3和10，如果至少有3个从服务器，并且这3服务器的延迟值都少于10秒，Master才会执行客户端请求的写操作
   # min-slaves-to-write 3
   # min-slaves-max-lag 10
   ```

3. **实现原理**：

   - 1）当建立一个 Slave 时， Slave 会向 Master 发送一个 `PSYNC master_run_id offset` 命令。
   - 2）如果 Slave 是首次连接，由于 Master 中不存在该 Slave 的复制偏移量，所以会触发一次完整重同步操作， 此时，Master 开始执行 `BGSAVE`， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。
   - 3）当 Master  `BGSAVE` 执行完毕后， Master 将执行保存操作所得的 .rdb 文件发送给 Slave， Slave 接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
   - 4）之后，Master 会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给 Slave，Slave 则实时同步这些数据。
   - 5）如果主从复制期间 Slave 断开连接，在自动重连后，会使用 `PSYNC master_run_id offset` 命令来进行同步，Master 会以增量复制的形式，向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。

   重连后的**部分重同步原理**：

   - 1）Master 会为被发送的复制流创建一个缓冲区 `in-memory backlog`， 并且 Master 和所有 Slave 之间都记录一个复制偏移量 `replication offset` 和一个主服务器 ID `master run id`。
   - 2）当出现网络连接断开时， Slave 重新连接后，会向 Master 请求继续执行原来的复制进程。
   - 3）如果 Slave 记录的主服务器 ID `master run id` ，和当前要连接的主服务器 ID `master run id` 相同， 并且 Slave 记录的偏移量 `replication offset` 所指定的数据，仍然保存在 Master 的复制流缓冲区 `in-memory backlog` 里面， 那么 Master 会向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
   - 4）否则，Slave 就要执行完整重同步操作。

4. **优点**：

   - 1）**部署简单**：仅使用两个节点，即可构成主从模式。
   - 2）**可以通过读写分离**：来避免读和写同时不可用的情况。

5. **缺点**：

   - 1）**无高可用保证**：一旦 Master 节点出现故障，主从节点就无法自动切换，直接导致 SLA 服务等级下降。
     - **解决方案**：添加哨兵监控。
   - 2）**Master 压力大**：所有的 Slave 节点数据的复制和同步，都由 Master 节点来处理，会造成 Master 节点压力过大。
     - **解决方案**：可以使用主从从的结构，通过引入从从同步，可以减少主从同步的次数。

6. **适用场景**：一般用于业务发展初期、并发量低、运维成本低的情况。

###### 2）哨兵模式 | 高可用、读多

![1632320226337](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632320226337.png)

1. **是什么**：Sentinel，哨兵，是 Redis 高可用的一种解决方案，可以监视一个或者多个 Redis Master 服务，以及其所有的从服务，当某个 Master 服务宕机后，会自动把这个 Master 下的某个从服务升级为 Master，从而代替已宕机的 Master，保证继续工作。

   Sentinel 的作用有：

   - 1）**监控**：Monitoring，Sentinel 会不断地检查 Master 和 Slave 是否运作正常。
   - 2）**提醒**：Notification，当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
   - 3）**自动故障迁移**：Automatic failover。当一个 Master 不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效 Master 的其中一个 Slave 升级为新的 Master， 并且让失效 Master 的其他 Slave 改为复制新的 Master。当客户端试图连接失效的 Master 时， 集群也会向客户端返回新 Master 的地址， 使得集群可以使用新 Master 代替失效 Master。

2. **怎么配置**：

   ```shell
   # 1、配置监控 127.0.0.1：6379 的 mymaster 服务器，并且客观下线需要取得2个(quorum)哨兵的同意，但是无论该值配置了多少，都需要多数哨兵的选举后，才能发起一次自动故障转移
   sentinel monitor mymaster 127.0.0.1 6379 2
   # 2、配置Master服务器密码（如果Master有配置的话）
   sentinel auth-pass <master-name> <password>
   # 3、配置判定mymaster主观下线的毫秒数
   sentinel down-after-milliseconds mymaster 60000
   # 4、配置主从切换的超时时间，需要自动故障转移时，如果当前哨兵没有去执行，那么在超过这个时间后，会由其他的哨兵来进行处理
   sentinel failover-timeout mymaster 180000
   # 5、配置在执行故障转移时，同步新mymaster的最大Slave并行数，如果全部Slave一起对新Master进行同步，由于在Slave载入RDB时会阻塞客户端请求，所以可能会造成所有Slave在短时间内全部不可用的情况出现
   sentinel parallel-syncs mymaster 1
   
   # 启动命令
   # 6、运行纯Sentinel服务器
   redis-sentinel /path/to/sentinel.conf
   # 7、在Redis Server上运行哨兵
   redis-server /path/to/sentinel.conf --sentinel
   
   # 运维命令
   # 8、查看imooc-master下的master节点信息
   sentinel master imooc-master
   # 9、查看imooc-master下的slaves节点信息
   sentinel slaves imooc-master
   # 10、查看imooc-master下的哨兵节点信息
   sentinel sentinels imooc-master
   ```

3. **Sentinel 自动发现原理**：

   - 1）一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换，通过发布与订阅功能，向频道 `__sentinel__:hello` 发送信息，来自动发现正在监视相同 Master 的其他 Sentinel ，无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址。
   - 2）**发布**：每个 Sentinel 会以 2 次 / s 的频率， 通过发布与订阅功能， 向被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道发送一条信息， 信息中包含了 Sentinel 的 IP、端口和运行 ID `runid`，还包括完整的 Master 当前配置。如果一个 Sentinel 包含的 Master 配置，比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。
   - 3）**订阅**：每个 Sentinel 都订阅了被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道， 查找之前未出现过的 Sentinel，当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了已知的、正在监视同一个 Master 的所有其他 Sentinel 。

4. **故障判定原理**：

   - 1）Sentinel 会以 1 次 / s的频率，向它所知的 Master、Slave、以及其他 Sentinel 实例，发送一个 `PING` 命令。
   - 2）如果某个实例距离最后一次有效回复 `PING` 命令的时间，超过了 `down-after-milliseconds` 的值， 那么这个实例会被 Sentinel 标记为**主观下线**。 
   - 3）如果一个 Master 被标记为主观下线， 那么正在监视这个 Master 的所有 Sentinel，都要以 1 次 / s 的频率，确认 Master 是否真的进入了主观下线状态。
   - 4）当 Master 重新向 Sentinel 的 `PING` 命令，返回有效回复时，Master 的主观下线状态就会被移除。
   - 5）否则，如果有足够数量（>= `quorum` ）的 Sentinel，在指定的时间范围内，同意这一判断， 那么这个主服务器被标记为**客观下线**。
   - 6）而当没有足够数量（>= `quorum` ）的 Sentinel 同意主服务器已经下线， Master 的客观下线状态就会被移除。

   **主观下线**：

   - 1）主观下线，Subjectively Down， 简称 SDOWN，指的是单个 Sentinel 实例，对超时服务实例做出的判断。
   - 2）只有一个 Sentinel 认为是主观下线时，并不一定会引起服务实例的故障迁移，只有在足够数量（>= `quorum` ）的 Sentinel 都将一个服务实例标记为主观下线之后， 服务器才会被标记为**客观下线**， 此时自动故障迁移才会执行。

   **客观下线**：

   - 1）客观下线，Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对同一个服务实例做出 SDOWN 判断， 并且在通过  `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务实例下线判断。
   - 2）客观下线条件只适用于 Master，对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以  Slave 或者其他 Sentinel 永远不会达到客观下线的条件。
   - 3）只要 Sentinel 发现某个 Master 进入了客观下线状态，某个 Sentinel 会被其他 Sentinel 推选出， 并对失效的 Master 执行**自动故障迁移**操作。

5. **自动故障转移原理**：

   - 1）**Leader Sentinel 选举**：当一个 Master 被判定为**客观下线**后，监视这个 Master 的所有Sentinel会通过 `Raft` 选举算法，选出一个 Leader Sentinel 去执行故障转移 `failover` 操作。
   - 2）**Master 重新选择**：当选举出 Leader Sentinel 后，Leader Sentinel 会根据以下规则，在失效 Master 属下的 Slave 当中，选择出新的 Master：
     1. 先淘汰主观下线 | 已断线 | 最后一次回复 `PING` 命令时间大于5秒钟 | 与失效 Master 断开连接时长超过 10 倍主观判断时长 `down-after-milliseconds` 的 Slave 节点。
     2. 选择配置 `slave-priority` 最高的 Slave 节点，如果没有，则继续选择。
     3. 选择复制偏移量 `replication offset` 最大的 Slave 节点，复制偏移量越大，说明数据复制的越完整。
     4. 如果复制偏移量不可用，或者 Slave 的复制偏移量相同， 则选择运行 ID `run_id` 最小的 Slave 节点，`run_id` 越小，说明重启次数越少。
   - 3）**故障转移流程**：
     1. Leader Sentinel  则根据 Master 选择规则，选出一个 Slave，向其发送 `SLAVEOF NO ONE` 命令，让它转变为 Master。
     2. 然后， Leader Sentinel 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel，让其他 Sentinel 对它们自己的配置进行更新。
     3. 接着， Leader Sentinel 会向已下线 Master 的其他 Slave，发送 `SLAVEOF host port` 命令， 让它们去复制新的 Master。
     4. 最后，当所有 Slave 都已经开始复制新的 Master 时， Leader Sentinel 则结束这次故障迁移操作。

6. **优点**：监控、提醒、自动故障转移，从而实现 Redis 的高可用。

7. **缺点**：如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

8. **适用场景**：适合读远多于写的业务场景，比如在秒杀系统中，用来缓存活动信息。

###### 3）集群模式 | 高可用、写多

![1632464692288](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632464692288.png)

1. **是什么**：

   - 1）Redis Cluster，是 Redis 3.0 版本之后推出的高可用实现。
   - 2）采用哈希虚拟槽的数据分区方案，把 key 分布到各个 Master 节点上，每个 Master 还可以跟若干个 Slave 做主从切换。
   - 3）由于做了数据分区，使用的功能，也就只是普通单机 Redis 所有功能的一个子集，比如不支持同时使用多个键的 Redis 命令、不支持多数据库只能适用 0 号数据库。
   - 4）路由方面，客户端可以连接任意 Master 节点，集群内部会按照不同的 key，告诉客户端，把请求转发到其他 Master 节点，同时让请求成功的客户端，还会缓存对应的映射关系，以提高下次集群访问的查询效率。

2. **怎么配置**：

   ```shell
   # 1、开启集群模式
   cluster-enabled yes
   # 2、每一个节点都需要有这么一个配置文件，3主3从则一共需要6份，用于存储集群模式下的集群状态等信息，由Redis自己维护，而这些信息会相互告知其他所有节点。如果要重新创建集群，只需要把这个文件删除掉就行。
   cluster-config-file nodes-201.conf
   # 3、节点超时时限，如果发生超时则会被认定为PFAIL，如果超过半数其他Master认定为PFAIL，则会被集群认定为FIAL，然后会进行主从切换
   cluster-node-timeout 5000
   # 4、开启AOF
   appendonly yes
   
   # 5、Redis3.x旧版集群构建方式，需要使用redis-trib.rb来构建集群，最新版使用C语言来构建了，这个要注意
   # ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
   
   # 新版Redis集群构建方式
   # 6、创建集群，主节点和从节点比例为1，1-3为主，4-6为从，1和4，2和5，3和6分别对应为主从关系，这也是最经典用的最多的集群模式
   redis-cli --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1
   # 7、集群客户端
   redis-cli -c -p 7000
   # 8、检查集群信息
   redis-cli --cluster check 127.0.0.1:6379
   ```

3. **分区实现原理**：Redis 集群的键空间被分割为 `16384` 个槽（slot）， 集群的最大节点数量也是 `16384` 个，但推荐的最大节点数量为 1000 个左右，每个主节点都负责处理 `16384` 个哈希槽的其中一部分，其键的映射算法为 `HASH_SLOT = CRC16(key) mod 16384`。

   为什么哈希槽数为 16384 个？

   `CRC16` 算法产生的 hash 值有 16 bit，即可产生 2 ^ 16 = 65536 个值，换句话说，值是分布在 0 ~ 65535 之间，那 Redis 在做 `mod` 运算的时候，为什么不 `mod` 65536，而是选择 `mod` 16384 呢？

   - 1）槽位数不宜过大：如果槽位为 65536，那么节点发送 `PING/PONG` 心跳包消息头所占用的空间会达到 8k （65536 / 8），过于庞大，传输时浪费带宽，而如果使用 16384 个槽位，心跳包消息头所占用的空间仅为 2k（16384 / 8），则大小还能接受。
   - 2）槽位数不宜过小：Redis Master 的哈希槽配置，是通过一张 bitmap 的形式来保存的，其填充率为 slots / N，N为节点数目，在 N 固定的情况下，如果槽位数越小，bitmap 填充率就越小，导致 bitmap 在传输过程中的压缩率就越高，就越消耗 CPU 资源。
   - 3）因此，16384 个插槽，是综合了心跳包大小、网络带宽、压缩率等方面考虑的结果，同时还能满足各种业务需求。

4. **路由转向原理**：

   - 1）一个 Redis 客户端可以向集群中的任意节点（包括从节点）发送 `GET key` 命令请求。

   - 2）集群节点会对命令请求进行分析， 如果该命令是集群可以执行的命令， 那么节点会查找这个命令所要处理的键所在的哈希槽。

   - 3）如果要查找的哈希槽正好就处于当前节点中，则接收到的命令由当前节点负责处理。

   - 4）如果所查找的哈希槽不处于当前节点中，则当前节点会先查看自身内部所保存的，哈希槽到节点 ID 的映射记录，然后向客户端回复一个 `-MOVED` 转向错误。

     ```shell
     GET x
     # GET命令收到一个 -MOVED 转向错误
     # x真正所在的目标哈希槽，目标节点IP，目标节点端口号
     -MOVED 3999 127.0.0.1:6381
     ```

   - 5）客户端收到 `-MOVED` 转向错误后，根据目标节点 IP 与端口号，会再向目标节点重新发送一次 `GET key`命令请求。

   - 6）如果客户端在重新发送 `GET key` 命令时，集群刚好又更改了 key 的 slot 配置， 此时客户端请求目标哈希槽，会再次收到 `-MOVED` 转向错误， 需要再次向新的目标节点重新发送一次 `GET key`命令请求。

   - 7）客户端会循环以上操作，直到该命令请求成功，然后记录下该成功请求的哈希槽的目标节点信息，在下次执行相同 key 命令时，加快正确节点的寻找速度。

5. **高可用原理**：

   - 1）**节点失效检测**：当一个节点 `PING` 不通另一个节点时，则会把它标记为 `PFAIL`；当一个节点要把另一个节点从 `PFAIL` 标记为 `FAIL` 时， 则必须得到大部分 Master 的同意才行。
   - 2）**从节点选举**：一旦某个 Master 进入 `FAIL` 状态， 如果这个 Master 有一个或多个 Slave 存在， 那么其中一个 Slave 会被升级为新的 Master， 而其他 Slave 则会开始对这个新的 Master 进行复制。

6. **优点**：

   - 1）高可用：当集群中的一部分节点失效或者无法进行通讯时， 集群仍然可以通过主从切换，继续处理命令请求。
   - 2）高性能：操作某个 key 时，Redis 不会先找到节点再处理，而是直接让客户端重定向，到目标 Redis 实例进行请求，这相较代理分片少了 proxy 的连接损耗。
   - 3）高拓展：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

7. **缺点**：

   - 只能使用普通单机 Redis 所有功能的一个子集：不支持同时使用多个键的 Redis 命令，不支持多数据库功能， 只能使用默认的 0 号数据库。
   - 占用带宽：虽然避免了 Master 单节点的问题，但集群内的数据同步、节点通信会占用一定的带宽。
   - 数据弱一致性：与其他高可用方案一样，Redis 集群属于 AP 模型，不保证数据的强一致性，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。

8. **适用场景**：在写操作比较多的情况下，集群模式才更有优势，相对于其他大多数情况，使用哨兵模式就能满足需求了。

##### 3、总

Redis AKF 拆分：

![1632542544732](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542544732.png)

###### 1）X 轴扩展 | 主从复制

- **特点**：
  1. 按照主从设计，Master 负责读写， Slave 负责读。
  2. 再结合哨兵集群，在 Master 故障时，使用 Slave 进行切换，从而实现高可用。
- **优点**：
  1. 主从，解决了读并发压力大的问题。
  2. 哨兵，解决了单点故障问题。
- **缺点**：单机容量会有限制，并且会出现写并发压力大的问题。

###### 2）Y 轴扩展 | 业务拆分

- **特点**：
  1. 把 Redis 所有键，按照业务进行拆分，拆分到不同的 Redis 实例上。
  2. 可以在 Y 轴的基础上，再进行 X 轴的主从复制的扩展，形成不同业务的 Redis 集群。
- **优点**：从分离不同业务数据的角度，暂时解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：当某个业务的集群达到一定规模后，如果数据量过大，仍然会出现单机容量受限，以及写并发压力大的问题。

###### 3）Z 轴扩展 | 数据分区

- **特点**：
  1. 将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。
  2. 可以在 Z 轴的基础上，叠加 X 轴的主从复制，集群内进行数据分片，比如 Redis Cluster。
  3. 可以再叠加 Y 轴的业务拆分，把整个 Redis 系统划分成多个不同业务的、数据分片过的 Redis Cluster。
- **优点**：增加了整个集群的算力、带宽和内存，从根本上解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：
  1. 数据分区后，不支持跨实例的命令与事务。
  2. 备份管理要复杂得多。
  3. 扩缩容时可能需要对数据再平衡。

综上，Redis 哨兵模式与 Redis Cluster 的主要区别为：

1. 原理上，Redis 哨兵模式是通过主从复制 + 故障时 Sentinel 做主从切换实现的，而 Redis Cluster 则是通过哈希虚拟槽分区 + 重定向客户端请求 + 主从复制 + 故障时 从节点选举 做主从切换实现的。
2. 使用上，由于 Redis Cluster 对数据做了分区，所以只能使用普通单机 Redis 所有功能的一个子集，比如不能使用多键命令，只能使用 0 号数据库，而 Redis 哨兵模式本质上是主从模式，依然可以使用所有命令。

=> 以上，就是我对 Redis 高可用架构 的一些理解，请问有什么细节需要补充的吗？

#### 1.9. 数据库、缓存双写一致性？

##### 1、总

1. 首先，从理论上来讲，给缓存设置**过期时间**，所有写操作以数据库的为准，对缓存操作只尽最大努力更新的话，如果数据库写成功，缓存更新失败，只要缓存到达了过期时间，那么后面的读请求自然会从数据库中，读取到新值，然后回填到缓存，是可以实现**最终一致性**的。
2. 而如果要给出不依赖过期时间方案的话，可以从更新/删除缓存的角度去思考，它们的大前提是，先读缓存，如果缓存没有，才从数据库读取：
   1. 先更新缓存，再更新数据库。（不可取，数据丢失）
   2. 先更新数据库，再更新缓存。（不可取，后者脏数据覆盖）
   3. 先删除缓存，再更新数据库。（不可取，延迟双删、异步双删依然不能保证一致性）
   4. 先更新数据库，再删除缓存。（可取，Cannal + MQ 实现业务解耦、以及最终一致性）

##### 2、分

###### 1）先更新缓存，再更新数据库 | 数据丢失

1. 这个方案会出现，同一个缓存被频繁写入，但还没来得及更新到数据库，造成数据丢失的问题。
2. 故，放弃。

###### 2）先更新数据库，再更新缓存 | 后者脏数据覆盖

1. 这个方案，也是有问题的，如果有请求 A 和请求 B 并发进行更新操作，那么就会出现：
   - （1）线程 A 更新了数据库。
   - （2）线程 B 更新了数据库。
   - （3）线程 B 更新了缓存。
   - （4）线程 A 更新了缓存。
2. 理论上，请求 A 更新缓存，应该比请求 B 更新缓存早才对，但是由于网络等原因，B 却比 A 更早更新了缓存，导致 A 最后才把脏数据刷到缓存中，造成数据不一致。
3. 故，放弃。

显然，删除缓存才是更好的选择。

###### 3）先删除缓存，再更新数据库 | 延迟双删、异步双删依然不能保证一致性

1. 这个方案，也还是有问题的，如果在请求 A 更新时，请求 B 并发查，会出现：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询，发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值填入缓存。
   - （4）请求 A 将新值写入数据库。
2. 上述情况就会导致不一致的情形出现，如果不给缓存设置过期时间，则该数据永远都是脏数据。
3. 此时，解决方案可以采用**延时双删**策略：
   - （1）先淘汰缓存。
   - （2）再写数据库（这两步和原来一样） 。
   - （3）关键来了，再**休眠** n 秒，然后淘汰缓存，这么做，可以把 n 秒内，所产生的缓存脏数据，再次删除掉。
4. 但是，这个 n 秒怎么确定，可以在写数据后，休眠的时间在读数据业务逻辑的耗时基础上，加几百 ms 即可，这么做的目的，就是确保读请求结束后，写请求可以删除读请求造成的缓存脏数据。
5. 然而，如果 MySQL 读写分离架构下，还是会出现不一致的情况：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 A 将数据写入数据库了。
   - （3）请求 B 查询缓存，发现缓存没有值，然后去从库查询，但是此时，还没有完成主从同步，因此，查询到的还是旧值。
   - （4）请求 B 将旧值写入缓存。
   - （5）数据库完成主从同步，从库变为新值 。
6. 上述情况也产生了数据不一致的现象，解决方法还是使用**延时双删**策略，只不过，休眠时间 n，需要在主从同步的延时时间基础上，加几百 ms，而不是读耗时加几百 ms。
7. 但是，采用这种同步淘汰策略，由于设计到阻塞休眠 n s，接口吞吐量将会降低很多，此时可以把第二次休眠后删除的步骤，改为**异步**的操作，即起一个线程做异步删除。这样，写请求就不用沉睡一段时间后才返回响应。
8. 如果采用**异步双删**，虽然保证了吞吐量，但第二次可能会**删除失败**，比如：
   - 为了方便，假设是单库。
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值写入缓存。
   - （4）请求 A 将新值写入数据库。
   - （5）请求 A 试图去删除，但由于某种原因失败了，导致缓存中一直存在 B 放入的旧值。
9. 这种情况下，如果第二次删除缓存失败，还是会出现后面缓存和数据库不一致的现象。
10. 所以，更新数据库前的缓存删除，起不到任何作用，一致性是由第二次缓存删除来保证的。
11. 故，放弃更新前缓存删除方案。

###### 4）先更新数据库，再删除缓存

1. 这种情况，也还是会存在并发问题：
   - （1）缓存刚好失效。
   - （2）请求 A 查询数据库，得一个旧值。
   - （3）请求 B 将新值写入数据库。
   - （4）请求 B 删除缓存。
   - （5）请求 A 将查到的旧值写入缓存。 
2. 上述情况，确实还是有脏数据，解决方案有：
   1. **过期时间**：给缓存设有效时间是一种方案。
   2. **异步删除**：采用上面的异步删除策略，保证读请求完成以后，再进行删除操作也可以，但同样，也存在缓存删除失败导致数据不一致的情况，此时可以提供一个**重试删除**机制即可解决。

##### 3、总

1. 因此，要保证数据库、缓存双写一致性的关键在于，**先更新数据库 + 再删除缓存 + 异步重试删除**，实现方案如下：

2. **方案一**：

   - （1）更新数据库后，再删除缓存。
   - （2）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （3）然后消费消息，获取到要删除的 key。
   - （5）接着根据 key 继续重试删除操作，直到成功。

   **缺点**：对业务线代码，造成了大量的侵入。

   ![1647257594150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257594150.png)

3. **方案二**： 启动一个订阅程序，去订阅数据库的 **binlog**，获得需要操作的数据，然后另起一个程序，获得这个订阅程序传来的数据，进行删除缓存操作。

   - （1）更新数据库数据。
   - （2）数据库则会把更新操作的信息，写入 binlog 日志当中。
   - （3）binlog 日志被订阅程序订阅到，则提取出所需要的数据以及 key。
     - 这个订阅 binlog 程序，在 MySQL 有现成的中间件（阿里# Canal），至于 Oracle 目前好像还没有现成的中间件。
   - （4）调用另一段非业务代码，获得 key。
   - （5）根据这个 key，尝试执行缓存删除操作。
   - （6）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （7）然后消费消息，获取到要删除的 key。
   - （8）接着根据 key 继续重试删除操作，直到成功。

   ![1647257612877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257612877.png)

=> 以上，就是我对数据库、缓存双写一致性的一些实现方案的理解，请问有什么细节需要补充的吗？

### 14> 消息队列

#### 1.1. Kafka 的高可靠保证？

##### 1、总

对于 Kafka 高可靠，需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 + `acks=all`（或者 `acks=-1`）  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 `acks=all` 保证消息成功写入所有 ISR，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 ISR 机制来保证，配合生产端 `acks=all` 来保证每次写入消息，必须在 ISR 集合中的所有 Broker 写入成功后才认为消息写入成功，响应 ACK 给生产端。
3. **消费端**：通过 `enable-auto-commit=false` 关闭自动 ACK，`ack-mode=manual` 打开手工 ACK，在处理消息完毕后，才进行一次手工 ACK `acknowledgement.acknowledge()`，避免处理异常后，不能再次重复消费的情况。

##### 3、总

以上，就是我对 Kafka 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.2. RabbitMQ 的高可靠保证？

##### 1、总

与 Kafka 高可靠类似，对于 RabbitMQ 高可靠，也需要从 3 个角度进行考虑，分别是生产端、Broker 端以及消费端的高可靠保证。

##### 2、分

1. **生产者端**：通过 @Transactional 事务管理 + 本地消息表打标 +  `publisher-confirms=true` 以及实现 ConfirmCallback 函数开启 Broker 消息 Confirm 机制  + 定时重发 + 失败补偿来保证，即保证本地消息表和业务表属于同一个事务，业务落库时消息也落库，使用 Broker Confirm 机制，保证消息成功写入 Broker，使用定时重发 + 失败补偿，可以保证消息最终会写入 Broker。
2. **Broker 端**：通过 `druable=true` 开启持久化队列 + 生产端消息设置 `deliveryMode=2` 开启持久化消息 ，来保证消息写入后，如果未被消费前，会保存在 Broker 中，防止 MQ 丢消息。
3. **消费端**：通过 `acknowledge-mode=mannul` 关闭自动 ACK，打开手工 ACK，在处理消息完毕后，才 `channel.basicAck` 进行一次手工 ACK，避免处理异常后，RabbitMQ 把消息删除了，导致消息的丢失。

##### 3、总

以上，就是我对 RabbitMQ 高可靠保证的一个理解，请问有什么细节需要补充的吗？

#### 1.3. RocketMQ、Kafka 底层文件原理？

##### 1、总

RocketMQ 消息存储是由 Comsume Queue + Commit Log 配合完成的，Kafka 消息存储是由多 Partition 进行存储的。

##### 2、分

###### RocketMQ

1. 在 RocketMQ 中，所有 Topic 消息都存储在一个称为 Commit Log 的文件中，默认最大为 1GB，超过 1GB 后消息后，就会写到下一个 Commit Log 文件。

2. 通过 CommitLog，RocketMQ 把所有消息存储在一起，以顺序 I/O 的方式写入磁盘，充分利用了磁盘顺序写，减少了 I/O 争用，提高了数据存储的性能。

3. 每个 Consumer 在第一次连接时，都会创建  Consume Queue，一个 Consume Queue 表示 topic#queue，不存储具体的消息，只存储路由到在 CommitLog 中的消息  offset，即具体的消息由 CommitLog 存储。

4. Consumer 在读取消息时，会先读取 Consume Queue，再通过 Consume Queue 中的 offset，读取
   CommitLog，从而得到原始的消息。

   ![1635678882127](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678882127.png)

###### Kafka

1. 在 Kafka 日志文件存储中，同一个 Topic 下会有多个不同的 Partition，每个 Partiton 为一个目录，Partition 是实际物理上的概念，而 Topic 则是逻辑上的概念。
2. 同时，一个 Partition 物理上又被分为多个 Log Segment 组成，Segment 不是一个目录，而是由 3 部分组成，分别为 `.index` 文件、`.timeindex` 文件 和 `.log` 文件，分别表示偏移量索引文件、时间戳索引文件和日志数据文件。
3. 然后，通过二分查找来解决查找效率问题，每个 Partition 被平均分配到多个 Segment 文件，也方便 Old Segment 已消费消息的清理，提高磁盘的利用率。

![1634213772578](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213772578.png)

**如何查找偏移量为 118 的消息**？根据时间戳查找的方式同理。

1. 首先，Kafka 会用一个 `ConcurrentSkipListMap` 跳跃表，来记录每个日志分段，通过它可以根据偏移量 `118` 定位到 Segment 在 00000000000000000000.index 中。
2. 然后，通过**二分查找**在该 `.index` 文件中，找到**不大于 `offset:118`  的最大索引项**，即 `offset:116` 那栏，得到 `position:9679`。
3. 接着，从 `.log` 文件中，物理位置为 `position:9679` 的位置，开始顺序查找 `offset:118` 的消息。

##### 3、总

因此，RocketMQ 与 Kafka 消息存储上的对比总结为：

|          | RocketMQ                                                     | Kafka                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 消息存储 | 将所有消息存储在同一个 CommitLog 中，且 Consume Queue 中只存储20个字节每个消息的位置信息 | 将每个 Partition的消息分开存储                               |
| 影响     | 单个 Broker 能支持更多的 Topic 和 Consume Queue，单机支持最高5w个队列，并且 Load 不会发生明显变化 | 单机超过 64 个 Partition，Load 会发生明显的飙高，发送消息的响应时间变长，但对于少 Partition 场景， 由于利用了 Partition 并行处理，使得此时的写性能高于 RocketMQ |
| 原因     | 所有消息都存储在同一个文件中，使得消息存储是磁盘顺序写       | 将消息按 Partition 存储在不同的文件中，使得整体消息存储是随机写，当 Partition 数量非常大时，会出现很多随机 I/O，导致所有 Broker 性能明显下降 |

=> 以上，就是我对 RocketMQ 和 Kafka 底层文件存储原理 的一个理解，请问有什么细节需要补充的吗？

### 15> 云原生

#### 1.1. Docker 和 K8S 有了解过吗？

##### 1、总

1. Docker，由 Go 语言开发，思想如 logo 一样，即集装箱 Container 容器思想，负责容器的运行和管理，通过隔离机制，使得每个容器间互不影响，以及通过限制每个容器的 CPU、内存和 I/O 资源，最大程度地压榨服务器资源源。
2. K8S，指 Kubernetes，是 Google#Omega 的开源版本，是目前市场占有率最高的容器编排产品，可以自动化部署、管理、扩展容器以及容器网络通信处理，为应用提供了理想的部署单元，和独立的执行环境，使得微服务部署更加简单，同时还支持集成到 CI/CD 工作流，提效 DevOps 团队工作。

##### 2、分

###### Docker 架构原理

![1647495796223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495796223.png)

1. Client：Docker 的客户端模块，用于运行 Docker 命令以及 Restful API。
2. Docker host：Docker 的服务器模块，存在一个 Docker Daemon 后台进程，负责整个 Docker 容器的生命周期管理，连接 Registry 下载镜像，以及提供 Client 的 API 端口来处理发送过来的命令。
3. Registry：Docker 的镜像仓库，分为 Docker Hub 官方公有的镜像仓库、Docker Datacenter 企业信任仓库、以及 Docker 内网私有仓库。
4. Images：Docker 镜像，可本地制作，也可来源于镜像仓库，是容器运行前代码、配置、环境变量、操作系统资源的打包，运行起来了之后叫做容器，类似于 VM 的配置模板，通过 UnionFS 联合文件系统，支持镜像的一层层叠加。
5. Containers：Docker 容器，每个容器共享主机的操作系统，通过 namespace 对 pid 进程、net 网络、ipc 信号量、mnt 文件系统、uts 用户组等进行**隔离**，通过 cgroup 对每个容器的 cpu、mem、io 等资源进行**限制**。

###### K8S 架构原理

![1647516641430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647516641430.png)

1. **Kubernetes Cluster**：K8S 集群，是计算、存储和网络资源的集合，是掌握所有计算、存储、网络资源，进行统计管理、调度的节点群。
2. **Namespace**：虚拟 K8S 集群，解决在同一个 Cluster 集群中，如何区分开 Controller 和 Pod 的问题，默认两个虚拟集群，`kube-system` 用于自身管理的集群，`kube-default` 用于应用部署的默认集群（不指定集群名称时）。

k8s 集群，分为一个 Master 节点和多个 Node 节点，

1. **Kubernets Maseter**：K8S 大脑节点，决定将应用放在哪里运行，它相比图中，该节点还隐藏了许多容器，比如：
   - **1）API Server**：API 服务端，通过控制台、网络，接收传过来的命令，判断是否符合语法标准，并根据实际环境进行处理。
   - **2）Scheduler**：调度执行器，对所有资源按照应用资源，执行统一调度，以及任务发布，负责决定将 Pod 放到哪⼀个 Node 上运⾏。
   - **3）Controller Manager**：控制器管理器，负责 Cluster 各种资源的统筹管理。
   - **4）ETCD**：类似于 ZK，对 K8S 集群的配置进行统一管理，保存了 K8S 的相关配置和状态信息，如果 POD 有发⽣变化，那么它会迅速通知相关的组件进⾏处理。
2. **Kubernets Node**：K8S 手脚节点，负责运行容器应用。
   - **1）Kubelet**：核心工作单元，是 K8S 里唯一一个没有以容器形式运行的组件，负责根据 Scheduler 发过来的信息，去创建和运⾏容器，并向 Master 报告运行状态，直接跟 Docker 容器进行沟通。 
   - **2）Docker daemon**：Docker 后台容器。
   - **3）Kube-proxy**：网络通讯、服务发现负载模块，是网络代理的概念，当 service 接收到请求后，转发到某个 node 时，会由该 node 的 kube-proxy 模块负责接收，然后转发到后端的容器中，如果有多个副本，还能提供负载均衡的能⼒。
   - **4）Pod**：是 K8S 的最小工作单元（所以，K8S 最小工作单元不是容器！），是运行在 Node 手脚节点上的一堆容器集合，相当于是比容器更大的"集装箱"，将网络共享、存储共享的一堆 Docker 容器，封装成一个 Pod，作为一个小单元进行管理，从而扩大管理粒度，降低管理复杂度，实现统一部署、以及网络和存储共享。
   - **5）Controller**：负责对 Pod 进行统一管理。
     1. **Deployment**：一个应用资源，基于 ReplicaSet，会产生一个部署请求，形成一堆 Pod。
     2. **ReplicaSet**：一个会在多个点节点部署多个的 Pod，以完成更多的功能。
     3. **DaemonSet**：一个在同一节点只会运行一份的 Pod。
     4. **StatefulSet**：一个有状态的服务，对外提供的 Pod 名称永远不变。
     5. **Job**：一个短时、定时作业的 Pod。
   - **6）Service**：
     1. 为 Pod 提供了负载均衡：在当 Pod 之间需要相互访问时，会去 DNS Server 找到对应的 IP 地址，通过 Kube-proxy 服务发现功能，进行网络数据包转发，实现网络服务功能，以用于描述 Pod 和 Pod 之间的应用访问。
     2. 为客户端提供固定的 IP + 端口：当 Pod 的 IP 发生变化时，Service 可以保证，客户端面对的 Pod 还是固定 IP 和端口。
3. 当需要执行部署，并指定两个副本时，其**执行流程**为：
   - 1）Kuberctl 发送部署请求到 API Server。
   - 2）API Server 通知 Controller Manager，去创建一个 Deployment 资源。
   - 3）Scheduler 执行调度任务，将两个副本 Pod，分发到 Node1 和 Node2 上。
   - 4）Node1 和 Node2 上的 Kubelet 在各自的节点上，创建并运行 Pod。

##### 3、总

=> 以上，就是我对 Docker 和 K8S 的一些理解，请问有什么细节需要补充的吗？

### 16> 分布式

#### 1.1. CAP 定理？

1. **CAP 定理**，又叫布鲁尔定理，指的是，在一个分布式系统中，最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）三项中的两项。
   - CAP 的适用场景是副本性数据，业务间的不一致性（比如订单和库存的不一致）不在 CAP 的讨论范畴。
2. **C：一致性（Consistency）**，数据在多个副本中保持一致，可以理解成两个用户访问两个系统 A 和 B，当 A系统数据有变化时，及时同步给 B 系统，让两个用户看到的数据是一致的。
   - 强调的是，对某个读操作，必须保证能够返回最新的写操作结果，要求的是**数据强一致性**，要和弱一致性、最终一致性、缓存一致性、业务一致性区分开来。
   - **保证方案**：分布式一致性算法。
3. **A：可用性（Availability）**，系统对外提供服务必须一直处于可用状态，在任何故障下，客户端都能在合理时间内，获得服务端非错误的响应。
   - 强调的是，对某次请求，必须保证在合理的时间内，返回合理的响应（不是错误和超时的响应），要求的是**返回及时**。
   - **保证方案**：接口高性能相关，比如缓存、限流、降级、熔断。
4. **P：分区容错性（Partition tolerance）**，在分布式系统中，遇到任何网络分区故障，系统仍然能对外提供服务。其中，网络分区是指，由于某些原因，子节点之间的网络出现故障，导致不同的节点分布在不同的子网络中，有可能子网络中只有一个节点，这就是网络分区。
   - 强调的是，当出现网络分区后，系统能够继续履行职责，要求的是**分布式和数据同步**。
   - **保证方案**：集群、日志复制、主从复制。

证明，为什么只能满足其中两个，而不能 3 个都满足：

![1647171096774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647171096774.png)

- 假设，系统 A 和系统 B 是可以通过网络，进行同步数据的。
- 此时，用户 1 和用户 2 分别要访问系统 A 和系统 B，理想情况下，用户 1 访问系统 A 对数据进行修改，将 data1 改成了 data2，同时用户 2 访问系统 B，拿到的数据应该是 data2。
- 但是，由于网络总是不可靠的，涉及网络调用，就需要一一进行分析：
  1. 当网络发生故障时，系统 A 和系统 B 没法进行数据同步，也就是不能满足 P，同时两个系统依然可以访
     问，那么此时其实相当于是单机系统，就不是分布式系统了，因此，对于分布式系统，P 是必须满足的。
  2. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让用户 2 通过系统 B 正确地拿到 data2，那么此时就满足了 C，由于 P 的存在，可能会导致一致性同步的时间无限延长，在同步期间，任何人不能访问系统 B，从而导致系统 B 不可用，以保证数据一致性，此时满足的是 CP。
  3. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让系统 B 能继续提供服务，那么此时，由于 P 的存在，一致性同步可能需要更多的时间，所以只能牺牲掉一致性，接受系统 A 没有将 data2 同步给系统B，此时满足的就是 AP。
- 因此，分布式系统只能同时满足 CAP 定理中其中 2 个，比如注册中心 Eureka 满足的是 AP，并不能保证 C，Zookeeper 保证了 CP，但不满足 A，而在生产中，A 和 C 的选择，没有正确的答案，应该要取决于自己的业务，比如 12306 系统满足 CP，是因为买票必须满足数据的一致性，不然一个座位多卖了，对铁路运输都是不可以接受的。

#### 1.2. Base 理论？

由于 CAP 中一致性 C 和可用性 A 无法兼得，eBay 的架构师，提出了 BASE 理论，它是通过牺牲数据的强一致性，来获得可用性，属于对 CAP 中 AP 方案的一个补充，BASE 理论并没有要求数据的强一致性，而是允许数据在一定的时间段内是不一致的，但在最终某个状态会达到一致。

它具有如下 3 种特征：

1. **基本可用**：Basically Available，分布式系统在出现不可预知故障时，允许损失部分可用性，保证核心功能的可用性。
2. **软状态**：Soft state，软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在，不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间，进行数据同步的过程存在延时。
3. **最终一致性**：Eventually consistent，最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是，需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

在生产环境中，很多公司，会采用 BASE 理论来实现数据的一致，因为产品的可用性相比强一致性来说，更加重要。

1. 比如在电商平台中，当用户对一个订单发起支付时，往往会调用第三方支付平台，比如支付宝支付或者微信支付。
2. 调用第三方成功后，第三方并不能及时通知我方系统，在第三方没有通知我方系统的这段时间内，我们给用户的订单状态显示支付中，等到第三方回调之后，我们再将状态改成已支付。
3. 虽然订单状态在短期内存在不一致，但是用户却获得了更好的产品体验。

#### 1.3. 分布式事务一致性？

##### 1）XA 方案 - 2PC 协议 | 数据库实现 | 非 100% 一致

**XA 方案**：

1. XA，是由 X/Open 组织提出的分布式事务规范，由一个事务管理器（TM）和多个资源管理器（RM）组成。
2. 当一个事务跨越多个节点时，为了保持事务 ACID 的特性，需要引入协调者（TM），来统一掌控所有参与者节点（RM）的操作结果，并最终指示这些节点是否要把操作结果进行真正的提交或者回滚。

**两阶段提交**，Two phaseCommit，是指在计算机网络以及数据库领域中，为了使基于分布式系统架构下的所有节点，在进行事务提交时，保持一致性而设计的一种算法，整体思路可以概括为：

1. 参与者将操作成败通知协调者。
2. 再由协调者根据所有参与者的反馈情报，决定各参与者是提交还是回滚。

所谓的两个阶段是指：**准备阶段和提交阶段**。

1. **准备阶段**：

   1. 事务协调者（TM）给每个参与者（RM）发送 Prepare 消息。
   2. 每个参与者（RM），要么直接返回失败，比如权限验证失败等，要么在执行本地事务，各自写本地的 redo log 和 undo log，但不提交事务。

   ![1647248864385](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647248864385.png)

2. **提交阶段**：

   1. 如果协调者（TM），收到了参与者（RM）的失败通知或者超时，则直接给每个参与者（RM）发送回滚（Rollback）通知；否则，发送提交（Commit）通知。
   2. 参与者（RM），根据协调者（TM）的指令，执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源，注意的是，2 PC 协议是必须在最后阶段，才会释放锁资源。

   ![1647250694317](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250694317.png)

**缺点**：

1. **同步阻塞问题**：执行过程中，所有参与节点（RM）都是事务阻塞的，当参与者（RM）占有公共资源时，其他第三方节点访问公共资源，将不得不处于阻塞状态。
2. **存在单点故障风险**：一旦协调者（TM）发生故障，参与者（RM）将会一直阻塞下去，尤其在第二阶段，协调者发生故障，那么所有的参与者（RM）还都处于锁定事务资源的状态中，而无法继续完成事务操作。
   - **解决方案**：如果是协调者（TM）挂了，可以重新选举一个协调者（TM），但是无法解决因为协调者（TM）宕机，导致的参与者（RM）处于阻塞状态的问题。
3. **数据不一致**：
   1. 在两阶段提交的二阶段中，当协调者（TM）向参与者（RM）发送 commit 请求后，如果发生局部的网络异常，或者在发送 commit 请求过程中，协调者（TM）发生故障，则会导致只有一部分参与者（RM）接收到了 commit 请求。
   2. 而在这部分参与者（RM）接到 commit 请求之后，就会执行 commit 操作。
   3. 但是，其他部分未接到 commit 请求的参与者（RM），则无法执行事务提交。
   4. 于是，整个分布式系统便出现了数据不一致性的情况。

##### 2）XA 方案 - 3PC 协议 | 数据库实现 | 非 100% 一致

![1647250732842](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250732842.png)

**3PC 算法流程**：

1. **`can commit` 阶段**：准备阶段，3PC 的 `can commit` 阶段其实和 2PC 的准备阶段很像。协调者（TM）向参与者（RM）发送 commit 请求，如果参与者（RM）可以提交就返回 Yes 响应，否则返回 No 响应。
2. **`pre commit` 阶段**：预提交阶段，协调者（TM），根据参与者（RM）的反应情况，来决定是否可以进行事务的 `preCommit` 操作：
   1. **参与者（RM）情况判断**：如果协调者（TM）从所有的参与者（RM），获得的反馈都是 Yes 响应，那么就会执行事务的预执行。
   2. **发送预提交请求**：协调者（TM）向参与者（RM），发送 `pre commit` 请求，并进入 prepared 阶段。
   3. **事务预提交**：参与者（RM）接收到 `pre commit` 请求后，会执行事务操作，并将 undo log 和 redo log记录到本地的事务日志中。
   4. **响应反馈**：如果参与者（RM）成功执行了事务操作，则返回 ACK 响应给协调者（TM），同时开始等待其最终的指令。
   5. **事务中断**：但是，如果有任何一个参与者（RM），向协调者（TM）发送了 No 响应，或者协调者（TM）等待超时，没有接到参与者（RM）的响应，那么就执行事务的中断：
      - **1）发送中断请求**：协调者（TM）发送中断 abort 请求给所有参与者（RM）。
      - **2）事务中断**：参与者（RM），收到来自协调者（TM）的 abort 请求后，或超时没收到协调者（TM）的任何请求，则执行事务中断，即什么都不用做，释放资源即可。
3. **`do commit` 阶段**：提交阶段，此阶段进行真正的事务提交，也需要分为以下 2 种情况：
   1. **发送提交请求**：协调者（TM），收到参与者（RM）返回的 ACK 响应，则会从预提交状态进入到提交状态，并向所有参与者（RM）发送 `do commit` 请求。
   2. **事务提交**：参与者（RM），接收到 `do commit` 请求后，执行正式的事务提交，并在完成事务提交后，释放所有事务资源。
   3. **响应反馈**：参与者（RM）事务提交完之后，向协调者（TM）再次返回 ACK 响应。
   4. **完成事务**：协调者（TM），再次接收到所有参与者（RM）的 ACK 响应之后，代表本次分布式事务完成。
   5. **中断事务**：但是，如果协调者（TM），没有接收到任意一个参与者（RM）返回的 ACK 响应，可能是响应的不是 ACK，也可能发生了超时，那么就会执行中断事务：
      - **1）发送中断请求**：协调者（TM），向所有参与者（RM）发送 `abort` 请求。
      - **2）事务回滚**：参与者（RM），接收到 `abort` 请求后，利用其在 `pre commit` 阶段记录的 undo log 来执行本地事务的回滚操作，并在完成回滚之后，释放所有的事务资源；但如果超时没收到协调者（TM）的任何请求，则参与者（RM）会进行**事务提交**（因为都到了这一阶段了，大概率是可以提交的）。
      - **3）反馈结果**：参与者（RM），完成事务回滚之后，向协调者（TM）发送 ACK 响应。
      - **4）中断事务**：协调者（TM），接收到参与者（RM）反馈的 ACK 响应之后，执行最终的事务中断。

**2PC 和 3PC 的区别**：

1. **3PC 能够及时释放资源**：3PC 比 2PC，多了一个 `can commit` 阶段，减少了不必要的资源浪费。
   - 因为 2PC 在第一阶段会占用资源，而 3PC 在 `can commit` 阶段不占用资源，只是校验一下 sql，如果不能执行，则直接返回，减少了资源占用。
2. **3PC 引入了参与者（RM）超时机制**：在协调者（TM）和参与者（RM），都引入超时机制。
   - **2PC**：只有协调者（TM）有超时机制，超时后，发送会发送回滚指令。
   - **3PC**：协调者（TM）和参与者（RM）都有超时机制：
     1. **协调者（TM）等待超时**：`can commit`、`pre commit` 阶段，如果收不到参与者（RM）的反馈，则协调者（TM）会向参与者（RM）发送中断指令，参与者（RM）进行事务中断，即什么都不用做，释放资源即可（`can commit` 是没有占用资源的 !）。
     2. **参与者（RM）等待超时**：`pre commit` 阶段，参与者（RM）进行回滚；`do commit` 阶段，参与者（RM）进行事务提交（因为都到了这一阶段了，大概率是可以提交的）。

**总结**：

1. 3PC 相对于 2PC 做了一定的改进，引入了参与者（RM）超时机制，并且增加了 `pre commit` 预提交阶段，使得故障恢复之后，协调者（TM）的决策复杂度降低，但整体的交互过程更长了，性能会有所下降，并且同样还会存在数据不一致的问题。
2. 3pc `do commit` 时，如果做的是回滚操作，参与者（RM）等待超时，它应该做的是回滚操作，但规定是做事务提交操作，即有概率出现数据不一致，所以，2PC 和 3PC 都**不能保证数据 100% 一致**，因此，一般都需要有**定时扫描补偿机制**来兜底。
3. 3PC 只是纯理论上的东西，相比于 2PC 只是做了一些优化，但是效果甚微，所以只做了解即可。

##### 3）AT 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

![1647251563240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647251563240.png)

AT 模式，基于支持本地 ACID 事务的关系型数据库实现：

1. **一阶段 `prepare` 行为**：在本地事务中，一并提交业务数据更新，和相应回滚日志记录。
2. **二阶段 `commit` 行为**：执行成功，则自动异步批量清理回滚日志。
3. **二阶段 `rollback` 行为**：通过回滚日志，自动解析生成补偿 SQL，完成数据回滚。

**缺点**：

1. 解析回滚日志，生成 SQL 损耗性能。
2. 默认事务隔离级别是读未提交，无法解决脏读。如果设定读已提交（`SELECT FOR UPDATE` 申请全局锁），则性能会直线下降。

##### 4）TCC 方案 | Seata 实现 | 默认读未提交，读已提交性能低下 

TCC，Try-Confirm-Cancel，是一种 Seata 的分布式事务解决方案，它将一个事务拆分成 3 个步骤：

1. **T**：try，业务检查阶段，主要进行业务校验，以及检查或者资源预留，也可以进行一些业务处理。
2. **C**：confirm，业务确认阶段，主要是对 `try` 阶段校验过的业务，或者预留的资源进行确认。
3. **C**：cancel，业务回滚阶段，与 Confirm 操作是互斥的，主要是释放 `try` 阶段预留的资源或者业务。

![1647254230571](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647254230571.png)

**TCC  方案 VS AT 方案**：

1. TCC 方案，相当于 AT 方案的人工版，属于事务补偿型。
2. AT 方案的回滚，是自动解析回滚日志，解析出反向 SQL。
3. 而 TCC 方案则是完全把 `perpare`、`rollback` 和 `commit` 三个方法全都交给开发者来实现。

**TCC 空回滚是解决什么问题的？**

1. 在没有调用 `try` 方法的情况下，调用了二阶段的 `cancel` 方法。
2. 比如，当 `try` 请求由于网络延迟或故障等原因，没有执行，且结果返回了异常时， `cancel` 不能正常执行，只能进行空回滚，因为 `try` 并没有对数据进行修改，如果 `cancel` 正常执行，对数据进行反向修改，那就会导致数据的不一致。
3. **解决思路**：
   1. 关键是要识别出这个空回滚，也就是需要知道 `try` 阶段到底是否执行，如果  `try`  执行了，那就正常回滚，如果  `try`  没有执行，那就空回滚。
   2. 可以让协调者（TM）在发起全局事务时，生成全局事务记录以及分支事务记录， `try` 阶段插入一条记录，表示 `try` 阶段执行了，`cancel` 阶段再读取该记录，如果该记录存在，则正常回滚，如果该记录不存在，则进行空回滚。

**如何解决 TCC 幂等问题？**

1. 为了保证 TCC 二阶段提交，重试机制不会引发数据的不一致，就要求 TCC 的二阶段 `confirm` 和 `cancel` 方法保证幂等性。
2. 这样才不会重复使用或者释放资源，但如果幂等性控制没有做好，很可能会导致数据不一致等严重问题。
3. **解决思路**：
   1. 在上述所说的分支事务记录中，增加执行状态，每次执行前都查询该状态是否已执行，执行过了就不再执行。
   2. 也可以用分布式锁解决。

**如何解决 TCC 中悬挂问题？**

1. 悬挂，就是对于一个分布式事务，其二阶段 `cancel` 方法比 一阶段的 `try` 方法先执行。
2. **出现原因**是，在调用分支事务 `try` 时，由于网络发生拥堵，造成了超时，协调者（TM）就会通知参与者（RM）回滚该分布式事务，可能回滚完成后，`try` 请求才到达参与者（RM）被真正执行。
3. **造成的后果**是，由于一个 `try` 方法预留的业务资源，只有该分布式事务才能使用，此分布式事务最后才执行的 `try`，导致业务资源预留后，无法被继续处理。
4. **解决思路**是：
   1. 如果二阶段执行完成，那一阶段就不能再继续执行。
   2. 在执行一阶段事务时，判断在该全局事务下，分支事务记录表中，是否已经有二阶段的事务记录，如果有，则不再执行 `try` 。

**缺点**：

1. 默认事务隔离级别读未提交，还是会出现脏读问题。
2. 所要编写的代码量，可能会恶心死人。

##### 5）Saga 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

Saga，长事务解决方案，事务一旦 start，各个参与者（RM）按照顺序，一个一个执行自己的逻辑，当其中有一个参与者（RM）执行失败，那么之前已经执行的参与者（RM）都需要**反向逆序**进行回滚。

![1647255581291](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647255581291.png)

**优点**：

1. 一阶段提交本地事务，无锁，高性能。
2. 事件驱动架构，参与者（RM）可异步执行，高吞吐。
3. 补偿服务易于实现。

**缺点**：默认事务隔离级别读未提交，还是会出现脏读问题，不保证隔离性。

**适用场景**：

1. **业务流程长、业务流程多时**。
2. **调用第三方业务**：参与者（RM）包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口时。

##### 6）本地消息表 | MQ 实现 | 最终一致性

本地消息表，其实就是利用了**各系统本地的事务**来实现分布式事务。

1. 本地消息表，顾名思义就是，会有一张存放本地消息的表，一般都是放在数据库中。
2. 然后，在执行业务时，将业务的执行和将消息放入消息表中的操作，包在同一个事务中，以保证消息放入本地表后，业务肯定能够执行成功。
3. 然后，再去调用下一个操作，如果下一个操作调用成功了，那么消息表的消息状态直接改成已成功。
4. 如果调用失败了，那也没事，会有后台任务定时去读取本地消息表，筛选出还未成功的消息，再调用对应的服务，服务更新成功了再变更对应消息的状态。
5. 其中，有可能消息对应的操作不成功，所以，还需要进行重试（要保证服务接口幂等），在超过最大次数时，还需要记录下来，报警，进行人工处理。

可以看到，本地消息表，其实实现的是最终一致性，容忍了数据暂时不一致的情况。

##### 7）可靠消息最终一致性方案 | MQ 实现 | 最终一致性	

可靠消息最终一致性方案，指的是：当事务发起方（消息发送者）执行完本地事务后，发出一条消息，保证事务参与方（消息的消费者）一定能够接受消息，并可以成功处理他自己的事务。

1. **可靠消息**：发起方一定得把消息传递到消费者。
2. **最终一致性**：最终，发起方的业务处理，和消费方的业务处理都得完成，达到数据的最终一致性。

![1647242994399](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647242994399.png)

**解决方案**：比如，阿里 RocketMQ 的消息事务（**双端都要进行确认，重试要保证幂等性**）

1. A（比如订单）系统，先发送一个 `prepared` 消息到 Broker。
2. 如果 `prepared` 消息发送失败，则取消操作，不再执行。
3. 如果 `prepared`  消息发送成功后，则执行 A 的本地事务，执行成功，则发送确认消息到 Broker，执行失败，则发送回滚消息到 Broker，其中，Broker 会**定时轮询**所有 `prepared` 消息回调的接口，以确认事务的执行状态。
4. 如果 Broker 收到了确认消息，则 B （比如仓储） 系统会接收到该事务消息，然后执行 B 的本地事务。
5. 如果 B 事务执行失败，则会不断重试，直到成功，或者达到一定次数后，发送报警，人工介入，来手工回滚或者补偿。

![1647256631363](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647256631363.png)

##### 8）最大努力通知方案 | MQ 实现 | 最终一致性

**概念**：

1. 其实，本地消息表，也可以算作最大努力通知，事务消息也可以算最大努力通知。
2. 本地消息表来说，会有后台任务定时去查看未完成的消息，然后去调用对应的服务，当一个消息多次调用都失败时，可以记录下来，然后人工介入，也可以直接舍弃掉，算最大努力通知。
3. 事务消息也是一样，当 half message 被 commit 了之后，确实就是普通消息了，如果订阅者一直不消费，或者消费不了，则会一直重试，最后进入死信队列，也算是最大努力通知。
4. 所以，最大努力通知，其实就是一种**柔性事务**的思想，我已经尽力我最大的努力，想达成事务的最终一致了。

**执行流程**：

1. 系统 A 本地事务执行完后，发送消息到 MQ。
2. 然后有个专门消费 MQ 的**最大努力通知服务**，去调用系统 B 的接口。
3. 要是系统 B 执行失败了，就会定时尝试重新调用系统 B 的接口，**反复 N 次** 。
4. 最后还是不行的话，就**放弃**。

**注意要点**：

1. **消息重复通知机制**：由于消费可能没有接收到通知，所以需要有一定的机制，对消息进行重复通知。
2. **消息校对机制**：如果尽最大努力，也没有通知到消费方，或者消费方消费消息后要再次消费，就可由消费方，主动向生产方，查询消息信息来满足需求。

**适用场景**：适用于对时间不敏感的业务，比如短信通知。

##### 9）分布式事务总结

1. 可以看出 2PC 和 3PC 是一种**强一致性事务**，不过还是有数据不一致、事务阻塞等风险，且只能用在数据库层面。
2. 而 TCC 则是一种**补偿性事务**的思想，适用范围更广，由于在业务层面实现，所以对业务的侵入性较大，每个分布式事务，都需要实现对应的三个方法。
3. 本地消息表、事务消息和最大努力通知，都属于**最终一致性事务**，所以，适用于一些对时间不敏感的业务。

**比如**：

1. 如果是一个严格资金绝对不能错的场景，可以用 **TCC 方案**。
2. 如果是一个一般的分布式事务场景，比如积分数据，可以用**事务消息**方案。
3. 如果分布式场景暂时允许数据不一致，则可以使用**本地消息表、最大努力通知**等最终一致性方案。

#### 1.4. 分布式 ID 的实现方案？

##### 1、总

1. 在分库分表环境中，由于表中数据同时存在不同数据库中，平时使用的自增主键 ID 将无用武之地，因为某个分区数据库自生成的 ID 无法保证全局唯一。
2. 因此，需要单独设计全局主键，来避免跨库主键重复的问题，我了解到的方案有：UUID、MyISAM ID 表、高可用 ID 服务器、Snowflake 分布式自增 ID 算法、以及美团的 Leaf 分布式 ID 生成系统。

##### 2、分

###### 1）UUID

UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8­4­4­4­12 的 36 个字符，比如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：方案最简单，且本地生成，性能高，没有网络耗时。
- **缺点**：
  1. 由于 UUID 非常长，会占用大量的存储空间。
  2. UUID 作为主键，建立索引和基于索引进行查询时，都会存在性能问题，在 InnoDB 下，UUID 的无序性会引起数据位置频繁变动，导致页分裂。

###### 2）MyISAM ID 表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();
```

- **概念**：
  1. `stub` 字段（存根）设置为**唯一索引**，同一 `stub` 值在 `sequence` 表中只有一条记录，支持同时给多张表生成全局 ID。
  2. 使用 MyISAM 存储引擎而不是 InnoDB，可以获取更高的性能，因为 MyISAM 使用的是表级锁，对表的读写是串行的，不用担心在并发时两次读取同一个 ID 值的问题。
  3. 使用 `REPLACE INTO + SELECT` 来获取自增 ID，保证两操作在同一事务内，它会先删除旧数据，再生成新数据，从而实现主键自增。
- **优点**：实现简单。
- **缺点**：
  1. 存在单点问题，且强依赖 DB，当 DB 异常时，会导致整个分布式系统都不可用。
  2. 虽然可以配置主从来增加可用性，但当主库挂了，主从切换时，数据一致性难以得到保证。
  3. 因此，整个系统的性能瓶颈，被限制在单台 MySQL 的读写性能上。

###### 3）高可用 ID 服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：Flickr（弗里克，雅虎的一个图片分享网站）团队使用的一种主键生成策略，与上面的 `sequence` 表方案类似，但可以更好地解决了单点故障和性能瓶颈的问题。

- **思想**：

  1. 建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 `sequence` 表用于记录当前全局 ID。
  2. 表中 ID 增长的**步长相同，等于库的数量，起始值依次错开**，这样能将 ID 的生成散列到各个数据库上，比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...）等等。

- **优点**：生成 ID 的压力，能够均匀分布在多台机器上，同时提高了系统的容错能力，当第一台出现了错误，可以自动切换到第二台机器，来获取 ID。

- **缺点**：

  1. 系统添加机器水平扩展时，需要停止原本正在运行的 ID 服务器，以**修改步长**。
  2. 每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。

- **优化方案 **：**批量获取 ID**。

  - 使用批量获取的方式，可以降低数据库的写压力，每次获取**一段**区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    - 1）比如，还是使用 2 台 DB 保证可用性，数据库中只存储当前的最大 ID。
    - 2）ID 生成服务，每次批量获取 6 个ID，可以先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从**号段缓存**中依次派发 0~5 的 ID。
    - 3）当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的ID。
    - 4）这样，数据库的压力降低为原来的 1/6。
  - **缺点**：ID 生成服务需要维护最大 ID 值，再下次生成 ID 时，需要告诉 DB M1、DB M2 各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

###### 4）Snowflake 分布式自增 ID 算法

Twitter 的 snowflake 算法，解决了分布式系统生成全局 ID 的需求，可以生成 64 位的 long 类型的数值。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

- **概念**：1 + 41 + 10 + 12  = 64位。
  1. 首先是，第 1 位不使用。
  2. 接下来是， 41 位的毫秒级时间戳，最大可以表示 **69年** 的时间。
  3. 然后是，5 位的 `datacenterId`，5位的 `workerId`，这 10 位长度，最多支持部署**1024 个节点**。
  4. 最后是，12 位是毫秒内的计数值，最大支持每个节点、每毫秒产生**4096 个 ID 序列**。
- **优点**：
  1. 毫秒数在高位，生成的 ID 整体上按时间趋势是**递增**的，还可以根据自身业务灵活分配 bit 位。
  2. 不依赖第三方系统，稳定、效率高，理论上 QPS 约为 409.6 w/s（2^12 * 1000 ms），且整个分布式系统中不会产生 ID 碰撞。
- **缺点**：强依赖于机器时钟，如果时钟回拨，则可能导致生成的 ID 重复。

###### 5）美团点评分布式ID生成系统 - Leaf

Leaf，服务美团点评公司内部产品，包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在 4 C 8 G 的机器上，QPS 能压测到近 5 w/s，TP 999 1ms，能够满足大部分的业务需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

**1、Leaf - segment ID 服务器方案：**

- **思想**：
  1. 获取 ID 时，向 proxy server 代理服务器批量获取 ID，每次获取一个 segment 号段（由 `step` 决定大小）的值。
  2. 用完之后，再去获取新的号段，可以大大减轻数据库的压力。
- **实现**：
  1. `biz_tag` 用来区分业务，`max_id` 表示该 `biz_tag` 目前所被分配的 ID 号段的最大值，`step` 表示每次分配的号段长度。
  2. 比如，`test_tag` 在第 1 台 Leaf 机器上是 1~1000 的号段，当这个号段用完时，会去加载另一个长度为step=1000 的号段，而如果另外机器的号段都没有更新的话，此时第 1 台机器会重新加载 3001~4000 的号段，同时，数据库对应的 `biz_tag` 这条数据的 `max_id` 会从 3000 被更新成 4000。
  3. 这样，各业务不同的发号需求用 `biz_tag` 字段来区分，每个 `biz-tag` 的 ID 相互隔离，互不影响，如果以后有性能要求，需要对数据库进行扩容时，则不用复杂的扩容操作，只需要对 `biz_tag` 分库分表即可。
  4. 而且，对比原来获取 ID 每次都需要写数据库，现在只需要把 `step` 设置得足够大，比如 1000，那么只有当 1000 个号被消耗完了之后，才会去重新读写一次数据库，此时读写数据库的频率从1  减小到了 **1 / step** 。
- **优点**：
  1. Leaf 服务可以很方便的进行**线性扩展**，性能完全能够支撑大多数业务场景。
  2. 生成的 ID 是**趋势递增**的 8 byte 的数字，满足上述数据库存储的主键要求。
  3. 容灾性高，Leaf 服务内部有**号段缓存**，即使 DB 宕机，短时间内，Leaf 仍能正常对外提供服务。
  4. 可以自定义 `max_id` 的大小，非常方便业务从原有的 ID 方式上**迁移**过来。
- **缺点**：
  1. **TP 999 数据波动大**：当号段使用完之后，还是会 hang 在更新数据库的 I/O 上，TP 999 数据会出现偶尔的尖刺。
  2. **高可用得不到保障**：DB 宕机会造成整个系统不可用。
  3. **生成的 ID 不够随机**：会泄露发号数量的信息，不太安全。

**2、双 buffer 优化方案：**

目的是，优化第 1 个缺点，当号段使用完、线程取号时阻塞的问题。

![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **背景**：
  1. Leaf 取号段的时机，是在号段消耗完时进行的，意味着号段临界点的 ID 下发时间，取决于下一次从 DB 取回号段的时间，并且在这期间，进来的请求也会因为 DB 号段没有取回来，导致线程阻塞。
  2. 假如 Leaf 服务取 DB 时，网络发生抖动，或者 DB 发生慢查询，就会导致整个系统的响应时间变慢。
- **思想**：
  1. 为了让 DB 取号段的过程能够做到无阻塞，不会在 DB 取号段时阻塞请求线程，可以让发号段消费到某个点时，就**异步**的把下一个号段加载到内存中，而不需要等到号段用尽时，才去更新号段。
- **实现**：
  1. 采用双 buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。
  2. 当前号段已下发 10% 时，如果下一个号段未更新，则**异步**另启一个更新线程去更新下一个号段。
  3. 当前号段全部下发完后，如果下个号段准备好了，则切换到下个号段为当前 segment 接着下发，循环往复。

**3、高可用容灾方案：**

目的是，解决第 2 个缺点，DB 宕机会造成整个系统不可用的问题。

![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

**DB 高可用方案**：

1. 采用 1 主 2 从的方式，同时分机房部署，Master 和 Slave 之间采用半同步复制的方式，进行数据同步，同时使用公司的 DBProxy（原 Atlas）数据库中间件，做主从切换。
2. 当然，这种方案在一些情况会退化成**异步模式**，甚至在非常极端情况下仍然会造成**数据不一致**的情况，但是出现的概率非常小。
3. 如果系统确实要保证 100% 的数据强一致，可以选择使用**类Paxos算法**，实现强一致 MySQL 的方案，但这样运维成本和精力都会相应的增加，应该需要根据实际情况进行选型。

**应用高可用方案**：

1. Leaf 服务分 IDC 部署，内部的服务化框架是 `MTthrift RPC`。
2. 服务调用时，根据负载均衡算法，优先调用同机房的 Leaf 服务。
3. 如果该 IDC 内，Leaf 服务不可用，则会选择其他机房的 Leaf 服务。
4. 同时，服务治理平台 `OCTO` ，还提供了针对服务的过载保护、一键截流、动态流量分配等服务保护措施。

**4、Leaf-snowflake 方案：**

目的是，优化第 3 个缺点，生成的 ID不够随机，会泄露发号数量信息，不太安全的问题。

![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

Leaf-snowflake 方案，完全沿用了 snowflake 方案的 bit 位设计，即是 `1+41+10+12` 的方式组装 ID 号。

1. 对于 `workerID` 的分配，当服务集群数量较小时，完全可以手动配置。
2. 但当 Leaf 服务规模较大时，动手配置成本太高，此时可以使用 ZK 持久顺序节点的特性，自动对 snowflake 节点配置 `wokerID`。

**对接 ZK 的步骤**：

1. 启动 Leaf-snowflake 服务时，会去连接 ZK，在 `leaf_forever` 父节点下，检查自己是否已经注册过，是否有该节点的持久化顺序子节点。
2. 如果有注册过，则直接取回自己的 `workerID`，启动服务。
3. 如果没有注册过，则在该节点下，创建一个持久化顺序节点，创建成功后，取回顺序号当做自己的 `workerID` 号，启动服务。
4. 除了每次会去 ZK 拿数据以外，也会在本机文件系统上，缓存一个 `workerID` 文件，当 ZK 出现问题且恰好 Leaf-snowflake 服务机器也需要重启时，还能保证服务正常启动，做到了对 ZK 的**弱依赖**，一定程度上提高了 SLA 。

![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

**解决 snowflake 时钟回退问题**：

由于 snowflake 强依赖机器时间，如果其发生了回拨，则可能会生成重复的 ID，解决方案为：

1. 首先，服务启动时，先检查自己是否写过 `ZK#leaf_forever` 节点。
   - 1）如果写过，则用自身系统时间与 `leaf_forever/#{self}` 节点记录时间做比较，且小于 `leaf_forever/​#{self}` 的时间，则认为当前机器时间发生了回拨，服务启动失败并报警。
   - 2）如果没写过，则证明是新服务节点，此时需要创建持久顺序节点 `leaf_forever/#{self}` ，并写入自身系统的时间。
2. 接下来，综合对比其余 Leaf 节点的系统时间，来判断自身系统时间是否准确，具体做法是：
   - 1）取 `leaf_temporary` 下的所有临时节点（**所有运行中的** Leaf-snowflake节点）的服务 IP+端口。
3. 然后，通过 RPC 请求，得到它们各自的系统时间，计算 `at = sum(time) / nodeSize`。
4. 如果计算结果 `at < 阈值`，认为当前系统时间准确，可以正常启动服务，同时写临时节点 `leaf_temporary/#{self}` ，每隔一段时间（3s），上报自身系统时间，并写入到 `leaf_forever/#{self}` 中，以维持租约。
5. 否则，则认为本机系统时间发生大步长的偏移，启动失败并报警。

##### 3、总

=> 以上，就是我对 分布式全局 ID 实现方案的一些理解，请问有什么细节需要补充的吗？

#### 1.5. 分布式限流？

##### 1、分布式限流维度？

1. **时间**：限流基于某段时间范围，或者某个时间点，也就是常说的时间窗口，比如每分钟、每秒钟的时间窗口做限定。
2. **资源**：基于可用资源的限制，比如设定最大访问次数，或者最高可用连接数。

=> 故，

1. **限流就是在某个时间窗口内，对资源访问做限制**，比如设定每秒最多放行 100 个访问请求。
2. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
3. 比如针对了某个 IP 的限流，限制其每秒最多 10 个访问，那么不管这个 IP 的请求，落在了分布式中的哪台机器上，只要是访问了集群中的服务节点，那么都会受到限流规则的制约。

##### 2、分布式限流规则？

在真正的场景里，往往不止设置一种限流规则，而是会设置多个限流规则共同作用，主要以下 4 种规则：

1. **QPS 和连接数控制**：Nginx、Gateway / Zuul、Redis + Lua、Sentinel、Guava#RateLimiter 等。
2. **传输速率**：Nginx 限制下载速度。
3. **黑白名单**：布隆过滤器。

![1647393890625](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393890625.png)

##### 3、分布式限流实现方案？

1. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
2. 所以，需要将限流信息，保存在一个中心化的组件上，这样它就可以获取到集群中所有机器的访问状态，从而实现分布式限流。

目前比较主流的**实现方案**有：

1. **网关层限流**：把限流规则应用在所有流量的入口处。
2. **中间件限流**：把限流规则存储在分布式环境中的某个中间件里，比如 Redis 缓存中，每个组件都可以从这里，获取到当前时刻的流量统计信息，从而决定是拒绝服务，还是放行流量。

##### 4、分布式限流算法 - 计数器算法？

![1647393051245](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393051245.png)

**概念**：

计数器算法，是指在指定的时间周期内，累加访问次数，如果达到设定的阈值，则触发限流策略，在下一个时间周期进行访问时，再将访问次数清零。

**实现**：此算法无论在单机，还是分布式环境下实现都非常简单，使用 `redis#incr` 原子自增性，再结合 key
的过期时间，可以轻松实现。

**缺点**：

1. 这个算法有一个临界问题，比如在上图中，在 0:00 到 1:00 内，只在 0:50 有 60 个请求，而在 1:00 到 2:00 之间，只在 1:10 有 60 个请求。
2. 虽然在 2 个一分钟的时间内，都没有超过 100 个请求，但是在 0:50 到 1:10 这 20 秒内，却有 120 个请求。
3. 虽然在每个周期内，都没超过阈值，但是在这 20 秒内，却已经远远超过了我们原来设置的 1 分钟内 100 个请求的阈值。

##### 5、分布式限流算法 - 滑动时间窗口算法？

![1647393095141](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393095141.png)

**概念**：

1. 为了解决计数器算法的临界值问题，于是就发明了滑动时间窗口算法，而在 TCP 网络通信协议中，就采用滑动时间窗口算法来解决网络拥堵问题的。
2. 滑动时间窗口，是将计数器算法中的实际周期，切分成多个小的时间窗口，分别在每个小的时间窗口中，记录访问次数，然后根据时间将窗口往前滑动，并删除过期的小时间窗口，最终只需要统计滑动窗口范围内的小时间窗口的总的请求数即可，本质上也是一种计数器算法。

**优点**：

1. 在上图中，假设我们设置一分钟的请求阈值是 100，则将一分钟拆分成 4 个小时间窗口，这样，每个小的时间窗口只能处理 25 个请求，用虚线方框表示滑动时间窗口，当前窗口的大小是 2，也就是在窗口内最多能处理50 个请求。
2. 随着时间的推移，滑动窗口也随着时间往前移动，比如上图开始时，窗口是 0:00 到 0:30 的这个范围，过了15 秒后，窗口右移到 0:15 到 0:45 的这个范围，窗口中的请求重新清零，很大地减少了计数器算法临界值问题出现的概率。
3. 在滑动时间窗口算法中，我们的小窗口划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。

**缺点**：滑动时间窗口算法，本质上还是计数器算法，所以极端情况下，还是会出现临界值问题，使用令牌桶算法则可以很好地解决这个问题。

##### 6、分布式限流算法 - 漏桶算法？

![1647394890225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394890225.png)

**概念**：

1. 漏桶算法的原理，就像它的名字一样，维持一个漏斗，拥有恒定的流出速度，不管水流流入的速度有多快，漏斗出水的速度始终保持不变。
2. 类似于消息中间件，不管消息的生产者请求量有多大，消息的处理能力取决于消费者。
3. `漏桶的容量 = 漏桶的流出速度 * 可接受的等待时长`，在这个容量范围内的请求，可以排队等待系统的处理，超过这个容量的请求，才会被抛弃。

**限流规则**：

在漏桶限流算法中，存在下面几种情况：

1. 当请求速度大于漏桶的流出速度时，也就是请求量大于当前服务所能处理的最大极限值时，会触发限流策略。
2. 当请求速度小于或等于漏桶的流出速度时，也就是服务的处理能力大于或等于请求量时，则正常执行。

**缺点**：当系统在短时间内，有突发的大流量时，漏桶算法处理不了。

**优点**：桶末端流量匀速流出，能够保证系统平稳运行，不用应对突发流量。

##### 7、分布式限流算法 - 令牌桶算法？

![1647394814391](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394814391.png)

**概念**：

1. 令牌桶算法，是增加一个大小固定的容器，也就是令牌桶，系统以**恒定的速率**向令牌桶中放入令牌，当令牌桶满时，再向令牌桶生成令牌时，令牌会被抛弃。
2. 如果有客户端来请求，先需要从令牌桶中拿一个令牌，拿到令牌，才有资格访问系统，这时令牌桶中少一个令牌。

**匀速要生成令牌原因**

1. **提高令牌利用率**：
   - 1）如果前 1 秒，一把梭哈了 10 个，但桶里都有 9 个了，此时只利用了 1 个令牌，其余 9 个令牌都会被丢弃。
   - 2）而如果匀速生成的话，就可以先 10 个令牌一个一个的发放，这样令牌也不至于被梭哈式的丢弃掉，提高了令牌的利用率。
2. **避免服务雪崩**：
   - 1）计数器算法和滑动时间窗口算法，在极端情况下，都会存在一个**临界值的问题**，即虽然某个统计窗口内没超过系统阈值，但前后区间总和却远远超过了系统阈值，从而有可能造成服务响应超时，甚至发生服务雪崩。
   - 2）采用匀速令牌生成，则可以避免某个区间前后之和大于系统阈值，因为**这个和 = 桶容量大小 + 令牌生成速度 * 区间跨度**，可见，令牌生成速度如果是匀速的话，那么这个和就会被限定在一个很小的值，从而可以很好的解决，上述那种人造区间洪峰流量的攻击，避免服务雪崩。

**限流规则**：

在令牌桶算法中，存在以下几种情况：

1. **请求速度大于令牌的生成速度**：那么令牌桶中的令牌会被取完，后续再进来的请求，由于拿不到令牌，会被限
   流。
2. **请求速度等于令牌的生成速度**：那么此时系统处于平稳状态。
3. **请求速度小于令牌的生成速度**：那么此时系统的访问量远远低于系统的并发能力，请求可以被正常处理。

**优点**：令牌桶算法，由于有一个桶的存在，可以处理短时间大流量的场景，这是令牌桶算法和漏桶算法的区别。

**缺点**： 由于可能会存在突发的大量，对系统设计时，需要保留一定的余力去面对。

#### 1.6. 分布式会话？

##### 1、为什么 cookie 无法防止 CSRF 攻击，而 token 却可以？

1. CSRF，Cross Site Request Forgery，跨站请求伪造，简单来说，就是用你的身份，去发送一些对你不友好的请求。
   - 1）比如，小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，于是小壮就好奇地点开了这个链接，结果发现自己的账户少了10000元。
   - 2）这是这么回事呢？原来黑客在链接中，藏了一个请求 `<a src=http://www.mybank.com/Transfer?bankId=11&money=10000>科学理财，年盈利率过万</> `，这个请求直接利用小壮的身份，给银行发送了一个转账请求，也就是通过小壮的 cookie 向银行发出请求。
2. 使用 session 认证时，一般使用 cookie 来存储 sessionid，在登陆后，后端生成这个 sessionid，放在 cookie 中，返回给客户端，而服务端通过 Redis 或者其他存储工具，记录保存着这个 sessionid。
3. 客户端登录以后，每次请求都会带上这个 sessionId，服务端就可以用这个 sessionId，来标识哪些请求来源于你个人。
4. 但是，如果别人通过 cookie，拿到了你的 sessionId 后，就可以代替你的身份访问系统了，在登录后的客户端中，攻击者可以通过让用户误点攻击链接，从而利用每次请求都会带上这个 sessionId 的特性，以达到攻击效果。
5. 而如果使用 token 的话，就不会存在这个问题，因为登录成功获得 token 后，一般存放在 local storage 中，然后是前端通过某些方式，在每个发到后端的请求中，都加上这个 token。
6. 而如果点击了个非法链接，由于是非法链接，不是脚本，没有查询 local storage#token 的能力，此时发送给服务端的请求也，是不会携带 token 的，也就是这个请求是非法的，这样，就不会出现 CSRF 漏洞的问题了。

##### 2、什么是 token? 什么是 JWT ? 如何基于 token 进行身份验证？

![1647336741900](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647336741900.png)

1. 由于 session 需要先保存一份在服务器端，使得服务存在状态，这给后端服务带来一定的麻烦，比如，需要保证有 session 信息的服务器的可用性、在扩容时还要为其做额外的考虑、由于依赖于 cookie，所以不适合移动端等等。
2. JWT ，JSON Web Token，可以让服务器端不用保存 session 信息，只需在登录后返回给客户端，由客户端进行保存，以后每次请求都带上这个 token，服务端解析 token 即可拿到 session 信息，从而使后端服务的扩展性得到提升，所以，**token 就相当于一个通行令牌**。
3. JWT，本质上就一段签名后的 JSON 数据，接收者可以根据签名，验证它的真实性，它由 3 部分构成：
   - **1）Header**：token 头，描述 JWT 的元数据，主要定义了，生成签名的算法，以及 token 的类型。
   - **2）Payload**：token 体，主要用来存放实际传递的数据。
   - **3）Signature**：token 签名，服务器通过 Payload、Header 和一个 secret 密钥，使用 Header 指定的签名算法来生成 token 令牌，默认是 `HMAC SHA256`，登录生成后，则把 token 令牌返回给客户端。
4. 客户端收到 token 后，可以保存在 cookie，或者 local storage 里面，在以后发出的所有请求，都携带这个令牌，以标识请求来源，然后服务端检查 JWT，并从中获取用户相关信息，从而替代掉 sessionId。
   - 1）如果放在 cookie 里，让请求发送时自动带上，则不能跨域问题，因为非子域下的 token 将会失效。
   - 2）所以，最好的做法是，放在 `HTTP Header#Authorization` 字段中。

##### 3、token 使用的最佳实践？

1. **设置合理的过期时间**。
2. **注销的 token，如果后端保存过，则需要及时清除**。
3. **监控 token 的使用频率**：防止数据被别人爬取，通过监控使用频率，从请求痕迹中，分析出是否为爬虫程序访问。 
4. **核心功能、敏感操作可以使用动态验证码**：比如提现功能，就要求在提现时，再次进行验证码校验，以防止非本人操作。
5. **识别网络环境、浏览器等信息**：比如，网络环境跟之前使用的不一样时，则需要 APP 重新登录。
6. **secret 加密密钥支持动态修改**：
   - 1）如果 token 的 secret  加密密钥泄露了，意味着别人可以伪造这些 token，这需要能够立刻修改密钥，以更改 token 生成和校验机制。
   - 2）此时，可以将 secret 密钥存储在配置中心，以支持动态修改刷新。
   - 3）但需要注意的是，建议在流量低峰时，再去做 secret 加密密钥的更换操作，否则会导致 token 全部失效，使得所有在线的请求，都需要重新申请 token，导致并发量突增。

##### 4、session 共享方案？

1. **集中式 session 服务器**：还是使用 sessionid 和 cookie 的机制，统一由一个集中式服务器进行 session 管理，缺点是，sessionid  存储在客户端本地有风险，且要保证集中式 session 服务器的高可用。
2. **session 同步**：对各服务器进行 session 数据同步，虽然可以保证每个服务器上都有全部的 session 信息，但当服务器数量过多时，同步会带来很大延迟，甚至同步失败，故放弃。
3. **负载均衡 IP 绑定**：通过负载均衡，比如 nginx 对客户端 IP 与某个服务实例进行绑定，让同一个 IP 只能在指定的同一个机器访问，缺点是对应服务实例宕机后，session 将会丢失，且失去了对请求进行负载均衡的意义。
4. **Redis 共享存储**：把 session 存放到 Redis 中，缺点是需要多访问一次 Redis，但真正实现了 session 共享，不仅可以跨服务器 session 共享，还可以跨平台 session 共享，比如网页端和 APP 端；同时，还支持水平扩展、无状态化后端服务，即使服务重启了，存在 Redis 中的 session 也至于丢失。

##### 5、认证与授权的区别？

1. 认证，Authentication，身份验证，是验证你的身份凭据，比如用户名、用户ID 和密码是否合法，通过这个凭据，系统可以得以知道你就是你，是**身份维度**。
2. 授权，Authorization，发生在认证之后，主要是掌控用户访问系统的权限，有些特定资源只能具有特定权限的人才能访问，比如 admin，是**权限维度**。
3. 认证和授权，一般在系统中都被结合使用，目的是为了保护系统安全。

##### 6、单点登录 SSO？

SSO，Single Sign On，单点登录，是一种会话共享的技术，指用户只需要在某一个网站登录后，那么他所产生的同一次会话，就共享给了其他网站，也就是说，实现了单点登录后，间接地也登录了其他网站。

- **会话**，session，代表的是客户端与服务器的一次交互过程，这个过程可以是连续的，也可以是断断续续的。

根据浏览器的跨域与 cookie 特性，二级域名可同享一级域名的 cookie， 其他不同域名间不共享 cookie，实现基于会话共享的单点登录，可以分为 2 种不同方案：相同一级域名的单点登录和不同一级域名的单点登录。

###### 1、相同一级域名的单点登录 | cookie + Redis

二级域名共享一级域名的 cookie，即 `www.abc.test.com` 和 `www.def.test.com` ，两者共享 `www.test.com` 域名下的 cookie。

**具体流程为**：

1. 首先，前端方面，登录后，后端可以把标志当前会话的 userId，设置到 `www.test.com` 域名下的 cookie 中。
2. 然后，后端方面，则把 userId 作为 key，把会话信息放到 Redis 中，实现分布式会话。

这样，用户在 `www.abc.test.com` 登录后，userId 放入了 `www.test.com`  的 cookie 中，会话信息放到了 Redis 中，只要会话没结束（浏览器没关闭），则在用户下次访问 `www.def.test.com` 时，后端照样能够拿到 cookie 中的 userId，从而去 Redis 查到有会话信息，则认为本次请求有效，无需重新登录，从而实现单点登录。

###### 2、不同一级域名的单点登录 | cookie + CAS + Redis

（图片仅供参考，与下面流程不符）

![1647352168308](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647352168308.png)

不同一级域名间的 cookie 无法共享，即 `www.abc.com` 和 `www.def.com`，两者间的 cookie 无法共享。

这样，就需要引入一个中心节点，用于专门承接单点登录工作，以实现以上两个域名间的 cookie 共享，这个中心节点就是 CAS。

- **CAS**，Center Authentication Service，中央认证服务，是一个单点登录的解决方案，用于不同一级域名之间的单点登录。

**具体流程为**：

![img](file:///D:/MyData/yaocs2/Desktop/%E5%A4%87%E6%B3%A8/5%20SSO/SSO_%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95_%E6%97%B6%E5%BA%8F%E5%9B%BE_20220315.png)

假设 CAS 服务端域名为 `www.cas.com`，其他一级域名都是它的客户端，这里有两个，分别为 `www.mtv.com` 和 `www.music.com` 。

1. 一个用户在某个时间，访问了 `www.mtv.com` 服务 A。
2. 此时，A 需要校验请求，由于 A 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
3. CAS 收到请求后，发现请求并没有会话标记，代表没有登录，则重定向用户到登录页面，需要用户进行登录。
4. 用户在登录成功后（账号密码校验通过），则 CAS 为用户创建会话，生成全局门票和临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 A。
5. A 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
6. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 A 登录成功。
7. 接着，用户跑去访问 `www.music.com` 服务 B。
8. 此时，B 需要校验请求，由于 B 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
9. CAS 收到请求后，发现请求有会话标记，然后去查 Redis 是否存在全局门票，如果存在，则说明会话已共享，认为用户已登录，然后生成临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 B。
10. B 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
11. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 B 登录成功。
12. 至此，一次不同一级域名间的单点登录流程完毕。

其原理在于，利用了两网站间接共享了 CAS 同一个域名的 cookie，使用其中的 userId 作为当前会话的标记，以让后端能够拿着这个标记，去 Redis 中判断是否已生成分布式会话，从而免去第二次的重复登录，实现单点登录。

**全局门票 VS 临时门票**：

1. **全局门票是分布式会话**，是判断当前会话是否已经登录的核心所在。
2. **临时门票是安全性保证**，用于跟 CAS 换取会话信息。
   - **1）假设不用临时门票**，而是直接把全局门票返回给客户端，这样就会导致，如果该全局门票被他人知道了，那么即使用户的当前会话关闭了，劫持者依然能够通过全局门票进行登录操作，就保证不了单点登录是同一次会话。
   - **2）而如果用的是临时门票**，就可以保证本次登录只在当前会话有效，会话结束后，cookie 中的 userId 过期，再次请求 CAS 的话，就需要重新登录和设置了，并且，就算临时门票被劫持了，只需在临时门票兑换会话信息的操作中，增加额外的校验（比如网站来源，或者校验 cookie 中有没有 userId），返回校验不通过，就可以避免掉上面这种劫持风险了。

#### 1.7. 分布式一致性算法？

##### 1、背景

1. 分布式系统，对分区容错性的一般解决方案是 `state machine replication` 状态机复制。
2. 分布式一致性算法，本质上就是一种 `state machine replication` 状体机复制的共识算法。
3. 分布式系统，有多个节点就会存在节点间通信的问题，存在着两种节点通讯模型：共享内存（Shared memory）和消息传递（Messages passing）传递模型。
4. 以下谈到的分布式一致性算法，都是基于**消息传递**通讯模型实现的，从而保证在分布式系统中，进程间基于消息传递就某个值达成一致。

##### 2、一致性模型

1. 现阶段工业，有 2 种一致性模型：弱一致性和强一致性。
2. 弱一致性中最主要的是最终一致性，对于**最终一致性**最好的体现是 DNS（Domain Name System） 和 Gossip （Cassandra、Redis 的通信协议）。
3. **强一致性**主要有：同步模型（主从同步）和多数派机制模型（Paxos、Raft、Zab）。

##### 3、同步模型

**基本思想**：

1. Master 接受写请求。
2. Master 复制日志至 Slave。
3. Master 等待，直到所有从库返回后，才响应客户端。

**存在的问题**：任意一个从节点返回失败，都会导致 Master 阻塞，导致整个集群不可用，虽然保证了一致性，但可用性大大降低。

##### 4、多数派模型

**基本思想**：

1. 每次写，都保证写入大于 N / 2 个节点。
2. 每次读，都保证从大于 N / 2 个节点中读。

**相关算法**：

![1647235115496](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235115496.png)

Paxos 算法，是莱斯利 · 兰伯特(Leslie Lamport) 于 1990 年提出的一种基于消息传递的一致性算法，其发展分类有：Basic Paxos、Multi Paxos 和 Fast Paxos，其中工业界用得最多的是 Raft 和 ZAB。

###### 1）Basic Paxos

**算法角色**：

- **Client**： 系统外部角色，请求发起者，像民众。
- **Proposer**： 接受 Client 请求，向集群提出提议（propose），并在冲突发生时，起到冲突调解的作用，像提议员，替民众提出议案。
- **Acceptor**：提议投票和接受者，只有在形成法定人数（Quorum，一般即为 majority 多数派）时，提议才会最终被接受，像国会议员。
- **Learner**：提议接受者，负责 backup 备份工作，对集群一致性没什么影响，像记录员。

![1647235532293](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235532293.png)

**算法阶段**，有 2 个阶段，每个阶段有 2 个分支阶段：

1. **Prepare**：提出一个提案，编号为N，只有 N 大于此 Proposer 之前提出的提案编号（全局递增的一种编号）， 请求才会被 Accpetor 的 Quorum 多数派接受。
2. **Promise**：接受发过来的请求，前提是该请求编号 N 大于之前任何提案的编号。
3. **Accept**：如果 Proposer 确认达到了多数派，则会发出 Accept 请求，该请求包含提案编号 N 和提案内容。
4. **Accpeted**：如果 Acccetor 集群在此期间，没有收到任何编号还大于 N 的提案，则接受刚刚的提案，否则忽略。

**算法问题**：

1. **活锁问题**：在议案还没有被接受时，如果再出现新议案编号，那么就会不断出现 Prepare + Promise 讨论新提案，而不是 Accept 接受一个提案。
   - **解决方案**：提供一个 random timeout，其他的提案需要等待一段随机时间，才被讨论。
2. **效率较低**：提交提案、接收提案进行了 2 轮的 RPC 操作，效率较低。
3. **实现难度大，且不容易理解**。

![1647235817187](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235817187.png)

###### 2）Multi Paxos

**目的**：为了减少角色，简化步骤。

**解决方案**：

1. 由于 Basic Paxos 存在活锁问题，其根因是多个 Proposer 导致的，所以，Multi Paxos 提出了一个新的概念 -> Leader，Leader 是唯一的 Proposer，所有请求都需经过此 Leader。
2. 由于 Basic Paxos 存在两轮 RPC 导致的效率低下问题，所以，Multi Paxos 则通过 Leader 角色 + 在消息中增加一个随机的 Term 任期，使得两轮 RPC 的情况，只在竞选 Leader （选举）时才出现，其余情况（复制）只需要进行一轮 RPC。

![1647236688258](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647236688258.png)

###### 3）Raft

Raft，可以认为是比 Multi Paxos 更简单的一致性算法。

其**算法角色**有：

1. **Leader**：主节点，整个集群只有一个 Leader，所有的写请求都通过 Leader 发送给 Follower。
   - **Term**：在每一个 Leader 的任期期间，都有唯一表示该任期的一个 Term。
2. **Follower**：从节点（跟随角色）。
3. **Candidate**：在 Leader 消息发送失败或宕机，整集群没有 Leader 时，Follower 接收 Leader 的心跳包超时，则它们以 Candidate 身份，开始竞选 Leader。Candidate 只是个中间状态，不会长期存在。

Raft 将分布式问题划分成 3 个小问题：

1. **Leader Election**：主节点选举，集群启动、或者 Leader 心跳包消息无法发送给 Follower 时，触发选主操作。

   集群启动：

   ![1647238020422](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238020422.png)

2. **Log Replication**：日志复制。

   1. 客户端请求 Leader 写入数据。
   2. Leader 将数据分发到 Follower 中，然后数据被写入 Follower 的内存。
   3. Follower 向 Leader 发送确认消息，Leader 首先提交自己的数据，响应客户端，然后向 Follower 发送提交数据请求。
   4. Follower 收到提交请求后，提交数据。

   ![1647238328150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238328150.png)

3. **Safety**：安全恢复。

   - **1）Leader 宕机感知**：

     1. 通过 timeout，来保证 Follower 能正确感知 Leader 宕机或消息丢失的事件，并触发 Follower 竞选Leader。

        ![1647238709444](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238709444.png)

     2. Leader 需要给 Follower 发送心跳包（heartbeats），数据也是携带在心跳包中，发送给 Follower 的。

        ![1647238617190](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238617190.png)

   - **2）选主平票情况**：Leader Election 平票时，两个 Candidates 会产生一个随机的 timewait，继续发送下一个竞选消息。

     ![1647238893242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238893242.png)

   - **3）脑裂（大小集群）情况**：

     1. 小集群由于没有得到多数派的回复，写操作失败。
     2. 大集群会发生重新选主的过程，且新 Leader 拥有自己新的 Term(任期)，写操作成功。
     3. 当小集群回到大集群时，由于小集群的 Term 小于新集群的 Term，则会同步大集群的信息。

     ![1647238545305](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238545305.png)

###### 4）ZAB

ZAB，全称是 Zookeeper atomic broadcast protocol，是 ZK 内部用到的一致性协议，基本与 Raft 相同：

1. Zab 将任期 Term 换成了 epoch。
2. 用于保证日志连续性的心跳检测，方向 ZAB 改由 Follower 发送至 Leader。

**算法角色**：

1. **Leader**：负责投票的发起和决议、更新系统状态。
2. **Follower**：接受客户端请求、响应客户端结果、参与投票。
3. **Observer**：可以接受客户端请求，将其转发给 Leader，但是不参与投票过程，只同步 Leader 状态，目的是为了扩展系统，提高读取速度。

ZAB 有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。

- **1）恢复模式（选主）**：
  1. 当服务启动或者在领导者崩溃后，ZAB 就进入了恢复模式。
  2. 当领导者被选举出来，且大多数 Follower 完成了和 Leader 的状态同步以后，恢复模式就结束了。
  3. 状态同步保证了 Leader 和 Follower 具有相同的系统状态。
  4. ZK 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的，系统默认的选举算法为 fast paxos。
- **2）广播模式（同步）**：
  1. 选完 Leader 以后，ZK 就进入状态同步过程。
  2. Leader 等待 Follower 连接。
  3. Follower 连接 Leader，将最大的 ZXID（全局递增的事务 ID）发送给 Leader。
  4. Leader 根据 Follower 的 ZXID 确定同步点。
  5. 完成同步后，通知 Follower 已经成为 uptodate 状态。
  6. Follower 收到 uptodate 消息后，又可以重新接受 Client 的请求，继续进行服务了。

#### 1.8. 分布式搜索？

##### 1、什么是分布式搜索？

分布式搜索，可以将更大范围分布的异构数据联合起来，形成一个逻辑整体，为用户提供强大的**全文检索**能力。

![1647400157225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647400157225.png)

##### 2、Lucene、Solr、ElasticSearch？

- **Lucene**：是一个基于 Java 的类库，集成了许多 API 方法，相当于一个 Jar 包，只能给 Java 使用，实现集群十分复杂。
- **Solr**：Apche 的开源项目，也是用的 Java 开发，基于 Lucene 的开源搜索引擎，本质上是对 Lucene 进行的一层封装，可以实现集群，可靠性，容错性高。
- **ElasticSearch**：也叫 ES，基于 Lucene 开发，提供很多 RestFul 风格的接口，可供其他语言使用，可扩展性更高，支持 PB 级别的近实时搜索。

##### 3、倒排索引 vs 正排索引？

- **正排索引**：文档 => 关键词，但根据关键词检索文档很费力，要一个文档一个文档，挨个遍历查找。
- **倒排索引**：关键词 => 文档，可以根据关键词，立马找到其出现过的所有文档。

##### 4、ES 核心概念？

1. **Near Realtime**：NRT，近实时，两个意思：
   - 1）从写入数据到数据可以被搜索到有一个小延迟（大概1秒）。
   - 2）基于es执行搜索和分析可以达到秒级。
2. **Cluster**：
   - 1）集群，包含多个节点，通过配置集群名称，来划分每个节点所属集群。
   - 2）对于中小型应用来说，刚开始一个集群只有一个节点很正常。
3. **Node**：节点，集群中的一个节点，节点也有一个名称，默认随机分配。
4. **index**：
   - 1）索引，包含一堆有相似结构的文档数据，比如客户索引、商品分类索引、订单索引。
   - 2）索引有一个名称，一个 index 包含很多 document，一个 index 就代表了一类类似的或者相同的document 。
   - 3）在 ES 5.x 版本以前，可以在一个索引中定义多个类型，6.x 之后一个索引只能创建一个类型，在 7~8.x 版本中，已经被彻底移除了。
5. **type**：类型，每个索引里都可以有一个或多个 type，type 是 index 中的一个逻辑数据分类，一个 type 下的document，都有相同的 field。
6. **document**：文档，是 ES 中的最小数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示，每个 index 下的 type 中，都可以去存储多个 document。
7. **field**：属性，一个 document 里面有多个 field，每个 field 就是一个数据字段。
8. **shard**：
   - 1）分区，单台机器无法存储大量数据，ES 就把一个索引中的数据，切分为多个 shard，分布在多台服务器上存储。
   - 2）有了 shard 就可以横向扩展，以存储更多数据，让搜索和分析等操作，分布到多台服务器上去执行，提升吞吐量和性能。
9. **replica**：
   - 1）副本，任何一个服务器随时都可能故障或宕机，导致 shard 可能就会丢失，因此，ES 为每个 shard 创建多个 replica 副本。
   - 2）replica 可以在 shard 故障时，提供备用服务，保证数据不丢失。

| ES       | 类比于 MySQL 中的     |
| -------- | --------------------- |
| index    | 库                    |
| type     | 表                    |
| document | 行                    |
| field    | 列                    |
| mappings | 表结构                |
|          |                       |
| **ES**   | **类比于 Kafka 中的** |
| Node     | Broker                |
| shard    | Partition             |
| replica  | Partition#Replica     |

##### 5、ES 读写原理？

**写原理**：

1. 把索引拆分成多个 shard 分区，每个 shard 存储部分数据。
2. 其中，一个 shard 可以有多个备份，也就是说，每个 shard 都会有一个 primary shard 主分区，负责写入数据，还有几个 replica shard 副本分区。
3. primary shard 主分区写入数据之后，会将数据同步到其他几个 replica shard 副本上去。
4. 通过这个分区 + 副本机制，可以保证每个 shard 都有多个备份，如果某个机器宕机了，则还会有别的副本在别的机器上，从而实现高可用。
5. 如果某台 primary shard 主分区宕机，那么会由 master 节点，让那个宕机节点上的 primary shard 主分区的身份，转移到其他机器上的 replica shard 副本分区中。
6. 当宕机的那台机器修复完，并重启之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据，让集群恢复正常。
7. 而如果 master 节点宕机了，那么则会重新选举一个节点为 master 节点。

**读原理**：

1. 客户端发送一个搜索请求，协调节点会把请求发送给所有的 shard。
2. 然后这些 shard 会去自己里面查，找到可能会匹配到的 doc，返回给协调节点。
3. 协调节点再去 doc 里面去做匹配，找到最符合查询需要的那些 document。
4. 最后再给客户端返回。

