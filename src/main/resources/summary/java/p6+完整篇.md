# 一、基础篇

## 1. 网络基础

### 1.1. TCP是什么？

TCP，Transmission Control Protocol，传输控制协议，是一种面向连接的、面向字节流的、可靠的传输层通信协议。

### 1.2. UDP是什么？

UDP，User Datagram Protocol，用户数据报协议，是一种无连接的、面向报文的、不可靠的传输层协议，为应用程序提供一种无需建立连接就可以发送封装好的IP数据包的方法。

### 1.3. TCP与UDP的差别？

|                     | TCP                                          | UDP                                  |
| ------------------- | -------------------------------------------- | ------------------------------------ |
| 是否连接            | 面向连接的                                   | 无连接的                             |
| 传输方式            | 面向字节流的（流入进程或进程流出的字节序列） | 面向报文的（完整的报文）             |
| 连接对象个数        | 只能 一对一、可全双工通信                    | 支持一对一、一对多、多对一和多对多   |
| 是否使用拥塞控制    | **<u>流量控制和拥塞控制</u>***               | 无流量控制和拥塞控制                 |
| 是否可靠            | 可靠的                                       | 不可靠的，尽最大努力交付             |
| **<u>首部开销</u>** | 8个字节                                      | 20~60字节（选项可达40个字节）        |
| 性能                | 传输效率低，所需资源多                       | 传输效率高，所需资源少               |
| 适用场景            | 文件、邮件                                   | 语音、视频、直播                     |
| 应用的协议          | HTTP、FTP、SMTP                              | **<u>RIP</u>**、DNS、**<u>SNMP</u>** |

### 1.4. TCP与UDP应用的协议？



![1620099899187](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620099899187.png)

### 1.5. TCP如何保证数据可靠传输？

> 思路：当出现差错时能让发送方重传出现差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度。
>
> TCP主要通过确认应答和超时重传机制、检验和、最大报文长度、滑动窗口控制、流量控制以及拥塞控制等方法实现数据的可靠性传输。

#### **1. 确认应答和超时重传机制**

1. 作用：发送方通过对字节流每个字节进行顺序标号发送，接收方需要对接收到的数据中最高需要给出确认（不应超过0.5s），如果在规定的时间内，发送方没有收到确认应答，则需要重传已发送的报文段。
2. 工作原理：

- **序号**：占4个字节，范围[0，2^32  - 1]，使用mod 2^32运算，n序号表示第n字节，共可表示2^40位（4GB）数据。
- **确认号**：占4个字节，表示期望收到对方下一个报文段的第一个数据字节的序号。若确认号=N，则表明到序号N-1为止的所有数据都已正确收到。
- **确认ACK**：占1位，仅当ACK=1时确认号有效，TCP规定，在连接建立后，所有传送的报文都必须把ACK置为1。

#### **2. 检验和**

1. 作用：通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。
2. 工作原理：

- **二进制反码求和运算**：
  - 0+0=0，但要产生进位1
  - 0+1=1，不需要产生进位1
  - 1+1=0，不需要产生进位1
  - 最高位产生进位1，最后结果需要+1
- 发送方：取12位TPC伪首部+TCP首部+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
- 接收方：取12位TPC伪首部+TCP首部（此时检验和已经不是全0了）+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

![1620126724402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620126724402.png)

#### **3. 最大报文段长度**

MSS，Maximum Segment Size，是指每一个TCP报文段中数据字段的最大长度 = TCP报文段长度 - TCP首部长度 

1. 作用：在连接建立过程中，双方选项上写入自己能支持的MSS（默认536字节），要保证在IP层传输时不需要再分片，减少网络开销，提高网络利用率。
2. 工作原理：

- MSS较小时，传输时加上TCP首部+IP首部+链路层首部，造成花费大开销实现少量数据传输，网络利用率低下。
- MSS较大时，TCP报文段非常长，在IP层传输被分解成多个短的数据报片，造成在终点时要把收到的各个短数据报片装配成原TCP报文段，而且分片多传输出错的概率大，还需要重传，使得花销增大。

#### **4. 以字节为单位的滑动窗口控制**

1. 作用：在没有收到接收方确认的情况下，发送方可以连续把窗口内的数据都发送出去，凡是已经发送过的数据，在未收到确认之前都必须暂时保留以便在超时重传时使用。这样可以提高超时重传机制下的发送效率和信道利用率。
2. 工作原理：

- 发送窗口里面的序号表示允许发送的序号，后沿后面部分表示已发送且已收到的确认，前沿前面部分表示不允许发送。*后沿变化有两种可能即不动（没有收到新的确认）和前移（收到了新的确认）。前沿通常是不断向前的，但也可能不动（收到通知窗口变小），还有可能向后收缩（不推荐）*。
- 接收窗口后沿部分表示已经发送过确认，已经交付主机了，不需要再保留这些数据，窗口内的需要是允许接收的。

![1620130103782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130103782.png)

#### **5. 利用滑动窗口实现的流量控制**

1. 作用：控制发送方速率不要太快，要让接收方来得及接收。*是点对点通信量的控制，是个端对端的问题（接收端控制发送端）。*
2. 工作原理：

- rwnd，receiver window，即通知窗口，发送方的发送窗口不能超过接收方给出的接收窗口数值。
- *持续计时器，persistence timer，收到零窗口通知时开启，时间到期后会发送一个零窗口探测报文段（仅携带1字节的数据），对方在这个探测报文段给出现在窗口值，如果仍然是零，则还会重新设置持续计时器。以解决零窗口互相等待问题。*

![1620130650215](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620130650215.png)

#### 6. 拥塞控制

1. 作用：防止过多的数据注入到网络中，避免网络中的路由器和链路过载。*拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的因素。*
2. 工作原理：

- cwnd，congestion window，拥塞窗口，发送方维持的一个状态变量，大小取决于网络的拥塞程度，并且动态变化。**发送方窗口上限值 = Min[rwnd，cwnd]**
- SMSS，Sender Maximum Segment Size，最大报文段。
- 慢开始门限，ssthresh，cwnd < ssthresh => 慢开始算法，cwnd > ssthresh时 => 拥塞避免算法。
- 慢开始，slow-start，先发送小字节探测一下（2~4个SMSS），由小到大逐渐增大拥塞窗口。在每收到一个对新的报文段的确认后，就可以把拥塞窗口增多一个SMSS数值（△cwnd = min[N，SMSS]，N指原先未被确认的、但现在刚刚收到确认的字节数）。
- 拥塞避免，congestion avoidance，cwnd缓慢增大，每经过1个往返时间RTT只把cwnd+1，不像慢开始阶段那样指数规律增长，而是按线性规律增长增长。如果网络出现了超时，发送方判断为网络拥塞，需要调整ssthresh为原来的一半，同时cwnd设置为1，重新进入慢开始阶段。
- 快重传，fast retransmit，接收方没收到某报文段时，需要立即返回3个缺失报文段的重复确认给发送方。发送方只要一收到3个重复确认（3 - ACK），则认为接收方确实没有收到该报文段，则进行重传，而不会误认为是网络拥塞。
- 快恢复，fast recovery，发送方知道只是丢失个别报文段后，不启动慢开始而是执行快恢复算法，调整ssthresh为cwnd/2，同时设置cwnd=ssthresh，并执行拥塞避免算法。

![1620132158175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620132158175.png)

### 1.6. TCP三次握手？

*服务端TCP进程先创建传输控制块TCB（TCP连接表、指向发送和接收缓存的指针、指向重传队列的指针、当前发送和接收序号等），处于LISTEN（收听）状态，等待客户端的连接请求。*

*客户端TCP进程创建传输控制块，打算建立TCP连接，向服务端发起连接请求报文段。*

- TCP规定，SYN报文段不能携带数据，但要消耗一个序号。
- TCP规定，ACK报文段可以携带数据，如果不携带数据则不用消耗序号。

1. 一次握手：客户端发送SYN=1，seq=x的请求报文段，随后客户端进入SYN-SENT（同步已发送）状态。
2. 二次握手：服务端返回ACK=1，ack=x+1，SYN=1，seq=y的确认报文段，随后服务器进入SYN-RECD（同步收到）状态。
3. 三次握手：客户端返回ACK=1，ack=y+1，seq=x+1的确认报文段，此时TCP连接已建立，客户端进入ESTABLISHED（已建立连接）状态。

*当服务端收到客户端的确认报文段后，也进入ESTABLISHED（已建立连接）状态。*

![1620138485517](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620138485517.png)

### 1.7. 为什么TCP需要三次握手，两次行吗？

- 三次握手的原因：主要是为了建立可靠的全双工通信信道，保证客户端与服务端同时具备发送与接收数据的能力。
- 两次握手不行的原因：

1. **两次握手只能保证单向连接是通畅的**。根据TCP确认应答和超时重传机制，通信双方必须维护一个序列号，发送方根据序列号标识哪些报文段是已经发送出去的，接收方也要根据序列号应答哪些报文段是已经确认的。**而三次握手的过程就是双方互相告知起始序列号的过程**，即客户端标记服务端确认，服务端标记客户端确认。如果只是两次握手，那么至多只有客户端的起始序列号得以确认，而另一方的序列号得不到确认，即只能确保单向连接是顺畅的。
2. **第三次握手可以防止已失效的连接请求报文段突然又传送到服务端，建立了多余的连接，造成资源的浪费。**

### 1.8. TCP四次挥手？

*客户端TCP进程先发起TCP释放报文段，并停止发送数据，主动关闭TCP连接。*

- TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
- TCP规定，ACK报文段可以携带数据，如果不携带数据则不用消耗序号。
- MSL，Maximum Segment LifeTime，最长报文段寿命，建议设置为2分钟。

1. 一次挥手：客户端发起FIN=1，seq=u的连接释放报文段，随后进入FIN-WAIT-1（终止等待1）状态，等待服务端确认。
2. 二次挥手：服务端返回ACK=1，ack=u+1，seq=v的确认报文段，随后进入CLOSE-WAIT（关闭等待）状态，此时客户端到服务端方向的连接已释放，TCP连接处于HALF-CLOSE（半关闭）状态。接着，客户端收到确认报文段后，进入FIN-WAIT-2（终止等待2）状态，等待服务端发出连接释放报文段。
3. 三次挥手：服务端TCP进程发起ACK=1，ack=u+1，FIN=1，seq=w的连接释放报文段，随后进入              LAST-ACK（最后确认）状态，等待客户端的确认。
4. 四次挥手：客户端返回ACK=1，ack=w+1，seq=u+1的确认报文段，随后进入TIME-WAIT（时间等待）状态，服务端接收到确认报文段后，进入CLOSE（关闭）状态。此时TCP连接还没有释放掉，必须经过时间等待计时器（TIME-WAIT timer）设置的2MSL时间后，客户端才进入CLOSED（关闭）状态。

![1620141320603](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620141320603.png)

### 1.9. 为什么TCP需要四次挥手？

- 四次挥手的原因：因为需要确保客户端与服务端的数据能够完成传输。前两次挥手后，关闭客户端到服务端方向的连接，服务端通知上层应用程序做好最后的准备，进入CLOSE-WAIT（等待关闭）状态。第三次挥手由服务端TCP进程发起连接释放报文段，根据TCP确认应答和超时重传机制，客户端必须返回确认报文段，所以产生第四次挥手。

### 2.0. 为什么TCP客户端需要等待2MSL才进入关闭状态？

- MSL，Maximum Segment LifeTime，最长报文段寿命，建议设置为2分钟。

1. **为了保证客户端发送的最后一个确认报文段能够达到服务器。**如果上一个确认报文丢失，设置2MSL能够在这个时间内，客户端再次收到服务端的FIN+ACK连接释放报文段，保证服务端释放TCP连接。
2. **还为了防止已失效的连接请求报文段突然又传送到服务端，建立了多余的连接，造成资源的浪费。**设置2MSL，可以使本次TCP连接持续的时间内所产生的报文段在网络中消失，确保下一个新的连接不会出现这种旧的连接请求报文段。

### 2.1. 如何查看TIME-WAIT状态的连接数量？

netstat -an | grep TIME_WAIT | wc -l

### 2.2. 为什么会TIME-WAIT过多？如何解决？

- 可能原因：在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接时，会出现大量socket处于TIME-WAIT状态。此时如果客户端的并发量持续很高，那么部分客户端就可能显示连接不上。
- 解决：

1. vim /etc/sysctl.conf，打开系统的TIME-WAIT重用和快速回收。

```shell
# 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
net.ipv4.tcp_tw_reuse = 1
# 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。
net.ipv4.tcp_tw_recycle = 1
```

2. /sbin/sysctl -p，使参数生效。

### 2.3. TCP报文段格式？

![1620179962619](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620179962619.png)

> TCP报文首部占用20~60字节。

- **源端口和目的端口**：各占2个字节，分别写入源端口号和目的端口号，实现TCP分功能。两个值分别加上IP首部的源端IP地址和目的端IP地址，可以唯一确定一个TCP连接。
- **序号**：占4个字节，范围[0，2^32  - 1]，使用mod 2^32运算，n序号表示第n字节，共可表示2^40位（4GB）数据。
- **确认号**：占4个字节，表示期望收到对方下一个报文段的第一个数据字节的序号。若确认号=N，则表明到序号N-1为止的所有数据都已正确收到。
- **数据偏移**：占4位，指TCP报文段的数据起始处，距离TCP报文段的起始处有多远即TCP报文段的**首部长度**。单位是32位字（4个字节），而4位二进制最大表示15，意味着**TCP首部长度最大长度为60字节**（即选项长度不能超过40字节）。
- **保留**：占6位，保留为今后使用，目前应置为0。
- **标志字段**：各占1位，共6位
  - **紧急URG**：URGent，当URG=1时，表名**紧急指针**有效，需要与**紧急指针**配合使用。URG告诉系统，此报文段中有紧急数据，应尽快传送（相当于高优先级的数据），而不要按原来的排队顺序来传送。
  - **确认ACK**：ACKnowledgment，仅当ACK=1时确认号有效，TCP规定，在连接建立后，所有传送的报文都必须把ACK置为1。
  - **推送PSH**：PuSH，发送方TCP把PSH置为1，则应该立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，则应该尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。
  - **复位RST**：ReSeT，当RST=1时，表明TCP连接出现严重差错，必须释放连接再重新建立连接。
  - **同步SYN**：SYNchronization，在连接建立时用来同步序号。SYN=1，表示这是一个连接请求或连接接受报文。
  - **终止FIN**：FINish，用来释放一个连接。当FIN=1时，表明此报文段发送方的数据已发送完毕，并要求释放连接。
- **窗口**：占2个字节，[0, 2^16 - 1]，指的是发送本报文段的一方的接收窗口，指明从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。窗口值作为接收方让发送方设置其发送窗口的依据，经常动态变化着。
- **检验和**：占2个字节，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。
  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方：取12位TPC伪首部+TCP首部+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
  - 接收方：取12位TPC伪首部+TCP首部（此时检验和已经不是全0了）+TCP报文段数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

![1620126724402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620126724402.png)

- **紧急指针**：占2个字节，紧急指针仅在**URG=1**时才有意义，指出本报文段中紧急数据的字节数（序号值+字节数=偏移量），即指出了紧急数据的末尾在报文段中的位置。窗口为零时也可发送紧急数据。
- **选项**：长度可变，最大可达40字节。常见的有**最大报文段长度MSS**、**窗口扩大选项**、**时间戳选项**、**选择确认选项**等。

### 2.4. UDP用户数据报格式？

![1620182389880](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620182389880.png)

> UDP报文首部占8个字节。

- **源端口**：占2字节，源端口号，在需要对方回信时选用，否则全0。

- **目的端口**：占2个字节，目的端口号，在终点交付报文时必须使用。

- **长度**：占2个字节，UDP用户数据报的长度，最小值是8（仅有首部时），最大表示2^16 - 1=65535个字节。

- **检验和**：占2个字节，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。

  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方：取12位UDP伪首部+UDP首部+UDP用户数据报的数据部分，对其16位字使用**二进制反码求和运算**， 把结果**取反**写入检验和字段。
  - 接收方：取12位UDP伪首部+UDP首部（此时检验和已经不是全0了）+UDP用户数据报的数据部分，对其16位字使用**二进制反码求和运算**，当无差错时结果应为全1，否则就表明有差错出现。

  ![1620182690813](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620182690813.png)

### 2.5. IP数据报格式？

![1620185300666](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620185300666.png)

> IP报文首部占20~60字节。

- **版本**：占4位，指IP协议的版本。通信双方使用的IP协议版本必须一致。IPv4的版本号为4，IPv6的版本号为6。
- **首部长度**：占4位，IP分组的首部长度，单位是32位字（4个字节），最小值是5，而4位二进制最大表示15，意味着**IP分组首部长度最大长度为60字节**（即选项字段不能超过40字节）。IP分组的首部长度如果不是4字节的整数倍时，必须利用最后的填充字段加以补充。
- **区分服务**：DS，Differentiated Services，也叫服务类型。占8位，用来获得更好的服务：*最小时延、最大吞吐量、最高可靠性、最小费用*。一般情况下都不使用这个字段。
- **总长度**：占16位，[0, 2^16 - 1]，指**首部和数据之和的长度**，最大长度为65535个字节。若所传送的数据报长度超过**数据链路层MTU（最大传送单元，默认1500字节）**，就必须把过长的数据报进行分片处理，分片该字段的值也会发生改变，即此时指**分片后的每一个分片的首部长度与该分片的数据长度的总和**。*IP协议规定，在互联网中所有的主机和路由器，必须能够接受长度不超过576字节的数据报，MSS+TCP固定首部+IP固定首部=536+20+20=576字节。*
- **标识**：identification，占16位，IP软件在存储器中维持了一个计数器，每产生一个数据报计数器就+1，并将此值赋给标识字段。**相同的标识字段的值可以使分片后的各数据报片重装为原来的数据报**。
- **标志**：flag，占3位，目前只有两位有意义。
  - **最低位MF**：More Fragment，MF=1表示后面还有分片的数据报，MF=0表示这个已经是若干数据报片中的最后一个了。
  - **中间位DF**：Don't Fragment，DF=1表示不能分片，DF=0表示允许分片。
- **片偏移**：占13位，指较长的分组经过分片后，某片在原分组中的相对位置，以8个字节为偏移单位，即原偏移1400字节，偏移量=1400/8=175。
- **生存时间**：TTL，Time to Live，占8位，指数据报在网络中的寿命。现表示跳数限制，单位是**跳数**，指路由器每次转发数据报之前需要把TTL值-1，若TTL值减小到零，就丢弃这个数据报不再转发。即**TTL表明数据报在互联网中至少可经过多少个路由器**，最大值为255。
- **协议**：占8位，协议字段指出此数据报携带的数据使用何种协议，以便使目的主机IP层知道应该将数据部分上交给哪个协议进行处理。TCP为6，UDP为17。
- **首部检验和**：占16位，通过检验和的方式，接收端可以检测出数据是否有差错和异常，假如有差错，报文段就会被直接丢弃，发送方需要重新发送报文段。**只检验数据报的首部部分，不检验数据部分。**ICMP、IGMP、UDP、TCP均同时检验首部部分和数据部分。
  - **二进制反码求和运算**：
    - 0+0=0，但要产生进位1
    - 0+1=1，不需要产生进位1
    - 1+1=0，不需要产生进位1
    - 最高位产生进位1，最后结果需要+1
  - 发送方对首部部分16位字使用**二进制反码求和运算**， 把结果**取反**写入首部检验和字段。
  - 接收方对首部部分16位字使用**二进制反码求和运算**（此时首部检验和已经不是全0了），当无差错时结果取反应为全0，否则就表明有差错出现。
- **源地址**：占32位。
- **目的地址**：占32位。
- **可选字段**：最大占40个字节，用来支持排错、测量以及安全检测等措施。必要时需要用全0的填充字段来补齐成为4字节的整数倍。实际上很少被使用。

### 2.6. 以太网MAC帧格式？

![1620190340385](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620190340385.png)

> 常用的以太网MAC帧格式有两种标准，一种是DIX Ethernet V2标准（即以太网V2标准），另一种是IEEE的802.3标准，现在市场上流行的都是以太网V2的MAC帧，但大家也常常把它称为IEEE 802.3标准的MAC帧。

MAC帧首部固定长度18个字节，有效MAC帧长度=首部长度+数据长度=64~1518字节。

- **目的地址**：6个字节，是指网卡的硬件地址（MAC地址），占48位，在网卡出厂时固化。
- **源地址**：6个字节，是指网卡的硬件地址（MAC地址），占48位，在网卡出厂时固化。
- **类型字段**：2个字节，用来标志上一层使用的是什么协议，以便把收到的MAC帧的数据上交给上一层的协议。*如值为0x0800，就表示上层的是IP数据报。*
- **数据字段**：长度在46~1500字节，46=64-18，1500=**以太网最大传输单元MTU**。当数据字段的长度小于46字节时，MAC子层会在数据字段后面加入一个整数字节的填充字段，以**保证以太网MAC帧不小于64字节**。上层协议具有识别有效的数据长度长度的功能，比如IP层就可以把填充的字节丢弃掉。
- **帧检验序列FCS**：使用CRC检验。

从MAC子层向下传到物理层时，还要在帧的前面插入8个字节（由硬件生成）

- 前7个字节是**前同步码**（1和0交替码），作用是使接收端的适配器在接收MAC帧时能够迅速调整其时钟频率，使它和发送端的时钟同步，也就是实现位同步（比特同步）。
- 最后一个字节是**帧开始界定符**，定义为10101011，最后两个连续的1表示MAC帧马上要开始了。

> 在以太网上传送数据时是以**帧**为单位传送的，各帧之间还必须有一定的间隙。
>
> 由于存在**帧开始界定符**，所以以外网不需要使用帧结束定界符，也不需要使用字节插入来保证透明传输。
>
> **以太网不负责重传丢弃的帧。**

### 2.7. 子网掩码的作用？

为了能够从IP数据报的首部看出源主机或目的主机所连接的网络是否进行了子网划分。

### 2.8. OSI与TCP/IP模型？

![1620196369515](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620196369515.png)

> OSI七层体系协议结构概念请求、理论完整，但既复杂又不使用。
>
> TCP/IP四层体系结构使用更为广泛。
>
> 五层协议体系结构总和了OSI和TCP/IP的优点，为介绍网络原理而设计出来的。

- OSI七层模型：物理层、数据链路层、网络层、运输层、会话层、表示层、应用层
- TCP/IP四层模型：网络接口层、网际层、运输层、应用层
- 五层协议模型：物理层、数据链路层、网络层、运输层、应用层
  - **物理层**：physical layer，以**比特**为单位，负责在发送双方**传送1和0**。
  - **数据链路层**：data link layer，以**帧**为单位，负责在两个相邻结点之间的链路上**传送帧**，包括控制信息（如同步信息、地址信息、差错控制等）。
  - **网络层**：network layer，以**IP数据报**为单位，负责为在分组交换网上的不同主机提供**通信服务**。在发送数据时，把运输层产生的报文或用户数据报封装成IP数据报进行传送。
  - **运输层**：transport layer，TCP以**报文段**为单位，UDP以**用户数据报**为单位，负责向两台主机中进程之间的通信提供**通用的数据传输服务**。
  - **应用层**：application layer，以**报文**为单位，负责通过应用进程之间的交互来完成**特定网络应用**。

### 2.9 常见的网络服务分层示例

| 分层       | 示例                                |
| ---------- | ----------------------------------- |
| 物理层     | 中继器、集线器                      |
| 数据链路层 | 网卡、网桥、交换机                  |
| 网络层     | 路由器、防火墙、ARP、IP、ICMP、IGMP |
| 运输层     | TCP、UDP                            |
| 应用层     | HTTP、SMTP、DNS、FTP                |

- **ARP**：Address Resolution Protocol，地址解析协议，从网络层使用的IP地址，解析出在数据链路层使用的硬件地址。
- **ICMP**：Internet Control Message Protocol，网际控制报文协议，允许主机或路由器报告差错情况和提供有关异常情况的报告，可以更有效地转发IP数据报，提高交付成功的机会。
- **IGMP**：Internet Group Management Protocol，网际组管理协议，让连接在本地局域网上的多播路由器**知道**本局域网上是否有主机（即主机中的某个进程）参加或退出了某个多播组。

### 3.0. TCP拆包、粘包？原因？解决方法？

- **TCP拆包**：

  - **概念**：如果要发送的数据包过大，就会被拆分成多个TCP报文分开传输，即**一个完整的包可能会被TCP拆分成多个包进行发送**。
  - **直接原因**：
    - 应用程序写入的数据大于套接字缓冲区的大小。
    - TCP报文段的数据部分长度大于MSS(536字节)，导致在IP层传输被分解成多个短的数据报片。
  - **根本原因**：网络层所收到上层交付的数据报长度，超过**数据链路层MTU（最大传送单元，默认1500字节）**，需要把过长的数据报进行IP分片处理。

- **TCP粘包**：

  - **概念**：**多个小的包可能会被TCP封装成一个大的数据包发送**。
  - **直接原因**：
    - 应用程序写入的数据小于套接字缓冲区的大小
    - 接收方不及时读取套接字缓冲区数据
  - **根本原因**：
    - **发送方原因**：TCP默认使用**Nagle算法**（通过减少必须发送包的个数，来增加网络软件系统的效率），即TCP会收集多个小分组，在一个确认到来时才一起发送，导致可能在发送方出现粘包问题。
    - **接收方原因**：TCP将接收到的数据包保存在接收缓存里，如果TCP接收数据包到缓存的速度，大于应用程序从缓存中读取数据包的数据，那么多个包就会被缓存起来，而应用程序就有可能读取到多个首尾相连粘在一起的包。
    - **TCP原因**：TCP是**面向字节流**的协议，报文格式不像UDP那样有专门的长度字段来记录实际报文的长度，交付上层的数据没有边界，导致粘包的发生。

- **解决方法**：

  最本质的原因在于**接收方无法分辨消息与消息之间的边界在哪**，因此，思路就是，通过某种方案给出边界。

  - **消息定长，空格补位**：每个消息的大小都一样，接收方只要累计接收数据，直到数据等到一个定长的指就将它作为一个消息。
  - **包尾加特殊字符作为边界**：比如FTP协议就是在包尾加上\r\n标记作为边界的。但问题在于通信双方要约定在数据正文中，不出现该特殊字符，否则会误判为消息的边界。
  - **包首部记录包体长度**：每个包首部至少包含数据包的长度，这样接收方可以通过读取包首部的长度字段，就知道每一个包的实际长度。

### 3.1. HTTP是什么？

HTTP，hypertext Transfer Protocol，超长文本传输协议，是一个**通常运行在TCP之上的**应用层协议，定义了浏览器怎么向万维网服务器请求万维网文档以及服务器怎么把文档传送给浏览器。

- **事务**：指一系列的信息交换是一个不可分割的整体，即要么所有的信息交换都完成，要么一次交换都不进行。
- **无连接**：指通信双方在交换HTTP报文之前不需要先建立HTTP连接。
- **无状态**：指同一个客户第二次访问同一个服务器上的页面时，服务器的响应与第一次访问时的相同（假设不会更新）。

### 3.2. HTTP协议/1.0/1.1/2.0？

- **HTTP/1.0**：
  - **概述**：每一个请求建立一个TCP连接，请求完成后立马断开连接（**短连接**）。
  - **缺点**：
    - **连接无法复用**，每次请求都要经历三次握手和慢启动，导致在并发量大的情况下服务器的压力负担大，以及带宽无法被充分利用。
- **HTTP/1.1**：
  - **概述：**多个http请求可以复用一个TCP连接，使用Connection Header（close/keep-alive）来区分**短/长连接**。服务器按照FIFO原则来处理不同请求。
  - **缺点**：在同一时间，针对同一域名下的请求有一定的限制，超过限制数目的请求会被阻塞。
- **HTTP/2.0**：
  - **概述**：**多路复用**（二进制帧的设计）允许同时通过单一的连接发起多重的请求-响应信息，可以很容易地去实现并行地在同一个TCP连接上双向交换信息，而不用依赖建立多个TCP连接。
  - **缺点**：普及速度慢，与HTTP1.1并存。

### 3.3. HTTP/1.0/1.1的主要区别？

1. **长连接**：减少了建立和关闭连接的消耗和延迟。
2. **Host头处理**：支持Host头域，不在以IP为请求方标志，解决一台物理机存在多个虚拟主机，共享IP地址的问题。
3. **错误状态码增多**：1.1新增了24个错误状态响应码，更加明确各个状态，如409（表示请求的资源与资源当前状态发生冲突）、410（表示服务器某个资源被永久性的删除）。
4. **网络连接的优化**：1.1支持断点续传，在请求头引入range头域（允许只请求资源的某个部分，返回码206），方便充分利用带宽和连接。
5. **提供更多的缓存控制策略**：

| 缓存控制头          | 解释                                                         | 备注     |
| ------------------- | ------------------------------------------------------------ | -------- |
| If-Modified-Since   | 允许在对应的资源未被修改的情况下，返回304未修改              | 1.0、1.1 |
| Expires             | 指定一个日期/时间，超过该时间则认为此响应已过期              | 1.0、1.1 |
| ETag                | Entity tag，对于某个资源的某个特定版本的一个表示符，通常是一个消息三列 | 1.1新增  |
| If-Unmodified-Since | 仅当该实体某个特定时间以来未被修改的情况下，才发送响应。     | 1.1新增  |
| If-Match            | 仅当客户端提供的实体与服务器对应的实体相匹配时，才进行对应的操作。主要用于PUT这样的方法中，仅当从用户上次更新某个资源后，该资源未被修改的情况下，才更新该资源。 | 1.1新增  |
| If-None-Match       | 允许在对应的内容未被修改的情况下，返回304未修改              | 1.1新增  |

### 3.4 HTTP/1.1/2.0的主要区别？

1. **多路复用**：2.0连接共享，不同的Request可以使用同一个连接传输，最后根据每个Request id组合成正常的请求。
2. **新的传输格式**：2.0使用二进制格式（基于二进制帧的设计），1.0依然使用基于文本的格式（基于文本分割解析）。
3. **Header压缩**：由于1.X中Header带有大量的信息，并且得重复传输，2.0使用Encoder来减少需要传输的Header大小。
4. **服务端推送**：2.0中，服务器可以对客户端的一个请求发送多个响应。

### 3.5. HTTPS连接的建立过程？

> HTTPS，Hyper Text  Transfer Protocol over SecureSocket Layer，是以安全为目标的HTTP通道，在HTTP的基础上通过传输加密和身份认证保证传输过程的安全性。

- HTTPS在内容传输的加密上使用的是**对称加密**（速度快），在证书验证阶段使用**非对称加密**（安全性高）。
- **对称加密**：双方持有**相同的密钥**，加密速度快。典型的对称加密算法有：DES、AES**。**
- **非对称加密**：**密钥成对出现（私钥和公钥）**。私钥只有自己知道，不在网络中传输。公钥可以公开，A使用B公钥加密后，B使用B的私钥解密。加密速度慢。典型的非对称加密算法有：RSA、DSA。

1. **发起请求**：首先客户端将它所支持的算法列表和一个用作产生密钥的**随机数1**发送给服务器。
2. **返回证书**：服务器从算法列表中选择一种算法，并将它和一份包含**服务器公钥**的证书以及**随机数2**返回给客户端，包含用于认证目的的服务器标识。
3. **证书验证**：客户端对服务器的证书进行验证（**数字签名**），抽取**服务器公钥**，再产生一个**预主密钥（pre_master_secret）**的随机密码串 + **服务器公钥**，使用非对称加密，将**加密后的信息**发送给服务器。此时，客户端使用**随机数1、随机数2、预主密钥**，独立计算出**加密和MAC密钥**，作为接下来的**会话密钥**。
4. **服务器解密**：服务器通过**服务器私钥**对传送过来的加密信息进行解密，得到**预主密钥**，与**随机数1、随机数2**独立计算出**加密和MAC密钥**，作为接下来的**会话密钥**。
5. **客户端发起测试**：客户端将握手消息经过**会话密钥**使用对称加密得到的MAC值发送给服务端，验证服务器能否正常接受客户端加密的消息。
6. **服务器响应测试**：服务器将握手消息经过**会话密钥**使用对称加密得到的MAC值返回给客户端，如果客户端能够接受并返回确认报文的MAC值，则SSL层建立完成。

### 3.6. HTTP与HTTPS的区别？

| HTTP                           | HTTPS                                     |
| ------------------------------ | ----------------------------------------- |
| 默认端口80                     | 默认端口443                               |
| URL以http://开头               | URL以https://开头                         |
| 明文传输、数据未加密、安全性差 | 传输过程SSL加密、安全性好、需要用到CA证书 |
| 消耗资源少、响应速度快         | 消耗资源多、响应速度慢                    |

### 3.7. HTTP请求报文有哪些方法？

| 方法    | 描述                                                     |
| ------- | -------------------------------------------------------- |
| GET     | 向特定资源发送请求，查询数据并返回实体                   |
| POST    | 向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |
| PUT     | 向服务器上传新的内容                                     |
| HEAD    | 类似于GET请求，返回的响应中没有具体的内容，用于获取报头  |
| DELETE  | 请求服务器删除特定的资源                                 |
| OPTIONS | 可以用来向服务器发送请求，来测试服务器的功能特性         |
| TRACE   | 回显服务器收到的请求，用于测试或者诊断                   |
| CONNECT | 用于代理服务器                                           |

### **3.8. Get和Post请求区别**？

|          | GET                                                          | POST                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 可见性   | 数据在URL中，所有人可见                                      | 数据不会显示在URL中                                          |
| 安全性   | 发送的数据是URL的一部分，安全性较差                          | 参数不会被保存在浏览器历史或者web服务器日志中，安全性较好    |
| 数据长度 | 受限制，最大2KB=2^10字节                                     | 无限制                                                       |
| 编码类型 | application/x-www-form-urlencoded                            | multipart/form-data                                          |
| 缓存     | 能被缓存，会保存在浏览器的浏览记录中，URL能够被作作为书签保存 | 不能被缓存                                                   |
| 意义     | 用于向特定资源发送请求，查询数据并返回实体                   | 用于向服务器添加信息，可能会导致新的资源建立或已有资源的修改 |

### 3.9. HTTP常见响应状态码？

> 1xx表示通知信息，如请求收到了或者正在进行处理。
>
> 2xx表示成功，如已接受或已知道。
>
> 3xx表示重定向，如要完成请求还必须采取进一步的行动。
>
> 4xx表示客户的差错，如请求中有错误的语法或者不能完车。
>
> 5xx表示服务器的差错，如服务器失效无法完成请求。

- 100：Continue，继续，客户端应继续请求。
- 200：OK，请求成功，一般用于GET和POST请求。
- 301：Move Permanently，资源永久重定向。
- 302：Found，资源暂时重定向。
- 400：Bad Request，客户端请求的语法错误，服务器无法理解。
- 403：Forbidden，服务器理解客户端的请求，但是拒绝执行此请求。
- 404：Not Found，服务器无法根据客户端的请求找到资源。
- 500：Internal Sever Error，服务器内容错误，无法完成请求。
- 502：Bad Gateway，作为**网关或者代理服务器**尝试执行请求时，从远程服务器中接收到了无效的响应。

### 4.0. 重定向与转发的区别？

|            | 重定向（Redirect）                                     | 转发（Forward）                                   |
| ---------- | ------------------------------------------------------ | ------------------------------------------------- |
| 地址栏路径 | 发生变化                                               | 不变                                              |
| 其他站点   | 可以访问其他站点（服务器）的资源                       | 只能访问当前服务器下的资源                        |
| 请求的次数 | 是两次请求，不能使用Request域对象来共享数据            | 是同一次请求，共享同一个Request域对象             |
| 效率       | 速度慢                                                 | 速度快                                            |
| 执行主体   | web容器，在同一个web容器中转发，对于客户端来说是透明的 | 客户端，服务器返回302状态码，客户端执行重定向操作 |

### 4.1. Cookie与Session的区别？

|          | Cookie                                                       | Session                                                      |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 共同点   | 用来跟踪浏览器用户身份                                       | 用来跟踪浏览器用户身份                                       |
| 位置     | 保存在客户端（浏览器）                                       | 保存在服务端                                                 |
| 安全性   | 不是很安全，可以分析本地的Cookie进行欺骗                     | 较安全                                                       |
| 作用     | 一般用来保存信息                                             | 记录用户的状态                                               |
| 产生机制 | 服务器通过设置响应头提示浏览器生成或者直接使用客户端脚本产生，然后请求时可以发送给服务器 | 客户端请求时，一般服务器会创建JSessionId标识，存放session值到散列表中 |

### 4.2. 在浏览器输入URL再回车确认后发生了什么？

URL判断、DNS查询、TCP连接、浏览器发起HTTP请求、服务器处理并响应HTTP请求、浏览器渲染页面

| 过程              | 过程                                                         | 使用的协议 |
| ----------------- | ------------------------------------------------------------ | ---------- |
| 1、URL判断        | 浏览器判断URL是否合法                                        | 无         |
| 2、DNS查询        | 浏览器查找DNS得到域名对应的IP地址，查找过程：浏览器缓存 -> 操作系统缓存 -> 路由器缓存 -> DNS缓存 -> 域名服务器 | DNS        |
| 3、TCP连接        | 根据IP地址与端口建立TCP连接                                  | TCP        |
| 4、HTTP请求       | 浏览器向服务器发送HTTP请求                                   | HTTP       |
| 5、响应HTTP请求   | 服务器处理并响应HTTP请求                                     | HTTP       |
| 6、浏览器渲染页面 | 浏览器接收HTTP响应并渲染页面                                 | 无         |

### 4.3. HTTP请求与响应报文格式？

![1620215152917](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620215152917.png)

- **开始行**：用于区分是请求报文还是响应报文。在请求报文中的开始行叫做**请求行**，在响应报文中的开始行叫**状态行**。开始行的**三个字段都以空格隔开**，最后的“CR”与"LF”分别代表"回车"和“换行”。
  - 请求报文：方法、URL、版本
  - 响应报文：版本、状态码、短语
- **首部行**：用来说明浏览器、服务器或者主体的一些信息，可以有好几行，也可以不用。每一个首部行都以CRLF结尾。在整个首部行结束时，**还有一空行将首部行和实体主体分开**。
- **实体主体**：请求包体或者响应包体。

## 2. 加解密基础

### 1.1. 常见签名与加密相关用语？

#### 1. 转义

转义字符能使其开头的序列具有不同于普通字符数列的语义。常见作用有：

- 如果不进行转义就可能与语法规定的某些**内容产生混淆**，所以某些内容需要转义。如Java的转义字符"\\"，用来区分字符串中，哪些是分割符，哪些是字符本身。
- 字符引用，用于转义键盘录入的字符，如字符串中的回车符和换行符，使其不可见，从而更容易表达其他内容。

#### 2. 编码解码

编码是采用一种新的载体来表示前一个载体所表达的信息，本质上是信息形式的转换，并没有保密的作用（因为编解码算法是公开的），目的是将信息转换成统一的格式，方便在不同系统中传输。

eg：信息 -> 编码 -> 二进制 -> 解码 -> 信息

*如果解码之后无法正确还原原来所表达的信息，此时就出现了**乱码**。通常是因为选用的解码和编码方式不同所导致的。*

常见编码类型有：

- **文本文件编码**：
  - 作用：将文本内容编码为**二进制数据**，以实现二进制数据进行存储或者传输的目的。
  - 相关技术：ASCII（1字节）、ISO8859-1、GBK（汉字2字节）、GBK2312、UTF-8（汉字0到4字节）、UTF-16、UTF-32等。
- **可打印字符编码**：
  - 作用：将二进制数据编码为**可打印的字符**，以实现通过可打印字符的形式进行存储或者传输的目的。
  - 场景：Web场景（图片）、公钥证书、电子邮件附件等（因为ASCII码128~255字符不可见，不方便路由传输）。
  - 相关技术：HEX、Base64等。
    - HEX：16进制字符，只有字母A~F，4位一组。
    - Base64：a-zA-Z0-9+=，64个字符，6位一组，再对照ASCII码表。

![1620302838656](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620302838656.png)

```java
        // 1、编码技术: 很多消息摘要、加解密算法都是针对二进制的
        try {
            // Base64编码: Q0FG => 6位一组, 3 * 8 = 4 * 6, 压缩率比HEX高, 可能会出现+、=符号
            String base64Str = Base64.getEncoder().encodeToString("CAF".getBytes("ASCII"));
            System.err.println(base64Str);

            // Base64解码: CAF
            String base64Org = new String(Base64.getDecoder().decode(base64Str), "ASCII");
            System.err.println(base64Org);
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }
```

- **URL编码**：
  - 作用：通过使用安全的字符去表示不安全字符从而达到适合传输的目的。
  - 场景：作为URL参数时：中文、空格、&、？、=

#### 3. 消息摘要

- 作用：为了校验**信息的完整性**，保证信息在传输过程中不被篡改。
- 场景：校验密码是否正确、校验下载文件是否完整无损。
- 相关技术：MD5（32字符16字节定长）、SHA、SHA256等。
- 特点：无法逆推、（优秀的Hash算法）结果定长、碰撞率低、相同输入相同输出、不同输入输出千差万别。
- 缺点：简单的摘要可通过穷举、撞库的方式得到原文，因此需要加盐增加算法的安全度。

```java
        // 2、消息摘要: 16字节, MD5、SHA, 哈希的算法, 单向的不能逆推, 优秀的哈希产生的结果是定长的, 碰撞率比较低, 少量Hash就千差万别
        // 作用: 用于验证原消息是否有改变、不同输入不同输出、相同输入相同输出、在数字签名中可以用来证明消息没被别人篡改过
        String input = "hello world";

        // MD5国内一般都使用HEX格式编码, 但事实上Base64也可
        System.err.println(MD5(input));// HEX是一个字符占4位, 16个字节, 共32个字符 => 5EB63BBBE01EEED093CB22BB8F5ACDC3
        System.err.println(MD5(MD5(input) + "加盐"));// MD5加盐(随机字符串), 极大加强安全性: 1FEED1AECF760C313879517FA3A8F2B6
        System.err.println(SHA1(input));// HEX是一个字符占4位, 20个字节, 共40个字符 => 2AAE6C35C94FCFB415DBE95F408B9CE91EE846ED
        System.err.println(SHA256(input));// HEX是一个字符占4位, 32个字节, 共64个字符 => B94D27B9934D3E08A52E52D7DA7DABFAC484EFE37A5380EE9088F7ACE2EFCDE9
```

```java
// MD5消息摘要
    public static String MD5(String str) {
        try {
            MessageDigest md5 = MessageDigest.getInstance("MD5");// 算法类型
            md5.update(str.getBytes("UTF-8"));// 字符集
            byte[] digest = md5.digest();// MD5范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA1不太安全
    public static String SHA1(String str) {
        try {
            MessageDigest SHA1 = MessageDigest.getInstance("SHA");
            SHA1.update(str.getBytes("UTF-8"));
            byte[] digest = SHA1.digest();// SHA1范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }

    // SHA256比较安全
    public static String SHA256(String str) {
        try {
            MessageDigest SHA256 = MessageDigest.getInstance("SHA-256");
            SHA256.update(str.getBytes("UTF-8"));
            byte[] digest = SHA256.digest();// SHA256范围到此为止
            return DatatypeConverter.printHexBinary(digest);
        } catch (NoSuchAlgorithmException e) {
            // do nothing
        } catch (UnsupportedEncodingException e) {
            // do nothing
        }

        return null;
    }
```

#### 4. 加密解密

对原来的明文按照某种算法进行处理，使其成为不可读的一段代码，即密文。

- 作用：保护数据不被非法人窃取、阅读，保证发送**消息的保密性**。

- 算法类型：

  - **对称加密**：
    - 概念：加密和解密时使用的**密钥是同一个**，因此又称为共享密钥加密算法。
    - 优点：算法公开、计算量小、速度快、效率高。
    - 缺点：发送双发使用相同的密钥，密钥容易泄露，安全性较弱。
    - 相关技术：DES（速度快、容易被破解）、AES（难以被破解）等。
  - **非对称加密**：
    - 概念：加密和解密使用**不同的密钥**，包含一个公开密钥（公钥）和一个私有密钥（私钥），因此又称为公开密钥加密算法。
    - 优点：密钥成对出现，且私钥存在传输泄露的风险，大大增加了安全性。
    - 缺点：算法复杂，速度远远低于对称加密算法、不适用于数据量较大的场景。
    - 相关技术：RSA等。

  *注意点：算法类型、字符集、使用哪个密钥、编码类型*

```java
        // 3、加密算法: RSA跨平台, 不推荐使用JAVA方式(PKCS8)来生成私钥和公钥, 推荐用OPEN SSL(Git Hub)方式生成(PKCS1 | PKCS8)
        //      1) 对称加密: 收发双方约定同一个Key, Key被劫持了就不安全了
        //      2) 非对称加密: 收发双发约定一对Key, 只把一半在网上流传, 另一半不流传
        // RSA非对称加密默认使用Base64格式编码
        String publicKeyStr = "MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDTse/HAlvTdgaUn4uCFiC6o++G\n" +
                "SPQ9XN3DjBOyitzOO0atlTG68KZnhEoUMZGJ2grKgWu49xjV8XY+8AUziAZfFJ5g\n" +
                "LXN/e9QuJ+yLm7hPfEmOAZorGLLxUV1ms266RqD9V9l2UJGlmVqo4ZV9pRnbxW8a\n" +
                "7sh2iR/2pIM5p3atiwIDAQAB";
        String privateKeyStr = "MIICdwIBADANBgkqhkiG9w0BAQEFAASCAmEwggJdAgEAAoGBANOx78cCW9N2BpSf\n" +
                "i4IWILqj74ZI9D1c3cOME7KK3M47Rq2VMbrwpmeEShQxkYnaCsqBa7j3GNXxdj7w\n" +
                "BTOIBl8UnmAtc3971C4n7IubuE98SY4BmisYsvFRXWazbrpGoP1X2XZQkaWZWqjh\n" +
                "lX2lGdvFbxruyHaJH/akgzmndq2LAgMBAAECgYEAgKkZeNNXKdsGvteEu4hlVeoC\n" +
                "zpOSVaUWZx3Abvf0oSbnmuIdOme+SxXczA8gTC8H9fHYna8YGhdJ7ZCFKL+YVqA3\n" +
                "y3ytx3VPcUR/DIexfsUKTQwxWbmwFOXjimHd1EOWglhP16jX+JqJdcYO8WUDaYJY\n" +
                "fII+52w4IBqXQzV0ROECQQDsjP6eVx+ocT3vPWKuO4k68xNIbJYv0rI6OUirq+iW\n" +
                "fEyt+qQg46p7cVcwjVy+smTEOcALljGp3qvBF+c9cEgbAkEA5RnFOnG4OWfEkzPF\n" +
                "bJPqZ49E59Yt6Gh0EC163IzFtirB/GMumrT70Gs1vItrZb8iYuhaK1uZB0lJLJPB\n" +
                "ppdnUQJBAKVa2hHtbR/eKSE3k+efjoo6qNwTq9i6PAQfTwFSJkArm55yepDTFLU9\n" +
                "wWkbKB3VrkLM68Yts4G/Oei8wNRdzMkCQE6LwE/iTzv3NLEXLdek+teYihJGHyUw\n" +
                "MqKdRSM6bEqhbDKguoi2BiOVri2/SwnuNtbcPJXi6JtT5++NlPYNsJECQAsU+Ama\n" +
                "zDNyx8oq/s/JmB/jk6HmNMUaujsBd4N3yvO9awaLEgeghD02lIa0smd9qgqLVhm8\n" +
                "rl0xPQV91p5pcFU=";

        // 如果不采用读文件的, 需要手动清理IDE加的"\n"
        publicKeyStr = publicKeyStr.replace("\n", "");
        privateKeyStr = privateKeyStr.replace("\n", "");

        String rsaEncryptStr = rsaEncrypt(input, toPublicKey(publicKeyStr));
        System.err.println(rsaEncryptStr);// UdYxJbZirWPDAHhIaTLA4q6jrdh0MWNu+OFZaAP5rZqvR9Vzynl53uyUe6OisyRxHS++q8EnHu6hEaFGdJNimuZ99yo0Lpq8AxudlUd7j9JvFd2EmAo+phA1KnC+SHn1BOF6qYVymhjxnsWnB2IHACIcFhWcHinC7txSVjZHQo0=
        String rsaDecryptStr = rsaDECRYPT(rsaEncryptStr, toPrivateKey(privateKeyStr));
        System.err.println(rsaDecryptStr);// hello world
```

```java
// Java生成RSA非对称加密公钥对象
    public static PublicKey toPublicKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(bytes);// 公钥统一标准X509编码
            return keyFactory.generatePublic(x509EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java生成RSA非对称加密私钥对象
    public static PrivateKey toPrivateKey(String str) {
        try {
            KeyFactory keyFactory = KeyFactory.getInstance("RSA");// 算法类型
            byte[] bytes = Base64.getDecoder().decode(str);// OPENSSL 生成的RSA公钥采用Base64编码
            PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(bytes);// JAVA私钥只能读PKCS8格式
            return keyFactory.generatePrivate(pkcs8EncodedKeySpec);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeySpecException e) {
            e.printStackTrace();
        }

        return null;
    }

   // RSA非对称加密
    public static String rsaEncrypt(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.ENCRYPT_MODE, key);// 加密模式
            byte[] bytes = str.getBytes("UTF-8");// 字符集
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // RSA通常使用Base64编码
            return Base64.getEncoder().encodeToString(doFinal);
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        }

        return null;
    }

    // RSA非对称解密
    public static String rsaDECRYPT(String str, Key key) {
        try {
            Cipher cipher = Cipher.getInstance("RSA");// 算法类型
            cipher.init(Cipher.DECRYPT_MODE, key);// 解密模式
            byte[] bytes = Base64.getDecoder().decode(str);// RSA通常使用Base64编码
            byte[] doFinal = cipher.doFinal(bytes);// RSA范围到此为止

            // 这里采用UAT-8字符集
            return new String(doFinal,"UTF-8");
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (NoSuchPaddingException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (BadPaddingException e) {
            e.printStackTrace();
        } catch (IllegalBlockSizeException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }

        return null;
    }
```

#### 5. 数字签名

- 作用：身份认证发送方，具有消息的不可抵赖性，同时保证消息的完整性。
- 相关技术：消息摘要算法 + 加密解密算法。

```java
        // 4、数字签名: 散列+加密 = 消息摘要 + 非对称加密
        //      1) 证明消息没被别人篡改过 => 消息摘要
        //      2) 证明确实是发送方发过来的 => 非对称加密, 使用自己的私钥加密消息
        String sign = rsaSign(toPrivateKey(privateKeyStr), input);
        System.err.println(sign);// PDhFYAx3FSIajHFYwP35PInipQxmFA/qtuCJXPALOoUf2nZlIC3Xt9qfSK/hovhhXBIuOSReTnKLCHDuvXJ0rfNVC1SqO4yYl5PXeiHgOjUj18VLxKyId0H9Z4+L47Uhb3JSsNv+X8trE6Q4dDj29xjVeVEBkfsKYdqjc8QxSPQ=
        boolean res = rsaVerifySign(toPublicKey(publicKeyStr), input, sign);
        System.err.println(res);// true
```

```java
    // Java利用MD5WithRSA实现数字签名, 一定要用自己的私钥进行数字签名
    public static String rsaSign(PrivateKey privateKey, String str) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initSign(privateKey);// 初始化私钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] sign = signature.sign();// 数字签名范围到此为止
            return Base64.getEncoder().encodeToString(sign);// 通常数字签名使用Base64编码
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return null;
    }

    // Java利用MD5WithRSA实现数字验签, 一定要用对方的公钥进行验签
    public static boolean rsaVerifySign(PublicKey publicKey, String str, String sign) {
        try {
            Signature signature = Signature.getInstance("MD5WithRSA");// 算法类型
            signature.initVerify(publicKey);// 初始化公钥
            signature.update(str.getBytes("UTF-8"));// 数据字符集采用UTF-8
            byte[] bytes = Base64.getDecoder().decode(sign);// 通常数字签名使用Base64编码
            return signature.verify(bytes);// 数字验签范围到此为止
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        } catch (InvalidKeyException e) {
            e.printStackTrace();
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        } catch (SignatureException e) {
            e.printStackTrace();
        }

        return false;
    }
```

### 1.2. 数字签名与数据加密的区别？

- **数字签名**：

![1620308002223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620308002223.png)

1. 发送方先使用Hash函数对将要发送的明文生成**消息摘要**。
2. 发送方使用**自己的私钥**签名消息摘要，生成**已签名的消息摘要**。
3. 发送方把将要发送的**明文**和**已签名的消息摘要**，一起发送给接收方。
4. 接收方再使用**发送方的公钥**对收到的**已签名的消息摘要**进行验证，验证通过可以得到原始的消息摘要。此步验证了**发送方的身份**。
5. 接收方使用相同的Hash函数对收到的**明文**生成**消息摘要**，与解密出来的消息摘要进行比对，判断两者是否一致。此步验证了**消息的完整性**。

- **数据加密**：

（基于大质数分解数学原理的非对称加密，一般大的数值对作为私钥，小的数值对作为公钥）

![1620305224976](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305224976.png)

![1620305447877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305447877.png)

1. 发送方先生成一个**对称密钥**，使用此密钥将对称加密将要发送的明文，生成密文。
2. 发送方使用**接收方的公钥**非对称加密上述生成的**对称密钥**，生成加密后的密钥。
3. 发送者将**密文**与**加密后的密钥**（*成为数字信封*），一起发送给接收方。
4. 接收者使用**自己的私钥**解密加密后的密钥得到原始的**对称密钥**，再用该对称密钥解密密文，得到真正的明文。

- **数字签名与数据加密的区别**：（共同点：都使用了公开密钥体系）

|                    | 数字签名                                                     | 数据加密                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 加密方式（发送时） | 使用发送方的私钥                                             | 使用接收方的公钥                                             |
| 解密方式（接收时） | 使用发送方的公钥                                             | 使用接收方的私钥                                             |
| 映射关系           | 一对多，只有拥有私钥的才能代表发送，任何拥有公钥的人都可以解密 | 多对一，任何拥有公钥的人都可以加密发送，只有拥有私钥的才能解密成功 |
| 使用的算法         | 非对称加密                                                   | 对称加密明文、非对称加密**对称密钥**                         |
| 作用               | 保证发送的消息的**完整性、身份认证和不可抵赖性**             | 发送的消息的**保密性**                                       |

### 1.3. PKCS1与PKCS8的区别？

使用OPEN SSL生成私钥和公钥：

- **PKCS1**：
  - 概念：一种标准的生成私钥Key的方法，是RSA的密钥的原本格式。
  - 特点：BEGIN 开头：BEGIN RSA PUBLIC KEY
  - 作用：生成私钥。
  - 语法：
    - 生成私钥：genrsa -out private 1024
    - 生成公钥：rsa -in private -pubout -out public

![1620305778221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305778221.png)

![1620305830513](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305830513.png)

![1620305962240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620305962240.png)

- PKCS8：
  - 概念：用于转换私钥，在PKCS1数据上增加了一些信息，使其可存储更多的元信息。
  - 特点：与PKCS1能够相互转换、可以用于非RSA对称加密算法、JAVA只认PKCS8。
  - 语法：
    - KCS1转换成PKCS8：pkcs8 -topk8 in private -nocrypt -out private_pkcs8

![1620306139689](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620306139689.png)



## **3. 操作系统基础**

### 1.1. 进程和线程的区别？

- **进程**：是**资源分配的最小单位**。
  - 在Java中，启动main函数相当于启动一个进程，而main函数所在的线程该进程中的线程，称为主线程。
- **线程**：是**任务调度和执行的最小单位**，线程并行执行，会存在资源竞争和上下文切换的问题。
  - 在Java中，一个进程可以有多个线程，多个线程共享进程的堆和方法区资源，但不共享栈和程序计数器，每个线程有自己的本地方法栈、虚拟机栈和程序计数器。各个线程之间切换工作时，负担要比进程小得多，所以线程也被称为轻量级进程。
- **协程**：是一种比线程更加轻量级的存在，一个线程可以拥有多个协程，协程没有增加线程数量，只是在线程的基础之上通过**分用复用**的方式运行多个协程。**协程只有和异步I/O结合起来才能发挥出最大的威力**，这是因为：
  - 对于计算密集型任务本身并不需要大量的线程切换（一般只需要C + 1），此时使用协程的作用非常有限，反而还增加了协程切换的开销。
  - 由于操作线程是任务调度和执行的最小单位，即操作系统只知道线程，并不知道协程的存在，所以在协程调用阻塞I/O时，操作系统会让线程进入阻塞状态，导致绑定在该线程之上的其他协程都会陷入阻塞而得不到调度（应该启动个新的线程或者封装I/O为异步非阻塞/O）。
- *管程：指的是管理共享变量以及对共享变量的操作过程，以让他们支持并发，是一种进程同步互斥工具。*
  - 作用：解决信号量机制变成麻烦，容易出错的问题。
  - 特点：各外部进程/线程只能通过管程提供的特定入口才能访问共享数据，且每次仅允许一个进程在管程内执行某个内部过程。
  - 场景：Java中的synchronized、wait()、notify()、notifyAll()等。

### 1.2. 进程间的通信方式？

1. **管道**：亲缘关系使用无名管道，非亲缘关系使用有名管道，遵循FIFO，是**半双工**通信方式，数据只能单向流动。
   - 无名管道：pipe，管道是一种半双工的通信方式，数据只能单向流动，且只能在具有亲缘关系的进程间使用（如父子进程）。
   - 高级管道：popen，指在当前程序进程中启动另一个程序进程，把其当做是当前程序进程的子进程。
   - 有名管道：named pipe，同样是半双工，但允许无亲缘关系进程间通信。
2. **信号**：signal，信号是一种比较复杂的通信方式，用于**通知接收进程某个事情已经发送了**。比如用户调用kill命令将信号发送给其他进程。
3. **消息队列**：message queue，消息队列即消息的链表， 存放在内核中并由消息队列标识符标识，克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等特点。
4. **共享内存**：shared memory，共享内存就是映射一段能被其他进程所访问的内存。
   - 这段共享内存由一个进程创建，多个进程都可以直接读写，是**最快的IPC方式**，是针对其他进程间通信方式运行效率低而专门设计的。
   - 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。
5. **信号量**，semophore，信号量是一个计数器，用于控制多个进程对共享资源的访问，常作为**进程间以及同一进程不同线程之间的同步手段**。
6. **套接字**：socket，与其他通信机制不同，它是通信双方的一种约定，用于**不同机器间的进程通信**。

### 1.3. 核心态与用户态？

> 特权指令是拥有特殊权限的指令，用于调用系统函数或系统软件等。比如内存清理、重置时钟、分配系统资源、修改虚存段表和页表、修改用户访问权限等。
>
> 非特权指令是普通权限的指令，在程序执行时都可以调用。

核心态与用户态是两种处理器状态：

- **核心态（Kernel Mode）**：
  - 当程序运行在0特权级时（RING0~3），称之为运行在**核心态**。RING0是最高的特权级。
  - 运行操作系统程序（**内核程序**），可以**执行特权指令和执行非特权指令**。CPU可以访问内存的所有数据，包括外围设备等硬件资源。
  - 处于核心态时，进程能访问所有的内存和对象，且所占有的处理器不允许被抢占。
- **用户态（User Mode）**：
  - 当程序运行在3级特权级时（RING0~3），称之为运行在**用户态**，RING3是最低的特权级，是普通用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。
  - 运行**应用程序**，只能执行**非特权指令**。只能**受限地**访问内存。
  - 处于用户态时，进程所能访问的内存空间和对象受到限制，其所占有的处理器可能被抢占。

### 1.4. 为什么要有核心态和用户态？

- 由于特权指令权限重大，如果使用不当将会导致整个系统崩溃，为了**保证系统安全**，这类指令只能用于操作系统或者其他系统软件，不直接提供给用户使用，所以CPU状态区分为核心态和用户态：
  - 特权指令必须在核心态执行，且内核态可以使用全部指令。
  - 用户态只能使用非特权指令，当用户态下使用特权指令时，将产生中断以阻止用户使用特权指令。

### 1.5. 用户态与核心态之间的切换？

- **用户态 -> 核心态**：通过**中断**实现，且**中断是用户态到核心态的唯一途径**。
  - *这里的中断指的是广义的中断，包括异常和狭义的中断。*
  - 因为发生中断意味着需要操作系统介入，开展管理工作，而操作系统的管理工作（如进程切换、分配I/O设备等）需要使用特权指令，所以CPU需要从用户态转为核心态。**中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。**
- **核心态 -> 用户态**：通过执行一个特权指令，将程序状态字（PSW）标志位设置为用户态即可。

### 1.6. 内中断与外中断？

广义的中断可以分为内中断和外中断：

- **内中断**：也称为**异常**、例外、陷入，信号来源于CPU内部，与当前执行指令有关。
  - **陷阱、陷入**：trap，有意而为之的异常，如系统调用。
  - **故障**：fault，由错误条件引起的，可能被故障处理程序修复，如缺页中断。
  - **终止**：abort，不可修复的致命错误造成的结果，终止处理程序不再将控制返回给引入终止的应用，如整数除以0。
- **外中断**：是**狭义的中断**，信号来源于CPU外部，与当前执行的指令有关。
  - **外设请求**：如外围设备的中断，即I/O操作完成发出的中断信号。
  - **人工干预**：如用户强行终止一个进程。

### 1.7. Linux的进程地址空间？

![1620546981765](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620546981765.png)

- **栈**：stack，进程运行的栈，存储局部变量、临时变量，函数调用时，存储函数的返回指针，用于控制函数调用和返回。在程序块开始时自动分配内存，结束时自动释放内存，其操作方式类似于数据结构中的栈。
- **内存映射段**：memory mapping space（mmap），系统调用使用的空间，通常用于文件映射到内存，在进程创建时，会将程序用到的平台、动态链接库加载到该区域。
- **堆**：heap，是能够动态分配的内存空间，需要程序员手工分配，分配方式类似于链表。
- **未初始化过的数据**：bss segment，存储未初始化的全局或者静态变量。
- **初始化过的数据**：data segment，存储已经初始化的全局或者静态变量。
- **程序段**：text segment，是程序代码在内存中的映射，存放函数体的二进制代码。

### 1.9. 内存保护、覆盖技术、内存交换、紧凑技术、虚拟内存技术？

- **内存保护**：保护各进程在自己的内存空间内运行，不会越界访问。
- **覆盖技术**：将程序分为多个段（即多个模块），常用的段常驻固定区，不常用段在需要时才调入覆盖区，替换覆盖区中原有的段。
- **内存交换**：内存紧张时，换出某些进程以腾出内存空间，再换入某些进程。
- **紧凑技术**：用于解决分区分配遗留碎片的问题，通过在内存中移动程序，将所有小的空闲区域合并为大的空闲区域。
- **虚拟内存技术**：允许一个作业分多次调入内存，其实现建立在离散分配的内存管理方式基础上，分为**请求分页存储管理**、**请求分段存储管理**以及**请求段页式存储管理**。
  - **请求调页功能**：访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存。
  - **页面置换功能**：内存空间不够时，将内存暂时用不到的信息换出到外存。

### 2.0. 外部碎片与内部碎片？

- **外部碎片**：指内存中某些空闲分区由于太小而难以利用上。
- **内部碎片**：指分配给某进程的内存区域中，如果有些部分没有用上，那么就说有内部碎片。

### 2.1. 操作系统内存管理方式？

> 连续分配管理，指为一个用户程序分配一个**连续的内存空间**，分为单一连续分配、固定分区分配和动态分区分配。
>
> 非连续分配管理，允许一个程序**分散**地装入到不相邻的内存分区中，分为基本分页存储管理、基本分段存储管理和基本段页式管理方式。

#### 连续分配管理

##### 1. 单一连续分配

- 思想：内存被分为**系统区和用户区**，系统区通常位于内存的低地址部分，用于存放操作系统相关数据。用户区用于存放用户进程相关数据。
- 特点：内存中只能有一道用户程序，用户程序独占整个用户区。
- 优点：实现简单、无外部碎片、无需进行内存保护。
- 缺点：只能用于单用户、单任务的操作系统中，有内部碎片，存储器利用率极低。
- ![1620549393027](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620549393027.png)

##### 2. 固定分区分配

- 思想：将整个用户空间划分为若干个**固定大小的分区**，在每个分区中只装入一道作业。
- 特点：该方式是最早、最简单的一种可运行多道程序的内存管理方式。
- 分类：分区大小相等、分区大小不等（需要有分区说明表）。
- 优点：实现简单、无外部碎片。
- 缺点：
  - 当用户程序太大时，可能所有的分区都满足不了要求，此时不得不采用覆盖技术来解决，降低性能。
  - 会产生内部碎片、内存利用率低。
- ![1620549849883](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620549849883.png)

##### 3. 动态分区分配

- 思想：又称可变分区分配，该方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小**动态地建立分区**，使分区大小适合程序的需要。
- 特点：系统分区大小和数目可变。
- 内存使用记录方式：
  - 空闲分区表：每个空闲分区对应一个表项，包含分区号、分区大小、分区起始地址信息等。
  - 空闲分区链：每个分区的起始部分和末尾部分分别设置前向指针和后向指针，其中起始部分可记录分区大小等信息。
- 动态分区分配算法：
  - 首次适应算法：First Fit，空闲分区按**地址递增**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 优点：最简单、性能最好。
    - 缺点：低地址部分会出现很多很小的空闲分区，增加查找的开销。
  - 最佳适应算法：Best Fit，空闲分区按**容量递增**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 缺点：会产生很多、很小、难以利用的外部碎片。
  - 最坏适应算法：Worst Fit，又称最大适应算法，空闲分区按**容量递减**的次序链接，分配内存时顺序查找，找到满足要求的第一个空闲分区。
    - 缺点：每次都选择最大的分区分配，会导致后面的大进程无大分区可分配。
  - 邻近适应算法：Next Fit，空闲分区以**地址递增**的次序链接（循环链表），分配内存时从**上次查找结束的位置**开始查找，找到满足要求的第一个空闲分区。
    - 缺点：相比首次适应算法，会出现高地址部分被分割成多个小分区，导致后面的大进程无大分区可配。
- 优点：可根据装入进行大小动态分配、没有内部碎片、支持多道程序。
- 缺点：有外部碎片，可以通过**紧凑技术**来解决外部碎片。
- ![1620550822833](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620550822833.png)

#### 非连续分配管理

##### 1. 基本分页存储管理

- 思想：把**内存分为一个个相等的小分区**，再按照分区大小把**进程拆分一个个小部分**。

- 相关概念：

  ![1620554821838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620554821838.png)

  - 页框：又称页帧、内存块、物理块，是指将内存空间分为一个个大小相等的分区。
  - 页框号：又称页帧号、内存块号、、物理块号，是指每个页框的编号，是从0开始的。
  - 页面：又称页，是指将用户进程的地址空间分为与页框大小相等的一个个区域。
  - 页号：是指每个页面的编号，也是从0开始的。注意的是，进程最后一个页面可能没有一个页框那么大，所以当页框过大时，会产生过大的内部碎片。
  - 页面长度：又称页面大小，每个页面的内存大小，一般要为2的整数幂，且等同于页框大小。
  - 页面始址：对应页面在内存中的起始物理地址。
  - 页内偏移量：又称页内地址，逻辑地址在页面内的偏移量。
  - 页表：负责记录进程页面和实际存放的内存块之间的对应关系。
  - 页表长度：指这个页表中一共有几个页表项，即一共有几页。
  - 页表项：进程每一页对应一个页表项，页表项 = 页号 + 块号。而**每个页表项长度是相同的，所以页号是隐含的**（因为可以算出来最大页表项长度）。页表项也是存放在页框中的，实际应用中，往往会使得每个页框恰好可以装得下整数个页表项（这样不会有内部碎片）。
  - 页表项长度：每个页表项的内存大小。最大页表项长度 = 总内存大小 / 页面长度。

- 特点：

  - 操作系统以页框为单位，为各个进程分配内存空间，进程的每个页面分别放入一个页框中，即进程的页面和内存的页框是一一对应的关系。
  - 各个进程页面不必连续存放，也不必按照先后顺序来存放，可以放到不相邻的各个页框中。
  - 页面外的实际物理地址是离散的，页面内的实际物理地址是连续的。
  - **页式管理中的地址是一维的**，即只要给出了一个逻辑地址，系统就可以自动算出页号、页内偏移量，并不需要显示告诉页内偏移量占多少位，因为页面大小是系统确定好了的（页面大小确定则逻辑地址结构也确定了）。

- **物理地址转换**：

  - 页号 = 逻辑地址 / 页面长度
    - M位内存，K位页面大小时，高（M - K）位表示页号。
  - 页内偏移量 = 逻辑地址 % 页面长度
    - M位内存，K位页面大小时，低K位表示页内偏移量。
    - K位页内偏移量，则页面大小为2^K大小。
  - 页面始址 = 内存块号 * 内存块大小
  - 物理地址 = 页面始址 + 页内偏移量

- **基本地址变换机构**：

  - 作用：用于实现逻辑地址到物理地址转换的一组硬件机构，即**硬件实现物理地址转换**。
  - 相关概念：
    - 页表寄存器：PTR，存放页表在内存中的起始地址F和页表长度M。在进程未执行时，页表始址和页表长度放在进程控制块PCB中，当进程被调度时，操作系统内核才会把它们放到PTR中。
  - 计算过程：

  ![1620555134892](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620555134892.png)

  1. 根据逻辑地址，计算出页号（高M-K位）和页内偏移量（低K位）。
  2. 判断页号是否越界：页号 <= 页表长度 - 1。
  3. 第一次访存（可用快表优化）：查询页表，找到页号对应的页表项，确定页面的内存块号：页表项地址 = 页表起始地址 + 页号 * 页表项长度。
  4. 用内存块号和页内偏移量，计算得到物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  5. 第二次访存：访问目标内存单元。

- **具有快表的地址变换机构**：

  - 作用：是基本地址变换机构的改进版本，**加快访存速度**。
  - 相关概念：
    - **局部性原理**：
      - **时间局部性**：如果执行了程序中的某条指令，那么在不久之后很可能再被执行。如果某个数据被访问过，那么在不久之后很可能再被访问。（因为程序中存在大量的循环）
      - **空间局部性**：如果程序访问了某个存储单元，那么在不久之后其附近的存储单元很有可能被访问。（因为很多数据在内存中都是连续存放的）
      - 应用：由于局部性原理，程序很有可能连续多次查询同一个页面，即同一个页表项，因此产生了**快表**机制。
    - 快表：TLB，联想寄存器，是一种访问速度比内存快很多的高速缓冲存储器，用来存放当前访问的**若干页表项**，以加速地址变换的过程。而内存中的页表成为慢表。
  - 计算过程：

  ![1620559002478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620559002478.png)

  1. 根据逻辑地址，计算出页号（高M-K位）和页内偏移量（低K位）。
  2. 判断页号是否越界：页号 <= 页表长度 - 1。
  3. **先查询快表**，如果要访问的页表项在快表中有副本，则直接取出，否则需要第一次访存：查询页表，找到页号对应的页表项，再**把页表项拷贝一份到快表中**。接着确定页面的内存块号：页表项地址 = 页表起始地址 + 页号 * 页表项长度。
  4. 用内存块号和页内偏移量，计算得到物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  5. 第二次访存：访问目标内存单元。

- **两级页表**：

  - 作用：**离散存储页表项**、页表项需要是调入内存（**虚拟内存技术**：页表项中增加是否已调入的标志位）。

  - 相关概念：

    ![1620560132360](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620560132360.png)

    - 二级页表：用于将常常的页表项分页。
    - 页目录表：又称外层页表、顶层页表，用于记录分页页表项后的二级页表的目录。
    - 逻辑地址结构：32位 = 10位一级页号 + 10位二级页号 + 页内偏移量

##### 2. 基本分段存储管理

- 思想：按照程序自身的逻辑关系，划分程序为若干个段，每一段都有一个段名（从0开始）。内存分配时，以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻。

- 相关概念：

  - 段号：段名，段号的位数决定了每个进程最多可以分几个段。
  - 段内地址：即段内偏移量，段内地址的位数决定了每个段的最大长度是多少。
  - 段表：记录进程各个逻辑的段在内存中的存放位置，每个进程一张，包括段号、段长、段基址。
  - 段表项：进程的每一段逻辑段对应一个段表项。每个段表项长度是相同的，所以段号是可以隐含的，不需要占存储空间。
  - 段表项长度：每个段表项的内存大小。最大段表项长度 = 最大段长位数 + 最大地址位数。

- 物理地址变换过程：

  ![1620561048183](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620561048183.png)

  1. 根据逻辑地址，得到段号（高M/2位）、段内地址（低M/2位）。
  2. 判断段号是否越界：段号 <= 段表长度 - 1。
  3. 第一次访存（可用快表优化）：查询段表，找到对应的段表项：段表项始址 = 段表始址 + 段号 * 段表项长度。
  4. 检查段内地是否超过段长：段内地址 <= 段长。
  5. 计算得到物理地址：物理地址 = 段基址 + 段内地址。
  6. 第二次访存：访问目标内存单元。

##### 3. 段页式管理

- 思想：将进程按逻辑模块分段，接着将各段分页，再将内存空间分为大小相同的内存块，最后进程将各页面分别装入各内存块中。

- 作用：结合分段管理的优点和分页管理的优点，既能有效提高内存利用率，也容易实现信息的共享与保护。

- 物理地址变换过程：

  ![1620562681599](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620562681599.png)

  1. 根据逻辑地址，得到段号（高M/2位）、页号（低M/2-K位）、页内偏移量（低K位）。
  2. 判断段号是否越界：段号 <= 段表长度 - 1。
  3. 第一次访存（可用快表优化）：查询段表，找到对应的段表项：段表项始址 = 段表始址 + 段号 * 段表项长度。
  4. 检查页号是否越界：页号 <= 页表长度 - 1。
  5. 第二次访存（可用快表优化），根据段表中的页表存放块号、页号查询页表，找到对应的页表项：页表项始址 = 页表始址 + 页号 * 页表项长度。
  6. 根据页表项中的内存块号、页内偏移量，计算得出物理地址：物理地址 = 页面始址 + 页内偏移量 = 内存块号 * 页面大小 + 页内偏移量。
  7. 第三次访存，访问目标内存单元。

### 2.2. 分页管理与分段管理的区别？

|                  | 分页管理                                           | 分段管理                                                     |
| ---------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| 管理维度         | 内存分区、进程分页，页是信息的物理单位             | 进程分段，段是信息的逻辑单位                                 |
| 透明度           | 对用户是透明的                                     | 对用户可见，用户编程需要显示给出段名                         |
| 单位大小         | 页大小固定，由系统决定                             | 段长度不固定，取决于编写的程序                               |
| 用户进程地址空间 | 是一维的，用户只需要给出一个助记符表示逻辑地址即可 | 是二维的，用户既要给出段名，也要给出段内地址                 |
| 目的             | 为了实现离散分配，提高内存利用率                   | 为了更好地满足用户需求                                       |
| 共享与保护       | 不容易实现信息共享与保护                           | 纯代码或可重入代码，更容易实现信息的共享与保护，只需要各进程指向同一个段即可实现共享 |
| 优点             | 内存空间利用率高、不会产生外部碎片                 | 没有内部碎片、容易实现信息共享与保护                         |
| 缺点             | 会产生少量的页内碎片、不容易实现信息共享与保护     | 段长过大难以分配连续空间、会产生外部碎片（可通过紧凑技术解决） |

### 2.3. 请求分页管理？

> **虚拟内存技术**：允许一个作业分多次调入内存，其实现建立在离散分配的内存管理方式基础上，分为**请求分页存储管理**、**请求分段存储管理**以及**请求段页式存储管理**。
>
> **请求调页功能**：访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存。
>
> **页面置换功能**：内存空间不够时，将内存暂时用不到的信息换出到外存。

- 特点：请求分页存储管理与基本分页存储管理的主要区别：需要操作系统提供**请求调页**（调入）以及**页面置换**（调出）功能。

- **页表机制**：也叫请求页表，是实现请求调页和页面置换功能的基础。对比基本分页存储管理的页表增加了4个字段：

  - 状态位：表示当前页面是否已经调入了内存。状态位为0代表当前页面还没有存在内存中。
  - 访问字段：用于记录当前页面最近被访问过几次，或者上次访问的时间，以供置换算法选择换出页面时参考。
  - 修改位：用于标记当前页面调入内存后是否被修改过（没有被修改过的页面是不需要写会外存的）。
  - 外存地址：表示当前页面在外存中的存放位置。

- **缺页中断机构**：**请求调页**的基础，在请求分页系统中，当要访问的页面不存在时，会产生一个**缺页中断**（内中断-故障），然后操作系统的缺页中断处理程序处理该中断。此时的缺页进程会**阻塞**，被放入阻塞队列，在调页完成后，操作系统才将其唤醒，放回就绪队列。

  缺页中断机构处理中断逻辑如下：

  - 如果内存中有空闲块，则为进程分配一个空闲块，将所缺失的页面装入该块，并修改请求页表中相应的页表项。
  - 如果内存中没有空闲块，则由**页面置换算法**选择一个页面淘汰，同时若该页面在内存期间被修改过，则还需要将其写回外存，而未修改过的页面则不需要写回外存。

- **地址变换机构**：

  与基本分页存储管理的页表不同的是：

  - 找到页表项时，需要判断页面是否在内存中。
  - 若页面不在内存中，则需要请求调页。
  - 如果调入页面内存空间不够时，需要进行页面置换。
  - 页面被访问、页面调入以及页面调出后，需要修改请求页表中相应的页表项。

![1620573633869](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620573633869.png)

### 2.4. 页面置换算法？

请求分页系统中，在内存空间不够时，由操作系统负责将内存中暂时用不到的信息换出到外存。

页面置换算法用于决定应该换出**哪个页面**到外存。

**页面的换入、换出**需要磁盘I/O，开销比较大，因此好的页面置换算法应该追求**更少的缺页率**，以减少页面换入、换出的次数。

缺页不等于页面置换，只有在缺少空闲内存块才需要发生页面置换。

#### 1. 最佳置换算法OPT

- 概念：optimal，每次淘汰**未来永不使用**或者**未来最长时间不再被访问**（顺方向）的页面。
- 优点：可以保持**最低的缺页率**。
- 缺点：**实际上无法实现**，因为操作系统无法提前预判未来的页面访问序列。

![1620648468359](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620648468359.png)

#### 2. 先换先出置换算法FIFO

- 概念：first in first out，每次淘汰**最早进入内存**的页面。
- 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时，只需要选择对头页面即可。
- **Belady异常**：贝拉底异常，指当为进程分配的内存块增大时，缺页的次数不减反增的异常现象。FIFO算法是唯一一个会出现Belady异常的页面置换算法。
- 优点：实现简单。
- 缺点：会有Belady异常，与运行时的规律不适应（因为先进入的页面后面也有可能最经常被访问），性能极差。 

![1620650037437](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620650037437.png)

![1620650005876](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620650005876.png)

#### 3. 最近最久未使用算法LRU

- 概念：least recently used，每次淘汰**最近最久未使用**（逆方向）的页面。
- 实现方法：在每个页面对应的页表项中，用**访问字段**来记录该页面从上次被访问到现在经历的时间t，当要淘汰页面时，选择页面中t值最大的，就是最近最久未使用的页面了。
- 优点：考虑到了时间局部性，性能好，实际应用较多。
- 缺点：实现困难，开销大，实现需要专门的硬件支持。

![1620649947028](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620649947028.png)

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:29
 **/
public class LRUCache {
    private LinkedHashMap<Integer,Integer> cache;
    private int capacity;   //容量大小

    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        cache = new LinkedHashMap<>(capacity);
        this.capacity = capacity;
    }

    // 使用过则需要放到链表尾部, 代表经常被使用，而链头代表的是最近最久未被使用的结点
    public int get(int key) {
        //缓存中不存在此key，直接返回
        if(!cache.containsKey(key)) {
            return -1;
        }

        int res = cache.get(key);
        cache.remove(key);   //先从链表中删除
        cache.put(key,res);  //再把该节点放到链表末尾处
        return res;
    }

    // 使用过则需要放到链表尾部, 代表经常被使用，而链头代表的是最近最久未被使用的结点
    // 在链表满时，还需要删除最近最久未被使用的结点，即链头结点
    public void put(int key,int value) {
        if(cache.containsKey(key)) {
            cache.remove(key); //已经存在，在当前链表移除
        }
        if(capacity == cache.size()) {
            //cache已满，删除链表头位置
            Set<Integer> keySet = cache.keySet();
            Iterator<Integer> iterator = keySet.iterator();
            cache.remove(iterator.next());
        }
        cache.put(key,value);  //插入到链表末尾
    }
}

```

```java
/**
 * @program: Java
 * @description: LRU最近最久未使用置换算法，通过LinkedHashMap内部removeEldestEntry方法实现
 * @author: Mr.Li
 * @create: 2020-07-17 10:59
 **/
class LRUCache {
    private Map<Integer, Integer> map;
    private int capacity;
	
    /**
     *初始化构造函数
     * @param capacity
     */
    public LRUCache(int capacity) {
        this.capacity = capacity;
        map = new LinkedHashMap<Integer, Integer>(capacity, 0.75f, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry eldest) {
                // 容量大于capacity 时就删除，删除最近最久未被使用的空闲结点
                return size() > capacity;
            }
        };
    }
    public int get(int key) {
        //返回key对应的value值，若不存在，返回-1
        return map.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        map.put(key, value);
    }
}
```

#### 4. 时钟置换算法CLOCK

- 概念：又称最近未用算法（NRU，not Recently Used），对比OPT和LRU，这是一种**性能和开销较平衡**的算法。
- 实现方法：

1. 为每个页面设置访问位（**访问位为1表示最近访问过，访问位为0表示最近没有访问过**），再将内存中的页面通过链表指针链接成一个循环队列。
2. 当页面被访问时，访问位将置为1。
3. 在淘汰页面时，循环检查访问位，把为1的置为0，为0的淘汰，如果第一轮全为1，则置换为0后进行第二轮扫描，所以**最多会经过2轮扫描**。
4. 而被置换进行的页面会被置为1，且扫描指针指向下一个页面。

- 优点：实现简单、算法开销小。
- 缺点：未考虑页面是否被修改过。

![1620651040375](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620651040375.png)

#### 5. 改进型时钟置换算法

- 概念：由于淘汰被修改过的页面时，需要写回外存，所以在时钟置换算法CLOCK的基础上，应该优先淘汰**最新没被修改过、没被访问过的**页面，避免写回外存的I/O操作。
- 实现方法：

1. 每个页面增加修改位（**修改位为0表示没有被修改过，修改位为1表示页面被修改过**），用（访问位，修改位表示），将所有可能被置换的页面排成一个循环队列。
2. 第一轮扫描：扫描第一个（0，0）即**最近没被修改过、没被访问过**的页面，本轮扫描不修改任何标志位。
3. 第二轮扫描：第一轮失败后，需要重新扫描。扫描第一个（0，1）即**最近被修改过、没被访问过**的页面用于替换，本轮扫描过的访问位置为0。
4. 第三轮扫描：第二轮失败后，需要重新扫描。扫描第一个（0，0）即**最近没被修改过、但被访问过**的页面用于替换，本轮扫描不修改任何标志位。
5. 第四轮扫描：第三轮失败后，需要重新扫描。扫描第一个（0，1）即**最近被修改过、也被访问过**的页面用于替换。改进型CLOCK算法淘汰一个页面**最多经过4轮扫描**。

- 优点：算法开销较小、性能也不错、考虑了页面是否被修改过（有修改位和访问位）。

![1620652055064](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620652055064.png)

### 2.5. 死锁的条件与解决方式？

> 哲学家进餐问题：每位哲学家都在等待自己右边的人放下筷子，即这些哲学家进程都因等待筷子资源而被阻塞，这就是发生了死锁。

- **死锁**：指在并发环境，**各进程因竞争资源而造成的一种互相等待对方手里资源**，导致各进程都阻塞，无法向前推进的现象。发生死锁后，若无外力干涉，这些进程都将无法向前推进。

- **死锁产生的必要条件**：产生死锁必须**同时满足**以下四个条件，只要其中任一条件不成立，死锁就不会发生。

  - **互斥条件**：进程对所分配的**资源不允许其他进程访问**，若其他进程访问该资源，只能等待至占有该资源的进程释放该资源。
  - **不剥夺条件**：进程所获得的资源在未使用完之前，**不可被剥夺**，只能主动释放。
  - **请求和保持条件**：进程获得一定的资源后，又对其他资源发出请求，且由于互斥条件进入阻塞状态后，还对自己占有的资源**保持不放**。
  - **循环等待条件**：存在一种**进程资源的循环等待链**，链中的每一个进程占有的资源被下一个进程所等待。
    - 注意！发生死锁时一定有循环等待，但发生循环等待时未必发生死锁（循环等待是死锁的必要不充分条件）。但如果系统中每类资源都只有一个，那循环等待则是死锁的充分必要条件。

- **死锁场景**：**对不可剥夺资源的不合理分配，可能会导致死锁。**

  - 对系统资源的竞争：各进程对不可剥夺资源的竞争可能引起死锁（如打印机），而对可剥夺资源的竞争是不会引起死锁的（如CPU）。
  - 进程推进顺序非法：请求和释放资源的顺序不当从而导致死锁。

- **死锁的处理策略**：

  - **预防死锁**：是**不允许死锁发生的静态策略**，破坏死锁的四个必要条件中的某一个。

    - **破坏互斥条件**：
      - 操作系统层面：采用SPOOLING技术，指操作系统用于把独占设备在逻辑上改造成共享设备。
      - 缺点：并不是所有的资源都可以改造成可共享使用的资源。很多时候都无法破坏互斥条件。
      - **Java层面**：乐观锁，CAS。
    - **破坏不可剥夺条件**：
      - 操作系统层面：进程请求不到其他资源时，必须立即释放保持的所有资源，或者考虑进程优先级强行剥夺想要的资源。
      - 缺点：实现比较复杂、释放资源可能会造成进程前一阶段的工作失效、反复申请和释放资源会增加系统开销，降低系统吞吐量、方案一可能会导致进程饥饿的发生。
      - **Java层面**：悲观锁，synchronized、ReentrantLock。
    - **破坏请求和保持条件**：
      - 操作系统层面：采用**静态分配方式**，进程运行需要一次申请完所有需要的资源，未满足则不能投入运行。一旦运行后，资源一直归它所有，且它不会再请求其他资源。
      - 缺点：资源利用率极低、可能会导致别的进程发生饥饿。
      - **Java层面**：数据库deadLock超时，即数据库通过锁定等待超时解决死锁。
    - **破坏循环等待条件**：
      - 操作系统层面：采用**顺序资源分配方式**，对系统该资源编号，规定每个进程必须按编号递增的顺序请求资源，对于编号相同的资源会一次申请完。
      - 缺点：不方便增加新的设备、实际使用资源的顺序可能和编号递增顺序不一致，可能会导致资源浪费、用户变成麻烦。

  - **避免死锁**：是**不允许死锁发生的动态策略**，避免系统进入**不安全状态**。

    - **安全序列**：指如果系统按照这种序列分配资源，每个进程都能顺利完成（安全序列可能有多个）。此时系统为**安全状态**，一定不会发生死锁。而如果分配资源后，系统中找不出任何一个安全序列，则系统进入了**不安全状态**，意味着之后可能发生死锁。

    - **银行家算法**：在资源分配之前先预判本次分配是否会导致系统进入不安全状态，从而决定是否答应该分配的请求，用于**避免死锁**。

      - 实现思路：保证优先分配资源给进程后，进程能够顺利执行完并归还资源，确保是安全状态。
      - 实现方法：Max矩阵、Allocation矩阵、Need矩阵、Available数组、Request数组、预判计算、回溯资源。

      ![1620737316076](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737316076.png)

  - **死锁的检测和解除**：**允许死锁发生**，系统负责检测出死锁并解除。

    - 死锁的检测：

      - 数据结构：两种结点（进程结点、资源结点），两种边（请求边、分配边）。
      - 算法思想：最终能消除所有变，则称这个图是可完全被简化的，此时一定没有发生死锁（相当于找到了一个安全序列）。反之，如果**最终不能消除所有边，那么此时就发生了死锁（死锁定理）**。
      - 实现方法：找到孤点进程（有向边相连以及不阻塞的进程）、简化边、继续简化...

      ![1620737385049](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620737385049.png)

    - **死锁的解除**：

      - 死锁的进程：用死锁检测算法化简资源分配图后，还连着边的那些进程才是死锁进程。
      - **主要方法有**：
        - **资源剥夺法**：**挂起（暂时放到外存上）某些死锁进程，并抢占它的资源**，将这些资源分配给其他死锁的进程。
          - 缺点：需要防止进程挂起过久导致出现饥饿问题。
        - **撤销进程法**：又称**终止进程法**，强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。
          - 缺点：虽然实现简单，但付出的代价是很大的。
        - **进程回退法**：让一个或者多个死锁进程回退到足以避免死锁的地步。
          - 缺点：操作系统需要记录进程的历史记录，设置还原点。
      - **考虑的维度**：进程优先级低的、执行时间少的、距离完成时间较久的、持有资源多的、批处理式的死锁进程。 

### 2.6. 死锁、饥饿、死循环？

- **死锁**：指各进程互相等待对方手里资源，导致各进程都阻塞，无法向前推进的现象。比如哲学家进餐问题。

- **饥饿**：指由于长期得不到想要的资源，某进程无法向前推进的现象。比如短进程优先（SPF）算法，会导致长进程饥饿问题。

- **死循环**：指某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug导致的，有时是程序员故意设计的。

  |          | 死锁                                                         | 饥饿                                                         | 死循环                                 |
  | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------- |
  | 共同点   | 都是进程无法向前顺利推进的现象                               | -                                                            | -                                      |
  | 进程数量 | 至少有两个或者两个以上的进程                                 | 可能只有一个进程                                             | 可能只有一个进程                       |
  | 进程状态 | 一定处于阻塞状态                                             | 可能是阻塞状态（长期得不到I/O设备），也可能是就绪状态（长期得不到处理机） | 可以是运行状态                         |
  | 原因     | 由于**操作系统**分配资源策略不合理导致的（各进程互相等待对方手里的资源） | 由于**操作系统**分配资源策略不合理导致的                     | 由代码逻辑错误导致的（**管理者问题**） |



## 4. 设计模式基础

### 1.1. 六大原则

|              | 总结                                                     |
| ------------ | -------------------------------------------------------- |
| 单一职责原则 | 实现类要职责单一                                         |
| 里氏替换原则 | 不要破坏继承体系                                         |
| 依赖倒置原则 | 要面向接口编程                                           |
| 接口隔离原则 | 设计接口时要精简单一                                     |
| 迪米特法则   | 要减少对其他类的直接依赖、减少类对外暴露的方法，降低耦合 |
| 开放原则     | 要对扩展开放，对修改关闭                                 |

#### 1. 单一职责原则

- 概念：**一个类只负责一项职责**，不要存在本职责外导致类发生变更的原因。
- 问题由来：如果类T负责两个不同的职责P1和P2，当职责P1需求发生改变修改T时，可能会导致P2功能发生故障。
- 原因分析：出现了职责扩散。
- 解决方案：
  - 根据P1和P2职责，划分为类1和类2。
  - 在职责扩散到无法控制之前，对代码进行部分重构。
- 优点：
  - 可以降低类的复杂度，一个类只负责一项职责，逻辑简单清晰。
  - 可提高类的可读性和系统的可维护性。
  - 减少需求变更时对其他功能的影响，减少出现的风险。
- 总结：
  - 只有逻辑足够简单，才可以在代码级别上违反单一职责原则。
  - 只有类中方法数量足够少，才可以在方法级别上违反单一职责原则。
  - 模块化的程序设计以及在员工工作安排上面，都适合单一职责原则。

#### 2. 里氏替换原则

- 概念：子类可以扩展父类的功能，但不能改变父类原有的功能；子类可以替换父类，但方法或者行为不能发生改变。即**子类可以扩展父类的功能，但不能改变父类原有的功能**。
- 问题由来：子类B在扩展新功能时，有可能会导致父类原有的功能发生故障。
- 原因分析：继承的弊端，会给程序代理侵入性，使得程序的可移植性减低，增加了对象的耦合性。
- 解决方案：
  - 类B扩展新功能时，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。
  - 如果子类对父类实现的方法进行修改，会对整个继承体系造成破坏，当子类要修改时，必须考虑所有的子类。并且，如果修改了父类，那么所有的子类功能可能都会发生故障。
- 优点：如果不遵循里氏替换原则，一开始程序可能是好好的，但是在之后的迭代过程中，代码出现问题的几率会大大增加，尤其当另外一个人接手项目之后。
- 总结：
  - 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。
  - 子类中可以增加自己独特的方法。
  - 当子类的方法重载父类的方法时，方法的前置条件（形参）要比父类方法更宽松。
  - 当子类的方法实现父类的抽象方法时，方法的后置条件（返回值）要比父类更严格。

#### 3. 依赖倒置原则

- 概念：**高层模块不能依赖底层模块**，二者都应该依赖其抽象；**抽象不应该依赖细节**，细节应该依赖抽象。
- 问题由来：类A（高层模块）本来依赖类B（低层模块），但现在要修改类A依赖类C（低层模块），修改程序时可能会导致不必要的风险。
- 解决方案：将类A改为依赖接口T，而类B和类C分别实现接口T，此时**类A可以通过接口T，间接访问类B和类C，大打降低了修改类A的几率**。
- 总结：
  - 相对于细节的多变性，抽象的东西要稳定得多。依赖倒置原则的核心思想是面向接口编程，通过使用接口或者抽象类来制定好规范和契约，不用去涉及任何具体的操作，将展开细节的任务交给实现类去完成，以达到解耦的目的。
  - 低层模块尽量都要有接口或者抽象类，高层模块尽量通过接口或者抽象类的形式访问低层模块。
  - 使用抽象类时，要遵循里氏替换原则。

#### 4. 接口隔离原则

- 概念：客户端不应该依赖它不需要的接口，即一个类对另一个类的依赖都应该建立在**最小的接口**上面。
- 问题由来：类A通过接口T依赖了类B和类D，但类D不是类A想要依赖的。
- 解决方案：将臃肿的接口T拆分为独立的Tb和Td接口，类A只需要依赖Tb即可。
- 优点：提高内聚，减少对外交互，用最少的方法完成最多的事情。
- 总结：
  - 尽量细化接口，建立单一接口，使得接口中的方法尽量少。但要有限度，过小则会导致接口数量过多，增加复杂度。
  - 为单个类建立专用的接口，不要包含太多。依赖几个专用的接口要比依赖一个综合的接口灵活得多，即可以提高系统的灵活性和可维护性。
  - 为依赖接口的类定制服务，只暴露给调用类需要的方法，建立最小的依赖关系。
- 区别单一职责：
  - 单一职责注重的是职责；接口隔离注重的是接口依赖的隔离。
  - 单一职责约束的是实现类，其次才是接口和方法，针对的是程序中的实现细节；接口隔离约束的是接口，针对的是抽象和整体框架的构建。

#### 5. 迪米特法则

- 概念：又称**最少知道原则**，要求一个对象应该对其他对象有最少的了解。
- 优点：降低类之间的耦合，每个类尽量减少对其他类的依赖，尽量减少对外暴露的方法，使得功能模块独立，低耦合。
- 总结：
  - 减少对其他类的依赖，只通过成员变量、方法的输入输出参数来对类进行注入，减少方法体内部类的直接使用。
  - 减少类对外暴露的方法。
  - 虽然遵循迪米特法则可以避免和非直接的类通信，但如果要通信，则必然会通过一个中介发生联系，而过分地使用迪米特法则，会产生大量的中介和中间传递类，导致系统复杂度变高。

#### 6. 开闭原则

- 概念：软件中的对象（类、模块、函数等）应该**对于扩展是开放的，对与修改是关闭的**。
- 问题由来：对软件原有代码进行修改时，可能会将错误引入原本已经测试过的代码中，破坏原有系统。
- 解决方案：当软件需求发生变化时，尽量通过扩展实体的行为实现需求变化，而不是通过修改原有的代码来应对变化。

### 1.2. UML图

#### 1. 类UML

![1620827681262](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827681262.png)

#### 2. 接口UML

![1620827737253](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827737253.png)

#### 3. 类图UML

![1620827711036](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827711036.png)

#### 4. 实现关系UML

![1620827793083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827793083.png)

#### 5. 泛化（继承）关系UML

![1620827830674](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827830674.png)

#### 6. 依赖关系UML

![1620827777826](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827777826.png)

#### 7. 一般关联关系UML

![1620827947066](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827947066.png)

#### 8. 组合关系UML

![1620827976361](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827976361.png)

#### 9. 聚合关系UML

![1620827988535](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1620827988535.png)

### 1.3. 单例模式

某个类只能生成一个实例，该实例被全局访问，比如Spring容器一级缓存里的单例池。

- 优点：唯一访问、提高性能
- 缺点：不适合有状态且需要变更的实例
- 实现方式：**所有方式都会被反序列破坏，但是都可以通过单例对象添加Object#readResolve() 方法, 直接返回单例对象即可防止破坏。**

|                       | 懒加载 | 线程安全 | 其他优点     | 缺点                       | 推荐 |
| --------------------- | ------ | -------- | ------------ | -------------------------- | ---- |
| 饿汉式                | 否     | 是       | 简单、速度快 | 提早占用内存、不可参数构造 | 是   |
| 懒汉式                | 是     | 否       | 可参数构造   | 线程不安全                 | 否   |
| 懒汉式-锁实现         | 是     | 是       | 可参数构造   | 加锁导致效率低下           | 否   |
| 懒汉式-静态内部类实现 | 是     | 是       | -            | 不可参数构造               | 是   |
| 双重检查锁            | 是     | 是       | 可参数构造   | 实现较复杂、可被反射破坏   | 是   |
| 枚举类                | 是     | 是       | 不被反射破坏 | 实现较复杂、不可参数构造   | 是   |

#### 1. 饿汉式

```java
/**
 * 1、饿汉式
 */
public class Singleton1 implements Serializable {
    private static final Singleton1 instance = new Singleton1();

    public static Singleton1 getInstance(){
        return instance;
    }
    
    private Singleton1() {
        // 防⽌反射获取多个对象的漏洞 true
        if(instance != null){
            throw new RuntimeException("获取单例异常!");
        }
    }
    
    // 防止反序列化获取多个对象的漏洞
    private Object readResolve() throws ObjectStreamException {
        return instance;
    }

}
```

#### 2. 懒汉式

```java
/**
 * 2、懒汉式-线程不安全
 */
public class Singleton2 implements Serializable {

    private static Singleton2 instance;// 类初始化为null

    public static Singleton2 getInstance(int code){
        if(instance == null){
            instance = new Singleton2(code);
        }
        return instance;
    }
}
```

#### 3. 懒汉式-锁实现

```java
/**
 * 3、懒汉式-线程安全-锁方法实现
 */
public class Singleton3 implements Serializable {
    
    private static Singleton3 instance;// 类初始化为null

    public static synchronized Singleton3 getInstance(int code){
        if(instance == null){
            instance = new Singleton3(code);
        }
        return instance;
    }
}
```

#### 4. 懒汉式-静态内部类实现

```java
/**
 * 4、懒汉式-线程安全-静态内部类
 */
public class Singleton4 implements Serializable {
    
    private static class Holder {
        private static final Singleton4 SINGLE_TON = new Singleton4();
    }
    
    public static Singleton4 getInstance(){
        return Holder.SINGLE_TON;
    }
}

```

#### 5. 双重检查锁

```java
/**
 * 5、双重检查锁
 */
public class Singleton5 implements Serializable {

    // volatile防止重排序导致实例化未完成
    private volatile static Singleton5 instance;// 必须要保证可见性

    public static Singleton5 getInstance(int code){
        // 第一次减少锁的开销
        if(instance == null){
            synchronized (Singleton5.class){
                // 第二次防止重复
                if(instance == null){
                    instance = new Singleton5(code);
                }
            }
        }

        return instance;
    }
}
```

#### 6. 枚举类

```java
/**
 * 6、枚举(JDK 1.5后)
 */
public class Singleton6 implements Serializable {

    private static enum SingletonEum {
        INSTANCE;// 创建一个枚举类, 天生就是单例的

        private Singleton6 singleton6;

        SingletonEum() {// 创建时创建singleton6单例对象
            singleton6 = new Singleton6();
        }

        public Singleton6 getInstance(){
            return singleton6;
        }
    }

    // 调用getInstance()才使用枚举类, 才对枚举类进行加载, 再枚举类的构造方法中创建了单例
    public static Singleton6 getInstance() {
        return SingletonEum.INSTANCE.getInstance();
    }
}
```

### 1.4. 工厂模式

#### 1. 简单工厂模式

简单工厂模式是**由一个工厂对象决定创建出哪一种产品类的实例**，是工厂模式家族中最简单实用的模式，可以理解为是不同工厂模式的一个特殊实现。

- 组成：
  - 工厂类角色：简单工厂类，即是根据类型创建具体产品，是具体产品的逻辑封装。
  - 抽象产品角色：一般是指具体产品继承的父类或实现的接口。
  - 具体产品角色：具体的实现类，相当于抽象业务的落地。
- 优点：
  - 解耦：实现了对责任的分割，专门的工厂类用于创建产品，客户类免除了除直接创建产品对象的责任，而仅仅是消费产品。
  - 简单：客户类无须知道所创建的具体产品类的类名，只需要知道具体产品类的对应参数即可。
  - 可配置（解决方案）：通过引入配置文件，可以在不修改任何客户类代码的情况下，更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。
- 缺点：
  - 中心化：由于工厂类集中了所有产品的创建逻辑，一旦不能工作, 整个系统都要受到影响。
  - 类爆炸：使用简单工厂模式将会增加系统中类的个数，在一定程度上增加了系统的复杂度和理解度。
  - 不灵活：系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。
  - 不够体系化：由于使用了静态工厂方法，造成了工厂角色无法形成基于继承的等级结构。
- 使用场景：
  - 工厂类负责创建的对象比较少时。
  - 客户类只知道传入工厂的参数，对于如何创建对象逻辑不关心时。
  - 由于简单工厂很容易违反高内聚责任分配原则，因此一般只在很简单的情况下应用。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        SimpleFatory simpleFatory = new SimpleFatory();
        simpleFatory.createProduct("HighLvA");
        simpleFatory.createProduct("B");
    }
}

// 抽象接口
public abstract class Product {

    public Product() {

    }
}

// 具体产品实现类
public class ProductA extends Product{

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }
}

// 简单工厂类
public class SimpleFatory {

    public Product createProduct(String type){
        switch (type){
            case "HighLvA":
                return new ProductA();
            case "B":
                return new ProductB();
            default:
                break;
        }

        return null;
    }
}
```

#### 2. 工厂方法模式

工厂方法模式的核心思想是**封装类中变化的部分**，提取其中个性化善变的部分为独立类，通过依赖注入以达到解耦、复用和方便后期维护拓展的目的。工厂方法模式是对简单工厂模式的**工厂做了抽象**。

- 组成：
  - 抽象工厂角色：工厂方法模式的核心，是具体工厂角色必须实现的接口或必须继承的父类，也就是对具体工厂的抽象。
  - 具体工厂角色：含有和具体业务逻辑有关的代码, 由客户类指明创建, 用于创建对应具体的产品对象。
  - 抽象产品角色：对比简单工厂模式，抽象逻辑没变。一般是指具体产品继承的父类或实现的接口。
  - 具体产品角色：对比简单工厂模式，抽象逻辑没变。具体的实现类，相当于抽象业务的落地。
- 优点：
  - 去中心化：工厂方法模式去掉了简单工厂模式中工厂的静态属性，使得它可以被子类继承，这样在简单工厂模式里集中在工厂方法上的压力，就可以由工厂方法模式里不同的工厂子类分担。
  - 开闭原则： 当有新的产品产生时，只要按照抽象产品角色、抽象工厂角色提供的合同来生成，那么就可以被客户使用，而不必去修改任何已有的代码。
- 缺点：
  - 类爆炸：在添加新产品时需要编写新的具体产品类，而且还要提供与之对应的具体工厂类。可见系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，而更多的类需要编译和运行，会给系统带来一些额外的开销。
- 使用场景：
  - 对于某种产品，调用者清楚地知道应该使用哪个具体工厂服务，从而实例化该具体工厂，生产出具体的产品。比如Java Collection中的iterator()方法。
  - 只是需要一种产品，而不想知道，也不需要知道究竟是哪个工厂生产的，即最终选用哪个具体工厂的决定权在生产者一方，生产者根据当前系统的情况来实例化一个具体的工厂返回给使用者，而这个决策过程对于**使用者来说是透明的**。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        FactoryProductA factoryProductA = new FactoryProductA();
        factoryProductA.createProduct();

        FactoryProductB factoryProductB = new FactoryProductB();
        factoryProductB.createProduct();
    }
}

// 抽象产品类
public abstract class Product {

    public Product() {

    }
}

// 产品实现类
public class ProductA extends Product {

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }
}

// 抽象工厂类
public interface AbstractFatory {

    public Product createProduct();
}

// 工厂实现类
public class FactoryProductA implements AbstractFatory{

    @Override
    public Product createProduct() {
        return new ProductA();
    }
}
```

#### 3. 抽象工厂模式

抽象工厂是指当有**多个抽象角色**时使用的一种工厂模式，可以向客户提供提供一个接口，使客户在不必指定产品的具体参数情况下（工厂方法模式），创建**多个产品族中**的产品对象（由于有抽象工厂角色对多个工厂进行聚合, 暴露各种产品生产的接口）。

> 工厂方法模式，针对的是多个产品系列结构（同一个抽象产品角色, 同一个产品族）。
>
> 抽象工厂模式，针对的是多个产品族结构（多个抽象产品角色,多个产品族）。
>
> 一个产品族内有多个产品系列（同一个抽象产品角色, 同一个产品）。

- 核心思想：在抽象工厂中，增加创建其他产品族的生产接口，并在具体子工厂中实现。
- 优点：
  - 抽象工厂：也是工厂方法模式的优点，分离了具体的类，客户通过抽象接口操纵实例，产品的类名也在具体工厂的实现中被分离，它们不出现在客户代码中。
  - 多产品族：易于交换产品系列，只需要改变具体工厂或者调用不同的接口，即可生产不同的产品。
  - 产品一致：有利于产品的一致性，当一个系列的产品对象被设计成一起工作时，抽象工厂很容易实现一个应用一次只能使用同一个系列的对象。
- 缺点：
  - 难以支持新种类的产品：产品族扩展费力，因为抽象工厂接口确定了可以被创建的产品集合，假如产品族需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。因此使用抽象工厂模式时，对产品等级结构的划分非常重要。
- 使用场景：
  - 一个系统要独立于它的产品创建、组合和表示时（无关性）。
  - 一个系统要由**多个产品系列**中的一个来配置时。
  - 需要强调一系列相关的产品对象的设计以便进行联合使用时。
  - 提供一个产品类库, 而只想显示它们的接口而不是实现时。
  - 如果创建的产品是一系列相互关联或者相互依赖的产品组时，可以使用抽象工厂模式。而如果产品间不存在关联或约束时，则使用多个独立的工厂来对产品进行创建，则更适合一点。

```java
// 客户类
public class Customer {

    public static void main(String[] args) {
        FactoryProductA factoryProductA = new FactoryProductA();
        factoryProductA.createProduct();
        factoryProductA.createNewProduct();

        FactoryProductB factoryProductB = new FactoryProductB();
        factoryProductB.createProduct();
        factoryProductB.createNewProduct();
    }
}

// 抽象产品类
public abstract class Product {

    public Product() {

    }
}

// 产品实现类
public class ProductA extends Product {

    public ProductA() {
        System.out.println("制造产品A: Product HighLvA...");
    }

}

// 抽象工厂类
public interface AbstractFatory {

    public Product createProduct();

    public NewProduct createNewProduct();
}

// 工厂实现类
public class FactoryProductA implements AbstractFatory {

    @Override
    public Product createProduct() {
        return new ProductA();
    }

    @Override
    public NewProduct createNewProduct() {
        return new NewProductA();
    }
}
```

### 1.5. 策略模式

定义一组算法，将**每一种算法**封装起来，从而使它们可以相互切换。

- 组成：
  - 策略封装角色：上层访问策略入口，持有抽象策略的引用（聚合关系）。
  - 抽象策略角色：提供接口或抽象类，定义策略组必须拥有的方法和属性。
  - 具体策略角色：实现抽象策略，定义具体的算法逻辑。
- 优点：
  - 重用：策略模式提供了管理相关**算法族**的方法，其等级结构定义了一个算法或者行为族，恰当使用继承和接口可以把公共的代码进行抽取，避免代码重复。
  - 减少嵌套：if-else语句不易维护，使用策略模式可以避免使用多重条件if-else语句。如果把采取哪一种算法或行为的逻辑与算法或行为本身的逻辑混合在了一起，统统列在一个语句里面，那这样比使用继承的办法还要原始和落后。
- 缺点：
  - 算法列表：客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择适当的算法类，因此，策略模式只适用于客户端知道算法或者行为的情况。
  - 类爆炸：由于策略模式把每个具体的策略实现都单独封装成类，如果备选的策略很多，那么对象的数目就会很可观。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Context context = new Context(new StrategyB());
        context.useStrateyAlgorithmLogic();
    }
}

// 策略封装上下文对象
public class Context {

    private Strategy strategy;

    public Context(Strategy strategy) {
        this.strategy = strategy;
    }

    /**
     * 调用策略
     */
    public void useStrateyAlgorithmLogic(){
        strategy.algorithmLogic();
    }
}

// 策略抽象接口
public interface Strategy {

    // 具体算法逻辑
    public void algorithmLogic();
}

// 具体策略A
public class StrategyA implements Strategy{

    @Override
    public void algorithmLogic() {
        System.out.println("这是策略A...");
    }
}
```

### 1.6. 命令模式

将一个请求封装为一个对象，从而可以使用不同的请求对客户进行**参数化、请求排队、记录请求日志、命令撤销**等操作。

- 特点：当需要向某些对象发送请求，但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个时使用命令模式时使用，可以使得请求发送者与请求接收者相解耦。
- 组成：
  - 抽象命令类：Command，抽象出命令对象，可以根据不同的命令类型，写出不同的实现类。
  - 具体命令类：ConcreteCommand，实现了抽象命令对象的具体实现。
  - 调用者/请求者：Invoker，请求的发送者，通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令之间存在关联。
  - 接收者：Receiver，执行与请求相关的操作，真正执行命令的对象，具体实现对请求业务的处理。
  - 客户类：Client，在客户类中创建调用者对象，具体命令类对象，在创建具体命令对象时指定对应的接收者。
- 优点：
  - 解耦：可以降低系统的耦合度。
  - 易用：可以容易地将新的命令加入到系统中。
  - 设计方便：可以容易地设计一个命令队列和宏命令（组合命令）。
  - 可撤销与重试：可以方便地实现对请求的Undo和Redo。
- 缺点：
  - 类爆炸：由于针对每一个命令都需要设计一个具体命令类，所以在使用命令模式时，可能会导致某些系统有过多的具体命令类。当某些系统可能需要大量具体命令类时，将会影响命令模式的使用。
- 使用场景：
  - 网络传输：命令的调用者和命令执行者之间存在不同的生命周期，意味着命令发送了并不是立即执行。即命令发送出去后，原先的请求发出者可能已经不存在了，而命令对象本身还在，可以通过网络传输到另一台机器，给执行者执行。比如, Struts2中的action调用。
  - 统一管理：命令需要进行各种管理逻辑，比如对多个命令的统一控制。
  - 撤销重试：系统需要支持撤销（反撤销)）或者重试操作时。命令对象可以把状态存储起来，等到客户端需要撤销命令所产生的效果时，可以调用undo（）方法，把命令所产生的效果撤销掉。命令对象还可以提供redo()方法，以供客户端在需要时再重新实施命令效果。比如数据库中的事务机制底层实现。
  - 回调：回调callBack（）系统的使用，其中callBack（）讲的就是先将一个函数登记上，然后在以后调用此函数。
  - 命令日志：将系统中所有命令记录在日志里，待系统奔溃时，可以根据日志中一条一条命令重新调用execute（）， 从而恢复系统在崩溃前所做的数据更新。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Receiver receiver = new Receiver();
        RemoteInvoker remoteInvoker = new RemoteInvoker(new TurnUpCommand(receiver), new TurnDownCommand(receiver));

        // 操作遥控器
        remoteInvoker.turnDownButton();
        remoteInvoker.turnUpButton();
        remoteInvoker.undoButton();
        remoteInvoker.undoButton();
        remoteInvoker.redoButton();
        remoteInvoker.redoButton();
    }
}

// 接收者实现类-电视机
public class Receiver {

    public void turnUp(){
        System.out.println("跳转到上一个台...");
    }

    public void turnDown(){
        System.out.println("跳转到下一个台...");
    }
}

// 请求发送实现类-遥控器
public class RemoteInvoker {

    private Command turnUpCommand;
    private Command turnDownCommand;

    private Stack<Command> undoCommadStack;
    private Stack<Command> redoCommadStack;

    public RemoteInvoker(Command turnUpCommand, Command turnDownCommand) {
        this.turnUpCommand = turnUpCommand;
        this.turnDownCommand = turnDownCommand;

        undoCommadStack = new Stack<>();
        redoCommadStack = new Stack<>();
    }

    // 遥控器-切上一个台的按钮实现
    public void turnUpButton(){
        turnUpCommand.execute();
        undoCommadStack.push(turnUpCommand);
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.clear();
        }
    }

    // 遥控器-切下一个台的按钮实现
    public void turnDownButton(){
        turnDownCommand.execute();
        undoCommadStack.push(turnDownCommand);
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.clear();
        }
    }

    // 遥控器-undo按钮实现
    public void undoButton(){
        if(!undoCommadStack.isEmpty()){
            Command command = undoCommadStack.pop();
            command.undo();
            redoCommadStack.push(command);
        }else {
            System.out.println("按钮无效...");
        }
    }

    // 遥控器-redo按钮实现
    public void redoButton(){
        if(!redoCommadStack.isEmpty()){
            redoCommadStack.pop().execute();
        }else {
            System.out.println("按钮无效...");
        }
    }
}

// 命令接口
public interface Command {

    // 执行命令
    public void execute();

    // 撤销命令
    public void undo();
}

// 转上一个台具体命令
public class TurnUpCommand implements Command{

    private Receiver receiver;

    public TurnUpCommand(Receiver receiver) {
        this.receiver = receiver;
    }

    @Override
    public void execute() {
        receiver.turnUp();
    }

    @Override
    public void undo() {
        receiver.turnDown();
    }
}

// 转下一个台具体命令
public class TurnDownCommand implements Command{

    private Receiver receiver;

    public TurnDownCommand(Receiver receiver) {
        this.receiver = receiver;
    }

    @Override
    public void execute() {
        receiver.turnDown();
    }

    @Override
    public void undo() {
        receiver.turnUp();
    }
}
```

### 1.7. 代理模式

为其他对象**提供一种代理**，以控制对这个对象的访问。在某种情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到**中介**的作用。

- 组成：
  - 抽象角色：通过接口或者抽象类声明真实角色实现的业务方法。
  - 代理角色：实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法，来实现抽象方法（持有真实角色对象的引用），并可以附加自己的操作。
  - 真实角色：实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。
- 分类：
  - 静态代理：静态代理，是由程序员创建或者工具生成代理类的源码，再在编译生成代理类。所谓静态，也就是程序运行前就已经存在**代理类的字节码文件**，这时代理类和委托了类的关系在运行前就确定了。
  - 动态代理：动态代理在实现阶段不用关心代理类，而在**运行阶段**才指定哪一个对象。
    - 分类：JDK动态代理、CGLIB动态代理。
    - [2.6. 动态代理？](#2.6. 动态代理？)
- 优点：
  - 职责清晰：真实角色就是实现实际业务逻辑的，不用去关心其他非本职的业务。而通过后期的代理去完成那些非真实角色本职的业务，编程简洁清晰。
  - 保护目标对象：在客户端和目标对象中间存在代理对象，起到中介以及保护目标对象的作用。
  - 高扩展性：符合开闭原则，代理类的实现不是通过修改原有的代码，而是通过扩展的方式，织入新的业务代码。符合对修改关闭，对扩展开放的原则。

```java
// 客户类(静态代理)
public class Client {

    public static void main(String[] args) throws Throwable {
        UserService userService = new UserServiceImplStaticProxy(new UserServiceImpl());
        userService.save();       
    }
}

/**
 * 抽象角色: 用户服务接口
 */
public interface UserService {

    public void save();
}

/**
 * 真实角色: 用户服务接口实现类
 */
public class UserServiceImpl implements UserService {

    @Override
    public void save() {
        System.out.println("保存用户信息...");
    }
}

/**
 * 代理角色: 用户服务实现静态代理类
 */
public class UserServiceImplStaticProxy implements UserService{

    private UserService userService;

    public UserServiceImplStaticProxy(UserService userService) {
        this.userService = userService;
    }

    @Override
    public void save() {
        System.out.println("静态代理前...");
        userService.save();
        System.out.println("静态代理后...");
    }
}
```

### 1.8. 模板方法模式

定义一个操作中算法的骨架，将一些步骤延迟到子类中，使得子类可以不改变算法结构即可**重定义**该算法的某些特定步骤。

- 组成：
  - 抽象父类：实现了模板方法，定义了算法的骨架。
  - 具体类：实现抽象类的抽象方法，即不同对象实现不同的具体细节。
- 优点：
  - 灵活：具体细节步骤实现定义在子类中，子类定义详细处理算法不会改变算法整体结构。
  - 代码复用：代码复用的基本技术，在数据库设计中尤为重要。
  - 开闭原则：存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合开闭原则。
- 缺点：
  - 类爆炸：每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。
- 使用场景：Spring、JDBC等各种框架中均有使用。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        /**
         * 模板方法模式:
         * a. 假设做菜有3步: 备料、做菜、上菜, 这三步是算法的骨架
         * b. 然后做不同菜需要不同的料, 做时不同的方法, 以及如何盛装给客人, 这些就是不同的实现细节
         */
        // 番茄炒蛋
        DodishTemplate eggsWithTomato = new EggsWithTomato();
        eggsWithTomato.dodish();

        // 红烧肉
        DodishTemplate braisedPork = new BraisedPork();
        braisedPork.dodish();
    }
}

// 抽象角色: 做菜的抽象父类
public abstract class DodishTemplate {

    /**
     * 做菜, 定义算法骨架
     */
    protected void dodish(){
        this.preparation();
        this.doing();
        this.carriedDishes();
    }

    /**
     * 备菜
     */
    protected abstract void preparation();

    /**
     * 做菜
     */
    protected abstract void doing();

    /**
     * 上菜
     */
    protected abstract void carriedDishes();
}

// 具体角色: 番茄炒蛋
public class EggsWithTomato extends DodishTemplate{

    @Override
    protected void preparation() {
        System.out.println("洗并切西红柿, 打鸡蛋...");
    }

    @Override
    protected void doing() {
        System.out.println("鸡蛋倒入锅里, 然后倒入西红柿一起炒...");
    }

    @Override
    protected void carriedDishes() {
        System.out.println("将炒好的西红寺鸡蛋装入碟子里, 端给客人吃...");
    }
}
```

### 1.9. 复合模式（MVC模式）

将多个模式结合起来形成一个框架，以解决一般性问题，在形式上，**复合模式是多个模式的结合**。

- 使用场景：
  - MVC就是典型的多个模式结合：
    - 观察者模式：V和C都是M的观察者，Model的状态更新要及时通知V更新视图，或者通知C做相应逻辑处理。
    - 策略模式：C是V的策略，所以V包含的控制逻辑就是选择策略，也就是选择控制器Controller。
    - 组合模式：V的自身实现应用了组合模式，即调用顶层容器的repaint方法，容器内的所有组件都会进行重绘。
  - MVC应用了多个模式，并能够较好的解决设计上的一般性问题，所以被成为复合模式。但应用复合模式的框架远不止MVC一个。

### 2.0. 适配器模式

定义一个包装类，用于**包装不兼容接口的对象**。把一个类的接口变换成客户端所期待的另一种接口，从而使原本接口不匹配而无法工作的两个类能够一起工作。

- 组成：
  - 包装类：适配器Adapter。
  - 被包装对象：适配器Adaptee，即被适配的类。
- 分类：
  - 类的适配器模式：
    - 特点：使用对象继承的方式实现，是静态的定义方式。
    - 优点：使用方便，代码简化，仅仅引入一个对象，并不需要额外地字段来引用Power实例。
    - 缺点：高耦合，灵活性低。在需要同时适配源类和其子类时，由于类的适配器不能和Adaptee子类一起工作，所以选择对象的适配器比较合适。
  - 对象的适配器模式：
    - 特点：使用对象组合的方式，是动态组合的方式。
    - 优点：灵活性高、低耦合。
    - 缺点：使用复杂、需要引入对象实例。在需要重新定义Adaptee部分行为时，由于类适配器可以重定义Adaptee部分行为，相当于子类覆盖父类的部分实现方法，所以选择类的适配器比较合适。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        // 获取进口电视机
        ImportedTv importedTv = new ImportedTv();
        
        // 类的适配器模式
        // 获取电视机电源适配器(实际上是一个电视机插头, 但也是个电源)
        TvPlug tvPlug = new PowerAdapter();
        // 开始转换电压
        tvPlug.converTo110v();
        // 开启电视机
        importedTv.work();
        
        // 对象的适配器模式
        // 获取新的电视机电源适配器(实际上是一个电视机插头, 但也是个电源)
        NewPowerAdapter newPowerAdapter = new NewPowerAdapter(new Power());
        // 开始转换电压
        newPowerAdapter.converTo110v();
        // 开启电视机
        importedTv.work();
    }
}

// 进口电视机
public class ImportedTv {

    public void work(){
        System.out.println("电视机正在开启...");
    }
}

// 被包装对象：电视机插头
public interface TvPlug {

    public void converTo110v();
}

// 被包装对象：电源
public class Power {

    public void supply220v(){
        System.out.println("提供220v电源...");
    }
}

// 包装对象：类的适配器模式-电视机电源适配器
public class PowerAdapter extends Power implements TvPlug {

    @Override
    public void converTo110v() {
        super.supply220v();
        System.out.println("开启转换电压...");
    }
}

// 包装对象：对象的适配器模式-电视机电源适配器
public class NewPowerAdapter implements TvPlug{

    private Power power;

    public NewPowerAdapter(Power power) {
        this.power = power;
    }

    public void converTo110v() {
        power.supply220v();
        System.out.println("开启转换电压...");
    }
}
```

### 2.1. 装饰者模式

通过创建一个包装对象，也就是用装饰来包裹真实的对象，在不必改变原类文件和使用继承的情况下，**动态地扩展**一个对象的功能。

- 特点：
  - 装饰对象和真实对象具有相同的接口，这样客户端对象就能以和真实对象相同的方式和装饰对象交互了。
  - 装饰对象包含一个真实对象的引用。
  - 装饰对象接收所有来自客户端的请求，它把这些请求转发给真实的对象。
  - 装饰对象可以在转发这些请求以前或者以后增加一些附加功能，这样就确保了在运行时，不用修改指定对象的结构就可以在外部增加附加的功能。
- 组成：
  - 顶层抽象父类：具有最一般的特性，是真实对象以及装饰组件的共同抽象。
  - 真实对象：代表的是具有业务意义的，能被修饰的底层对象。
  - 组件抽象父类：具有装饰组件的一般性，是装饰组件的抽象。
  - 包装对象：代表的是能够装饰真实对象的组件，实现了组件抽象父类。
- 优点：
  - 灵活：装饰者模式与继承关系的目的都是扩展对象功能，但是装饰者模式可以提供比继承更多的灵活性。
  - 高扩展：通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合。
- 缺点：
  - 复杂：这种比继承更加灵活机动的特性，也同时意味着更多的复杂性。
  - 类爆炸：装饰者模式会导致设计中出现许多小类，如果过度使用，会使程序变得很复杂。
- 使用场景：
  - 需要扩展一个类的功能，或者给一个类添加附加职责。
  - 需要动态地给一个对象添加功能，这些功能可以再动态的撤销。
  - 需要增加由一些基本功能的排列组合而产生了非常大量的功能，而如果使用继承关系变得不现实。比如JDK中的IO类便使用了装饰者模式，其中的InputStream是顶层抽象父类，FilterInputStream是组件抽象父类。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        /**
         * 开始下单
         */
        // 要一杯 深焙咖啡, 摩卡, 奶泡
        Beverage beverage1 = new DarkRoast();
        beverage1 = new Mocha(beverage1);
        beverage1 = new Whip(beverage1);
        System.out.println(getDescAndCost(beverage1.getDescription(), beverage1.cost()));
    }

    public static String getDescAndCost(String desc, BigDecimal cost){
        return String.format("Description: %s, $%f", desc, cost);
    }
}

// 顶层抽象父类-饮料抽象类
public abstract class Beverage {

    private String description = "Unkown Beverage";

    /**
     * 获取饮料描述-子类中重写
     * @return
     */
    public String getDescription() {
        return description;
    }

    /**
     * 获取饮料价格-子类中实现
     * @return
     */
    public abstract BigDecimal cost();
}

// 真实对象：深焙咖啡类-一种具体的饮料
public class DarkRoast extends Beverage {

    @Override
    public String getDescription() {
        return "深焙咖啡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("3.00");
    }
}

// 组件抽象父类-因为调料叠加以后也是一种饮料, 所以能继承饮料抽象类
public abstract class CondimentDecorator extends Beverage {

    /**
     * 所有的具体调料装饰者都必须实现getDescription(), 这样才能够用递归的方式来得到所选饮料的整体描述
     * @return
     */
    public abstract String getDescription();
}

// 包装对象-摩卡调料类-一种具体的调料
public class Mocha extends CondimentDecorator {

    /**
     * 持有一个具体饮料的引用
     */
    private Beverage beverage;

    public Mocha(Beverage beverage) {
        this.beverage = beverage;
    }

    @Override
    public String getDescription() {
        return beverage.getDescription() + ", 摩卡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("0.2").add(beverage.cost());
    }
}

// 包装对象-奶泡调料类-一种具体的调料
public class Whip extends CondimentDecorator {

    /**
     * 持有一个具体饮料的引用
     */
    private Beverage beverage;

    public Whip(Beverage beverage) {
        this.beverage = beverage;
    }

    @Override
    public String getDescription() {
        return beverage.getDescription() + ", 奶泡";
    }

    @Override
    public BigDecimal cost() {
        return new BigDecimal("0.4").add(beverage.cost());
    }
}
```

### 2.2. 观察者模式

一个目标物件管理所有相依于它的观察者物件，并且在它本身的**状态改变**时主动发出通知，透过呼叫各观察者所提供的方法来实现，通常被用来实现事件处理系统。

- 特点：
  - 当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新，完美地将观察者模式和被观察者的对象分离开，在模块之间划定了清晰的界限，提高了应用程序的可维护性和重用性。
  - 将一个系统分割成一些类相互协作的类有一个不好的副作用，那就是需要维护相关对象之间的一致性，当不希望为了维持一致性，而使各类紧密耦合导致会给维护、扩展和重用都带来不便时，可以使用观察者模式来解决这类耦合关系。
- 组成：
  - 抽象主题：Subject，抽象主题提供一个接口，可以增加和删除观察者对象。它把所有观察者对象的引用保存到一个聚集里，每个主题都可以有任意数量的观察者。
  - 具体主题：Concrete Subject，将有关状态存入具体观察者对象，在具体主题内部状态改变时，给所有登记过的观察者发出通知。
  - 抽象观察者：Observer，为所有具体的观察者定义一个接口，在得到主题通知时更新自己。
  - 具体观察者：Concrete Observer，实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题状态协调。
- 优点：
  - 解耦：观察者模式解除了主题和具体观察者的耦合，让耦合的双方都依赖于抽象，不依赖具体，从而使得各自的变化都不会影响另一边的变化。
- 缺点：
  - 需考虑异步：在应用观察者模式时需要考虑以下开发短路问题，程序中包括一个被观察者和多个观察者，开发和调试比较复杂，而且Java中的消息通知默认是顺序执行的，一个观察者的卡顿会影响整体的执行效率，因此，在这种情况下，一般考虑采用异步的方式。
  - 需考虑进一步解耦：如果依赖关系未完全解除，如抽象通知者依旧依赖抽象的观察者，这时可以采用委托的方式（引用方法类型）来解决。
- 使用场景：
  - 当一个抽象模型有两个方面，其中一个方面依赖于另一个方面，需要将二者封装在独立的对象中，以使它们可以各自独立地改变和复用时。
  - 当一个对象的改变需要同时改变其他对象，但又不知道具体有多少对象需要改变时。
  - 当一个对象必须通知其他对象，但它又不知道其他对象是谁时，也就是希望这些对象之间不是紧密耦合的。

```java
// 客户类
public class Client {
    public static void main(String[] args) {
        CustomerA customerA = new CustomerA();
        customerA.addObserver(new Cashier(customerA));
        customerA.addObserver(new Accountant(customerA));
        customerA.addObserver(new Dilliveryman(customerA));
        customerA.payOrder();
    }
}

// 客户主题抽象类
public abstract class CustomerSubject {

    private Vector<JobStation> observers = new Vector<>();

    private String state;

    public void addObserver(JobStation jobStation){
        observers.add(jobStation);
    }

    public void removeObserver(JobStation jobStation){
        observers.remove(jobStation);
    }

    public abstract void payOrder();

    public Vector<JobStation> getObservers() {
        return observers;
    }

    public String getState() {
        return state;
    }

    public void setState(String state) {
        this.state = state;
    }
}

// 具体主题类：具体客户类A
public class CustomerA extends CustomerSubject {

    @Override
    public void payOrder() {
        super.setState("已付款");
        System.out.println("我是用户, 我已经完成订单付款...");
        for(JobStation jobStation : super.getObservers()){
            jobStation.updateJobState();
        }
    }
}

// 抽象观察者: 工作岗位接口
public interface JobStation {

    public void updateJobState();
}

// 具体观察者：出纳工作人员
public class Cashier implements JobStation{

    private String state;

    private CustomerSubject customerSubject;

    public Cashier(CustomerSubject customerSubject) {
        this.customerSubject = customerSubject;
    }

    @Override
    public void updateJobState() {
        if(customerSubject.getState().equals("已付款")){
            this.state = "已入账";
            System.out.println(String.format("我是出纳员, 我来登记入账 => %s.", this.state));
        }
    }
}
```

### 2.3. 建造者模式

将一个复杂对象的**构造与他的表示分离**，使同样的构建过程可以创建不同的表示。

- 特点：
  - 将一个复杂的对象分解为多个简单的对象，然后一步步构建而成，它将变与不变相分离，即产品的组成部分是不变的，但每一部分是可以灵活选择的。
  - 当需要创建的产品具备复杂创建过程时，可以抽取公共创建过程，然后交由具体实现类自定义创建流程， 使得同样得创建行为可以生产出不同的产品，分离了创建与表示，使创建的产品灵活性大大增加。
- 组成：
  - 指挥者：Director，它调用建造者对象中的部件构造与装配方法完成复杂对象的创建，在指挥者中不涉及具体的产品信息。
  - 抽象构造者：Builder，它是一个包含创建产品各个子部分的抽象方法的接口，通常还包含一个返回复杂产品的getResult()方法。
  - 具体构造者：Concrete Builder，实现Builder接口，完成复杂产品的各个部件的具体方法。
  - 产品：它是包含多个部件的复杂对象，由具体建造者来创建其各个零部件。
- 过程：

1. 指挥者Director直接和客户Client进行需求沟通。
2. 沟通后，指挥者将客户创建产品的需求划分为各个部件的建造请求Builder。
3. 将各个部件的建造请求委派到具体的建造者ConcreteBuilder。
4. 各个具体建造者ConcreteBuilder负责进行产品部件的构建。
5. 最终构建成具体产品Product。

- 优点：
  - 封装性好：构建和表示分离，即同样的构建过程能取到不同的表示。
  - 扩展性好：各个具体的构造者独立，有利于系统的解耦。
  - 易用：客户端不必知道产品内部组成的细节，建造者可以对创建过程逐步细化，而不对其他模块产生任何影响，便于控制细节风险。
  - 灵活：改造多参数构造对象可以使得传递参数更加灵活，代码具有更高的可读性。
- 缺点：
  - 范围限制：产品的组成部分必须相同，这限制了其使用范围。
  - 维护成本高：如果产品的内部变化复杂，当产品内部发生变化时，则建造者也要同步修改，后期维护成本较大。
- 使用场景：
  - 相同的方法，当有不同的执行顺序时，产生不同的结果时。
  - 多个部件零件，都可以装配到一个对象中，但是产生的结果又不相同时。
  - 产品类非常复杂，或者产品类中不同的调用顺序产生不同的作用时。
  - 初始化一个对象特别复杂，参数多， 而且很多参数都具有默认值时。
- 建造者模式 VS 工厂模式：
  - 建造者模式注重零部件的**组装过程**，而工厂模式更注重零部件的**创建过程**，但两者可以结合使用。
  - 建造者模式注重方法的**调用顺序,** 而工厂模式注重**创建对象**。
  - **创建对象的方式不同**：建造者模式通过指挥类来指导如何生成对象，包括对象的组装过程和构造步骤。而工厂模式是通过客户端实例化工厂类，然后调用工厂方法获取所需的产品对象。
  - **关注重点不一样**：建造者模式不仅要创建出对象，还要知道对象由哪些部件组成。而工厂模式只需要把对象创建出来就可以了。
  - **创建对象的粒度不同**：建造者模式创建复杂对象，由各种复杂的部件组成，建造顺序不同最终对象部件也会不一样。而工厂模式创建出来的对象都一样或者是一系列的产品族。
  - 如果将抽象工厂模式看成**汽车配件生产工厂**，生产一个产品族的产品，那么建造者模式就相当于一个**汽车组装工厂**，通过对部件的组装生成出一辆完整的汽车。

```java
// 客户类
public class Client {

    public static void main(String[] args) {
        Director directorA =  new Director(new ConcreteBuildA());
        Director directorB =  new Director(new ConcreteBuildB());

        // 获取产品A
        directorA.assembledProduct();

        // 获取产品B
        directorB.assembledProduct();
    }
}

// 指挥者类
public class Director {

    private Builder builder;

    public Director(Builder builder) {
        this.builder = builder;
    }

    // 组装产品
    public Product assembledProduct(){
        builder.buildNilProduct();
        builder.buildPartA();
        builder.buildPartB();
        builder.buildPartC();
        return builder.getProduct();
    }
}

// 抽象Builder类
public abstract class Builder {

    // 构造空属性产品
    protected Product product;

    public abstract void buildPartA();

    public abstract void buildPartB();

    public abstract void buildPartC();

    // 获取产品
    public void buildNilProduct() {
        this.product = new Product();
    }

    // 获取产品
    public Product getProduct() {
        return product;
    }
}

// 具体建造者类A
public class ConcreteBuildA extends Builder{

    @Override
    public void buildPartA() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartA("我是A Part A.");
        System.out.println("A建造者建造了Part A...");
    }

    @Override
    public void buildPartB() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartB("我是A Part B.");
        System.out.println("A建造者建造了Part B...");
    }

    @Override
    public void buildPartC() {
        if(super.product == null){
            throw new RuntimeException("请先构建空产品");
        }

        super.product.setPartC("我是A Part C.");
        System.out.println("A建造者建造了Part C...");
    }
}

// 产品类
public class Product {

    private String partA;
    private String partB;
    private String partC;

    public String getPartA() {
        return partA;
    }

    public void setPartA(String partA) {
        this.partA = partA;
    }

    public String getPartB() {
        return partB;
    }

    public void setPartB(String partB) {
        this.partB = partB;
    }

    public String getPartC() {
        return partC;
    }

    public void setPartC(String partC) {
        this.partC = partC;
    }
}
```



## **5. Java基础**

### 1.1. 面向对象三大特性？

**封装、继承、多态**

- **封装**：对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法。
- **继承**：子类扩展新的数据域或者功能，并复用父类的属性与功能，单继承、多实现。
- **多态**：通过继承（多个子类对同一方法的重写），也可以用过接口（实现接口）。

### 1.2. Java与C++的区别？

Java和C++都是面向对象语言，都能够实现面向对象思想（即**封装、继承、多态**）。

|          | Java                         | C++                |
| -------- | ---------------------------- | ------------------ |
| 继承     | 单继承，可通过接口实现多继承 | 多继承             |
| 访存     | 不提供指针直接访存           | 有指针的概念       |
| 内存管理 | JVM自动管理                  | 程序员需要手动管理 |

### 1.3. 多态是什么？

多态，按字面意思就是多种状态。**在面向对象语言中，接口的多种不同实现方式即为多态，允许将基类的指针或者引用指向派生类的对象，在具体访问时实现方法的动态绑定。**

- 条件：
  - 多态建立在继承的基础上，先有继承才能有多态。
  - 多态另一个条件是，在创建子类时必须使用父类指针以及new实际的子类类型。

### 1.4. static和final关键字？

- **static**：可以修饰属性和方法
  - 修饰属性：
    - 代表类级别属性，所有对象共享一份，随着类的加载而加载，只加载一次，先于对象的创建。
    - 可以使用类名直接调用。
  - 修饰方法：
    - 随着类的加载而加载。
    - 可以使用类名直接调用。
    - 在静态方法中，只能调用静态的成员，以及不可以使用this。
- **final**：最要用于变量、方法、类。
  - 修饰变量：
    - 如果变量是基本数据类型，则其数值一旦在初始化后就不能更改了。
    - 如果是引用类型的变量，则其在初始化后就不能更改指向的对象了。
  - 修饰方法：
    - 锁定方法，防止任何继承类重写其含义（类中所有的private方法都隐式地指定为了final修饰）。
  - 修饰类：
    - 表名这个类不能被继承，其中该类中的所有成员、方法都会被隐式地指定为final修饰。
    - *另：要使一个类不能被继承，除了final关键字外，还可以私有化构造器（不能继承内部类）。*

### 1.4. 抽象类和接口？

- **抽象类**：
  - 包含抽象方法的类，使用abstract修饰。
  - 抽象类不能被实例化。
  - 抽象类只能被继承，所以不能使用final修饰。
  - 使用场景：既想约束子类具有共同的行为，不在乎其如何实现，又想拥有缺省的方法以及拥有实例变量时。
- **接口**：
  - 是一个抽象类型，是抽象方法的集合。
  - 支持多继承，接口中定义的方法默认是public abstract修饰的抽象方法。
  - 使用场景：想要约束多个实现类具有统一行为，不在乎每个实现类如何实现，又想实现类各个功能之间可以没有任何联系（多继承）时。
- 相同点：都不能被实例化、都可以定义抽象方法，靠子类/实现类实现抽象方法。
- 不同点：

| 抽象类                     | 接口                                      |
| -------------------------- | ----------------------------------------- |
| 有构造方法                 | 没有构造方法                              |
| 可以包含普通方法           | JDK7前只能是"抽象方法"                    |
| 只能单继承                 | 支持多继承                                |
| 可以定义各种类型的成员变量 | 只能定义public static final修饰的静态常量 |

### 1.5. 泛型和泛型擦除？

泛型的本质是**参数化类型**。

- 使用方式：可以用在类、接口和方法上，分别成为泛型类、泛型接口和泛型方法，还可以用在方法的参数和返回值上（此时该方法只是普通方法）。
  - 泛型类：
    - 当指定了泛型类型，整个类泛型都必须同一类型。
    - 没有指定泛型类型，整个类可以为任意类型（Object类型）。
  - 泛型接口：
    - 实现泛型接口时，当接口指定泛型类型时，实现类必须保持相同的泛型类型。
    - 当接口没指定泛型类型时，实现类可以不指定泛型类型（Object类型）。
  - 泛型方法：
    - 在修饰符和返回值之间的位置，声明了泛型的才是泛型方法。
    - 而只使用泛型类型参数和返回值的，只是普通方法。
  - 泛型通配符：
    - 泛型的上限：<? extends 类型>，作为实参传递时，只能传递子类及本类类型。
    - 泛型的下限：<? super 类型>，作为实参传递时，只能传递父类级本类类型。
  - 泛型数组：
    - 不可以创建一个确切泛型类型的数组，比如不能List<String>[] ls = new ArrayList<String>[10];
    - 但可以创建一个确切通配符类型的数组，且获取时必须进行类型转换。比如可以List<?>[] ls = new ArrayList<?>[10];
- **泛型擦除**：
  - Java的泛型是伪泛型，使用泛型的时需要加上类型参数，在编译器编译生成字节码时会被去掉，这个过程称为泛型擦除。
  - 比如List<String>类型，在编译之后都会 成为List类型，JVM看到的只是List，因此泛型附加的类型信息对JVM来说是不可见的，**只在编译期间有效，在运行期间无效**。
- **泛型优点**：
  - 可以指定类型，不用强转，代码简洁，提高了编码期间的可读性
  - 保证集合中存的元素都是同一类型的元素，程序更加健壮。
- 桥接方法：
  - 概念：在子类继承泛型父类或者实现泛型接口，并且指定了泛型类型时，编译器会自动在子类中生成桥接方法。
  - 原因：如果不生成桥接方法，在泛型擦除后，父类类型变为了Object类型，而子类方法参数还是指定的类型，此时就不算实现父类或者接口方法了。因此，为了**维持多态性**，会在子类中生成Object类型的桥接方法，其实现是把Object参数强转成指定的类型，方便指向具体的实现方法。

```java
/**
 * 泛型类
 */
public class MyGeneric<T> {

    private T genericCode;

    // 静态方法-不含泛型
    public static void main(String[] args) {

    }

    // 静态泛型方法-含泛型
    public static <E> E test(E args) {
        return args;
    }

    // 构造方法-使用类的泛型
    public MyGeneric(T genericCode) {
        this.genericCode = genericCode;
    }

    // 普通方法-使用类的泛型
    public T getGenericCode() {
        return genericCode;
    }

    // 普通方法-使用类的泛型
    public void setGenericCode(T genericCode) {
        this.genericCode = genericCode;
    }
}
```

### 1.6. Java异常体系？

![1621048569059](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1621048569059.png)

- **Throwalbe**：Java中所有错误或者异常的超类。
- **Error**：指Java运行时系统内部的错误以及资源耗尽的错误。应用程序不会抛出该类对象，如果出现这样的错误，除了告知用户，剩下的就是尽力使程序安全地终止。
- **Exception**：
  - **RuntimeException**：运行时异常，程序应该从逻辑角度尽可能避免这类异常的发生。
  - **非运行时异常**：这类异常必须使用try-catch进行捕捉处理，否则编译器报错。比如IOExceptin、SQLException。

### 1.7. 反射原理以及使用场景？

指在运行状态中，对于任意一个类，都能够知道这个类所有的属性和方法，并且都能够调用它的任意一个方法。

- 原理：首先获取反射类的字节码，然后将字节码中的方法、变量、构造函数等映射成相应的Method、Field、Constructor等对象。
- 反射类Class对象获取方式：
  - **类名.class**：Class personClazz = Person.class，就一份字节码，所以是同一个Class对象。
  - **Object#getClass（）**：每一个对象都有getClass（）方法，用于返回对象真实的Class对象（对象的元数据）。
  - **Class.forName（String）**：根据一个类的权限定名来构建Class对象。
- 使用场景：通用框架开发、动态代理、自定义注解。

### 1.8. Java构造方法？

构造方法，也叫构造函数，是Java中一种特殊的函数，函数名与类名相同，无返回值。

- 一般用于**初始化成员属性和成员方法**，在对象创建时运行，只运行一次。
- 构造方法可以被重载，只有当类中没有显式声明任何构造方法时，才会有默认的无参构造方法。

### 1.9. Java初始化块？

代码初始化块是类的成员之一，每次类的创建会隐式调用它，本质上是一个代码块或者方法体。

初始化块分为**静态初始化块**和**非静态初始化块**，其好处是减少多个构造器内重用的代码。

- **静态初始化**块优先级最高，会在类第一次被加载时最先执行（也在main方法前），在**非静态初始化块**之前执行。

### 2.0. Java this关键字？

- 关键字this代表**当前对象的引用**：当前对象指的是调用类中的属性或者方法的对象。
- 关键字this不可以在静态方法中使用：因为静态方法不依赖于当前类的实例。

### 2.1. 重载与重写的区别？

- **重载**：指可以在同一个类中定义多个同名方法，但要求参数列表不同，与方法返回值无关。成员方法和构造方法都可以进行重载，可以通过重载构造方法来实现多种初始化行为。重载要求如下：
  - 方法必须都在同一个类中。
  - 方法名相同。
  - 方法参数个数或者参数类型不同。
  - 与方法返回值、返回类型、方法修饰符无关。
- **重写**：指子类中方法签名与父类相同的方法，使用@override注解标识。重写要写如下：
  - 方法在父类和子类不同的类中。
  - 方法名相同。
  - 方法参数个数和参数类型都要相同。
  - 方法返回值类型相同，或者子类方法返回值类型是父类方法返回值的一个子类类型。
  - 子类方法不能缩小方法的访问权限。

### 2.2. 基本数据类型与包装类？

**三类八种基本数据类型**，每个基本类型都有对应的包装类。包装类变量是个指针，没初始化前默认为null。

| 种类   | 基本数据类型           | 存储位数 | 取值范围                                                     | 默认值         | 包装类    |
| ------ | ---------------------- | -------- | ------------------------------------------------------------ | -------------- | --------- |
| 数值型 | byte（位）             | 8 bit    | -2^7到2^7 -1                                                 | 0              | Byte      |
| 数值型 | short（短整数）        | 16 bit   | -2^15到2^15 -1                                               | 0              | Short     |
| 数值型 | int（整数）            | 32 bit   | -2^31到2^31 - 1                                              | 0              | Integer   |
| 数值型 | long（长整数）         | 64 bit   | -2^63到2^63 - 1                                              | 0L             | Long      |
| 数值型 | float（单精度浮点数）  | 32 bit   | 负数范围：-3.402823E+38到-1.401298E-45，正数范围：1.401298E-45到3.402823E+38 | 0.0F           | Float     |
| 数值型 | double（双精度浮点数） | 64 bit   | 负数范围：-1.797693E+308到-4.9000000E-324，正数范围：4.9000000E-324到1.797693E+308 | 0.0D           | Double    |
| 字符型 | char（字符）           | 16 bit   | 0到2^16 - 1                                                  | '\u0000'（空） | Character |
| 布尔型 | boolean                | 1 bit    | true和false                                                  | false          | Boolean   |

### 2.3. 序列化与反序列化？

- **序列化**：
  - 指将Java对象转化为字节序列的过程，即将对象的状态转化成字节流，然后可以通过这些值再生成相同状态的对象。
  - 对象序列化，是对象持久化的一种实现方法，是将对象的属性和方法转化为一种序列化的形式，用于存储和传输。
- **反序列化**：
  - 指将字节序列转化为Java对象的过程，即将对象字节序列重建对象的过程。
- 优点：
  - 实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上，通常是放在文件里，比如Redis的RDB。
  - 利用序列化实现远程通信，即在网络上传送对象的字节序列，比如Google的ProtoBuf。
- 反序列失败场景：
  - 如果SerialVersionUID不一致，会导致反序列化失败。

### 2.4. Object类？

**Object类是所有类的父类**，在使用任何类都可以使用Object类中的方法：

- toString（）：默认是 类名+hashCode，一般需要重写。

- equals（）：

  - 默认为==，比较对象的引用地址是否相同。
  - 实际上往往需要重写，用于判断两个类的实例是否逻辑（内容）相等。

- hashCode（）：

  - 对象的哈希码，协定声明相等对象必须具有相等的哈希码，即对象equal则hashCode一定相等，hashCode不等则对象一定不equal；对象不euqal时hashCode可能相等，hashCode相等时可能不equal，比如HashMap散列冲突。

  - 因此**重写equals（）方法时必须重写hashCode（）方法**，因为HashMap#get(String)时使用

    first.hash == hash && ((k = first.key) == key || (key != null && key.equals(k)))

    即hash相等且（地址相同或者对象equal）来获取key对象的值，如果修改后，对象equal但hashCode不等，则HashMap会出错。

- finalize（）：

  - 在垃圾回收前调用，默认为空实现。
  - 子类可以重写finalize（）方法，以配置系统资源或执行其他清除。

- clone（）：深拷贝，类需要实现Cloneable接口。

- getClass（）：用于返回对象真实的Class对象（对象的元数据）。

- wait（）、wait（long）、wait（long，int）、notify（）、notifyAll（）：用于线程等待或唤醒。

### 2.5. String类？

- **String**：使用**数组**存储内容，由于数组使用final修饰，因此String定义的字符串的值是不可变的。
- **StringBuffer**：对方法都加了synchronize关键字，是线程安全的，适用于多线程环境下在字符缓冲区进行大量操作，但效率不如StringBuilder。
- **StringBuilder**：StringBuilder方法没有加synchronzie关键字，是非线程安全的，适用于单线程环境下在字符缓冲区进行大量操作，效率比StringBuffer高。

#### String不可变的好处

1. 可以使用**字符串常量池**，多次创建同样的字符串，可以指向同一个内存地址。
2. 可以很方便地用作HashMap的key，因为通常建议把不可变对象作为HashMap的key。
3. hashCode生成后就不会改变，使用时无需重新计算。
4. 线程安全，因为具备不变性的对象一定是线程安全的。

### 2.6. 动态代理？

[1.7. 代理模式](#1.7. 代理模式)&nbsp;

动态代理，指在实现阶段不用关心代理类，而在**运行阶段**才指定哪一个对象。

> **JDK动态代理**：Proxy类利用反射机制以及一个**实现InvocationHandler的处理类**，生成一个实现了原委托类接口（为了可以调用被代理方法） 和 继承了Proxy类（为了持有已经实现InvocationHandler实例的引用） 的代理类，使得在调用代理类具体方法时去调用实现InvocationHandler接口的处理类里的方法。
>
> **CGLIB动态代理**：利用ASM开源包，通过**修改委托类的Class文件的字节码生成子类**来处理，其中主要是生成的子类去覆盖原本委托类中的方法，并在覆盖方法中实现增强，但是因为采用的是继承，所以对于final类或者方法是无法继承和代理的。

#### 1. JDK动态代理 VS CGLIB动态代理

- JDK动态代理：在调用代理类方法时，是通过引用调用InvocationHandler实现类的invoke方法，然后再反射调用委托类的方法，**属于反射调用，存在一定的性能花销**。
- CGLIB动态代理：在调用代理类方法时，是通过引用调用MethodInterceptor实现类的intercept方法，然后通过方法签名的index索引，去代理类的FastClass查找到代理类中具体的方法，最后该方法调用父类（原委托类）的方法, **属于父类方法调用，性能花销小**。

|               | JDK动态代理                              | CGLIB动态代理                                                |
| ------------- | ---------------------------------------- | ------------------------------------------------------------ |
| 生成代理Class | 生成效率高                               | 每次都会生成新的FastClass文件，所以Class生成效率会比JDK动态代理的低 |
| 方法调用      | 属于反射调用，调用效率较低               | 属于父类方法调用，所以调用效率会比JDK动态代理的高            |
| 实现原理      | 如果原委托类没有实现接口时，则不可以使用 | 原委托类有无实现接口一样可以使用，但不可以代理private和final修饰的方法 |
| 使用场景      | 比较适合代理非代理对象                   | 无需频繁创建代理对象，比较适合代理单例对象                   |
| 迭代状态      | 每个JDK版本都有迭代，性能得到增强        | 止步不前                                                     |

#### **2. JDK动态代理**

为了解决静态代理中代理类接口过多的问题，可以通过JDK自带的java.lang.reflect.Proxy类，通过反射实现动态代理。

##### 使用步骤

1. 编写一个委托类的接口：如UserService，把实现方法save（）声明出去。
2. 实现一个真正的委托类：即UserServiceImpl，实现接口save（）方法。
3. 创建一个动态代理类：实现InvocationHandler接口，并重写invoke方法，在实际调用前后编写需要代理的业务逻辑。其中**动态代理类需要持有委托类的引用**，用于反射调用委托类的save()实现方法。
4. 客户端生成代理对象：在客户端中生成动态代理类对象，调用声明的save（）方法。

- **newProxyInstance（）方法参数**：
  - **ClassLoader loader**：原委托类的类加载器。
  - **Class<?>[] interfaces**：原委托类实现的接口类型数组。
  - **InvocationHandler**：事件处理类，代理对象方法调用的实际处理者。在执行原委托类方法时，会触发该事件处理器，把原委托类的方法作为Method参数传入，供代理对象使用。

```java
// 委托类接口：用户服务接口
public interface UserService {

    public void save();
}

// 真正的委托类：用户服务接口实现类
public class UserServiceImpl implements UserService {

    @Override
    public void save() {
        System.out.println("保存用户信息...");
    }
}

// 动态代理类：用户服务实现JDK动态代理类
public class UserServiceImplJdkProxy implements InvocationHandler {

    private UserService userService;

    public UserServiceImplJdkProxy(UserService userService) {
        this.userService = userService;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理前...");

        Object result = method.invoke(userService, args);

        System.out.println("JDK动态代理后...");
        return result;
    }
}

// 客户端生成代理对象
public class Client {

    public static void main(String[] args) throws Throwable {
        UserServiceImplJdkProxy userServiceImplJdkProxy = new UserServiceImplJdkProxy(new UserServiceImpl());
        
        UserService userService = (UserService) Proxy.newProxyInstance(
                UserServiceImpl.class.getClassLoader(), new Class[]{UserService.class}, userServiceImplJdkProxy);
        
        userService.save();
    }
}
```

##### 实现原理

- **源码分析**：

1. newProxyInstance（）通过反射生成含有接口方法的Proxy Class，其中Proxy Class又继承了Proxy类。
2. $Proxy0构造方法中，调用父类的构造方法，Proxy父类得到InvocationHandler的实例引用。
3. 最后该代理对象的所有方法调用，都会反射转发到InvocationHandler.invoke（）方法。
4. InvocationHandler.invoke（）：允许在原委托类的业务方法的反射调用前后，织入其他代码，从而实现动态代理。

```java
// com/sun/proxy/$Proxy0.java
public final class $Proxy0 extends Proxy implements UserService
{
    private static Method m3;// com.jsonyao.cs.proxyPattern.UserServic => save()

    static
    {
            // 反射获取UserService接口的save()方法
            m3 = Class.forName("com.jsonyao.cs.proxyPattern.UserService").getMethod("save", new Class[0]);
            ...
    }
    
    // 20201112 构造方法
    public $Proxy0(InvocationHandler invocationhandler)
    {
        // 20201112 调用父类构造器, 赋值自定义InvocationHandler
        super(invocationhandler);
    }
    
    // 20201112 实现了UserService的save()方法
    public final void save()
    {
            // 20201112 调用父类注入的invocationHandler实例实现的invoke()方法
            // 20201112 参数分别为Object proxy, Method method, Object[] args
            super.h.invoke(this, m3, null);
            return;
    }
    
    ...
}
```

#### 3. CGLIB动态代理

解决委托类没有实现任何接口时的动态代理。

##### 使用步骤

1. 实现一个MethodInterceptor：方法调用会被转发到该类的intercept（）方法。
2. 客户端构建CGLIB Enhacner：指定原委托类，以及回调接口实现类MethodInterceptor。
3. 客户端获取代理对象执行业务方法：调用Enhacner#create（）方法得到代理对象，使用代理对象调用业务方法。

```java
// CGLIB动态代理方法拦截类
public class MyMethodInterceptor implements MethodInterceptor {

    public static final HelloCglib helloCglib = new HelloCglib();

    /**
     * @param obj => 20201113 增强后的代理对象
     * @param method => 20201113 原始方法
     * @param objects => 20201113 参数数组
     * @param methodProxy => 20201113 可以使用methodProxy#invokeSuper调用FastClass方法
     */
    @Override
    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理前...");

// 20201113 实际是调用了FastClass的invoke方法, 去调用父类的原方法, 对比JDK动态代理提高了性能
        Object object = methodProxy.invokeSuper(o, objects);
     
        System.out.println("CGLIB动态代理后...");
        return object;
    }
}

public class Client {

    public static void main(String[] args) throws Throwable {
        // 设置代理类生成的目录
        System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, ".\\cglib\\classes");

        // 构建CGLIB Enhacner, 指定原委托类，以及回调接口实现类MethodInterceptor
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(HelloCglib.class);
        enhancer.setCallback(new MyMethodInterceptor());
        
        // 客户端获取代理对象执行业务方法：final方法不会被代理
        HelloCglib helloCglib = (HelloCglib) enhancer.create();
        helloCglib.helloAagin();
    }
}
```

##### 实现原理

- 利用ASM开源包，通过**修改委托类Class文件的字节码**生成子类，去覆盖原委托类的方法，并在覆盖方法中实现了增强。
- 在调用代理类方法时，通过引用调用MethodInterceptor实现类的invoke方法，然后通过**方法签名的index索引去代理类的FastClass中查找**代理类中具体的方法，最后调用该方法时调用父类即原委托类的方法，从而实现动态代理。
- **源码分析**：
  1. Enhancer#setSuperclass（Class）：设置委托类为Enhancer的成员变量。
  2. Enhancer#setCallback（Callback）：设置回调函数实例为Enhancer的成员变量。
  3. Enhancer#create（）：使用父类、接口、过滤器、回调函数、版本号等信息生成标识类的key -> 构造出multi-values key对象 => 用于获取/设置缓存。
  4. AbstractClassGenerator#create（Object key）：生成字节码增强文件，并设置multi-values key对应的缓存。
  5. Enhancer#createUsingReflection（Class）：设置代理对象的回调函数实例（其中MethodInterceptor实现了Callback接口，实际上callback就是实现的MethodInterceptor实例）以及反射生成代理对象实例。
  6. 代理对象HelloCglib$$EnhancerByCGLIB$$6bf7bfad的static初始化块：调用MethodProxy.create生成原委托类方法、代理对象代理方法的签名。
  7. MethodProxy.create（Class, Class, String，String, String）：生成原委托类方法、代理对象代理方法的签名。
  8. MethodProxy#invokeSuper(o, objects)：o: 增强后的代理对象, objects参数列表。
  9. 代理对象的FastClass HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271#getIndex（Signature）：根据原委托类方法、代理对象的代理方法的签名生成FastClassInfo索引。
  10. 代理对象的FastClass HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271#invoke(int , Object , Object)：根据代理方法索引、代理对象、参数列表调用FastClass方法。
  11. 代理对象HelloCglib$$EnhancerByCGLIB$$6bf7bfad#CGLIB$helloAagin$5()：调用代理对象的CGLIB$helloAagin$5()方法。
  12. 原委托类HelloCglib#helloAagin（）：调用父类HelloCglib原委托类的helloAagin方法，避免反射调用，提高性能。

```java
// Enhance类
public class Enhancer extends AbstractClassGenerator
{
    // 1. 设置委托类为Enhancer的成员变量
    public void setSuperclass(Class superclass) {
    	...
        // 如果不是接口且父类不是Object类, 则设置父类为自己本身
        this.superclass = superclass;
    }
    
    // 2. 设置回调函数为Enhancer的成员变量
    public void setCallback(final Callback callback) {
        setCallbacks(new Callback[]{ callback });
    }
    
    // 3. Enhancer#create()
    private Object createHelper() {
    	...
        // 使用父类、接口、过滤器、回调函数、版本号等信息生成标识类的key -> 构造出multi-values key对象 => 用于获取/设置缓存
        return super.create(KEY_FACTORY.newInstance((superclass != null) ? superclass.getName() : null, ReflectUtils.getNames(interfaces), 
        											filter,
                                                    callbackTypes,
                                                    useFactory,
                                                    interceptDuringConstruction,
                                                    serialVersionUID));
                                                    
    // 类abstract public class AbstractClassGenerator implements ClassGenerator
    // 4. super#create()生成字节码增强文件，并设置multi-values key对应的缓存
    protected Object create(Object key) {
    	...
		if (gen == null) {
			// 根据默认策略生成代理对象的Class文件字节流
			byte[] b = strategy.generate(this);
			// 根据字节流获取Class文件名
			String className = ClassNameReader.getClassName(new ClassReader(b));
			// 添加Class文件名到类加载器中
			getClassNameCache(loader).add(className);
			// 根据Class文件名 & Class文件字节流 & 类加载器生成代理对象的Class
			gen = ReflectUtils.defineClass(className, b, loader);
		}
		// 添加代理类Class对象到类加载器缓存中
		if (useCache) {
			cache2.put(key, new WeakReference(gen));
		}
		
		// 5. 生成代理对象实例
		return firstInstance(gen);
    }
    // 类abstract public class AbstractClassGenerator implements ClassGenerator
    
    // 5. Enhancer类生成代理对象实例
    protected Object firstInstance(Class type) throws Exception {
        if (classOnly) {
            return type;
        } else {
            return createUsingReflection(type);
        }
    }
    private Object createUsingReflection(Class type) {
        // 5. 设置代理对象的回调函数, 其中MethodInterceptor实现了Callback接口, 实际上callback就是实现的MethodInterceptor
        setThreadCallbacks(type, callbacks);
        ...
        // 5. 反射生成代理对象实例
        return ReflectUtils.newInstance(type);
    }
}

// CGLIB代理类，原委托类为HelloCglib
public class HelloCglib$$EnhancerByCGLIB$$6bf7bfad extends HelloCglib implements Factory
{
	    static void CGLIB$STATICHOOK1()
    {
    	// Method数组: 含动态代理生成的方法 & 原委托类所有非Final的方法
        Method amethod[];
        // 之前设置的回调函数
        CGLIB$THREAD_CALLBACKS = new ThreadLocal();
        // 代理对象的Class对象
        Class class1 = Class.forName("com.jsonyao.cs.proxyPattern.HelloCglib$$EnhancerByCGLIB$$6bf7bfad");
        // 原委托类的Class对象
        Class class2;
        
        // 6. 静态代码块: 调用MethodProxy#create生成原委托类方法、代理对象代理方法的签名
        CGLIB$helloAagin$5$Proxy = MethodProxy.create(class2, class1, "()V", "helloAagin", "CGLIB$helloAagin$5");
        ...
    }
    
    // 11. 调用代理对象的CGLIB$helloAagin$5()
    final void CGLIB$helloAagin$5()
    {
    	// 12. 最后一步：调用父类HelloCglib原委托类的helloAagin方法，避免反射调用，提高性能
        super.helloAagin();
    }
}

// MyMethodInterceptor#invoke（）入参：MethodProxy
public class MethodProxy {

    // 7. 生成原委托类方法、代理对象代理方法的签名
    public static MethodProxy create(Class c1, Class c2, String desc, String name1, String name2) {
        MethodProxy proxy = new MethodProxy();
        proxy.sig1 = new Signature(name1, desc);
        proxy.sig2 = new Signature(name2, desc);
        proxy.createInfo = new CreateInfo(c1, c2);
        return proxy;
    }

    // 8. Object object = methodProxy.invokeSuper(o, objects);
    // 8. o: 增强后的代理对象, objects参数列表
    public Object invokeSuper(Object obj, Object[] args) throws Throwable {
        try {
        	// 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
            init();
            FastClassInfo fci = fastClassInfo;
            
            // 10. 根据代理方法索引、代理对象、参数列表调用FastClass方法
            return fci.f2.invoke(fci.i2, obj, args);
        } catch (InvocationTargetException e) {
            throw e.getTargetException();
        }
    }
    
    private static class FastClassInfo
    {
        FastClass f1;
        FastClass f2;
        int i1;
        int i2;
    }
    
    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
    private void init()
    {
        if (fastClassInfo == null)
        {
            synchronized (initLock)
            {
                if (fastClassInfo == null)
                {
                    CreateInfo ci = createInfo;

                    FastClassInfo fci = new FastClassInfo();
                    fci.f1 = helper(ci, ci.c1);
                    fci.f2 = helper(ci, ci.c2);
                    fci.i1 = fci.f1.getIndex(sig1);
                    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
                    fci.i2 = fci.f2.getIndex(sig2);
                    fastClassInfo = fci;
                    createInfo = null;
                }
            }
        }
    }
}

// FastClass抽象父类
abstract public class FastClass
{
	abstract public int getIndex(Signature sig);
    
    abstract public Object invoke(int index, Object obj, Object[] args) throws InvocationTargetException；
}

// 20201113 HelloCglib代理后的FastClass文件
public class HelloCglib$$EnhancerByCGLIB$$6bf7bfad$$FastClassByCGLIB$$9448a271 extends FastClass {
    
    // 9. 根据原委托类方法、代理对象代理方法的签名生成FastClassInfo索引
     public int getIndex(Signature var1) {
        String var10000 = var1.toString();
         switch(var10000.hashCode()) {
            ...
        	case -1512990617:
            	if (var10000.equals("CGLIB$helloAagin$5()V")) {
                	return 16;
            	}
            	break;  
            ...
         }
     }
    
    // 10. 根据代理方法索引、代理对象、参数列表调用FastClass方法
    public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException {
        6bf7bfad var10000 = (6bf7bfad)var2;
        int var10001 = var1;
        try {
            switch(var10001) {
                ...
                case 16:
                    // 11. 调用代理对象的CGLIB$helloAagin$5()
                	var10000.CGLIB$helloAagin$5();
                	return null;
                ...
            }
        }
    }
}
```

### 2.7. 值传递、引用赋值、引用复制？

- **值传递**：基本类型变量的赋值为**值传递**，比如int i = 1。
- **引用赋值**：对象变量的赋值为**引用赋值**，即新变量和老变量具有相同的引用。
- **引用复制**：对象作为方法参数传递，传递的是原对象引用的副本，即发生了**引用复制**。
  - 在引用副本所引用的对象，如果没有提供操作对象成员变量的方法，该引用副本不会修改原引用的对象，比如String。
  - 在引用副本所引用的对象，如果有提供操作对象成员变量的方法，该引用副本会修改原引用的对象，比如StringBuilder.append(i)。
  - 引用副本在被更改后，不会影响到原引用的值。

### 2.8. 基本类型、对象类型、数组类型引用的内存分布情况？

- **基本类型**：boolean、byte、short、char、int、float以及对应的引用类型**在栈上**占4个字节，long、double在栈上占8字节。也就是此时对于每个方法来说，栈上的空间在编译时已经确定了的。
- **对象类型**：比如new Object（）**在堆中分配空间**，再由**栈引用指向堆中的对象**。
  - **字符串类型**：比如String str = new String("hello")，此时类似于对象类型的内存分布情况，**栈中的str**引用指向**堆中**的String对象的首地址，而String对象里有char[] chars、int startIndex、int length属性，其中chars引用指向‘h’ ‘e’ ‘l’ ‘l’ ‘o’**字符数组**的首地址。
- **数组类型**：**栈中**的引用指向**一维数组（行）**的首地址，**堆中**开辟实际数组的空间。
  - **一维数组**：比如int[] arr = new int[2]，此时栈中的arr引用占4个字节，指向堆中开辟的2个连续的int 4个字节空间的首地址。
  - **二维数组**：比如int[][] arr2 = new int[2] [4]，此时栈中的arr2引用还是占4个字节，指向堆中开辟的2个连续的int[]4个字节的空间的首地址，而每个int[]引用又指向堆中开辟的4个连续的int 4个字节空间的首地址。
    - **二维空数组**：比如int[][] arr3 = new int[2] []，此时栈中的arr2引用还是占4个字节，指向堆中开辟的2个连续的int[] 4个字节的空间的首地址，而每个int[]引用为null。

### 2.9. 引用与指针？

- **引用**：**引用一旦指向了对象，则不能再被更改，即使对象变了引用的东西也会跟着变，强调的是对象的不变性**（即一定要"小明干活"），**类似于对象的别名**，比如对象（员工）"小明"改名为了"小强"，此时引用（上司）还是知道那个对象叫是"小强"，即引用强调的是员工（对象）的不变性。
- **指针**：**指针允许自由操作地址的指向，强调的是指向的地址是自由的**，即关系自由性（谁干活不重要, 但一定要有人干），比如指针（上司）与地址"小明"分配工作内容，但第二天地址"小明"辞职了，这时指针（上司）可以把活分配给新的地址"小强"，即改变了指向的地址。
- **混淆点**：引用类似于指针，与指针一样，查看引用可以知道具体指向的地址，但引用并不能操作该地址的指向。但是**Java中没有指针，只有引用**：
  - **Java中谈引用是从内存分析的角度思考的**，分析引用指向那个对象，这种引用的对象到底什么时候可以被回收等等。
  - 而**谈的“指针’”是从数据结构的角度思考**，比如这个链表头指针移动到哪里哪里等等，实际上移动到哪里哪里，但实际也还是引用的赋值，因为从内存的角度来说，就是把新的头节点的引用赋值给原来的头节点，因此也还是引用。
  - 所以**Java没有指针，只有引用**。

### 3.0. Java四种引用类型？

![1623655664473](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1623655664473.png)

#### 强引用

- **概念**：
  - jdk 1.8包中没有这个类，是普通类的引用。
  - M m = new M（），此时m为强引用对象。
- **特点**：
  - **强引用“引用”（动词）的对象永远不会被垃圾收集器回收**，即使将要发生OOM（OutOfMemoryError）。
  - **普通引用**就是强引用对象，可直接访问“引用”的对象。
- **使用场景**：直接访问“引用”的对象，做业务操作。

#### 软引用

- **概念**：
  - SoftReference，Reference引用抽象基类的实现类。
  - SoftReference m = new SoftReference（new M（）)，此时m为软引用对象。要注意的是，虽然m为软引用对象SoftReference，但在内存分布中，栈m到堆SR之间是强引用（普通引用）关系，而**SR内部到M才是真正的软引用关系**。
- **特点**：
  - 只被软引用“引用”的对象不会被垃圾收集器立即回收，垃圾收集器会根据内存需求自行是否决定清除“引用”的对象：**只有在堆内存不足时**，垃圾收集器才会去回收只被软引用“引用”的对象。
  - 在虚拟机抛出 OutOfMemoryError 之前，保证清除软可达对象的所有软引用，鼓励虚拟机实现偏向于**清除最近创建或最近使用的软引用**。
  - **先清除软引用，再将软引用加入引用队列**：垃圾收集器在某个时间点确定被软引用"引用"的对象是软可达的，此时会以原子方式清除“引用”的对象的所有软引用，以及对任何其他软可达对象的所有软引用，**同时或稍后会将已经注册到引用队列的新清除的软引用加入引用队列**。
- **使用场景**：常用于实现内存敏感的缓存，比如Guava中的LocalCache。

#### 弱引用

- **概念**：
  - WeakReference，Reference引用抽象基类的实现类。
  - WeakReference m = new WeakReference(new M（）)，此时m为弱引用对象。要注意的是，虽然m为弱引用对象WeakReference，但在内存分布中，栈m到堆WR之间是强引用（普通引用）关系，而**WR内部到M才是真正的弱引用关系**。
- **特点**：
  - 垃圾收集器一旦发现了只被弱引用“引用”的对象，**无论堆内存是否足够**，都会回收“引用”的对象的内存。
  - **先清除弱引用，再将弱引用加入引用队列**：垃圾收集器在某个时间点确定被弱引用“引用”的对象是弱可达的，此时会以原子方式清除“引用”的对象的所有弱引用，以及对任何其他弱可达对象的所有弱引用，以及声明所有以前弱可达的对象是可终结的，**同时或稍后会将已注册到引用队列的弱引用加入队列**。
- **使用场景**：
  - 常用于实现规范化Map集合，如ThreadLocal的Entry#Key对象。
  - 这是因为在Map集合实现的缓存中，会出现**无用Key对象被Map实例强引用导致出现内存泄露问题**（即没用的对象没被释放掉），这时弱引用包装的真实的Key对象，使用弱引用实例来作为key，可以缩短Key的生命周期，使得Key可以更快地被垃圾收集器回收掉，从而解决无用Key对象带来的内存泄露问题。
  - 要注意的是，如果使用弱引用包装Key对象，在真实的Key对象被回收后，弱引用实例的Key会被置为null，形成null-Value的键值对，导致**出现无用Value对象的内存泄露问题**。这就需要真实的Key对象被回收时，删除对应的弱引用实例-Value键值对，解决无用Value对象带来的内存泄露问题。

#### 虚引用

- **概念**：
  - PhantomReference，Reference引用抽象基类的实现类。
  - PhantomReference m = new PhantomReference（new M（），new ReferenceQueue（）），此时m为虚引用对象。要注意的是，虽然m为虚引用对象PhantomReference，但在内存分布中，栈m到堆PR之间是强引用（普通引用）关系，而**PR内部到M才是真正的虚引用关系**，且虚引用创建时必须绑定一个引用队列。
- **特点**：
  - 只被虚引用“引用”的对象跟没有被“引用”是一样的，**“引用”的对象随时会被垃圾收集器回收**。
  - 虚引用“引用”的对象不能被检索到，即通过**调用虚引用的get（）总是返回null**。
  - **加入引用队列不需要先清除与对象的“引用”**：在垃圾收集器确定**“引用”的对象可能会被回收后**，会将其上的虚引用对象加入引用队列进行排队（此时没有清除与对象之间的“引用”）。
- **使用场景**：常用于调度预检清理操作，比如JVM用于管理堆外内存（直接内存）的释放。

![1623670905412](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1623670905412.png)

### 3.1. ArrayList与LinkedList？

|                    | ArrayList                                      | LinkedList                         |
| ------------------ | ---------------------------------------------- | ---------------------------------- |
| 实现接口           | List                                           | List、Deque                        |
| 数据结构           | 基于数组实现                                   | 基于双向链表实现                   |
| 提供的API          | List方法                                       | 栈、队列、双端队列方法             |
| 插入元素           | 数组尾部                                       | 链头、链尾两个方向都可以           |
| 初始容量与扩容机制 | 10，每次扩容1.5倍容量                          | 无容量限制，无扩容机制             |
| 适用场景           | 支持对元素进行快速随机访问，适合随机查找和遍历 | 适合数据的动态插入和删除           |
| 不适合场景         | 不适合大量插入和删除                           | 不支持元素的随机访问，必须遍历链表 |

### 3.2. 如何实现List线程安全？

- List API外层使用**锁**保证线程安全。
- **Collections内部类SynchronizedList**，通过持有传入的List引用，以及Object mutex对象锁，提供synchronized关键字修饰List接口方法，从而包装成线程安全的List。
- **Vector**，可增长数组，默认容量10，默认容量扩容2倍，通过使用synchronized关键字修饰方法保证线程安全。
- **CopyOnWriteArrayList**，写时复制，读操作不需要加锁，只保证数据最终一致性，无法保证实时性。

### 3.3. 快速失败fail-fast机制？

- **大多数迭代器都是快速失败的**，即如果在创建迭代器后的任何时间**对结构进行结构修改（modCount）**，则除了通过迭代器自己的remove方法之外，该迭代器都将抛出{ @link ConcurrentModificationException}。
- 这在**面对并发修改时，迭代器可以快速干净地失败**，而不是在未来不确定的时间冒着任意、非确定性行为的风险去修改。
- 无法保证迭代器的快速失败行为，因为一般而言，在存在非同步并发修改的情况下，不可能做出任何硬保证，**只会尽最大努力抛出ConcurrentModificationException，**因此，编写一个依赖于这个异常来保证其正确性的程序是错误的，**快速失败行为只适用于检测错误**。

### 3.4. 详细介绍HashMap?

#### 特点

- **HashMap，Map接口基于散列表的非线程安全的实现，允许null值和null键，不保证元素的顺序**。所以，在散列表均匀分散元素的情况下，get和put方法时间复杂度为O（1），而迭代所需的时间与其**容量**（散列表桶数）和**实际大小**（键值对数）成正比，因此不要设置过高的初始容量或者过低的负载因子（会导致大容量）。
- 几个重要的参数：
  - **当前容量**：当前容量是散列表中存储桶的数量，而初始容量只是创建散列表的容量。
  - **负载因子**：等于实际大小 / 当前容量，当散列表中的条目数超过阈值（负载因子和当前容量的乘积）时，HashMap发生扩容，使散列表具有大约两倍容量（桶数）。
  - **阈值**：等于负载因子 * 当前容量，默认为16（即默认容量），当table为空表时，则在扩容时用作新表的容量；否则，用作判断是否扩容的条件，如果当前容量大于阈值，则需要扩容散列表。
  - **实际大小**：HashMap所有的条目总数。
- **默认提供的负载因子0.75，在时间和空间成本之间提供了很好的权衡**：
  - 较高会减少空间的开销，但增加了查找的成本（由于高负载因子，导致扩容次数减少，桶拉链变长）。
  - 较低会增加扩容的次数，增加空间的开销，但好在桶拉链变短，查找效率高，哈希冲突少。
- HashMap的所有迭代器都是**快速失败**的，即如果在创建迭代器后的任何时间对结构进行结构修改，则除了通过迭代器自己的remove方法之外，该迭代器都将抛出{ @link ConcurrentModificationException}。

#### 数据结构

数组 + 链表 + 红黑树：

![1625405326188](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625405326188.png)

#### 构造方法

- 4个构造方法，分别为空参的、指定初始容量的、指定初始容量和负载因子的、指定复制集合的。
- 默认负载因子为0.75，默认容量为16。

#### HashCode扰动函数

- **hash（Object）**，将HashCode右移16位，从而混合HashCode的高位和低位，加大低位的随机性，减少哈希碰撞发生的概率，是一种**性能、效用和质量**的折衷方案。
  - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查
    找效率。
  - HashCode右移16位，使得高位能被利用起来，保证了效用性。
  - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。

#### 哈希索引的计算方法

- **（n - 1） & hash，相当于hash % n**：n指散列表的当前容量（桶数量），hash指获取hash（key）即key的hashCode扰动后结果。
  - **不能直接使用HashCode作为索引的原因**：int类型的hashCode，范围为[-2^32，2^32 - 1]，如果散列表
    数组与HashCode一一对应，需要40亿的空间（int[40亿]），明显这在内存是放不下的，也就是说明
    hashCode是不能直接作为数组索引的。因此，如果使用hashCode对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组也还能利用上hashCode。
  - **n为2的幂次原因**：为了解决hashCode对散列表数组长度取模，设计了HashCode的扰动函数以及为2幂次的容量n，可以通过n-1来获得取模操作的低位掩码，此时**只需要通过低位掩码与扰动后的**
    **hashCode（hash值）进行一次与运算**，即可得到该hash值在散列表数组中的索引。其次通过在扩容方
    法中，经过hash值与低位掩码相与，可以保证扩容后，**只会移动少部分相与结果高位为1的桶链表**，其他
    保持不变，减少了扩容时的时间。
- **通过tableSizeFor（int）返回给定目标容量的2的幂次**，底层通过-1，右移1、2、4、8、16位，再+1得到目标容量。

#### resize扩容方法

1. **扩容前分3种情况判断，来确定新容量和阈值**：
   - 当前容量 > 0，则容量 * 2，阈值 * 2。
   - 当前容量 <= 0，且阈值 > 0，说明HashMap已被初始化且表为空表，则使用阈值作为新的容量。
   - 当前容量 <= 0，且阈值 <= 0，说明HashMap还没被初始化，则使用默认容量16以及默认阈值12=16 * 0.75。
2. **创建新容量的散列表**：(Node<K,V>[])new Node[newCap]；
3. **从头遍历散列表，移动结点**：
   - 如果桶j只有一个元素，则重新计算哈希索引，转移元素到新表即可。
   - 如果桶j为红黑树，则调用红黑树的split方法，拆分红黑树，以重新计算每个结点的哈希索引。根据哈希索引是否不变，拆分成高低lo和hi链表，lo链表移动到新桶时保持原桶位置不动，hi链表往前移动oldCap长度的位置。其中如果拆分后的链表长度小于等于6时，则会把**红黑树退化成普通链表**。
   - 如果桶j为普通链表，则重新计算每个结点的哈希索引，根据哈希索引是否不变，拆分成高低lo和hi链表，lo链表移动到新桶时保持原桶位置不动，hi链表往前移动oldCap长度的位置。

#### put方法

3个常用的顶层API方法put、putIfAbsent、putAll，它们依赖于putVal方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果p桶为null，则直接new Node放到该桶即可。
3. 如果p桶不为null，则分4种情况判断：
   - 如果桶头结点p的hash值相等且（key相等 或者 equals），说明p就是要找的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 否则，如果桶头结点p为红黑树结点，则使用**TreeNode的实例方法putTreeVal**添加key：value。
   - 否则，p为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 如果找不到对应的结点，则在链尾new Node一个结点，并且添加后如果当前链表至少有8个结点，则调用**HashMap的实例方法treeBin**将当前桶链表树化为红黑树（treeBin还会判断散列表容量是否大于等于64）。
4. 如果发生的不是值替换，则更新修改模数、实际大小，如果实际大小大于阈值，则还需要调用resize（）进行扩容并转移结点。最后返回null，代表结点插入成功。

#### remove方法

2个常用的顶层API方法remove（Object）和remove（Object，Object），它们都依赖removeNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果桶p为null，则返回null，代表HashMap不存在对应的结点。
3. 如果p桶不为null，则分4种情况判断：
   - 如果桶头结点p的hash值相等且（key相等 或者 equals），说明p就是要找的结点，将p引用赋值给node引用，待后面做删除操作。
   - 否则，如果桶头结点p没有后继，则将p引用赋值给node引用，待后面做删除操作。
   - 否则，如果p有后继且p为红黑树结点，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点，并将其引用赋值给node引用，待后面做删除操作。
   - 如果p有后继且p为普通结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，并将其引用赋值给node引用，待后面做删除操作。如果找不到，则设置node引用为null。
4. 如果node引用为null，则返回null，代表HashMap不存在对应的结点；如果node引用不为null，说明找到了对应结点（如果此时matchValue为true，则还需要判断value是否equals），则分为3种情况判断：
   - 如果node为红黑树结点，则调用**TreeNode的实例方法removeTreeNode**删除该结点。
   - 如果node为普通结点，且为桶头结点，则脱钩node结点，并更新桶头结点为它的后继。
   - 如果node为普通结点，但不为桶头结点，则链接它的前驱和后继，脱钩node结点。
5. 最后如果脱钩结点成功，则更新修改模数、实际大小，返回node结点。

#### get方法

2个常用的顶层API方法get、getOrDefault，它们都依赖getNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶first。
2. 如果桶first为null，则返回null，代表HashMap不存在对应的结点。
3. 如果first桶不为null，则分4种情况判断：
   - 如果桶头结点first的hash值相等且（key相等 或者 equals），说明first就是要找的结点，则直接返回first结点。
   - 否则，如果桶头结点first没有后继，则返回null，代表HashMap不存在对应的结点。
   - 否则，如果first有后继且first为红黑树结点，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点并返回。
   - 如果first有后继且first为普通结点，则遍历first链表，如果找到hash值相等且（key相等 或者 equals）的结点并返回。如果找不到，则返回null，代表HashMap不存在对应的结点。

### 3.5. HashMap红黑树？

#### TreeNode性质

- **性质1**：红黑树的结点要么是红色，要么是黑色。
- **性质2**：红黑树的根结点是黑色的。
- **性质3**：红黑树的叶子结点（nil）都是黑色的。
- **性质4**：红黑树的红色结点必须有两个黑色结点。
  - **推论**：从根结点到每个叶子结点的所有路径上，不可能存在两个连续的红色结点。
- **性质5**：红黑树是黑色平衡的，即从根结点到每个叶子结点的所有路径中，所经过的黑色结点数都是一样的。
  - **推论**：如果一个结点右黑色的子结点，那么该结点一定是有两个孩子结点，因为必须有另一半才能保证该
    结点黑色平衡。

#### 旋转

- 背景：在结点的添加和删除后，**为了避免子树高度变化，需要通过子树内部调整来保证树达到平衡**，其中2-3-4树是通过结点旋转和结点元素变化实现的，红黑树是通过结点**旋转和变色**实现。
- **左旋**：口诀，**左右左右右**，即以x结点作为旋转点进行**左**旋，旋转后，x的**右**结点p成为x的父结点，p原本的**左**结点成为x结点的**右**结点，p原本的**右**结点保持不变。
- **右旋**：口诀，**右左右左左**，即以x结点作为旋转点进行**右**旋，旋转后，x的**左**结点p成为x的父结点，p原本的**右**结点成为x结点的**左**结点，p原本的**左**结点保持不变。

#### 插入后平衡红黑树

**balanceInsertion（TreeNode，TreeNode）**：对应2-3-4树的情况：

- **a. 空结点新增**：成为一个2结点，插入前树为null，插入后x需要变黑色，作为根结点。
- **b. 合并到2结点中**：成为一个3结点，插入前2结点为黑色，插入后无论是（上黑下左红 |  上黑下右红）, 都符合3结点要求，因此无需调整。
- **c. 合并到3结点中**：成为一个4结点，插入前为3结点（上黑下左红 |  上黑下右红），插入后成为4结点黑红红的情况，根据x插入位置不同分为6种情况：
  - **c.2.1.**  左三(中左左*) ，黑红红，不符合红黑树定义 => 需要调整，则中1右旋，中1变红，左1变黑。
  - **c.2.2.** 中左右*(其实就相当于左三，因为对父结点进行左旋，即得到左三) ，黑红红，不符合红黑树定义 => 需要调整，则左1左旋（得到左三），中1右旋，中1变红，新左变黑。
  - **c.2.3.** 右三(中 右右*) ，黑红红，不符合红黑树定义 => 需要调整，则中1左旋，中1变红，右1变黑。
  - **c.2.4.** 中 右左*(其实就相当于右三，因为对父结点进行右旋，即得到右三) 黑红红，不符合红黑树定义 => 需要调整，则右1右旋（得到右三），中1左旋，中1变红，新右变黑。
  - **c.2.5.** 中左 右*，黑红 红，符合红黑树定义 => 无需调整。
  - **c.2.6.** 中左* 右，黑红 红，符合红黑树定义 => 无需调整。
- **d. 合并到4结点中**：成为一个裂变状态（变色后相当于升元了），插入前为4结点（黑红红），插入后4结点颜色反转，爷结点成为新的x结点，准备下一轮的向上调整，根据x插入的位置不同分为4种情况：
  - **d.2.1.** 中左左* 右(黑红红 红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，左2保持为红， 右1变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.2.** 中左右* 右(黑红红 红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，右1保持为红，右2变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.3.** 中左 右左*(黑红 红红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，左2保持为红，右1变黑，中看作为“插入结点”，继续向上调整。
  - **d.2.4.** 中左 右右*(黑红 红红)，不符合红黑树定义 => 需要调整，则中变红，左1变黑，右1变黑，右2保持为红，中看作为“插入结点”，继续向上调整。

#### 删除结点前/后平衡红黑树

**balanceDeletion（TreeNode，TreeNode）**：删除结点前/后平衡红黑树，如果x所在结点为2-3-4树的2结点，则平衡后再删除，如果x所在结点为3结点或者4结点，在平衡前对应的结点就已经删除了，此时x作为该结点的替代结点而保留下来：

- **x自己搞得定**：
  - 自己搞得定的意思就是，可以**在自己结点内部处理完毕**（对应2-3-4树结构），不影响其他树的结构。
  - **a.1. x为3结点或者4结点的红结点**：直接置黑返回x结点即可调整完毕（因为x是作为替代结点而保留下来的），然后交由上层方法删除x结点。
- **x自己搞不定，兄弟搞得定**：
  - 自己搞不定的意思就是，自身结点为黑结点，如果直接删除会导致父结点所在的树黑色不平衡。
  - 兄弟搞得定的意思就是，**兄弟结点存在多余的子结点**（即兄弟结点为3结点或者4结点），此时，x的父结点就可以借出结点下来合并到x结点中，兄弟结点再借出结点合并到父结点中，这样x就可以顺利删除了，同时2-3-4树的结构还保持不变。
  - 但是，**前提是x的兄弟结点是真正的兄弟结点，即为黑色的结点**，如果为红色的结点，说明其只是父结点（3结点）的红结点，此时需要对父结点进行旋转，以保证x有真正的兄弟结点。
  - **b.1. 兄弟结点为3结点，但无右（左）**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr无右孩子在对父结点左旋时，会导致xpr为null，导致2-3-4树的结构不正确，因此，**b.1是一个临时情况，需要对xpr进行右旋，转换为b.2有右进一步处理**。x为右子树一方时则相反。
  - **b.2. 兄弟结点为3结点，但有右（左）**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr有右，则可以顺利地对父结点xp进行左旋。左旋后，在2-3-4树结构看来，xp作为xpr的左孩子（相当于父结点借出去一个结点，合并到x结点中），xpr作为xp的父亲（**相当于兄弟结点借出去一个结点，合并到父结点中**），xpr借出去的结点颜色为xp借出去的结点颜色，xp借出去的结点颜色一定要为黑色（相当于3结点），xpr剩余结点一定要为黑色（相当于叶子结点），返回x结点即可调整完毕，交由上层方法删除x结点。x为右子树一方时则相反。
  - **b.3. 兄弟结点为4结点，肯定有右**：在x在左子树一方时，x的兄弟结点xpr为右子树，如果xpr有右，则可以顺利地对父结点xp进行左旋。左旋后，在2-3-4树结构看来，xp作为xpr的左孩子（相当于父结点借出去一个结点，合并到x结点中），xpr作为xp的父亲（**相当于兄弟结点借出去一个结点，合并到父结点中，而且还多借出左孩子合并到x结点中**），xpr合并到父结点的颜色为xp借出去的结点颜色（而借出去的左孩子本来为红色所以不用变），xp借出去的结点颜色一定要为黑色（相当于4结点），xpr剩余结点一定要为黑色（相当于叶子结点），返回x结点即可调整完毕，交由上层方法删除x结点。x为右子树一方时则相反。
  - 在b.3中对于兄弟结点为4结点时，兄弟结点可以借出1个结点（需要旋转两次）或者2个结点（只需要旋转一次），**在JDK中无论是HashMap还是TreeMap，都选择借出2个结点，因为可以减少花销。**
- **x自己搞不定，而且兄弟也搞不定**：
  - 自己搞不定的意思就是，自身结点为黑结点，如果直接删除会导致父结点所在的树黑色不平衡。
  - 兄弟也搞不定的意思就是，**兄弟结点也为黑结点，没有多余的子结点**，如果直接删除x，则导致叔结点所在路径多了一个黑色结点，造成黑色不平衡。
  - **c.1. 兄弟结点为2结点**：此时，为了让x能够顺利删除，**兄弟结点需要置红（自损）**，这样x在删除后，x父结点所在树还是黑色平衡的。但是，如果x父结点为黑色，x爷结点所在树则不黑色平衡了（因为父结点这边少了一个黑色结点），所以父结点的叔结点要也要被置红。**因此需要一路向上自损，直到碰到任意一个终止条件即可结束**：
    - **自损的终止条件1（向上碰到根结点）**：经过一路置红叔结点（置红叔结点是没问题的，因为出现该情况是叶子结点为3结点黑黑黑的时候，此时如果叔结点没有孩子结点即为黑色，而对于更上层的叔结点来说，貌似不会出现叔为黑红红这种情况），直到循环到根结点时（因为上面已经没有父节点了），则代表自损完毕，此时整棵树都是黑色平衡的了（都减少了一个黑色结点）。
    - **自损的终止条件2（向上碰到红结点）**：如果碰到红色结点时，只需要把该结点置黑，则不需要在置红叔结点了，此时相当于在父结点这边子树补回了一个黑色结点，而不影响叔结点那边子树的黑色结点数目，因此整棵树还是黑色平衡的。

#### 链表树化成红黑树

HashMap的实例方法treeBin，先判断散列表容量是否大于等于64，如果不是则调用resize扩容即可，否则维护桶链表为**双向无环链表**，接着底层调用**TreeNode的实例方法treeify**树化该链表成为红黑树，其步骤为：

1. 取桶头结点作为根结点，置黑。
2. 遍历桶链表，比较根结点hash值比较当前结点x的hash值大小，小于等于的继续遍历左子树，大于的遍历右子树，然后插入当前遍历结点到对应的位置，再平衡红黑树。

#### 红黑树退化成普通链表

**untreeify（HashMap）**：

1. 遍历桶链表，重新构建后继为null的Node结点，再重新维护每个结点的next指针。
2. 遍历结束，最后返回链头指针hd即可。

#### 添加红黑树结点

**putTreeVal（HashMap，Node，int，K，V）**：红黑树结点的添加方法（插入成功则返回null，插入失败则
返回已经存在的结点）。其步骤为：

1. 从根结点遍历比较插入结点x的hash值，小于等于0的说明x应该在左边，大于0的说明
   x应该在右边。
2. 找到合适位置后（叶子结点），构建TreeNode结点，维护x与父结点、prev结点、next结点的关系。
3. 插入后平衡红黑树，返回null，表示插入成功。

#### 删除红黑树结点

**removeTreeNode（HashMap，Node，boolean）**：

- **替代结点**：红黑树是一种自平衡的二叉搜索树，而二叉搜索树删除，本质上是**找前驱或者后继结点来替代删除**（这里是replacement替代p然后删除p）。
- **A. 如果要删除的结点是叶子结点**：则直接删除即可（肯定为黑色）。
- **B. 如果要删除的结点只有一个孩子结点**：则使用孩子结点进行替代，然后删除"替代结点"。
- **C. 如果要删除的结点有两个孩子结点**：则需要找到前驱或者后继进行替代，然后删除"替代结点"。
  - **C.1. 如果替代结点没有孩子结点**：此时所在的结点为2-3-4树的2结点，则直接要"替代结点"即可。
  - **C.2. 如果替代结点有孩子结点且孩子结点为替代方向**：此时所在的结点为2-3-4树的3结点或者4结点，则继续使用孩子结点进行替代，然后“替代结点”即可（二次替代）。
- 无论是哪种情况，红黑树结点的删除方法，都要调用平衡红黑树的方法，在删除结点前/后平衡红黑树。

#### 获取红黑树结点

**getTreeNode（int，Object）**：

1. 根据hash值和key值，从根结点开始查找红黑树结点，小于等于0的说明x应该在左边，大于0的说明x应该在右边。
2. 直到找到hash值相等且（key相等 或者 equals），说明该结点就是要找的结点，则返回即可。
3. 如果找不到，则返回null，代表没找到对应的结点。

### 3.6. JDK1.7 HashMap与JDK1.8 HashMap的区别？

JDK1.8 主要解决或者优化了以下问题：

- resize（）扩容优化：取消了rehash，分高低位转移链表，保证转移后结点相对顺序不变，从而解决了多线程死循环问题。但HashMap仍是非线程安全的，并发添加结点可能会造成数据丢失。
- 插入方式改成尾插法，同时引用红黑树，避免链表过长影响查找效率，同时保证插入的性能。

|                  | JDK1.7 HashMap                                               | JDK1.8 HashMap                                               |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 数据结构         | 数组 + 链表                                                  | 数组 + 链表 + 红黑树                                         |
| HashCode扰动函数 | 9次扰动（4次移位，5次异或），有哈希种子影响                  | 2次扰动（1次移位，1次异或），无哈希种子                      |
| 扩容方法         | 可以rehash（容量 > 哈希种子阈值时），转移后结点相对顺序反转（头插法） | 无rehash，分高低位转移链表，转移后结点相对顺序不变           |
| 插入方法         | 无冲突，则插入数组；有冲突，则插入链表（头插法）             | 无冲突，则插入数组；有冲突，则插入链表（尾插法）；有冲突 & 插入后链表长度 >= 8，且散列表容量 >=64，则把链表树化成红黑树 |

#### JDK 1.7 HashMap导致CPU 100%的原因？

在多线程环境下，使用HashMap进行put操作时，可能会产生**循环链表**，在下次获取其所在桶链时导致**死循环**，导致CPU利用率飙升，甚至接近100%，因此，在高并发情况下是不能使用HashMap的。

- **原因**：当多个线程并发扩容时，同时进入了transfer转移结点的方法，由于该方法没有做线程同步的处理，且采用的是头插法，在获取**e结点和newTable[i]**时，有可能获取到同一个结点（肯定是旧表的尾结点），接着在后面的e.next = newTable[i]中，对e的后继赋值了e，导致在e结点上产生了**循环链表**。

```java
// 头插法：注意！头插法转移元素会使用的当前链表元素顺序反转，导致并发扩容时获取newTable[i]得到别的线程转移完成的尾结点，从而出现循环链表。而JDK8 HashMap中的分高低位链表转移+尾插法的方式，既可以解决key需要重新计算索引，也可以解决循环链表的出现。
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while(null != e) {
            // 0. 模拟循环链表产生的情况，两个线程A、B并发执行到这里，一个结点e
            // 1. B失去CPU时间片，回到就绪态；A继续执行
            // 3. 此时，B得到CPU时间片，重新回到运行态，获取到的e已经在新桶中了，next为null
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            
            // 2. A执行下面三句后，e放进了新散列表中，此时e.next为null，然后把这个循环链表放在了新散列表的i索引上，而由于next为null，赋值给e后则退出循环，完成结点的转移操作
            // 4. B获取新桶的i索引得到e，此时设置e.next为了e，产生了循环链表！然后把这个循环链表放在了新散列表的i索引上，而由于next为null，赋值给e后则退出循环，完成结点的转移操作
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```

### 3.7. 如果实现散列表线程安全？

- HashMap API外层使用**锁**保证线程安全。
- **Collections内部类SynchronizedMap**，通过持有传入的Map引用，以及Object mutex对象锁，提供synchronized关键字修饰Map接口方法，从而包装成线程安全的Map。
- **HashTable**，散列表的线程安全实现类，默认初始容量11，默认负载因子0.75，不允许为null键和null值，通过使用synchronized关键字修饰方法保证线程安全，效率低下。
- **ConcurrentHashMap**，支持高并发检索和更新的散列表实现类，默认初始容量和负载因子与HashMap一样，不允许为null键和null值，可在保持并发可读的同时最小化锁竞争。

### 3.8. 详细介绍ConcurrentHashMap？

#### 特点

- ConcurrentHashMap，**一个支持高并发检索和高并发更新的散列表实现类**，实现ConcurrentHashMap接口，不允许为null键和null值。其主要设计目标是**保持并发可读性，同时最小化更新时的锁争用**，次要目标是保持与java.util.HashMap相同或更好的空间消耗，并支持许多线程对空表的高初始插入率（自旋+CAS保证）。
- 几个重要的参数：
  - **当前容量**：当前容量是散列表中存储桶的数量，而初始容量只是创建散列表的容量。
  - **控制变量sizeCtl**：通常等于通常等于0.75 * 容量，但在构造函数中等于初始容量；散列表初始化时为-1；散列表在扩容时，高16位为扩容标记，低16位为并发扩容线程数（从2开始, 步长为+1）。
  - **分布计数变量**：计数基数baseCount，分布计数单元格数组counterCells，单元格繁忙标记cellsBusy。
  - **转移相关变量**：转移最小块索引transferIndex，可以减少协助转移结点时的竞争；转移目标散列表nextTable。
- 几种类型的结点：
  - **Node**：实现Map.Entry，是ConcurrentHashMap中最普通的链表结点，拥有hash、key、val、next成员变量，是其他类型结点的父类，其中val和next使用volatile修饰，保证线程可见性。
  - **TreeNode**：继承Node结点，是ConcurrentHashMap中的红黑树结点，在Node结点的基础上还维护了parent、left、right、red红黑树成员变量。
  - **TreeBins**：
    - 继承Node结点，是ConcurrentHashMap中红黑树的桶结点，hash值为-2，持有红黑树根结点root指针和链头first指针，不保存键和值。
    - 同时维护了读写锁，强迫写线程必须等待所有读线程完成后，才能进行红黑树结点操作。
    - 当读时不存在并发写线程，使用root指针走红黑树遍历方式查找结点；当读时存在并发写线程，使用first指针走链表遍历方式查找结点。
  - **ForwardingNode**：
    - 继承Node结点，是ConcurrentHashMap中的转发结点，hash值为-1，持有nextTable引用，没有键和值。
    - 在线程协助转移结点到新表后，会在旧表原位置维护一个Forwarding结点，以标识旧表正在发生扩容操作，让下一个线程碰到时可以协助进行转移旧表结点。
  - ReservationNodes：（不懂不要说）不保存hash值、key和value。用作占位符，同时在computeIfAbsent和相关方法中建立值。
- 几个重要方法：
  - **get方法**：
    - 一般不会阻塞，可与put和remove等更新方法同时执行，**反映的是最近完成更新的结果**，因此，对于putAll操作，并发检索可能只反映出插入的某些条目。
    - 类似的，迭代器反映的也是散列表在迭代器创建时，或者创建后的某个时刻的状态的
      元素，不会抛出 {@link java.util.ConcurrentModificationException
      ConcurrentModificationException}。
  - **size方法**：
    - 通常仅在Map不存在并发更新时才有用，否则结果反映的是瞬态状态，并不是准确的数值。
    - 因此可以用于监测或估计目的，而不适用于程序控制。
    - 其中size并发计数实现参考的是LongAdder，CounterCell计数数组机制避免了更新计数时的锁争用，但如果在并发访问期间读取过于频繁，可能会遇到缓存抖动（为了保证缓存一致性而出现的等待）。
  - **put与remove方法**：
    - 对于hash值为-1的ForwardingNode结点，会协助进行转移结点。
    - 对于hash值为-2的TreeBins结点，会先对结点进行加锁，获取到锁后才再用红黑树方式添加key-value。
    - 对于普通Node结点，会对桶头结点进行加锁，获取到锁后再使用链表方法添加key-value。
  - **扩容方法**：
    - 当散列表容量超过阈值时（ 0.75），则需要扩容散列表，sizeCtl字段中的生成戳resizeStamp，可保证其扩容不会重复执行。
    - 在启动扩容和设置nextTable之后，任何注意到forwarding结点或者桶过满的线程，都可以协助转移散列表结点，转移线程会根据transferIndex索引字段，小块小块地进行转移结点，从而减少争用。然而，这些线程可能会继续进行插入等操作，而不是停顿。
    - 由于散列表根据2的幂次进行扩容，所以每个桶中的元素要么保持相同的索引，或者以2次幂的偏移量
      进行移动。通过捕获可以重用的旧结点，来消除不必要的结点创建，因为它们的next指针不会改变。
    - 在结点转移后，会在旧表桶中保留一个特殊的转发节点（具有哈希字段“MOVED”），在遇到转发节点时，访问和更新操作会使用持有的nextTab作为新的散列表而重新启动。

#### 数据结构

数组 + 链表 + 红黑树，锁有CAS+自旋锁、synchronized可重入锁、TreeBin读写锁。

![1625493877273](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625493877273.png)

#### 构造方法

- 5个构造方法，分别为空参的、指定初始容量的、指定初始容量和负载因子的、指定初始容量、负载因子和并发线程数的（concurrencyLevel只是为了兼容JDK1.7 ，第一不为负数就好，第二在initialCapacity < concurrencyLevel时赋值initialCapacity 为concurrencyLevel）、指定复制集合的。
- 默认负载因子为0.75，默认容量为16。

#### HashCode扰动函数

- **spread（int）**：HashCode右移16位，从而**混合HashCode的高位和低位，加大低位的随机性，减少哈希碰**
  **撞发生的概率**，是一种性能、效用和质量的折衷方案。
  - 使用简单的位移与异或操作，减少系统的计算损耗；使用高位异或，可以减少低位冲突的可能性，保证查
    找效率。
  - HashCode右移16位，使得高位能被利用起来，保证了效用性。
  - 使用高位异或，可以减少低位冲突的可能性，保证散列表的质量。

#### 哈希索引的计算方法

- **（n - 1） & hash，相当于hash % n**：n指散列表的当前容量（桶数量），hash指获取hash（key）即key的hashCode扰动后结果。
  - **不能直接使用HashCode作为索引的原因**：int类型的hashCode，范围为[-2^32，2^32 - 1]，如果散列表
    数组与HashCode一一对应，需要40亿的空间（int[40亿]），明显这在内存是放不下的，也就是说明
    hashCode是不能直接作为数组索引的。因此，如果使用hashCode对散列表数组长度取模，那么就可以解决这个问题，从而保证较小的数组也还能利用上hashCode。
  - **n为2的幂次原因**：为了解决hashCode对散列表数组长度取模，设计了HashCode的扰动函数以及为2幂次的容量n，可以通过n-1来获得取模操作的低位掩码，此时**只需要通过低位掩码与扰动后的**
    **hashCode（hash值）进行一次与运算**，即可得到该hash值在散列表数组中的索引。其次通过在扩容方
    法中，经过hash值与低位掩码相与，可以保证扩容后，**只会移动少部分相与结果高位为1的桶链表**，其他
    保持不变，减少了扩容时的时间。
- **通过tableSizeFor（int）返回给定目标容量的2的幂次**，底层通过-1，右移1、2、4、8、16位，再+1得到目标容量。

#### 获取扩容标记方法

- **resizeStamp（int）**：
  - 获取容量n的扩容标记位，用于更新为sizeCtrl。
  - 等于容量n的高0位数值 | 1 << 15。高16为扩容标记，第16位为并发扩容线程数(从2开始, 步长+1)。结果肯定为负数。

#### 并发计数更新方法

在putVal和removeNode方法更新元素后，先并发叠加计数x，叠加成功后做扩容判断。其并发叠加计数x步骤为：

1. 先尝试在baseCount叠加x，如果叠加成功，则继续做扩容判断。
2. 如果baseCount叠加x失败，则根据当前线程哈希值h=ThreadLocalRandom.getProbe()，尝试在CounterCell[h * (n-1)]叠加x，如果叠加成功，则继续做扩容判断。
3. 如果CountCell叠加x失败，则调用fullAddCount 自旋+CAS 竞争添加到CounterCell[] as，其步骤为：
   - 如果as不为null，则判断CounterCell[h & (n-1)]是否为null：
     - 如果CounterCell[h & (n-1)]为null，则CAS竞争创建CounterCell[h & (n-1)]，竞争成功则叠加x结束自旋，竞争失败则继续自旋，如果创建前as繁忙（as正在初始化/扩容/叠加x），则标志为已冲突，获取新的线程哈希值h，继续自旋。
     - 如果CounterCell[h & (n-1)]不为null，则CAS竞争在CounterCell[h & (n-1)]上叠加x，竞争成功则结束自旋，竞争失败则获取新的线程哈希值h，继续自旋。
     - 否则，如果CounterCells数组引用发生变更或者长度超出CPU核心数，则也会标志为已冲突，获取新的线程哈希值h，继续自旋。
     - 否则，如果连续冲突2次，还没竞争叠加x成功，则扩容2倍CounterCells数组，扩容完毕后继续自旋。
   - 如果as为null或者为空，则CAS竞争初始化as = new CounterCell[2]，竞争成功则叠加x到as[h & 1]中，结束自旋。
   - 如果as竞争初始化失败，则叠加x到baseCount中，结束自旋。

#### 并发扩容方法

- 并发扩容时使用到的一些判断条件：

```java
// 第一个扩容线程时，CAS更新并发阈值sizeCtl，此时sc为rs <<< 16 + 2
U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)
    
// 其他协助转移线程加入结点转移工作时，CAS更新并发阈值sizeCtl，此时sc + 1
U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)
    
// 通过sizeCtl判断当前线程扩容是否为ConcurrentHashMap的同一次扩容
(sc >>> RESIZE_STAMP_SHIFT) == rs 

// 当前线程完成转移工作后，CAS更新并发阈值sizeCtl，此时sc-1
U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)
    
// 通过sizeCtl判断当前线程是否为最后一个提交转移工作的线程
(sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT
```

- 启动扩容前判断：如果sumCount（）> sizeCtl且 当前容量 < 最大容量，则说明需要扩容，扩容启动步骤为：
  1. resizeStamp（n）获取扩容标记rs，如果rs小于0，说明散列表正在被其他线程扩容，则CAS更新sizeCtrl=sc+1，更新成功后调用transfer(tab, nt)，加入扩容一起转移结点。
  2. 如果rs大于等于0，说明散列表还没被扩容，则CAS更新sizeCtrl=(rs << RESIZE_STAMP_SHIFT) + 2)，更新成功后调用transfer(tab, null)，开始扩容创建nextTab并转移结点。
  3. 要注意的是，在addCount（long，int）方法中，转移tab到nextTab完成返回后，还要继续判断nextTab是否需要扩容，如果nextTab也在扩容中，则加入扩容一起转移结点。
- transfer（Node[]，Node[]）：转移旧散列表tab中的结点到新散列表nextTab中，会在启动扩容、协助扩容处调用。其转移结点的步骤为：
  - 如果nextTab还没创建，则先创建nextTab。
  - 如果nextTab已创建，则转移线程步骤为：
    - 划分转移区间 -> i为转移结点 -> 继续前进划分转移区间，直到没有划分到散列表开头。
    - 划分转移区间 -> i为业务结点-> 锁桶头+转移普通链表/红黑树 -> 转移完成（会在桶处留下forwarding结点） -> 继续前进划分转移区间，直到没有划分到散列表开头。
    - 如果当前线程不为最后一个转移完成线程，即**(sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT**，则直接返回即可，无需提交新散列表nextTab。
    - 如果当前线程为最后一个转移完成线程，即**(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT**，则进行最后一次检查i与transferIndex（是否到散列表开头），没问题则提交新散列表nextTab（设置为table）。

#### put方法

3个常用的顶层API方法put、putIfAbsent、putAll，它们依赖于putVal方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果散列表为null或者n为0，则初始化容量为16的散列表，sizeCtl为12=16 * 0.75。
3. 否则，如果p桶为null，则直接new Node再CAS放到该桶即可。
4. 否则，如果p桶结点hash值-2，说明p为Forwardding结点，则当前线程加入扩容一起转移结点。
5. 否则，如果p不为Forwardding结点，则对桶头结点进行加synchronized锁，再判断桶头结点的哈希值：
   - 如果桶头结点的hash值大于等于0，说明它为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点，如果此时onlyIfAbsent为false，则发生值替换，直接返回即可。
   - 如果找不到对应的结点，则在链尾new Node一个结点，并且添加后如果当前链表至少有8个结点，则调用**ConcurrentHashMap的实例方法treeBin**将当前桶链表树化为红黑树（treeBin还会判断散列表容量是否大于等于64）。
   - 否则，如果桶头结点的hash小于0即TreeBin结点，说明p为红黑树，则使用**TreeBin的实例方法putTreeVal**添加key：value。
6. 如果发生的不是值替换，则并发更新计数、判断是否需要扩容（要的话则发起扩容）。最后返回null，代表结点插入成功。

#### remove方法

2个常用的顶层API方法remove（Object）和remove（Object，Object），它们都依赖replaceNode方法，其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶p。
2. 如果散列表为null或者n为0，则返回null，代表ConcurrentHashMap不存在对应的结点。
3. 如果桶p为null，则返回null，代表ConcurrentHashMap不存在对应的结点。
4. 否则，如果桶头结点hash值为-2，说明它为Forwardding结点，则当前线程加入扩容一起转移结点。
5. 否则，如果p不为Forwardding结点，则对桶头结点进行加synchronized锁，再判断桶头结点的哈希值：
   - 如果桶头结点的hash值大于等于0，说明它为普通链表结点，则遍历p链表，如果找到hash值相等且（key相等 或者 equals）的结点（如果此时指定了value，则还需要判断value是否equals），则脱钩该结点。
   - 如果找不到，则返回null，代表ConcurrentHashMap不存在对应的结点。
   - 否则，如果桶头结点的hash小于0即TreeBin结点，说明p为红黑树，则调用**TreeNode的实例方法getTreeNode**获取hash和key对应的结点，调用**TreeNode的实例方法removeTreeNode**删除该结点。
6. 最后如果脱钩结点成功，则并发更新计数，返回旧值，代表删除成功。

#### get方法

2个常用的顶层API方法get、getOrDefault，getOrDefault依赖get方法，其中val和next使用volatile修饰，保证线程可见性，所以get方法可以不加锁地照常遍历，而读红黑树由于会涉及到旋转，所以有写时会走链表读，树读时不能写。其步骤为：

1. hash（key）计算key的hash值，(n - 1) & hash计算出哈希索引，tab[i]得到哈希索引对应散列表的桶e。
2. 如果散列表为null或者n为0，则返回null，代表ConcurrentHashMap不存在对应的结点。
3. 如果桶e为null，则返回null，代表ConcurrentHashMap不存在对应的结点。
4. 如果e桶不为null，则分4种情况判断：
   - 如果桶头结点e的hash值相等且（key相等 或者 equals），说明e就是要找的结点，则直接返回e结点。
   - 否则，如果e的hash小于0，说明e可能为转发结点、红黑树结点、computeIfAbsent临时结点，则根据调用各自实现的find方法：
     - 如果e为转发结点，则根据hash以及key对象查找nextTable结点，找到hash相等，且Key
       相等或者equals的结点并返回。
     - 如果e为红黑树结点，则根据hash值和key值，从根结点开始查找红黑树结点 => 同
       HashMap#getTreeNode（int，Object）。
     - 如果e为computeIfAbsent临时结点，则返回null。
   - 否则，如果桶头没找e结点, 则继续遍历e链表, 找到hash值相等, 且Key相等或者equals结点并返回。
5. 最后如果实在找不到key对应的结点，则返回null，代表ConcurrentHashMap不存在对应的结点。

### 3.9. ConcurrentHashMap红黑树？

- 红黑树过程与HashMap类似，但不同的地方在于，TreeBin维护了一个读写锁（写时加锁），读红黑树由于会涉及到旋转，所以有写时会走链表读，树读时不能写。
- 对于TreeBin#putTreeVal或者TreeBin#removeTreeNode方法，即使外层有获取可重入锁synchronized，在操作红黑树之前，也要调用lockRoot()，调用完成后再unlockRoot()。其原理如下：

1. TreeBin持有lockState读写锁状态（WRITER=1，WAITER=2，READER=4，读/写状态可与等待状态结合），以及waiter等待写锁线程。
2. 调用lockRoot时，首先CAS竞争更新lockState为【WRITER】，竞争成功则说明当前线程持有写锁成功，可以继续做红黑树操作，操作完后unlockRoot释放写锁，置lockState为0。
3. 竞争失败，则调用contendedLock继续**争抢写锁**，争抢不到写锁的会进入阻塞状态，直到所有调用TreeBin#find（int，Object）的线程调用完毕后才会被唤醒，然后重新争抢写锁。
   - 如果当前红黑树不存在写或者读线程【((s = lockState) & ~WAITER) == 0】，则当前线程去竞争写锁，如果竞争成功则返回，否则继续自旋。
   - 否则，如果还不存在等待写锁的线程【(s & WAITER) == 0】，则当前线程去竞争成为等待写锁的线程，竞争成功则成为等待写锁的线程，否则继续自旋。
   - 否则，说明当前线程为等待锁的线程，但竞争写锁还是失败，则进入阻塞状态。而那些争抢不到写锁, 也进入不了阻塞状态成为等待写锁的线程，会一直自旋等待锁状态变更。
4. TreeBin#find（int，Object）**更新读锁状态**：
   - 如果当前红黑树存在写线程或者等待写锁线程【((s = lockState) & (WAITER|WRITER)) != 0】, 为了减少锁竞争以便写操作尽快完成，则以遍历链表的方式去遍历出红黑树结点并返回。
   - 否则，说明当前红黑树没有写线程或者等待写锁线程，则CAS叠加lockState读锁状态（每个读线程叠加一次【READER】）， 然后再以红黑树方式去遍历红黑树结点并返回。

### 4.0. JDK1.7 ConcurrentHashMap与JDK1.8 ConcurrentHashMap的区别？

JDK1.8 主要优化了以下内容：

- 取消Segment[]+HashEntry[]+链表的数据结构，改用Node[]+链表+红黑树的数据结构，提升查找效率。
- 取消了hashSeed参与HashCode扰动。
- 取消了Segment+HashEntry+ReentrantLock分段锁，改用Node+CAS自旋锁+synchronized+TreeBin读写锁来保证并发安全，其中synchronized只锁定桶结点，红黑树读写锁使并发读性能得到提升。
- 取消了concurrencyLevel作为Segment[]长度，JDK 1.8 ConcurrentHashMap的concurrencyLevel为了兼容JDK1.7 ConcurrentHashMap，实际意义不大（第一不为负数就好，第二在initialCapacity < concurrencyLevel时赋值initialCapacity 为concurrencyLevel）。
- 取消了获取可重入锁后添加结点+计数+扩容的方式，改用添加结点后，释放synchronized+CAS自旋锁+并发计数+并发扩容方式提高并发量。

|                  | JDK1.7 HashMap                                        | JDK1.8 HashMap                                               |
| ---------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| 数据结构         | 数组 + 链表                                           | 数组 + 链表 + 红黑树                                         |
| HashCode扰动函数 | 16次扰动（7次移位，4次相加，5次异或），有哈希种子影响 | 2次扰动（1次移位，1次异或），无哈希种子                      |
| 并发安全原理     | Segment+HashEntry+ReentrantLock分段锁                 | Node+CAS自旋锁+synchronized+TreeBin读写锁                    |
| 构造方法         | concurrencyLevel作为Segment[]长度                     | concurrencyLevel为了兼容JDK1.7 ConcurrentHashMap，实际意义不大 |
| 扩容方法         | 获取可重入锁后，添加结点+计数+扩容                    | 添加结点后，释放synchronized+CAS自旋锁+并发计数+并发扩容     |

# 二、JVM篇 

### 1.1. JDK、JRE、JVM的区别？

![1625884268478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625884268478.png)

从图中可以看出，**JDK包含了JRE，而JRE又包含了JVM**。

- **JDK**，Java Development Kit，是Java的软件开发工具包（SDK），包含JRE和Java工具。
- **JRE**，Java Runtime Environment，是Java的运行时环境，大部分都是C和C++语言编写的，可以在其上运行、测试应用程序的Java平台，包括JVM和Java核心类库。
- **JVM**，Java Virtual Machine，Java虚拟机，是一种用于计算设备的规范，是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的，屏蔽了与具体平台相关的信息，使得Java语言编译程序只需要在Java虚拟机上运行的字节码，就可以不加修改地在多种平台上运行。

### 1.2.  JVM整体架构？

![1625963806257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625963806257.png)

- JVM包含**2个子系统和2个组件**：2个子系统分别为Class Loader（类加载子系统）、Execution Engine（执行引擎）；2个组件分为别Runtime data area（运行时数据区）、Native Interface（本地接口）。
  - **Class loader（类加载子系统）**：根据给定的全限定名类名（如java.lang.Object）来装载class文件到Runtime data area中的Method Area（方法区）。
  - **Runtime data area（运行时数据区域）**：这就是我们常说的JVM的内存。
  - **Execution engine（执行引擎）**：执行class文件中的指令。
  - **Native Interface（本地接口）**：与native libraries交互，是其它编程语言交互的接口。
- 架构整体流程：

1. 通过编译器把 Java 代码转换成字节码，**类加载器（ClassLoader）**再把字节码加载到内存中，将其放在**运行时数据区（Runtime data area）**的方法区内。
2. 而字节码文件只是 JVM 的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解析器**执行引擎（Execution Engine）**，将字节码翻译成底层系统指令，再交由 CPU 去执行。
3. 而这个过程中需要调用其他语言的**本地接口（Native Interface）**来实现整个程序的功能。

### 1.3. 详细介绍类加载机制？

![1625975271139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625975271139.png)

程序主动使用某个类时，如果这个类还未被加载到内存中，则JVM会通过**加载、链接、初始化**3个步骤来对该类进行初始化。如果没有意外，JVM将会连续完成3个步骤，所以有时也把这个3个步骤统称为**类加载或类初始化**。

1. **加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。
   - 加载过程需要**类加载器**参与。类加载器，可以从不同来源加载类的二进制数据，比如：本地Class文件、Jar包Class文件、网络Class文件等等。
   - Java类加载器由JVM提供，是所有程序运行的基础，JVM提供的这些类加载器通常被称为系统类加载器。
   - 除此之外，开发者可以通过继承ClassLoader基类来创建自己的类加载器。
   - Java的类加载是动态的，不会一次性将所有类全部加载后再运行，而是保证程序运行的基础类完全加载到JVM中。至于其他类，则**在需要的时候才加载**（为了节省内存开销）。
     - **隐式加载**：程序在运行过程中，当碰到通过new 方式生成对象时，将会隐式调用类装载器，加载对应的类到JVM中。
     - **显式加载**：通过class.forname（）反射方法，显式加载需要的类。
2. **链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：
   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
     - 文件验证：是否以0xCAFEBABE开头、版本号是否合理等。
     - 元数据验证：是否有父类、是否继承了final类、非抽象类是否实现了所有抽象方法等。
     - 字节码验证：运行检查、栈数据类型和操作码的操作参数是否吻合（不能大于栈空间）、跳转指令是否指向合理的位置。
     - 符号引用验证：常量池中描述的类是否存在、访问的方法或字段是否存在且有足够的权限。
     - 可使用**-Xverify:none**关闭验证：比如提高IDEA的启动速度。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。
   - 实际上，JVM不一定完全按照类加载机制顺序执行，比如解析操作有可能会发生在初始化操作之后。
3. **初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。
   - 执行< clinit >方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。
     - 初始化的顺序和源文件中的顺序一致。
     - 子类的< clinit >被调用前，会先调用父类的< clinit >。
     - JVM会保证clinit方法的线程安全性。
   - 即执行顺序为：JVMTest5静态块 -> super静态块 -> Sub静态块 -> Super构造块 -> Super构造方法 -> Sub构造块 -> Sub构造方法。
     - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
     - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
     - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

```java
// JVMTest5不用被实例化，所以不会调用JVMTest5的构造块和构造方法
public class JVMTest5 {
    static {
        System.out.println("JVMTest5静态块");
    }

    {
        System.out.println("JVMTest5构造块");
    }

    public JVMTest5() {
        System.out.println("JVMTest5构造方法");
    }

    public static void main(String[] args) {
        new Sub();
    }
}

class Super {
    static {
        System.out.println("Super静态块");
    }

    public Super() {
        System.out.println("Super构造方法");
    }

    {
        System.out.println("Super构造块");
    }
}

class Sub extends Super {
    static {
        System.out.println("Sub静态块");
    }

    public Sub() {
        System.out.println("Sub构造方法");
    }

    {
        System.out.println("Sub构造块");
    }
}
```

### 1.4. 什么是类加载器？类加载器有哪些？

![1625986988156](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625986988156.png)

**类加载器**，是能够实现通过类的全限定名，获取该类的二进制字节流的**代码块**。JVM提供了3种类加载器，启动类加载器、扩展类加载器、系统类加载器（也叫应用类加载器），以及用户自定义的类加载器（其父类为应用类加载器）。

- **启动类加载器**：Bootstrap ClassLoader，该类加载使用C++实现，其引用为null，无法被java程序直接引用。用于加载Java核心类库，即负责把**/lib**目录下或者**-Xbootclasspath**参数指定路径下的Jar包加载到内存中。
  - 注意，JVM是按照文件名识别加载Jar包，如rt.jar，如果文件名不被虚拟机识别，即使把Jar包丢到lib目录下也是没有作用的。
  - 处于安全考虑，启动类加载器只能加载包名为java、javax、sun等开头的类。
- **扩展类加载器**：ExtClassLoader，由Java实现，父类加载器为启动类加载器（持有为null的parent引用，并不是真正的继承关系）。用于加载 Java 的扩展库，即负责把**/lib/ext**目录下或者**-Djava.ext.dir**参数指定路径下的类库加载到内存中。
  - 开发者可以直接使用标准的扩展类加载器。
- **系统类加载器**：AppClassLoader，也叫应用类加载器，由Java实现，父类加载器为ExtClassLoader（持有ExtClassLoader的parent引用，并不是真正的继承关系）。用于加载一般的Java 应用类，即负责把**java -classpath**或者**-D java.class.path**指定路径下的类库加载到内存中。
  - 一般情况下，系统类加载器是程序中默认的类加载器。
  - 开发者可以直接使用应用类加载器，可以通过**ClassLoader.getSystemClassLoader（）**来获取。
- **用户自定义的类加载器**：用户可以通过继承 java.lang.ClassLoader类的方式，来自定义自己的加载器。
  - 应用场景：
    - 加密编译后的class字节码 ->  自定义ClassLoader -> 加载该class时解密字节码。
    - 自定义ClassLoader，加载时从非标准来源加载字节码：比如数据库、网络上。

### 1.5. 什么是双亲委派机制？

#### 概念

加载器之间存在着"父子关系"（区别于Java里的继承），子加载器保存着父加载器的引用。

1. 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回。
2. 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到，则解析或者返回。
3. 如果找不到，才会交还子加载器加载目标类，查找逻辑交由子加载器实现。

#### 实现原理

- **java.lang.ClassLoader**：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法。
- **loadClass（String，boolean）**：类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找。
- **findClass（String）**：加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用**defineClass（String，Resource）**方法生成Class对象。
- **resolveClass（Class<?>）**： 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值。
- **defineClass（String，Resource）**：在Java堆区生成Class对象。

```java
// java.lang.ClassLoader#loadClass：扩展类、系统类以及自定义的加载器都继承这个类，需要实现findClass方法
public abstract class ClassLoader {
    
    // 类加载方法，子类在查询缓存中没有加载该Class后，会调用该方法，走双亲委派机制去查找
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            // 当一个类加载器需要加载一个目标类时，先会去缓存中查找，如果找到，则解析或者返回
            Class<?> c = findLoadedClass(name);// native方法
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    // 如果缓存中找不到，则委托给父加载器加载，父加载器会在自己的加载路径中搜索目标类，如果找到则解析或者返回
                    if (parent != null) {
                        c = parent.loadClass(name, false);
                    } 
                    // 交由启动类加载器加载
                    else {
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }

            // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
            if (resolve) {
                resolveClass(c);
            }

            // 返回class
            return c;
        }
    }
    protected final Class<?> findLoadedClass(String name) {
        if (!checkName(name))
            return null;
        return findLoadedClass0(name);
    }
    private native final Class<?> findLoadedClass0(String name);
    
    // 底层调用native方法，解析生成出来的Class对象，将Class常量池（Constant Pool）的符号引用转换为直接引用，且为类变量（静态变量/实例变量[在该对象实例化时]）分配内存并设置初始值
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
    private native void resolveClass0(Class<?> c);

    // 加载器自身去加载Class的方法，交由子类去实现。比如子类URLClassLoader（ExtClassLoader和AppClassLoader的父类），根据URL找到对应的Class文件后，会调用defineClass(String，Resource)方法生成Class对象
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
}
```

#### 双亲委派模型好处

- 此机制保证了Java核心类库被优先加载，避免了用户编写的类动态替换Java核心类的错误，使得Java程序能够稳定运⾏。
- 同时也避免了类的重复加载，使用双亲委派模型，JVM能够根据**类的完整类名+ClassLoader实例对象**来区分不同的类。如果不使⽤双亲委派模型，⽽是每个类加载器⾃⼰加载的话，会出现⼀些问题。⽐如编写⼀个称为 java.lang.Object 类的话，在程序运⾏的时候，系统会有多个不同的Object 类，此时会出现Object类的选择问题。

#### 双亲委派模型局限

1. SPI接口，Service Provider Interface，允许第三方为其提供实现，如JDBC、JNDI等 。
2. SPI接口属于Java核心类库，由启动类加载器加载（rt.jar），而SPI的第三方代码则是作为Java应用所依赖的Jar中（Classpath下）。
3. 其中SPI接口中的代码经常需要加载具体的第三方实现类，并调用其相关方法，此时由于双亲委派模型的存在，启动类加载器无法直接加载SPI实现类，也无法反向委托给系统类加载器加载，从而让JDK SPI机制产生了问题。

#### 打破双亲委派模型

如果不想打破双亲委派模型，则只需要重写findClass方法即可；如果想打破双亲委派模型，则需要重写整个loadClass方法。

##### 线程上下文类加载器

- **背景**：由于双亲委派模型存在SPI局限，需要一种特殊的类加载器来加载第三方类库，此时线程上下文加载器是个很好的选择。
- **线程上线文类加载器**：是从JDK 1.2开始引入的，可以通过java.lang.Thread#getContextClassLoader（）和setContextClassLoader（ClassLoader）方法来获取和设置线程的上下文类加载器。如果没有手动设置，则线程将会继承父线程的上下文类加载器，默认为系统类加载器，即在线程中运行的代码可以通过此类来加载Classpath下的类和资源。
- **打破双亲委派**：从图中可以看到，启动类加载器委派线程上下文加载器，把jdbc.jar中的实现类加载到内存中以便SPI相关类使用，因此打破了双亲委派模型，使得Java类加载更加灵活。

![1625996283343](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1625996283343.png)

- **实现原理**：
  - contextClassLoader是在ClassLoader.SystemClassLoaderAction#run（）方法进行了赋值，其中构造了**java.system.class.loader**加载器实例（实际上为AppClassLoader？），并持有当前加载器的parent作为其父加载器。
  - 接着，ClassLoader.SystemClassLoaderAction#run（）方法通过Thread#setContextClassLoader（ClassLoader）设置到当前线程的实例变量中，从而使得当前Thread实例持有contextClassLoader的引用。
  - 最后，java.sql.DriverManager在调用sevice.loader（Driver.class）时，jdbc.jar中在META-INF/sevice/java.sql.Driver配置的**com.mysql.cj.jdbc.Driver**，就会在java.util.ServiceLoader#load（Class）方法调用Thread.currentThread().getContextClassLoader()时进行类加载，从而达到SPI的目的。
  - 可以看出虽然java.util.ServiceLoader是rt.jat包的核心类库，由启动类加载器加载，但通过Thread.currentThread().getContextClassLoader()确实加载到了第三方包下的com.mysql.cj.jdbc.Driver，因此线程上下文类加载器可以打破双亲委派模型。

```java
// java.sql.DriverManager，启动类加载器加载
public class DriverManager {
 	static {
        loadInitialDrivers();
        println("JDBC DriverManager initialized");
    }
    
    private static void loadInitialDrivers() {
        AccessController.doPrivileged(new PrivilegedAction<Void>() {
            public Void run() {
                // SPI加载
                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);
                Iterator<Driver> driversIterator = loadedDrivers.iterator();
            }
            ...
        }
    }      
}    


// java.util.ServiceLoader，启动类加载器加载
public final class ServiceLoader<S>implements Iterable<S> {  
    // SPI加载: 获取当前线程上下文类加载器进行SPI加载，从而打破了双亲委派模型
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    ...
}
```

##### Tomcat类加载机制

- **背景**：
  - a. 一个web容器可能要部署两个或者多个应用程序，不同的应用程序可能会依赖同一个第三方类库的不同版本，因此要保证每一个应用程序的类库都是**独立、相互隔离**的。
  - b. 同一个web容器中的**相同类库的相同版本**可以共享，否则会有**重复的类被加载进JVM**。
  - c. **web容器也有自己的类库**，不能和应用程序的类库混淆，基于安全考虑，需要相互隔离。
  - d. Jsp文件也是要编译成class文件的，web容器需要支持在**Jsp**文件修改后，可以实现**HostSwap（热替换）**的功能。

![1626065847576](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626065847576.png)

- **类加载器逻辑关系**：

  Common、Catalina、Shared类加载器（本质上是URLClassLoader）分别加载/common/、/server/、/shared/路径下的Class，但在Tomcat6后已经统一合并到了/lib目录下了。

  - **CommonClassLoader**：Tomcat最基本的类加载器，加载对应路径中的Class，可**以被Tomcat容器本身以及各个webapp访问**。
  - **CatalinaClassLoader**：Tomcat容器私有的类加载器，加载对应路径中的class，**对于webapp不可见**。
  - **SharedClassLoader**：各个webapp共享的类加载器，加载对应路径中的class，**对于所有webapp可见，但对于Tomcat容器不可见**。
  - **WebappClassLoader**：各个webapp私有的类加载器，每一个webapp对应一个WebAppClassLoader实例，加载路径中的class，**只对当前webapp可见**。
  - **JasperClassLoader**：
    - 每一个Jsp文件对应一个JasperClassLoader实例，**加载范围仅仅是这个Jsp文件所编译出来的那一个Class文件**。
    - JasperClassLoad出现的目的就是为了被丢弃，当Web容器检测到Jsp文件被修改时，会替换掉目前的JasperClassLoader实例，并通过重新建立一个新的JasperClassLoader实例来实现JSP文件的HostSwap（热替换）功能。

![1626066067882](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626066067882.png)

![1626090586657](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090586657.png)

- **类加载流程**：WebappClassLoaderBase#loadClass(String, boolean)流程：

1. 先查找Tomcat缓存，如果找得到，则返回Tomcat缓存中的Class对象。
2. 如果Tomcat缓存中找不到，则查找JVM缓存，如果找得到，则返回JVM缓存中的Class对象。
3. 如果JVM缓存中也找不到，则用扩展类加载器来加载（**重点！这里并没有首先使用系统类加载器，而是直接使用了扩展类加载器来加载，也就是打破了系统类加载器的双亲委派机制**），根据双亲委派机制，扩展类加载器会委派启动类加载器来加载Class，从而保证了JRE核心类库不会被重复加载。
4. 如果指定了delegateLoad（需要先委托父类加载），则**先调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保持顺序加载机制），如果找不到**才调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），找到则返回，找不到则抛出ClassNotFoundException异常。
5. 如果没有指定delegateLoad（需要先委托父类加载），则**先调用调用本地的findClass（String）**搜索本地存储库（WEB-INF/classes -> WEB-INF/lib），如果找不到**才调用父类加载器加载**（share -> common -> app -> ext -> bootstrap，这里是为了保底机制），找到则返回，找不到则抛出ClassNotFoundException异常。

![1626090700749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626090700749.png)

- **总结**：可以看到，Tomcat#WebappClassLoaderBase的类加载机制是**打破了双亲委派模型**的：
  - **ext -> bootstarp模型**：保证了JRE核心类库不会被重复加载，满足了背景b加载JVM共同类库的需求。
  - **ext -> webapp模型**：实现了每个web应用只加载自己的类库（WEB-INF/classes -> WEB-INF/lib），从而实现了应用间的类库隔离，满足了背景a的需求。
  - **webapp -> share -> common模型**：实现了所有web应用之间、web与Tomcat之间，能够加载相同的类库，避免指定的类库不会被重复加载，满足了背景b加载其他共同类库的需求。
  - **（不确定）catalina -> 父类加载器模型**：实现了只加载Tomcat容器自身的类库，对于webapp是看不到的（可在config/catalina.properties的server.loader中配置jar和class的路径），满足了背景c的需求。
  - **（不确定）Jsp -> webapp -> 父类加载器模型**：通过在jsp修改后卸载再生成新的Jsp类加载器，重新加载新生成的Jsp class，从而实现Jsp的HostSwap（热替换），满足了背景d的需求。

### 1.6. JVM运行时数据区？

![1626181528728](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181528728.png)

JVM在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。

这些区域都有各自的用途，以及创建和销毁的时间，有些区域随着JVM进程的启动而存在（**线程共享**），有些区域则是依赖线程的启动和结束而建立和销毁（**非线程共享**）。

JVM所管理的内存被划分为如下几个区域：

- **程序计数器**：Program Counter Register，非线程共享，JVM当前线程所执行的**字节码的行号指示器**，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。
- **虚拟机栈**：Java Virtual Machine Stacks，非线程共享，每个方法在执行的同时都会在Java 虚拟机栈中创建一个栈帧（Stack Frame），用于存储**局部变量表、操作数栈、动态链接和方法返回地址**；
- **本地方法栈**：Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。

### 1.7. 详细介绍程序计数器？

- **概念**：程序计数器，Program Counter Register，非线程共享，JVM当前线程所执行的字节码的行号指示器，字节码解析器的工作是通过改变这个计数器的值，来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能，都需要依赖这个计数器来完成。

- **出现的原因**：由于JVM多线程是通过线程轮流切换，并分配处理器执行时间的方式来实现的，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，需要**记住原线程的下一条指令的位置**，所以每条线程都要有一个独立存储、互不影响的程序计数器，称之为“**线程私有**”的内存。

- **例子**：

  1. 比如线程A在看直播。
  2. 突然，线程B来了一个视频电话，就会抢夺线程A的时间片，就会打断了线程A，线程A就会挂起。
  3. 然后，视频电话结束，如果没有线程计数器，此时线程A就不知道要干什么了；如果有线程计数器，此时线程A就可以想起来要去看直播了。

  => 线程是最小的执行单位，不具备“记忆”功能，只负责去干，这就需要**由程序计数器来为线程提供保护和恢复现场**的功能。

### 1.8. 详细介绍虚拟机栈？

![1626137840755](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626137840755.png)

Java虚拟机栈**是线程私有的（非线程共享）**，每个线程都会有自己的虚拟机栈，其生命周期与线程生命周期一致。单位是**栈帧**，在每个方法执行的时候，都会创建一个栈帧，在被调用直至执行完毕的过程，对应一个栈帧在虚拟机栈中**从入栈到出栈**的过程。

每个栈帧都存放着**局部变量表、操作数栈、动态链接和方法返回地址**。

> 在JVM规范中，对此区域规定了两种异常状况：在固定情况下，如果线程请求的栈深度大于虚拟机所允许的最大栈深度，则会抛出**StackOverflowError**异常；在可动态扩展情况下，如果虚拟机栈无法申请到足够的内存，或者在创建新线程的时候没有足够的内存去创建对应的虚拟机栈，则会抛出**OutOfMemoryError**异常。

在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

- **局部变量表**：

  - 是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。
  - 存放了编译期可知的各种**基本数据类型**（boolean、byte、char、short、int、float、long、double，对包装类型在栈中保存地址、在堆中保存值）、**对象引用**（Reference类型，可能是一个指向对象起始地址的引用指针，也可能是一个代表对象的句柄或者其他与对象相关的位置）和**returnAddress类型**（指向下一条字节码指令的地址）。
  - 局部变量表所需的内存空间在编译期间完成分配，方法在运行之前，该局部变量表所需要的内存空间是固定的，运行期间不会发生改变。

- **操作数栈**：

  - 用于保存计算过程中的**中间结果**，同时作为计算过程中变量临时的存储空间。
  - 操作数栈在方法的执行过程中，根据字节码指令往操作数栈中写入数据或提取数据，即入栈和出栈操作。
  - 比如add（）方法执行过程中，其操作数栈与局部变量表的交互顺序为：15入栈（操作数栈写入数据） -> 15出栈（操作数栈提取数据到局部变量表） -> 1入栈（操作数栈写入数据） -> 1出栈（操作数栈提取数据到局部变量表） -> 15入栈（加载局部变量表变量15） -> 1入栈（加载局部变量表变量1） -> iadd（执行相加15 + 1指令） -> 16出栈（操作数栈提取结果到局部变量表）-> return（如果返回值为void，则当前栈帧出栈即可，如果带有返回值，则局部变量表中的结果16，还会入栈操作数栈中）。

  ```java
  public class Test {
      public void add() {
          int a = 15;
          int b = 1;
          int c = a + b;
      }
  }
  ```

- **动态链接**：

  - 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接（Dynamic Linking）。
  - Class 文件的常量池中存在大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数，这些符号引用一部分会在类加载阶段或**第一次使用时转化为直接引用，这种转化成为静态解析**。另一部分将在**每一次运行期间转化为直接引用，这部分称为动态连接**。

- **方法返回地址**：returnAddress类型（**指向下一条字节码指令的地址**）:

  - 当一个方法开始执行后，只有两种方式可以退出这个方法。一种是执行引擎遇到**任意一个方法返回的字节码指令**，这时候可能会有返回值传递给上层方法的调用者，是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为**正常完成出口**。
  - 另一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是 Java 虚拟机内部产生的异常，还是代码中使用 athrow 字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种称为**异常完成出口**。一个方法使用异常完成出口的方式退出，是不会给上层调用者产生任何返回值的。
  - 无论采用何种退出方式，在方法退出后都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来恢复它的上层方法的执行状态。一般来说，方法正常退出时，**调用者的PC计数器的值可以作为返回地址**，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常处理器表来确定的，栈帧中一般不会保存这部分信息。
  - 方法退出的过程实际上就等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上次方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，**调整PC计数器的值以指向方法调用指令后面的一条指令等**。

- 附加信息：虚拟机规范允许具体的虚拟机实现增加一些规范里没有描述的信息到栈帧中，例如与调试相关的信息，这部分信息完全取决于具体的虚拟机实现。实际开发中，一般会把动态连接、方法返回地址与其他附加信息全部归为一类，成为栈帧信息。

### 1.9. 详细介绍本地方法栈？

- 本地方法栈，Native Method Stack，非线程共享，与虚拟机栈的作用是一样，只不过虚拟机栈是服务Java方法的，而本地方法栈是为虚拟机调用Native方法服务的。
- Native方法是看不到的，必须要去oracle官网去下载才可以看的到，而且native关键字修饰的大部分源码都是C和C++的代码。
- 在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，因此同样会抛StackOverflowError异常，以及OutOfMemoryError异常。
  - 在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。

### 2.0. 详细介绍堆？

![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
  - 非栈上分配情况下，**创建的对象会存储在堆内存中，在栈上存储该对象的引用**（栈空间只包含方法基础数据类型的局部变量以及引用堆对象的引用变量）。
  - ClassA a = new ClassA（）；此时a叫实例，不能说a对象，**实例在栈上，对象在堆中**，操作实例实际上是通过实例指针间接操作对象，多个实例可以指向同一个对象。
  - 栈中的数据和堆中的数据销毁并不是同步的，方法一旦结束，**栈中的局部变量会立即销毁**；堆中的对象不一定会销毁，因为可能有其他变量也指向了该对象，直到没有变量指向该对象，才有可能会被垃圾回收。
  - 类的成员变量在对象中，每个对象都有自己成员变量的存储空间；而**类的方法只有一套**，存储在方法区中，被该类的所有对象共享，对象在使用方法的时候才会将方法压入栈中，而**方法在不使用时并不会占用内存**。
- 对象在堆中分配好以后，会在栈中保存一个4字节的实例（指向对象堆内存地址），用来定位对应的对象在堆中的位置，便于找到该对象。但在开启逃逸分析后，某些未逃逸的对象也可以通过标量替换的方式在**栈上分配**。
- 堆是垃圾回收（GC）的主要场所，从内存回收角度来看，可以分为**新生代和老年代，默认内存大小比值为1：2**，对于新生代又可以分为**Eden区（伊甸园）、Survivor区（存活区），默认内存大小比值默认为8：2**，而Survivor区又分为**Surviver0（From Survivor）和Survivor1（To Survivor），默认内存大小比值默认为1：1**。
- **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配小对象，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **优点 - 加速对象分配**：
    - 当多个线程同时在堆上分配对象时，由于堆是线程共享的，为了保证线程同步，JVM底层采用CAS + 失败重试的方式来做同步处理，如果多线程竞争非常激烈，那么此时在堆中分配对象性能是非常差的。因此，JVM设计了TLAB，来避免堆分配对象时的线程冲突，从而提升分配对象的效率。
  - **缺点 - 大对象无法分配**：TLAB空间比较小，所以大对象无法在TLAB分配，这时只能直接分配到线程共享的堆里面。
- 堆可以处于物理上不连续的内存空间中，可通过 -Xmx（最大堆内存）和 -Xms（初始堆内存） 来扩展空间大小。如果堆中没有内存可以完成对象分配，且堆也无法再扩展时，将会抛出OutOfMemoryError异常。

### 2.1. 详细介绍方法区？

![1626181213768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626181213768.png)

- **方法区**：Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - **永久代**：是Hotspot虚拟机特有的概念（在别的JVM没有），是方法区的一种实现，主要存放类信息、常量等方法区内容。
    - 在JDK1.6 中，方法区中包含的数据，除了JIT编译生成的代码是存放在native memory的CodeCache区域，其他都存放在永久代。
    - 移除永久代的工作从JDK1.7就开始了，在JDK1.7中，存储在永久代的部分数据就已经转移到了Java Heap或者是Native Heap。但永久代仍存在于JDK1.7中，并没完全移除，比如**符号引用**（Symbols）转移到了native heap，**字面量**（interned strings，见字符串常量池）转移到了java heap，**类的静态变量**（class statics）转移到了java heap。
    - 在Java 8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存：元空间（Metaspace）中，此时‑XX：MaxPermSize 参数失去了意义，取而代之的是-XX：MaxMetaspaceSize。
  - **元空间**：JDK8后用于替代永久代，存储类的元数据信息，存放在本地内存中。
    - **元空间与永久代最大的区别**：元空间并不是在JVM虚拟机中 ，而是使用了本地内存，默认情况下，元空间的大小仅受本地内存限制，解决了永久代容易溢出的问题。
  - **元空间替代永久代的原因**：
    - 字符串存在永久代中，容易出现性能问题和内存溢出。
    - 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则会导致空间的浪费。
    - JRockit虚拟机方法区没有永久代的实现，Oracle需要将HotSpot与JRockit合二为一 ，剔除永久代。
    - （？）永久代会为GC带来不必要的复杂度，并且回收效率偏低。
- 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。
  - **常量池 - 静态常量池**：也叫class文件常量池，即class文件中的常量池，占用class文件绝大部分空间。主要存放：
    - **字面量**：相当于Java语言层面常量的概念，如文本字符串、final修饰的变量。
    - **符号引用**：属于编译原理方面的概念，包括类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。
  - **常量池 - 运行时常量池**：当class文件加载到内存后，JVM会将静态常量池中的内容存放到运行时常量池中，这就是常说的“常量池”，主要存放：
    - 编译期间产生的字面量、符号引用。
    - 注意，运行时常量池具有动态性，也就是并非只有通过class文件常量池才能进入，运行期间也可能将新的常量放入池中，比如调用String#intern（）方法。
  - **常量池 - 字符串常量池**：可以理解为运行时常量池中分出来的一部分，当类加载到内存时，**字符串**会存到字符串常量池里面，即在编译阶段把所有字符串放到一个常量池中。
    - String#intern（）方法，native方法，返回规范的字符串，equals判断常量池是否有存在的字符串，如果没有则会将实参字符串加入常量池。
    - 程序运行时，除非手动向常量池中添加常量，比如调用String#intern（）方法，否则JVM不会自动添加常量到常量池。
    - 至于程序启动时，哪些字符串或常量、变量会加入常量池，取决于本身的编译性质，如果本身是字面量则会加入常量池；如果是变量，由于地址不能确定，所以在不调用String#intern（）时是并不会加入常量池的。
    - JDK5以后，除了有字符串常量池，实际上还有数值型常量池，也就是Java中大部分基本类型的包装类都实现了常量池技术，比如Byte、Short、Integer、Long、Character、Boolean，而两种浮点数类型的包装类Float、Double并没有实现常量池技术。其中，只有Integer常量池缓存区间（-128~127），可通过-XX:AutoBoxCacheMax参数进行设置。
  - **常量池的好处**：
    - 常量池是为了避免频繁的创建和销毁对象而影响系统性能，实现了对象的共享。
    - 常量池可以节省内存空间：常量池中所有相同的字符串常量被合并，只占用一个空间。
    - 常量池可以节省运行时间：在比较字符串时，==比equals（）快，所以对于两个引用变量，只用==判断引用是否相等，就可以判断实际值是否相等了。
- 垃圾回收在方法区出现得比较少，这个区域回收的目的主要是针对**常量池的回收和类的卸载**。
- 方法区也是可以由内存不连续的内存区域组成，也是可扩展的，当方法区无法满足内存分配需求时，则会抛出OutOfMemoryError异常。

### 2.2. 堆和虚拟机栈的区别？

|              | 堆                                                           | 虚拟机栈                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 物理地址     | 堆的物理地址是不连续的，因此分配对象的速度较慢               | 虚拟机栈使用的是栈数据结构，物理地址是连续的，因此分配对象的速度较快 |
| 内存大小     | 由于堆是不连续的，所以分配到的内存是在运行期才确定的，因此大小不固定，一般堆大小远远大于虚拟机栈 | 虚拟机栈是连续的，所以分配到的内存大小在编译期就已经确定好了，因此大小是固定的 |
| 存放内容     | 堆存放的是对象的实例和数组，所以更关注的是数据的存储         | 虚拟机栈存放的是局部变量、操作数栈、动态链接和方法返回地址，所以更关注的是程序方法的执行 |
| 程序的可见性 | 堆是线程共享的                                               | 栈是线程私有的，只对于线程是可见                             |
| 生命周期     | 堆的生命周期与JVM的生命周期相等                              | 虚拟机栈的生命周期与所在线程的生命周期相等                   |

### 2.3. 详细介绍直接内存？

- **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，是利用本地方法库直接在堆外申请的内存区域，这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。

- 直接内存（堆外内存）的使用，**避免了在I/O操作时Java堆和Native堆中来回复制数据**，从而提高性能。

  - 在JVM层面，每当程序需要执行一个I/O操作时，都需要将数据先从**Java Heap**复制到**C Heap**中，才能够触发系统调用完成操作。
  - 其中，C Heap内存站在JVM角度来看，属于堆外内存，但是站在操作系统的角度来看，其实都属于进程的Heap，**操作系统并不知道JVM的存在**，所以认为都是普通的用户程序。因此，JVM在I/O时永远比使用Native方法多一次数据复制。
  - **为什么必须有这一次的数据复制呢**？
    - 这是因为JVM只是一个用户程序，本身并没有直接访问硬件的能力，所有的I/O操作都需要借助于系统调用来实现。在Linux系统中，与I/O相关的read（）和write（）系统调用，都需要传入一个指向在程序中分配的一片内存区域的起始地址指针，然后操作系统才会将数据填入到这片区域或者从这片区域中读出数据。
    - 如果直接使用JVM堆中对应byte[]类型的地址的话，则会有两个无法解决的问题：一是，**Java中的对象实际的内存布局跟C不一样**，不同的JVM可能有不同的实现，byte[]的首地址可能只是个对象头，并不是真实的数据；二是，**垃圾收集器的存在使得JVM会经常移动对象的位置**，这样同一个对象的真实内存地址随时都有可能发生变化，而虽然JVM知道对象地址变了，但是操作系统并不知道。
  - 因此，在适当的位置直接使用直接内存，可以避免数据从JVM Heap到C Heap的拷贝。

- **API上**：可以使用**Unsafe**类或者**ByteBuffer**类分配直接内存：

  - **Unsafe**：Unsafe.allocateMemory（size）：
    - Unsafe可用来直接访问系统内存资源并自主管理，在提升Java运行效率、增强Java语言底层操作能力方面起了很大的作用。
    - 可以认为，**Unsafe类是Java中留下的后门**，提供了一些底层的操作，比如直接访问内存、线程调度等。
    - Unsafe不属于Java标准，官方并不建议使用Unsafe，并且从JDK 9开始去Unsafe，然而目前业界有很多好用的类库大量用了Unsafe类，比如JUC atomic包下的类、Netty、Hadoop、Kafka等，所以了解一下还是有好处的。
    - 不同JDK版本中，Unsafe类有区别：在JDK 8中归属于sun.misc包下；在JDK 11中归属于sun.misc包下与jdk.internal.misc下（这个功能更强大）。

  ```java
  public class DirectMemoryTest1 {
      private static final int MB_1 = 1024 * 1024;
  
      public static void main(String[] args) throws IllegalAccessException, NoSuchFieldException {
          //通过反射获取Unsafe类并通过其分配直接内存
          Field unsafeField = Unsafe.class.getDeclaredFields()[0];
          unsafeField.setAccessible(true);
          Unsafe unsafe = (Unsafe) unsafeField.get(null);
  
          // 分配1M内存，并返回这块内存的起始地址
          long address = unsafe.allocateMemory(MB_1);
  
          // 向内存地址中设置对象
          unsafe.putByte(address, (byte) 1);
  
          // 从内存中获取对象
          byte aByte = unsafe.getByte(address);
          System.out.println(aByte);
  
          // 释放内存
          unsafe.freeMemory(address);
      }
  }
  ```

  - **ByteBuffer**：ByteBuffer.allocateDirect（size）：

  ```java
  public class DirectMemoryTest2 {
      private static final int ONE_MB = 1024 * 1024;
  
      public static void main(String[] args) {
          // 底层使用unsafe分配内存，unsafe.freeMemory(address)释放内存
          ByteBuffer buffer = ByteBuffer.allocateDirect(ONE_MB);
          
          // 相对写，向position的位置写入一个byte，并将postion+1，为下次读写作准备
          buffer.put("abcde".getBytes());
          buffer.put("fghij".getBytes());
  
          // 转换为读取模式
          buffer.flip();
  
          // 相对读，从position位置读取一个byte，并将position+1，为下次读写作准备
          // 读取第1个字节(a)
          System.out.println((char) buffer.get());
  
          // 读取第2个字节
          System.out.println((char) buffer.get());
  
          // 绝对读，读取byteBuffer底层的bytes中下标为index的byte，不改变position
          // 读取第3个字节
          System.out.println((char) buffer.get(2));
      }
  }
  ```

- **JVM参数上**：可以使用-XX：MaxDirectMemorySize控制，默认是0，表示不控制。

- **优点**：

  - **减少了垃圾回收的工作**：因为直接内存是由操作系统直接管理的内存，分配到直接内存的对象不受JVM管理，也就不用JVM对其进行垃圾回收了。
  - **I/O效率高**：由于I/O操作中，使用直接内存可以减少一次Java Heap与C Heap之间的内存拷贝，从而提高了性能。

- **缺点**：

  - **直接内存难以控制**：直接内存不受JVM管理，需要用户自己来释放内存，当发生内存溢出时排查问题可能会变得非常困难。

- **适用场景**：

  - **需要存储的数据大且生命周期长**。
  - **频繁的I/O操作**，比如并发网络通信。

### 2.4. JVM执行引擎？

- JVM核心的组件就是**执行引擎**，负责执行虚拟机的字节码，一般会先编译成机器码后执行。
- “虚拟机”是一个相对于“物理机”的概念，虚拟机的字节码是不能直接在物理机上运行的，需要执行引擎编译成机器码后才可在物理机上执行。

### 2.5. 编译器优化机制？

#### 字节码运行模式

- **解释执行**：由解释器一行一行翻译字节码执行。
  - 优势在于没有编译的等待时间，可以节省内存（不存放到CodeCache），但由于要一行一行去翻译性，所以能差一些。
- **编译执行**：把字节码编译成字节码，直接执行机器码。
  - 运行效率会高很多，一般比解释执行快一个数量级，但带来了额外的内存（CodeCache）和CPU的开销。
- 相关命令：

| JVM参数              | 显示值                             | 说明                                                  |
| -------------------- | ---------------------------------- | ----------------------------------------------------- |
| java -version        | mixed mode，表示混合模式           | 查看字节码运行模式                                    |
| java -Xint -version  | interpreted mode，表示解释执行模式 | 指定解释执行模式                                      |
| java -Xcomp -version | compiled mode，表示编译执行模式    | 指定JVM优先以编译模式运行，不能编译的再以解释模式运行 |
| java -Xmixed         | mixed mode，表示混合模式           | 指定以混合模式运行（默认）                            |

#### JIT即时编译器

- **背景**：

  - JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。
  - 为了提高热点代码的执行效率，JVM会使用**即时编译器**，把这些热点代码编译成与本地平台相关的机器码，并进行**各层次的优化**。

- **概念**：Just In Time Compiler，JIT即时编译器，简称JIT编译器，在运行时JVM将会把热点代码编译成与本地平台相关的机器码，并进行各种层次的优化（比如锁粗化等），从而提高热点代码的执行效率。

  - **Hotspot - C1即时编译器**：也被称为Client  Compiler，是一个简单快速的编译器，主要关注局部性的优化，适用于执行时间较短或者对启动性能有要求的程序。比如GUI应用对界面启动速度就有一定的要求，此时适合用C1 编译器。
  - **Hotspot - C2 即时编译器**：也被称为Server Compiler，是为长期运行的服务器端应用程序做性能调优的编译器，适用于执行时间长或者对峰值性能有要求的程序。
  - **javac是前端编译**（也叫前期编译），负责把java代码编译成class字节码；而**JIT是后端编译**，负责把字节码编译成本地平台相关的机器码。

- **分层编译优化**：

  - level 0：解释执行。
  - level 1：简单的C1编译，使用C1编译器进行一些简单的优化，不开启Profiling（JVM的性能监控）。
  - level 2：受限的C1编译，仅执行**带方法调用次数**以及**循环回边执行次数**Pofiling的C1编译。
  - level 3：完全的C1编译，会执行带有所有Profiling的C1代码。
  - level 4：C2编译，使用C2编译器进行优化，该级别会启用一些编译耗时较长的优化，在一些情况下，会根据性能监控信息进行一些非常激进的性能优化。

  => 级别越高，应用启动越慢，优化的 开销越高，峰值性能也越高。

| JVM参数                                          | 默认值 | 说明                    |
| ------------------------------------------------ | ------ | ----------------------- |
| -XX：-TieredCompilation                          | ？     | 只开启C2（禁用123层）   |
| -XX：+TieredCompilation -XX：TieredStopAtLevel=1 | -      | 只开启C1（只开启0~1层） |

#### CodeCache

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。

#### 热点代码

- **概念**：JVM一般开始会以解释器解释执行，当发现某个方法或者代码块的运行特别频繁，则会认为这些代码为**热点代码**。

- **探测方法**：

  - **基于采样的热点探测**：周期性检查各个线程的栈顶，经常出现在栈顶的则为热点方法。
  - **基于计数器的热点探测**：Hotspot使用的方法，思路是为每个方法或者代码块建立一个**计数器**，统计其执行的次数，如果超过某个阈值，则认为它是热点代码。

- **Hotspot内置计数器**：

  - **方法调用计数器**：Invocation Counter，用于统计方法被调用的次数（不是绝对次数，而是在一个相对的执行频率，即一段时间内方法被调用的次数），在不开启分层编译的情况下，默认C1阈值为1500次，C2为10000次。

  | JVM参数                  | 默认值 | 说明                                                     |
  | ------------------------ | ------ | -------------------------------------------------------- |
  | -XX：CompileThreshold=？ | ？     | 指定方法调用计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626357990780](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626357990780.png)

  - **回边计数器**：

    - 回边，Back Edge，指定的是在字节码中遇到控制流向后跳转的指令。
    - 回边计数器，Back Edge Counter，用于统计一个方法中循环体代码执行的次数，在不开启分层编译的情况下，默认C1为13995次，C2为10700次。
    - 建立回边计数器的目的是为了触发OSR，OnStackReplacement编译，是一种在运行时替换正在运行函数或者方法的栈帧的技术，是一种用于提升benchmark跑分非常有效的技术。

    | JVM参数                         | 默认值 | 说明                                                 |
    | ------------------------------- | ------ | ---------------------------------------------------- |
    | -XX：OnStackReplacePercentage=? | ?      | 指定回边计数器阈值命令（开启分层编译后，此阈值失效） |

  ![1626358121407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626358121407.png)

#### 方法内联

- **概念**：把目标方法的代码复制到发起调用的方法之中，即方法内联，避免发生真实的方法调用，从而减少方法调用时压栈和出栈的操作，以减少内存消耗和操作的时间，提高系统性能。
  - 方法内联，本质上是空间换时间的方式，也就是即时编译器在编译期间把方法调用连接起来，从而减少入栈和出栈的开销。
- **内联条件**：
  - **方法体足够小**：
    - 热点方法，方法体小于325字节会尝试内联，可用-XX：FreqInlineSize命令修改阈值大小。
    - 非热点方法，方法体小于35字节会尝试内联，可用-XX：MaxInlineSize命令修改阈值大小。
  - **被调用的方法运行时的实现可以被唯一确定**：
    - static方法、private方法以及final方法，JIT可以唯一确定具体的实现代码，此时会尝试内联。
    - 而public的实例方法，指向的实现可能是自身、父类或者子类的代码，仅当JIT能够唯一确定其唯一实现时，才有可能完成内联。
- **内联带来的问题**：
  - 由于经过内联后的代码会变多，其增加的代码量取决于方法的调用次数和方法本身的大小，在一些极端情况下，内联可能会引起CodeCahce溢出，可能会导致JVM退化成解释执行模式。
    - CodeCahce：是热点代码的一个缓存区，即时编译器编译后的代码以及本地方法代码都会存放在这个区间内，空间大小比较有限（JDK 8中只有240M内存），比较容易出现CodeCahce溢出。

| JVM参数                             | 默认值 | 说明                                                         |
| ----------------------------------- | ------ | ------------------------------------------------------------ |
| -XX：+Printlnlining                 | -      | 打印内联详情，该参数需和-XX：+UnlockDiagnosticVMOption配合使用 |
| -XX：+UnlockDiagnosticVMOption      | -      | 打印JVM诊断相关的信息                                        |
| -XX：MaxlnlineSize=？               | 35     | 如果非热点方法的字节码超过该值（单位字节），则无法内联       |
| -XX：FreqlnlineSize=？              | 325    | 如果热点方法的字节码超过该值（单位字节），则无法内联         |
| -XX：lnlineSmallCode=？             | 1000   | 如果目标编译后生成的机器码大小大于该值（单位字节），则无法内联 |
| -XX：MaxlnlineLevel=？              | 9      | 内联方法的最大调用帧数（嵌套调用的最大内联深度）             |
| -XX：MaxTrivialSize=？              | 6      | 如果方法的字节码少于该值（单位字节），则直接内联             |
| -XX：MinlnlingThreshold=？          | 250    | 如果目标方法的调用次数低于该值，则不去内联                   |
| -XX：LiveNodeCountlnliningCutoff=？ | 40000  | 编译过程中最大活动节点（IR节点）的上限，仅对C2编译器有效     |
| -XX：lnliningFrequencyCount=？      | 100    | 如果方法的调用点（call site）的执行次数超过该值，则触发内联  |
| -XX：MaxRecursivelnlining Level=？  | 1      | 如果递归调用大于该值，则不去内联                             |
| -XX：+lnlineSynchronizedMethods     | 开启   | 是否允许同步方法的内联                                       |

#### 逃逸分析

- **概念**：分析变量能否逃出它的作用域。

- **4种逃逸场景**：

  - **全局变量赋值逃逸**：局部变量作用域放大到全局变量。

  ```java
  public static SomeClass someClass;
  
  // 全局变量赋值逃逸
  public void globalVariablePointerEscape() {
      someClass = new SomeClass();
  }
  ```

  - **方法返回值逃逸**：变量作用域随着方法返回而放大。

  ```java
  // someMethod(){
  //   SomeClass someClass = methodPointerEscape();// 方法返回值逃逸
  // }
  public SomeClass methodPointerEscape() {
      return new SomeClass();
  }
  ```

  - **实例引用逃逸**：变量作用域随着方法参数逃逸到其他作用域。

  ```java
  // 实例引用传递逃逸
  public void instancePassPointerEscape() {
      this.methodPointerEscape().printClassName(this);
  }
  
  
  ```

  - **线程逃逸**：类变量或者可以被其他线程中访问的实例变量，即共享变量，可以随着线程共享发生的逃逸。

- **逃逸状态标记**：JVM针对每个逃逸场景进行分析，分析后会给对象做一个逃逸状态标记。

  - **全局逃逸标记**：一个对象可能从**方法**或者**线程**中逃逸，即其他方法或者其他线程也可以访问这个对象。
    - 对象被作为方法的返回值。
    - 对象作为静态字段或者成员变量。
    - 如果某个类重写了析构函数finalize（）方法，则整个类的对象都会被标记为全局逃逸状态，并且一定会放到堆内存里面。
  - **参数逃逸状态**：一个对象被作为参数传递给一个方法，但在接收参数的方法之外无法访问该对象，且该对象对其他线程也是不可见的。
  - **无逃逸状态**：一个对象不会发生逃逸。

| JVM参数                    | 默认值       | 说明             |
| -------------------------- | ------------ | ---------------- |
| -XX：+DoEscapeAnalysis     | JDK8默认开启 | 是否开启逃逸分析 |
| -XX：+EliminateAllocations | JDK8默认开启 | 开启标量替换     |
| -XX：+EliminateLocks       | JDK8默认开启 | 是否开启锁消除   |

#### 逃逸分析优化 - 标量替换

标量替换指的是，在通过逃逸分析确定对象不会被外部访问，且对象可以进一步被分解后（聚合量），JVM不会创建该对象，而是创建其成员变量（标量）去代替。

- **标量**：不能被进一步分配的量，比如基础数据类型和对象的地址引用。
- **聚合量**：可以进一步分解的量，可以由标量聚合而成，比如字符串、自己定义变量。

```java
public void someTest() {
    // someTest没有逃逸时, 且可以进一步分解, 则可以进行标量替换
    SomeTest someTest = new SomeTest();
    someTest.age = 1;
    someTest.id = 1;

    // 开启标量替换之后, 上述代码会被优化成: 并不会创建SomeTest对象
    int age = 1;
    int id = 1;
}


```

#### 逃逸分析优化 - 栈上分配

栈上分配指的是，在通过逃逸分析确定对象不会被外部访问后，并且对象足够的小，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。

#### 逃逸分析优化 - 锁消除

等到并发章节再写。

### 2.6. 详细介绍创建一个对象的步骤？

**步骤：类加载检查、类加载（加载、链接、初始化）、分配内存、初始化零值、设置对象头、执行init方法**

1. **类加载检查** ：当JVM遇到new指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。

2. **类加载 - 加载**：指的是将类的**class文件（二进制数据）**读入到内存，并转换成**方法区中的运行时数据结构**。同时在堆中生成一个代表这个类的**java.lang.Class对象**，该对象封装了类在方法区中的数据结构，并且向用户提供了访问方法区数据结构的接口，即Java反射的接口。

3. **类加载 - 链接**：该阶段负责把**类的二进制数据合并到JRE中**，可分为如下3个阶段：

   - **验证**：验证Class文件是否符合规范，是否能被当前的虚拟机加载处理，确保加载的类没有安全方面的问题。
   - **准备**：为类的静态变量（static）分配内存，并初始化为初始值（0或null）。而对于静态常量（final static修饰）会直接被赋值为用户定义的值。
   - **解析**：将Class常量池（Constant Pool）的符号引用转换为直接引用。

4. **类加载 - 初始化**：类初始化是类加载的最后一步，真正执行Java代码，主要工作是为静态变量（static）赋值为用户定义的值。初始化完毕类就可以被使用了。

   - 执行clinit 方法，clinit方法由编译器自动收集类里面的**所有静态变量的赋值动作及静态语句**合并而成，也叫**类构造器方法**。

5. **分配内存**：在确定对象需要创建后，接下来JVM将为对象分配内存，分配⽅式有 **“指针碰撞”** 和 **“空闲列表”** 两种，在分配内存的过程中，需要注意使用的是哪一种垃圾收集算法，因为垃圾收集算法的不同会导致内存块是否规整，从而影响到分配内存的方式是使用指针碰撞还是使用空闲列表。

   - 在进行内存分配的时候，如果使用的是指针碰撞方法，还需要注意并发情况下，内存的分配是否是线程安全的。一般使用**加同步块**的方式和**线程私有分配缓存区**这两种方式解决线程安全的问题。

6. **初始化零值**：对象内存分配完成后，JVM需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的**实例字段**在Java代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。

7. **设置对象头**： 初始化零值完成之后，JVM要对对象进⾏必要的设置，比如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息将存放在对象头中。另外，根据JVM当前运⾏状态的不同，比如是否启⽤偏向锁等，对象头会有不同的设置⽅式。

   - **对象头主要包括两部分**：用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳）以及类型指针（即对象指向该类元数据的指针，JVM通过这个指针来确定这个对象是哪个类的实例）。

   ![1626822381182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626822381182.png)

8. **执⾏init⽅法**： 从JVM的视⻆来看，⼀个新的对象已经产⽣了，但从Java程序的视⻆来看， init⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏new指令之后会接着执⾏init⽅法，这样⼀个真正可⽤的对象才算产⽣出来。

   - 类初始化后，如果是实例化一个新对象，还会调用< init >方法，与< clinit >类似，< init >方法可以看作是**对象构造方法**，是由编译器自动收集类中所有实例变量的赋值动作、实例代码块和构造函数合并而成的。
   - 如果是对实例变量直接赋值或者使用实例代码块赋值，那么编译器会将这些代码合并到实例构造函数中去，并且它们还会被放在对父类构造函数的调用语句之后（因为Java要求构造函数的第一条语句必须是父类构造函数的调用语句)，自身构造函数的代码之前去执行。
   - 因此，类构造器和对象构造器的初始化过程为：**父类的类构造器 -> 子类的类构造器 -> 父类成员变量的赋值和实例代码块 -> 父类的构造函数 -> 子类成员变量的赋值和实例代码块 -> 子类的构造函数。**

### 2.7. 对象内存分配过程？

![1626823040622](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626823040622.png)

1. 对象首先尝试栈上分配，如果栈上分配成功，则直接在栈上分配对象。
   - **栈上分配**指的是，在通过**逃逸分析**确定对象不会被外部访问后，并且**对象足够的小**，那么JVM会直接在栈上分配对象，而其对象内存在出栈时会被回收，从而减少垃圾回收的压力。
2. 如果不能在栈上分配，且**对象也足够的小**，则尝试TLAB分配，如果TLAB分配成功，则直接在TLAB分配对象。
   - **TLAB**：Thread Local Allocation Buffer，线程私有分配缓存区，是一块**线程专用的内存分配区域**，JVM会为每个线程分配一块TLAB区域，**实质占用的是Eden区的空间（即分配独享、使用共享）**，用于给每个线程往自己的TLAB中分配**小对象**，这样可以避免堆分配对象时的线程冲突，从而提升分配对象的效率。
3. 如果也不能在TLAB分配（大部分对象），则对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
4. 然而，**新建的对象不一定直接分配到Eden区**：如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
5. 同时还要注意的是，**由于JVM有动态年龄判定机制，对象不一定要达到年龄才能进入老年代**：
   - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

### 2.8. Java垃圾回收机制？

- **背景**：
  - 在Java中，程序员是**不需要显式去释放一个对象的内存**的，而是由虚拟机自行执行。
  - 在JVM中，有一个垃圾回收线程，它是低优先级的，在正常情况下是不会执行的，只有在虚拟机空闲或者当前堆内存不足时，才会触发执行，扫面那些没有被任何引用的对象，并将它们添加到要回收的集合中，进行回收。
- **使用场景原则**：
  - **内存要求**：内存不够，则需要想办法提高对象的回收率，以多回收一些对象，从而腾出更多的内存。
  - **CPU要求**：CPU不够，则需要降低垃圾回收频率，让CPU多去执行业务，而不是垃圾回收。
- **垃圾回收的区域**：虚拟机栈、本地方法栈和程序计数器是线程独享的，是随着线程的创建而创建的，随着线程的销毁而销毁的， 是不需要考虑垃圾回收的；而堆和方法区是线程共享的，需要关注垃圾回收。
  - **堆**：是垃圾回收的主要区域，用于回收创建的对象。
  - **方法区**：用于回收废弃的常量以及不需要的类。
- **回收时机**：由对象存活算法决定。

### 2.9. 对象存活算法？

#### 引用计数法

通过对象的引用计数器，来判断该对象是否被引用，比如有对象引用就+1，其引用失效就-1，当为0时，则代表该对象没有被引用。

- **优缺点**：实现简单，判断效率高；但无法解决对象循环引用的问题，**目前Java并不使用该算法**。

![1626436324696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436324696.png)

#### 可达性分析

以**根对象（GC Roots）**作为起点向下搜索，走过的路径被称为**引用链**（Reference Chain），如果某个对象到根对象之间没有引用链相连，则认为该对象是不可达的，是可以被回收的。**Java使用的是该存活算法**。

- **根对象**包括：
  - 虚拟机栈（栈帧中的局部变量表）中Reference对象所引用的对象。
  - 方法区中类的静态属性（static）Reference对象所引用的对象。
  - 方法区中常量（final）Reference对象所引用的对象。
  - 本地方法栈中JNI（即Native方法）Reference对象所引用的对象。

![1626436445717](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626436445717.png)

- **可达性分析完整流程**：注意，一个对象即使不可达，也不一定会被回收，还要继续判断有无必要执行析构函数**finalize（）**方法，如果方法里面重新建立了与根对象之间的引用链，则不会去回收，否则还是会被回收。
  - **两次标记过程**：
    - 第一次标记不在“关系网”中的对象。
    - 第二次先判断该对象有没有实现finalize（）方法，如果没有实现，则直接判断该对象可回收；如果实现了，则会先放在一个队列中，并由JVM建立的一个低优先级的线程去执行它，随后会进行第二次的小规模标记，而在这次被标记的对象就会真正地被回收了。
  - **使用建议**：
    - 避免使用finalize（）方法，操作不当可能会导致问题。
    - finalize（）方法优先级低，什么时候会被调用也无法确定，因为什么时候发生GC是不确定的。
    - 建议使用try...catch...finally来代替finalzie（）方法。

![1626437028531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437028531.png)

### 3.0. JVM垃圾回收算法

分为**基础垃圾回收算法**（标记清除算法、标记整理算法和复制算法）和**综合垃圾回收算法**（分代搜集算法和增量算法）。

#### 基础 - 标记清除算法

- **优缺点**：实现简单；但存在内存碎片，影响对象的内存分配速度，在极端情况下需要遍历整个内存链表。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 再清理掉要回收的对象。

![1626437545225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437545225.png)

#### 基础 - 标记整理算法

也叫标记压缩算法。

- **优缺点**：无内存碎片；但由于整理需要计算和时间整理对象到一端，存在CPU和时间的开销。
- **算法流程**：

1. 通过可达性分析，标记需要回收的对象。
2. 然后把所有存活对象压缩到内存的一端。
3. 再清理掉边界外的所有空间。

![1626437785184](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437785184.png)

#### 基础 - 复制算法

- **优缺点**：性能好（无需标记所有对象，只需找出存活的并移动即可），无内存碎片；但内存利用率低，最多才达到50%。
- **算法流程**：

1. 把内存分为两块，每次只使用其中一块。
2. 通过可达性分析，将存活的对象复制到另一块未使用的内存中，然后清除掉正在使用的那块内存中的所有对象。
3. 最后交换两块内存块的角色，等待下次回收重复执行上述操作。

![1626437874675](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626437874675.png)

#### 综合 - 分代收集算法

- **概念**：

  - 各种商业虚拟机堆内存的垃圾收集基本上都采用了分代收集算法。
  - 根据对象的存活周期，把内存分为多个区域，**不同区域使用不同的回收算法**来回收对象，以提升整体性能。
  - 堆是垃圾回收的主要区域，其内存可以划分为以下区域：

  ![1626349372632](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626349372632.png)

- **垃圾回收类型**：

  - **新生代回收**：Minor GC或者Young GC
  - **老年代回收**：Major GC，执行Major GC往往伴随一次Minor GC，所以**Major GC  ≈ Full GC**。
  - **清理整个堆**：Full GC = Major GC + Minor GC。

- **对象内存分配过程**：

  - **典型模型**：
    - **回收新生代使用复制算法**，因此新生代需要有两块内存（Eden区和Survivor区，8：2），Survivor区也有两块内存（From Survivor和To Survivor，1：1）。
      1. 对象在创建时会优先存放到**Eden区**，当Eden区满时会触发Minor GC，即JVM会将Eden区存活的对象拷贝到**Survivor区（From Survivor/To Survivor）**里。
      2. 而在下次Minor GC时，JVM又会将存活的对象拷贝到To Survivor/From Survivor区里，下下一次再周而复始。
      3. 对象每经历一次垃圾回收后，如果仍然存活，则**该对象年龄+1**，当对象年龄达到阈值（默认15），则会晋升到**老年代**。
    - **回收老年代使用标记清除或者标记整理算法**，老年代：新生代，默认内存大小比值为2：1。
  - **新建的对象不一定直接分配到Eden区**：
    - 如果对象大于-XX：PretenureSizeThreshold（默认为0，表示所有对象都优先在Eden区分配），则会直接分配到老年代。
    - 如果对象非常大，而新生代空间又不足，则会将该对象直接放到老年代去担保，主要是为了避免分配到采用复制算法的新生代，在大对象存活时内存拷贝带来的大量消耗。
  - **对象不一定要达到年龄才能进入老年代**：
    - **动态年龄**：如果Survivor区中相同年龄对象的大小总和，超过了Survivor区空间大小的一半时，则会晋升大于等于该年龄的对象到老年代。

- **触发垃圾回收的条件**：

  - **新生代Minor GC**：Eden区空间不足时。
  - **老年代/Full GC**：
    - **老年代空间不足**：没有足够空间，或者内存碎片过多导致没有足够的连续空间去分配对象。
    - **元空间不足**：方法区的元空间不足也会触发Full GC。
    - **显示调用System.gc（）**：该方法的作用是建议垃圾回收器执行垃圾回收，会触发Full GC，可以使用-XX：+DisableExplicitGC参数忽略System.gc（）的调用。

- **分代收集算法的好处**：

  - **更有效的清除不再需要的对象**：对于生命周期比较短的对象，在新生代就会被回收掉了。
  - **提升了垃圾回收的效率**：如果不做分代处理，每次回收需要扫描整个堆的对象，而分代回收则需要扫描新生代或者老年代就可以了。

- **分代收集算法的调优原则**：

  - **合理设置Survivor区的大小，避免内存浪费**：因为Survivor区的内存利用率不高，如果设置得过大，则会导致内存浪费严重。
  - **让GC尽量发生在Minor GC级别，尽量减少Full GC的发生**。

| JVM参数                        | 默认值 | 说明                                                         |
| ------------------------------ | ------ | ------------------------------------------------------------ |
| -XX：+NewRatio=？              | 2      | 老年代：新生代的内存大小比值                                 |
| -XX：SurvivorRatio=？          | 8      | Eden区：Survivor区的内存大小比值                             |
| -XX：PretenureSizeThreshold=？ | 0      | 分配到老年代的对象大小阈值，为0表示不做限制，所有对象都优先在Eden区分配 |
| -Xms                           | -      | 最小堆内存                                                   |
| -Xmx                           | -      | 最大堆内存                                                   |
| -Xmn                           | -      | 新生代大小                                                   |
| -XX：+DisableExplicitGC        | 开启   | 忽略掉System.gc（）的调用                                    |
| -XX：NewSize=？                | -      | 新生代初始内存大小                                           |
| -XX：MaxNewSize=？             | -      | 新生代最大内存                                               |

#### 综合 - 增量算法

每次只收集一小片区域内存的垃圾，从而减少系统的停顿时间，见G1收集器的实现。

### 3.1. JVM垃圾收集器？

#### 相关概念

- **垃圾回收算法**：为实现垃圾回收提供理论支持。
- **垃圾收集器**：利用垃圾回收算法，实现垃圾回收的实践落地。
- **Stop The World**：**简写为STW，也叫全局停顿**，处于该状态时，Java代码将停止运行，而native代码可以继续运行，但无法与JVM进行交互。
  - **原因**：多半由于垃圾回收导致，也有可能由Dump线程、Dump堆、死锁检查等操作导致。
  - **危害**：服务会停止，没有响应；STW时间过长，可能会导致主从发生切换，影响生产环境。
- **并行收集**：指多个垃圾收集线程同时并行工作，但在收集过程中，用户线程处于等待状态。
- **并发收集**：指用户线程与垃圾收集线程同时工作。
- **应用吞吐量**：指的是CPU用于运行业务代码的时间，与CPU总消耗时间的比值。
  - **计算公式**：应用吞吐量 = 运行业务代码时间 / （运行用户代码时间 + 垃圾收集时间）* 100%，垃圾收集时间越长，应用吞吐量越小。

 ![1626495749202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626495749202.png)

#### 新生代 - Serial收集器

- **背景**：最基本的、发展历史最悠久的收集器。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **单线程、简单、相对高效**：由于是单线程实现的，不存在与其他线程的交互开销，可以专心做垃圾回收。
  - **收集过程全程Stop The World**。
- **适用场景**：
  - **用于客户端程序**：如果应用以java -client -jar方式启动时，默认使用的就是Serial收集器。
  - **用于单核机器上**：常见于一些嵌入式低性能的机器上运行。
- **执行过程**：
  - **Safepoint**：当发生GC时，用户线程必须全部停下来，才可以进行垃圾回收，这个状态可以认为JVM 是安全的（safe），整个堆的状态是稳定的。如果在GC前，有线程迟迟进入不了safepoint状态，那么整个 JVM都在等待这个线程，从而造成了GC整体时间变长。

![1626496514434](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626496514434.png)

#### 新生代 - ParNew收集器

- **背景**：Serial收集器的多线程版本，除了使用多线程不同以外，其他都和Serial收集器一样，包括JVM参数、Stop The World别的表现和垃圾收集算法。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **多线程、收集过程全程Stop The World**。
  - 可使用**-XX：ParallelGCThreads**设置垃圾收集的线程数，一般设置为CPU核心数就可以了。
- **适用场景**：主要用来和CMS收集器配合使用。
- **执行过程**：

![1626505507768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505507768.png)

#### 新生代 - Parallel  Scavenge收集器

- **背景**：也叫吞吐量优先收集器，也是并行的多线程收集器（多线程的方式与ParNew收集器类似）。
- **垃圾收集算法**：复制算法。
- **特点**：
  - **可以达到一个可控制的吞吐量**：
    - -XX：MaxGCPauseMillis，设置阈值后，JVM将**尽力控制**最大的垃圾收集停顿时间为该阈值。
    - -XX：GCTimeRatio，设置吞吐量的大小，取值0~100，设置后JVM将花费不超过1 + / （1+n）的时间用于垃圾收集。
  - **自适应GC策略**：可用-XX：+UseAdptiveSizePolicy启用，启用后无需手动设置-Xmn、-XX：SurvivorRatio等参数，虚拟机会根据系统的运行状况收集性能监控信息，动态地调整这些参数，从而达到最优的停顿时间以及吞吐量。因此Parallel  Scavenge收集器存在着一定的智能性。
- **适用场景**：比较注重吞吐量的场景。
- **执行过程**：

![1626505950316](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626505950316.png)

#### 老年代 - Serial Old收集器

- **背景**：也叫串行老年代收集器，可以认为是Serial收集器的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：除了算法采用标记整理算法与Serial收集器不同之外，其他都是一样的。
- **适用场景**：
  - 可以和Serial、ParNew、Parallel Scavenge三个新生代收集器配合使用。
  - CMS收集器在出现故障时，会使用Serial Old收集器作为备用。
- **执行过程**：

![1626506526709](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506526709.png)

#### 老年代 - Parallel Old收集器

- **背景**：可以认为是Parallel Scavenge的老年代版本。
- **垃圾回收算法**：标记整理算法。
- **特点**：只能和Parallel Scavenge新生代收集器使用。
- **适用场景**：关注吞吐量的场景。
- **执行过程**：

![1626506871826](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626506871826.png)

#### 老年代 - CMS收集器

- **背景**：CMS，Concurrent Mark Sweep，并发标记清除，是一个并发收集器，可以与用户线程同时工作。
- **垃圾回收算法**：标记清除算法。Serial Old与Parallel Scavenge采用的是标记整理算法。
- **特点**：
  - **优点**：
    - **Stop The World时间比较短，大多过程都是并发执行的**：只有1. 初始标记和5. 重新标记阶段存在Stop The World，其他阶段都是并发执行的）。
  - **缺点**：
    - **CPU资源比较敏感，并发执行的阶段会导致应用吞吐量的降低**：由于垃圾收集线程也需要占用一定的CPU资源，与业务线程一起去争抢CPU时间片，导致影响业务线程的执行效率，降低应用吞吐量。
    - **无法处理浮动垃圾**：由于并发清除阶段用户线程仍在并发执行，其可能会产生新的垃圾，这部分垃圾称为浮动垃圾，而CMS无法在本次GC清理掉这些浮动垃圾，需要留到下次GC才能清理掉。
    - **不能等到老年代几乎满了才开始收集**：因为用户线程并发执行，必须为老年代预留足够的内存给用户线程使用。如果CMS执行期间预留的内存不能满足用户程序的需要，则会出现一次Concurrent Mode  Failure异常，这将会导致JVM**改用备用的Serial Old收集器**去收集老年代的垃圾，从而导致Stop The World时间加长。
      - 可使用CMSInitiatingOccupancyFraction，设置老年代占比达到多少后（默认68%），就会触发CMS垃圾收集。
    - **存在内存碎片（最令人诟病的地方）**：标记清除算法会导致内存碎片的产生。
      - 可使用UseCMSCompactAtFullCollection，在完成Full GC后是否要进行内存碎片的整理（默认打开）。
      - 也可使用CMSFullGCsBeforeCompaction，在进行几次Full GC后就进行一次内存碎片的整理（默认为0）。
  - **其他**：对于CMS收集器，Major GC和Full GC并不约等于，因为CMS是作用在老年代的垃圾回收，这里讲的Major GC并不是之前讲的Full GC。
- **适用场景**：
  - **希望系统停顿时间短，响应速度快的场景**：比如各种服务端应用场景。
- **执行过程**：

1. **初始标记**： 
   - initial  mark，标记根对象（GC Roots）能直接关联到的对象，因此能够标记到的对象会比较少。
   - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
2. **并发标记**：
   - concurrent mark，找出所有根对象（GC Roots）能够关联到的对象。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
3. **并发预清理**：
   - concurrent-preclean，**不一定会执行的阶段**，可用-XX：-CMSPrecleaningEnabled，关闭并发预清理阶段，默认是打开的。
   - 重新标记那些在并发标记阶段，引用被更新了的对象（比如新晋升到老年代的对象），从而减少后面重新标记阶段的工作量。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
4. **并发可中止的预清理阶段**：
   - concurrent-abortable-preclean，**不一定会执行的阶段**，使用该阶段的前提条件是：当Eden区使用量大于CMSScheduleRemarkEdenSizeThreshold的阈值（默认2M）时，才会执行该阶段。
   - 与并发预清理阶段所工作的事情是一样的。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 该阶段的主要作用是：允许用户能够控制预清理阶段的结束时机。
     - 比如，扫描多长时间：可用CMSMaxAbortablePrecleanTime进行设置，默认为5秒。
     - 再如，当Eden区使用占比达到多大阈值就结束本阶段：可用CMSScheduleRemarkEdenPenetration进行设置，默认为50%。
5. **重新标记**：
   - remark，修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
     - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
     - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
   - 存在Stop The World，一般来说（经验之谈），重新标记所花费的时间会比初始标记阶段的要长一些，但会比并发标记阶段的段一些。
6. **并发清理**：
   - concurrent sweep，或者叫**并发清除**，会基于标记结果，清除掉要前面标记出来需要清除的垃圾（会存在内存碎片）。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。
   - 为什么是并发清除，而不是并发整理？
     - 由于本阶段是并发执行的，如果还要整理对象的话，则还需要移动对象的位置。
     - 试想一下如果既要回收垃圾，又要整理移动对象的位置，还要与用户线程并发执行，保证业务程序没有问题，这实现起来会变得非常困难，还容易出错。
     - 而采用并发清除就变得容易了许多，因此这里是并发清除而不是并发整理。
7. **并发重置**：
   - concurrent reset，清理本次CMS GC的上下文信息，为下一次GC做准备。
   - 垃圾收集线程和用户线程并发执行，没有Stop The World。

![1626507231972](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626507231972.png)

#### 新生代&老年代 - G1收集器

- **背景**：Garbge First，是一款面向服务器端应用的垃圾收集器，既可以用在新生代，又可以用在老年代，即整个堆内存，会优先处理那些垃圾多的Region（First是价值优先的意思）。

- **垃圾回收算法**：复制算法。

- **革命性变化**：

  - **堆内存布局上的变化**：G1将整个堆划分成了若干个大小相等的区域，每个区域叫一个Region。
    - Region的大小可通过-XX：G1HeapRegionSize来指定，取值范围为1M~32M，必须为2的N次幂。
    - 在G1收集器里，同一代的对象可能是不连续的：一共分为4类Region，分别为Eden Region（伊甸园）、Survivor Region（存活区）、Old Region（老年代）、 Humongous Region（用于存储大对象，即超过Region大小一半的对象，而特大对象会分配到连续的Humongous Region里面）。

  ![1626511732234](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626511732234.png)

  - **设计思想上的变化**：**化整为零，分而治之**，本质上是应用了**增量算法**的思想。
    - 将堆内存按照Region分成多个块。
    - 然后会去跟踪每个Region里面的垃圾堆积的价值大小（即回收一个Region能够获取到多大的剩余空间）。
    - 最后构建一个优先列表，根据允许的收集时间，**优先回收价值高的Region**（回收后能够得到大的空间），以获得更高的垃圾收集效率。

- **特点**：

  - 可以作用在整个堆，既可以作用在新生代，又可以作用在老年代。
  - 垃圾回收时的停顿时间是可控的。
    - 可用MaxGCPauseMillis=？去控制。
  - 回收Region使用的是复制算法，无内存碎片的问题。

- **适用场景**：

  - 占用内存较大的应用（比如6G以上）。
  - 用于替换CMS垃圾收集器。
    - 对于JDK 8，G1和CMS的性能差异并不大，都可以使用。（经验之谈）如果内存<=6G，建议使用CMS；如果内存>6G，可以考虑使用G1。
    - 对于> JDK 8，则使用G1，因为CMS从JDK 9就已经被废弃了。

- **垃圾收集机制**：

  - **Young GC**：过程上与之前的Minor GC差不多（**复制算法**），只不过回收的单位是Region。

    - 所有Eden Region都满了时，会触发Young GC。
    - 所有Eden Region里面存活的对象，都会转移到Survivor Region里面去。
    - 而原先在Survivor Region中存活的对象，则会转移到新的Survivor Region中，或者晋升到Old Region中。
    - 其中，回收后空闲的Region会被放入空闲的列表中，等待下次被使用。

  - **Mixed GC**：最能体现G1的设计思想，与CMS有类似之处，但也有许多差异，比如使用的是复制算法。

    - 老年代大小占整个堆的百分比达到一定阈值时，则会触发Mixed GC。
      - 可用-XX：InitiatingHeapOccupancyPercent指定，默认为45%。
    - Mixed GC会回收所有Young Region，同时回收**部分**Old Region，回收那些根据收集时间与回收价值而选择的Old Region。
    - **执行过程**：除2. 并发标记是并发执行，其他阶段都是需要Stop The World的，但由于每次只回收部分Region，所以**Stop The World的时间是可控的**。

    1. **初始标记**：
       - Initial Marking，与CMS的初始标记类似，都是标记根对象（GC Roots）能直接关联到的对象。
       - 存在Stop The World，不过由于标记的对象比较少，所以STW的时间也是比较短的。
    2. **并发标记**：
       - Concurrent Marking，与CMS的并发标记类似，用于找出所有根对象（GC Roots）能够关联到的对象。
       - 垃圾收集线程和用户线程并发执行，没有Stop The World。
    3. **最终标记**：
       - Final Marking，与CMS的重新标记类似，用于修正并发标记期间，由于用户线程并发运行，导致标记发生变动的那些对象的标记。
         - 比如在并发标记期间，错误地把已经死亡了的对象，标记为了存活，会导致部分垃圾不被回收。
         - 再如把存活的对象错误地标记成为了死亡，可能会导致用户程序之后无法继续执行。
       - 存在Stop The World。
    4. **筛选回收**：
       - Live Data Counting and Evaluation，会对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间（MaxGCPauseMillis）来制定回收计划，并选择一些Region进行回收。
       - **回收过程：复制算法，无内存碎片**。
         - 选择一系列Region构成一个回收集。
         - 接着把决定要回收的Region中的存活对象复制空的 Region中。
         - 最后删除掉需要回收的Region。
       - 存在Stop The World。

  ![1626513840821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626513840821.png)

  - **Full  GC**：
    - 当G1在复制对象时发现内存不够，或者无法分配足够内存（比如特大对象没有足够的连续Humongous Region可分配）时，则会触发Full GC。
    - 一旦触发Full GC，在Full GC模式下使用的是Serial Old模式的垃圾回收，将会出现长时间的Stop The World。

- **G1调优原则**：

  - 尽量减少Full GC的发生，尽量只停留在Young GC或者Mixed GC的模式上进行垃圾回收。
  - **减少Full GC的思路**？
    - **增加预留的内存**：可用过加大-XX：G1ReserveRercent来实现，默认为堆的10%。
    - **更早地回收垃圾，可降低老年代大小占整个堆的百分比的阈值，提早触发Mixed GC**：可通过减少-XX：InitiatingHeapOccupancyPercent来实现，默认为45%。
    - **增加并发阶段使用的线程数**：可增大-XX：ConcGCThreads，这样就可以有更多的垃圾回收线程去工作，但会降低业务应用的吞吐量。

#### 其他垃圾收集器

Shenandoah、ZGC、Epsilon，JDK 14处于实验状态，不建议在生产环境中使用。

#### 如何选择垃圾收集器？

不能纸上谈兵，要根据实际情况选择。

- 应用系统所关注的最主要的矛盾点？
  - 响应快、吞吐量高：Parallel Scaveng。
  - Web应用，低延迟：CMS或者G1。
  - 桌面端应用，启动慢：Serial & -Xverify：none参数。
- 应用系统的基础设施？
  - 单核：Serial。
  - Windows + JDK11：应用不了ZGC，需要升级到JDK14才支持。
- 应用系统的JDK的版本？
  - JDK6用不了G1。
  - Oracle JDK用不了Shenandoah。

#### 垃圾收集器相关JVM参数

详细见《JVM参数选型-高级选型-常用高级垃圾收集选项》一栏。

### 3.2. JVM性能调优工具？

详细见《JVM调优工具集锦》：基于JDK 11编写。

#### JDK内置 - 监控类工具

##### jps

Java Virtual Machine Process Status Tool，实验性工具，用于查看所有Java进程，比ps -ef  | grep java方便。

```java
eg：
jps -q：只查看进程号。
jps -m：查看传递给main方法的参数。
jps -l：查看启动类的全限定名。
jps -v：查看JVM启动时的参数。


```

##### jstat

JVM Statistics Monitoring Tool，实验性工具，⽤于监控JVM的各种运⾏状态息，包括**内存状态**和**垃圾回收**。

```java
命令格式：jstat -<option> [-t] [-h<lines>] <vmid> [<interval> [<count>]]
  -<option> ：指定参数，取值可⽤jstat -options查看
  -t        ：⽤来展示每次采样花费的时间
  <lines>   ：每抽样⼏次就列⼀个标题，默认0，显示数据第⼀⾏的列标题
  <interval>：抽样的周期，格式使⽤:<n>["ms"|"s"]，n是数字，ms/s是时间单位，默认是ms
  <count>   ：采样多少次停⽌，默认是一直打印

option参数解释：
-class    :：显示类加载器的统计信息
-gcutil    ：垃圾回收统计概述
-gc        ：垃圾回收堆的行为统计
-gcnew     ：新生代行为统计
-gcold     ：年老代和永生代行为统计
-gccapacity：各个垃圾回收代容量(young,old,perm)和他们相应的空间统计


```

#### JDK内置 - 故障排查类工具

##### jinfo

Java Configuration Info，实验性参数，主要⽤来查看以及调整JVM参数。

```java
命令格式：jinfo <option> <pid>

1）查看能力:
jinfo 11666：查看11666进程的Java System Properties、VM Flags、VM Arguments
jinfo -sysprops 11666          ：只查看11666进程的Java System Properties
jinfo -flags 11666             ：只查看11666进程的VM Flags
jinfo -flag 11666 Xmx          ：只查看11666进程的Xmx参数（最大堆内存大小）
jinfo -flag 11666 Xms          ：只查看11666进程的Xms参数（初始堆内存大小）
jinfo -flag 11666 Xmn          ：只查看11666进程的Xmn参数（新生代内存大小）
jinfo -flag 11666 MetaspaceSize：只查看11666进程的MetaspaceSize参数（元空间内存大小）

2）动态修改能力：不用重启JVM就可以生效，但能力比较有限
java -XX:+PrintFlagsInitial | grep manageable：只有显示出来的结果才能被动态修改。
开关类（打开/关闭）：jinfo -flag +HeapDumpAfterFullGC 11666
赋值类（更新为60） ：jinfo -flag MinHeapFreeRatio=60 11666


```

##### jmap

Java Memory Map，实验性工具，⽤来展示对象内存映射或者堆内存详细信息。

- **生成堆dump的8种方式**：
  - **jmap**：jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆Dump文件为mydump.hprof。
  - **jcmd**：jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）。
  - **jhsdb jmap**：jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件。
  - **Visual VM**：Monitor界面的Heap Dump按钮Dump堆，相当于jmap dump命令。
  - **OOM异常自动后生成**：使用-XX：+HeapDumpOnOutOf  MemeoryError，使JVM在OOM异常出现后自动生成堆Dump文件。
  - **Ctrl + （Pause）Break生成**：使用-XX：+HeapDumpOnCtrBreak，开启后可使用Ctrl + （Pause）Break，让虚拟机生成堆Dump文件。
  - **kill -3命令**：在Linux操作系统下，发送kill -3 pid命令生成堆Dump文件。
  - **借助SpringBoot Actuator生成**：对于SpringBoot应⽤，可以使⽤SpringBoot Actuator提供的/actuator/heapdump来实现堆Dump的生成。

```java
命令格式：jmap [option] <pid>

option参数解释：
-heap             ：打印java heap摘要
-clstats          ：打印Java堆的类加载器统计信息
-finalizerinfo    ：打印等待finalization的对象的信息
-histo[:live]     ：打印Java堆的直⽅图。如果指定了live⼦选项，则仅统计活动对象
-dump:dump_options：生成java堆的dump文件。其中，dump_options的取值为：
              live：指定时，仅Dump活动对象；如果未指定，则转储堆中的所有对象
          format=b：以hprof格式Dump堆
     file=filename：将堆Dump到filename

eg:
jmap -dump:live,format=b,file=mydump.hproft 11666：转储java的堆dump文件为mydump.hprof


```

##### jstack

Stack Trace for Java，实验性工具，⽤于打印当前虚拟机的线程快照（线程快照也叫Thread Dump或者javacore⽂件，包含展示每个线程正在做什么、执行到了哪里等信息），常用于定位线程出现长时间卡顿的原因，比如死锁、死循环等。

- **生成线程dump的4种方式**：
  - **jstack**：jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息。
  - **jcmd**：jcmd 11666 Thread.print -l：打印11666进程所有线程以及线程持有锁的额外信息。
  - **jhsdb jstack**：jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息。
  - **VisualVM**：Threads界面的Thread Dump按钮Dump线程，相当于jstack。

```java
命令格式：jstack [-l][-e] <pid>
  
option参数解释：
-l：显示有关线程持有的锁的额外信息
-e：展示有关线程的额外信息（⽐如分配了多少内存、定义了多少个类等等）

eg：
jstack -l -e 11666：打印11666进程的所有线程以及持有锁的额外信息


```

##### jhat

JVM Heap Analysis Tool，实验性工具，⽤来分析jmap⽣成的堆Dump，能力比较弱，有非常多的替代品（比如VisualVM、Eclipse Memory Analyzer），且在JDK 11已被废弃（可在JDK 8中使用），对于学习不太重要了。

```java
命令格式：jhat [options] heap-dump-file

option参数解释：
-stack false | true   ：开启或关闭跟踪对象分配调⽤栈，默认true
-refs false | true    ：开启或关闭对对象引⽤的跟踪，默认true
-port port-number     ：指定jhat HTTP Server的端⼝，默认7000
-exclude exclude-file ：指定⼀个⽂件，该⽂件列出了应从可达对象查询中排除的数据成员
-baseline exclude-file：指定基线堆Dump⽂件。两个堆Dunmp中，对于⽐较两个不同的堆转储很有⽤
-debug intSets        ：指定该⼯具的debug级别。设置为0，则不会有debug输出。数值越⾼，⽇志越详细
-version              ：显示版本


```

##### jcmd

JVM Command，⽤于将诊断命令请求发送到正在运⾏的Java虚拟机，从JDK 7开始提供。

```java
命令格式：jcmd <pid | main class> <command ...|PerfCounter.print|-f file>

命令参数解释：
pid              ：接收诊断命令请求的进程ID
main class      :：接收诊断命令请求的main类的所有进程
command          ：command必须是⼀个有效的jcmd命令
PerfCounter.print：打印指定Java进程上可⽤的性能计数器
-f filename      ：从指定⽂件中读取命令并执⾏
-l               ：查看所有的JVM进程。jcmd不使⽤参数与jcmd -l效果相同

eg：
jcmd 11666 GC.heap_dump -all mydump.hprof：⽣成Java堆Dump⽂件（HPROF格式）
jcmd 11666 GC.run						 ：调⽤一次java.lang.System.gc()
jcmd 11666 Thread.print -l		         ：打印11666进程所有线程以及线程持有锁的额外信息


```

##### jhsdb

Java Hotspot Debugger，Hotspot进程调试器，可⽤于从崩溃的JVM附加到Java进程或核⼼转储，从JDK 9开始引入，JDK 9前使用sa-jdi.jar（jhsdb的原型）也是可以的。

```java
1）jhsdb clhsdb --pid 11666：进入11666进程的jhsdb的交互界面
eg：（交互界面下）
	flags          ：展示所有以-XX开头的JVM参数的值
	g1regiondetails：查看G1每个Region的起始指针、结束指针、是哪一个分代的信息

2）jhsdb hsdb --pid 11666：进入11666进程的图形化界面

3）jhsdb jinfo --flags --pid 11666：打印11666进程的VM标志

4）jhsdb jmap --binaryheap --dumpfile mydump.hprof --pid 11666：生成11666进程的堆dump文件

5）jhsdb jstack --locks --mixed -pid 11666：打印11666进程的栈、本地方法栈以及持有锁的额外信息

6）jhsdb jsnap --all -pid 11666：打印11666进程所有性能计数器的信息=jcmd的PerfCounter.print


```

#### JDK内置 - 可视化工具

##### jhsdb

jhsdb hsdb --pid 11666：进入11666进程的图形化界面，其菜单功能包括：

- Inspect Thread：这个线程的诊断信息，包含对象头和指向对象元数据的指针（Java类型的名字、继承关系、实现接⼝关系，字段信息、⽅法信息、运⾏时常量池的指针、内嵌的虚⽅法表（vtable）以及接⼝⽅法表（itable）等）。
- Stack Memory：这个线程栈的内存数据信息。
  - 第⼀列：内存地址（虚拟地址，⾮物理内存地址）。
  - 第⼆列：该地址上存储的数据，以字宽为单位。
  - 第三列是：对数据的注释，竖线表示范围，横线或斜线连接范围与注释⽂字。
- Show Java stack trace：这个线程的线程栈信息。
- Show Thread Information：这个线程的其他信息。
- Find Crashes：可找出这个线程崩溃的原因。
- Windows Console：可输⼊诊断命令，也就是jhsdb clhsdb命令交互页面。

![1626576342750](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576342750.png)

##### jconsole

- Java Monitoring and Management Console，是⼀款基于JMX（Java Manage-ment Extensions）的可视化监控、管理⼯具，主要是通过JMX的MBean（Managed Bean）对系统进⾏信息收集和参数动态调整。
  - JMX是⼀种开放性的技术，它既可以⽤在虚拟机本身的管理上，也可以⽤于运⾏在虚拟机之上的软件中。⽬前很多软件都⽀持基于JMX进⾏管理与监控。
- 执行jconsole命令打开界面，然后输入线程号即可。

![1626576867182](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626576867182.png)

##### VisualVM

- 也叫JVisualVM，是⼀个All-in-One Java Troubleshooting Tool，即多合一的故障排查工具，从JDK 6开始提供，是⽬前最强⼤的监控及故障处理程序之⼀。
- JDK 8输入jvisualvm启动即可，JDK 9输入独自安装，其界面菜单功能包括：
  - Overview：展示应⽤的概要信息，相当于可视化的jps、jinfo。
  - Monitor：展示一些监控信息，包括CPU、内存、类、线程等曲线图，Perform GC按钮通知JVM执⾏垃圾回收，Heap Dump按钮Dump堆，相当于jmap dump命令。
  - Threads：展示查看线程状态，以及Thread Dump按钮Dump线程，相当于jstack。
  - Sampler：抽样器，可⽤于实时性能分析，支持CPU抽样以及内存抽样。
  - Profiler：性能分析，提供了程序运⾏期⽅法级的处理器执⾏时间分析及内存分析。
    - 执⾏该性能分析，会对程序运⾏性能有⽐较⼤的影响，⼀般不建议在⽣产环境使⽤这项功能，建议使用JMC来代替。
    - 开启类共享（⼀种共享类，从⽽提升加载速度、节省内存的技术）可能会导致执⾏Profiler的应⽤崩
      溃，建议在执⾏Profiler的应⽤上添加-Xshare:off，关闭掉类共享。
  - 分析堆dump文件：File -> Load -> 选择hprof -> 打开 -> 分析。
  - 其他插件：VisualVM还支持安装插件来扩展功能，比如Visual CC来实时分析垃圾回收的情况。

![1626577315983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626577315983.png)

##### JDK Mission Control

- 也叫Java Mission Control，简称JMC，是一款监控、定义线上问题以及性能调优的神器。
  - 它是⼀款商业授权⼯具（例如在JDK 8中），需要商业授权才能在⽣产环境中使⽤，现已开源，在JDK 11（哪怕是OpenJDK）中，任何⼈都可以使⽤JFR + JMC（需遵循 UPL协议 ）。
- JMC的两大功能：
  - 作为JMX控制台，监控虚拟机MBean提供的数据。
  - 可持续收集数据的JFR，并可作为JFR的可视化分析⼯具。
    - JFR：Java Flight Recorder，是⼀种⽤于收集有关运⾏中的Java应⽤的诊断信息和性能数据的⼯具。它⼏乎没有性能开销，因此，即使在负载很⼤的⽣产环境中也可以使⽤。
    - 主要用于性能分析、性能分析、⽀持与调试的场景。
- MBean服务器菜单功能介绍：
  - 概览：各种概要信息。
  - MBean浏览器：展示应⽤被JMX管理的Bean。
  - 触发器：配置触发规则，当规则满⾜时，就触发某个操作（在操作⼀栏配置）。
  - 系统：查看系统相关信息。
  - 内存：查看内存相关信息。
  - 线程：查看线程相关信息。
  - 诊断命令：可视化使⽤诊断命令，相当于可视化的jcmd。
- 飞行记录性菜单功能介绍：
  - 如果应用JDK版本 < JDK11，则启动项目时需要添加-XX:+UnlockCommercialFeatures -XX:+FlightRecorder。
  - ⾃动分析结果：JMC⾃动给出的优化提议。
  - Java应⽤程序：展示应⽤的各种执⾏情况。
  - JVM内部：展示JVM层⾯的执⾏情况。
  - 环境：展示操作系统层⾯的执⾏情况。
  - 事件：展示录制期间发⽣的事件。
- JMC优点：
  - JFR在⽣产环境中对吞吐量的影响⼀般不会⾼于1%。
  - JFR监控过程是可动态的，⽆需重启。
  - JFR监控过程对应⽤完全透明，⽆需修改应⽤的代码，也⽆需安装额外的插件或代理。
  - JFR提供的数据质量⾮常⾼，对监控、排查的参考价值更⼤。
- JMC缺点：
  - JFR并不完全向后兼容。⽐如，在JDK 11⾥⾯⽣成的JFR⽂件，⽤早期的JMC（例如JMC 5.5）⽆法打开。
  - JMC 7.0.1⽆法分析堆dump⽂件（hprof格式），但 官⽅Wiki 宣称⽀持分析堆dump⽂件。

![1626578206459](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626578206459.png)

#### 第三方工具

##### Memory Analyzer Tool

- Memory Analyzer Tool，简称MAT，可以作为独⽴软件，也可作为Eclipse插件存在，是⼀个快
  速且功能丰富的Java堆内存分析器，可帮助您查找内存泄漏并减少内存消耗。

- MAT主要功能：

  - 找出内存泄漏的原因。
  - 找出重复引⽤的类和jar。
  - 分析集合的使⽤。
  - 分析类加载器。

- 相关概念：

  - **浅堆**：一个对象E自身所消耗的内存，根据堆转储格式，对象⼤⼩可能会被调整（例如，对⻬为8bit），从⽽更好地模拟VM的实际消耗量。⼀般来说，对象的浅堆是对象在堆中的⼤⼩，⽽同⼀对象的保留⼤⼩是在垃圾回收对象时将释放的堆内存量。
  - **X的保留集**：Retained set，当E被垃圾回收时，由GC删除的对象集E和G。同理，如果E没有被回收，那么该集合中的对象E和G都会“保留下来”。
  - **X的保留堆**：Retained heap，指的是对象E的保留集E和G的内存⼤⼩，即由于它的存活导致多⼤的内存没有被回收。
  - **前导对象集的保留集**：前导对象E不可达时，被释放的那些对象E和G，所以这里前导对象集E的保留集为E和G。

  ![1626581295844](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626581295844.png)

  - **支配树**：MAT提供了对象图的⽀配树，通过将对象参考图转换为⽀配树，可以轻松地识别最⼤的保留内存块以及对象之间的依赖关系。⽀配树是在对象图的基础上建⽴的，在⽀配树中，每个节点都是其⼦节点的直接⽀配者。因此，基于⽀配树可以轻松看出对象之间的依赖关系。其具有以下属性：
    - 对象从属于X的⼦树（例如对象被X⽀配）就是X的Retained set。
      - **X⽀配Y**：如果对象图中从起始（或Root）节点到Y的每条路径都必须经过X，那么就说对象X⽀配对象Y。
      - **直接⽀配者**：某个对象路径最短的⽀配者。
      - **间接支配者**：一个对象X支配了该对象Y，但又不是Y的直接支配者，则称X为Y的间接支配者。
    - 如果X是Y的直接⽀配节点，那么⽀配X的节点也可以⽀配Y。
    - ⽀配树中的边并不直接对应于对象图中的对象引⽤。

  ![1626582280791](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582280791.png)

- MAT菜单功能介绍：

  - inspector：透视图，⽤于展示⼀个对象的详细信息，例如内存地址、加载器名称、包名、对象名称、对象所属的类的⽗类、对象所属的类的加载器对象、该对象的堆内存⼤⼩和保留⼤⼩，gc root信息。下半部分展示类的静态属性和值、对象的实例属性和值、对象所属的类的继承结构。
  - Heap Dump History：列出最近分析过的⽂件。
  - 功能选择栏：从左到右依次是：概览、类直⽅图、⽀配树、OQL查询、线程视图、报告相关、详细功能。其中概览就是上图的这个⻚⾯，其他则提供了⼀些更细致的分析能⼒。总的来说，功能上和VisualVM⼤同⼩异，但分析得更加细致。
  - 饼图：展示retained size对象占⽤⽐例。
  - Actions：常⽤的内存分析动作。
    - Histogram：列出内存中的对象，对象的个数及其⼤⼩。点击后⽣成的报表：
      - Class Name ： 类名称，java类名。
      - Objects ： 类的对象的数量，这个对象被创建了多少个。
      - Shallow Heap ：⼀个对象内存的消耗⼤⼩，不包含对其他对象的引⽤。
      - Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和。
    - Dominator Tree：列出最⼤的那些对象，以及他们为什么存活。
    - Top Consumers：打印最昂贵的对象，以内和包分组。
    - Duplicate Classes：检测被多个classloader加载的类。
  - Reports：报表功能，包括：
    - Leak Suspects：⾃动分析内存泄漏的原因，并能直接定位到Class，找到可能导致内存泄露的代码⾏数。
    - Top Components：列出占⽤超过1%的组件的报告信息。
  - Step by Step：
    - Top Components：分析从属于指定包或者class loader的对象。

![1626582745483](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626582745483.png)

##### JITWatch

- JITWatch是JIT编译器的⽇志分析器与可视化⼯具，可⽤来检查内联决策、热点⽅法、字节码以及汇编的各种细节，经常和HSDIS配合使⽤，实际中用的也不是特别多。
  - HSDIS是⼀个HotSpot虚拟机即时编译代码的反汇编插件，它包含在HotSpot虚拟机的源码当中，在OpenJDK的⽹站也可以找到单独的源码下载，但并没有提供编译后的程序。
- 安装HSDIS后，启动应用，添加以下参数，用于收集反汇编日志，执行完后将会⽣成⼀个  /Users/itmuch.com/logfile.log ⽂件，⾥⾯包括了各种类编辑以及汇编信息。
  - UnlockDiagnosticVMOptions：开启诊断信息。
  - PrintAssembly：输出反汇编内容。
  - Xcomp：以编译模式启动，这样，⽆执⾏⾜够次数来预热即可触发即时编译。
  - LogCompilation：打印编译相关信息。
  - LogFile：指定⽇志⽂件。
  - TraceClassLoading：是否跟踪类的加载。

```java
java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp -XX:+LogCompilation -XX:LogFile=/Users/itmuch.com
/logfile.log -XX:+TraceClassLoading -jar xxx.jar


```

- 最后使用JITWatch可视化阅读⽇志，使用以下命令启动JITWatch，选择反汇编日志，点击start即可可视化地分析了。

```java
mvn clean compile exec:java


```

![1626583188575](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626583188575.png)

### 3.3. JVM参数选项？

笔记时间：2021-07-18。

#### 标准选项

- 用于**执行常见操作**（比如检查JRE版本、设置类路径、启动详细输出等），各种厂牌的虚拟机都会支持。
- **格式不统一**，以java -help的结果为准。
- **常见的标准选项有**：

| JVM参数                          | 作用                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| -class-path \| -classpath \|- cp | 指定JVM类搜索路径，多个路径之间以分号隔开。如果指定了-classpath，则JVM就忽略系统变量CLASSPATH中指定的路径。如果-classpath和CLASSPATH都没有指定，则JVM会从当前路径寻找class |
| -server                          | 以server模式启动JVM，与client模式恰好相反。适合生产环境，适用于服务器。64位的JVM自动以server模式启动 |
| -client                          | 以client模式启动JVM，这种方式启动速度快，但运行时性能和内存管理效率不高，适合客户端程序或者开发调试。64位的JVM不支持client模式 |
| -Dproperty=value                 | 设置系统属性值。其中， property是属性名称，value是属性值，如果value有空格，则需要使用双引号，比如-Dfoo=“foo bar” |
| -javaagent：jarpath[=options]    | 加载指定的Java编程语言代理                                   |
| -verbose：class                  | 显示类加载相关的信息，当报找不到类或者类冲突时，可用此参数来诊断 |
| -verbose：gc                     | 显示垃圾收集事件的相关信息                                   |
| -verbose：jni                    | 显示本机方法和其他Java本机接口（JNI）的相关信息              |
| -version                         | 展示JDK版本                                                  |

#### 附加选项

- JDK 11文档中称为**额外参数**，JDK 8文档中称为**非标准参数**，是**Hotspot虚拟机的通用选项**，其他厂牌的JVM不一定会支持，并且未来可能会发生变化。
- 附加选项都以**-X开头**，具体以java -x的结果为准。
- **常见的附加选项有**：

| JVM参数                  | 默认值                                                       | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| -Xcomp                   | 默认情况下，client模式下会解释执行10000次（< JDK 11），server模式下会解释执行10000次，并收集信息，此后才可能编译运行。 | 在第一次调用时强制编译方法。指定该选项将禁用解释方法调用。此外，还可使用-XX：CompileThreshold选项更改在编译之前解释执行方法的调用次数 |
| -Xint                    | -                                                            | 以解释模式运行                                               |
| -Xmixed                  | -                                                            | 热点方法以编译模式运行，其他方法以解释模式运行               |
| -Xloggc：option          | -                                                            | 将GC事件的相关信息记录到文件中                               |
| -Xnoclassgc              | -                                                            | 禁用类的垃圾收集。使用该参数可节省一些GC时间，缩短应用程序运行期间的停顿。但一旦使用该参数，那么应用程序中的类对象就会始终被视为活动对象，从而导致这块内存被永久占用。如果使用不当，将会导致内存溢出 |
| -Xshare：mode            | auto：尽可能使用CDS，是32位的Hotspot JVM的默认值；on：开启CDS。如果CDS无法被开启，将会打印错误信息；off：不适用CDS | 设置类数据共享模式（class data sharing，即CDS）。注意，此选项只应用于测试目的，并且可能由于操作系统使用地址空间布局随机化而导致间歇性故障，不应在生产环境中使用 |
| -XshowSettings：category | all：默认值，展示所有设置；locale：展示语言环境相关的设置；properties：展示系统属性相关的设置；vm：展示JVM的设置；system：展示Linux主机系统或者容器的配置 | 展示设置                                                     |
| -Xmn                     | -                                                            | 设置年轻代的初始值以及最大值，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节，例如-Xmn256m。此外，还可用-XX：NewSize设置年轻代初始大小，-XX：MaxNewSize设置年轻代最大大小 |
| -Xms                     | -                                                            | 设置堆内存的初始大小，以字节为单位。此值必须是1024的倍数且大于1MB。如果未设置此选项，则将堆内存初始大小设置为老年代和年轻代分配的大小之和。设置格式同-Xmn，例如-Xms6144K |
| -Xmx                     | -                                                            | 设置堆内存的最大大小，以字节为单位。此值必须是1024的倍数且大于2MB。等效于-XX：MaxHeapSize |
| -Xss                     | 默认值取决于平台，64位Linux：1024KB；64位 MacOS：1024KB；64位Oracle Solaris：1024KB；Windows：默认值取决于虚拟内存 | 设置线程栈大小，以字节为单位                                 |

#### 高级选项

- 高级选项是**为开发人员提供的选项**，用于调整Java **HotSpot虚拟机**操作的特定区域（这些区域通常具有特定的系统要求，并且可能需要对系统配置参数的特权访问），其他厂牌的JVM不一定会支持，并且未来可能会发生变化。
- 高级选项都以**-XX开头**，可以使用以下方法查看所支持的选项：

```java
1）解锁参数并打印：java -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsInitial

2）jhsdb clhsdb --pid 11666，进入交互页面后使用flags查看


```

- **使用格式**：
  - **boolean类型**：格式为-XX：（+/-），+表示将选项设置为true，-表示将选项设置为false。
  - **非boolean类型**：格式为-XX：选项=值。
- **常见的高级选项有**：

##### 常用高级运行时选项

用于控制HotSpot VM的运行时的各种行为。

| JVM参数                               | 默认值或者取值方式 | 作用                                                         |
| ------------------------------------- | ------------------ | ------------------------------------------------------------ |
| -XX：ActiveProcessorCount=n           | -                  | JVM使用多少个CPU核心，去计算用于执行垃圾收集或者ForkJoinPool线程池的大小 |
| -XX：InitiatingHeapOccupancyPercent=n | 45                 | 老年代大小到达该阈值，会触发G1 Mixed GC                      |
| -XX：LargePageSizeInBytes=n           | -                  | 设置用于Java堆的大页面尺寸，以字节为单位，其数值必须是2的幂次，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxDirectMemorySize=n            | -                  | 设置java.nio包的直接缓存区分配的最大总大小，以字节为单位，也可在size后追加字母k或者K表示千字节，m或者M表示兆字节，g或者G表示千兆字节 |
| -XX：MaxGCPauseMillis=n               | 200ms              | 期望的最大停顿时间                                           |
| -XX：OnError=string                   | -                  | 发生错误的时候做某事，string是一个或者多个命令，多个命令使用分号分隔，如果字符串包含空格，则必须将其用引号引起来。比如“gcore %p；dbx - %p”，表示当发生错误时，使用gcore命令创建核心dump文件 |
| -XX：OnOutOfMemoryError=string        | -                  | 当发生OOM异常时做模式，配置格式同-XX：OnError                |
| -XX：ParallelGCThreads=n              | -                  | 设置GC并行阶段的线程数                                       |
| -XX：+PrintCommandLineFlags           | 关闭               | 打印命令行标记                                               |
| -XX：ThreadStackSize=size             | -                  | 设置线程栈的大小，和-Xss等价                                 |
| -XX：-UseBiasedLocking                | -                  | 禁用偏向锁                                                   |
| -XX：-UseCompressedOops               | 启用               | 禁用压缩指针。此选项仅适用于64位JVM，当Java堆大小小于32GB时，将使用压缩指针。启用此选项后，对象引用将表示为32位偏移量，而非64位指针，这通常会在运行Java堆大小小于32GB的应用程序时提高性能。当Java堆大小大于32GB时，可使用-XX：ObjectAlignmentInBytes选项 |
| -XX：GCLogFileSize=n                  | 512KB              | 处理大型日志文件                                             |
| -XX：+UseLargePages                   | 关闭               | 启用大页面内存的使用                                         |
| -XX： VMOptionsFile=filename          | -                  | 允许用户在文件中指定VM选项。比如java -XX：VMOptionsFile=/var/my_vm_options_HelloWorld |
|                                       |                    |                                                              |
| 元空间参数                            |                    |                                                              |
| -XX：MetaspaceSize                    | 20.8MB             | 元空间的初始值，元空间占用达到该值就会触发垃圾回收，进行类的卸载，同时收集器会自动调整该值。如果能够释放空间，则会自动降低该值（减少空间浪费）；如果释放空间很少，则在不超过-XX：MaxMetaspaceSize的情况下，适当提高该值（保证有足够空间） |
| -XX：MaxMetaspaceSize                 | 受限于本地内存大小 | 元空间大小的最大值                                           |
| -XX：MinMetaspaceFreeRatio            | 40%                | 垃圾收集后，计算当前元空间的空闲百分比，如果小于该值，则增加元空间的大小（保证有足够空间） |
| -XX：MaxMetaspaceFreeRatio            | 70%                | 垃圾收集后，计算当前元空间的空闲百分比，如果大于该值，则减少元空间的大小（减少空间浪费） |
| -XX：MinMetaspaceExpansion            | 332.8KB            | 元空间增长时的最小幅度                                       |
| -XX：MaxMetaspaceExpansion            | 5.2MB              | 元空间增长时的最大幅度                                       |
|                                       |                    |                                                              |
| 直接内存参数                          |                    |                                                              |
| -XX：MaxDirectMemorySize              | -                  | 设置最大直接内存大小，对Unsafe不起作用，但对ByteBuffer有效   |
|                                       |                    |                                                              |
| TLAB参数（不建议修改）                |                    |                                                              |
| -XX：+UseTLAB                         | 开启               | 是否启用线程私有分配缓存区（Thread-Local Allocation Buffer） |
| -XX：MinTLABSize                      | 2048B              | 最小TLAB大小，单位字节                                       |
| -XX：+ResizeTLAB                      | 是                 | 是否动态调整TLAB的大小                                       |
| -XX：TLABRefillWasteFraction          | 64                 | 由于TLAB空间比较小，因此很容易装满。比如TLAB 100KB，已使用80KB，当需要再分配一个30KB的对象时，就无法分配到这个TLAB了。这时虚拟机会有两种选择，第一，废弃当前TLAB，这样就会浪费20KB的空间；第二，保留当前的TLAB并将这30KB的对象直接分配在堆上，这样将来有小于20KB的对象时，仍可以使用这块空间。实际上，JVM内部维护了一个叫做refill_waste的值，当请求对象大于refill_waste时，会在堆中分配；若小于该值，则会废弃当前TLAB，新建TLAB分配对象。可以用TLABRefillWasteFraction来调整该阈值，表示TLAB中允许产生这种浪费的比例，默认为64，即允许使用1/64的TLAB空间作为refill_waste。默认情况下，TLAB和refill_waste都会在运行时不断地调整，使系统的运行状态达到最优。如果想要禁用自动调整TLAB的大小，可以使用-XX：-ResizeTLAB禁用ResizeTLAB，并使用-XX：TLABSize手工指定一个TLAB的大小 |
| -XX：+TLABStats                       | 是                 | 是否提供详细的TLAB的统计信息                                 |
| -XX：TLABSize                         | 0                  | 设置TLAB的初始大小，如果设置为0，JVM会自动设置TLAB的初始大小 |
| -XX：TLABWasteTargetPercent           | 1                  | 允许TLAB占用Eden空间的百分比                                 |

##### 常用高级JIT编译器选项

用于控制HotSpot VM如果执行的JIT编译。

| JVM参数                                       | 默认值                                                   | 作用                                                         |
| --------------------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| -XX：+BackgroundCompilation                   | 开启                                                     | 启用JIT后台编译                                              |
| -XX：CompileCommand=command，method[，option] | -                                                        | 在指定方法上执行指定command。command可选项为：break：在调试JVM时设置一个断点，以便在指定方法编译开始时停止； compileonly：排除所有未指定的所有方法；dontinline：防止内联指定方法；exclude：排除指定的方法；help：打印-XX： CompileCommand选项的帮助信息；inline：尝试内联指定的方法；log：排除指定方法以外的所有方法的编译日志记录（用-XX：+Log Compilation打印编译日志），默认情况下将对所有编译方法执行日志记录；option：将JIT编译选项传递给指定的方法，以代替最后一个参数（option）。编译选项设置在方法名称之后，且可指定多个编译选项，以逗号或者空格分隔；print：在编译指定的方法后打印生成的汇编代码；quiet：不打印编译命令，默认情况下，将显示使用-XX：CompileCommand选项指定的命令 |
| -XX：+DoEscapeAnalysis                        | 开启                                                     | 启用逃逸分析                                                 |
| -XX：+Inline                                  | 开启                                                     | 启用方法内敛                                                 |
| -XX：InlineSmallCode=n                        | 1000B                                                    | 指定内联的以编译的方法的最大代码大小，以字节为单位           |
| -XX：+LogCompliation                          | 关闭                                                     | 将编译活动记录到当前工作目录的hotspot.log文件中，也可用+XX：LogFile选项来指定其他日志文件路径和名称。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：MaxInlineSize=n                          | -                                                        | 设置要内联的方法的最大字节码大小，以字节为单位               |
| -XX：+PrintAssembly                           | 关闭                                                     | 打印字节码和本地方法的汇编代码，需要HSDIS的支持。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
| -XX：+PrintCompaction                         | 关闭                                                     | 打印哪些方法被内联。该选项必须与-XX：+ UnlockDiagnosticVMOptions配合使用 |
|                                               |                                                          |                                                              |
| CodeCache参数                                 |                                                          |                                                              |
| -XX：ReservedCodeCacheSize=n                  | 不同版本不同，JDK 8 + 64位以及JDK 11 + 64位都是240MB     | 设置 JIT编译的代码的最大代码缓存大小，以字节为单位，最大不超过2GB，否则会产生错误。该配置不应小于-XX： InitialCodeCacheSize的值，以java -XX：PrintFlagsFianl \| grep ReservedCodeCacheSize的结果为准 |
| -XX：InitialCodeCacheSize=n                   | 不同的操作系统，以及不同的编译器的值也会不同，一般为48MB | 设置代码缓存区的初始大小，以java -XX：PrintFlagsFianl \| grep InitialCodeCacheSize的结果为准 |
| -XX：-PrintCodeCache                          | 关闭                                                     | 在JVM停止时打印代码缓存的使用情况                            |
| -XX：-PrintCodeCacheOnCompilation             | 关闭                                                     | 每当方法被编译后，就打印一下代码缓存区的使用情况             |
| -XX：+UseCodeCacheFlushing                    | 打开                                                     | 代码缓存区即将耗尽时，尝试回收一些早期编译但又很久没有被调用的方法 |
| -XX：-SegementedCodeCache                     | 关闭，表示使用整体的代码缓存区                           | 是否使用分段的代码缓存区                                     |

##### 常用高级可服务性选项

用于控制系统信息收集与调试支持。

| JVM参数                                  | 默认值                                | 作用                                                         |
| ---------------------------------------- | ------------------------------------- | ------------------------------------------------------------ |
| -XX：HeapDumpPath=path                   | -                                     | 指定堆Dump的文件路径，经常和-XX：+HeapDumpOnOutOf MemoryError选项配合使用 |
| -XX：LogFile=path                        | 在当前工作目录中创建，名为hotspot.log | 指定日志文件的路径，经常和-XX：+LogCompilation配合使用       |
| -XX：+Unlock ExperimentalVMOptions       | 关闭                                  | 用于解锁JVM实验性参数                                        |
| -XX：+UnlockDiagnosticVMOptions          | 关闭                                  | 用于解锁JVM诊断性参数                                        |
|                                          |                                       |                                                              |
| JDK 8日志参数                            |                                       |                                                              |
| -XX：+PrintFlagsInitial                  | 关闭                                  | 打印支持的高级选项，并展示默认值                             |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |
| -XX：+PrintGCCause                       | 打开                                  | 是否在GC日志中打印造成GC的原因                               |
| -XX：+PrintGCID                          | 关闭                                  | 打印垃圾GC的唯一标识                                         |
| -XX：+PrintGCDateStamps                  | 关闭                                  | 以日期的格式输出GC的时间戳，如2013-05-04T21：53：59.234+0800 |
| -XX：+PrintGCTimeStamps                  | 关闭                                  | 以基准时间的格式，打印GC时间戳                               |
| -XX：+PrintHeapAtGC                      | 关闭                                  | 在GC前后打印堆信息                                           |
| -XX：+PrintHeapAtGCExtended              | 关闭                                  | 在开启PrintHeapAtGC的前提下，额外打印更多堆的相关信息        |
| -XX：+PrintGCApplicationStoppedTime      | 关闭                                  | 打印垃圾回收期间程序暂定的时间                               |
| -XX：+PrintGCApplicationConcurrentTime   | 关闭                                  | 打印每次垃圾回收前，程序未中断的执行时间，可与PrintGCApplicationStoppedTime配合使用 |
| -XX：+PrintClassHistogramAfterFullGC     | 关闭                                  | Full GC之后打印堆的直方图                                    |
| -XX：+PrintClassHistogramBeforeFullGC    | 关闭                                  | Full GC之前打印堆的直方图                                    |
| -XX：+PrintReferenceGC                   | 关闭                                  | 打印处理引用对象的时间消耗，需开启PrintGCDetails才有效       |
| -XX：+PrintTLAB                          | 关闭                                  | 查看TLAB空间的使用情况                                       |
| -XX：-UseGCLogFileRotation               | 关闭                                  | 轮换文件，日志文件达到一定大小后，就创建一个新的日志文件。需指定-Xloggc：时才有效 |
| -XX：GCLogFileSize                       | 8KB                                   | 设置单个日志文件的大小，需开启UseGCLogFileRotation才有效     |
| -XX：NumberOfGCLogFiles                  | 0，表示保留所有日志                   | 日志轮换时，保留几个日志文件                                 |
| -Xloggc：path                            | -                                     | 指定GC日志文件路径                                           |
| -XX：+PrintAdaptiveSizePolicy            | 关闭                                  | 某些GC收集器有自适应策略，自适应调整策略会动态调整Eden、Survivor、老年代的大小。使用该标记，可打印自适应调节策略的相关信息 |
| -XX：+PrintTenuringDistribution          | 关闭                                  | 查看每次Minor GC后新的存活周期的阈值                         |
| -XX：G1PrintRegionLivenessInfo           | -                                     | 标记阶段结束后打印所有Region的存活情况，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+G1PrintHeapRegions                 | -                                     | 打印堆的区域上的分配和释放的信息，需开启-XX：+UnlockDiagnosticVMOptions后才能使用 |
| -XX：+PrintStringDeduplicationStatistics | -                                     | JDK 8u20开始，使用G1垃圾收集器，可支持-XX：+UseStringDeduplication开启字符串去重。可用-XX：+PrintStringDeduplicationStatistics打印字符串去重的统计信息 |
|                                          |                                       |                                                              |
| JDK 11统一日志管理（只剩下两个）         |                                       |                                                              |
| -XX：+PrintGC                            | 关闭                                  | 输出GC日志                                                   |
| -XX：+PrintGCDetails                     | 关闭                                  | 打印GC详情                                                   |

##### 常用高级垃圾收集选项

用于控制HotSpot VM如何执行垃圾收集

| 收集器                | 参数以及默认值                             | 备注                                                         |
| --------------------- | ------------------------------------------ | ------------------------------------------------------------ |
| Serial                | -XX：+UseSerialGC                          | 虚拟机在Client模式下的默认值，开启后，使用Serial + Serial Old的组合 |
| ParNew                | -XX：+UseParNewGC                          | 开启后，使用ParNew + Serial Old的组合                        |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
| Parallel Scavenge     | -XX：+UseParallelGC                        | 虚拟机在Server模式下的默认值，开启后，使用Parallel Scavenge + Serial Old的组合 |
|                       | -XX：MaxGCPauseMillis=n                    | 收集器尽可能保证单次内存回收停顿的时间不超过这个值，但是并不保证不超过该值，只是尽可能 |
|                       | -XX：GCTimeRatio=n                         | 设置吞吐量的大小，取值范围为0~100，假设GCTimeRatio的值为n，那么系统将花费不超过1 / （1 + n）的时间用于垃圾收集 |
|                       | -XX：+UseAdaptiveSizePolicy                | 开启后，无需人工指定新生代的大小（-Xmn）、Eden和Survivor的比例（-XX：SurvivorRatio）以及晋升老年代对象的年龄（-XX：PretenureSizeThreshold）等参数，收集器会根据当前系统的运行情况自动调整 |
| Serial Old            | 无                                         | Serial Old是Serial的老年代版本，主要用于Client模式下的老年代收集，同时也是CMS在发生Concurrent Mode Failure时的后备方案 |
| Parallel Old          | -XX：+UseParallelOldGC                     | 开启后，使用Parallel Scavenge + Parallel Old的组合。Parallel Old是Parallel Scavenge的老年代版本，在注重吞吐量和CPU资源敏感的场合，可以优先考虑这个组合 |
| CMS                   | -XX：+UseConcMarkSweepGC                   | 开启后，使用ParNew + CMS的组合，Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后备收集器使用 |
|                       | -XX：CMSInitiatingOccupancyFraction=68     | CMS收集器在老年代空间被使用多少后触发垃圾收集，默认68%       |
|                       | -XX：+UseCMSCompactAtFullCollection        | 在完成垃圾收集后是否要进行一次内存碎片整理，默认开启         |
|                       | -XX：CMSFullGCsBeforeCompaction=0          | 在进行若干次Full GC后就进行一次内存碎片整理，默认为0         |
|                       | -XX：+UseCMSInitiatingOccupancyOnly        | 允许使用占用值作为启动CMS收集器的唯一标准，一般和CMSFullGCsBeforeCompaction配合使用。如果开启，那么当CMSFullGCsBeforeCompaction达到阈值就开始GC，如果关闭，那么JVM仅在第一次使用CMSFullGCsBeforeCompaction的值，后续则自动调整，默认关闭 |
|                       | -XX：+CMSParallelRemarkEnabled             | 重新标记阶段会并行执行，使用此参数可降低标记停顿，默认打开（仅适用于CMS + ParNew的GC） |
|                       | -XX：+CMSScavengeBeforeRemark              | 开启或关闭在CMS重新标记阶段之前的清除Young GC的尝试。新生代里一部分对象会作为GC Roots，让CMS在重新标记之前，做一次Young GC，而YGC能够回收掉新生代里大多数对象，这样就可以减少GC Roots的开销。因此，打开此开关，可在一定程度上降低CMS重新标记阶段的扫描时间，当然，开启此开关后，Young GC也会消耗一些时间。PS：开启此开关并不保证在标记阶段前一定会进行清除操作，生产环境建议开启，默认关闭 |
| CMS-Precleaning       | -XX：+CMSPrecleaningEnabled                | 是否启用并发预清理，默认开启                                 |
| CMS-AbortablePreclean | -XX：CMSScheduleRemarkEdenSizeThreshold=2M | 如果Eden区的内存使用超过该值，才可能进入并发可中止的预清理阶段 |
| CMS-AbortablePreclean | -XX：+CMSMaxAbortablePrecleanTime=5000     | 并发可终止的预清理阶段持续的最大时间                         |
| CMS                   | -XX：+CMSClassUnloadingEnabled             | 使用CMS时，是否启用类卸载，默认开启                          |
|                       | -XX：+ExplicitGCInvokesConcurrent          | 显示调用System.gc（）会触发Full GC，会有Stop The World，开启此参数后，可让System.gc（）触发的垃圾回收变成一次普通的CMS GC |
| G1                    | -XX：+UseG1GC                              | 使用G1收集器                                                 |
|                       | -XX：G1HeapRegionSize=n                    | 设置每个 Region的大小，该值必须为2的幂次，范围为1M到32M，如果不指定G1会根据堆的大小自动决定 |
|                       | -XX：MaxGCPauseMillis=200                  | 设置最大停顿时间，默认值为200毫秒                            |
|                       | -XX：G1NewSizePercent=5                    | 设置年轻代占整个堆的最小百分比，默认值为5，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1MaxNewSizePercent=60                | 设置年轻代占整个堆的最大百分比，默认值为60，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：ParallelGCThreads=n                   | 设置垃圾收集器在并行阶段使用的垃圾收集线程数，当逻辑处理器小于8时，n的值与逻辑处理器数量相同；如果逻辑处理器数量大于8时，则n的值大约为逻辑处理器数量的5/8，大多数情况下是这样，除了较大的SPARC系统，其中n的值约为逻辑处理器的5/16 |
|                       | -XX：ConcGCThreads=n                       | 设置垃圾收集器并发阶段使用的线程数量，设置n大约为ParallelGCThreads的1/4 |
|                       | -XX：InitiatingHeapOccupancyPercent=45     | 老年代大小达到该阈值，则会触发Mixed GC，默认值为45           |
|                       | -XX：G1MixedGCLiveThresholdPercent=85      | Region中的对象，活跃度低于该阈值，才可能被包含在Mixed GC收集周期中，默认值为85，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1HeapWastePercent=5                  | 设置浪费的堆内存百分比，当可回收百分比小于浪费百分比时，JVM就不会启动Mixed GC，从而避免昂贵的GC开销。此参数相当于用来设置允许垃圾对象占用内存的最大百分比。 |
|                       | -XX：G1MixedGCCountTarget=8                | 设置在标记周期完成之后，最多执行多少个Mixed GC，默认值为8，启动多个Mixed GC可以缩短老年代的收集时间 |
|                       | -XX：G1OldCSetRegionThresholdPercent=10    | 设置在一次Mixed GC中被收集的老年代的比例上限，默认值为Java堆的10%，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
|                       | -XX：G1ReservePercent=10                   | 设置预留空闲内存百分比，虚拟机会保证Java堆有这么多空间可用，从而防止对象晋升时无空间可用而失败，默认值为Java堆的10% |
|                       | -XX：G1PrintHeapRegions                    | 输出Region被分配和回收的信息，默认为false                    |
|                       | -XX：G1PrintRegionLivenessInfo             | 在清理阶段的并发标记环节，输出堆中的所有Regions的活跃度信息，默认为fasle |
| Shenandoah            | -XX：+UseShenandoahGC                      | 使用Shenandoah收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| ZGC                   | -XX：+UseZGC                               | 使用ZGC收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |
| Epsilon               | -XX：+UseEpsilonGC                         | 使用Epsilon收集器，这是个实验参数，需要-XX：+UnlockExperimentalVMOptions解锁实验参数后，才能使用该参数 |

### 3.4. JVM线上故障排查？

#### 如何打印JVM日志？

- JDK 8垃圾收集日志打印参数：

打印GC明细、日期、系统相对时间戳、GC的原因、GC日志存储的位置。

```java
-Xms50m -Xmx50m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -Xloggc:/Users/itmuch.com/gclog.log
```

- JDK 11垃圾收集日志打印参数：

打印GC详情、GC日志存储的位置，使用-Xlog进行统一日志管理。

```java
-Xms50m -Xmx50m -Xlog:gc*=trace:file=/Users/itmuch.com/xloggc.log
```

- JDK 8运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志。

```java
-XX:+TraceClassLoading -XX:+TraceBiasedLocking
```

- JDK 11运行时日志打印参数：

跟踪类加载的情况，以及偏向锁相关的日志，使用-Xlog进行统一日志管理。

```java
-Xlog:class+load=debug,biasedlocking=debug:file=/Users/itmuch.com/trace.log

```

#### 如果分析GC日志？

- **自动分析GC日志工具**：

  - **GCEasy（在线）**：<https://www.gceasy.io/>。

  ![1626740104774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740104774.png)

  - **GC Viewer（老牌）**：<https://github.com/chewiebug/GCViewer>。

  ![1626740032908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626740032908.png)

  - **GCPlot（很久没维护了）**：<https://github.com/GCPlot/gcplot>。

- **手工分析，格式如下**：

##### Serial GC日志

除CMS、G1 GC日志与Serial GC（Serial + Serial Old）日志不太一样外，其他的格式都是类似的。

###### JDK 8 Serial GC日志

```java
# Serial GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseSerialGC -Xmx50m -Xloggc:./gc_analysis.log

# JDK相关信息
Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)

# 内存相关信息
Memory: 4k page, physical 8266332k(2973848k free), swap 16532664k(9866032k free)

# 展示当前应用使用的JVM参数
CommandLine flags:
    -XX:-BytecodeVerificationLocal
    -XX:-BytecodeVerificationRemote
    -XX:InitialHeapSize=52428800
    -XX:+ManagementServer
    -XX:MaxHeapSize=52428800
    -XX:+PrintGC
    -XX:+PrintGCDateStamps
    -XX:+PrintGCDetails
    -XX:+PrintGCTimeStamps
    -XX:TieredStopAtLevel=1
    -XX:+UseCompressedClassPointers
    -XX:+UseCompressedOops
    -XX:-UseLargePagesIndividualAllocation
    -XX:+UseSerialGC

# 年轻代GC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:08.848+0800:
# 相对时间戳(PrintGCTimeStamps):
    3.708:
# 造成GC的原因(PrintGCCause):...:
    [GC (Allocation Failure) 2021-04-15T20:36:08.849+0800: 3.709:
# 展示DefaultNew的回收前后的内存以及年轻代总内存大小(Serial DefNew)
    [DefNew: 13696K->1663K(15360K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0099516 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13696K->2410K(49536K),
# GC (Allocation Failure) 到目前总共花费的时间
    0.0111863 secs]
# 用户、系统、实际耗时
    [Times: user=0.00 sys=0.00, real=0.01 secs]

# FullGC日志: 当前时间戳(PrintGCDateStamps):
    2021-04-15T20:36:20.608+0800:
# 相对时间戳(PrintGCTimeStamps):
    15.466:
# 造成GC的原因(PrintGCCause):...:
    [Full GC (Metadata GC Threshold) 2021-04-15T20:36:20.608+0800: 15.466:
# 老年代回收之前和回收之后的内存大小以及老年代总内存大小
    [Tenured: 5749K->6890K(34176K),
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0256217 secs]
# 展示回收前后整个堆内存以及堆内存总大小
    13665K->6890K(49536K),
# 元空间回收之前和回收之后的内存大小以及元空间总内存大小
    [Metaspace: 20533K->20533K(1067008K)],
# Full GC (Metadata GC Threshold) 到目前总共花费的时间
    0.0257088 secs]
# 用户、系统、实际耗时
    [Times: user=0.01 sys=0.00, real=0.02 secs]

```

###### JDK 11 Serial GC日志

```java
# JDK11 Serial GC收集器日志分析:

[0.104s][info][gc] Using Serial
# 内存概览: 堆内存地址、堆内存总大小、、压缩指针模式
[0.105s][info][gc,heap,coops] Heap address: 0x00000000fe200000, size: 30 MB, Compressed Oops mode: 32-bit
# 年轻代GC, 第1次回收为GC(0)
[1.846s][info][gc,start     ] GC(0) Pause Young (Allocation Failure)
# 年轻代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) DefNew: 8192K->1024K(9216K)
# 老年代回收前后的内存以及总内存大小
[1.862s][info][gc,heap      ] GC(0) Tenured: 0K->4482K(20480K)
# 元空间回收前后的内存以及总内存大小
[1.862s][info][gc,metaspace ] GC(0) Metaspace: 6131K->6131K(1056768K)
# 整个堆回收前后的内存以及总内存大小
[1.862s][info][gc           ] GC(0) Pause Young (Allocation Failure) 8M->5M(29M) 16.267ms
# 用户、系统、实际耗时
[1.862s][info][gc,cpu       ] GC(0) User=0.00s Sys=0.00s Real=0.02s
[4.813s][info][gc,start     ] GC(1) Pause Young (Allocation Failure)
[4.824s][info][gc,heap      ] GC(1) DefNew: 9216K->1024K(9216K)
[4.824s][info][gc,heap      ] GC(1) Tenured: 4482K->6236K(20480K)
[4.824s][info][gc,metaspace ] GC(1) Metaspace: 11473K->11473K(1060864K)
[4.824s][info][gc           ] GC(1) Pause Young (Allocation Failure) 13M->7M(29M) 11.722ms

```

##### CMS GC日志

使用ParNew + CMS的组合，Serial Old作为后备。

```java
# CMS GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseConcMarkSweepGC -Xmx50m -Xloggc:./GC_CMS.log
# 结论: => 日志格式大体上与GC_Serial.log一致, 但增加了一些CMS的步骤描述

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3336640k free), swap 16532664k(9654484k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:MaxNewSize=17477632 -XX:MaxTenuringThreshold=6 -XX:OldPLABSize=16 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC 
2021-04-15T21:04:10.842+0800: 2.650: [GC (Allocation Failure) 2021-04-15T21:04:10.842+0800: 2.650: [ParNew: 13696K->1664K(15360K), 0.0128738 secs] 13696K->2445K(49536K), 0.0131776 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]

# 1、初始标记
2021-04-15T21:04:22.827+0800: 14.635: [GC (CMS Initial Mark) [1 CMS-initial-mark: 7035K(34176K)] 8820K(49536K), 0.0007531 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:22.827+0800: 14.636: [CMS-concurrent-mark-start]
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-mark: 0.019/0.019 secs] [Times: user=0.06 sys=0.03, real=0.02 secs]
# 3、并发预清理 -> (4、并发可中止清理)
2021-04-15T21:04:22.847+0800: 14.655: [CMS-concurrent-preclean-start]
2021-04-15T21:04:22.848+0800: 14.656: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 5、重新标记
2021-04-15T21:04:22.848+0800: 14.656: [GC (CMS Final Remark) [YG occupancy: 2776 K (15360 K)]2021-04-15T21:04:22.848+0800: 14.656: [Rescan (parallel) , 0.0009519 secs]2021-04-15T21:04:22.849+0800: 14.657: [weak refs processing, 0.0000363 secs]2021-04-15T21:04:22.849+0800: 14.657: [class unloading, 0.0032038 secs]2021-04-15T21:04:22.853+0800: 14.660: [scrub symbol table, 0.0038571 secs]2021-04-15T21:04:22.856+0800: 14.664: [scrub string table, 0.0003238 secs][1 CMS-remark: 7035K(34176K)] 9811K(49536K), 0.0087240 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]
# 6、并发清除
2021-04-15T21:04:22.857+0800: 14.665: [CMS-concurrent-sweep-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-sweep: 0.003/0.003 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 7、并发重置
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset-start]
2021-04-15T21:04:22.860+0800: 14.668: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]

# 1、初始标记
2021-04-15T21:04:27.076+0800: 18.884: [GC (CMS Initial Mark) [1 CMS-initial-mark: 21029K(34176K)] 22587K(49536K), 0.0011465 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 2、并发标记
2021-04-15T21:04:27.077+0800: 18.885: [CMS-concurrent-mark-start]
2021-04-15T21:04:27.113+0800: 18.921: [CMS-concurrent-mark: 0.036/0.036 secs] [Times: user=0.08 sys=0.01, real=0.04 secs]
# 3、并发预清理
2021-04-15T21:04:27.114+0800: 18.922: [CMS-concurrent-preclean-start]
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-preclean: 0.001/0.001 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、并发可中止清理
2021-04-15T21:04:27.115+0800: 18.923: [CMS-concurrent-abortable-preclean-start]
2021-04-15T21:04:27.282+0800: 19.090: [GC (Allocation Failure) 2021-04-15T21:04:27.282+0800: 19.090: [ParNew: 14979K->1443K(15360K), 0.0043541 secs] 36009K->22692K(49536K), 0.0044774 secs] [Times: user=0.06 sys=0.00, real=0.00 secs] 
2021-04-15T21:04:27.418+0800: 19.226: [CMS-concurrent-abortable-preclean: 0.050/0.303 secs] [Times: user=0.47 sys=0.00, real=0.30 secs]
# 5、重新标记
2021-04-15T21:04:27.418+0800: 19.226: [GC (CMS Final Remark) [YG occupancy: 8840 K (15360 K)]2021-04-15T21:04:27.418+0800: 19.226: [Rescan (parallel) , 0.0028890 secs]2021-04-15T21:04:27.421+0800: 19.229: [weak refs processing, 0.0000623 secs]2021-04-15T21:04:27.421+0800: 19.229: [class unloading, 0.0035473 secs]2021-04-15T21:04:27.425+0800: 19.233: [scrub symbol table, 0.0088034 secs]2021-04-15T21:04:27.434+0800: 19.242: [scrub string table, 0.0005316 secs][1 CMS-remark: 21248K(34176K)] 30088K(49536K), 0.0162688 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]
# 6、并发清除
2021-04-15T21:04:27.435+0800: 19.243: [CMS-concurrent-sweep-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-sweep: 0.012/0.012 secs] [Times: user=0.03 sys=0.00, real=0.01 secs]
# 7、并发重置
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset-start]
2021-04-15T21:04:27.447+0800: 19.255: [CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]


```

##### G1 GC日志

与Serial GC、CMS GC格式差异非常大。

```java
# G1 GC收集器日志分析: -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+UseG1GC -Xmx50m -Xloggc:./GC_G1.log

Java HotSpot(TM) 64-Bit Server VM (25.91-b14) for windows-amd64 JRE (1.8.0_91-b14), built on Apr  1 2016 00:58:32 by "java_re" with MS VC++ 10.0 (VS2010)
Memory: 4k page, physical 8266332k(3458332k free), swap 16532664k(9495268k free)
CommandLine flags: -XX:-BytecodeVerificationLocal -XX:-BytecodeVerificationRemote -XX:InitialHeapSize=52428800 -XX:+ManagementServer -XX:MaxHeapSize=52428800 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TieredStopAtLevel=1 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:-UseLargePagesIndividualAllocation

# 年轻代G1 GC: 下面的缩进表示日志的子任务
2021-04-15T21:12:09.426+0800: 2.494: [GC pause (G1 Evacuation Pause) (young), 0.0052693 secs]
   # 并发任务解释
   [Parallel Time: 4.1 ms, GC Workers: 4]
      # GC统计
      [GC Worker Start (ms): Min: 2493.6, Avg: 2493.6, Max: 2493.6, Diff: 0.0]
      # GC扫描对象统计
      [Ext Root Scanning (ms): Min: 0.0, Avg: 0.7, Max: 1.1, Diff: 1.1, Sum: 2.7]
      # Update Remembered Sets(指保存到堆中的区域跟踪引用 -> 保存到Update Buffers更新缓存中)
      [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Update Buffers数量统计
         [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0]
      # Remembered Sets扫描统计
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      # Code Root扫描统计
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.2, Diff: 0.2, Sum: 0.3]
      # 拷贝存活对象统计
      [Object Copy (ms): Min: 0.0, Avg: 2.2, Max: 3.1, Diff: 3.1, Sum: 8.6]
      # 中断统计
      [Termination (ms): Min: 0.0, Avg: 0.2, Max: 0.2, Diff: 0.2, Sum: 0.6]
         # 尝试中断统计
         [Termination Attempts: Min: 1, Avg: 1.3, Max: 2, Diff: 1, Sum: 5]
      # GC线程其他工作统计
      [GC Worker Other (ms): Min: 0.0, Avg: 1.0, Max: 4.0, Diff: 3.9, Sum: 4.1]
      # GC线程总工作统计
      [GC Worker Total (ms): Min: 4.0, Avg: 4.1, Max: 4.1, Diff: 0.1, Sum: 16.3]
      # GC线程结束时间
      [GC Worker End (ms): Min: 2497.6, Avg: 2497.7, Max: 2497.7, Diff: 0.1]
   # 串行任务, 修复Code Root耗时统计
   [Code Root Fixup: 0.1 ms]
   # 串行任务, 清除Code Root耗时统计
   [Code Root Purge: 0.0 ms]
   # 清除Card Table中的Dirty Card耗时统计
   [Clear CT: 0.0 ms]
   # 其他任务
   [Other: 1.0 ms]
      # Collection Set选择区域耗时统计
      [Choose CSet: 0.0 ms]
      # 对象引用处理耗时统计
      [Ref Proc: 0.8 ms]
      # 引用队列ReferenceQueue耗时统计
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.0 ms]
      # 处理超大对象耗时统计
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      # 释放Collection Set耗时统计
      [Free CSet: 0.0 ms]
      # 各区域内存变化统计
   [Eden: 14.0M(14.0M)->0.0B(18.0M) Survivors: 0.0B->2048.0K Heap: 14.0M(50.0M)->2555.5K(50.0M)]
 # 用户、系统、实际耗时
 [Times: user=0.00 sys=0.00, real=0.01 secs]

# 最重要, 体现了G1 GC的过程
# 并发回收日志: 1、初始标记(stop the world)
2021-04-15T21:12:11.327+0800: 4.394: [GC pause (Metadata GC Threshold) (young) (initial-mark), 0.0047654 secs]
   [Parallel Time: 4.3 ms, GC Workers: 4]
      [GC Worker Start (ms): Min: 4394.3, Avg: 4394.3, Max: 4394.3, Diff: 0.0]
      [Ext Root Scanning (ms): Min: 0.9, Avg: 1.0, Max: 1.1, Diff: 0.2, Sum: 4.1]
      [Update RS (ms): Min: 0.6, Avg: 0.7, Max: 0.8, Diff: 0.2, Sum: 2.7]
         [Processed Buffers: Min: 2, Avg: 3.8, Max: 7, Diff: 5, Sum: 15]
      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]
      [Object Copy (ms): Min: 2.4, Avg: 2.5, Max: 2.5, Diff: 0.1, Sum: 9.9]
      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
         [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4]
      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]
      [GC Worker Total (ms): Min: 4.2, Avg: 4.2, Max: 4.2, Diff: 0.0, Sum: 16.8]
      [GC Worker End (ms): Min: 4398.5, Avg: 4398.5, Max: 4398.5, Diff: 0.0]
   [Code Root Fixup: 0.0 ms]
   [Code Root Purge: 0.0 ms]
   [Clear CT: 0.1 ms]
   [Other: 0.4 ms]
      [Choose CSet: 0.0 ms]
      [Ref Proc: 0.2 ms]
      [Ref Enq: 0.0 ms]
      [Redirty Cards: 0.1 ms]
      [Humongous Register: 0.0 ms]
      [Humongous Reclaim: 0.0 ms]
      [Free CSet: 0.0 ms]
   [Eden: 5120.0K(26.0M)->0.0B(26.0M) Survivors: 4096.0K->4096.0K Heap: 14.9M(50.0M)->11.3M(50.0M)]
 [Times: user=0.06 sys=0.00, real=0.01 secs]
# 开始扫描初始标记阶段Survivor区的Root Region
2021-04-15T21:12:11.332+0800: 4.399: [GC concurrent-root-region-scan-start]
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-root-region-scan-end, 0.0055232 secs]
# 2、并发标记
2021-04-15T21:12:11.338+0800: 4.405: [GC concurrent-mark-start]
2021-04-15T21:12:11.352+0800: 4.419: [GC concurrent-mark-end, 0.0143048 secs]
# 3、最终标记(stop the world)
2021-04-15T21:12:11.355+0800: 4.422: [GC remark 2021-04-15T21:12:11.355+0800: 4.422: [Finalize Marking, 0.0001519 secs] 2021-04-15T21:12:11.355+0800: 4.422: [GC ref-proc, 0.0006391 secs] 2021-04-15T21:12:11.356+0800: 4.423: [Unloading, 0.0037653 secs], 0.0048311 secs]
 [Times: user=0.00 sys=0.00, real=0.00 secs]
# 4、筛选回收(stop the world)
2021-04-15T21:12:11.360+0800: 4.427: [GC cleanup 12M->12M(50M), 0.0005645 secs]
 [Times: user=0.00 sys=0.02, real=0.00 secs] 
```

#### 如何定位CPU过高的地方？

- **定位问题代码的方法**：
  - 可以使用JMC MBean服务器实时查看：但需要应用开启JMX连接。
  - **也可以使用top + jstack配合查看**：

1. top查看当前CPU占用率最高的进程，拿到占用率最高的进程号36032：

   ```java
   top
   ```

2. top -Hp查看该进程线程的运行信息，拿到占用率最高的线程号36044：

   ```java
   top -Hp 36032
   ```

3. printf得到该线程号36044的16进制数8ccc，用于搜索dump文件：

   ```java
   printf %x 36044
   ```

4. jstack dump出进程36032所有的线程栈，得到文件1.txt：

   ```java
   jstack -l 36032 > 1.txt
   ```

5. cat搜索线程栈文件1.txt，找到16进制为8ccc（即线程号为36044），并往后再搜索30行的内容：

   ```java
   cat 1.txt | grep -A 30 8ccc
   ```

6. 定位该线程中的出问题代码，并分析原因：原来是有个for循环，导致CPU过高。

```java
@Override
public void run() {
    while (true) {
        double a = Math.random() * Math.random();
        System.out.println(a);
    }
}
```

- **CPU过高的场景与解决方案**？
  - **无限while循环**：
    - 尽量避免无限循环。
    - 也可以让循环执行得慢点，比如sleep（）或者yeild（）。
  - **频繁GC**：
    - 尽量降低GC频率。
  - **频繁创建新的对象**：
    - 合理使用单例，避免频繁创建对象。
  - **频繁的线程上下文切换**：
    - 降低切换的频率，不过需要结合业务进行业务改造，而改造的难度取决于业务的复杂度。
  - 序列化和反序列化：
    - 原因：大多都是由于使用了不合理的类库导致的，比如XStream反序列化大对象，改用ObjectInputStream来解决问题。
    - 解决方案：使用合理的API来实现，选择好用的序列化与反序列化的类库。
  - 正则表达式：
    - 原因：由于正则表达式使用NFA自动机的引擎，在进行字符串匹配时会发生回溯，一旦发生回溯可能会导致CPU过高的问题。
    - 解决方案：改写正则表达式，降低回溯的发生。

#### 如何解决内存溢出问题？

##### 堆内存溢出

- **相关概念**：**堆**：Java Heap，线程共享，在JVM启动时创建，是Java虚拟机中内存最大的一块，**专门用来保存对象，几乎所有对象以及数组的内存都在堆上分配**。
- **定位问题代码的方法**：

1. 指定OOM溢出后转储堆Dump：

   真实环境下，堆内存溢出很可能会导致进程直接挂掉，根本不会打印堆栈日志，所以需要JVM发生异常时自动转储出堆Dump文件，以便出现问题后能够进行分析。

   ```java
   --XX:+HeapDumpOnOutOfMemoryError
   
   
   ```

2. 在项目根目录，找到堆Dump文件，使用MAT打开堆Dump文件：

   ![1626605721295](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605721295.png)

3. 点击Leak Suspects，分析内存泄露：

   ![1626605971298](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626605971298.png)

4. 查看问题对象Object[]的details，分析with incoming references，即问题对象被引用的情况：

   此外，如果Leak Suspects有堆栈信息，也可以从堆栈信息中分析问题所在。

   ![1626606234660](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1626606234660.png)

5. 原来是因为无限循环插入了一堆随机String对象：

   ```java
   public class HeapOOMTest {
       private List<String> oomList = new ArrayList<>();
   
       public static void main(String[] args) {
           HeapOOMTest oomTest = new HeapOOMTest();
           while (true) {
               oomTest.oomList.add(UUID.randomUUID().toString());
           }
       }
   }
   
   ```

- **堆内存溢出的场景**？
  - **内存泄露**：
    - 可以借助MAT或者VisualVM，去查看泄露对象到对象的引用链，分析这个泄露的对象是通过哪个路径跟哪个对象关联，从而导致没有被回收掉。最后找到内存泄露对象的创建位置，优化相关的代码。
  - **存在生命周期或者数据结构不合理的对象**：
    - 更换不合理对象的生命周期或者数据结构。
  - **机器的堆内存大小设置得过小**：
    - 根据实际情况适当增大-Xms、-Xmn的值。

##### 栈内存溢出

- **相关概念**：在Hotspot虚拟机中，**栈内存是不允许扩展的**，且不区分虚拟机栈和本地方法栈，统一使用-Xss设置栈的大小，但同样会抛StackOverflowError异常，以及OutOfMemoryError异常。在有些VM中是有区分开的，比如使用-Xss设置虚拟机栈大小，-Xoss设置本地方法栈大小。
- **定位的方法**：栈溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
- **栈内存溢出的场景**？
  - **递归调用深度过大**：
    - 原因：每递归调用一次，就会创建一个栈帧压入栈中，在栈容量有限的情况下，当容纳不了足够多的栈帧时，则会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **方法内创建过多的局部变量**：
    - 原因：局部变量存放在局部变量表中，当栈中容纳不了这么多变量时也会抛出StackOverflowError异常。
    - 解决方法：优化问题代码。
  - **创建了过多的线程**：
    - 原因：栈是线程独享的，每个线程会创建自己的栈，当创建新线程的时候没有足够的内存去创建对应的栈，则会抛出**OutOfMemoryError**异常。
    - 解决方法：优化问题代码。
- **如何保证创建足够多的线程**？
  - **减少-Xss配置**：由于栈是线程独享的，每个线程会创建自己的栈，对于相同的内存总量，减少每个栈的大小，就可以创建更多的栈，在OOM之前就可以创建更多的线程了。
  - **增大栈能分配的内存**：尽量减少除了栈以外的内存占用，增大栈内存占用。其中公式为：
    - 栈内存 = 机器总内存 - 操作系统内存 - 堆内存 - 方法区内存 - 程序计数器内存 - 直接内存。 
  - **尽量杀死其他应用程序**：这样可以为目标应用腾出更多的内存。
  - **增大操作系统对线程数量的限制**：
    - sysctl -w kernel.threads-max：增大Linux系统支持的最大线程数（表示物理内存决定的理论系统进程数上限，一般会很大）。
    - sysctl -w kernel.pid_max：增大Linux系统限制某用户下最多可以运行多少进程或线程数。
    - sysctl -w vm.max_map_count：增大限制一个进程可以拥有的VMA(虚拟内存区域)的数量。
      - 虚拟内存区域是一个连续的虚拟地址空间区域。在进程的生命周期中，每当程序尝试在内存中映射文件，链接到共享内存段，或者分配堆空间的时候，这些区域将被创建。
    - ulimit -u：增大用户最多可启动的进程数目。

##### 方法区溢出

- **相关概念**：

  - Methed Area，别命Non-Heap（非堆），线程共享，是JVM规范中定义的一个逻辑概念，用于存储已被虚拟机加载的**类信息、常量、静态变量和即时编译后的代码**等数据，具体放在哪里，不同的实现可能会放在不同的地方。
  - 在JDK8以后，元空间替代了永久代，使得方法区与堆存在交集，静态变量和字符串常量池存放在堆中，类信息和运行时常量池放在元空间中，而静态常量池是class文件里的常量池，未加载前并不占用内存。

- **定位的方法**：方法区溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。

- **方法区内存溢出分类**：

  不同的JDK版本，方法区存放的结构不同，所以相同的代码导致的内存溢出抛出的异常信息也可能不同。

  - **永久代溢出 & 堆内存溢出**：
    - 对于小于JDK 7的版本，采用的是**永久代**存储符号引用、字符串以及类的静态变量，所以小于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 7把符号引用（native heap）、字符串常量池以及类的静态变量移动到了**堆**中，所以大于等于JDK 7的版本，在遇到字符串过多的情况下，是否溢出取决于**堆的大小**。
  - **永久代溢出 & 元空间溢出**：
    - 对于小于JDK 8的版本，采用的是**永久代**存储类信息，所以小于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**永久代**的大小。
    - 由于JDK 8中使用了**元空间**替代永久代，采用运行时常量池存储已加载的类的元数据信息，所以大于等于JDK 8的版本，在遇到类加载过多的情况下，是否溢出取决于**元空间**的大小，而元空间是放在**本地内存**上的，只要**机器内存**足够大，理论上是很难发生溢出的。

- **方法区内存溢出的场景**？

  - **常量池对象太大**：
    - **原因**：比如字符串过多。
    - **解决方案**：根据JDK版本，为（字符串）常量池预留足够的空间。
      - < JDK 7：增大PermSize、MaxPermSize。
      - 》= JDK7：增大-Xms、-Xmx。
  - **加载的类过多**：
    - **原因**：
      - **动态代理的操作库生成了大量的动态类**：比如CXF、XSource、CGLIB等动态代理的框架，因为增强的类越多，就需要更多的空间来存储类的定义信息。
      - **JSP过多**：因为JSP是在第一次被访问的时候，才会被编译成Java类，在极端场景下，访问过多的JSP页面，可能会打满方法区导致内存溢出。
      - 脚本语言动态类加载：比如Grovy脚本出现的动态类加载导致的元空间溢出的问题。
    - **解决方案**：
      - < JDK 8：增大PermSize、MaxPermSize。
      - 》= JDK 8：可以留空元空间相关的配置（本地内存实现，不配置时JVM会动态去分配），或者设置合理的元空间大小。

##### 直接内存溢出

- **相关概念**：
  - **直接内存**：DirectBuffer，是一块由操作系统直接管理的内存，也叫**堆外内存**，并不是JVM运行时数据区的一部分，也不是JVM规范中定义的内存区域，但这部分内存会被频繁使用，而且也可能会导致OOM错误的出现。
- **定位的方法**：直接溢出后，抛出的错误会导致进程的挂掉，还是可以在日志中打印出堆栈日志，这时分析日志文件即可定位到问题代码了。
  - java.lang.OutOfMemoryError：Unsafe导致直接内存溢出报错没有小尾巴。
  - java.lang.OutOfMemoryError: Direct buffer memory：ByteBuffer直接内存溢出报错是有小尾巴的。
  - **（经验之谈）如果堆Dump文件看不出问题或者太小，可考虑是直接内存溢出的问题**。
- **直接内存溢出的场景**？
  - **内存泄露多导致的内存溢出**：
    - **原因**：分配对象到直接内存后，不使用时不释放内存，然后继续分配对象，时间久了就会出现溢出问题。
    - **解决方案**：设置最大直接内存大小-XX：MaxDirectMemorySize，**对Unsafe不起作用**，但对ByteBuffer有效（会先设置long maxMemory = VM.maxDirectMemory（））。

##### 代码缓存区溢出

- **概念**：CodeCache，代码缓存区，是非堆区域，缓存的是JIT编译器编译后的代码（即机器码），以及部分JNI的机器码，不过JIT编译生成的机器码占主要部分。
  - 解释执行可以节省内存，不存放到CodeCache，立即执行。
  - 编译执行后的代码会存放在CodeCache里，虽然CodeCache在即将耗尽时会尝试回收，但满了后却会让JIT停止工作，此后已编译过的代码会继续以编译模式执行，还没有编译过的代码将会退化成以解释执行模式执行，从而出现系统运行变慢、响应时间增大的现象。
- **定位的方法**：
  - 使用jconsole连接进程观察CodeCache。
  - 日志打印出VM warning：CodeCache is full. Compiler has been disabled信息。
  - 项目平常性能OK，但突然出现性能下降，业务又没有问题时，可排查是否由代码缓存区溢出所导致。
- **代码缓存区溢出的场景**：
  - **单体项目过于庞大但CodeCache又设置得过小**。
    - **解决方案**：
      - 可以对照jconsole设置合理的-XX：ReservedCodeCacheSize（代码缓存区的最大大小）。
      - 而对于微服务等代码量不多的小应用来说，240MB默认的CodeCache一般都是够用的了。

#### 项目越跑越慢如何定位与解决？

可能的场景有：

- **Stop The World时间过长、GC频繁**：

  - **定位方法**：检查GC日志。
  - 解决方案？：增加-XX：ParallelGCThreads并行收集的线程数、根据实际情况更换垃圾收集器。

- **项目依赖的资源导致变慢**：

  - **定位方法**：检查数据库、网络等资源是否被其他程序占用了很多。
  - 解决方案？：释放调用问题的资源。

- **CodeCache满了**：会导致JIT从编译执行退化成了解释执行。

  - **定位方法**：使用jconsole检查CodeCache大小。

- **线程争抢过于激烈**：会导致目标线程抢不到CPU片。

  - **定位方法**：使用VisualVM检查目标进程中的线程运行情况、分析ThreadDump（比如可以使用FastThread、PerfMa进行可视化分析）。
    - 结果发现：在循环中创建了一堆线程池，且使用完了又没关闭掉，导致线程池争抢激烈，消耗CPU资源严重。
    - 解决方案：使用完线程池后，在finally代码块把线程池关闭掉；同时根据业务规则命名线程（new ThreadFactoryBuilder().setNameFormat("my-thread-pool-%d")），方便以后定位问题。

- 服务器问题（了解就好）：操作系统问题、其他进程争抢资源。

  如果一个实例发生了问题，根据情况选择，要不要着急去重启。如果出现的CPU、内存飙高或者日志里出现了OOM异常**第一步是隔离**，第二步是**保留现场**，第三步才是**问题排查**。

  - **隔离**：就是把你机器从请求列表里摘除，比如把nginx相关的权重设成零。

  - **保留现场**：

    1. **系统当前网络连接**：使用 ss 命令而不是netstat的原因是：netstat 在网络连接非常多的情况下，执行非常缓慢。后续的处理，可通过查看各种网络连接状态的梳理，排查 TIME_WAIT或者CLOSE_WAIT，或者其他连接过高的问题，非常有用。

       ```shell
       ss -antp > $DUMP_DIR/ss.dump 2>&1
       ```

    2. **网络状态统计**：

       ```shell
       # 它能够按照各个协议进行统计输出，对把握当时整个网络状态，有非常大的作用。
       netstat -s > $DUMP_DIR/netstat-s.dump 2>&1
       
       # 在一些速度非常高的模块上，比如 Redis、Kafka，就经常发生跑满网卡的情况。表现形式就是网络通信非常缓慢。
       sar -n DEV 1 2 > $DUMP_DIR/sar-traffic.dump 2>&1
       ```

    3. **进程资源**：通过查看进程，能看到打开了哪些文件，可以以进程的维度来查看整个资源的使用情况，包括每条网络连接、每个打开的文件句柄。同时，也可以很容易的看到连接到了哪些服务器、使用了哪些资源。这个命令在资源非常多的情况下，输出稍慢，请耐心等待。

       ```shell
       lsof -p $PID > $DUMP_DIR/lsof-$PID.dump
       ```

    4. **CPU 资源**：主要用于输出当前系统的 CPU 和负载，便于事后排查。

       ```shell
       mpstat > $DUMP_DIR/mpstat.dump 2>&1
       vmstat 1 3 > $DUMP_DIR/vmstat.dump 2>&1
       sar -p ALL  > $DUMP_DIR/sar-cpu.dump  2>&1
       uptime > $DUMP_DIR/uptime.dump 2>&1
       ```

    5. **I/O 资源**：一般，以计算为主的服务节点，I/O 资源会比较正常，但有时也会发生问题，比如**日志输出过多，或者磁盘问题**等。此命令可以输出每块磁盘的基本性能信息，用来排查 I/O 问题。在第 8 课时介绍的 GC 日志分磁盘问题，就可以使用这个命令去发现。

       ```shell
       iostat -x > $DUMP_DIR/iostat.dump 2>&1
       ```

    6. **内存问题**：free 命令能够大体展现操作系统的内存概况，这是故障排查中一个非常重要的点，比如 SWAP 影响了 GC，SLAB 区挤占了 JVM 的内存。

       ```shell
       free -h > $DUMP_DIR/free.dump 2>&1
       ```

    7. **其他全局**：dmesg 是许多静悄悄死掉的服务留下的最后一点线索。当然，ps 作为执行频率最高的一个命令，由于内核的配置参数，会对系统和 JVM 产生影响，所以我们也输出了一份。

       ```shell
       ps -ef > $DUMP_DIR/ps.dump 2>&1
       dmesg > $DUMP_DIR/dmesg.dump 2>&1
       sysctl -a > $DUMP_DIR/sysctl.dump 2>&1
       ```

    8. **进程快照**：此命令将输出 Java 的基本进程信息，包括**环境变量和参数配置**，可以查看是否因为一些错误的配置造成了 JVM 问题。

       ```shell
       ${JDK_BIN}jinfo $PID > $DUMP_DIR/jinfo.dump 2>&1
       ```

    9. **dump堆信息**：jstat 将输出当前的 gc 信息。一般，基本能大体看出一个端倪，如果不能，可将借助 jmap 来进行分析。

       ```shell
       ${JDK_BIN}jstat -gcutil $PID > $DUMP_DIR/jstat-gcutil.dump 2>&1
       ${JDK_BIN}jstat -gccapacity $PID > $DUMP_DIR/jstat-gccapacity.dump 2>&1
       ```

    10. **堆信息**：jmap 将会得到当前 Java 进程的 dump 信息。如上所示，其实最有用的就是第 4 个命令，但是前面三个能够让你初步对系统概况进行大体判断。因为，第 4 个命令产生的文件，一般都非常的大。而且，需要下载下来，导入 MAT 这样的工具进行深入分析，才能获取结果。这是分析内存泄漏一个必经的过程。

        ```shell
        ${JDK_BIN}jmap $PID > $DUMP_DIR/jmap.dump 2>&1
        ${JDK_BIN}jmap -heap $PID > $DUMP_DIR/jmap-heap.dump 2>&1
        ${JDK_BIN}jmap -histo $PID > $DUMP_DIR/jmap-histo.dump 2>&1
        ${JDK_BIN}jmap -dump:format=b,file=$DUMP_DIR/heap.bin $PID > /dev/null  2>&1
        ```

    11. **JVM 执行栈**：

        ```shell
        # jstack 将会获取当时的执行栈。一般会多次取值，我们这里取一次即可。这些信息非常有用，能够还原 Java 进程中的线程情况。
        ${JDK_BIN}jstack $PID > $DUMP_DIR/jstack.dump 2>&1
        
        # 为了能够得到更加精细的信息，我们使用 top 命令，来获取进程中所有线程的 CPU 信息，这样，就可以看到资源到底耗费在什么地方了。
        top -Hp $PID -b -n 1 -c >  $DUMP_DIR/top-$PID.dump 2>&1
        ```

    12. **高级替补**：

        ```shell
        # 有时候，jstack 并不能够运行，有很多原因，比如 Java 进程几乎不响应了等之类的情况。我们会尝试向进程发送 kill -3 信号，这个信号将会打印 jstack 的 trace 信息到日志文件中，是 jstack 的一个替补方案。
        kill -3 $PID
        
        # 对于 jmap 无法执行的问题，也有替补，那就是 GDB 组件中的 gcore，将会生成一个 core 文件。我们可以使用如下的命令去生成 dump：
        gcore -o $DUMP_DIR/core $PID
        ${JDK_BIN}jhsdb jmap --exe ${JDK}java  --core $DUMP_DIR/core --binaryheap
        ```

    13. **内存泄漏的现象**：稍微提一下 jmap 命令，它在 9 版本里被干掉了，取而代之的是 jhsdb，你可以像下面的命令一样使用。一般内存溢出，表现形式就是 Old 区的占用持续上升，即使经过了多轮 GC 也没有明显改善。比如ThreadLocal里面的GC Roots，内存泄漏的根本就是，这些对象并没有切断和 GC Roots 的关系，可通过一些工具，能够看到它们的联系。

        ```shell
        jhsdb jmap  --heap --pid  37340
        jhsdb jmap  --pid  37288
        jhsdb jmap  --histo --pid  37340
        jhsdb jmap  --binaryheap --pid  37340
        ```

# 三、并发篇 

### 1.1. CPU、内存、外存、操作系统、应用程序、进程、线程、协程、管程、超线程？

在计算机中：

- **CPU**：是核心的硬件资源，承担所有的计算任务。
- **内存**：承担运行时数据的保存任务。
- **外存**：承担数据外部永久存储的任务，如硬盘等。
- **操作系统**：统领计算任务的调度、资源的分配。
- **应用程序**：是存放在硬盘中的可执行文件，主要包括代码指令和数据，以进程的形式运行于操作系统之上，享受操作系统提供的服务。
- **进程**：是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。
- **线程**：指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。
- **协程**：是一种比线程更加轻量级的存在，一个线程可以拥有多个协程，协程没有增加线程数量，只是在线程的
  基础之上通过**分用复用**的方式运行多个协程。
- **管程**：是管理共享变量以及对共享变量的操作过程，以让它们支持并发，是一种**进程同步互斥工具**。
- **超线程**：指**在单核CPU上可以并发AB两个线程**，如果AB资源不冲突，则AB两个线程就可以并发执行；而如果AB都在访问同一个资源，那么只能等前一个线程执行完，后一个线程才能执行。

### 1.2. 详细介绍进程的结构？

进程是程序的一次启动执行，是**操作系统资源分配的最小单位**。操作系统将程序装入内存，给程序分配必要的系统资源， 并且开始运行程序的指令。

一般来说，一个进程由**程序段**、**数据段**和**进程控制块**三部分组成。在进程内部，代码段和数据段有自己的独立地址空间，不同进程的地址空间是相互隔离的。

- **程序段**：一般称为代码段，是进程的程序指令在内存中的位置，包含需要执行的指令集合。
- **数据段**：是进程操作数据在内存中的位置，包含需要操作的数据集合。
- **程序控制块**：Program Control Block，PCB，包含进程的描述信息和控制信息，是进程存在的唯一标志。
  - **进程的描述信息**：主要包括：
    - **进程ID**：是唯一的，代表进程的身份。
    - **进程状态**：比如运行、就绪、阻塞；
    - **进程优先级**：是进程调度的重要依据。
  - **进程的调度信息**：主要包括：
    - **程序起始地址**：即程序第一行指令的内存地址，是从这里开始程序的执行。
    - **通信信息**：进程间通信时的消息队列。
  - **进程的资源信息**：主要包括：
    - **内存信息**：内存占用情况和内存管理所用的数据结构。
    - **I/O设备信息**：所用的I/O设备编号及相应的数据结构。
    - **文件句柄**：所打开文件的信息。
  - **进程上下文**：
    - 即**进程的环境**，主要包括**执行时各种CPU寄存器的值**、**当前程序计数器（PC）的值**以及**各种栈的值**等。
    - 在操作系统切换进程时，当前进程被迫让出CPU，当前进程的上下文就保存在PCB结构中，供下次恢复运行时使用。

![1629615113218](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615113218.png)

### 1.3. 详细介绍线程的结构？

为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，进程内部演进出了并发调度的诉求，于是就发明了线程。

线程指进程代码段的一次顺序执行流程，是**CPU任务调度和执行的最小单位**，一个进程可以有多个线程。

一个标准的线程主要由**线程描述信息**、**程序计数器（ProgramCounter，PC）**和**栈内存**三部分组成。

- **线程描述信息**：也即线程的基本信息，主要包括：
  - **线程ID**：Thread ID，线程标识符，是线程的唯一标识，同一个进程内不同线程的ID不会重复。
  - **线程名称**：主要是方便用户识别，用户可以指定线程的名字，如果没有指定，系统就会自动分配一个名称。
  - **线程优先级**：表示线程调度的优先级，优先级越高，获得CPU的执行机会就越大。
  - **线程状态**：表示当前线程的执行状态，为新建、就绪、运行、阻塞、结束等状态中的一种。
  - **其他信息**：比如是否为守护线程等。
- **程序计数器**：记录着线程下一条指令的代码段内存地址。
- **栈内存**：
  - 是代码段中局部变量的存储空间，为线程所独立拥有，在线程之间不共享。
  - 在JDK 1.8中，每个线程在创建时默认被分配**1MB**大小的栈内存，其中栈内存和堆内存不同，栈内存不受垃圾回收器管理。
    - 在Java中，执行程序流程的重要单位是“**方法**”，而栈内存的分配单位是“**栈帧**”（或者叫“方法帧”）。
    - 方法的每一次执行都需要为其分配一个栈帧（方法帧），栈帧主要保存该方法中的局部变量、方法的返回地址以及其他方法的相关信息。
    - 当线程的执行流程进入方法时，JVM就会为方法分配一个对应的栈帧压入栈内存；当线程的执行流程跳出方法时，JVM就从栈内存弹出该方法的栈帧，此时方法帧的局部变量的内存空间就会被回收。
    - 由于栈帧（方法帧）的操作是后进先出的模式，这也是标准的栈操作模式，因此**存放方法帧的内存也被叫作栈内存**。

![1629615141818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615141818.png)

### 1.4. 线程上下文切换？

- **线程上下文**：是指某一时刻**CPU寄存器**和**程序计数器**的内容，CPU通过时间片分配算法来循环执行线程，由于CPU时间片非常短，因此CPU需要通过不停地切换上下文以执行不同的线程。
- **上下文切换**：在当前任务执行完CPU时间片切换到另一个任务之前，操作系统会先保存该任务的状态（包括程序计数器、虚拟机栈中每个栈帧的信息），以便下次再切换回这个任务时，可以再加载这个任务的状态。这种**任务从保存到再加载的过程就是一次上下文切换**。
- **线程上下文切换的开销**：
  - **直接消耗**：指CPU寄存器需要保存和加载、系统调度器的代码需要执行、TLB实例需要重新加载等。
  - **间接消耗**：指多核的CPU高速缓存之间需要共享数据，间接对程序造成影响。
- **线程上线文切换的场景**：
  - **抢占式**：一般跟锁竞争有关，可以减少锁争用，来减少线程上下文切换。
    - **线程的CPU时间片已用完**：当前执行线程（任务）的**CPU时间片用完**之后，CPU会调度下一个线程。
  - **时间片轮转**：一般跟时间片有关，可以减少线程数，来减少线程上下文切换。
    - **线程被挂起**：比如调用了Thread#sleep、Thread#yield、Object#wait、LockSupport#park、synchronized、lock、阻塞式I/O等方法后。
- **如何减少线程上下文切换**：
  - **合理使用线程**：合理设置线程数目，避免创建不必要的线程，既可以最大化利用CPU，又可以减少线程切换的开销。
    - **高并发，低耗时的情况，**建议减少线程数。
    - **低并发，高耗时的情况**，建议增加线程数。
    - **高并发高耗时，**需要分析任务类型、增加排队、加大线程数等。
  - **减少锁争用**：通过设计算法来减少争抢锁的概率，比如JDK 7 ConcurrentHashMap中的**分段锁**，将ConcurrentHashMap分为多个段，每个段有自己的哈希表，线程只需要获取某段的分段锁，就可以操作该段的哈希表。这样保证线程安全的同时，还可以减少锁的争用，从而减少线程的上下文切换。
  - **无锁并发编程**：如CAS算法，通过自旋+CAS，不需要加锁也可以实现线程安全，其实现有Atomic包下的原子类、JDK 8 ConcurrentHashMap等。
  - 使用协程：通过线程的分用复用，在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

### 1.5. 进程与线程的区别？

|              | 线程                                                         | 进程                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 目的不同     | 为了充分发挥CPU的计算性能，提升CPU硬件资源的利用率，同时弥补进程调度过于笨重产生的问题，满足进程内部并发调度的诉求 | 用于将程序装入内存，运行程序的指令                           |
| 概念不同     | 线程是“进程代码段”的一次顺序执行流程，是CPU调度的最小单位    | 进程是程序的一次启动执行，是操作系统分配资源的最小单位，一个进程由一个或多个线程组成，一个进程至少有一个线程 |
| 共享空间不同 | 各线程之间共享进程的方法区内存、堆内存、系统资源（文件句柄、系统信号等） | 进程之间是相互独立的，但进程内部的各个线程之间并不完全独立   |
| 切换速度不同 | 线程上下文切换快                                             | 进程上下文切换慢                                             |

### 1.6. 进程的状态？

- **背景**：进程是程序的一次执行，在这个执行过程中，有时进程正在被CPU处理，有时又需要等待CPU服务，其状态会有各种变化。**为了方便对各个进程的管理**，操作系统需要将进程合理地划分为几种状态。
- **进程的几种状态**：
  - **创建态**：New，进程正在被创建，操作系统为进程分配资源、初始化PCB。
  - **就绪态**：Ready，进程已经具备运行条件，但由于没有空闲CPU，而暂时不能运行。
    - 进程处于就绪态，代表已经拥有了除处理机之外所有需要的资源，一旦获得处理机，即可立即进入运行态开始运行，即**万事俱备，只欠CPU**。
  - **运行态**：Running，进程占有CPU，并在CPU上运行。
    - 注意，单机处理机环境下，每时刻最多只有一个进程处于运行态；而双核环境下，可以同时有两个进程处于运行态。
  - **阻塞态**：Waiting/Blocked，又称等待态，进程因申请某一资源没有被分配，或者等待某一事件而暂时不能运行。
    - 比如等待操作系统分配打印机、等待读磁盘操作的结果。CPU是计算机中最昂贵的部件，为了提高CPU的利用率，需要先将其他进程需要的资源分配到位，才能得到CPU的服务。
  - **终止态**：Terminated，进程运行结束，或者由于bug导致进程无法继续执行下去（比如数组越界错误，此时需要撤销进程），此时进程需要从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。

### 1.7. 进程状态的转换？

- **创建态 -> 就绪态**：系统完成创建进程相关的工作。
- **就绪态 -> 运行态**：进程被CPU调度。
- **运行态 -> 就绪态**：进程被分配的CPU时间片到了，或者CPU被其他高优先级进程抢占了。
- **运行态 -> 阻塞态**：等待系统资源分配，或者等待某事件的发生，属于进程的**主动行为**。
- **阻塞态 -> 就绪态**：系统资源已分配到位，或者等待的事件已发生，属于进程的**被动行为**。
  - 注意，不能由阻塞态直接转换为运行态，因为需要等待CPU的调度。
  - 也不能由就绪态直接转换为阻塞态，因为进入阻塞态是进程的主动请求，必然需要进程在运行时才能发出这种请求。
- **运行态 -> 终止态**：进程运行结束，或者运行过程中遇到不可修复的错误。

![1629536288202](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629536288202.png)

### 1.8. Java线程状态与状态切换？

Java线程的生命周期，即Java线程状态，线程在某时刻只能处于一种状态。注意！这些状态只为JVM虚拟机状态，不代表任何操作系统的线程状态。

- **NEW**：新建状态**（对应进程创建态）**，处于该状态的线程尚未启动。
  - new Thread（...）创建了线程，但未调用start（）启动线程时。
- **RUNNABLE**：可执行状态，该状态包含操作系统进程的就绪、运行两种状态。
  - **Ready**：就绪状态**（对应进程就绪态）**，仅仅代表当前线程具备运行的资格，如果线程没有被操作系统的调度程序挑选中，则会永远处于就绪状态。
    - Thread#start（）、线程的CPU时间片用完、Thread#sleep（long）、线程抢到对象锁（Object Monitor）、Thread#yield（）。
  - **Running**：运行状态**（对应进程运行态）**，调用Thread#run（）方法不一定会马上被并发执行，在线程获取了CPU时间片之后，才真正启动并发执行，此时线程进入运行状态。
- **BLOCKED**：阻塞状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且在线程抢到锁或者等待事件发生后，会回到就绪状态。
  - 线程阻塞等待锁、阻塞式I/O操作。
- **WAITING**：等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且需要被其他线程**显式地唤醒**，才会回到就绪状态。
  - 调用无时限的Object#wait（）、Thread#join（）、LockSupport#park（）时。
- **TIMED_WAITING**：限时等待状态**（对应进程阻塞态）**，处于该状态的线程不会占用CPU资源，不会被分配CPU时间片，且如果指定时间内没有被唤醒，限时等待的线程会被**系统自动唤醒**，会回到就绪状态。
  - Thread#sleep（long）、Object#wait（long）、LockSupport#park Nanos（long）、LockSupport#parkUntil（long）、Thread#join（long）。
  - 因此，对应进程状态可得出结论：进入BLOCKED状态、WAITING状态、TIMED_WAITING状态的线程，都会让出CPU的使用权，在处于等待或者阻塞状态的线程被唤醒后，才会回到就绪状态，然后需要重新获取CPU时间片才能接着运行。
- **TERMINATED**：
  - 终止状态**（对应进程终止态）**，也叫死亡状态，处于RUNNABLE状态的线程，在**Thread#run（）方法执行完成之后**，就会变成该状态。
  - 当然，如果在Thread#run（）方法执行过程中，发生了**运行时异常**而没有被捕获，Thread#run（）方法将被异常终止，线程也会变成该状态。

![1629615205233](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615205233.png)

### 1.9. 线程切换相关方法？

| 方法                            | 作用                                                         | 状态转换（JVM线程）                                          | 状态转换（进程）                    |
| ------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ----------------------------------- |
| Thread#start（）                | 被synchronized修饰，开始执行Thread线程，然后JVM会调用run方法 | NEW -> RUNNABLE                                              | NEW -> READY                        |
| Thread#run（）                  | 如果运行的目标任务不为null，则调用Runnable#run方法           | RUNNABLE -> TERMINATED                                       | READY -> RUNNING -> TERMINATED      |
| Thread#yiled（）                | 让步CPU，向调度程序提示，当前线程愿意放弃其当前对处理器的使用 | RUNNABLE                                                     | RUNNING -> READY                    |
| Thread#sleep（long）            | 使当前正在执行的线程休眠（暂时停止执行），且当前线程不会失去任何监视器的所有权 | RUNNABLE -> TIMED_WAITING -> RUNNABLE                        | RUNNING -> Waiting/Blocked -> READY |
| Object#wait（）                 | 需要被synchronized修饰，当前线程阻塞等待该对象调用notify、notifyAll、中断 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待锁) -> RUNNABLE    | RUNNING -> Waiting/Blocked -> READY |
| Object#wait（long）             | 需要被synchronized修饰，当前线程阻塞等待该对象调用notify、notifyAll、中断或者指定时间过去(为0时需要一直等待) | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Thread#join（）                 | 被synchronized修饰，无限等待调用线程的死亡，实质上是调用当前Thread实例的wait方法进行阻塞等待 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待锁) -> RUNNABLE    | RUNNING -> Waiting/Blocked -> READY |
| Thread#join（long）             | 被synchronized修饰，等待调用线程的死亡，实质上是调用当前Thread实例的wait方法进行阻塞等待 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#park                | 基于Linux#mutex和condition实现，无限阻塞当前线程，直到当前线程unpark被调用、被中断 | *RUNNABLE -> WAITING(唤醒后不需要等待对象锁) ->RUNNABLE*     | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#parkNanos           | 基于Linux#mutex和condition实现，在指定的等待时间内阻塞当前线程，直到当前线程unpark被调用、被中断、time时间过去 | *RUNNABLE -> TIMED_WAITING(唤醒后不需要等待对象锁) ->RUNNABLE* | RUNNING -> Waiting/Blocked -> READY |
| LockSupport#parkUntil           | 基于Linux#mutex和condition实现，在绝对时间前阻塞当前线程, 直到当前线程unpark被调用、被中断、time时间过去 | *RUNNABLE -> TIMED_WAITING(唤醒后不需要等待对象锁) -> RUNNABLE* | RUNNING -> Waiting/Blocked -> READY |
| Condiction#await                | 基于LockSupport#park实现，当前线程阻塞等待, 直到收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待Lock锁) -> RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitUninterruptibly | 基于LockSupport#park实现，当前线程阻塞等待, 直到收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> WAITING ->  BLOCKED(唤醒后等待Lock锁) -> RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#await(long)          | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitNanos           | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |
| Condiction#awaitUntil           | 基于LockSupport#park实现，当前线程阻塞等待, 直到时间过去、收到唤醒或者中断信号, 在可以返回当前线程之前, 必须重新获取与此Condition关联的锁 | RUNNABLE -> TIMED_WAITING -> BLOCKED(唤醒后等待锁) ->RUNNABLE | RUNNING -> Waiting/Blocked -> READY |

### 2.0. 线程通信？

线程的通信，指当多个线程共同操作共享的资源时，线程间通过某种方式互相告知自己的状态，以避免无效的资源争夺。

- 等待 - 通知：Java中使用普遍的线程间通信方式，指的是一个线程A调用了同步对象的wait()方法进入等待状态，而另一线程B调用了同步对象的notify()或者notifyAll()方法通知等待线程，当线程A收到通知后，重新进入就绪状态，准备开始执行。
  - 线程间的通信需要借助同步对象（Object）的监视器来完成，Object对象的wait()、notify()方法就如开关信号，用于完成等待方和通知方之间的通信。
- 共享内存：见进程通信。
- 管道流：见进程通信。

### 2.1. Object#wait核心原理？

在调用同步对象的wait()和notify()系列方法时，“当前线程”必须拥有该对象的**同步锁**。

1. 当线程调用了locko（某个同步锁对象）的wait()方法后，JVM会将当前线程加入locko监视器的WaitSet（等待集），等待被其他线程唤醒。
2. 当前线程会释放locko对象监视器的Owner权利，让其他线程可以抢夺locko对象的监视器。
3. 让当前线程等待，其状态变成WAITING。

![1629677601364](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629677601364.png)

### 2.2. Object#notify核心原理？

在调用同步对象的wait()和notify()系列方法时，“当前线程”必须拥有该对象的**同步锁**。

1. 当线程调用了locko（某个同步锁对象）的notify()方法后，JVM会唤醒locko监视器WaitSet中的第一条等待线程。
2. 当线程调用了locko的notifyAll()方法后，JVM会唤醒locko监视器WaitSet中的所有等待线程。
3. 等待线程被唤醒后，会从监视器的WaitSet移动到EntryList，线程具备了排队抢夺监视器Owner权利的资格，其状态从WAITING变成BLOCKED。
4. EntryList中的线程抢夺到监视器的Owner权利之后，线程的状态从BLOCKED变成Runnable，具备重新执行的资格。

![1629677703149](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629677703149.png)

### 2.3. Object#wait与Thread#sleep的区别？

1. wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。
2. wait 方法会主动释放 monitor 锁，在同步代码中执行 sleep 方法时，并不会释放 monitor 锁。
3. wait 方法意味着永久等待（因为没带时间参数），直到被中断或被唤醒才能恢复，不会主动恢复，sleep 方法中会定义一个时间，时间到期后会主动恢复。
4. wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。

### 2.4. LockSupport#park与Thread#sleep的区别？

LockSupport.park()和Thread.sleep()方法，进入阻塞的线程**不会释放持有的锁**，因此在持有锁的时候调用该方法需要谨慎。

1. Thread.sleep()没法从外部唤醒，只能自己醒过来；而被LockSupport.park()方法阻塞的线程可以通过调用LockSupport.unpark()方法去唤醒。
2. Thread.sleep()方法声明了InterruptedException中断异常，这是一个受检异常，调用者需要捕获这个异常或者再抛出；而调用LockSupport.park()方法时不需要捕获中断异常。
3. 被LockSupport.park()方法、Thread.sleep()方法所阻塞的线程有一个特点，当被阻塞线程的Thread.interrupt()方法被调用时，被阻塞线程的中断标志将被设置，该线程将被唤醒。不同的是，二者对中断信号的响应方式不同：LockSupport.park()方法不会抛出InterruptedException异常，仅仅设置了线程的中断标志；而Thread.sleep()方法会抛出InterruptedException异常。
4. 与Thread.sleep()相比，调用LockSupport.park()能更精准、更加灵活地阻塞、唤醒指定线程。
5. Thread.sleep()本身就是一个Native方法；LockSupport.park()并不是一个Native方法，只是调用了一个Unsafe类的Native方法（名字也叫park）去实现。
6. LockSupport.park()方法还允许设置一个Blocker对象，主要用来供监视工具或诊断工具确定线程受阻塞的原因。

### 2.5. LockSupport#park与Object#wait的区别？

1. Object.wait()方法需要在synchronized块中执行；而LockSupport.park()可以在任意地方执行。
2. Object.wait()方法，进入阻塞的线程**会释放持有的锁**；而LockSupport.park()可以在任意地方执行，进入阻塞的线程**不会释放持有的锁**。
3. 当被阻塞线程被中断时，Object.wait()方法抛出了中断异常，调用者需要捕获或者再抛出；当被阻塞线程被中断时，LockSupport.park()不会抛出异常，调用时不需要处理中断异常。
4. 如果线程在没有被Object.wait()阻塞之前被Object.notify()唤醒，也就是说在Object.wait()执行之前去执行Object.notify()，就会抛出IllegalMonitorStateException异常，是不被允许的；而线程在没有被LockSupport.park()阻塞之前被LockSupport.unPark()唤醒，也就是说在LockSupport.park()执行之前去执行LockSupport.unPark()，不会抛出任何异常，是被允许的。

### 2.6. 线程中断的相关方法？

| 方法                                | 作用                                                         |
| ----------------------------------- | ------------------------------------------------------------ |
| public void interrupt()             | 1. 中断实例线程（注意！实例线程不⼀定是当前线程，⽽是指调⽤该⽅法的Thread实例所代表的线程）。2. 如果实例线程处于阻塞状态（比如调用了wait方法或者io等待时），则会立马退出阻塞，并抛出InterruptedException异常，线程就可以通过捕获InterruptedException来做一定的处理，然后线程退出。3. 如果实例线程正在运行中，实际上只是给线程设置⼀个中断标志，线程仍会继续运⾏，线程自己要在适当的位置通过调用isInterrupted方法来查看自己是否被中断，并做退出操作。4. 如果线程的interrupt方法先被调用，然后线程调用阻塞方法进入阻塞状态，InterruptedException异常依旧会抛出。5. 如果线程捕获InterruptedException异常后，继续调用阻塞方法，将不再触发InterruptedException异常。 |
| public static boolean interrupted() | 测试当前线程是否已经被中断（检查中断标志），返回⼀个boolean并清除中断状态，第⼆次再调⽤时中断状态已经被清除，将返回⼀个false。 |
| public boolean isInterrupted()      | 只测试实例线程是否被中断 ，不清除中断状态。                  |

### 2.7. 创建线程的方式？

#### 实现Runnable接口

- 优先使用。

```java
public class RunnableThread implements Runnable {
    @Override
    public void run() {System.out.println('用实现Runnable接口实现线程');}
}
```

#### 实现Callable接口

- 有返回值、可抛出异常。

```java
class CallableTask implements Callable<Integer> {
    @Override
    public Integer call() throws Exception { return new Random().nextInt();}
}
```

#### 继承Thread类

- 在不修改Thread方法情况下，不建议使用。

```java
public class ExtendsThread extends Thread {
    @Override
    public void run() {System.out.println('用Thread类实现线程');}
}
```

#### 使用线程池

- 底层都是实现Runable#run方法。

```java
static class DefaultThreadFactory implements ThreadFactory {
    
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null) ? 
            s.getThreadGroup() : Thread.currentThread().getThreadGroup();
        namePrefix = "pool-" + poolNumber.getAndIncrement() +"-thread-";
    }
    
    public Thread newThread(Runnable r) {
        Thread t = 
            new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0);
        
        if (t.isDaemon()) t.setDaemon(false);// 是否守护线程
        if (t.getPriority() != Thread.NORM_PRIORITY) 
            t.setPriority(Thread.NORM_PRIORITY);// 线程优先级
        
        return t;
    }
}
```

### 2.8. 详细介绍线程池？

#### 特点

- ThreadPoolExecutor，继承AbstractExecutorService，实现ExecutorService、Executor接口，**使用多个线程之一来执行每个提交的任务**，通常使用 {@link Executors} 工厂方法进行配置。
- **线程池优点**：
  - **降低资源消耗**：线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，通过**重复利用已创建的线程**可以降低线程创建和销毁造成的消耗。
  - **提高响应速度**：当任务到达时，可以不需要等待线程创建就能**立即执行**。
  - **提高线程的可管理性**：线程池提供了一种限制、管理资源的策略，维护一些基本的线程统计信息，如已完成任务的数量等。通过线程池可以**对线程资源进行统一的分配、监控和调优**。

#### 原理记忆图

![1629770131750](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629770131750.png)

#### 构造方法 

```java
// 线程池构造函数7大参数
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler) {
    
}
```

| 参数                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| corePoolSize             | 核心线程数                                                   |
| maximumPoolSize          | 最大线程数                                                   |
| keepAliveTime            | 空闲线程的保活时间，线程池中超过corePoolSize数目的空闲线程最大存活时间（等待任务的最长时间） |
| TimeUnit                 | 空闲线程的保活时间单位                                       |
| workQueue                | 任务阻塞队列                                                 |
| threadFactory            | 线程工厂                                                     |
| RejectedExecutionHandler | 拒绝策略处理程序，当提交任务数超过maxmumPoolSize+workQueue容量之和，或者线程池已关闭时，任务会交给拒绝策略处理程序来处理 |

#### 线程池状态

![1629772009056](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629772009056.png)

- **线程池控制状态ctl**，是一个原子整数，封装了两个概念字段：
  - workerCount，低29位，表示**有效线程数**（当前活动的线程数）。
  - runState，高3位，表示**线程池状态**，比如是否正在运行、正在关闭等。
- runState提供主要的**生命周期控制**，提供5种取值，这些值之间的数字顺序很重要，以允许进行有序比较。
  - runState取值有：
    - **RUNNING**：接受新任务并处理排队任务。
    - **SHUTDOWN**：不接受新任务，但处理排队任务。
    - **STOP**：不接受新任务，不处理排队任务，并中断正在进行的任务。
    - **TIDYING**：所有任务都已终止，workerCount 为0，转换到状态 TIDYING 的线程将运行 terminate()
      钩子方法。
    - **TERMINATED**： terminate() 钩子方法已完成.
  - runState 会随时间单调增加，但**可以不用命中每个状态**。转换有：
    - **RUNNING -> SHUTDOWN**：在调用 **shutdown()** 时，可能隐含在 finalize() 中。
    - **（RUNNING 或 SHUTDOWN）-> STOP**：在调用 **shutdownNow()** 时。
    - **SHUTDOWN -> TIDYING**：当**队列为空**且**工作线程数量为0**时。
    - **STOP -> TIDYING**：当**工作线程数量为0**时。
    - **TIDYING -> TERMINATED**：当 terminate() 钩子方法完成时。

```java
public class ThreadPoolExecutor extends AbstractExecutorService {
	// 线程池控制状态ctl, 高3位表示线程池状态, 低29位表示有效线程数, 初始为(1110, 0000, 0000, 0000, 0000, 0000, 0000, 0000) < 0
    private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
    
    // 29位
    private static final int COUNT_BITS = Integer.SIZE - 3;
    
    // 低29位存储有效线程数(约5亿个线程)
    private static final int CAPACITY   = (1 << COUNT_BITS) - 1;
    
    private static final int RUNNING    = -1 << COUNT_BITS;// 运行状态, 高3位: 111
    private static final int SHUTDOWN   =  0 << COUNT_BITS;// 关闭状态, 高3位: 000
    private static final int STOP       =  1 << COUNT_BITS;// 停止状态, 高3位: 001
    private static final int TIDYING    =  2 << COUNT_BITS;// 整理状态, 高3位: 010
    private static final int TERMINATED =  3 << COUNT_BITS;// 终止状态, 高3位: 011
}
```

#### 线程复用原理

![1629788027448](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629788027448.png)

- 线程工人类Worker：
  - 继承AQS抽象类，以实现轻量级的独占锁，用于**记录独占线程**。
  - **持有Thread引用**，在构造Worker时设置，在ThreadPoolExecutor#runWorker（）或者ThreadPoolExecutor#addWorker（）中，用于执行任务或者启动线程。
  - 持有firstTask引用，**作为第一个任务执行**，之后便从任务队列中获取任务执行了。
  - 实现Runnable接口，在线程工厂工造线程时，把**本身当做一个执行任务传入**，使其能够在ThreadPoolExecutor#addWorker（）方法中，执行完firstTask后Thread#start（）启动Worker引用的线程实例时，从而调用Worker#run（）方法。
  - Worker#run（）方法调用ThreadPoolExecutor#runWorker（）方法，在ThreadPoolExecutor#runWorker（）方法中，清空firstTask（此时firstTask肯定被执行过了），接着ThreadPoolExecutor#getTask（）**轮训获取**任务队列中的任务，然后调用Runnable#run（）方法执行任务，其中如果检测到STOP状态时，还会中断Worker持有的实例线程。
- **空闲线程淘汰原理**：
  - 在ThreadPoolExecutor#getTask（）方法中，如果线程池为SHUTDOWN状态且队列为空，或者线程池为STOP状态，或者空闲线程获取任务超时，则都会扣减ctl低29位的有效工人数量，并返回null的任务。否则阻塞获取任务。
  - 返回null的任务，在ThreadPoolExecutor#runWorker（）方法轮训被检测到，则会调用ThreadPoolExecutor#processWorkerExit（）来真实移除工人集合中的指定Worker，接着调用tryTerminate（）尝试清空线程，最后根据ctl获取当前工作线程数、核心线程数、最大核心线程数、是否允许核心线程空闲，来决定是否需要增加Worker，如果不需要则直接返回即可，如果需要则重新调用ThreadPoolExecutor#addWorker（）增加非核心线程（允许核心线程空闲也代表只有非核心线程）。
  - tryTerminate（）在线程池为STOP状态 或者 为SHUTDOWN状态且队列为空时, 如果工作线程数不为0, 则需要中断一个工作线程，如果为TIDYING状态还会调用钩子terminated()方法 ，代表线程池已终止。

```java
// 线程工人, 实现Runnable本身可以作为一个任务, 实现AQS以简化获取和释放围绕每个任务执行的锁, 实现了一个简单的不可重入互斥锁
private final class Worker extends AbstractQueuedSynchronizer implements Runnable {
    
    final Thread thread;// 该工人正在运行的线程, 如果工厂生产线程失败, 则为null
    Runnable firstTask;// 该工人要运行的初始任务, 可能会为空
    volatile long completedTasks;// worker已完成任务计数器
    
    // 注意! 在构造Worker时, 使用了当前worker实例作为Thread#Runnable实例变量, 如果运行的目标任务不为null, 则调用Runnable#run方法
    Worker(Runnable firstTask) {
        setState(-1); // inhibit interrupts until runWorker 禁止中断直到 runWorker
        this.firstTask = firstTask;
    
     // 注意! 在构造Worker时, 使用了当前worker实例作为Thread#Runnable实例变量, 如果运行的目标任务不为null, 则调用Runnable#run方法
        this.thread = getThreadFactory().newThread(this);
    }

    // 指定当前工人来运行任务: 先获取firstTask -> 从任务队列中获取任务 -> beforeExecute -> 运行获取到的任务 -> afterExecute -> 线程运行后的清理工作processWorkerExit
    public void run() {
        runWorker(this);
    }
}
```

#### 任务处理过程

![1629786785786](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629786785786.png)

1. 首先获取线程池控制位ctl，根据ctl获取当前工作线程数，如果工作线程数小于核心线程数，则使用当前任务作为firstTask创建核心线程。
2. 如果核心线程创建成功，则直接返回即可；如果核心线程创建失败，说明线程池可能是状态发生了变化，或者线程数超过了核心线程数，则需要重新获取线程池控制位ctl，再次判断。
3. 如果判断到线程池状态仍然为RUNNING，说明只是发生了线程数超过了核心线程数，这时只需要把任务追加到任务队列即可。
   1. 如果任务追加成功，为了稳重起见，重新获取线程池控制位ctl，再次判断线程池状态是否为RUNNING。
   2. 如果线程池确认仍然为RUNNING，为了保证能够有线程拉取任务，则再判断当前工作线程数是否为0，如果没有则不适用firstTask创建非核心线程；如果有则直接返回即可，代表线程池任务投递成功。
   3. 如果线程池确实不为RUNNING，则移除刚才追加的任务，然后履行拒绝策略，代表无论是SHUTDOWN还是STOP或者其他，都不接收任何新的任务了。
4. 如果判断到线程池状态不为RUNNING，或者任务追加失败，则尝试使用当前任务作为firstTask创建非核心线程。
5. 如果非核心线程创建失败，则履行拒绝策略；如果非核心线程创建成功，则直接返回即可（因为非核心线程执启动后会执行firstTask）。

```java
// 在未来的某个时间执行给定的任务, 任务可以在新线程或现有池线程中执行, 如果任务无法提交执行, 则该任务由当前 {@code RejectedExecutionHandler} 来处理
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();

    // 获取ctl控制位c
    int c = ctl.get();

    // 根据控制位ctl获取工作线程数, 如果工作线程数小于核心线程数
    if (workerCountOf(c) < corePoolSize) {
        // 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
        if (addWorker(command, true))
            // 如果启动工作线程成功, 则直接返回
            return;

        // 如果启动工作线程失败, 则重新获取ctl控制位c
        c = ctl.get();
    }

    // 如果线程池仍为运行状态, 则往任务队列填充任务command
    if (isRunning(c) && workQueue.offer(command)) {
        // 如果任务填充成功, 则再获取ctl控制位recheck
        int recheck = ctl.get();

        // 如果此时线程池不为运行状态, 则从执行程序的内部队列中删除该任务，从而导致它在尚未启动时无法运行
        if (!isRunning(recheck) && remove(command))
            // 如果删除成功, 则履行任务command和当前任务执行者executor的拒绝策略
            reject(command);
        // 如果此时线程池仍为运行状态, 但工作线程数为0, 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 如果线程池不为运行状态, 或者往任务队列填充任务command失败, 则检查是否可以根据当前池状态和给定界限（核心或最大值）添加新的工作线程, 如果添加工作线程成功, 则返回true; 如果添加工作线程失败, 则回滚工作线程并返回false
    else if (!addWorker(command, false))
        // 如果worker添加失败, 则履行任务command和当前任务执行者executor的拒绝策略
        reject(command);
}
```

#### 线程工厂

| 实现类                  | 特性                                                         |
| ----------------------- | ------------------------------------------------------------ |
| DefaultThreadFactory    | 默认线程工厂，创建的线程都在同一个 {@link ThreadGroup} 中，并且具有相同的 {@code NORM_PRIORITY} 优先级和非守护进程状态。 |
| PrivilegedThreadFactory | 能够继承权限的线程工厂, 创建的线程具有相同的线程上下文和类加载器 |

#### 阻塞队列

![1629788141222](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629788141222.png)

##### BlockingQueue接口实现

| 实现类                | 界限性 | 特性                                                         |
| --------------------- | ------ | ------------------------------------------------------------ |
| ArrayBlockingQueue    | 有界   | 1. 基于数组实现的有界阻塞队列。2. 初始化时必须指定容量大小。3. 一旦指定容量大小，其容量就不能修改了。 |
| LinkedBlockingQueue   | 有界   | 1. 基于单向链表实现的有界阻塞队列。2. 容量可选，空参构造时为Integer.MAX_VALUE，相当于无界队列。 |
| LinkedBlockingDeque   | 有界   | 1. 基于双向链表实现的阻塞双端队列。2. 容量可选，空参构造时为Integer.MAX_VALUE，相当于无界队列。 |
| PriorityBlockingQueue | 无界   | 1. 基于优先级堆实现的无界优先级阻塞队列。2. 允许插入NULL元素。3. 元素必须实现 Comparable接口，用于队列排队。 |
| DelayQueue            | 无界   | 1. Delayed元素（标记了给定延迟后应作用的对象）、底层依赖PriorityQueue的无界优先级队列。2. 元素必须实现Delayed接口，同时需要实现Comparable接口，一般情况下按照过期时间的优先级排序。3. 使用场景：定时关闭连接、缓存对象、超时处理 |
| DelayedWorkQueue      | 无界   | 1. ScheduledThreadPoolExecutor延迟线程池的内部类、基于小顶堆的数据结构的、专门的延迟任务队列。2. 元素需要实现RunnableScheduledFuture接口。 |
| SynchronousQueue      | 有界   | 1. 同步队列，其容量为0，不存储任何元素，每个插入操作都会阻塞等待另一个线程进行相应的删除操作才会恢复，take和put需要配对使用。2. 利用自旋 + LockSupport方式阻塞 + CAS乐观锁方式实现栈或者队列结构实现，全程没有使用悲观锁也能保证同步，吞吐量高。 |

| LinkedTransferQueue   | 无界   | 1. 基于链表实现的无界消息阻塞队列，一个新增的元素会与一个删除的空元
素配对。2. 比其他队列多了 transfer（）和tryTransfer（）方法，用于数据交换。3. 既有同步队列中生产者与消费者的特性，也包含了对高并发无锁CAS + 自旋的优化，通过跳过2个结点才更新head指针，减少一半线程的CPU自旋损耗，又利用LockSupport.park（）来实现BlockingQueue的阻塞特性，还提供了异步非阻塞、延迟消费消息的方法。 |

##### BlockingQueue接口方法

|          | 抛出异常                   | 特殊值（null或者false，取决于具体实现） | 阻塞                 | 超时                                                        |
| -------- | -------------------------- | --------------------------------------- | -------------------- | ----------------------------------------------------------- |
| **插入** | {@link #add add(e)}        | {@link #offer offer(e)}                 | {@link #put put(e)}  | {@link #offer(Object, long, TimeUnit) offer(e, time, unit)} |
| **删除** | {@link #remove remove()}   | {@link #poll poll()}                    | {@link #take take()} | {@link #poll(long, TimeUnit) poll(time, unit)}              |
| **检索** | {@link #element element()} | {@link #peek peek()}                    | 不适用               | 不适用                                                      |

#### 拒绝策略

![1629794826356](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629794826356.png)

- 当Executor已经关闭，或者当Executor对最大线程数和工作队列容量已经饱和时，在
  {@link #execute(Runnable)} 方法中提交的新任务将被 {@link RejectedExecutionHandler} 的{@link
  RejectedExecutionHandler#rejectedExecution(Runnable, ThreadPoolExecutor)} 拒绝。

| 实现类              | 特性                                                         | 优点                                                         |
| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| AbortPolicy         | 默认的拒绝策略，在任务被拒绝时，会抛出运行时异常             | 可以阻止系统正常运行                                         |
| CallerRunsPolicy    | 调用execute时，线程自己会去运行任务，提供了一个简单的反馈控制机制，可以减慢提交新任务的速度 | 不会造成任务丢失，同时减缓提交任务的速度，给执行任务缓冲时间 |
| DiscardPolicy       | 被拒绝时，任务会被简单地丢弃                                 | 如果允许任务丢失，这是最好的一种方案                         |
| DiscardOldestPolicy | 如果Executor没有关闭，工作队列头部的任务被丢弃，然后重试执行，但可能会再次失败，导致重复执行 | 丢弃最老的一个请求，也就是**即将被执行的任务**，并尝试再次提交当前任务 |

#### 线程池调优

##### 线程池大小设置

需要先确认任务的类型，分为CPU密集型任务、IO密集型任务、混合型任务，以下都是经验公式以及通过工具粗略计算得出的范围，而最优的参数还是需要在实际环境中**不断压测、调优**才能得到的。

- **CPU密集型任务**：
  - **概念**：CPU密集型指定的是，任务需要大量的运算，没有阻塞，CPU一直全速运行。
  - **目的**：需要尽可能少的线程数量，以减少线程上下文切换的次数，提高CPU的利用率，一般此时合理的目标线程数为（CPU核数 + 1）。
  - **经验公式**：N + 1。
- **IO密集型任务**：
  - **概念**：IO密集型指的是，任务大量时间都花在IO的阻塞上，希望的是CPU尽可能去调度其他任务，而不是等待线程，浪费CPU资源，因此需要更多的线程数以供CPU调度。
  - **目的**：需要尽可能多的线程数，但过多的线程数会带来过多的上下文切换，因此要适度，一般此时合理的目标线程数为（CPU核数 * 2）。
  - **经验公式**：2 * N。
- **混合型任务**：
  - **概念**：既有CPU密集型任务，又有IO密集型任务。
  - **经验公式**：N * U * （1 + WT / ST） = CPU核心数 * 目标CPU利用率 * （1 + 平均线程等待时间 / 平均线程运行时间），当**目标CPU利用率为100%**时，等于 CPU核心数 * （1 + 平均线程等待时间 / 平均线程运行时间）。
    - N为CPU核心数，U为目标CPU利用率，WT为线程等待时间，ST为线程运行时间。
    - 观察公式可得，**如果平均线程等待时间越长，则需要的线程数越多；如果平均线程运行时间越短，则需要的线程越少**。
  - **相关工具**：使用VisualVM观察、继承PoolSizeCalculator工具类粗略计算。

##### 阻塞队列设置

- **内存上**：估算单个任务占用内存，以及线程池计划占用内存。
- **排队策略上**：
  - **直接交接**：
    - **实现举例**：工作队列的一个很好的默认选择是 {@link SynchronousQueue}，它将任务交给线程而不用其他方式保留它们。在这里，如果没有线程可立即运行，则将任务排队的尝试将失败，因此将构
      建一个新线程。 
    - **适用场景**：在处理可能具有内部依赖性的请求集时，**可避免锁定**。
    - **缺点**：直接切换通常需要无限的maximumPoolSizes以避免拒绝新提交的任务，所以局限在于，当命
      令平均持续到达速度快于它们可以处理的速度时，可能会出现**无限线程的增长问题**。
  - **无界队列**：
    - **实现举例**：使用无界队列（如没有预定义容量的 {@link LinkedBlockingQueue}）将导致新任务在所有 corePoolSize 线程都忙时在队列中等待。因此，不会创建超过 corePoolSize 的线程，也即设置的maximumPoolSize没有任何作用。
    - **适用场景**：当**每个任务完全独立于其他任务**时，这可能是合适的，因此任务不会影响彼此的执行。例如，在网页服务器中。
    - **缺点**：虽然这种排队方式在平滑请求的**瞬时爆发**方面很有用，但局限在于，当命令的平均到达速度超
      过它们的处理速度时，**工作队列可能会无限增长**。
  - **有界队列**：
    - **实现举例**：有界队列（如{@link ArrayBlockingQueue}）在与有限的 maximumPoolSizes 一起使用。
    - **优点**：有助于**防止资源耗尽**。
    - **缺点**：可能更难以调整和控制。

##### 池大小与队列调优总结

- 当使用**有界队列**来构造**有界线程池**时，队列大小和最大池大小会**相互制衡**：
  - **使用大队列和小池**：
    - 可以最大限度地减少CPU使用率、操作系统资源和上下文切换开销。
    - 但可能会导致人为地降低吞吐量，如果任务频繁阻塞，则任务可能需要更长的响应时间。
  - **使用小队列和大池**：
    - 这会使CPU更忙，可能会遇到不可接受的线程调度开销，降低吞吐量。

#### Executors便捷构造方法

![1629794884916](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629794884916.png)

- **Executors便捷构造方法的弊端**：
  - FixedThreadPool、SingleThreadExecutor、ScheduledThreadPool、ScheduledThreadPoolExecutor：使用无界的任务队列，有可能会导致OOM。
  - CachedThreadPool、ScheduledThreadPool、ScheduledThreadPoolExecutor：使用无界的线程池，允许创建最大线程数为 Integer.MAX_VALUE，可能会导致OOM。
- **解决方案**：不建议使用Executors便捷构造，建议专门指定参数来创建线程池，底层使用有界队列以及创建有界线程池，以防止OOM。

| 方法                           | 参数                                                         | 线程池实例类型              | 特性                                                         |
| ------------------------------ | ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| newCachedThreadPool            | 0核心线程数，MAX最大线程数，60秒保活时间，同步队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 缓存型、无界线程池，会先查看线程能否复用，有就复用，没有就新建，且具有自动回收线程的功能。2. 适用于生存周期很短的异步任务，或者负载较轻的服务。 |
| newFixedThreadPool             | n核心线程数，n最大线程数，0秒保活时间，无界阻塞队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 固定大小线程池，任意时间最多只有固定数目的活动线程存在。2. 适用于线程数比较稳定的并发场景，或者执行长期的任务。 |
| newSingleThreadExecutor        | 1核心线程数，1最大线程数，0秒保活时间，无界阻塞队列，默认线程工厂，拒绝时抛出异常 | ThreadPoolExecutor          | 1. 单后台线程池，任意时间最多只有一个活动线程存在，可以保证任务按照提交顺序执行。2. 适用于需要严格控制执行顺序的场景。 |
| newScheduledThreadPool         | n核心线程数，MAX最大线程数，0秒保活时间，延迟任务无界队列，默认线程工厂，拒绝时抛出异常 | ScheduledThreadPoolExecutor | 1. 调度型线程池，拥有调度能力。2. 适用于执行定时任务或者延期任务。 |
| newScheduledThreadPoolExecutor | 1核心线程数，MAX最大线程数，0秒保活时间，延迟任务无界队列，默认线程工厂，拒绝时抛出异常 | ScheduledThreadPoolExecutor | 1. 调度型线程池，拥有调度能力，但核心线程只有一个。2. 适用于执行定时任务或者延期任务。 |
| newWorkStealingPool            | 等于CPU核数的并发线程数， 默认ForkJoin线程工厂，异步模式     | ForkJoinPool                | 1. 创建一个ForkJoinPool。2. 适用于分而治之、递归计算的CPU密集型场景 |

#### 如何优雅地关闭线程池？

优雅地关闭线程池，指的是允许任务丢弃，**保证所有线程被中断退出**。

1. 使用Runtime.getRuntime（）.**addShutdownHook**（ ShutdownHookThread, Callable）注册线程池关闭任务，其任务逻辑为：
2. 先调用**shutdown（）**拒绝接收新任务，结合**awaitTermination（long）**指定估计等待时间（比如60s），同步等待线程处理任务完毕。
3. 如果awaitTermination（）返回true，可以提前返回；如果awaitTermination（）返回false，说明预估的时间到了仍然没处理完，或者抛出中断异常，说明当前等待线程中用户中断了，则调用**shutdownNow（）**拒绝处理任务队列任务。
4. 最后模仿Dubbo框架中线程池关闭源码的部分代码，补充检测线程池状态是否为TERMINATED，如果仍然没关闭，则1000次**循环awaitTermination（）等待 +  shutdownNow（）**中断所有线程，如果抛出异常则记录日志。

#### 线程池其中一个线程异常会发生什么？

##### execute调用

1. 当异常线程是被execute调用时，在ThreadPoolExecutor#runWorker（）中，如果没有实现钩子方法处理异常，则**会抛出Throwable异常**。

2. 接着调用finally块的processWorkerExit(w, completedAbruptly)方法，由于completedAbruptly为true，所以会先从工作线程集合中移除这个异常的Worker，然后重新生成一个新的Worker加入到工人集合中，**以实现替换**。

   ```java
   // 使用指定工人运行任务: 先获取firstTask -> 从任务队列中获取任务 -> beforeExecute -> 运行获取到的任务 -> afterExecute -> 线程运行后的清理工作processWorkerExit
   final void runWorker(Worker w) {
       // 获取当前线程wt， 用于运行beforeExecute方法
       Thread wt = Thread.currentThread();
   
       // 获取要运行的初始任务task
       Runnable task = w.firstTask;
       w.firstTask = null;
   
       // 先释放锁, 同步器状态从-1更改为0, 允许中断当前线程
       w.unlock(); // allow interrupts 允许中断
   
       // worker需要突然死亡
       boolean completedAbruptly = true;
       try {
           // 执行阻塞或定时等待任务, 如果需要淘汰线程, 则使用存活时间定时获取任务, 在获取不到时则标记超时等待下一轮清空多余线程; 如果不需要淘汰线程, 则阻塞获取任务
           // 通过worker里的线程启动后, 自旋获取任务队列中的任务, 实现线程复用!!! 通过存活时间、核心线程与任务队列, 控制资源消耗
           while (task != null || (task = getTask()) != null) {
               // 如果任务不为空, 则获取worker锁, 设置当前线程为独占线程
               w.lock();
   
               // 如果运行状态为停止(不接受新任务)、整理(任务终止)、终止状态(已完成), 且线程已被中断, 但当前线程中断标记位不为true, 则中断当前线程
               if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted())
                   // 中断当前线程, 如果从Thread其他实例方法调用该方法, 则会清除中断状态, 然后会收到一个{@link InterruptedException}
                   wt.interrupt();
               try {
                   // 执行任务前的钩子方法, 用于给子类实现回调
                   beforeExecute(wt, task);
   
                   // 运行任务
                   Throwable thrown = null;
                   try {
                       task.run();
                   } catch (RuntimeException x) {
                       thrown = x; throw x;
                   } catch (Error x) {
                       thrown = x; throw x;
                   } catch (Throwable x) {
                       thrown = x; throw new Error(x);
                   } finally {
                       // 执行任务后的钩子方法, 用于给子类实现回调, 该方法由执行任务的线程调用, t为执行任务期间抛出的Throwable
                       afterExecute(task, thrown);
                   }
               } finally {
                   task = null;
   
                   // 更新worker的任务完成数
                   w.completedTasks++;
   
                   // 释放锁, 同步器状态从1更改为0
                   w.unlock();
               }
           }
   
           // worker需要不突然死亡
           completedAbruptly = false;
       } finally {
           // 从工作线程集中删除线程, 并且可能会终止池或替换工作线程, 当指定的completedAbruptly为true时, 会先减少ctl工作线程数并替换工作线程
           processWorkerExit(w, completedAbruptly);
       }
   }
   
   ```

3. 此后由于没有任何程序捕获这个异常，将在ThreadGroup#uncaughtException（）中捕获到，并**打印出异常堆栈信息**。

   ```java
   // 当此线程组中的线程由于未捕获的异常而停止，并且该线程没有安装特定的 {@link Thread.UncaughtExceptionHandler} 时，由Java虚拟机调用
   public void uncaughtException(Thread t, Throwable e) {
       if (parent != null) {
           parent.uncaughtException(t, e);
       } else {
           Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler();
           if (ueh != null) {
               ueh.uncaughtException(t, e);
           } else if (!(e instanceof ThreadDeath)) {
               System.err.print("Exception in thread \"" + t.getName() + "\" ");
               e.printStackTrace(System.err);
           }
       }
   }
   
   ```

##### submit调用

1. 当异常线程是被submit调用时，同样在ThreadPoolExecutor#runWorker（）中，如果没有实现钩子方法处理异常，则**会抛出Throwable异常**。

2. 接着调用finally块的processWorkerExit(w, completedAbruptly)方法，由于completedAbruptly为true，所以会先从工作线程集合中移除这个异常的Worker，然后重新生成一个新的Worker加入到工人集合中，以**实现替换**。

3. 但在FutureTask#run（）程序中捕获到Throwable异常，并设置到Future#outcome结果中，因此并**不会打印异常堆栈信息**。

   ```java
   try {
       result = c.call();
       ran = true;
   } catch (Throwable ex) {
       result = null;
       ran = false;
   
       // 如果计算时发生异常, 则为异步计算结果设置异常结果, 并更新任务状态为已发生异常状态, 最后遍历等待线程堆栈结点, 并清空唤醒每个结点的线程, 并在完成前调用done方法触发子类的回调, 以及清空运行的任务
       setException(ex);
   }
   
   ```

### 2.9. Java对象结构？

Java对象（Object实例）结构包括三部分：**对象头、对象体和对齐字节**：

- **对象头**：
  - **Mark Word**：
    - 标记字，用于存储自身运行时的数据，例如GC标志位、哈希码、锁状态等信息。
    - 主要用于表示对象的线程锁状态，另外还可以用来配合GC存放该对象的HashCode。
  - **Class Pointer**：类对象指针，用于存放方法区Class对象的地址，虚拟机通过这个指针来确定这个对象是哪个类的实例。
  - **Array Length**：数组长度，是一个可选的字段。
    - 如果对象是一个Java数组，那么此字段必须有，用于记录数组的长度。
    - 如果对象不是一个Java数组，那么此字段不存在。
- **对象体**：
  - 包含对象的成员变量，包括父类的成员变量，其内存按4字节对齐。
- **对齐字节**：
  - 也叫填充对齐，用来保证Java对象所占内存字节数为8的倍数。
  - HotSpot VM的内存管理要求对象起始地址必须是8字节的整数倍，由于对象头本身是8的倍数，当对象的成员变量数据不是8的倍数时，则需要填充数据来保证8字节的对齐。

![1629615319144](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615319144.png)

#### Oop对象指针压缩

- Mark Word、Class Pointer、Array Length与JVM位数有关。
  - 在32位JVM中，它们为32位。
  - 在64位JVM中，它们为64位。
- 如果JVM中对象数量过多，想要节约内存，可以使用**+UseCompressedOops**开启指针压缩，开启后，以下类型的指针将会从64位压缩到32位：
  - Class对象的属性指针，即静态变量。
  - Object对象的属性指针，成员变量。
  - 普通对象数组的元素指针。
- 当然，也不是所有的指针都会压缩，一些特殊类型的指针不会被压缩，比如：
  - 指向PermGen（永久代）的Class对象指针，而在JDK 8的是指向元空间的Class对象指针。
  - 本地变量、堆栈元素、入参、返回值和NULL指针等。
- 在堆内存小于32GB的情况下，64位JVM的UseCompressedOops选项是默认开启的，表示会将原来64位的Oop对象指针压缩为32位。

### 3.0. Java内置锁原理？

#### 内置锁的Mark Word结构信息

- Java内置锁（synchronized）涉及很多重要信息，它们都存放在对象结构的对象头Mark Word字段中，其中Mark Word的位结构不会受到Oop对象指针压缩选项的影响。
- Java内置锁状态一共有4种，级别由低到高分别为：**无锁、偏向锁、轻量级锁和重量级锁**。
  - 在JDK 1.6之前，Java内置锁是一个重量级锁，效率比较低下。
  - 在JDK 1.6之后，为了提高锁的获取和释放的效率，JVM对synchronized的实现进行了优化，引入了偏向锁和轻量级锁。
  - 从此Java内置锁就有了以上4种状态，并且它们会随着竞争的情况逐渐升级，但不可降级。
  - Java内置锁的状态与Mark Word字段的结构强相关，为了让Mark Word字段存储更多的信息，JVM将Mark Word**最低两位**设置为Java内置锁状态位，不同锁状态对应着不同的Mark Word结构。
- 64位Mark Word与32位Mark Word类似，它们的结构信息如下图：
  - **lock**：锁状态标记位，2bit，占2个字节。由于Mark Word希望用尽可能少的二进制位表示尽可能多的信息，因此设置了lock标记，该值的不同则整个Mark Word表示的含义也不同。
  - **biased_lock**：对象是否启用偏向锁标记，1bit，占1个字节。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。
    - 因此，【lock，biased_lock】两个标记位组合在一起，共同表示Object实例处于什么样的锁状态。
    - 【01，0】表示无锁，【01，1】表示偏向锁，【00，无】表示轻量级锁，【10，无】表示重量级锁，【11，无】表示GC标记。
  - **age**：Java对象的分代年龄，4bit，占4个字节。在GC中，对象在Survivor区复制一次，年龄就增加1，当对象达到设定的阈值时，将会晋升到老年代。
    - 由于age只有4位，因此-XX：MaxTenuringThreshold选项最大值为15，即对象的年龄阈值为15。
  - **identity_hashcode**：hashcode，对象标识，哈希码，31bit，占31位字节。
    - 采用延迟加载技术，当调用Object.hashCode（）方法，或者System.identityHashCode（）方法，来计算对象的HashCode后，其结果将被写到该对象头中。
    - 当对象被锁定时，该值会移动到 Monitor监视器中。
  - **thread**：线程ID值，54bit，占54个字节，持有偏向锁的线程ID。
  - **epoch**：偏向时间戳，2bit，占2个字节。
  - **ptr_to_lock_record**：在轻量级锁的状态下，指向栈帧中锁记录的指针，62bit，占62个字节。
  - **ptr_to_heavyweight_monitor**：在重量级锁的状态下，指向对象监视器的指针，62bit，占62个字节。

![1629596133871](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629596133871.png)

![1629596155693](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629596155693.png)

#### 无锁

![1629597556442](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597556442.png)

无锁，即无线程竞争，在Java对象刚创建时，还没有任何线程来竞争，此时对象处于无锁状态。

- 此时，偏向标志位为0，锁状态标志位为01。

#### 偏向锁

![1629597869808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629597869808.png)

偏向锁，是指一段同步代码一直被同一个线程所访问，偏向锁状态下的Mark Word会记录内置锁偏爱的线程ID，从而让内置锁认定该线程为“熟人”，从而该线程可以自动获取锁，降低获取锁的代价。

- **主要解决无竞争下的锁性能问题**：由于线程ID被记录在锁对象的Mark Word中（CAS设置），以后该线程获取锁时，只需要判断一下线程ID和标志位，就可以直接进入同步块，连CAS操作都不需要，省去了大量有关锁申请的操作，消除了无锁竞争情况下的同步原语，从而提高了程序的性能。
- **偏向锁的膨胀**：
  1. 如果偏向锁已经被A占据，一旦有第二个线程B来争抢这个对象，由于偏向锁不会主动释放，所以B看到的内置锁是偏向状态，表明已经存在了竞争，则JVM会去检查原来持有该对象锁的占有线程A是否依然存活。
  2. 如果发现A已经挂了，则将锁对象变为无锁状态，然后重新偏向B线程。
  3. 如果发现A依然存活，则会进一步检查A的调用堆栈是否有锁记录持有该偏向锁。如果存在锁记录，表明原来的线程A仍然在使用该偏向锁，即A和B此时发生了锁竞争，JVM则会撤销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。
- **偏向锁的撤销**：如果锁对象经常被多个线程竞争，那么偏向锁就是多余的，并且撤销偏向锁的过程也会带来一些性能开销。
  1. 在一个安全点停止拥有锁的线程。
  2. 遍历线程的栈帧，检查是否存在锁记录，如果存在，则需要清空**锁记录**（锁记录是线程私有的，每个线程都有自己的一份锁记录），使其变为无锁状态，并修复锁记录指向的Mark Word，清除其线程ID。
  3. 将当前锁升级为轻量级锁。
  4. 唤醒当前线程。
- **偏向锁的撤销条件**：
  - 多个线程竞争偏向锁。
  - 调用偏向锁对象的hashCode（）方法，或者System.identityHashCode（）方法，计算对象的**HashCode**之后，将哈希码放置到了Mark Word中，内置锁变成无锁状态，偏向锁会被撤销。
- 经验表明，大部分情况下一个同步代码块的线程都是同一个线程，总体来说，**使用偏向锁带来的好处大于偏向锁撤销和膨胀带来的代价**。
  - 如果某些临界区存在两个或者两个以上的线程竞争，偏向锁反而会降低性能，此时可以在启动JVM时把偏向锁的默认功能关闭。

#### 轻量级锁

![1629598045639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629598045639.png)

轻量级锁，也被成为**非阻塞同步锁、乐观锁**，是指当锁处于偏向锁，又被另一个线程企图抢占时，偏向锁就会升级为轻量级锁，而企图抢占的线程会通过**自旋**的形式尝试获取锁，不会阻塞抢锁线程，以提高性能。其中，哪个线程先占有锁对象，锁对象的Mark Word就指向哪个线程栈帧中的锁记录。

- **引入轻量级锁的主要目的**：在多线程竞争不激烈的情况下，通过CAS机制竞争锁，减少重量级锁产生的性能损耗，尽可能不动用操作系统层面的互斥锁，在应用层面上通过**自旋**来解决线程同步的问题。

  - **自旋原理**：如果持有锁的线程能在很短时间内释放锁资源，竞争等待锁的线程则不需要进行内核态和用户态的切换进入阻塞状态，它们只需要CPU自旋，等待持有锁的线程释放锁后即可立即获取锁，避免了用户线程和内核切换的消耗，从而提高性能。
  - **自旋锁分类**：
    - **普通自旋锁**：指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。
      - JDK 1.6的轻量级锁使用的是普通自旋锁，需要使用-XX：+UseSpinning选项手工开启。
      - 默认情况下，自旋次数为10次，可以通过-XX：PreBlockSpin选项来进行更改。
      - 然而，线程自旋需要消耗CPU，如果一直获取不到锁，那么线程也不能一直占用CPU自旋做无用功，因此需要设定一个自旋等待的最大时间。
    - **适应性自旋锁**：
      - JVM对于自旋周期的选择，JDK 1.7引入了**适应性自旋锁**（自动开启），指的是自旋的时间不是固定式的，而是由前一次在同一个锁上的自旋时间，以及锁的拥有者状态来决定的，解决的是**锁竞争时间不确定**的问题，使得**竞争程度趋于稳定**。
      - **自旋成功了则下次自旋的次数就会更多**：如果抢锁线程在同一个锁对象上之前成功获得过锁（竞争力强，适合竞争），JVM则会认为这次自旋很可能再次成功，此次允许自旋等待持续相对更长的时间。
      - **自旋失败了则下次自旋的次数就会减少**：如果对于某个锁，抢锁线程很少成功获得过（竞争力弱，不适合竞争），JVM则减少自旋时间甚至省略自旋过程，以避免浪费CPU资源。

- **轻量级锁的抢占过程**：

  1. 在抢锁线程进入临界区之前，如果该内置锁没有被锁定，JVM首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前Mark Word的拷贝。

     ![1629601733727](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629601733727.png)

  2. 然后，抢锁线程将使用CAS自旋操作，尝试将内置锁对象头的Mark Word的ptr_to_lock_record（锁记录指针）更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，**这个线程就拥有了对象锁**。

  3. 接着，JVM将Mark Word中的lock标记位改为00，代表该内置锁对象处于轻量级锁状态。

  4. 抢锁成功之后，JVM会将Mark Word中原来的锁对象信息（如哈希码等），保存在抢锁线程锁记录中的Displaced Mark Word字段中，再将抢锁线程中锁记录的owner指针指向锁对象。

     ![1629602512221](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629602512221.png)

- **轻量级锁的膨胀**：

  - 如果临界区代码执行耗时较长，在其执行期间，其他线程都在原地CAS+自旋等待替换ptr_to_lock_record，导致一直空耗CPU，带来很大的性能损耗。
  - 而轻量级锁的本意，是**为了减少多线程进入操作系统层面互斥锁的概率**，并不是要替代其互斥锁。
  - 因此，在内置锁争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁实现的重量级锁。

#### 重量级锁

![1629599089661](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629599089661.png)

重量级锁，也称为**同步锁**，是指当锁处于轻量级锁，如果持有锁的线程执行的时间，超过了自旋等待的最大时间仍然没有释放锁，自旋等待锁的线程不会一直自旋下去，而是会进入阻塞状态，该锁也膨胀为重量级锁。

- 锁对象的Mark Word会再次发生变化，指向一个**监视器对象**，该监视器对象会用集合的形式来登记和管理排队的线程。

  - **监视器**：是一个同步工具，相当于一个许可证，拿到许可证的线程即可进入临界区进行操作，没有拿到的则需要阻塞等待。在JVM中，每个对象都关联一个监视器，监视器和对象一起创建、销毁，保证同一时间只有一个线程可以访问被保护的临界区代码。监视器也可以说是同步机制，主要特点是：
    - **同步**：监视器所保护的临界区代码互斥地执行，一个监视器是一个运行许可，任一线程进入临界区代码都需要获得这个许可，离开时会把许可归还。
    - **协作**：监视器提供Signal机制，允许正持有许可的线程暂时放弃许可进入阻塞等待状态，等待其他线程发送Signal去唤醒；其他拥有许可的线程可以发送Signal，唤醒正在阻塞等待的线程，让它可以重新获得许可并启动执行。

- 重量级锁通过**监视器**的方式，保障了任何时间只允许一个线程通过受到监视器保护的临界区代码。在Hotspot虚拟机中，监视器由C++类**ObjectMonitor**实现：

  - **_recursions**：线程的重入次数。
  - **_owner**：标识拥有该Monitor的线程，即获得锁的线程。
  - **cxq**：竞争队列，所有请求锁的线程首先会被放入这个竞争队列中。cxq由Node及其next指针逻辑构成（单向链表），并不存在一个队列的数据结构，只是一个虚拟队列：
    1. 在线程进入cxq前，抢锁线程会先尝试通过CAS自旋获取锁，如果获取不到，则会进入cxq队列，显然抢锁操作这对于那些已经进入了cxq队列的线程是不公平的，因此**synchronized同步块所使用的重量级锁是非公平锁**。
    2. 每次新加入的Node会在cxq的队头进行，通过CAS改变第一个结点的指针为新增结点，同时设置新增结点的next指向后续结点。
    3. 从cxq取出元素时，会从队尾获取。由于只有owner线程才能从队尾取出元素，即线程出列操作无争用，因此cxq是**无锁结构**。
  - **_EntryList**： 候选竞争队列，由于cxq会被线程并发访问，为了降低对cxq队尾的争用，在owner线程释放锁时，JVM会从cxq中迁移线程到EntryList中，并会指定EntryList中某个线程（一般为Head）为OnDeck Thread（Ready Thread），因此EntryList中的线程是作为候选竞争线程而存在的。
    - **OnDeck Thread**：
      - JVM不直接把锁传递给Owner Thread，而是把锁竞争的权利交给OnDeck Thread，On Deck需要重新竞争锁，这种行为称为**竞争切换**，虽然牺牲了一些公平性，但极大提升了系统的吞吐量。
      - OnDeck Thread获取到锁资源后将会变为Owner Thread，无法获得锁的OnDeck Thread则会依然留在EntryList中。
      - 另外，在OnDeck Thread成为Owner的过程中，还要一个**不公平**的事情：后来的新抢锁线程可能会直接通过CAS自旋成为Owner而获得锁。
  - **_WaitSet**：等待队列，某个拥有ObjectMonitor的线程（owner线程）在调用Object.wait（）方法之后将被阻塞，然后该线程将被放置在 _WaitSet链表中，直到某个时刻通过Object.notify（）或者Object.notifyAll（）唤醒后，该线程才会重新进入EntryList中继续候选竞争锁。

  ![1629615372409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629615372409.png)

- **重量级锁性能低**：重量级锁使用了操作系统底层的互斥锁（Mutex Lock），会导致线程在**用户态和内核态之间的频繁切换**，从而带来较大的性能损耗。

  - 处于cxq、EntryList、WaitSet中的线程都处于阻塞状态，线程的阻塞或者唤醒，都需要操作系统来帮忙。比如在Linux内核中采用pthread_mutex_lock系统调用（互斥锁）来实现，因此，进程需要从用户态切换到内核态。
  - 进程从用户态切换到内核态，这种切换需要消耗很多时间，有可能比用户执行代码的时间还要长，而由于轻量级锁使用CAS进行自旋抢锁，都处于用户态下，进程不存在用户态和内核态之间的切换，因此轻量级锁开销较小，而重量级锁使用了Linux内核态下的互斥锁，会造成较大的性能开销。

#### 执行过程总结

![1629617805708](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617805708.png)

![1629617826584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629617826584.png)

synchronized执行过程总结：

1. **确认是否为可偏向状态**：线程抢锁时，JVM首先检测内置锁对象Mark Word中的biased_lock（偏向锁标识）是否设置成1，lock（锁标志位）是否为01，如果都满足，则确认内置锁对象为**可偏向状态**。
2. **确认线程ID**：在内置锁对象确认为可偏向状态后， JVM会检查Mark Word中的线程ID是否为抢锁线程的ID。
3. **同线程ID，直接执行临界区代码**：如果是，则表示抢锁线程处于偏向锁状态，然后抢锁线程快速获得锁，开始执行临界区代码。
4. **竞争锁成功，升级为偏向锁**：如果Mark Word中的线程ID并未指向抢锁线程，则通过CAS操作去竞争锁。
   - 如果竞争成功，则将Mark Word中的线程ID设置为抢锁线程，偏向标志位设置为1，锁标志位设置为01，然后执行临界区代码，此时内置锁对象为**偏向锁状态**。
5. **发生锁竞争失败，偏向锁升级为轻量级锁**：如果CAS操作竞争失败，说明发生了竞争，此时JVM会去检查原先持有锁的线程是否存活。
   - 如果原线程已经死亡，则设置Mark Word为抢到锁的线程ID，内置锁继续保持为偏向锁。
   - 如果原线程没有死亡，且其堆栈中存在该内置锁的所记录，则需要撤销偏向锁，进而升级为**轻量级锁**（继续由原持有锁线程持有）。
6. **其他线程继续CAS竞争，以获取轻量级锁**：如果仍然有其他线程继续竞争轻量级锁，则在JVM将在替换锁对象Mark Word中的ptr_to_lock_record过程中，使用**CAS替换**为抢锁线程的锁记录指针。
   - 如果替换成功，则代表抢锁线程获得了**轻量级锁**。
   - 如果替换失败，表明存在其他线程竞争锁，则JVM接着尝试使用**CAS+自旋**方式来替换。
     - 如果替换成功，代表抢锁成功，则锁对象继续保持为**轻量级锁状态**。
7. **CAS+自旋失败，轻量级锁升级为重量级锁**：如果CAS+自旋替换失败，即超过了最大自旋次数，轻量级锁则升级为重量级锁，此后等待锁的线程都需要进入**阻塞状态**。

**总的来说**：

1. **偏向锁**是在没有发生锁争用的情况下使用的。
2. 一旦有了第二个线程争用锁，偏向锁则会升级为**轻量级锁**。
3. 如果锁争用很激烈，轻量级锁的CAS+自旋到达自旋阈值后，轻量级锁则会升级为**重量级锁**。

#### 适用场景总结

| 锁       | 优点                                                         | 缺点                                           | 适用场景                                 |
| -------- | ------------------------------------------------------------ | ---------------------------------------------- | ---------------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的消耗，和执行非同步方法比，仅存在纳秒级的差距 | 如果线程间存在锁竞争，则会带来额外的锁撤销消耗 | 适用于只有一个线程访问临界区的场景       |
| 轻量级锁 | 竞争的线程不会阻塞，提高程序的响应速度                       | 抢不到锁竞争的线程会使用CAS自旋等待，会消耗CPU | 锁占用时间很短，追求响应时间，但吞吐量低 |
| 重量级锁 | 线程竞争不使用自旋，不会消耗CPU                              | 使用系统互斥锁，线程阻塞，响应时间缓慢         | 吞吐量高，追求吞吐量，但锁占用时间较长   |

#### 锁消除

锁消除是指，JVM在 JIT编译时，通过对运行上下文的扫描，经过逃逸分析，去除不可能存在共享资源竞争的锁（没发生逃逸的变量作为内置锁对象时），消除没有必要的锁，节省毫无意义的锁请求时间，以提高性能。

#### 锁粗化

锁粗化是指，将多个连续的加锁和解锁操作连接在一起，扩展成一个范围更大的锁，避免频繁的加锁和解锁操作。

- **JVM默认是开启锁消除和锁粗化的**。
- 也可以通过-server -XX：-DoEscapeAnalysis -XX：-EliminateLocks来关闭锁消除和锁粗化。

### 3.1. Java锁分类？

- 显示锁分类有：可重入锁和不可重入锁、悲观锁和乐观锁、公平锁和非公平锁、可中断锁和不可中断锁、共享锁和独占锁。
- 其他锁概念有：互斥锁和读写锁、分段锁、自旋锁、偏向锁、轻量级锁、重量级锁。

#### 可重入锁和不可重入锁

- 从**同一个线程是否可以重复占有同一个锁对象**的角度来分：
  - **可重入锁**：也叫作递归锁，指的是一个线程可以**多次**抢占同一个锁。
  - **不可重入锁**：与可重入锁相反，指的是一个线程只能抢占**一次**同一个锁。
- JUC的ReentrantLock类是可重入锁的一个标准实现类，而synchronized内置锁逻辑上也是可重入的。

#### 悲观锁和乐观锁

- 从**线程进入临界区前是否锁住同步资源**的角度来分：
  - **悲观锁**：先锁再用。
    - 就是悲观思想，每次进入临界区操作数据的时候都认为别的线程会修改，所以线程每次在读写数据时都会**上锁**，锁住同步资源，这样其他线程需要读写这个数据时就会**阻塞**，一直等到拿到锁。
    - 总体来说，悲观锁适用于**写多读少**的场景，遇到**高并发写时性能高**。
  - **乐观锁**：用时检查。
    - 是一种乐观思想，每次去拿数据的时候都认为别的线程不会修改，所以**不会上锁**，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复**读-比较-写**的操作。
    - 总体来说，乐观锁适用于**读多写少**的场景，遇到**高并发写时性能低**。
    - Java中的乐观锁基本都是通过CAS自旋操作实现的，但在争用激烈的场景下，CAS自旋会出现大量的**空自旋**，会导致乐观锁性能大大降低。
- Java的synchronized轻量级锁是一种乐观锁，synchronized重量级锁、ReentrantLock是一种悲观锁。

#### 公平锁和非公平锁

- 从**线程抢占锁的机会是否公平、平等**的角度来分：
  - **公平锁**：指不同的线程抢占锁的机会是公平的、平等的，从抢占时间上来说，先对锁进行抢占的线程**一定**被先满足，抢锁成功的**次序体现为FIFO（先进先出）顺序**。简单来说，公平锁就是保障各个线程获取锁都是按照顺序来的，**先到的线程先获取锁**。
    - **优点**：所有的线程都能得到资源，不会饿死在队列中，适合大任务使用。
    - **缺点**：**吞吐量会下降**，队列里面除了第一个线程，其他的线程都会阻塞，CPU唤醒阻塞线程的开销大。
  - **非公平锁**：指不同的线程抢占锁的机会是非公平的、不平等的，从抢占时间上来说，先对锁进行抢占的线程**不一定**被先满足，抢锁成功的**次序不会体现为FIFO（先进先出）顺序**。
    - **优点**：非公平锁由于线程有机会提前插队抢锁，减少了线程挂起的概率，从而减少了一些唤醒线程的开销，**因此整体的吞吐量会比公平锁的高点**。
    - **缺点**：可能会导致线程饥饿问题，即队列中的线程可能会一直获取不到锁，或者长时间获取不到锁。
- 默认情况下，ReentrantLock实例是非公平锁，但是，如果在实例构造时传入了参数true，所得到的锁就是公平锁。另外，ReentrantLock的tryLock（）是一个特例，无论ReentrantLock实例是公平的还是非公平的，都会进行非公平的方式抢锁，即一旦有线程释放了锁，正在tryLock的线程就能优先取到锁，即使已经有其他线程在等待队列中。
- **公平锁效率低原因**：
  - 公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在等待，如果有，则要将当前线程挂起，并加到队列，由于没有抢锁机制，导致每次都要唤醒队列最前面线程，这样相比较非公平锁就多了一次**线程的挂起和唤醒**。
  - 而对于非公平锁，后来的线程**有一定几率**逃离被挂起的开销，因此减少了线程挂起和唤醒的几率，整体上提高了吞吐量。**因此整体的吞吐量会比公平锁的高点**。

#### 可中断锁和不可中断锁

- 从**线程抢锁等待时是否会响应中断**的角度来分：
  - **可中断锁**：如果某一线程A正占有锁在执行临界区代码，另一线程B正在阻塞式抢占锁，可能由于**等待时间过长**，线程B不想等待了，想先处理其他事情，我们可以让它**中断自己的阻塞等待**，这种就是可中断锁。
  - **不可中断锁**：一旦这个锁被其他线程占有，如果自己还想抢占，**只能选择等待或者阻塞**，直到别的线程释放这个锁，如果别的线程永远不释放锁，那么自己只能**永远等下去**，并且没有办法终止等待或阻塞。
- Java的synchronized内置锁就是一个不可中断锁，而JUC的显式锁（如ReentrantLock）是一个可中断锁。

#### 共享锁和独占锁

- 从**每次是否只有一个线程能持有锁**的角度来分：
  - **独占锁**：
    - 指每次**只有一个线程**能持有的锁。独占锁是一种悲观保守的加锁策略，它不必要地限制了读读竞争，如果某个只读线程获取锁，那么其他的读线程都只能等待，这种情况下就**限制了读操作的并发性**，因为读操作并不会影响数据的一致性。
    - JUC的ReentrantLock类是一个标准的独占锁实现类。
  - **共享锁**：
    - 允许**多个线程**同时获取锁，容许线程并发进入临界区。与独占锁不同，共享锁是一种乐观锁，它放宽了加锁策略，并**不限制读读竞争**，允许多个执行读操作的线程**同时访问共享资源**。
    - JUC的ReentrantReadWriteLock（读写锁）类是一个共享锁实现类。使用该读写锁时，读操作可以有很多线程一起读，但是写操作只能有一个线程去写，而且在写入的时候，别的线程也不能进行读的操作。

#### 互斥锁和读写锁

- 上面讲的共享锁和独享锁是一种广义的说法，而互斥锁与读写锁是指**具体的实现**。
- **JDK中的互斥锁和读写锁实现有**：
  - **互斥锁**：ReentrantLock。
  - **读写锁**：ReadWriteLock。
- 用ReentrantLock锁替代ReentrantReadWriteLock锁虽然可以保证线程安全，但是也会浪费一部分资源，因为多个读操作并没有线程安全问题，所以在读的地方使用ReentrantReadWriteLock读锁，在写的地方使用ReentrantReadWriteLock写锁，可以**提高程序执行效率**。

#### 偏向锁、轻量级锁和重量级锁

- 这些锁指的是**Synchronized的锁状态**，在Java 5通过引入锁升级的机制来实现高效Synchronized，详细介绍如上。
- **偏向锁**：
  - 是指一段同步代码**一直被一个线程所访问**，那么该线程会自动获取锁，从而降低获取锁的代价。
- **轻量级锁**：
  - 是指当锁是偏向锁的时候，**被另一个线程所访问**，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
- **重量级锁**：
  - 是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当**自旋一定次数**的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。
  - 重量级锁会让其他申请的线程进入阻塞，性能降低。

#### 分段锁

- 分段锁，是一种**锁的设计思想**，并不是具体的一种锁，目的是**细化锁的粒度**，对于ConcurrentHashMap而言，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作，通过分段锁的形式来实现高效的并发操作。
- ConcurrentHashMap中的分段锁称为Segment， 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的**并行插入**。

#### 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是**采用循环的方式去尝试获取锁**。

- **优点**：减少线程上下文切换的消耗。
- **缺点**：循环会消耗CPU，如果出现大量的空自旋，可能还会导致总线风暴。

##### CLH自旋锁

- CLH锁，是一种基于队列排队（单向链表）的自旋锁，由于是Craig、Landin和Hagersten三人一起发明的，因此被命名为CLH锁，也叫CLH队列锁，能够确保无饥饿性、提供先来先服务的公平性。

  - 申请线程只在本地变量上**普通自旋**，不断**轮询前驱的状态**，如果发现前驱释放了锁就结束自旋，成功获取锁。
  - 因此，在节点加入队列之后，抢锁线程不需要进行CAS自旋，只需普通自旋即可，在争用激烈的场景下，**可以大大减少CAS操作的数量，以避免CPU的总线风暴**。

- **CLH自旋锁的大致流程**：

  1. 初始状态队列尾部属性tail，指向一个EMPTY节点。
  2. 线程在抢锁时，会创建一个新的Node加入等待队列尾部，此时tail指向该Node，同时该Node的preNode属性指向tail之前指向的节点（第一个时为EMPTY节点），并且该操作是通过CAS自旋完成的，以确保操作成功。
  3. 线程加入抢锁队列之后，如果不为头结点，则会在前驱节点上自旋，循环判断前驱节点的locked属性是否为false。如果为false就表示前驱节点释放了锁，当前线程抢占到锁，当线程抢到锁之后，**其locked属性一直为true，代表正在使用锁**。
  4. 等到该线程临界区代码执行完，然后调用unlock（）方法释放锁，设置node的前驱引用为null，更新locked属性才为false，代表成功释放了锁。

  ![1630134819633](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630134819633.png)

  ![1630134919788](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630134919788.png)

- **CLH自旋锁的优缺点**：

  - **优点**：空间复杂度低，如果有N个线程、L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O(L+N)，N个线程有N个Node，L个锁有L个Tail。
  - **缺点**：在NUMA架构的CPU平台上性能很差，如果在NUMA架构上使用CLH自旋锁，每个CPU内核有自己的内存，如果前驱节点在不同的CPU内核上，且其内存位置比较远，在CLH自旋判断前驱节点的locked属性时，性能将大打折扣。而CLH锁在SMP架构的CPU平台上则不存在这个问题，性能还是挺高的。
  - **解决方案**：使用MCS队列锁来提升NUMA架构下自旋锁的性能。

##### MCS自旋锁

与CLH自旋锁最大的不同是**线程自旋的规则不同**，CLH是在前驱结点的locked域上自旋等待，而MCS是在**自己的结点的locked域上自旋等待**，从而解决了CLH在NUMA系统架构中，获取locked域状态内存过远的问题。

- **MCS自旋锁的大致流程**：

  1. 队列初始化时没有结点，tail=null。
  2. 线程A想要获取锁，于是将自己置于队尾，由于它是第一个结点，**其locked域为false，表示获得了锁**。
  3. 线程B和C相继加入队列，此时a -> next=b, b -> next=c，尾指针指向线程C对应的结点。由于B和C现在没有获取锁，处于等待状态，所以它们的locked域为true。
  4. 线程A释放锁后，顺着它的next指针找到了线程B，并把B的locked域设置为false，触发线程B获取锁。

  ![1630136366948](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630136366948.png)

### 3.2. Java锁优化？

- **系统层面上**：偏向锁、轻量级锁、重量级锁、适应性自旋锁、CLH自旋锁、MCS自旋锁、锁消除、锁粗化。
- **使用层面上**：
  - **减少锁的时间**：不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放。
  - **减少锁的粒度**：将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间，java中很多数据结构都是采用这种方法提高并发操作的效率，比如分段锁。
  - **锁粗化**：大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度，比如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的。
  - **锁分离**：使用读写锁，ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写。
  - **无锁**：使用CAS，如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用CAS效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+CAS操作会是非常高效的选择。

### 3.3. 并发编程三大问题？

要想并发程序正确地执行，必须要保证**原子性、可见性以及有序性**。只要有一个没有得到保证，就有可能会导致程序运行不正确。而由于需要尽可能释放CPU的能力，因此在CPU上不断增加内核和缓存，而随着**CPU内核和缓存的增加**，导致了并发编程的**可见性**和**有序性**问题。

#### 原子性问题

所谓原子操作，就是**不可中断的一个或一系列操作**，是指不会被线程调度机制打断的操作。这种操作一旦开始，就一直运行到结束，中间不会有任何线程的切换。

- **问题发生原因**：线程并发操作时，发生了意想不到的调度或者中断。
- **解决方案**：互斥锁、乐观锁（CAS）。
- **场景举例**：比如i++操作。

#### 可见性问题

一个线程对共享变量的修改，另一个线程能够立刻可见，我们称该共享变量具备**内存可见性**。

- **问题发生原因**：线程并发执行，**某些线程读到了没及时刷到主内存的值**，导致最后并发操作后刷回主存的值发生错误。

  - JMM（Java Memory Model，**Java内存模型**）规定，将所有的变量都存放在公共主存中，当线程使用变量时会把主存中的变量复制到自己的工作空间（或者叫私有内存）中，线程对变量的读写操作，是自己工作内存中的变量副本。

- **解决方案**：

  - 所有线程都将共享变量**刷新到主存**，比如使用Java提供的关键字volatile修饰共享变量。
  - 硬件层面可由**MESI协议**来解决。

- **场景举例**：

  1. 主存中有变量sum，初始值为0。
  2. 线程A计划将sum加1，先将sum=0复制到自己的私有内存中，然后更新sum的值。线程A操作完成之后其私有内存中sum的值为1，然而线程A将更新后的sum值回刷到主存的时间是**不固定**的。
  3. 在线程A没有回刷sum到主存前，刚好线程B同样从主存中读取sum，此时值为0，和线程A进行同样的操作，最后期盼的sum=2目标没有达成，最终sum=1。
  4. 最终导致，虽然发生了两次+1操作，但结果只增加了1，导致结果不对，原因为线程A的修改还在其工作内存中，还没有刷入主存，**对线程B不可见**，此时线程B读取到了主内存中的值并发执行了+1操作。

  ![1629965063896](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629965063896.png)

#### 有序性问题

所谓程序的有序性，是指程序**按照代码的先后顺序执行**。如果程序执行的顺序与代码的先后顺序不同，并导致了错误的结果，即发生了有序性问题。

- **问题发生原因**：发生了**指令级重排序**，虽然不会影响单个线程的执行，但是会影响多个线程并发执行的正确性。

- **解决方案**：Java中使用**volatile**关键字可以解决指令重排序的问题。

- **场景举例**：x、y赋值操作发生在a、b赋值操作之前，导致出现（0，0）的结果。

  ![1629966035812](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629966035812.png)

### 3.4. 字节序列大小端问题？

- **背景**：
  - 第一大阵营是PowerPC系列CPU，采用**大端模式**存放数据。
  - 第二大阵营是X86系列CPU，采用**小端模式**存放数据。
- **大端模式**：
  - 是指数据的**高字节保存在内存的低地址**中，而数据的**低字节保存在内存的高地址**中。
  - 大端存放模式有点类似于把数据当作字符串顺序处理：**地址由小向大增加，而数据从高位往低位放**。
  - **适用场景**：由于所有网络协议都是采用大端模式来传输数据的，因此有时也会把大端模式称为**“网络字节序”**。当两台采用不同字节存放模式的主机通信时，在发送数据之前，都必须经过字节次序转换，转成“网络字节序”（大端模式）后再进行传输。
- **小端模式**：
  - 是指数据的**高字节保存在内存的高地址**中，而数据的**低字节保存在内存的低地址**中。
  - 这种存储模式将地址的高低和数据位权有效地结合起来，**高地址部分权值高，低地址部分权值低**，此模式和日常的数字计算在方向上是一致的。
  - **适用场景**：在处理器（即CPU）的计算过程中，因为使用小端模式在数据类型转换的时候（尤其是指针转换）不用考虑地址问题，所以小端模式是**处理器的主流字节存放模式**。**JVM所采用的字节存放模式是小端模式**。

![1629896683986](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629896683986.png)

![1629896701845](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629896701845.png)

### 3.5. CPU三大架构？

- **多处理器结构**：Symmetric Multi-Processor，SMP，对称多处理器，服务器中多个CPU对称工作，每个CPU访问内存地址所需时间相同，主要特征是**共享**，包含对CPU，内存，I/O等进行共享。所有的CPU会共享一条总线，靠此总线连接主存，每个核都有自己的高速缓存，各核相对于BUS对称分布，因此，这种结构称为对称多处理器。

  - **优点**：常见的PC、手机、老式服务器都是SMP架构，其**架构简单**，但**拓展性能非常差**。
  - **缺点**：SMP能够保证内存一致性，但这些**共享的资源很可能成为性能瓶颈**，随着CPU数量的增加，每个CPU都要访问相同的内存资源，可能导致内存访问冲突，可能会导致CPU资源的浪费。

  ![1630129986362](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630129986362.png)

- **非一致存储访问结构**：Non-Uniform Memory Access，NUMA，非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个CPU组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，访问本地内存的速度将远远高于访问远地内存（系统内其它节点的内存）的速度，这也是非一致存储访问的由来。

  - **优点**：NUMA较好地解决SMP的扩展问题。
  - **缺点**：当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。

  ![1630201447035](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201447035.png)

- **海量并行处理结构**：Massive Parallel Processing，MPP，大规模并行处理，由多个 SMP 服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。

  - **优点**：每个节点只访问自己的本地资源（如内存、存储等），是一种**完全无共享**结构（节点之间数据不共享，只有通过网络连接实现的协同），因而**扩展能力最好**，理论上其扩展无限制，目前的技术可实现512个节点互联，数千个 CPU。
  - **缺点**：数据按某种规则散布到了各个节点上，**很难做高可用**；每个客户端同时连接所有节点通信，**很影响网络**。

  ![1630201176460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201176460.png)

### 3.6. CPU物理缓存架构？

- **背景**：由于CPU的运算速度比主存（物理内存）的存取速度快很多，**为了提高处理速度**，现代CPU不直接和主存进行通信，而是在CPU和主存之间设计了多层的Cache（**高速缓存**），越靠近CPU的高速缓存越快，容量也越小。
- **CPU高速缓存结构**：
  - L1高速缓存和L2高速缓存只能被一个单独的CPU内核使用，容量最小，速度最快。
    - L1高速缓存最接近CPU，容量最小（如32KB、64KB等）、存取速度最快，每个核上都有一个L1高速缓存。
    - ·L2高速缓存容量更大（如256KB）、速度低些，在一般情况下，每个内核上都有一个独立的L2高速缓存。
  - L3高速缓存被同一个CPU芯片上的所有CPU内核共享。
    - L3高速缓存最接近主存，容量最大（如12MB）、速度最低，由在同一个CPU芯片板上的不同CPU内核共享。
  - 主存由系统中的所有CPU共享，容量最大，速度最慢。

![1629962629036](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629962629036.png)

- **缓存命中过程**：
  1. CPU内核读取数据时，先从L1高速缓存中读取。
  2. 如果没有命中，再到L2、L3高速缓存中读取。
  3. 假如这些高速缓存都没有命中，则会到主存中读取所需要的数据。
- **CPU处理过程**：
  1. 先将计算需要用到的数据缓存在CPU的高速缓存中。
  2. 在CPU进行计算时，直接从高速缓存中读取数据。
  3. 在计算完成之后写回高速缓存中。
  4. 在整个运算过程完成后，再把高速缓存中的数据同步到主存。
- **高速缓存优点**：
  - 写缓冲区可以保证指令流水线持续运行，可以避免由于CPU停顿下来等待向内存**写入数据而产生的延迟**。
  - 通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，**减少对内存总线的占用**。

### 3.7. MESI缓存一致性协议？

硬件层的MESI协议是一种用于解决内存可见性问题的手段，其中，CPU主要提供了两种解决办法：**总线锁和缓存锁**。

#### 总线锁

- **背景**：操作系统提供了总线锁机制。线程总线（也叫CPU总线）是所有CPU与芯片组连接的主干道，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送控制信号，通过地址总线发送地址信号指定其要访问的部件，通过数据总线实现双向传输。

- **概念**：总线锁的意思是，在线程总线中加入一把锁，当不同的CPU内核访问同一个缓存行时，只允许一个CPU内核进行读取，该CPU内核将**独享共享内存**。

  1. 在CPU内核1要对a执行访问操作的时候，将在总线上发出一个LOCK#信号，使得其他CPU无法通过总线来访问共享主存中的数据，把CPU和主存之间的通信锁住，从而锁住变量a所在的缓存行。
  2. 这样其他CPU内核就不能操作缓存，从而阻塞其他CPU内核，使CPU内核1可以独享此共享内存，即总线被锁住，得等CPU内核1访问完，CPU内核2才能访问b。

  ![1629969079553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629969079553.png)

- **缺点**：某一个CPU**访问主存**时，总线锁把CPU和主存的通信给锁住了，其他CPU不能操作其他主存地址的数据，使得**效率低下，开销较大**。

#### 缓存锁

- **背景**：总线锁的粒度太大了，最好的方法就是**控制锁的保护粒度**，只需要保证被多个CPU缓存的同一份数据一致即可。所以引入了缓存锁（如缓存一致性机制），后来的CPU都提供了缓存一致性机制，Intel 486之后的处理器就提供了这种优化。
- **概念**：
  - 相比总线锁，**缓存锁降低了锁的粒度**，实现对共享内存的独占性访问，缓存锁（缓存一致性协议）会阻止两个CPU同时修改共享内存的数据。
  - 为了达到数据访问的一致，需要各个CPU在访问高速缓存时遵循一些协议，在存取数据时根据协议来操作，常见的协议有**MSI、MESI、MOSI**等，最常见的就是MESI协议。

#### 缓存一致性机制

缓存一致性机制就是，当某CPU对高速缓存中的数据进行操作之后，通知其他CPU将放弃存储在它们内部的缓存数据，或者从主存中重新读取。

#### 缓存一致性协议

- **背景**：在多CPU的系统中，为了保证各个CPU的高速缓存中数据的一致性，会实现缓存一致性协议，每个CPU通过嗅探在总线上传播的数据来检查自己的高速缓存中的值是否过期，当CPU发现自己缓存行对应的主存地址被修改时，就会将当前CPU的缓存行设置成**无效状态**，当CPU对这个数据执行修改操作时，会重新从系统主存中把数据读到CPU的高速缓存中。
- **高速缓存副本一致性写入模式**：
  - **直写模式**：Write-Through，在数据更新时，同时写入低一级的高速缓存和主存。
    - **优点**：操作简单，因为所有的数据都会更新到主存，所以其他CPU读取主存时都是最新值。
    - **缺点**：数据写入速度较慢，因为数据修改之后需要同时写入低一级的高速缓存和主存。
  - **回写模式**：Write-Back，数据的更新并不会立即反映到主存，而是只写入高速缓存，只在数据被**替换出高速缓存或者变成共享（S）状态**时，如果发现数据有变动，才会将最新的数据更新到主存。
    - **优点**：数据写入速度快，因为发生数据变动时不需要写入主存，所以这种模式占用总线少，**大多数CPU的高速缓存采用这种模式**。
    - **缺点**：实现一致性协议比较复杂，因为最新值可能存放在私有高速缓存中，而不是存放在共享的高速缓存或者主存中。
- **主要实现**：MSI协议、MESI协议等。

##### MSI协议

MSI协议，也叫作**写入失效协议**，采用的是**缓存回写模式**，是缓存一致性协议的基础版本。

1. c1和c2先后读取主存中的同一变量m值0。
2. c1更新m值为1后，并不会更新主存，而是通知c2使其高速缓存中的变量m失效。
3. 在c2第二次读取m时，c1会将m的最新值返回给c2，并且更新主存中m值，此时c1和c2的m值会变成共享状态，且等于主存中的m值。

![1629978291010](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629978291010.png)

##### MESI协议

MESI协议，是MSI协议的扩展，要求在每个**缓存行**（64字节，高速缓存操作的基本单位）维护两个状态位（2bit），使得每个数据位可能处于**M、E、S和I**这4种状态之一，是一种基于过期机制的高速缓存一致性保障协议。

- **MESI状态**：

  - **M：Modified**，被修改，处于Modified状态的缓存行数据只在本CPU中有缓存，且其数据与主存中的数据不一致，数据被修改过。
    1. 该缓存行的数据只在本CPU的私有高速缓存中进行了缓存，而**其他CPU中没有**，是被修改过的（Dirty），即**与主存中的数据不一致**，且没有更新到内存中。
    2. 该缓存行中的内存需要在未来的某个时间点（允许其他CPU读取主存中相应的数据之前）写回（Write Back）主存，当被写回主存之后，该缓存行的状态会变成**独享状态**。
  - **E：Exclusive**，独享的，处于Exclusive状态的缓存行数据只在本CPU中有缓存，且其数据与内存中一致，没有被修改过。
    1. 该缓存行的数据只在本CPU的私有高速缓存中进行了缓存，而**其他CPU中没有**，缓存行的数据是未被修改过的（Clean），并且**与主存中的数据一致**。
    2. 该状态下的缓存行在任何时刻被其他CPU读取之后，其状态将变成**共享状态**。
    3. 在本CPU修改了缓存行中的数据后，该缓存行的状态可以变成**Modified状态**。
  - **S：Shared**，共享的，处于Shared状态的缓存行的数据在多个CPU中都有缓存，且与主存一致。
    1. 该缓存行的数据可能在**本CPU以及其他CPU**的私有高速缓存中进行了缓存，并且各CPU私有高速缓存中的数据**与主存数据一致**（Clean）。
    2. 当有一个CPU修改该缓存行时，其他CPU中该缓存行将被作废，变成**无效状态**。
  - **I：Invalid**，无效的，该缓存行是**无效的**，可能有其他CPU修改了该缓存行。

- **MESI状态转换过程**：

  1. **初始阶段**：开始时，缓存行没有加载任何数据，所以它处于“**I状态**”。
  2. **本地写阶段**：Local Write，如果CPU内核写数据到处于“I状态”的缓存行，缓存行的状态就变成“**M状态**”。
     - 注意：处于“M状态”的缓存行，再由本地CPU写入或者读出，状态是不会改变的。
  3. **本地读阶段**：Local Read，如果本地CPU读取处于“I状态”的缓存行，很明显此缓存没有数据给它。此时分两种情况：
     - ①其他CPU的高速缓存中也没有此行数据，那么从内存加载数据到此缓存行后，将它设成“**E状态**”，表示只有本CPU有此行数据，其他CPU都没有；
     - ②其他CPU的高速缓存有此行数据，就将此缓存行的状态设为“**S状态**”。
  4. **远程读阶段**：Remote Read，假设我们有两个CPU c1和c2，如果c2需要读c1的缓存行内容，c1需要把它的缓存行内容通过主存控制器（MemoryController）发送给c2，c2接收到后将相应的缓存行状态设为“**S状态**”。在设置之前，**主存要从总线上得到这份数据并保存**。
  5. **远程写阶段**：Remote Write，其实确切地说不是远程写，而是c2得到c1的数据后，不是为了读，而是为了写，**也算是本地写**。此时由于本来数据就是从c1那里拷贝过来的，此时c2需要发出一个**RFO（Request For Owner）请求**，说明它需要拥有这行数据的权限，此后其他CPU的相应缓存行设为“**I状态**”，从而保证了数据的安全，但处理RFO请求以及设置“I状态”的过程将给写操作带来**很大的性能消耗**。

  ![1629980427644](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629980427644.png)

#### 总线风暴

CPU会通过MESI协议保障变量的缓存一致性，为了保障“缓存一致性”，不同的内核需要通过总线**来回通信**，因而所产生的流量一般被称为“**缓存一致性流量**”，而由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将成为瓶颈，这就是所谓的**总线风暴**。

- 总线风暴与CPU的架构和设计有关，并不是所有的CPU都会产生总线风暴，由于使用lock前缀指令的Java操作（包括CAS、volatile）恰恰会产生缓存一致性流量，**当有很多线程同时执行lock前缀指令操作时，在SMP架构的CPU平台上必然会导致总线风暴**。

### 3.8. 详细介绍Unsafe？

- Unsafe是位于sun.misc包下的一个类，主要提供一些用于**执行低级别、不安全的底层操作**，如**直接访问系统内存资源、自主管理内存资源**等。

- Unsafe类的全限定名为sun.misc.Unsafe，从名字中可以看出这个类对普通程序员来说是“危险”的，一般的应用开发都不会涉及此类，**Java官方也不建议直接在应用程序中使用这些类**。

  - 由于使用Unsafe类可以像C语言一样使用**指针操作内存空间**，这无疑增加了指针相关问题、内存泄漏问题出现的概率。

  - 总之，在程序中过度使用Unsafe类会使得程序出错的概率变大，使得安全的语言Java变得**不再安全**，因此对Unsafe的使用一定要慎重。

  - **Unsafe实例获取方式**：

    ```java
    // 不受信任的代码, 只能通过反射获取Unsafe类并通过其分配直接内存
    Field unsafeField = Unsafe.class.getDeclaredFields()[0];
    unsafeField.setAccessible(true);
    Unsafe unsafe = (Unsafe) unsafeField.get(null);
    
    ```

- Unsafe大量的方法都是native方法，基于C++语言实现，这些方法在**提升Java运行效率、增强Java语言底层资源操作能力**方面起到了很大的作用。

#### 操作Java变量方法

- **getObject(Object o, long offset)**：根据对象和64位地址偏移量, 获取某个Object类型Java变量的值。
- **putObject(Object o, long offset, Object x)**：根据对象和64位地址偏移量, 将x值存储到Java变量中, 其字段类型必须为Object类型。
- **staticFieldOffset(Field f)**：返回给定静态字段的位置, 任何给定的字段将始终具有相同的偏移量, 并且同一类的两个不同字段永远不会具有相同的偏移量和基数。
- **objectFieldOffset(Field f)**：返回给定字段在其类的存储分配中的位置, 任何给定的字段将始终具有相同的偏移量, 并且同一类的两个不同字段永远不会具有相同的偏移量和基数。
- **staticFieldBase(Field f)**：获取给定静态字段的基本“对象”(可能引用一个对象, 它是一个“cookie”, 不能保证是一个真正的对象, 它不应该以任何方式使用, 除了作为此类中get和put例程的参数), 如果有的话,可以通过 {@link #getInt(Object, long)} 之类的方法访问给定类的静态字段。
- **arrayBaseOffset(Class<?> arrayClass)**：返回给定数组Class的存储分配中第一个元素的偏移量。

#### 操作类和对象方法

- **defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain)**：告诉VM定义一个类。
- **allocateInstance(Class<?> cls)**：分配一个实例，但不运行任何构造函数。如果尚未初始化类，则初始化该类。

#### 操作C堆方法

- **getByte(long address)**：从给定的内存地址获取一个值。
- **putByte(long address, byte x)**：将值存储到给定的内存地址中。
- **getAddress(long address)**：从给定的内存地址获取本地指针。
- **putAddress(long address, long x)**：将本地指针存储到给定的内存地址。

#### 分配内存方法

- **allocateMemory(long bytes)**：分配一个新的本地内存块，以字节为单位给定大小。
- **reallocateMemory(long address, long bytes)**：重新分配一个新的本地内存块，以字节为单位给定大小。
- **setMemory(Object o, long offset, long bytes, byte value)**：将给定内存块中的所有字节设置为固定值(通常为零), 当对象引用为空时, 偏移量提供一个绝对基地址。
- **copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes)**：将给定内存块中的所有字节设置为另一个块的副本, 当对象引用为空时, 偏移量提供一个绝对基地址。
- **freeMemory(long address)**：释放本地内存块。

#### 系统属性方法

- **addressSize()**：获取本地指针的字节大小。
- **pageSize()**：获取本地内存页面的字节大小。

#### 多线程同步方法

- **compareAndSwapObject(Object o, long offset, Object expected, Object x)**：如果当前保持预期状态，则将Java变量原子更新为x。
- **getAndAddInt(Object o, long offset, int delta)**：以原子方式将给定值添加到给定对象o中给定偏移量处的字段或数组元素的当前值。
- **getAndSetInt(Object o, long offset, int newValue)**：在给定的偏移量处以原子方式将给定值与给定对象 o 内的字段或数组元素的当前值进行交换。
- **getObjectVolatile(Object o, long offset)**：从给定具有 volatile 加载语义的Java变量中获取引用值, 否则等同于 {@link #getObject(Object, long)}。
- **putObjectVolatile(Object o, long offset, Object x)**：使用volatile存储语义将引用值存储到给定的Java变量中。否则等同于{@link #putObject(Object, long, Object)}, 该方法会保证存储对其他线程的立即可见性。
- **putOrderedObject(Object o, long offset, Object x)**：使用volatile存储语义将引用值存储到给定的Java变量中，否则等同于{@link #putObject(Object, long, Object)}, 该方法不保证存储对其他线程的立即可见性。

#### 挂起与恢复方法

- **unpark(Object thread)**：唤醒在park上阻塞的指定线程, 如果该线程并未阻塞, 则它在后续调用park时不会被阻塞。
- **park(boolean isAbsolute, long time)**：阻塞当前线程, 直到当前线程unpark被调用、被中断、time时间过去(非绝对时为纳秒, 绝对时为毫秒, 为0时代表无限阻塞)。

#### 内存屏障方法

- **loadFence()**：确保在栅栏之前不会对loads重排序, 在栅栏后不会对loads或stores重排序。
- **storeFence()**：确保栅栏前不会对stores重排序, 在栅栏后不会对loads或stores重排序。
- **fullFence()**：确保在栅栏之前不会对loads或stores进行重新排序，而在栅栏之后则不会对stores或loads进行重新排序。

### 3.9. 详细介绍CAS？

#### 概念

- CAS，**CompareAndSwap**，比较并交换，是乐观锁的一种实现方式，是一种**无锁算法**，该算法关键依赖两个值——期望值（旧值）和新值，底层CPU利用原子操作判断内存原值与期望值是否相等，如果相等就给内存地址赋新值，否则不做任何操作。
- 操作系统层面的CAS是一条**CPU的原子指令（cmpxchg指令）**，正是由于该指令具备**原子性**，因此使用CAS操作数据时不会造成数据不一致的问题，Unsafe提供的CAS方法直接通过native方式（封装C++代码）调用了底层的CPU指令cmpxchg。
- 当CAS将内存地址的值与预期值进行比较时，如果相等，就证明内存地址的值没有被修改，可以替换成新值，然后继续往下运行；如果不相等，就说明内存地址的值已经被修改，放弃替换操作，然后重新自旋。
- **使用CAS进行无锁编程的步骤大致如下**：
  1. 获得字段的期望值（oldValue）。
  2. 计算出需要替换的新值（newValue）。
  3. 通过CAS将新值（newValue）放在字段的内存地址上，如果CAS失败就重复第（1）步到第（2）步，一直到CAS成功，这种重复俗称**CAS自旋**。
- **CAS对象字段偏移量参数概念**：可见，**对象字段偏移量**，指的是从对象结构的对象头中开始算起，落在对象体中的字节数。

![1629897755808](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629897755808.png)

#### 优点

CAS是处于用户态下的CPU指令级的原子操作，在用于线程同步时，可以不使用锁机制实现，线程也无需进入阻塞状态，没有用户态与内核态之间的切换，**性能开销较小**。

- **JDK应用场景**：
  - java.util.concurrent.atomic包中的原子类、Java AQS、显式锁以及CurrentHashMap等。
  - synchronized重量级锁涉及操作系统内核态下互斥锁的使用，其线程阻塞和唤醒需要进程在用户态到内核态的频繁切换，导致**重量级锁开销大、性能低**；synchronized轻量级锁使用CAS进行自旋抢锁，**CAS是CPU指令级的原子操作**，并处于用户态下，所以**轻量级锁的开销较小**。

#### 缺点

##### 只能保证单个变量原子性

当对一个共享变量执行操作时，可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，CAS就无法保证操作的原子性。

- **解决方案**：把多个共享变量**合并**成一个共享变量来操作。

##### 空耗CPU资源

在高并发、线程争用激烈的场景下，大量的CAS**空自旋**会浪费大量的CPU资源，大大降低了程序的性能。

- **优化思路**：当并发修改的线程少，冲突出现的机会少时，自旋的次数也会很少，CAS的性能会很高；当并发修改的线程多，冲突出现的机会多时，自旋的次数也会很多，CAS的性能会大大降低。所以，**提升CAS无锁编程效率的关键在于减少冲突的机会**，其有效方式之一是**以空间换时间**。

- **解决方案**：

  - **分散操作热点**：LongAdder，其核心思想是**热点分离**，将value值分离成一个数组，当多线程访问时，通过Hash算法将线程映射到数组的一个元素进行操作，在获取最终的value结果时，则将数组的元素求和即可。可见，LongAdder通过**以空间换时间**的方式，将原始的一个value值拆分为分布式的value值，减少了CAS时线程之间的冲突，以提升性能。

    ![1629957184893](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629957184893.png)

  - **使用队列削峰**：将发生CAS争用的线程加入一个队列中排队，降低CAS争用的激烈程度，比如JUC中非常重要的基础类抽象队列同步器AQS。

##### ABA问题

指线程A进行CAS操作，但是线程A发现M位置的数据仍然是V1，然后线程A操作成功。尽管线程A的CAS操作成功，但是不代表这个过程是没有问题的，线程A操作的数据V1可能已经不是之前的V1，而是**被线程B替换过的V1**，这就是ABA问题。

- **场景举例**：如果使用得不合理，CAS原子操作就会存在ABA问题：

  1. 现有一个LIFO（后进先出）堆栈，该堆栈使用单向链表实现，元素的插入和删除都发生在单向链表的头部。

     ![1629950310341](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1629950310341.png)

  2. 假设线程A和线程B是两个在堆栈上进行并发操作的线程，其中线程A计划从Head位置通过CAS进行元素E2的弹出操作。

  3. 在线程A刚好启动CAS的执行，但是没有开始之前，线程B抢在前面从Head位置中弹出元素E2、E1，并压入了一个新元素E3，再压入了E2，线程B完成操作之后，栈帧的Head位置的数据仍然是E2，此时head -> E2 -> E3。

  4. 但线程A认为的是head -> E2 -> E1，此时CAS将E2出栈并设置E1为头结点后，会出现head -> E1，而E3却成为了一个游离的NULL -> E3 -> NULL结点。因此，也就是在线程A执行完毕后，线程B之前压入的E3元素处于游离状态，不再存在于堆栈中，平白无故被丢掉了，这就是ABA问题引发的不正常状态。

- **解决方案**：

  - 可以使用**版本号（Version）**方式来解决。每次在执行数据的修改操作时都会带上一个版本号，版本号和数据的版本号一致就可以执行修改操作并对版本号执行加1操作，否则执行失败。
  - 由于每次操作的版本号都会随之增加，因此不会出现ABA问题，因为版本号只会增加，不会减少。

  ```java
  // 1、使用AtomicStampedReference解决ABA问题
  public class AtomicStampedReference<V> {
      // 使用原始数量、初始版本号构造
      public AtomicStampedReference(V initialRef, int initialStamp) {
          pair = Pair.of(initialRef, initialStamp);
      }
      
      // CAS+版本号更新为newReference和newStamp
      public boolean compareAndSet(V   expectedReference,
                                   V   newReference,
                                   int expectedStamp,
                                   int newStamp) {
          Pair<V> current = pair;
          return
              expectedReference == current.reference &&
              expectedStamp == current.stamp &&
              ((newReference == current.reference &&
                newStamp == current.stamp) ||
               casPair(current, Pair.of(newReference, newStamp)));
      }
  }
  
  // 2、或者使用AtomicMarkableReference解决ABA问题
  public class AtomicMarkableReference<V> {
      // 使用原始数量、初始标记构造
      public AtomicMarkableReference(V initialRef, boolean initialMark) {
          pair = Pair.of(initialRef, initialMark);
      }
  
      // CAS+标记更新为newReference和newMark
      public boolean compareAndSet(V       expectedReference,
                                   V       newReference,
                                   boolean expectedMark,
                                   boolean newMark) {
          Pair<V> current = pair;
          return
              expectedReference == current.reference &&
              expectedMark == current.mark &&
              ((newReference == current.reference &&
                newMark == current.mark) ||
               casPair(current, Pair.of(newReference, newMark)));
      }
  }
  
  ```

##### 总线风暴

在**SMP架构**的CPU平台上，大量的CAS操作可能会导致**总线风暴**。

- sun.misc.Unsafe#compareAndSwapInt（），会根据当前CPU的类型**是否为多核CPU**，来决定是否为cmpxchg指令**添加lock前缀**。
  - 如果程序在多核CPU上运行，就为cmpxchg指令加上lock前缀（lockcmpxchg）。反之，如果程序在单核CPU上运行，就省略lock前缀，因为单核CPU不需要lock前缀提供的内存屏障效果。
  - 在Intel X86平台下，CAS的汇编指令lock cmpxchg是一个l**ock前缀指令**，因此CAS操作和volatile一样，也需要CPU保障变量的**缓存一致性**。
- CPU会通过MESI协议保障变量的缓存一致性，为了保障“缓存一致性”，不同的内核需要通过总线**来回通信**，因而所产生的流量一般被称为“**缓存一致性流量**”，而由于总线被设计为固定的通信能力，如果缓存一致性流量过大，总线将成为瓶颈，这就是所谓的**总线风暴**。
  - 总线风暴与CPU的架构和设计有关，并不是所有的CPU都会产生总线风暴，由于使用lock前缀指令的Java操作（包括CAS、volatile）恰恰会产生缓存一致性流量，**当有很多线程同时执行lock前缀指令操作时，在SMP架构的CPU平台上必然会导致总线风暴**。
- **解决方法**：分散热点、使用队列削峰（比如AQS的对抢锁线程进行排队），从而最大程度上减少了CAS操作数量。

### 4.0. 什么是重排序？

- 重排序是单核时代非常优秀的优化手段，有足够多的措施保证其在单核下的正确性，而在多核时代，如果工作线程之间不共享数据或仅共享不可变数据，重排序也是性能优化的利器。
- 但如果工作线程之间共享了可变数据，由于两种重排序的结果都不是固定的，因此会导致工作线程似乎表现出了**随机行为**。
- 编译器和CPU常常会对指令进行重排序，因此重排序主要分为两类：**编译器重排序**和**CPU重排序**。

![1630031189798](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630031189798.png)

#### 编译器重排序

- 编译器重排序指的是，在代码编译阶段进行指令重排，不改变程序执行结果的情况下，为了提升效率，编译器对指令进行乱序的编译。
  - 其目的在于，与其等待阻塞指令（如等待缓存刷入）完成，不如先去执行其他指令。
  - 其优点在于，与CPU重排序相比，编译器重排序能够完成**更大范围、效果更好**的乱序优化。

#### CPU重排序

- CPU重排序指的是，为了CPU的执行效率，流水线都是并行处理的，在不影响语义的情况下，处理次序和程序次序是允许不一致的，只要满足**As-if-Serial规则**即可。
  - **处理次序**：Process Ordering，机器指令在CPU实际执行时的顺序。
  - **程序次序**：Program Ordering，程序代码的逻辑执行顺序。
- 一般来说，CPU为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行顺序同代码中的先后顺序一致，但是它会保证程序**最终的执行结果**和代码顺序执行的结果是一致的。
- CPU重排序包括两类：**指令级重排序**和**内存系统重排序**。

##### 指令级重排序

- 指令级重排序指的是，在不影响程序执行结果的情况下，为了提升效率，CPU内核采用ILP（Instruction-Level Parallelism，指令级并行运算）技术来将多条指令重叠执行。
- 如果指令之间**不存在数据依赖性**，CPU就可以改变语句的对应机器指令的执行顺序。

##### 内存系统重排序

- 内存系统重排序指的是，对于现代的CPU来说，在CPU内核和主存之间都具备一个**高速缓存**，其主要作用是减少CPU内核和主存的交互。在CPU内核进行读操作时，如果缓存没有的话就从主存取，而对于写操作都是先写在缓存中，最后再一次性写入主存，从而提升性能，但可能会导致一个**数据不一致**的问题。
- 内存系统重排序和指令级重排序不同，内存系统重排序为**伪重排序**，也就是说只是**看起来**像在乱序执行而已。

### 4.1. As-if-Serial规则？

- As-if-Serial规则指的是，无论如何重排序，都必须保证代码在单线程下运行正确。
  - 为了遵守As-if-Serial规则，编译器和CPU不会对存在数据依赖关系的操作进行重排序，因为这种重排序会改变执行结果。
    - 为了保证As-if-Serial规则，Java异常处理机制也会为指令重排序做一些特殊处理：JIT在重排序时会在catch语句中插入错误补偿代码，补偿执行语句，将程序恢复到发生异常时应有的状态。
    - 这种做法会将异常捕捉的和处理的底层逻辑变得非常复杂，但是JIT的优化原则是，尽力保障正确的运行逻辑，哪怕以catch块逻辑变得复杂为代价。
  - 但是，如果指令之间不存在数据依赖关系，这些指令可能被编译器和CPU重排序。
- 虽然编译器和CPU遵守了As-if-Serial规则，保证在单CPU执行的情况下保证结果的正确性，在多核CPU并发执行的场景下，由于CPU的一个内核无法清晰分辨其他内核上指令序列中的数据依赖关系，因此可能出现乱序执行，从而导致程序运行结果错误。
- 因此，As-if-Serial规则只能保障**单内核**指令重排序之后的执行结果正确，不能保障多内核以及跨CPU指令重排序之后的执行结果正确。

### 4.2. 硬件层内存屏障？

- 内存屏障（Memory Barrier），又称内存栅栏（Memory Fences），是一系列的CPU指令，是一项让**CPU高速缓存内存可见**的技术，也是一项**保障跨CPU内核有序执行指令**的技术。
- **硬件层内存屏障**分为三种：读屏障、写屏障和全屏障。
  - **读屏障**：Load Barrier，在指令前插入读屏障，可以在指令执行时，**让高速缓存中的数据失效**，强制重新从主存加载数据，并且读屏障会告诉CPU和编译器，**先于这个屏障的指令必须先执行**。
    - 读屏障既使得指令执行时，当前CPU内核对共享变量的更改对所有CPU内核可见，又阻止了一些可能导致读取无效数据的指令重排。
    - 读屏障对应着X86处理器上的lfence指令，将强制**所有读操作都在lfence指令执行之后**被执行，并且强制本地高速缓冲区的值**全部失效**，以便从主存中重新读取共享变量的值。
  - **写屏障**：Store Barrier，在指令后插入写屏障，可以在指令执行时，**让高速缓存中的最新数据更新到主存**，让其他线程可见，并且写屏障会告诉CPU和编译器，**后于这个屏障的指令必须后执行**。
    - 写屏障对应X86处理器上的sfence指令，会保证**所有写操作都在sfence指令执行之前**被完成，并把高速缓冲区的数据都**刷新到主存**中，使得当前CPU对共享变量的更改对所有CPU可见。
  - **全屏障**：Full Barrier，又称为StoreLoad Barriers，是一种全能型的屏障，具备读屏障和写屏障的能力
    - X86处理器平台上mfence指令综合了sfence指令与lfence指令的作用，强制所有在mfence之前的store/load指令都在mfence执行之前被执行，所有在mfence之后的store/load指令都在该mfence执行之后被执行。简单来说，**X86处理器禁止对mfence指令前后的store/load指令进行重排序**。
    - X86处理器上的**lock前缀指令**也具有内存全屏障的功能。
- **硬件层内存屏障的作用**：
  - **强制让高速缓存的数据失效**：硬件层的内存屏障强制把高速缓存中的最新数据写回主存，让高速缓存中相应的脏数据失效，一旦完成写入，任何访问这个变量的线程将会得到最新的值。
  - **阻止屏障两侧的指令重排序**：编译器和CPU可能为了使性能得到优化而对指令重排序，但是插入一个硬件层的内存屏障，相当于告诉CPU和编译器先于这个屏障的指令必须先执行，后于这个屏障的指令必须后执行。
- **volatile与硬件层内存屏障**：
  - volatile在X86处理器上被JVM编译之后，它的汇编代码中会被插入一条**lock前缀指令**（lock ADD），从而实现**全屏障**目的。
  - 由于不同的物理CPU硬件所提供的内存屏障指令的差异非常大，因此**JMM**定义了自己的一套相对独立的内存屏障指令，用于屏蔽不同硬件的差异性。
  - 很多Java关键字（如volatile）在语义中包含JMM内存屏障指令，在不同的硬件平台上，这些**JMM内存屏障指令**会要求JVM为不同的平台生成相应的硬件层的内存屏障指令。

### 4.3. Java内存模型JMM？

![1630043244494](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630043244494.png)

#### JMM概念

- JMM，Java Memory Model，Java内存模型，并不像JVM内存结构一样是真实存在的运行实体，而是体现为一种规范和规则，该规范定义了一个线程对共享变量写入时，**如何确保对另一个线程是可见的**。
  - 为此，JMM提供了合理的禁用缓存以及禁止重排序的方法，用于解决**可见性和有序性**。
  - 同时，JMM还能**屏蔽各种硬件和操作系统的访问差异**，保证Java程序在各种平台下对内存的访问最终都是一致的。
- **Java内存模型规定**，所有的变量都存储在主存中（类似于物理内存），每个线程都有自己的工作内存（类似于CPU中的高速缓存）。工作内存保存了线程使用到的变量的拷贝副本，线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行，不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主存来传递。
- **JMM两个重要概念**：
  - **主存**：堆内存。
    - 主要存储的是**Java实例对象**，所有线程创建的实例对象都存放在主存中，包括成员变量对象、方法中的局部变量对象，以及共享的类信息、常量、静态变量等。
    - 由于是共享数据区域，因此多条线程对同一个变量进行访问可能**会发现线程安全问题**。
  - **工作内存**：线程私有数据区域。
    - 主要存储**当前方法的所有本地变量信息**，工作内存中存储着主存中的变量副本，每个线程只能访问自己的工作内存，即线程中的本地变量对其他线程是不可见的，即使两个线程执行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，包括字节码行号指示器、相关Native方法的信息。
    - 注意，由于工作内存是每个线程的私有数据，线程间无法相互访问工作内存，因此存储在工作内存的数据**不存在线程安全问题**。
- **JMM场景举例**：以Java为例，一个i++方法编译成字节码后，在JVM中是分成以下三个步骤运行：
  1. 从主存中复制i的值到CPU的工作内存中。
  2. CPU取工作内存中的值，然后执行i++操作，完成后刷新到工作内存。
  3. 将工作内存中的值更新到主存。

#### JMM与JVM物理内存的区别

|        | JMM                                                          | JVM                                                          |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 模型上 | 属于概念和规范维度的模型，是一个参考性质的模型，是一组规则，并不实际存在 | 虽然也是一个概念和规范维度的模型，但是大家常常将JVM理解为实体的、实现维度的虚拟机，通常是指HotSpot VM |
| 规定上 | 规定所有的变量都存储在主存中（类似于系统内存，但有区别），还能包含部分共享缓存，而每个Java线程都有自己的工作内存（类似于CPU高速缓存，但也有区别）。 | 定义了一个指令集、一个虚拟计算机架构和一个执行模型，具体的JVM实现需要遵循JVM的模型 |
| 作用上 | 确保了在不同的编译器和不同的CPU平台上，为Java程序员提供了一致的内存可见性和指令并发执行的有序性 | 能够运行根据JVM模型指令集编写的代码，就像真机可以运行机器代码一样 |

#### JMM与硬件内存架构的关系

多线程的执行最终都会映射到CPU上执行，但是Java内存模型和硬件内存架构并不完全一致。总体上来说，JMM和计算机硬件内存架构是**相互交叉**的关系，是一种**抽象概念划分与真实物理硬件的交叉**：

- 对于硬件内存来说只有寄存器、缓存内存、主存的概念，并没有工作内存（线程私有数据区域）和主存（堆内存）之分，也就是说JMM对内存的划分对硬件内存并没有任何影响。
- 而JMM只是一种抽象的概念，是一组规则，并不实际存在，无论是工作内存的数据还是主存的数据，对于计算机硬件来说都会存储在计算机主存中，当然也有可能存储到CPU高速缓存或者寄存器中。

![1630044892085](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630044892085.png)

#### JMM 8个操作

JMM定义了一套自己的主存与工作内存之间的交互协议，即**一个变量如何从主存拷贝到工作内存，又如何从工作内存写入主存**，该协议包含8种操作，并且要求JVM具体实现必须保证其中每一种操作都是**原子的、不可再分的**。

- 如果要把一个变量从主存复制到工作内存，就要按**顺序执行Read和Load操作**；如果要把变量从工作内存同步回主存，就要**按顺序执行Store和Write操作**。
- JMM规定，执行上述8种基本操作时必须满足如下规则：
  1. 不允许read和load、store和write操作之一单独出现，以上两个操作**必须按顺序执行，但没有保证必须连续执行**，也就是说，read与load之间、store与write之间是可插入其他指令的。
  2. 不允许一个线程丢弃它最近的assign操作，也就是说当线程使用assign操作对私有内存的变量副本进行变更时，它必须使用write操作将其同步到主存中。
  3. 不允许一个线程无原因地（比如没有发生过任何assign操作）把数据从线程的工作内存同步回主存中。
  4. 一个新的变量只能从主存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，也就是说对一个变量实施use和store操作之前，必须先执行assign和load操作。
  5. 一个变量在同一个时刻只允许一个线程对其执行lock操作，但lock操作可以被同一个线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
  6. 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。
  7. 如果一个变量实现没有被lock操作锁定，就不允许对它执行unlock操作，也不允许unlock一个被其他线程锁定的变量。
  8. 对一个变量执行unlock操作之前，必须先把此变量同步回主存（执行store和write操作）。

![1630045226983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630045226983.png)

| 操作   | 作用对象 | 说明                                                         |
| ------ | -------- | ------------------------------------------------------------ |
| Read   | 主存     | 读取。把一个变量的值从主存传输到工作内存中，以便随后的Load操作使用。 |
| Load   | 工作内存 | 载入。把Read操作从主存中得到的变量值，载入到工作内存的变量副本中（可以简单理解为CPU的高速缓存）。 |
| Use    | 工作内存 | 使用。每当JVM遇到一个需要使用变量值的字节码指令时，都会执行Use操作，会把工作内存中的一个变量值传递给执行引擎。 |
| Assign | 工作内存 | 赋值。每当JVM遇到一个给变量赋值的字节码指令时，都会执行Assign操作，操作引擎通过Assign操作给工作内存的变量赋值。 |
| Store  | 工作内存 | 存储。把工作内存的一个变量值传递到主存中，以便随后的Write操作使用。 |
| Write  | 主存     | 写入。把Store操作从工作内存中得到的变量值，写入到主存的变量中。 |
| Lock   | 主存     | 锁定。把一个变量标识为某个线程独占的状态。                   |
| Unlock | 主存     | 解锁。把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 |

#### JMM内存屏障

由于不同CPU硬件实现内存屏障的方式不同，**JMM屏蔽了这种底层CPU硬件平台的差异，定义了不对应任何CPU的JMM逻辑层内存屏障，提供了自己的内存屏障指令**，要求JVM编译器实现这些指令，由JVM在不同的硬件平台生成对应的内存屏障机器码，禁止特定类型的编译器（不是所有的编译器重排序都要禁止）和CPU重排序，解决**有序性问题**。

- JMM内存屏障主要有**Load和Store**两类：

  - **Load Barrier**：读屏障，在读指令前插入读屏障，可以在指令执行时，让高速缓存中的数据失效，重新从主存加载数据。
  - **Store Barrier**：写屏障，在写指令后插入写屏障，可以在指令执行时，让写入缓存的最新数据写回主存。

- 在实际使用时，JMM会对Load Barrier和Store Barrier两类屏障进行组合，用于**禁止特定类型的CPU重排序**：

  - **LoadLoad**：LL屏障。

    - 在执行预加载或者支持乱序处理的指令序列中，需要显示地声明LoadLoad屏障。
    - 在Load2要读取的数据被访问前，使用LoadLoad屏障，能保证Load1要读取的数据被读取完毕。

    ```java
    // LoadLoad屏障伪代码
    Load1；LoadLoad；Load2
    
    ```

  - **StoreStore**：SS屏障。

    - 如果CPU刷新数据时，不能保证按顺序从高速缓冲向主存（或其他CPU），则需要使用StoreStore屏障。
    - 在Store2以及后续写入操作执行前，使用StoreStore屏障，能保证Store1的写入结果对其他CPU可见。

    ```java
    // StoreStore屏障伪代码
    Store1；StoreStore；Store2
    
    ```

  - **LoadStore**：LS屏障。

    - LoadStore屏障，用于在数据写入操作执行前，确保完成数据的读取。
    - 在Store2以及后续写入操作执行前，使用LoadStore屏障，能保证Load1要读取的数据被读取完毕。

    ```java
    // LoadStore屏障伪代码
    Load1；LoadStore；Store2
    
    ```

  - **StoreLoad**：SL屏障。

    - StoreLoad屏障，用于在数据读取操作执行前，确保完成数据的写入。该屏障是一个**全能型屏障**，其开销是4种屏障中最大的，因为兼具其他3个屏障的效果，现代的多核CPU大多支持该屏障。
    - 在Load2以及后续所有读取操作执行前，使用StoreLoad屏障，能保证Store1的写入对所有CPU可见。

    ```java
    // StoreLoad屏障伪代码
    Store1；StoreLoad；Load2
    
    ```

### 4.4. volatile原理？

#### 保证内存可见性

使用volatile修饰的变量，在变量值发生改变时，会立刻同步到主存，并使其他线程的变量副本失效，即一个线程修改了某个volatile变量的值，该值对其他线程立即可见。

- 在正常情况下，系统操作并不会校验共享变量的缓存一致性，只有当共享变量用**volatile**关键字修饰后，才可以保证共享变量的**内存可见性**，也就是将共享变量的改动值立即刷新回主存，该变量所在的缓存行才会被要求进行**缓存一致性的校验**。
- 分析volatile关键字对应的汇编指令，可知在操作volatile变量之前，多出了一个 lock前缀指令**lock addl（lock ADD）**。
- **lock前缀指令具有以下功能**：
  - **将当前CPU缓存行数据立即写回主存**：在执行指令期间，CPU可以**独占共享内存**（即主存）。
    - 对共享内存的独占，老的CPU（如Intel 486）通过**总线锁**方式实现。
    - 由于总线锁开销比较大，因此新版CPU（如IA-32、Intel 64）通过**缓存锁**实现对共享内存的独占性访问，缓存锁（缓存一致性协议）会阻止两个CPU同时修改共享内存的数据。
  - **失效其他CPU中相同地址的缓存行**：
    1. 写回操作时要**经过总线传播数据**，而每个CPU通过嗅探在总线上传播的数据来检查自己缓存的值是否过期。
    2. 当CPU发现自己缓存行对应的内存地址被修改时，就会将当前CPU的缓存行设置为**无效状态**。
    3. 当CPU要对这个值进行修改的时候，会强制重新从主存中把数据读到CPU缓存。
  - **禁止指令级重排序**：lock前缀指令还可以作为**内存屏障**，禁止指令重排序，避免多线程环境下程序出现乱序执行的现象。

#### 禁止指令重排序

##### 硬件层面上

用volatile修饰的变量，在硬件层面上，会通过在指令前后加入**内存屏障指令**（lock前缀指令）来实现，以保证执行的有序性。

- 为了实现volatile关键字语义的有序性，JVM编译器在生成字节码时，会在指令序列中插入**内存屏障**来禁止特定类型的处理器重排序。

- JMM建议JVM volatile采取**保守策略**严格禁止重排序：

  - 在每个volatile读操作的后面插入一个**LoadLoad屏障**，以及一个**LoadStore屏障**，禁止后面的普通读、普通写和前面的volatile读操作之间发生重排序。
    - LoadLoad屏障：在Load2要读取的数据被访问前，使用LoadLoad屏障，能保证Load1要读取的数据被读取完毕。
    - LoadStore屏障：在Store2以及后续写入操作执行前，使用LoadStore屏障，能保证Load1要读取的数据被读取完毕。

  ![1630053036307](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630053036307.png)

  - 在每个volatile写操作前插入一个StoreStore屏障，在写操作后面插入一个StoreLoad屏障，禁止前面的普通写和后面的volatile写操作之间发生重排序，同时禁止后面的普通读和前面的volatile写操作之间发生重排序。
    - StoreStore屏障：在Store2以及后续写入操作执行前，使用StoreStore屏障，能保证Store1的写入结果对其他CPU可见。
    - StoreLoad屏障：在Load2以及后续所有读取操作执行前，使用StoreLoad屏障，能保证Store1的写入对所有CPU可见。

  ![1630052862174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630052862174.png)

- 由于上述JMM建议的volatile写和volatile读的内存屏障插入策略，是针对任意处理器平台的，所以非常保守。不同的处理器有不同“松紧度”的处理器内存模型，只要不改变volatile读写操作的内存语义，不同JVM编译器可以根据具体情况省略不必要的JMM屏障。

  - 以X86处理器为例，该平台的JVM实现仅仅在volatile写操作后面插入一个StoreLoad屏障，其他的JMM屏障都会被省略。
  - 由于StoreLoad屏障的开销大，因此在X86处理器中，volatile写操作比volatile读操作的开销会大很多。

##### JMM层面上

用volatile修饰的变量，在JMM层面上，是通过对volatile有着特殊约束来实现的，以保证执行的有序性。

- 使用volatile修饰的变量其**read、load、use都是连续出现的**，所以每次使用变量的时候都要从主存读取最新的变量值，替换私有内存的变量副本值（如果不同的话）。
- 其对同一变量的**assign、store、write操作都是连续出现的**，所以每次对变量的改变都会立马同步到主存中。

#### 复合操作不具备原子性

虽然volatile修饰的变量，其要求对变量的（read、load、use）以及（assign、store、write）必须是连续出现的，每次读取的变量可以是最新值，且可以强制刷新回主存，但是在不同CPU内核上并发执行的线程，还是有可能出现读取脏数据的时候，因此volatile变量的复合操作并不具备原子性。

- **场景举例**：

  1. 假设有两个线程A、B分别运行在Core1、Core2上，并假设此时的value为0，线程A、B也都读取了value值到自己的工作内存。
  2. 现在线程A将value变成1之后，完成了assign、store的操作，假设在执行write指令之前，线程A的CPU时间片用完，线程A被空闲，**但是线程A的write操作没有到达主存**。
  3. 由于线程A的store指令触发了写的信号，线程B缓存过期，**重新从主存读取到value值**，但是线程A的写入没有最终完成，线程B读到的value值还是0。
  4. 线程B执行完成所有的操作之后，将value变成1写入主存。
  5. 线程A的时间片重新拿到，重新执行store操作，将过期了的1写入主存。

  => 可见，虽然A、B两线程执行了两次+1操作，但是最终结果只是增加了1而不是2，因此，volatile变量的复合操作不具备原子性。

- **解决方法**：对于复合操作，volatile变量无法保障其原子性，如果要保证复合操作的原子性，就需要使用**锁**。

![1630118559462](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630118559462.png)

### 4.5. Happens-Before规则？

JMM定义了一套Happens-Before规则（先行发生规则），确保只要两个Java语句之间存在Happens-Before关系，JMM需要尽量确保这两个Java语句之间的**内存可见性和指令有序性**。

Happens-Before规则的主要内容包括以下几个方面：

1. **程序顺序执行规则**：即as-if-serial规则，在同一个线程中，有依赖关系的操作按照先后顺序，前一个操作必须**先行发生于**后一个操作，换句话说就是，单个线程中的代码顺序无论怎么重排序，对于结果来说是不变的。
   - As-if-Serial规则，仅仅用来保证程序在单线程执行结果的正确性，但是无法保证程序在多线程执行结果的正确性。
2. **volatile变量规则**：对volatile变量的写操作必须**先行发生于**对volatile变量的读操作。
   - 如果第二个操作为volatile写，无论第一个操作是什么都不能重排序。
   - 如果第一个操作为volatile读，无论第二个操作是什么都不能重排序。
3. **传递性规则**：如果A操作先于B操作，而B操作又先行发生于C操作，那么A操作**先行发生于**C操作。
4. **监视锁规则**：对一个监视锁的解锁操作**先行发生于**后续对这个监视锁的加锁操作。
   - 即无论在单线程还是多线程中，同一个锁如果处于被锁定状态，那么必须先对锁进行释放操作，后面才能继续执行lock操作，先获取锁的线程，对x赋值之后释放锁，另一个再获取锁时，一定能看到前一个加锁线程对x赋值的改动。
   - 由于监视器互斥执行的特性，监视锁规则不会对临界区内的代码进行约束，临界区内的代码可以重排序，其他线程根本无法“观察”到该线程在临界区内的重排序，这种重排序既提高了执行效率，又没有改变程序的执行结果。但JMM不允许临界区内的代码“逸出”到临界区之外，因为那样会破坏监视器的语义。
5. **start规则**：对线程的start操作**先行发生于**这个线程内部的其他任何操作，具体来说就是，如果线程A执行B.start()启动线程B，那么线程A的B.start()操作先行发生于线程B中的任意操作。
   - 即如果主线程A启动子线程B后，线程B能看到线程A在start（）操作前的任何操作。
6. **join规则**：如果线程A执行了B.join()操作并成功返回，那么线程B中的任意操作**先行发生于**线程A所执行的ThreadB.join()操作。
   - 即线程A等待子线程B完成后，线程B的所有赋值操作，线程A都能够看到。

### 4.6. 详细介绍AQS？

![1630209591346](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209591346.png)

#### 背景

- **CAS自旋的两大性能问题**：
  - CAS恶性空自旋会浪费大量的CPU资源。
  - 在SMP架构的CPU上会导致“总线风暴”。
- 解决CAS恶性空自旋的有效方式之一是**以空间换时间**，较为常见的方案有两种：**分散操作热点和使用队列削峰**。
  - JUC并发包使用的是**队列削峰**的方案解决CAS的性能问题，并提供了一个基于双向队列的削峰基类——抽象基础类**AbstractQueuedSynchronizer**。

#### 特点

- AbstractQueuedSychronizer，**简称AQS**，抽象队列同步器，提供一个构建锁和同步器的框架，能够简单且⾼效地构造出应⽤⼴泛的⼤量的同步器，可以用于实现**依赖先进先出 (FIFO) 等待队列**的阻塞锁和相关同步器（信号量、事件等），旨在成为大多数依赖**单个原子 {@code int} 值来表示状态**的同步器的有用基础。
- AQS支持**独占模式（默认）和共享模式**，在不同模式下等待的线程**共享同一个 FIFO 队列**。
  - 当以独占模式获取时，其他线程尝试获取不会成功。
  - 当以共享模式获取时， 多个线程尝试获取可能会成功。当共享模式获取成功时，下一个等待线程（如果存在）也必须确定它自己是否也可以获取（前驱通过调用setHeadAndPropagate方法传播告知）。
- AQS定义了一个嵌套的 {@link ConditionObject} 类，{@link ConditionObject}可以被支持独占模式的子类用作 **{@link Condition} 实现**，而{@link ConditionObject} 的行为当然取决于其同步器实现的语义。
- AQS还为内部队列提供检查、检测和监视方法，同时也为ConditionObject提供类似方法。

#### 实现原理

##### AQS核⼼思想

1. 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
2. 如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，而这个机制AQS是通过CLH队列（自旋锁）实现的，即将暂时获取不到锁的线程加⼊到队列中。
3. 每当线程通过AQS获取锁失败时，线程将被封装成一个Node节点，通过CAS原子操作插入队列尾部。
4. 当有线程释放锁时，AQS会尝试让队头的后继节点占用锁。

![1630209724753](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209724753.png)

##### AQS主等待队列

AQS主等待队列，是CLH队列（自旋锁）的一个变种，AQS将它们改为用于阻塞同步器：

- 主等待队列的每个节点都充当一个**特定的通知式监视器**，持有一个**等待线程**（用于保存后继有关控制信息），一个**状态字段**（用于跟踪线程是否应该阻塞）。
- 在前驱结点Release时，当前结点将会收到信号，从而可能会尝试获取成为在队列中的head结点，但并不保证成功，只是给予当前结点参与竞争的权利。
- 而要加入CLH队列，需要原子地将其拼接为新的尾部，要出列则需要设置该结点成为head结点。
- “prev”前驱指针（原始CLH锁中没有前驱指针），用于处理取消结点：如果一个结点被取消，则它的后继会重新链接到一个未取消的前驱；以及判断是否为头结点，方便后继执行一次尝试抢占锁的操作。
- “next”后继指针，用于实现阻塞与通知机制：每个节点的线程id保存在它自己的节点中，因此前驱通过遍历下一个链接来确定它是哪个线程来通知下一个节点唤醒。
- 此外，AQS主等待队列还需要一个**虚拟头结点**来启动，但是AQS不会在构建时创建它们，因为如果从不存在争用，那将是浪费精力。因此，AQS只会在第一次争用时，才构造结点并设置头指针和尾指针。
- 即使AQS内部基于FIFO队列，但它也不会自动执行FIFO采集策略，因为在入队之前会先调用获取的检查，所以新的获取线程可能会抢在其他被阻塞和排队的线程之前。
  - 虽然该策略无法保证公平或者无饥饿，但允许较早的排队线程在较晚的排队线程之前竞争，从而能够保持**最高的吞吐量和可扩展性**。
  - 如果需要可以定义{@code tryAcquire} 或者 {@code tryAcquireShared} ，通过内部调用一种或多种检查方法来禁用插入，从而提供公平的 FIFO 获取顺序。比如{@link #**hasQueuedPredecessors**}（一种专门设计用于公平同步器使用的方法）返回 {@code true}时不允许插入，因此大多数公平同步器可以基于该方法，从而定义 {@code tryAcquire} 返回 {@code false}，代表不允许提前插入。

![1630238528789](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630238528789.png)

##### AQS条件队列

- Condition，是JUC用来替代传统Object的wait()/notify()线程间通信与协作机制的新组件，相比调用Object的wait()/notify()，调用Condition的await()/signal()这种方式实现**线程间协作更加高效**。
  - Condition与Object的wait()/notify()作用是相似的，都是使得一个线程等待某个条件，只有当该条件具备signal()或者signalAll()方法被调用时等待线程才会被唤醒，从而重新争夺锁。
  - 不同的是，Object的wait()/notify()由JVM底层实现，而Condition接口与实现类完全使用Java代码实现。当需要进行线程间的通信时，建议结合使用ReetrantLock与Condition，通过Condition的await()和signal()方法进行线程间的阻塞与唤醒。
- ConditionObject类是实现条件队列的关键，每个ConditionObject对象都维护一个单独的条件等待队列。每个ConditionObject对应一个条件队列，它记录该队列的头节点和尾节点。
  - 在一个显式锁上，我们可以创建多个等待任务队列，这点和内置锁不同，Java内置锁上只有唯一的一个等待队列。
  - Condition条件队列是单向的，而AQS同步队列是双向的，AQS节点会有前驱指针。一个AQS实例可以有多个**条件队列，是聚合关系**；但是一个AQS实例只有一个**同步队列，是逻辑上的组合关系**。
- AQS条件队列，也使用了相同的Node队列结点，但额外维护了一个nextWaiter指针，在调用Condition#await时，会把一个Condition结点插入到条件队列中，然后根据Condition#signal信号，该结点将会被转移到主队列中，去参与AQS竞争，竞争失败的会重新阻塞，阻塞后依赖于AQS的CLH机制实现唤醒。

![1630238750935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630238750935.png)

##### 队列结点数据结构

![1630208598316](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630208598316.png)

- **waitStatus**：
  - **waitStatus为0**：表示当前节点处于初始状态。
  - **CANCELLED = 1**：表示线程因为中断或者等待超时，需要从等待队列中取消等待，其节点不会参与竞争，且会一直保持取消状态。
  - **SIGNAL = -1**：表示其后继的节点处于等待状态，当前节点对应的线程如果释放了同步状态或者被取消，就会通知后继节点，使后继节点的线程得以运行。
  - **CONDITION = -2**：表示该线程在条件队列中阻塞，当持有锁的线程调用了CONDITION的signal（）方法之后，节点会从条件队列转移到AQS主等待队列上，去竞争锁。
  - **PROPAGATE = -3**：表示下一个线程获取共享锁后，自己的共享状态会被无条件地传播下去，因为共享锁可能出现同时有N个锁可以用，这时直接让后面的N个节点都来工作，这样就不会让其他等待的线程等很久，这种向后传播的目的也是**通知其他等待的线程尽快获取锁**。
- **thread**：存放进入AQS队列中的线程引用。
- **nextWaiter**：如果当前结点为条件等待结点，则说明该结点处于某个Condition的等待队列上，指向该条件队列的后继等待结点；如果当前结点为普通结点，则只作为独占（null）/共享（new Node）模式的标记。
  - **SHARED**：new Node（），共享模式的标记，表示线程是因为获取共享资源时阻塞而被添加到队列中的。
  - **EXCLUSIVE**：null，独占模式的标记，表示线程是因为获取独占资源时阻塞而被添加到队列中的。
- **prev**：前驱结点，当前结点会在前驱结点上自旋，循环检查前驱结点的waitStatus状态。用于处理取消结点，如果一个结点被取消，则它的后继会重新链接到一个未取消的前驱；以及判断是否为头结点，方便后继执行一次尝试抢占锁的操作。
- **next**：后继结点，用于实现阻塞与通知机制，每个节点的线程id保存在它自己的节点中，因此前驱通过遍历下一个链接来确定它是哪个线程来通知下一个节点唤醒。

#### 同步状态

AQS中维持了一个单一的volatile修饰的状态信息state，使用int类型的state标示锁的状态，可以理解为锁的同步状态。

#### 钩子方法

AQS钩子方法，默认实现是抛出UnsupportedOperationException异常，而AQS其他方法都是final类型的方法，无法被子类重写。

- **tryAcquire(int)**：独占锁钩子，尝试获取资源，若成功则返回true，若失败则返回false。
- **tryRelease(int)**：独占锁钩子，尝试释放资源，若成功则返回true，若失败则返回false。
- **tryAcquireShared(int)**：共享锁钩子，尝试获取资源。
  - 负数，表示失败。
  - 正数，表示成功，且有剩余资源。
  - 0，也表示成功，但没有剩余可用资源。
- **tryReleaseShared(int)**：共享锁钩子，尝试释放资源，若成功则返回true，若失败则返回false。
- **isHeldExclusively()**：独占锁钩子，判断该线程是否正在独占资源，只有用到condition条件队列时才需要去实现它。

#### 独占模式

![1630209980487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630209980487.png)

![1630210001133](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210001133.png)

- 独占模式下，tryAcquire返回的是boolean值，其含义取决于实现类定义的语义。
  - 经过推算，要实现独占就要保证：如果想要获取同步器，则当已存在独占线程时，则要返回false，当没存在独占线程时，则要返回true。
- 每个结点尝试获取同步器，获取失败的生成Node结点，并加入AQS主队列参与竞争，竞争失败的则会将前驱结点设置为SINGAL状态，然后阻塞。
- 每个结点（此时作为后继的前驱）释放同步器时，由于当前为SINGAL状态，所以会唤醒后继结点，重新参与AQS竞争。

##### 获取资源

1. 尝试以独占模式获取同步器，如果获取成功，则直接返回即可。
2. 如果获取失败，则使用当前线程构建独占模式的Node结点，并CAS+自旋直至入队成功。
3. 入队成功后，则调用acquireQueued方法，自旋判断前驱是否为头结点，如果是则执行一次抢占锁的操作，抢占成功则更新头结点，并返回中断标记interrupted（该方法唯一返回入口）。
4. 如果检测到前驱不为头结点，或者抢占锁失败，则使用LockSupport.park（this）来阻塞当前线程。
5. 直到LockSupport.unpark（当前线程的实例）调用后，当前线程被唤醒，会先检查线程中断状态，然后才会重新自旋检查前驱状态、抢占锁或者继续阻塞。

##### 可抛中断异常原理

对比普通独占获取资源方法，可抛中断异常获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会**提前抛出中断异常**，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireInterruptibly方法来添加入队结点。
3. 接着自旋判断到前驱为头结点，并成功抢占锁后，不会返回任何值。
4. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会**立马抛出中断异常**。

##### 定时获取原理

对比普通独占获取资源方法，定时获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会提前抛出中断异常，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireNanos方法来添加入队结点，并且根据当前系统纳秒时间，来**计算剩余过期时间**。
3. 接着自旋判断到前驱为头结点，并成功抢占锁后，会**返回true**，代表在规定时间内成功获取到了锁。
4. 如果前驱不为头结点，或者抢锁失败，则会继续根据当前系统纳秒时间，来**计算剩余过期时间**，并且如果发现超过了定时时间，则会**返回false**，代表未能在规定时间内获取到锁，抢锁失败。
5. 如果没超过定时时间，则调用的是LockSupport.parkNanos(this, nanosTimeout)来**定时阻塞当前线程**。
6. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

##### 释放资源

1. 尝试以独占模式释放同步器，如果释放失败，则直接返回false即可，代表释放失败。

2. 如果释放成功，则需要继续判断头结点，如果头结点为空，或者为初始的普通结点，则返回true，代表释放成功。

3. 如果头结点为业务结点，则还需要调用**unparkSuccessor（head）**方法来唤醒后续排队的结点，唤醒后则返回true，代表释放成功。

   - 调用释放方法并不会重新设置头结点，而仅仅是更新头结点的waitStatus以及唤醒后继结点。
   - 而重新设置头结点和清空头结点，将留到其后继获取同步状态成功后进行更新，这样可以保证后继线程自己来确保成为头结点，比放在释放方法里由非头线程设置头结点要严谨一些。

   4. unparkSuccessor（head）方法，会先更新头结点的waitStatus为0，然后获取后继结点s，使用LockSupport.unpark(s.thread)来唤醒s结点的排队线程，代表当前结点出队成功。

#### 共享模式

- 共享模式下，tryAcquireShared返回的是int值，其含义取决于实现类定义的语义。
- PROPAGATE相当于启动一个**占位的作用**：
  - 获取到的资源非最后一个资源的结点，状态为PROPAGATE。
  - 获取到的资源最后一个资源的结点，状态一开始为0，不过很快就会在下一个结点阻塞前，设置为SINGAL；
  - 当它们释放共享锁时，如果为PROPAGATE结点释放，则无任何唤醒后继结点的操作，而如果为SINGAL结点释放，则会唤醒后继结点，接着又会重复出现PROPAGATE和SINGAL结点，然后往复之前的操作。

##### 获取资源

对比普通独占获取资源方法，共享获取资源方式，**主要不同的地方在于**：

1. 在尝试获取共享资源时，如果获取到的数量大于等于0，说明获取成功，此时直接返回即可。
2. 但在获取到的数量小于0时，说明获取失败，此时需要调用doAcquireShared方法来添加入队结点，但此时设置的结点的nextWaiter不在是默认的null，而是SHARED，代表为共享模式的结点。
3. 接着自旋判断到前驱为头结点，会进行一次尝试获取共享资源，如果获取的数量大于等于0，说明获取成功，则**调用setHeadAndPropagate方法**更新当前结点为头结点，**调用doReleaseShared方法**设置头结点为PROPAGATE，表示下一个线程获取共享锁后，自己的共享状态会被无条件地传播下去，**通知其他等待的线程尽快获取锁**。传播完毕后，返回之前需要判断当前线程是否有被中断，如果是的话则调用一次中断方法，重新设置线程中断标志再返回。
4. 如果获取的数量小于0，说明获取失败，则在调用shouldParkAfterFailedAcquire方法时，由于此时该前驱为最后一个成功获取资源的结点，所以会更新前驱为SINGAL，代表在前驱释放锁成功后，需要唤醒当前线程，接着使用LockSupport.park（this）来阻塞当前线程。
5. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，不会抛出中断异常，而是更新代码中断标志位为true。

##### 可中断式获取

对比普通共享获取资源方法，可抛中断异常获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会**提前抛出中断异常**，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireInterruptibly方法来添加入队结点。
3. 接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是**直接返回**。
4. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会**立马抛出中断异常**。

##### 定时式获取

对比普通共享获取资源方法，定时获取的方式，**主要不同的地方在于**：

1. 尝试以独占模式获取同步器前，会先检查线程是否被中断过，如果是会提前抛出中断异常，阻止继续往下执行。
2. 在抢占失败一次后，直接调用doAcquireSharedNanos方法来添加入队结点，并且根据当前系统纳秒时间，来**计算剩余过期时间**，如果定时时间小于等于0，则**返回false**，表未能在规定时间内获取到锁，抢锁失败。
3. 接着自旋判断到前驱为头结点，在尝试获取共享资源成功，并传播完毕后，返回之前不会判断当前线程是否有被中断，而是**返回true**，代表在规定时间内成功获取到了锁。
4. 如果前驱不为头结点，或者抢锁失败，则会继续根据当前系统纳秒时间，来**计算剩余过期时间**，并且如果发现超过了定时时间，则会**返回false**，代表未能在规定时间内获取到锁，抢锁失败。
5. 如果没超过定时时间，则调用的是LockSupport.parkNanos(this, nanosTimeout)来**定时阻塞当前线程**。
6. 被LockSupport.unpark（当前线程的实例）被唤醒后，会先检查线程中断状态，如果发现线程已被中断，则会立马抛出中断异常。

##### 释放资源

1. 尝试以共享模式释放同步器，如果释放失败，则直接返回false即可，代表释放失败。
2. 如果释放成功，则需要继续判断头结点，如果头结点为SIGNAL结点，则需要调用unparkSuccessor（head）方法来唤醒后续排队的结点，唤醒后则返回true，代表释放成功。
   - unparkSuccessor（head）方法，会先更新头结点的waitStatus为0，然后获取后继结点s，使用LockSupport.unpark(s.thread)来唤醒s结点的排队线程，代表当前结点出队成功。
3. 如果头结点是waitStatus为0的普通结点（在并发设置传播特性时走到这里），则需要CAS更新waitStatus为PROPAGATE，然后返回true，代表释放成功。
   - 调用释放方法并不会重新设置头结点，而仅仅是更新头结点的waitStatus以及唤醒后继结点。
   - 而重新设置头结点和清空头结点，将留到其后继获取同步状态成功后进行更新，这样可以保证后继线程自己来确保成为头结点，比放在释放方法里由非头线程设置头结点要严谨一些。

#### 条件同步

![1630210049637](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210049637.png)

![1630210030025](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630210030025.png)

- **ConditionObject数据结构**：
  - **firstWaiter**：条件队列的第一个节点。
  - **lastWaiter**：条件队列的最后一个节点。
- **ConditionObject构造方法**：
  - 由ReentrantLock.Sync#newCondition()方法调用，从而创建一个ConditionObject实例对象。

##### 条件阻塞等待

1. 首先会创建一个**Condition结点**，并放入Condition条件队列的队尾。
2. 然后获取全部的同步状态来释放锁，其中会调用**unparkSuccessor方法**唤醒AQS主等待队列中头结点的后继线程。
   - 这里执行的一次AQS释放锁操作，类似于执行一次synchronized重量级锁的【指定EntryList头结点线程为OnDeck Thread】一样，用于从**候选竞争队列EntryList**中选取就绪线程。
   - 由于要触发一次AQS抢锁操作，需要一定的资源次数来获取，为了不影响其他结点的使用，先获取了全部的同步器状态，然后马上全部释放掉，保证同步器状态不变，但是如果发生了并发问题，释放失败的话则会抛出IllegalMonitorStateException监视器异常。
3. 接着判断当前结点是否已经在AQS主等待队列中，如果还没有进入主等待队列，则执行while循环，将当前线程阻塞，直到该结点被调用**doSignal方法**离开等待队列，重新回到同步队列成为同步节点后，线程才退出while循环。如果期间发生了虚假唤醒，则需要检查线程中断状态，如果已发生了中断，则需要退出while循环。
   - 条件队列，相当于synchronized重量级锁的**cxq队列**，所有请求等待线程都是被放入这个队列中，在调用到结点的doSignal方法时，会将结点waitStatus更新为0，放入AQS主等待队列中参与AQS主等待队列的排队，在成功抢占锁后会退出Object#await那里的while循环。
   - 而这里的AQS主等待队列，则相当于synchronized重量级锁的**EntryList队列**，用于管理等待队列竞争锁的问题，同理，这里把条件队列结点转移到AQS主等待队列结点中等待，是因为需要把竞争锁的工作，交由更加专业的AQS主等待队列去完成。
4. 退出while循环后，代表结点肯定在AQS主等待队列中了，则开始调用acquireQueued方法尝试抢锁，如果没抢到锁，则使用LockSupport.part（this）进入阻塞，**根据AQS机制来实现唤醒**。
5. 当从acquireQueued方法中返回，说明当前线程已经抢到锁了，则先检查返回值，如果为true，说明抢锁期间发生了中断，则更新代码的中断模式为THROW_IE或者REINTERRUPT，然后继续运行。
6. 最后在void返回前，清空Condition条件队列中被取消的节点，响应代码更新到的中断模式。
   - REINTERRUPT，代表在退出等待时重新标记线程为已中断状态。
   - THROW_IE，代表在退出等待时要抛出nterruptedException。

##### 定时式等待

对比普通条件阻塞等待方法，定时等待的方式，**主要不同的地方在于**：

1. 在会创建Condition结点前，会先**校验线程是否已中断**，如果是则会提前抛出中断异常，阻止继续往下执行。
2. 接着进入判断是否在主等待队列+while阻塞循环前，会先根据系统纳秒时间，计算出超时时间，然后调用LockSupport.parkNanos(this, nanosTimeout)方法，来**定时阻塞当前线程**。
3. 当在while循环中发生了虚假唤醒，则重新计算超时时间，继续判断+循环，如果发现**已经超时了**，则取消Condition结点，交由AQS主等待队列去管理和释放。
4. 最后，在清空Condition条件队列中被取消的节点，且响应代码更新到的中断模式完毕后，不再是void返回了，而是返回是否发生了超时，**如果为true代表没有发生超时，如果为false代表发生了超时**。

##### 条件唤醒

1. 先更新指定的条件队列结点的waitStatus为0，然后enq方法自旋入队，返回其前驱结点p。
2. 如果前驱结点p的状态是取消状态，或者设置p为Signal状态失败，则唤醒当前线程，让其退出Condition#await中的while循环，进行一次抢占锁的操作，抢占失败则需要AQS机制来唤醒，从而保证必定能被AQS管理到。
3. 如果结点顺利入队，则参与AQS主等待队列的排队，交由AQS机制来管理和释放。

#### 典型实现

![1630201659838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630201659838.png)

##### CountDownLatch

- CountDownLatch，一种同步辅助，**它允许一个或多个线程等待，直到执行的一组操作完成才唤醒这些线程**。
- {@code CountDownLatch} 使用给定的计数进行初始化，{@link #await await} 方法阻塞，直到当前计数由于 {@link #countDown} 方法的调用而达到零，之后所有等待线程都被释放，并且 {@link #await await} 的任何后续调用立即返回。这是一种**一次性现象**（即计数无法重置），如果需要重置计数的版本，请考虑使用 {@link CyclicBarrier}。
- {@code CountDownLatch} 是一种**多功能同步工具**，可用于多种用途。 
  - 计数初始化为1的 {@code CountDownLatch} 用作简单的开关锁存器或门闩。所有调用 {@link #await await} 的线程在门处等待，直到它被调用 {@link # countDown}。
  - 计数初始化为 N 的 {@code CountDownLatch} 可用于使一个线程等待，直到 N 个线程完成某个操作，或者某个操作已完成 N 次。

###### Sync

- **tryAcquireShared**：实现钩子方法，尝试获取共享资源。
  1. 如果计数为0，则返回1，代表获取资源成功，此时在共享模式下，会唤醒一个又一个的线程，实现**释放全部等待线程**的功能。
  2. 如果计数不为0，则返回-1，代表获取资源失败，此时在共享模式下，会**阻塞所有排队线程**。
- **tryReleaseShared**：实现钩子方法，尝试释放共享资源。这里的共享释放，做的是**传播，而非许可的累加**。
  1. 开始自旋，如果计数为0，则返回false，代表门闩资源释放失败，因为计数已经为0，不能再减了。
  2. 如果计数不为0，则计数-1，然后使用CAS更新，最后返回更新后是否为0。
     - 如果为0，则返回true，代表当前线程为最后一个到达门闩的线程，需要**释放资源**。
     - 如果不为0，则返回false，代表当前线程不是最后一个到达的线程，需要继续**阻塞等待**。

###### await

1. 由“主线程”调用，传入的参数为1，代表需要获取1个资源。
2. 由于实现了tryAcquireShared钩子方法，1又不等于0，所以每次都会返回-1，代表获取资源失败，导致**主线程入队+阻塞**。

###### countDown

1. 由"子线程"调用，传入的参数为1，代表需要释放1个资源。
2. 由于实现了tryReleaseShared钩子方法，该方法每次都会减少1，如果没减到0，则返回false，代表当前线程还不是最后一个到达的线程，因此不会做任何唤醒操作。
3. 而如果减到了0，则返回true，代表当前线程为**最后一个到达的线程**，因此会调用doReleaseShared方法，唤醒头结点后继线程，由于资源为0，所以该后继线程能够获取资源成功，进而继续唤醒后继线程，实现唤醒等待线程的功能。

##### ReentrantLock

- ReentrantLock，**{@link Lock}接口的可重入、互斥锁实现**，与使用{@code synchronized}方法和语句访问的隐式监视器锁具有相同的基本行为和语义，但具有扩展功能，由上次成功lock但尚未unlock的线程拥有：
  - 当锁不属于另一个线程时，调用 {@code lock} 的线程将返回并成功获取锁。
  - 如果当前线程已经拥有锁，该方法将立即返回。 可以使用方法 {@link #isHeldByCurrentThread} 和 {@link #getHoldCount} 进行检查。
- ReentrantLock的构造函数接受一个可选的公平参数，当设置{@code true}时，在争用情况下，锁倾向于授予对**等待时间最长的线程**的访问权限，否则这个锁不能保证这个特定的访问顺序。与使用默认设置的程序相比，使用由多个线程访问的公平锁的程序可能会显示出较低的总体吞吐量（即更慢，通常慢得多），但是能避免线程饥饿问题。
  - 请注意，**锁的公平性并不能保证线程调度的公平性**。因此，使用公平锁的许多线程之一可能会连续多次获得它，而其他活动线程没有进行并且当前没有持有该锁。
  - 另请注意，**未计时的 {@link #tryLock()} 方法不符合公平性设置**。 即使其他线程正在等待，如果锁可用，它也会成功。
- ReentrantLock，建议的做法是，在lock成功获取锁后需要try-finally或try-catch的保护，以确保在必要时unlock。

###### Sync

- **nonfairTryAcquire**：非钩子方法，用于提供公共的**非公平、非阻塞**获取独占资源的方法。
  1. 先获取当前锁次数，如果锁次数为0，则CAS更新锁次数为需要获取的次数，更新成功后设置当前线程为独占线程，然后返回true，代表获取独占资源成功。
  2. 如果锁次数不为0，但当前独占线程为当前线程，则累加需要获取的次数为锁次数，代表**锁重入**，然后返回true，代表获取独占资源成功。
  3. 如果锁次数不为0，当前独占线程也不为当前线程，则返回false，代表获取锁失败，需要等待独占线程释放锁。
- **tryRelease**：实现钩子方法，**作为公共的锁释放方法**，尝试释放独占资源。
  1. 计算剩余锁次数 = 当前锁次数 - 需要释放的锁次数。
  2. 如果当前独占的线程不为当前线程，则抛出IllegalMonitorStateException监视器异常。
  3. 如果当前独占的线程确实为当前线程，如果剩余锁次数为0，则**清空当前独占的线程**、更新锁次数，并返回true，代表锁已经被释放了。
  4. 如果剩余锁次数不为0，则只更新锁次数，然后返回false，代表锁仍然被持有。

###### NonfairSync

- **lock**：实现Lock#lock方法。
  1. CAS更新锁次数为1，只有锁次数为0，才会更新成功，更新成功后设置当前线程为独占线程，实现**非公平提前抢锁成功**的功能。
  2. 如果锁次数不为0，则会更新失败，此时调用AQS#acquire方法非公平+入队+阻塞，实现**非公平、阻塞获取锁**的功能。
- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 调用Sync公共的非钩子方法，用于提供公共的**非公平、非阻塞**获取独占资源的方法。

###### FairSync

- **lock**：实现Lock#lock方法，阻塞获取锁。
  1. 直接调用AQS#acquire方法公平抢锁+入队+阻塞，实现**公平、阻塞获取锁**的功能。
- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 先获取当前锁次数，如果锁次数为0，且AQS主等待队列中不存在任何排队线程，才会使用CAS更新锁次数为需要获取的次数，更新成功后设置当前线程为独占线程，然后返回true，代表获取独占资源成功，实现**公平按排队顺序抢锁**的功能。
  2. 如果锁次数不为0，但当前独占线程为当前线程，则累加需要获取的次数为锁次数，代表**锁重入**，然后返回true，代表获取独占资源成功。
  3. 如果锁次数不为0，当前独占线程也不为当前线程，则返回false，代表获取锁失败，需要等待独占线程释放锁。

###### 阻塞式获取锁

```java
// 阻塞方式获取锁
public void lock() {
    sync.lock();
}

```

###### 可中断式获取锁

```java
// 以阻塞、独占可中断模式获取同步器
public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

```

###### 快速失败式获取锁

```java
// 非公平方式尝试获取锁, 如果可用则获取锁并立即返回值{@code true}; 如果锁不可用, 则立即返回值{@code false}
public boolean tryLock() {
    return sync.nonfairTryAcquire(1);
}

```

###### 定时式获取锁

```java
// 定时可中断式尝试获取锁, 获得则返回true, 否则返回false
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

```

###### 释放锁

```java
// 释放锁
public void unlock() {
    sync.release(1);
}

```

##### ReentrantReadWriteLock

- ReentrantReadWriteLock，{@link ReadWriteLock} 的实现，支持与 {@link ReentrantLock} 类似的语义。
- ReentrantReadWriteLock具有一下属性：
  - **非公平模式（默认）**: 
    - 当构造为**非公平（参数为false）**时，读写锁的进入顺序是未指定的，受重入约束。
    - 持续竞争的非公平锁，可能会无限期推迟一个或多个读或写线程（线程饥饿），但通常比公平锁具有更高的吞吐量。
  - **公平模式**：
    - 当构造为**公平（参数为true）**时，线程使用近似到达顺序策略竞争进入。只有当前持有的锁被释放时，等待时间最长的写线程才会被分配写锁。或者如果有一组读线程等待的时间比所有等待写入器线程都长，则该组将被分配读取锁。
    - 如果写锁被持有，如果有一个试图获取**公平读锁（非可重入）**的线程将被阻塞，那么它将会直到当前等待的最老的写线程获得并释放写锁之后，该线程才会获得读锁。
    - 同理，如果一个等待的写线程放弃等待，留下一个或多个读线程作为队列中最长的等待者，并且写入锁空闲，那么这些读取器将被分配读取锁。
    - 除非读锁和写锁都是空闲的（这意味着没有等待线程），否则尝试获取公平写锁（非可重入）的线程将阻塞。
    - 请注意，非阻塞 {@link ReadLock#tryLock()} 和 {@link WriteLock#tryLock()} 方法不遵守此公平设置，如果可能将会立即获取锁，而不管等待线程。
  - **可重入性**：
    - ReentrantReadWriteLock，允许读和写以 {@link ReentrantLock} 接口的样式重新获取读或写锁。 
    - 但在写线程持有的所有写锁都被释放之前，不允许非可重入读锁。
    - 此外，写线程可以获取读锁，但反之则不行。基于这点，当调用或回调在读锁下，执行读取的方法期间持有写锁时，可重入可能很有用。
    - 而如果读线程试图获取写锁，它将永远不会成功。
  - **锁降级**：
    - 根据可重入性，ReentrantReadWriteLock允许从写锁降级到读锁，通过获取写锁，然后获取读锁，然后释放写锁，此时仍然持有读锁。
    - 但是，无法从读锁升级到写锁，即**只支持锁降级，不支持锁升级**。
  - **锁获取中断**：读锁和写锁，都允许线程在获取锁期间发生中断。
  - **Condition支持**：
    - 写锁提供了一个 {@link Condition} 实现，它的行为方式与写锁相同，就像 {@link ReentrantLock#newCondition} 为 {@link ReentrantLock} 提供的{@link Condition} 实现一样。因此， **该{@link Condition} 只能与写锁一起使用**。
    - **读锁不支持 {@link Condition}**， 并且 {@code readLock().newCondition()} 抛出 {@code UnsupportedOperationException}。
  - **仪表监控**：
    - ReentrantReadWriteLock，支持确定是持有锁还是争用锁的方法。
    - 这些方法设计用于监视系统状态，而不是用于同步控制。
- ReentrantReadWriteLock，可用于在某些类型的集合的某些用途中**提高并发性**。这通常只有在**预期集合很大**、**访问的读取线程比写入线程多**、**读取时需要的开销超过同步的开销**时才有意义。

###### Sync

- **tryAcquire**：实现钩子方法，尝试获取独占资源。
  1. 先获取当前锁状态，根据锁状态获取独占线程的个数（int的低16位）。
  2. 如果锁状态不为0，且独占线程个数为0或者当前独占线程不为当前线程，则返回false，代表存在**读线程不允许获取写锁**。
  3. 如果锁状态不为0，且当前独占线程为当前线程，说明是当前线程获取到了写锁，则累加低16位累加锁次数，然后返回true，代表**写锁重入**。
  4. 否则锁状态为0，如果**获取写锁需要等待**，或者CAS更新累加后的锁状态失败，则返回false，代表**写锁获取失败**。
  5. 如果写锁不需要等待，且CAS更新累加后的锁状态成功后，则设置当前独占线程为当前线程，然后返回true，代表**写锁获取成功**。
- **tryRelease**：实现钩子方法，尝试释放独占资源。
  1. 判断当前独占线程是否为当前线程，如果不是，则抛出监视器异常IllegalMonitorStateException。
  2. 如果当前独占线程为当前线程，则获取锁次数**低16位扣减**需要的锁次数，然后根据扣减后的锁次数，获取写锁次数，如果写锁次数为0，说明**写锁被释放了**，则清空当前独占线程。
  3. 如果写锁仍未释放，或者被释放且清空了独占线程，则更新锁状态，然后返回写锁释放结果，**如果为true，代表写锁释放成功，如果为false，代表写锁仍未释放**。
- **tryAcquireShared**：实现钩子方法，尝试获取共享资源。
  1. 先获取锁状态，根据锁状态获取写锁次数，如果写锁次数不为0，且当前独占线程不为当前线程，则返回-1，代表共享资源获取失败。
  2. 如果写锁次数为0，或者当前独占线程为当前线程，说明没有写线程，或者当前线程已经持有了写锁，则根据锁状态获取读锁次数，如果**获取读锁不需要被阻塞**，则CAS更新**高16位读锁次数**，更新成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），最后返回1，代表读锁获取成功。
  3. 如果**获取读锁需要等待**，或者CAS更新**高16位读锁次数**失败，则开始自旋，如果自旋先判断到独占线程存在，且不为当前线程，则返回-1，代表读锁获取失败，因为**其他线程持有了写锁**。
  4. 否则写锁没被持有，或者写锁被当前线程持有，如果确实在**获取读锁需要等待**（需要在缓存读锁计数失效时返回false），如果缓存中的读锁次数为0（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），说明当前线程的读锁已经释放了，不可继续重入，则返回-1，代表读锁获取失败，因为当前线程不为第一个获得读锁的线程，所以需要重新排队，从而实现**排队获取读锁**。
  5. 如果判断过了独占线程，以及缓存读锁次数后依然没问题，说明当前线程可以继续重入，则CAS更新**高16位读锁次数**，更新成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存），最后返回1，代表读锁获取成功；如果CAS更新失败，在继续自旋判断+重新更新。
- **tryReleaseShared**：实现钩子方法，尝试释放共享资源。
  1. 判断当前线程是否命中一级缓存，缓存读锁次数为1，说明当前线程为最后一个释放读锁的线程，则清空f一级缓存，使得该线程下次能够继续获取读锁；如果读锁次数不为1，说明当前线程还可以继续重入，则减少读锁次数。
  2. 如果当前线程没有命中二级缓存，则更新缓存的读锁次数-1（如果一级缓存命中则获取一级缓存，如果命中二级缓存则获取二级缓存）。
  3. 缓存的读锁次数更新完毕后，则开始自旋，**高16位减少一单位的锁状态**，然后CAS更新，如果CAS更新失败则继续自旋计算+更新。
  4. 否则，CAS更新成功，如果剩余锁状态为0，则返回true，代表读锁释放成功；如果剩余锁状态不为0，则返回false，代表读锁仍未释放成功。
- **tryWriteLock**：尝试以非公平、非阻塞方式获取独占资源（写锁），相比tryAcquire少了writerShouldBlock的调用，即在锁状态为0时，CAS更新累加后的锁状态前，**不需要校验写锁是否需要等待**。
  1. 先获取当前锁状态，根据锁状态获取独占线程的个数（int的低16位）。
  2. 如果锁状态不为0，且独占线程个数为0或者当前独占线程不为当前线程，则返回false，代表存在**读线程不允许获取写锁**。
  3. 如果锁状态不为0，且当前独占线程为当前线程，说明是当前线程获取到了写锁，则累加低16位累加锁次数，然后返回true，代表**写锁重入**。
  4. 否则锁状态为0，如果CAS更新累加后的锁状态失败，则返回false，代表**写锁获取失败**。
  5. 如果CAS更新累加后的锁状态成功后，则设置当前独占线程为当前线程，然后返回true，代表**写锁获取成功**。
- **tryReadLock**：尝试以非公平、非阻塞方式获取共享资源（读锁），相比tryAcquireShared少了对readerShouldBlock的调用，即无需在缓存读锁计数失效时返回false，这些缓存是用于**获取当前线程的读锁重入次数**，以及在控制公平获取读锁时，用于判断线程是可以重入，还是已经释放过了再获取则需要**重新排队**。
  1. 先获取锁状态，根据锁状态获取写锁次数，如果写锁次数不为0，且当前独占线程不为当前线程，则返回-1，代表共享资源获取失败。
  2. 如果写锁次数为0，或者当前独占线程为当前线程，说明没有写线程，或者当前线程已经持有了写锁，则根据锁状态获取读锁次数，如果CAS更新**高16位读锁次数**成功后，则再更新当前线程缓存的读锁次数（如果一级缓存命中则累加一级缓存，如果命中二级缓存则累加二级缓存），最后返回1，代表读锁获取成功。
  3. 如果CAS更新**高16位读锁次数**失败，则继续自旋判断+更新。

###### NonfairSync

- **writerShouldBlock**：获取写锁时是否需要等待。
  - 由于为非公平抢锁，所以返回false，代表**永远不需要等待写锁**，实现**非公平抢锁**的功能。
- **readerShouldBlock**：获取读锁时是否需要等待。
  - 如果AQS主等待队列中头结点后继为独占结点，则返回true，说明第一个线程为独占线程，此时获取读锁需要等待。
  - 如果AQS主等待队列中头结点后继为共享结点，则返回false，说明第一个线程不为独占线程，此时获取读锁不需要等待，实现**非公平抢锁**的功能。

###### FairSync

- **writerShouldBlock**：获取写锁时是否需要等待。
  - 由于为公平抢锁，所以需要判断AQS主等待队列头结点后继的线程实例是否存在，如果存在则返回true，代表需要**公平排队获取写锁**。
- **readerShouldBlock**：获取读锁时是否需要等待。
  - 由于为公平抢锁，所以需要判断AQS主等待队列头结点后继的线程实例是否存在，如果存在则返回true，代表需要**公平排队获取读锁**。

###### 阻塞式获取读锁

```java
// 共享方式获取读锁, 如果写锁未被另一个线程持有，则获取读锁并立即返回; 如果写锁被另一个线程持有, 则当前线程会阻塞
public void lock() {
    sync.acquireShared(1);
}

```

###### 可中断式获取读锁

```java
// 可中断共享方式获取读锁, 如果写锁未被另一个线程持有，则获取读锁并立即返回; 如果写锁被另一个线程持有, 则当前线程会阻塞
public void lockInterruptibly() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

```

###### 快速失败获取读锁

```java
// 非公平、共享方式尝试获取锁, 如果写锁未被另一个线程持有, 则获取读锁并立即返回值 {@code true}; 如果写锁被另一个线程持有，则此方法将立即返回值 {@code false}
public boolean tryLock() {
    return sync.tryReadLock();
}

```

###### 定时式获取读锁

```java
// 非公平、定时、可中断、共享方式尝试获取锁, 如果写锁未被另一个线程持有, 则获取读锁并立即返回值 {@code true}; 如果写锁被另一个线程持有，则此方法将立即返回值 {@code false}
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

```

###### 释放读锁

```java
// 共享方式释放锁, 如果读锁同步器状态现在为0, 则会尝试共享方式释放读锁
public void unlock() {
    sync.releaseShared(1);
}

```

###### 阻塞式获取写锁

```java
// 独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public void lock() {
    sync.acquire(1);
}

```

###### 可中断式获取写锁

```java
// 独占、可中断方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

```

###### 快速失败式获取写锁

```java
// 非公平、独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public boolean tryLock( ) {
    return sync.tryWriteLock();
}

```

###### 定时式获取写锁

```java
// 非公平、定时、可中断、独占方式获取写锁, 如果读锁和写锁都没有被另一个线程持有, 则获取写锁并立即返回, 将写锁持有计数设置为1; 如果当前线程已经持有写锁, 则持有计数加一并且该方法立即返回(重入性); 如果该锁由另一个线程持有，则当前线程将阻塞, 直到获得写锁为止, 然后写锁持有计数设置为1
public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

```

###### 释放写锁

```java
// 独占方式释放锁, 如果当前线程是此锁的持有者, 则持有计数递减; 如果保持计数现在为零, 则锁定被释放; 如果当前线程不是此锁的持有者, 则抛出 {@link IllegalMonitorStateException}
public void unlock() {
    sync.release(1);
}

```

##### Semaphore

- Semaphore，计数信号量，从概念上讲，**信号量维护一组许可**。
  - 每个{@link#acquire}会直到许可证是可用的，然后获取。
  - 每个{@link#RELEASE}添加一个许可，释放阻塞的获取线程。
  - 实际上{@code Semaphore}有维护许可对象，它只是让计数可用，从而采取相应的行动。
- 信号量通常用于限制可以访问某些（物理或逻辑）资源的线程数。 
- Semaphore，可以初始化为 1 的信号量，并且使用时最多只有一个许可可用，用作互斥锁。 这通常被称为**二元信号量**，因为它只有两种状态：一个许可可用，或零个许可可用。以这种方式使用时，二进制信号量具有属性（与许多 {@link java.util.concurrent.locks.Lock} 实现不同），即“锁”可以由所有者以外的线程释放（因为**信号量具有没有所有权的概念**），这在某些特定上下文中很有用，例如**死锁恢复**。
- Semaphore的构造函数可以选择接受公平参数：
  - 当公平性设置为 false 时，为非公平模式，则不保证线程获取许可的顺序。特别是，允许插入，即调用 {@link #acquire} 的线程可以在一直等待的线程之前，分配一个许可（逻辑上，新线程将自己置于等待线程队列的头部）。
  - 当公平性设置为true时，为公平模式，信号量保证调用任何 {@link #acquire()acquire} 方法的线程被选择以按照它们对这些方法的调用的处理顺序（先进先出）获得许可。
  - 请注意，未计时的 {@link #tryAcquire() tryAcquire} 方法**不遵守公平设置**，但会采用任何可用的许可。
  - 通常，**用于控制资源访问的信号量应初始化为公平的**，以确保没有线程因访问资源而饿死。 当使用信号量进行其他类型的同步控制时，**非公平排序的吞吐量大于公平性排序的吞吐量**。

###### Sync

- **tryReleaseShared**：实现钩子方法，自旋尝试释放共享资源，直到释放到许可则返回true。这里的共享释放，做的是**许可的累加，而非传播**。
  1. 开始自旋，获取最新的许可数量，计算累加需要释放的许可数量，如果累加后的结果反而还小了，则抛出错误，因为**不能释放负数的许可**。
  2. 否则CAS更新许数量为累加后的结果，如果CAS成功，则返回true，代表获取许可成功，否则继续自旋。
- **nonfairTryAcquireShared**：非钩子方法，非公平自旋方式获取共享资源，直到获取到才返回剩余许可。
  1. 开始自旋，获取最新的许可数量，扣减需要获取的许可数量，如果扣减后的剩余许可数量小于0，则返回负数，代表资源获取失败。
  2. 如果剩余许可数量大于等于0，则CAS更新许可数量，更新成功则**返回剩余许可数量**，否则继续自旋。

###### NonfairSync

- **tryAcquireShared**：实现钩子方法，底层调用Sync#nonfairTryAcquireShared方法，会非公平自旋方式获取共享资源。

###### FairSync

- **tryAcquireShared**：实现钩子方法，对比Sync#nonfairTryAcquireShared方法，扣减许可前会先判断AQS主队列头结点后继线程是否已经存在，如果是则返回-1，代表获取共享资源失败，需要去排队。

###### 可中断阻塞式获取许可

```java
// 以阻塞、共享可中断模式获取同步器状态
public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

```

###### 不可中断阻塞式获取许可

```java
// 以阻塞、不可中断、共享模式获取同步器状态
public void acquireUninterruptibly() {
    sync.acquireShared(1);
}

```

###### 快速失败式获取许可

```java
// 非公平快速失败方式获取同步器状态
public boolean tryAcquire() {
    return sync.nonfairTryAcquireShared(1) >= 0;
}

```

###### 定时式获取许可

```java
// 以阻塞、共享、定时、可中断模式获取同步器状态
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

```

###### 释放许可

```java
// 尝试释放共享模式的同步器状态, 如果释放成功, 则返回true; 如果释放失败, 则返回false
public void release() {
    sync.releaseShared(1);
}

```

##### ThreadPoolExecutor

###### Worker

线程工人类，实现Runnable本身可以作为一个任务，实现AQS以简化获取和释放围绕每个任务执行的锁，实现了一个简单的**不可重入的、互斥的任务锁**。

- **tryAcquire**：实现钩子方法，尝试获取独占资源，如果更新锁计数为1，则设置当前线程为独占线程，然后返回true，代表获取独占锁成功；否则返回false，代表获取独占锁失败。
- **tryRelease**：实现钩子方法，尝试释放独占资源，清空独占线程，并重置锁计数为0，永远返回true，代表独占锁释放成功。

###### 阻塞式获取锁

```java
// 阻塞式获取锁, 快速失败失败还会进去AQS队列中排队
public void lock()        { acquire(1); }

```

###### 快速失败式获取锁

```java
// 快速失败式获取锁, 只会将0 CAS更新为1(unused没用), CAS成功则设置当前线程为独占线程, 并返回true, 代表获取成功, 否则返回false, 代表获取失败
public boolean tryLock()  { return tryAcquire(1); }

```

###### 释放锁

```java
// 释放锁, 只会将同步状态设置为0, 并清空独占线程以及返回true, 代表释放成功
public void unlock()      { release(1); }

```

##### CyclicBarrier

- CyclicBarrier，一种同步辅助工具，它允许一组线程全部等待彼此到达公共屏障点，在涉及固定大小的线程组的程序中很有用。
- CyclicBarrier屏障之所以被称为Cyclic循环的，因为它可以在等待线程被释放后**重新使用**。
- {@code CyclicBarrier} 支持一个可选的 {@link Runnable} 命令，该命令在每个屏障点运行一次，在参与者中的最后一个线程到达之前，其他参与者线程都会被阻塞。此屏障操作对于在任何一方继续之前更新共享状态很有用，为方便起见，每次调用 {@link #await}（被唤醒后） 都会返回该线程在屏障处的**到达索引**。
- {@code CyclicBarrier}的每次使用都表示为一个生成Generation实例，每当障碍物被触发或重置时，Generation都会发生变化，因此可以有许多Generation与使用{@code CyclicBarrier}的线程相关联。
  - 由于锁以不确定的方式分配给等待线程，但一次只能激活Generation其中之一，因此其余的Generation要么坏了要么被绊倒了。
  - 另外，如果有中断但没有后续复位，则该Generation将损坏。

###### await

1. 先阻塞式获取栅栏入口的ReentrantLock，获取到后则获取分代实例Generation，如果发现Generation已经损坏，则抛出BrokenBarrierException异常。
2. 如果Generation还没损坏，则再检验当前线程的中断状态，如果已中断，则破坏当前Generation，重置栅栏参与线程数，并唤醒所有等待的线程。
3. 如果Generation还没损坏，且当前线程没被中断，说明当前线程达到了栅栏，因此参与数-1。
4. 如果减少到了0，说明当前线程为最后一个到达栅栏的线程，则还需要运行栅栏任务（如果有），生成下一代Generation，重置栅栏参与线程数，并唤醒所有等待的线程，并返回0，代表最后一个到达栅栏的索引。
5. 如果还没减少到0，则开始自旋，如果不需要超时，则调用Condiction#await阻塞当前线程，如果还没发生超时，则调用Condiction#awaitNanos定时阻塞当前线程。
6. 当最后一个线程达到栅栏，或者等待期间任意一个线程发生了中断，会破坏当前Generation，唤醒所有线程，如果唤醒后判断到当前Generation已损坏，则抛出BrokenBarrierException异常。
7. 如果Generation没损坏，但已被更新，说明最后一个线程确实到达了栅栏，则返回当前线程达到索引（越接近0，说明越完到达）。
8. 如果Generation没损坏，但没被更新，说明当前线程发生了等待超时，则破坏当前Generation，唤醒所有线程，并抛出超时异常TimeoutException。
9. 最后释放栅栏入口的ReentrantLock。

### 4.7. synchronized与ReentrantLock与的区别？

| 区别点   | Synchronized                   | ReentrantLock                    |
| -------- | ------------------------------ | -------------------------------- |
| 使用方式 | 是一个关键字                   | 是一个实现类                     |
| 实现方式 | 由JVM实现控制                  | 由AQS实现控制                    |
| 锁的获取 | 如果资源被锁，会一直等待       | 如果资源被锁，可以有多种处理方式 |
| 锁的释放 | 被锁的代码执行完，或者发生异常 | 需要在finally中，手动编程释放    |
| 锁的状态 | 无法判断                       | 可以判断，isLocked（）           |
| 锁的特性 | 可重入、不可中断、非公平锁     | 可重入、可中断、公平锁、非公平锁 |

```java
【ReentrantLock可中断锁】
ReentrantLock中的lockInterruptibly()方法使得线程可以在被阻塞时响应中断，比如一个线程t1通过lockInterruptibly()方法获取到一个可重入锁，并执行一个长时间的任务，另一个线程通过interrupt()方法就可以立刻打断t1线程的执行，来获取t1持有的那个可重入锁。
而通过ReentrantLock的lock()方法或者Synchronized持有锁的线程是不会响应其他线程的interrupt()方法的，直到该方法主动释放锁之后才会响应interrupt()方法。

```

### 4.8. 内存泄露与内存溢出？

#### 内存泄露

内存泄漏，memory leak，指不再用到的内存没有及时释放。

- 对于持续运行的服务进程必须及时释放内存，否则系统可用的内存会越来越小，内存占用率越来越高，轻则影响系统性能，重则导致内存不足、进程崩溃甚至操作系统崩溃。

#### 内存溢出

内存溢出，out of memory，指应用所需要的内存超过了系统所能分配的内存，从而导致应用没法正常工作，直接后果是导致应用程序崩溃，严重了还会导致系统安全问题。

- 内存溢出无法根本解决，只能尽可能避免，比如说在应用程序申请内存之前对可用内存进行检查、增大分配给应用的内存、优化程序代码、减少应用中的大数据复杂操作等。

### 4.9. 详细介绍ThreadLocal？

#### 背景

- 为了保证多个线程对变量的安全访问，将变量放到某个对象中，使变量在每个线程中都有独立值，不会出现一个线程读取变量时，被另一个线程修改的现象，JDK设计了ThreadLocal类，通常被翻译为“**线程本地变量**”类或者“**线程局部变量**”类。
  1. 如果程序创建了一个ThreadLocal实例，那么在访问这个变量的值时，每个线程都会拥有一个独立的、自己的本地值。
  2. “线程本地变量”可以看成专属于线程的变量，不受其他线程干扰，保存着线程的专属数据。
  3. 当线程结束后，每个线程所拥有的那个本地值会被释放。在多线程并发操作“线程本地变量”的时候，线程各自操作的是自己的本地值，从而规避了线程安全问题。

#### 特点

- ThreadLocal，**提供线程局部变量**，依赖于附加到每个线程的Map中，即Thread.threadLocals 和inheritableThreadLocals，使得每个访问的线程都有**自己的、独立的变量副本**。
  - 在该Map中**ThreadLocal 对象充当键**，通过threadLocalHashCode进行搜索，这是一个自定义哈希代码（仅在 ThreadLocalMaps 中有用），它消除了在相同线程使用连续构造的 ThreadLocals 的常见情况下的冲突，同时在不太常见的情况下保持良好行为。
  - 只要线程处于活动状态，并且 {@code ThreadLocal} 实例可访问，每个线程都持有对其线程局部变量副本的**隐式引用**；线程消失后，它的所有线程本地实例副本都将进行**垃圾回收**（除非存在对这些副本的其他引用）。
- ThreadLocal是**解决线程安全问题**的一个较好的方案，通过为每个线程提供一个独立的本地值去解决并发访问的冲突问题。在很多情况下，使用ThreadLocal比直接使用同步机制（如synchronized）解决线程安全问题更简单、更方便，且结果程序**拥有更高的并发性**。其使用场景大致可以分为以下两类：
  - **线程隔离**：
    - ThreadLocal的主要价值在于线程隔离，ThreadLocal中的数据只属于当前线程，其本地值对别的线程是不可见的，在多线程环境下，可以防止自己的变量被其他线程篡改。
    - 另外，由于各个线程之间的数据相互隔离，**避免了同步加锁**带来的性能损失，大大提升了并发性的性能。
    - 常见的案例有：数据库连接独享、Session数据管理等，由于每个线程绑定一个数据库连接，使得这个数据库连接为线程所独享，从而避免数据库连接被混用而导致操作异常问题。
  - **跨函数传递数据**：
    - 因为ThreadLocal的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到，线程执行过程中所执行到的函数，都能读写ThreadLocal变量的线程本地值，从而可以方便地实现跨函数的数据传递。
    - 使用ThreadLocal保存函数之间需要传递的数据，在需要的地方直接获取，也能**避免通过参数传递数据带来的高耦合**。
    - 常见的案例有：用来传递请求过程中的用户ID、请求过程中的Session、HTTP的用户请求实例HttpRequest，以及其他在函数之间频繁传递的数据等。

#### 实现原理

##### 早期实现

- 早期版本的ThreadLocal是这样设计的，一个ThreadLocal实例可以形象地理解为一个Map，当工作线程Thread实例向本地变量保持某个值时，会以“Key-Value对"的形式保存在ThreadLocal内部的Map中。
- 其中Key为线程**Thread实例**，Value为待保存的值，当工作线程Thread实例从ThreadLocal本地变量取值时，会以Thread实例为Key，获取其绑定的Value。

![1630407029053](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630407029053.png)

##### 优化后的实现

- 经过后来的优化后（下面的源码都以优化后的数据结构为准），ThreadLocal的内部结构发生了演进，虽然还是使用了Map结构，但是Map结构的拥有者已经发生了变化，其拥有者为Thread实例，**每一个Thread实例拥有一个Map实例**，且Key值也发生了变化，由之前的Thread实例更改为了**ThreadLocal实例**。
- 每一个Thread线程内部都有一个ThreadLocalMap，如果给一个Thread创建多个ThreadLocal实例，然后放置本地数据，那么当前线程的ThreadLocalMap中就会有多个“Key-Value对”，其中ThreadLocal实例为Key，本地数据为Value。
- 每一个线程在获取本地值时，都会将ThreadLocal实例作为Key从自己拥有的ThreadLocalMap中获取值，别的线程无法访问自己的ThreadLocalMap实例，自己也无法访问别人的ThreadLocalMap实例，达到相**互隔离，互不干扰**。

![1630411048268](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630411048268.png)

##### 变化点

| 变化点                         | 早期实现            | 优化后的实现    |
| ------------------------------ | ------------------- | --------------- |
| Key发生了变化                  | Thread实例          | ThreadLocal实例 |
| ThreadLocalMap拥有者发生了变化 | 拥有者为ThreadLocal | 拥有者为Thread  |

##### 优化的好处

- **每个ThreadLocalMap存储的“Key-Value对”数量变少**，早期版本的“Key-Value对”数量与线程个数强关联，如果线程数量多，则ThreadLocalMap存储的“Key-Value对”数量也多，而新版本的ThreadLocalMap的Key为ThreadLocal实例，多线程情况下ThreadLocal实例比线程数少。
- 早期版本ThreadLocalMap的拥有者为ThreadLocal，在Thread实例销毁后，ThreadLocalMap还是存在的；而新版本的ThreadLocalMap的拥有者为Thread，在当Thread实例销毁后，ThreadLocalMap也会随之销毁，**在一定程度上能减少内存的消耗**。

#### 线程本地变量

```java
public class Thread implements Runnable {
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
    ...
}

// ThreadLocal.ThreadLocalMap
public class ThreadLocal<T> {
    static class ThreadLocalMap {
        private static final int INITIAL_CAPACITY = 16;// 初始容量，必须是2的幂
        private Entry[] table;// 散列表，table.length必须始终是2的幂
        private int size = 0;// 散列表实际大小
        private int threshold;// 散列表阈值

        // 条目对象
        static class Entry extends WeakReference<ThreadLocal<?>> {
            Object value;

            // Entry#Key 强引用=> WeakReference 弱引用-> ThreadLocal:v
            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
    }
}

```

##### 设置原理

**Thread#set**：设置当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果获取到的ThreadLocalMap实例为空，说明本地变量还没初始化，则调用setInitialValue方法设置初始值，先获取初始值, 如果ThreadLocal.ThreadLocalMap threadLocals已被初始化, 则为其赋初值, 否则**惰性构造**默认容量16、默认负载因子16 * 2/3、当前ThreadLocal实例作为第一个Entry#Key的ThreadLocalMap。
3. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则直接返回即可。
4. 如果获取到的Entry弱键为空，说明存在弱键已失效，则清空该槽设置一个弱键包装后的key-value条目，然后向后清空所有弱键为空的槽。
5. 如果获取到的Entry为null，则新增一个key-value条目，更新实际大小，向后清除清空所有弱键为空的槽。
6. 接着判断**是否需要扩容**，如果当前实际大小大于等于阈值（len *  1/2），说明需要扩容，则调用resize方法进行扩容，否则直接返回即可。
   - **ThreadLocalMap#resize**：ThreadLocalMap扩容方法，创建两倍容量的新散列表 -> 遍历旧表，重新计算该元素在新表上的索引，转移结点到新表 -> 根据新表容量设置阈值（len * 2/3）-> 更新新表、更新实际大小 -> 最后返回。

##### 删除原理

**Thread#remove**：删除当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则清空WeakReference.referent（即清空弱键，会导致e.get()返回null），然后清空该槽，并且向后清空所有弱键为空的槽，最后返回。

##### 获取原理

**Thread#get**：获取当前线程的本地变量原理。

1. 先获取当前线程实例，然后调用getMap方法，获取该实例的成员变量**Thread#threadLocals**，即ThreadLocalMap实例。
2. 如果获取到的ThreadLocalMap实例为空，说明本地变量还没初始化，则调用setInitialValue方法设置初始值，先获取初始值, 如果ThreadLocal.ThreadLocalMap threadLocals已被初始化, 则为其赋初值, 否则**惰性构造**默认容量16、默认负载因子16 * 2/3、当前ThreadLocal实例作为第一个Entry#Key的ThreadLocalMap。
3. 如果ThreadLocalMap实例已被初始化，则根据**ThreadLocal中的散列码**来计算散列表索引，来获取ThreadLocalMap中的Entry，如果Entry不为空，且**弱键为当前ThreadLocal实例**，说明该Entry就是要找的Entry，则直接返回即可。
4. 如果根据计算出来的索引获取不到Entry，则调用getEntryAfterMiss查找：如果弱键为空，说明存在弱键已失效，则清空该槽，并且向后清空所有弱键为空的槽；否则向后线性探测下一个Entry，继续遍历；如果**线程探测+清空缓存**后，仍然找不到key匹配的Entry，则返回null。

#### 内存泄露

##### ThreadLocal实例内存泄露

- **场景举例**：线程tn调用funcA()方法新建了一个ThreadLocal实例，使用local局部变量指向这个实例，接着set方法设置100后，调用get方法获取一次。

  ```java
  public void funcA() {
      ThreadLocal<Integer> local = new ThreadLocal<>();
      local.set(100);
      local.get();
  }
  
  ```

- **弱键的好处**：

  1. local是强引用，在set方法设置后，线程tn的ThreadLocalMap成员内部会新建一个Entry实例，其Key以**弱引用包装**的方式指向ThreadLocal实例。
  2. 当线程tn执行完funcA()方法后，funcA()的方法栈帧将被销毁，栈帧中的强引用local会被回收，而由于线程tn仍在继续，导致Thread#ThreadLocalMap中对应的Entry.Key引用还指向ThreadLocal实例。
  3. **如果Entry的Key引用是强引用**，则会导致Key引用指向的ThreadLocal实例及其Value值，都不能被GC回收，这将造成严重的**内存泄漏**问题。
  4. **如果Entry的Key引用是弱引用**，由于ThreadLocalMap中Entry的Key使用了弱引用，在下次GC发生时，就可以使那些没有被其他强引用指向、仅被Entry的Key所指向的**ThreadLocal实例能被顺利回收**，在Entry的Key引用被回收之后，其Entry的Key值变为null，后续当ThreadLocal的get()、set()或remove()被调用时，ThreadLocalMap的内部代码会**清除这些Key为null的Entry**，从而完成相应的内存释放，**避免ThreadLocal内存泄露**。

  ![1630466341260](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630466341260.png)

##### Entry.value内存泄露

ThreadLocal虽然使用了弱键，但仍导致内存泄漏，发生条件如下（同时满足）：

1. **线程长时间运行而没有被销毁**。

   - 在线程池中的Thread实例很容易满足此条件。

2. ThreadLocal引用被设置为null，且后续在同一Thread实例执行期间，没有发生对其他ThreadLocal实例的**get()、set()或remove()**操作。

   - 如果后续没有调用过任何get()、set()或remove()操作，弱键的ThreadLocal实例被回收后，key为null，但Entry没有被回收，出现了Entry.value的内存泄露。
   - 只要存在一个针对任何ThreadLocal实例的get()、set()或remove()操作，就会触发Thread实例拥有的ThreadLocalMap的Key为null的**Entry清理工作**，释放掉ThreadLocal弱引用为null的Entry，避免**Entry.value的内存泄露**。

   ![1630483124536](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630483124536.png)

##### static & final内存泄露

- **使用static、final的好处**：
  - ThreadLocal实例作为ThreadLocalMap的Key，针对一个线程内的所有操作是共享的，所以建议设置static修饰符，以便被所有的对象共享。由于静态变量会在类第一次被使用时装载，只会分配一次存储空间，此类的所有实例都会共享这个存储空间，所以**使用static修饰ThreadLocal就会节约内存空间**。
  - 为了**确保ThreadLocal实例的唯一性**，除了使用static修饰之外，还会使用final进行加强修饰，以防止其在使用过程中发生动态变更。
  - 此外，ThreadLocal实例常常添加private修饰呢，主要目的是**缩小使用的范围**，尽可能不让他人引用。
- **static、final导致内存泄露的原因**：
  - 使用static、final修饰ThreadLoacl实例，ThreadLoacl实例会以单例形式存在，导致指向该ThreadLoacl实例的ThreadLocalMap#Entry.Key在Thread实例的生命期内始终保持为非null，从而导致Key所在的Entry不会被自动清空，这就会让Entry中的Value指向的对象一直被Entry强引用，于是Value指向的对象在线程生命期内不会被释放，导致发生内存泄漏。
  - 因此，在使用完static、final修饰的ThreadLocal实例之后，必须**调用remove()**来进行显式的释放操作。

##### 避免内存泄露总结

可见，使用ThreadLocal容易发生内存泄漏，如果能保证使用完ThreadLocal**及时调用remove方法**，则可以简单、有效地避免内存泄漏的发生。

# 四、MySQL篇

### 1.1. 为什么使用数据库？

使用数据库保存数据，**既能保证数据永久保存，又能兼顾查询效率**。

| 数据保存位置 | 内存中           | 文件中                                                      | 数据库中                                                     |
| ------------ | ---------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| 优点         | 存取速度快       | 数据永久保存                                                | 1）数据永久保存；2）使用SQL语句，查询方便效率高；3）管理数据方便 |
| 缺点         | 数据不能永久保存 | 1）速度比内存操作慢；2）需要频繁的IO操作；3）查询数据不方便 | -                                                            |

### 1.2. 数据库OLTP与OLAP的区别？

数据处理大致可以分成两大类：OLTP和OLAP。

- **OLTP**：
  - Online Transaction Processing，**联机事务处理系统**，表示事务性非常高的系统，一般都是高可用的在线系统，以小的事务以及小的查询为主，评估其系统的时候，一般看其每秒执行的Transaction以及Execute SQL的数量。
  - 在OLTP系统中，单个数据库每秒处理的Transaction往往超过几百个，或者是几千个，Select 语句的执行量每秒几千甚至几万个，典型系统有电子商务系统、银行、证券等。
  - OLTP 系统，是一个数据块变化非常频繁、SQL 语句提交非常频繁的系统，因此出现瓶颈的地方就是CPU与磁盘子系统。
    - 对于数据块来说，应尽可能让数据块保存在内存当中；对于SQL来说，尽可能使用变量绑定技术来达到SQL 重用，减少物理I/O 和重复的SQL 解析，从而极大的改善数据库的性能。 
- **OLAP**：
  - Online Analytical Processing，**联机分析处理系统**，也叫DSS决策支持系统，就是大家所说的数据仓库。
  - 在OLAP系统中，语句的执行量不是考核标准，因为一条语句的执行时间可能会非常长，读取的数据也非常多，所以，考核的标准往往是磁盘子系统的吞吐量（带宽），如能达到多少MB/s的流量。
    - 磁盘子系统的吞吐量往往取决于磁盘的个数，应尽量采用个数比较多的磁盘以及比较大的带宽，如4Gb的光纤接口。

|          | OLTP                                 | OLAP                             |
| -------- | ------------------------------------ | -------------------------------- |
| 定位     | 基本日常的事务处理                   | 复杂分析、决策支持               |
| 强调指标 | 内存命中率、SQL变量绑定、SQL并发执行 | SQL执行时长、磁盘I/O、带宽吞吐量 |
| 数据     | 当前的、最新的、细节的               | 历史的、聚集的、统一的           |
| 读写方式 | 每次读写数十条记录                   | 每次读上百万条记录               |
| 工作单位 | 简单的事务                           | 复杂的查询                       |
| DB大小   | 100MB-GB                             | 100GB-TB                         |

### 1.3. 数据库产品对比？

| 产品           | 优点                                                        | 缺点                                             | 备份                                      | 高可用                                         | 适用场景                                   |
| -------------- | ----------------------------------------------------------- | ------------------------------------------------ | ----------------------------------------- | ---------------------------------------------- | ------------------------------------------ |
| 关系型数据库   |                                                             |                                                  |                                           |                                                |                                            |
| MySQL          | 支持事务、开源免费                                          | 数据量大时，需要进行水平拆分                     | mysqldump逻辑备份，xtrabackup工具物理备份 | 主从（读写分离）、分片集群                     | 中小型LAMP                                 |
| Oracle         | 支持事务、支持大字段、性能最高                              | 管理维护麻烦、价格昂贵                           | exp逻辑备份，RMAN工具物理备份             | 双机热备、Oracle Dataguard主从、Oracle RAC集群 | 大部分事业单位                             |
| SQL Server     | 方便易用                                                    | 只能运行在windows平台、性能不够稳定              | -                                         | -                                              | windows平台OLTP                            |
| PostgreSQL     | 支持事务、稳定性强、性能高                                  | 扩容麻烦、MVCC并发版本需定期清理                 | COPY命令逻辑备份，pgdump物理备份          | 主从、Slony-I第三方组件做数据同步、集群有bug   | 地理位置信息处理                           |
| SQLite         | 自给自足、无需服务器、开源免费                              | 只能本地嵌入，无法远程访问                       | -                                         | -                                              | 嵌入式设备、本地应用程序                   |
| DB2            | 并行性高、适合海量数据                                      | -                                                | -                                         | -                                              | 数据仓库、数据挖掘                         |
| 非关系型数据库 |                                                             |                                                  |                                           |                                                |                                            |
| Redis          | 单线程、支持K-V以及多种数据结构存储、支持持久化，适合热数据 | 容量受内存限制，不便于海量数据读写，不适合冷数据 | RDB、AOF                                  | 主从、哨兵、集群                               | 缓存、最新回复、点赞数、共同好友、排行榜   |
| MemCache       | 多线程、性能高、速度快，用于减轻数据库负载                  | 不支持持久化、只能存储K-V数据                    | 不支持                                    | 集群没有同步复制机制                           | 前端缓存、用户信息、好友信息、文章信息     |
| MongoDB        | 文档结存存储、海量数据性能优越                              | 不支持事务、占用空间大、无法关联查询             | mongoexport逻辑备份、mongodump物理备份    | 主从、1.6 ReplicaSets复制集故障时自动切换      | Json文件、日志分析、敏捷开发、地理位置信息 |

### 1.4. MySQL与Oracle的使用区别？

#### MySQL

- MySQL是一个**关系型数据库管理系统**，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品，是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的关系数据库管理系统之一。
  - **关系数据库**：指将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。
- MySQL所使用的SQL语言，是用于访问数据库的最常用标准化语言，采用了双授权政策，分为社区版和商业版，由于其**体积小、速度快、总体拥有成本低**，尤其是**开放源码**这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。
  - **SQL**：Structured Query Language，结构化查询语言，是一种数据库查询语言，用于**存取数据、查询、更新和管理**关系数据库系统。

#### Oracle

Oracle Database，又名Oracle RDBMS，简称Oracle，是甲骨文公司的一款关系数据库管理系统，系统可移植性好、使用方便、功能强，适用于各类大、中、小微机环境，是一种**高效率的、可靠性好的、适应高吞吐量**的数据库方案。

| 区别         | Oracle                                                       | MySQL                                                        |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 开源免费与否 | 收费                                                         | **开源免费**                                                 |
| 超长文本处理 | 使用CLOB类型                                                 | 使用text和longtext类型                                       |
| 日期字段查询 | select * from tb1 where dt>to_date('2020-09-13 12:15:01', 'yyyy-MM-dd hi24:mi:ss'); | select * from tb1 where dt>'2020-09-13 12:15:01';            |
| 分页实现     | select * from (select t.*,rownum num from tb1 t where rownum<=100 ) where num>50; | select username from tb1 limit 50, 100;                      |
| group by     | 不允许返回group by外的其他字段                               | 可以任意返回一个字段值                                       |
| 修改字段类型 | 空字段直接改，不允许更改字段名称，改类型必须保证正确         | alter table tb1 change column f1_old f1_new int(11) comment 'xxx'; |
| 表字段注释   | 只能在创建字段之后指定                                       | 可以在建表时指定，也可以在建表完成后修改                     |
| 字段移位     | 建表后不能移位                                               | 建表之后可以修改字段顺序                                     |
| 创建索引     | 只能在建表完成后添加                                         | 可以在建表时添加，也可以在建表完成后添加                     |
| 查询建表语句 | select  dbms_metadata.get_ddl(table, 'tb1') from dual;       | show create table tb1;                                       |
| 查询执行计划 | explain plan for select + select * from table(dbms_xplan.display()); | explain select                                               |

### 1.5. MySQL数据类型？

- **整数类型**：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。
  - 任何整数类型都可以加上UNSIGNED属性，表示数据是无符号的，即非负整数。
  - 整数类型可以被指定长度，但在大多数场景是没有意义的，不会限制值的合法范围，只会影响显示字符的个数，而且需要和UNSIGNED ZEROFILL属性配合使用才有意义。
    - 比如，如果用户插入的数据为12的话，那么数据库实际存储数据为00012。
- **实数类型**：FLOAT、DOUBLE、DECIMAL。
  - **DECIMAL**：可以用于存储比BIGINT还大的整型，能存储精确的小数。
  - **FLOAT和DOUBLE**：有取值范围，并支持使用标准的浮点进行近似计算。
    - 计算时，FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL可以理解成是用字符串进行处理。
- **字符串类型**：VARCHAR、CHAR、TEXT、BLOB。
  - **尽量避免使用TEXT/BLOB类型**，查询时会使用临时表，导致严重的性能开销。
  - 使用时要注意只分配需要的空间，更长的列排序时会消耗更多内存。
  - **varchar与char**：对于经常变更的数据来说，CHAR比VARCHAR更好，因为CHAR**不容易产生碎片**；对于非常短的列，CHAR比VARCHAR在**存储空间上更有效率**。
    - **varchar**：使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用1字节表示，否则使用2字节表示，当存储的内容超出设置的长度时，内容会被截断。
      - 用于存储可变长字符串，它比定长类型更节省空间。
    - **char**：字段定长，根据定义的字符串长度分配足够的空间，会根据需要使用空格进行填充，当存储的内容超出设置的长度时，内容会被截断。
      - 适合存储很短的字符串，或者所有值都接近同一个长度。
- **日期类型**：timestamp、datetime。
  - **尽量使用timestamp**，空间效率高于datetime。
  - 如果需要存储微妙，可以使用bigint存储。

### 1.6. MySQL存储引擎？

存储引擎，Storage engine，是**MySQL的一套文件系统实现**，使用各种不同的技术将数据存储在文件或内存中，通过使用不同的存储机制、索引技巧、锁定水平，来提供不同的能力，以使得能够获得额外的速度或者功能，从而改善应用的整体功能。

- **Innodb**：提供对事务的支持，还提供了行、表锁以及外键的约束，索引与数据同一文件。
  - 适合更新和删除操作频率高，要保证数据的完整性的、并发量高的场景，比如OA自动化办公系统。如果没有特别的需求，使用默认的InnoDB即可。
- **MyIASM**：不提供事务的支持，不支持行锁和外键，索引与数据在不同的文件。
  - 适合以读写插入为主的应用程序，比如博客系统、新闻门户网站。
- **MEMORY**：所有的数据都在内存中，数据的处理速度快，但是安全性不高。

### 1.7. MySQL锁分类？

当数据库发生**并发事务**时，需要**锁机制**来保证访问的次序，以满足事务的**隔离性**，最终保证**数据的一致性**。

#### 悲观锁和乐观锁

从**事务进入临界区前是否锁住同步资源的角度**来分：

- **悲观锁**：先锁再用。
  - 就是悲观思想，事务每次进入临界区操作数据的时候都认为别的事务会修改，所以事务每次在读写数据时都会**上锁**，锁住同步资源，这样其他事务需要读写这个数据时就会**阻塞**，一直等到拿到锁。
  - 适用于**写多读少**的场景，遇到**高并发写时性能高**，比如MySQL的**排他锁**。
- **乐观锁**：用时检查。
  - 是一种乐观思想，事务每次去拿数据的时候都认为别的事务不会修改，所以**不会上锁**，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复**读-比较-写**的操作。
  - 适用于**读多写少**的场景，遇到**高并发写时性能低**，MySQL的乐观锁可以通过**Version+SQL判断**实现。

#### 排他锁和共享锁

按照**锁定资源的方式**来分：

- **共享锁**：Shared lock，简称S锁，允许持有锁读取行的事务，即读锁，加锁时将自己和子节点全加S锁，父节点直到表头全加IS锁。
  - **兼容性**：读写互斥，加了S锁的记录，允许其他事务再加S锁，不允许其他事务再加X锁。
  - **加锁方式**：select … lock in share mode。
- **排他锁**：Exclusive lock，简称X锁，允许持有锁修改行的事务，即写锁， 加锁时将自己和子节点全加X锁，父节点直到表头全加IX锁 。
  - **兼容性**：写读互斥，写写互斥，加了X锁的记录，不允许其他事务再加S锁或者X锁。
  - **加锁方式**：select … for update。

#### 表锁和行锁

按照**锁定资源的粒度**来分：

##### 表锁

Mysql中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单 ，资源消耗也比较少，加锁快，不会出现死锁 。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，**MyISAM和 InnoDB引擎都支持表级锁**。

###### 意向锁

Intention Locks，表明某个事务正在某些行持有了锁，或该事务准备去持有锁，其存在是为了**协调行锁和表锁**的关系，支持多粒度的锁（表锁与行锁）并存。

- **意向共享锁**：Intention shared lock，IS，事务有意向对表中的某些行加S锁，在请求S锁前，要先获得IS锁。
- **意向排他锁**：Intention exclusive lock，IX，事务有意向对表中的某些行加X锁，在请求X锁前，要先获得IX锁。
- **意向锁举例**：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞，因此意向锁通过这种**锁叠加的方式**实现了行锁和表锁共存，并且满足了事务隔离性的要求。
- **为什么意向锁是表级锁**：当需要加一个排他锁时，需要根据意向锁去判断表中**有没有数据行被锁定**，此时如果意向锁是行锁，则需要遍历每一行数据去确认，性能低下；而如果意向锁是表锁，则只需要**判断一次**即可知道有没数据行被锁定，**性能较高**。
- **意向锁兼容性**：指当事务A对某个数据范围（行或表）上了“某锁”后，另一个事务B是否能在这个数据范围上“某锁”，可见，意向锁之间、读锁与意向锁之间互相兼容，写锁与其他锁之间都不兼容。

| 互斥性       | 共享锁（S） | 排它锁（X） | 意向共享锁IS | 意向排他锁IX |
| ------------ | ----------- | ----------- | ------------ | ------------ |
| 共享锁（S）  | ✅           | ❌           | ✅            | ❌            |
| 排它锁（X）  | ❌           | ❌           | ❌            | ❌            |
| 意向共享锁IS | ✅           | ❌           | ✅            | ✅            |
| 意向排他锁IX | ❌           | ❌           | ✅            | ✅            |

###### 自增锁

AUTO-INC Locks，是一种特殊的表级锁，发生涉及**AUTO_INCREMENT**列的事务性插入操作时产生。

##### 行锁

Mysql中锁定粒度最小的一种锁，只针对当前操作的行进行加锁，能大大减少数据库操作的冲突，其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。**InnoDB默认使用行锁**，按**锁算法**的角度来分，InnoDB支持的行锁包括如下几种：

###### 记录锁

Record Lock，对**索引项**加锁，锁定**符合条件的行**，其他事务不能修改和删除加锁项。

- 如果该表上没有任何索引，那么InnoDB会在后台创建一个隐藏的聚蔟主键索引，那么锁住的就是这个隐藏的**聚蔟主键索引**。

###### 间隙锁

Gap Lock，对索引项之间的间隙加锁，锁定**记录的范围，不包含索引项本身**，其他事务不能在锁范围内插入数据。

- 比如在 1、2、3中，间隙锁的可能值有 (∞, 1)，(1, 2)，(2, ∞)。
- 可用于**防止幻读**，保证索引间的不会被插入数据。

###### 临建锁

Next-key Lock，锁定索引项本身和索引范围，**左开右闭区间**，即Record Lock+Gap Lock的结合，可解决幻读问题。

- 默认情况下，InnoDB select … for update使用Next-Key Lock来锁定记录。但当查询的索引含有唯一属性的时候，Next-Key Lock会进行优化，**降级为Record Lock**，即仅锁住索引本身，不是范围。
- 另外，Next-Key Lock在不同的场景中会退化：

| 场景                                        | 退化后的锁类型                   |
| ------------------------------------------- | -------------------------------- |
| 使用unique index精确匹配（=），且记录存在   | Record Lock                      |
| 使用unique index精确匹配（=），但记录不存在 | Gap Lock                         |
| 使用unique index范围匹配（< 或 >）          | Record Lock + Gap Lock，左开右闭 |

##### 页锁

MySQL中锁定粒度介于行级锁和表级锁中间的一种锁，表级锁速度快，但冲突多；行级冲突少，但速度慢，因此取了折衷的页级，**一次锁定相邻的一组记录**，其开销和加锁时间界于表锁和行锁之间、会出现死锁、锁定粒度界于表锁和行锁之间、并发度一般。

##### 锁的选择

比如执行，update test set name=“hello” where name=“world”，精确匹配时：

1. 如果更新条件没有走索引，则会进行全表扫描，扫表时会阻止其他任何的更新操作，**上升为表锁**。
2. 如果更新条件为索引字段，但是为非唯一索引，则会**使用Next-Key Lock**，保证在符合条件的记录上加上排他锁，锁定当前非唯一索引以及其对应的主键索引的值，同时，还要保证锁定的区间不能插入新的数据。
3. 如果更新条件为唯一索引，则会使用**Record Lock**。

#### MySQL死锁排查

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

常见的解决死锁的方法

1. InnoDB目前处理死锁的方法是，将持有最少行级排他锁事务进行**回滚**，这是相对比较简单的死锁回滚算法。
2. **相同的访问顺序**，如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。
3. 在同一个事务中，尽可能做到**一次锁定所需要的所有资源**，减少死锁产生概率；
4. 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过**表级锁**定来减少死锁产生的概率；

```mysql
show engine innodb status\G
-- TABLE LOCK：表锁
-- lock mode IX：意向锁
-- RECORD LOCK：行锁
-- index GEN_CLUST_INDEX：聚蔟索引，InnoDB加锁是给索引加的锁
-- lock_mode X：写锁，间隙锁
-- lock_mode X locks rec but not gap：行锁，非间隙锁
-- lock_mode X locks rec but not gap waiting：行锁等待
-- LATEST DETECTED DEADLOCK：最近探测到的死锁，排查到发生死锁
```

### 1.8. MVCC多版本并发控制？

#### 概念

MVCC，Multi-Version Concurrency Control，即**多版本并发控制**，实现对数据库的并发访问，实现读写冲突时的无锁并发控制。

- 可以在并发读写数据库时，做到在**读操作时不用阻塞写操作，写操作也不用阻塞读操作**，提高了数据库并发读写的性能。
- 同时还可以解决**脏读、不可重复读、幻读**等事务隔离问题，但不能解决更新丢失问题。
- MVCC手段只适用于Msyql **RC读已提交和 RR可重复读** 的事务隔离级别，RU读未提交由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC。

#### 当前读和快照读

- **当前读**：非MVCC实现，读取的是记录的最新版本，读取时要保证其他并发事务不能修改当前记录，会对读取的记录进行**加锁**。当前读就是悲观锁的具体功能实现
  - **举例**：select lock in share mode（共享锁）, select for update（拍他锁），update、insert、delete（排他锁）、串行化事务隔离级别。
- **快照读**：MySQL实现MVCC理想模型的中一个具体的**非阻塞读功能**，避免了加锁的操作，可以降低开销、提高并发性能，但快照读可能读到的不一定是数据的最新版本，而可能是之前的**历史版本**。
  - **前提**：快照读的前提是，事务使用**非串行化**的隔离级别，因为串行化级别下的快照读会**退化成当前读**。
  - **举例**：不加锁的select。

#### MySQL实现MVCC

![1630673126935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630673126935.png)

##### 版本链

InnoDB中，每次修改版本都会在版本链中记录，通过**undo log + roll_pointer**实现：

- **trx_id**：当前版本的事务ID，用来存储的每次对某条记录进行修改的时候的**事务ID**。当每个事务开启时，都会被分配一个ID，而这个ID是递增的，因此越新的事务其ID值越大。
- **roll_pointer**：回滚指针，由于每次对记录修改时，都会把老版本写入到undo日志中，使用回滚指针来指向这条记录**上一个版本**的位置，通过它来获得上一个版本的记录信息。
  - 注意，插入操作的undo日志没有roll_pointer，因为它没有老版本。

##### undo log

undo log是用于记录旧版本的链表，链首为最新的旧记录，链尾为最早的旧记录，主要分为两种：

- **insert undo log**：
  - 代表事务在insert新记录时产生的undo log，只在事务回滚时需要，并且在**事务提交后可以被立即丢弃**。
- **update undo log**：
  - 对MVCC其实质性的帮助，事务在进行update或delete时产生的undo log，不仅在事务回滚时需要，**在快照读时也需要**，所以不能随便删除。
  - 只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程（InnoDB专门的记录清理线程）统一清除。

##### Read View

![1630674963257](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630674963257.png)

Read View，是事务进行快照读操作时产生的**读视图**，是数据库当前的一个快照，记录了系统当前**活跃事务ID**，用于做**可见性判断**。

- **活跃事务ID**：即还没有commit的事务ID。

- **可见性判断**：当某个事务执行快照读时，会对该记录创建一个Read View读视图， 并把它作为条件，来**判断当前事务能够看到哪个版本的数据**，其中可能是当前版本的数据，也有可能是该行记录的undo log里面的某个版本的老数据。

  1. **trx_id == creator_trx_id**：可以访问这个版本，这个版本的事务ID等于当前事务ID（创建Read View的事务ID），即**自己能够读到自己的版本**。
     - creator_trx_id用来标记当前生成Read View的事务，使得能够让该事务读取到自己未提交的版本。
  2. **trx_id < min_trx_id**：可以访问这个版本，这个版本的事务ID小于最小活跃事务ID，说明这个版本**已经提交过了**，对于当前做可见性判断的事务来说，**是可以看见的**。
     - min_trx_id用来标记最早未提交的事务A，对比版本记录中的事务B，从而判断出B是否已经提交。
  3. **trx_id > max_trx_id**：不可以访问这个版本，这个版本的事务ID大于下一个事务ID，说明这个版本记录是在该Read View生成之后产生的，已经超出了版本链范围，而快照读只能读取版本链中的版本，因此该版本对于当前做可见性判断的事务来说，**是不应该看见的**。
     - max_trx_id用来标记下一个将要生成的事务A，对比版本记录中的事务B，从而判断出B是否超出版本链范围。
  4. **min_trx_id <= trx_id <= max_trx_id**：
     - 如果这个版本的事务ID为m_ids中的某个值，则不可以访问这个版本的，因为m_ids都是活跃的、还没提交的事务，说明该版本记录还没有提交，对于当前做可见性判断的事务来说，**是不应该看见的**。
     - 如果这个版本的事务ID不为m_ids中的某个值，则可以访问这个版本，因为没在m_ids里，又小于等于max_trx_id，说明该版本记录已提交了，对于当前做可见性判断的事务来说，**是可以看见的**。

  => 因此，如果可见性判断到要读取的版本记录为**自己创建的或者已经提交的**，则说明对于当前做可见性判断的事务来说，**该版本记录是可以看见的**。

### 1.9. 事务四大特性ACID？

事务，Transaction，是指**访问、更新数据库数据一个程序执行单元**，是逻辑上的一组操作，要么都执行，要么都不执行，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。

> ACID 则是衡量事务的四个特性，按照严格的 SQL 标准，只有同时满足 ACID 特性的才算是事务，但在各大数据库厂商的实现中，真正能严格满足 ACID 事务的少之又少。
>
> 比如 MySQL NDB Cluster 事务不满足持久性和隔离性，InnoDB RR 不满足严格的隔离性，Oracle RC 也不满足严格的隔离性等等。
>
> 所以，与其说 ACID 是事务必须满足的条件，不如说它们是衡量事务的四个维度而已。

- **原⼦性**： Atomicity， 事务是最小的执行单位，不允许分割，整个事务中所有的操作，要么全部提交成功，要么全部失败回滚，强调的是**事务操作原子不可分割**。

  - **undo log**：回滚日志，属于逻辑日志，记录的是 sql 执行相关的信息，是 MySQL 中事务**原子性**和**隔离性**实现的基础。
  - **实现原理**：在 MySQL InnoDB 中，当事务对数据库进行修改时，InnoDB 会生成对应的 undo log。如果事务执行失败或调用了 rollback，导致事务需要回滚时，就可以根据 undo log 的内容做与之前**相反**的工作，把数据回滚到修改之前的样子，以实现事务原子性操作。
    1. 对于每个 insert，回滚时会执行 delete。
    2. 对于每个 delete，回滚时会执行 insert。
    3. 对于每个 update，回滚时会执行一个相反的 update，把数据改回去。

- **一致性**：Consistency， 指事务执行结束后，数据库的完整性约束没有被破坏，都是合法的数据状态，强调的是**数据状态事务前后的一致**。

  - **数据库的完整性约束包括但不限于**：
    - **实体完整性**：比如，行的主键存在且唯一。
    - **列完整性**：比如，字段的类型、大小、长度都要符合要求。
    - **外键约束**：比如，主键所在的表是主表，外键所在的表是从表。
    - **用户自定义完整性**：比如，转账前后，两个账户余额的和应该保持不变。
  - **实现原理**：可以说，**一致性是事务追求的最终目标**，原子性、持久性和隔离性都是为了保证数据库状态的一致性。其中，实现一致性的措施包括：
    - **数据库层面的保障**：原子性、持久性和隔离性的保证，以及一些其他约束，比如不允许向整型列插入字符串值，或者字符串长度不能超过列的限制等等。
    - **应用层面的保障**：比如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。

- **隔离性**： Isolation，并发访问数据库时，⼀个⽤户的事务不被其他事务所⼲扰，各并发事务之间数据库是独⽴的，一个事务所做的修改在最终提交之前，对其他事务是不可见的，强调的是**事务间的数据操作互不影响**。

  - **实现原理**：
    - **写写操作**：使用**锁机制**来保证隔离性。
    - **写读操作**：
      - **快照读**：使用**MVCC**来保证隔离性。
      - **当前读**：使用**锁机制**保证隔离性。

- **持久性**：Durability， ⼀个事务被提交之后，它对数据库中数据的改变是持久的，即使数据库发⽣故障，也不应该对其有任何影响，强调的是**事务后的数据会永久保存**。

  - **Buffer Pool**：为减少每次读写数据的磁盘I/O，InnoDB 提供了 Buffer Pool 缓存，其中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲。当从数据库读取数据时，InnoDB 会先从 Buffer Pool 中读取，如果 Buffer Pool 中没有，则从磁盘读取后放入 Buffer Pool；当向数据库写入数据时，同样 InnoDB 也会先写入 Buffer Pool，Buffer Pool 中修改的数据会定期刷新到磁盘中，这一过程称为**刷脏**。

    - **优点**：大大提高了读写数据的效率。
    - **缺点**：如果 MySQL 宕机，而此时 Buffer Pool 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，**无法保证事务的持久性**。

  - **实现原理**：InnoDB 引入 redo log 来解决 Buffer Pool 的问题， 以保证事务的持久性。

    1. 当数据修改时，修改 Buffer Pool 中的数据前，会先在把这次操作**写入** redo log 缓冲区。
    2. 写入 redo log缓冲区后，根据innodb_flush_log_at_trx_commit属性来决定**刷盘机制**：
       - **0**：表示当事务提交时，不会把 redo log 缓冲区的日志**同步**到磁盘 redo log 文件中，而是等待线程每秒的刷新，不能完全保证全部写入成功。
       - **1**：表示当事务提交时，把 redo log 缓存区的日志**同步**到磁盘 redo log 文件中，且会保证全部写入成功。
       - **2**：表示当事务提交时，异步把 redo log 缓存区的日志**同步**到磁盘 redo log 文件中，不能完全保证全部写入成功。
    3. 如果 MySQL 宕机，重启时可以**读取** redo log 中的数据，对数据库进行**恢复**。

    ![1632132586785](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632132586785.png)

  - **redo log**：重做日志，属于物理日志，用于保证事务的持久性。

    - **WAL**：Write-ahead logging，预写式日志，redo log 采用 WAL ，所有修改先**写入**日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。

    - **写入 redo log 性能高于 Buffer Pool 刷脏**：因此，写入 redo log 是可以用在 Buffer Pool 刷脏之前来保证事务持久性的。

      | 写入 redo log 缓冲区                 | Buffer Pool刷脏                                              |
      | ------------------------------------ | ------------------------------------------------------------ |
      | 是追加操作，属于顺序 I/O             | 每次修改的数据位置都是随机的，属于随机 I/O                   |
      | 只需要修改的部分，大大减少了无效 I/O | 以数据页 Page 为单位（MySQL默认为16 KB），一个 Page上只出现一个小修改，需要将整页写入磁盘，存在大量的无效 I/O |

    - **redo log vs binlog**：

      | 不同点   | redo log                         | bin log                      |
      | -------- | -------------------------------- | ---------------------------- |
      | 日志名称 | 重做日志                         | 二进制日志                   |
      | 日志作用 | 用于崩溃恢复，保证事务的持久性   | 用于时间点恢复，保证主从复制 |
      | 存储内容 | 属于物理日志，内容基于磁盘数据页 | 逻辑日志，内容为一条条SQL    |
      | 实现层面 | InnoDB存储引擎实现               | MySQL服务器层实现            |
      | 写入时机 | 事务提交时、每秒一次             | 事务提交时写入               |

### 2.0. 事务并发问题？

- **脏读**：Drity Read，指两个事务并发执行，事务A已更新某一份数据，事务B读取同一份数据，出于某种原因，事务A回滚了更新的操作，导致事务B读取的数据不正确。
  - **产生原因**：事务A读取了事务B中**未提交的数据**。
  - **特点**：违背了隔离性。
- **不可重复读**：Non-repeatable read，指两个事务并发执行，事务A前后两次查询的结果不一样（**行内容发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**修改并提交了事务**。
  - **特点**：相比脏读的区别是，不可重复读是读取另一事务提交的数据。这种现象是正常的，是由于事务的隔离级造成的，但是在在某些特别的情况下也是不允许的。 
- **幻读**：Phantom Read，指两个事务并发执行，事务A前后两次查询的结果不一样（**出现了幻行，导致行数量发生了变更**）。
  - **产生原因**：事务A前后两次查询有间隔，期间内，被事务B**新增数据并提交了事务**，比如事务A查询了几行数据，而事务B并发插入了新的几行数据，事务A在接下来的查询中，会发现有几行数据是它先前所没有的。
  - **特点**：和不可重复读一样，都是读取了另外一个事务的数据，不同的是不可重复读查询的是同一条数据，而幻读则是针对批量的数据，或者说**不可重复读是A读取了B的更新数据，幻读是A读取了B的新增数据**。

### 2.1. 事务隔离级别？

| 事务隔离级别 | 存在的事务并发问题     |
| ------------ | ---------------------- |
| 读未提交     | 脏读、幻读、不可重复读 |
| 读已提交     | 幻读、不可重复读       |
| 可重复读     | 幻读                   |
| 串行化       | 没有事务并发问题       |

- **读未提交**：READ UNCOMMITTED，是最低的事务隔离级别，事务可以读取到其他事务未提交的数据，可能会导致脏读、不可重复读和幻读。

  - **当前读**：读取数据**不需要加共享锁**，这样就不会与修改的数据上的排他锁冲突了。

- **读已提交**：RC，READ COMMITTED，也叫不可重复读，事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的，是大多数据库的默认事务隔离级别（**比如Oracle**），可以阻⽌脏读，但还是可能会导致不可重复读和幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在语句执行完以后释放共享锁**。
  - **快照读**：MVCC
    - **Read View以select为单位**，每次select都会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **不可重复读的原因**：由于Read View以select为单位，每次select都会生成一个Read View，两者的可见性判断的结果可能不一样，能看到的版本也就不一样，从而可能导致事务前后两次的**查询别人版本的结果**不一致，产生不可重复读。

- **可重复读**：RR，REPEATABLE READ，事务对同⼀字段的**多次读取的结果都是⼀致的**，除⾮数据是被事务本身所修改，是**MySQL的默认事务隔离级别**，可以阻⽌脏读和不可重复读，但还是可能会导致幻读。

  - **当前读**：读操作**需要加共享锁**，但是**在事务提交之前并不释放共享锁**，也就是必须等待事务执行完毕以后，才释放共享锁。
    - **解决幻读的方式**：
      - **使用间隙锁**：MySQL默认开启间隙锁，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。
      - **使用MVCC快照读**：快照读基于Read View来实现，每个事务对应一个Read View，解决了幻读的问题。
      - **升级到串行化隔离级别**：把隔离级别设置成SERIALIZABLE，但这样所有事务都只能顺序执行，自然不会因为并发有什么影响了，但是性能会下降许多，实际中很少用到。
  - **快照读**：MVCC
    - **Read View以事务为单位**，每个事务只会生成一个Read View，事务根据这个Read View做可见性判断，只读取那些期间自己创建的（未提交）以及已经提交了的版本记录，即只读别人提交过的，不能读别人未提交的，做到了读已提交的隔离性。
    - **解决不可重复读、幻读的问题**：由于Read View以事务为单位，每个事务只会生成一个Read View，事务前后的快照读只对应同一份Read View，可见性判断一致，能看到的版本一致，因此整个事务过程中**查询别人版本的结果**一致，避免了不可重复读、幻读的发生，因此在MySQL中RR可重复读隔离级别下，是没有事务并发问题的。

  |        | RC                                   | RR                         |
  | ------ | ------------------------------------ | -------------------------- |
  | 实现   | 多条查询语句会创建多个不同的ReadView | 仅需要一个版本的ReadView   |
  | 粒度   | 语句级读一致性                       | 事务级读一致性             |
  | 准确性 | 每次语句执行时间点的数据             | 第一条语句执行时间点的数据 |

- **串行化**：SERIALIZABLE，是最高的隔离级别，通过强制事务串行执行，所有的事务依次逐个执⾏，事务之间完全不存在互相⼲扰，解决了幻读的问题，即阻止了所有的事务并发问题，包括脏读、不可重复读和幻读。

  - **当前读**：**锁定整个范围的键**，并一直持有锁，直到事务完成，可能导致大量的超时和锁争用的问题，实际中很少使用。

### 2.2. MySQL慢SQL与慢查询日志？

#### 慢SQL

- **危害**：
  - **从数据库角度看**：
    - 每个SQL执行都需要消耗一定I/O资源，SQL执行的快慢，决定资源被占用时间的长短。
    - 假设总资源是100，如果有一条慢SQL占用了30的资源共计1分钟，那么在这1分钟时间内，其他SQL能够分配的资源总量就是70，如此循环，当资源分配完的时候，会**导致所有新的执行SQL进行排队等待**。
  - **从应用的角度看**：SQL执行时间长，意味着应用需要等待，导致用户的体验较差。
- **治理原则**：
  - **优先治理写库的慢SQL**：目前数据库基本上都是读写分离架构，读在从库上执行，写在主库上执行，而由于从库的数据都是从主库上复制过去的，如果主库等待较多，则会**加大与从库的复制时延**。
  - **执行次数多的慢SQL优先治理**：如果有一类SQL高并发集中访问某一张表，应当优先治理。

#### 慢查询日志

慢查询日志，是MySQL内置的一项功能，可以记录执行超过指定时间的SQL语句，即**记录慢SQL**。

- **参数设置方式**：

  - **修改my.cof配置文件**：

    ```sh
    [mysqld]
    # ...
    log_output = 'FILE,TABLE';
    show_query_log = ON
    
    # 表示0.001s，即默认值为1ms，表示任何SQL都会记录起来，对于实际业务没任何意义
    long_query_time = 0.001
    ```

  - **set global设置全局变量**：

    ```sql
    set global log_output = 'FILE,TABLE';
    set global slow_query_log = 'ON';
    
    -- 表示0.001s，即默认值为1ms，表示任何SQL都会记录起来，对于实际业务没任何意义
    set global long_query_time = 0.001;
    ```

- **慢查询日志分析**：

  - **log_output = TABLE**：select * from `mysql`.slow_log。
  - **log_output = FILE**：使用show variables like '%slow_query_log_file%'获取日志路径，使用mysqldumpslow分析日志。

  ![1630805035402](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630805035402.png)

  ```mysql
  -- mysqldumpslow：
  -- -s：排序方式，默认为at
  --		1) al：平均时间
  --		2）ar：平均返回记录
  --		3）at：平均查询时间
  --		4） c：访问计数
  --		5） l：锁定时间
  --		6） r：返回记录
  --		7） t：查询时间
  -- -r：将-s的排序倒序
  -- -t：top n的意思，展示最前面的几条
  -- -g：正则匹配，只有符合正则的行才会展示
  -- -a：展示原始SQL
  
  -- eg: 得到返回记录集中最多的10条SQL
  mysqldumpslow -s -r -t 10 /var/lib/mysql/894503c23e0-slow.log
  
  -- eg: 得到按照查询时间排序，并且带有left join的10条SQL
  mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/894503c23e0-slow.log
  ```

| 慢查询日志参数                         | 作用                                                         | 默认值    |
| -------------------------------------- | ------------------------------------------------------------ | --------- |
| log_output                             | 日志输出的类型，可以设置多种格式，比如FILE，TABLE；默认为FILE，表示文件；设置成TABLE，则将日志记录到mysql.slow_log中； | FILE      |
| long_query_time                        | 执行时间超过指定阈值，才记录到慢查询日志，单位为秒，可使用小数表示小于秒的时间 | 10        |
| log_queries_not_using_indexs           | 是否要将未使用索引的SQL，都记录到慢查询日志中，此配置会无视long_query_time的配置，生产配置建议关闭，开发环境建议开启 | OFF       |
| log_throttle_queries_not_using_indexes | 和log_queries_not_using_indexs配置使用，如果log_queries_not_using_indexs打开，则该参数将限制每分钟写入的、未使用索引的SQL数量 | 0         |
| min_examined_row_limit                 | 扫描行数至少达到指定阈值，才记录到慢查询日志                 | 0         |
| log_show_admin_statements              | 是否要记录管理语句，默认关闭，管理语句包括ALTER、ANALYZE、CHECK、CREATE、DROP、OPTIMIZE、REPAIR | OFF       |
| slow_query_log_file                    | 指定慢查询日志的文件路径                                     | /var/路径 |
| log_slow_slave_statements              | 该参数在从库上设置，决定是否记录在复制过程中超过long_query_time的SQL，如果binlog格式是row，则该参数无效 | OFF       |
| log_show_extra                         | 当log_output=FILE时，是否要记录额外信息（>= MySQL 8.0.14开始提供），对log_output=TABLE的结果无影响 | OFF       |

### 2.3. 详细介绍MySQL EXPLAIN？

- 使用EXPLAIN关键字可以**模拟优化器执行SQL语句**，分析查询语句或是结构的性能瓶颈。
- 在select语句之前增加explain关键字，MySQL会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行SQL。

#### 总结

基于MySQL 8.0编写，理论上支持MySQL 5.0以及更高版本。

| Explain结果字段   | json名称      | 含义                         |
| ----------------- | ------------- | ---------------------------- |
| id                | select_id     | 该语句的唯一标识             |
| select_type       | 无            | 查询类型                     |
| table             | table_name    | 表名                         |
| partitions        | partitions    | 匹配的分区                   |
| **type**          | access_tpye   | 联接类型                     |
| **possible_keys** | possible_keys | 可能的索引选择               |
| **key**           | key           | 实际选择的索引               |
| **key_len**       | key_length    | 索引的长度                   |
| ref               | ref           | 索引的哪一列被引用了         |
| **rows**          | rows          | 估计要扫描的行               |
| **filtered**      | filtered      | 表示符合查询条件的数据百分比 |
| **Extra**         | 没有          | 附件信息                     |

#### id

该语句的唯一标识：

- 如果结果包含多个id值，则**数字越大，越先执行**。
- 而相同id的，则**从上往下依次执行**。

#### select type

查询类型，有以下几种取值：

| 查询类型             | 作用                                                         |
| -------------------- | ------------------------------------------------------------ |
| SIMPLE               | 简单查询（未使用UNION或者子查询）                            |
| PRIMARY              | 最外层的查询                                                 |
| UNION                | 在UNION中的第二个和随后的SELECT被标记为UNION，如果UNION被FROM子句中的子查询包含，则它的第一个SELECT会被标记为DERIVED（派生表）。 |
| DEPENDENT UNION      | UNION中的第二个或后面的查询，依赖了外面的查询                |
| UNION RESULT         | UNION的结果                                                  |
| SUBQUERY             | 子查询中的第一个SELECT                                       |
| DEPENDENT SUBQUERY   | 子查询中的第一个SELECT，依赖了外面的查询                     |
| DERIVED              | 用来表示包含在FROM子句的子查询中的SELECT，MySQL会递归执行并将结果放入到一个临时表中，内部称其为Derived table（派生表），因为该临时表是从子查询派生出来的 |
| DEPENDEDNT DERIVED   | 派生表，依赖了其他的表                                       |
| MATERIALIZED         | 物化子查询                                                   |
| UNCACHEABLE SUBQUERY | 子查询，结果无法缓存，必须针对外部查询的每一行重新评估       |
| UNCACHEABLE UNION    | UNION属于UNCACHEABLE SUBQUERY的第二个或后面的查询            |

#### table

表示当前这一行正在访问哪张表，如果SQL定义了表名，则展示表的别名。

#### partitions

当前查询匹配记录的分区，对于未分区的表，返回null。

#### type

**重点**，连接类型，有如下几种取值，性能从好到坏排序：

| 连接类型        | 含义                                                         | 备注                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| system          | 该表只有一行，相当于系统表                                   | system是const的特例                                          |
| const           | 针对主键或者唯一索引的等值查询，最多返回一行数据             | 查询速度非常快                                               |
| eq_ref          | 当使用了索引的全部组成部分，并且索引是**主键或者非空唯一索引**才会发生 | 性能仅次于system和const                                      |
| ref             | 当满足索引的最左前缀规则，或者索引**不是主键也不是唯一索引**时才会发生 | 如果索引只匹配到少量的行，则性能也是不错的                   |
| fulltext        | 全文索引                                                     | 使用MyISAM存储引擎才有                                       |
| ref_or_null     | 该类型类似于ref，但MySQL会额外搜索哪些行包含NULL，           | SELECT * FROM ref_table WHERE key_col = expr OR key_col IS NULL； |
| index_merge     | 该类型表示使用了索引合并优化，表示一个查询里面用到了多个索引 | -                                                            |
| unique_subquery | 该类型和eq_ref类型，但使用了**IN查询**，且**子查询是主键或者唯一索引** | value IN (SLECT id FROM single_talbe WHERE expr)             |
| index_subquery  | 和unique_subquery类型，只是**子查询使用的是非唯一索引**      | value IN (SELECT key_col FROM single_table WHERE other_expr) |
| range           | 范围扫描，表示检索了指定范围的行，主要用于有限制的索引扫描   | 常见的有，BETWEEN、>、>=、<、<=、IS NULL、<=>、LIKE、IN      |
| index           | 全索引扫描，和ALL类型，只不过index是全盘扫描了索引的数据     | 当查询仅使用索引中的一部分列时，会使用该类型，有两种触发场景：1）覆盖索引，比ALL快，此时只扫描索引数，Extra列为Using Index；2）全表扫描，同ALL，此时会回表查询数据，Extra列不会出现Using Index； |
| ALL             | 全表扫描                                                     | 性能最差                                                     |

#### possible_keys

展示当前查询可以使用哪些索引，由于这一列的数据是在SQL优化过程早期创建的，因此，有些索引可能对于SQL后续优化过程是没用到的。

#### key

表示MySQL实际选择的索引。

#### key_len

索引使用的字节数，由于存储格式，当字段允许为NULL时，key_len比不允许为NULL的大1个字节，计算公式为：

- **varchar（10）+ 允许为NULL**：2（varchar变长字段） + 10 \* ( Character Set）+ 1（允许为NULL）。
  - **varchar变长字段**：使用额外1或2个字节存储字符串长度。列长度小于255字节时，使用**1字节**表示，否则使用**2字节**表示，当存储的内容超出设置的长度时，内容会被截断。
  - **Character Set**：UTF8 = 3字节, GBK = 2字节, LATIN = 1字节。
  - **允许为NULL** = 1字节。
- **varchar（10）+ 不允许为NULL**：2（varchar变长字段） + 10 \* ( Character Set）。
- **char（10）+ 允许为NULL**：10 \* ( Character Set） + 1（允许为NULL）。
- **char（10）+ 不允许为NULL**：10 \* ( Character Set） 。

#### ref

表示索引的哪一列被引用了，将哪个字段或者常量，和key列所使用的字段进行比较。

- 如果ref是一个函数，则使用的值是函数的结果。
  - 要想查看是哪个函数，可在Explain语句之后紧跟一个SHOW WARNING语句。

#### rows

MySQL估算会扫描的行数，数值越小，性能越高。

#### filtered

表示符合查询条件的数据百分比，最大100，用rows * filtered可获得和下一张表连接的行数。

#### Extra

展示有关本次查询的附件信息，取值如下：

| 附件信息                                                     | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Child of 'table' pushed join@1                               | 此值只会在NDB CLUSTER下出现                                  |
| const row not found                                          | 查询的表是空的                                               |
| Deleting all rows                                            | 对于DELETE语句，某些引擎（比如MyISAM）支持以一种简单而快速的方式删除所有数据，如果使用了这种优化，则会显示此值 |
| Distinct                                                     | 查找Distinct值，当找到第一个匹配的行后，将停止为当前行组合搜索更多的行 |
| FirstMatch(table_name)                                       | 当前使用了半连接FirstMatch策略                               |
| Full Scan on NULL key                                        | 子查询中的一种优化方式，在无法通过索引访问NULL值时会使用     |
| Impossible HAVING                                            | HAVING子句始终为false，不会命中任何行                        |
| Impossible WHERE                                             | WHERE子句始终为false，不会命中任何行                         |
| Impossible WHERE noticed after reading const tables          | MySQL已经读取了所有const（或者system）表，并发现WHERE子句始终为false |
| LooseScan（m...n）                                           | 当前使用了半连接LooseScan策略                                |
| No  matching min/max row                                     | MIN、MAX语句中，没有任何能满足WHERE条件的行                  |
| No matching row in const table                               | 对于关联查询，存在一个空表，或者没有行能够满足唯一索引条件   |
| No matching rows after partition pruning                     | 对于DELETE或者UPDATE语句，优化器在partition pruning（分区修剪）之后，找不到要DELETE或者UPDATE的内容 |
| No tables used                                               | 当此查询没有FROM子句或者拥有FROM DUAL子句时出现              |
| Not exists                                                   | MySQL能对LEFT JOIN优化，在找到符合LEFT JOIN的行后，不会为上一行组合中检查此表中的更多行，只查找一次 |
| Plan isn't ready yet                                         | 使用了EXPLAIN FOR CONNECTION，当优化器尚未完成为在指定连接中执行的语句创建执行计划时，就会出现此值 |
| Range checked  for each record（index map：N）               | MySQL没有找到合适的索引去使用，但是去检查是否可以使用range或者index_merge来检索行时，会出现此提示 |
| Recursive                                                    | 出现了递归查询                                               |
| Rematerialize                                                | 用得很少                                                     |
| Scanned N databases                                          | 表示在处理INFOMATION_SCHEMA表的查询时，扫描了几个目录，N的取值可以是0、1或者all |
| Select tables optimized away                                 | 优化器确定最多返回1行时会出现此提示，一般在用某些聚合函数访问存在索引的某个字段时，优化器会通过索引直接一次定位到所需要的数据行完成整个查询时，会展示该值 |
| Skip_open_table，Open_firm_only，Open_full_table             | 表示适用于INFORMATION_SCHEMA表查询的文件打开优化，Skip_open_table表示无需打开表文件，信息已经通过扫描数据字典获得；Open_firm_only表示仅需要读取数据字典以获取表信息；Open_full_table表示未优化的信息查找，表信息必须从数据字典以及表文件中获取 |
| Start temporary，End temporary                               | 表示临时表使用Duplicate Weedout策略                          |
| unique row not found                                         | 对于形如select ... from tab_name的查询，但没有行能够满足唯一索引或者主键查询的条件时出现 |
| **Using filesort**                                           | 当Query中包含ORDER BY操作，而且无法利用索引完成排序操作时，MySQL Query Optimizer不得不选择相应的排序算法来实现。在数据较少时，从内存排序，否则从磁盘排序。 其中，Explain不会显式地告诉客户端用哪种排序。 |
| **Using Index**                                              | 仅使用索引树中的检索列信息，不必进行其他查找以读取实际行，当查询仅使用属于单个索引的列时，会使用此策略 |
| **Using index condition**                                    | 使用索引下推时出现，表示先按条件过滤索引，过滤完索引后，找到符合索引条件的数据行，随后用WHERE子句中的其他非索引条件，去过滤这些数据行。 |
| **Using index for group-by**                                 | 数据访问和Using Index一样，所需数据只需要读取索引，当Query中使用GROUP BY或者DISTINCT子句时，如果所有分组字段也在索引中，该信息就会出现 |
| Using index for skip scan                                    | 表示使用了Skip Scan                                          |
| Using join buffer（Block Nested Loop），Using join Buffer（Batched Key  Access） | 使用Block Nested Loop或者Batched Key  Access算法来提高join的性能 |
| Using MRR                                                    | 使用了Muti-Range Read优化策略                                |
| Using sort_union（..），Using union（..），Using intersect（..） | 这些提示索引扫描如何合并为index_merge连接类型                |
| **Using temporary**                                          | 为了解决该查询，MySQL创建了一个临时表来保存结果，如果查询包含不同列的GROUP BY和ORDER BY子句，通常会发生这种情况。 |
| **Using Where**                                              | 如果不是读取表的所有数据，或者不仅仅通过索引就可以获取所有需要的数据时，则会出现该值 |
| Using where with pushed condiction                           | 仅用于NDB                                                    |
| Zero limit                                                   | 该查询有一个limit 0子句，不能选择任何行                      |

### 2.4. MySQL SQL性能分析？

除了使用EXPLAIN分析模拟优化器执行SQL语句外，还可以深入SQL内部来分析性能瓶颈，包括三种形式：

#### SHOW PROFILE

SHOW PROFILES，是MySQL的一个性能分析命令，可以跟踪SQL各种资源消耗情况，但官方文档声明SHOW PROFILES已被废弃，建议使用Performance Schema作为替代品。

- **使用步骤如下**：

  ```sql
  -- 1. 查看是否支持SHOW PROFILES功能，yes表示支持
  select @@have_profiling;
  
  -- 2. 查看是否启用了SHOW PROFILES功能，0表示未启动，1表示已启动
  select @@profiling;
  
  -- 3. 开启SHOW PROFILES功能
  set profiling = 1;
  
  -- 4. 使用SHOW PROFILES功能，默认展示15条，可通过set profiling_history_size来设置
  SHOW PROFILES;
  
  -- 5. 关闭SHOW PROFILES功能
  set profiling = 0;
  ```

  ![1630814806087](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630814806087.png)

- 默认情况下，SHOW PROFILES只展示Status和Duration两列，如果想展示更多信息，还可以**指定type**。

| type             | 含义                                         |
| ---------------- | -------------------------------------------- |
| ALL              | 显示所有信息                                 |
| BLOCK IO         | 显示阻塞I/O次数                              |
| CONTEXT SWITCHES | 显示自愿及非自愿的上下文切换次数             |
| CPU              | 显示用户与系统CPU使用时间                    |
| IPC              | 显示消息发送与接收的次数                     |
| MEMORY           | 显示内存相关的开销                           |
| PAGE FAULTS      | 显示页错误相关的开销                         |
| SOURCE           | 列出相应操作对应的函数名及其在源码中的行位置 |
| SWAPS            | 显示swap交换次数                             |

#### INFORMATION_SCHEMA.PROFILING

SHOW PROFILES本质上读的就是INFORMATION_SCHEMA.PROFILING表，因此除了使用SHOW PROFILES做性能分析，也可以直接查询INFORMATION_SCHEMA.PROFILING，除非设置set profiling = 1，否则该表不会有任何数据。 

```sql
SHOW PROFILE FOR QUERY 2;

-- 等价于
SELECT STATE, FORMAT(DURATION, 6) AS DURATION
FROM INFORMATION_SCHEMA.PROFILING
WHERE QUERY_ID = 2
ORDER BY SEQ;
```

| INFORMATION_SCHEMA.PROFILING字段          | 含义                                         |
| ----------------------------------------- | -------------------------------------------- |
| QUERY_ID                                  | SQL语句的唯一标识                            |
| SEQ                                       | 一个序号，展示具有相同QUERY_ID值的行显示顺序 |
| STATE                                     | 分析状态                                     |
| DURATION                                  | 在这个状态下持续了多久时间（秒）             |
| CPU_USER，CPU_SYSTEM                      | 用户和系统CPU使用情况（秒）                  |
| CONTEXT_VOLUNTARY，CONTEXT_INVOLUNTARY    | 发生了多少次自愿和非自愿的上下文切换         |
| BLOCK_OPS_IN，BLOCK_OPS_OUT               | 块输入和输出操作的数量                       |
| PAGE_FAULTS_MAJOR，PAGE_FAULTS_MINOR      | 主要和次要的页错误信息                       |
| SWAPS                                     | 发生了多少次SWAP                             |
| SOURCE_FUNCTION，SOURCE_FILE，SOURCE_LINE | 当前状态是在源码的哪里执行的                 |

#### PERFOMANCE_SCHEMA

PERFORMANCE_SCHEMA是MySQL建议的性能分析方式，未来SHOW PROFILES、INFORMATION_SCHEMA.PROFILING都会被废弃。

```sql
-- 1. 查看是否开启性能监控，默认是开启的（>= MySQL 5.6）
mysql> SELECT * FROM performance_schema.setup_actors;
+------+------+------+---------+---------+
| HOST | USER | ROLE | ENABLED | HISTORY |
+------+------+------+---------+---------+
| %    | %    | %    | YES     | YES     |
+------+------+------+---------+---------+

-- 2. 开启相关监控
mysql> UPDATE performance_schema.setup_instruments
       SET ENABLED = 'YES', TIMED = 'YES'
       WHERE NAME LIKE '%statement/%';

mysql> UPDATE performance_schema.setup_instruments
       SET ENABLED = 'YES', TIMED = 'YES'
       WHERE NAME LIKE '%stage/%';
       
mysql> UPDATE performance_schema.setup_consumers
       SET ENABLED = 'YES'
       WHERE NAME LIKE '%events_statements_%';

mysql> UPDATE performance_schema.setup_consumers
       SET ENABLED = 'YES'
       WHERE NAME LIKE '%events_stages_%';

-- 3. 执行业务SQL后，获取EVENT_ID
mysql> SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT
       FROM performance_schema.events_statements_history_long WHERE SQL_TEXT like '%10001%';
+----------+----------+--------------------------------------------------------+
| event_id | duration | sql_text                                               |
+----------+----------+--------------------------------------------------------+
|       31 | 0.028310 | SELECT * FROM employees.employees WHERE emp_no = 10001 |
+----------+----------+--------------------------------------------------------+

-- 4. 根据EVENT_ID获取SQL性能分析信息
mysql> SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration
       FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=31;
+--------------------------------+----------+
| Stage                          | Duration |
+--------------------------------+----------+
| stage/sql/starting             | 0.000080 |
| stage/sql/checking permissions | 0.000005 |
| stage/sql/Opening tables       | 0.027759 |
| stage/sql/init                 | 0.000052 |
| stage/sql/System lock          | 0.000009 |
| stage/sql/optimizing           | 0.000006 |
| stage/sql/statistics           | 0.000082 |
| stage/sql/preparing            | 0.000008 |
| stage/sql/executing            | 0.000000 |
| stage/sql/Sending data         | 0.000017 |
| stage/sql/end                  | 0.000001 |
| stage/sql/query end            | 0.000004 |
| stage/sql/closing tables       | 0.000006 |
| stage/sql/freeing items        | 0.000272 |
| stage/sql/cleaning up          | 0.000001 |
+--------------------------------+----------+
```

### 2.5. MySQL OPTIMIZER_TRACE优化器跟踪？

OPTIMIZER_TRACE是MySQL 5.6引入的一项跟踪功能，可以跟踪优化器做出的各种决策，比如访问表的方法、各种开销的计算、各种的转换等，并将跟踪结果记录到INFORMATION_SCHEMA.OPTIMIZER_TRACE表中。

- 默认关闭，在开启后可分析SELECT、INSERT、REPLACE、UPDATE、EXPLAIN、SET、DECLARE、IF、RETURN、CALL。

- **使用步骤**：

  ```sql
  -- 1. 开启OPTIMIZER_TRACE
  SET OPTIMIZER_TRACE="enabled=on",END_MARKERS_IN_JSON=on;
  SET optimizer_trace_offset=-30, optimizer_trace_limit=30;
  
  -- 2. 执行业务SQL
  select *
  from salaries
  where from_date = '1986-06-26' and to_date = '1987-06-26';
  
  -- 3. 查看跟踪信息
  SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE limit 30;
  
  -- 4. 关闭OPTIMIZER_TRACE
  SET optimizer_trace="enabled=off";
  ```

- **OPTIMIZER_TRACE字段含义**：

  | 字段                              | 含义                                                         |
  | --------------------------------- | ------------------------------------------------------------ |
  | QUERY                             | 查询的SQL语句                                                |
  | TRACE                             | QUERY字段对应语句的跟踪信息                                  |
  | MISSING_BYTES_BEYOND_MAX_MEM_SIZE | 跟踪信息过长时，被截断的跟踪信息字节数                       |
  | INSUFFICIENT_PRIVILEGES           | 执行跟踪语句的用户是否有查看对象的权限，当不具有权限时，该列信息为1且TRACE字段为空，一般在调用带有SQL SECURITY DEFINER的视图，或者存储过程的情况下，会出现此问题 |

- **TRACE字段内容**：

  ```java
  # 跟踪结果展示
  TRACE: {
  	"steps": [{
  			# 1. 准备阶段的执行过程
  			"join_preparation": {
  				"select#": 1,
  				"steps": [{
  					"expanded_query": "/* select#1 */ select `salaries`.`emp_no` AS `emp_no`,`salaries`.`salary` AS `salary`,`salaries`.`from_date` AS `from_date`,`salaries`.`to_date` AS `to_date` from `salaries` where ((`salaries`.`from_date` = '1986-06-26') and (`salaries`.`to_date` = '1987-06-26'))"
  				}] /* steps */
  			} /* join_preparation */
  		},
  		{
  			# 2. 优化阶段的执行过程，是分析OPTIMIZER_TRACE的重点
  			"join_optimization": {
  				"select#": 1,
  				"steps": [{
  						# 2.1. 条件处理，主要对WHERE条件进行优化处理
  						"condition_processing": {
  							# 优化的对象类型，比如WHERE 或者 HAVING
  							"condition": "WHERE",
  							# 优化前的原始语句
  							"original_condition": "((`salaries`.`from_date` = '1986-06-26') and (`salaries`.`to_date` = '1987-06-26'))",
  							# 主要包括三步，分别是quality_propagation（）、constant_propagation（）、trivial_condition_removal（）
  							"steps": [
  							    # 等值条件句转换
  							    {
  									# 转换类型句
  									"transformation": "equality_propagation",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal('1986-06-26', `salaries`.`from_date`) and multiple equal('1987-06-26', `salaries`.`to_date`))"
  								},
  								# 常量条件句转换
  								{
  									# 转换类型句
  									"transformation": "constant_propagation",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal('1986-06-26', `salaries`.`from_date`) and multiple equal('1987-06-26', `salaries`.`to_date`))"
  								},
  								# 无效条件移除的转换
  								{
  									# 转换类型句
  									"transformation": "trivial_condition_removal",
  									# 转换之后的结果输出
  									"resulting_condition": "(multiple equal(DATE'1986-06-26', `salaries`.`from_date`) and multiple equal(DATE'1987-06-26', `salaries`.`to_date`))"
  								}
  							] /* steps */
  						} /* condition_processing */
  					},
  					{
  						# 2.2. 用于替换虚拟生成列
  						"substitute_generated_columns": {} /* substitute_generated_columns */
  					},
  					{
  						# 2.3. 分析表之间的依赖关系
  						"table_dependencies": [{
  							# 涉及的表名，如果有别名，也会展示出来
  							"table": "`salaries`",
  							# 行是否可能为NULL，这里指JOIN操作之后，这张表里的数据是不是可能为NULL。如果语句中使用了LEFT JOIN，则后一张表row_may_be_null会显示为true
  							"row_may_be_null": false,
  							# 表的映射编号，从0开始递增
  							"map_bit": 0,
  							# 依赖的映射表，当使用STRAIGHT JOIN强行控制连接顺序或者LEFT JOIN/RIGHT JOIN有顺序差别时，会在depends_on_map_bits中展示前置表的map_bit值
  							"depends_on_map_bits": [] /* depends_on_map_bits */
  						}] /* table_dependencies */
  					},
  					{
  						# 2.4. 列出所有可用的ref类型的索引，如果使用了组合索引的多个部分，则会在ref_optimizer_key_uses下列出多个元素，每个元素中会列出ref使用的索引及对应值
  						"ref_optimizer_key_uses": [{
  								"table": "`salaries`",
  								"field": "from_date",
  								"equals": "DATE'1986-06-26'",
  								"null_rejecting": false
  							},
  							{
  								"table": "`salaries`",
  								"field": "to_date",
  								"equals": "DATE'1987-06-26'",
  								"null_rejecting": false
  							}
  						] /* ref_optimizer_key_uses */
  					},
  					{
  						# 2.5. 估算需要扫描的记录数
  						"rows_estimation": [{
  							# 表名
  							"table": "`salaries`",
  							"range_analysis": {
  								# 如果全表扫描的话，需要扫描多少行，以及需要的代价
  								"table_scan": {
  									"rows": 2838216,
  									"cost": 286799
  								} /* table_scan */ ,
  								# 列出表中所有的索引，并分析其是否可用。如果不可用的话，会列出不可用的原因是什么，如果可用会列出索引中可用的字段
  								"potential_range_indexes": [{
  										"index": "PRIMARY",
  										"usable": false,
  										"cause": "not_applicable"
  									},
  									{
  										"index": "salaries_from_date_to_date_index",
  										"usable": true,
  										"key_parts": [
  											"from_date",
  											"to_date",
  											"emp_no"
  										] /* key_parts */
  									}
  								] /* potential_range_indexes */ ,
  								# 如果有下推的条件，则带条件考虑范围查询
  								"setup_range_conditions": [] /* setup_range_conditions */ ,
  								# 当使用了GROUP BY或者DISTINCT时，是否有合适的索引可用。当未使用GROUP BY或者DISTINCT时，会显示chosen=false，cause=not_group_by_or_distinct；如果使用了GROUP或者DISTINCT，但为多表查询时，则会显示chosen=false，cause=not_single_table。其他情况下会尝试分析索引（potential_group_range_indexes）并计算对应的扫描行数及其所需代价
  								"group_index_range": {
  									"chosen": false,
  									"cause": "not_group_by_or_distinct"
  								} /* group_index_range */ ,
  								# 是否使用了skip scan，skip scan是MySQL 8.0的新特性
  								"skip_scan_range": {
  									"potential_skip_scan_indexes": [{
  										"index": "salaries_from_date_to_date_index",
  										"usable": false,
  										"cause": "query_references_nonkey_column"
  									}] /* potential_skip_scan_indexes */
  								} /* skip_scan_range */ ,
  								# 分析各个索引的使用成本
  								"analyzing_range_alternatives": {
  									# range扫描分析
  									"range_scan_alternatives": [{
  										# 索引名
  										"index": "salaries_from_date_to_date_index",
  										# range扫描的条件范围
  										"ranges": [
  											"0xda840f <= from_date <= 0xda840f AND 0xda860f <= to_date <= 0xda860f"
  										] /* ranges */ ,
  										# 是否使用了index dive，该值会被参数eq_range_index_dive_limit变量值影响
  										"index_dives_for_eq_ranges": true,
  										# 该range扫描的结果集是否根据主键值进行排序
  										"rowid_ordered": true,
  										# 是否使用了MRR
  										"using_mrr": false,
  										# 表示是否使用了覆盖索引
  										"index_only": false,
  										# 扫描的行数
  										"rows": 86,
  										# 索引的使用成本
  										"cost": 50.909,
  										# 表示是否使用了索引
  										"chosen": true
  									}] /* range_scan_alternatives */ ,
  									# 分析是否使用了索引合并(index merge)，如果未使用，会在cause中展示原因；如果使用了索引合并，会在该部分展示索引合并的代价
  									"analyzing_roworder_intersect": {
  										"usable": false,
  										"cause": "too_few_roworder_scans"
  									} /* analyzing_roworder_intersect */
  								} /* analyzing_range_alternatives */ ,
  								# 在前一个步骤中分析了各类索引使用的方法及代价，得出了一定的中间结果之后，在summary阶段汇总前一阶段的中间结果确认最后的方案
  								"chosen_range_access_summary": {
  									# range扫描最终选择的执行计划
  									"range_access_plan": {
  										# 展示执行计划的type，如果使用了索引合并，则会展示index_roworder_intersect
  										"type": "range_scan",
  										# 索引名
  										"index": "salaries_from_date_to_date_index",
  										# 扫描的行数
  										"rows": 86,
  										# range扫描的条件范围
  										"ranges": [
  											"0xda840f <= from_date <= 0xda840f AND 0xda860f <= to_date <= 0xda860f"
  										] /* ranges */
  									} /* range_access_plan */ ,
  									# 该执行计划的扫描行数
  									"rows_for_plan": 86,
  									# 该执行计划的执行代价
  									"cost_for_plan": 50.909,
  									# 是否选择该执行计划
  									"chosen": true
  								} /* chosen_range_access_summary */
  							} /* range_analysis */
  						}] /* rows_estimation */
  					},
  					{
  						# 2.6. 负责对比各可行计划的开销，并选择相对最优的执行计划
  						"considered_execution_plans": [{
  							# 当前计划的前置执行计划
  							"plan_prefix": [] /* plan_prefix */ ,
  							# 涉及的表名，如果有别名，也会展示出来
  							"table": "`salaries`",
  							# 通过对比considered_access_paths，选择一个最优的访问路径
  							"best_access_path": {
  								# 当前考虑的访问路径
  								"considered_access_paths": [{
  										# 使用索引的方式
  										"access_type": "ref",
  										# 索引
  										"index": "salaries_from_date_to_date_index",
  										# 行数
  										"rows": 86,
  										# 开销
  										"cost": 50.412,
  										# 是否选用这种执行路径
  										"chosen": true
  									},
  									{
  										"access_type": "range",
  										"range_details": {
  											"used_index": "salaries_from_date_to_date_index"
  										} /* range_details */ ,
  										"chosen": false,
  										"cause": "heuristic_index_cheaper"
  									}
  								] /* considered_access_paths */
  							} /* best_access_path */ ,
  							# 类似于explain的filtered列，是一个估算值
  							"condition_filtering_pct": 100,
  							# 执行计划最终的扫描行数，由considered_access_paths.rows * condition_filtering_pct计算获得
  							"rows_for_plan": 86,
  							# 执行计划的代价，由considered_access_paths.cost相加获得
  							"cost_for_plan": 50.412,
  							# 是否选择了该执行计划
  							"chosen": true
  						}] /* considered_execution_plans */
  					},
  					{
  						# 2.7. 基于considered_execution_plans中选择的执行计划，改造原有的where条件，并针对表增加适当的附加条件，以便于单表数据的筛选，主要是为了便于索引条件下推（ICP），但ICP是否开启并不影响这部分内容的构造
  						"attaching_conditions_to_tables": {
  							# 原始的条件语句
  							"original_condition": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))",
  							# 使用启发式算法计算已使用的索引，如果已使用的索引的访问类型是ref，则计算用range能否使用组合索引中更多的列，如果可以，则用range的方式替换ref
  							"attached_conditions_computation": [] /* attached_conditions_computation */ ,
  							# 附加之后的情况汇总
  							"attached_conditions_summary": [{
  								# 表名
  								"table": "`salaries`",
  								# 附加的条件或原语句中能直接下推给单表筛选的条件
  								"attached": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))"
  							}] /* attached_conditions_summary */
  						} /* attaching_conditions_to_tables */
  					},
  					{
  						# 2.8. 最终的、经过优化后的表条件
  						"finalizing_table_conditions": [{
  							"table": "`salaries`",
  							"original_table_condition": "((`salaries`.`to_date` = DATE'1987-06-26') and (`salaries`.`from_date` = DATE'1986-06-26'))",
  							"final_table_condition   ": null
  						}] /* finalizing_table_conditions */
  					},
  					{
  						# 2.9. 改善执行计划
  						"refine_plan": [{
  							"table": "`salaries`"
  						}] /* refine_plan */
  					}
  				] /* steps */
  			} /* join_optimization */
  		},
  		{
  			# 3. 执行阶段的执行过程
  			"join_execution": {
  				"select#": 1,
  				"steps": [] /* steps */
  			} /* join_execution */
  		}
  	] /* steps */
  }
  
  ```

### 2.6. MySQL数据库诊断命令？

MySQL数据库诊断命令，可以帮助了解数据库的运行情况。

| 命令                 | 作用                                                         |
| -------------------- | ------------------------------------------------------------ |
| SHOW PROCESSLIST     | 查看当前正在运行的线程，如果执行此命令的用户拥有PROCESS权限，则可看到所有线程；否则只能看到自己的线程。等价于select * from information_schema.PROCESSLIST; |
| SHOW STATUS          | 查看服务器相关信息                                           |
| SHOW VARIABLES       | 查看MySQL的变量                                              |
| SHOW TABLE           | 查看表以及视图的状态                                         |
| SHOW INDEX           | 查看索引相关信息                                             |
| SHOW ENGINE          | 查看有关存储引擎的相关信息                                   |
| SHOW MASTER STATUS   | 查看有关master binlog文件的相关信息                          |
| SHOW SLAVE STATUS    | 查看slave线程的相关信息                                      |
| SHOW PROCEDURE       | 查看存储过程相关信息                                         |
| SHOW FUNCTION STATUS | 查看函数相关信息                                             |
| SHOW TRIGGERS        | 查看触发器相关信息                                           |
| SHOW WARNINGS        | 查看error、waring、note级别的诊断信息                        |
| SHOW ERRORS          | 查看error级别的诊断信息，和show warnings类似                 |
| SHOW BINARY LOGS     | 查看服务器上所有的binary log                                 |
| SHOW BINLOG EVENTS   | 查看binary log中的事件                                       |
| SHOW RELAYLOG EVENTS | 查看复制从库的relay log事件相关信息                          |

### 2.7. MySQL索引分类？

- 索引，是按照特定的数据结构，把数据表中的数据放在索引文件中，以便于快速查找。
- 索引存在于磁盘中，会占据物理空间。

| 存储内容   | InnoDB           | MyISAM             |
| ---------- | ---------------- | ------------------ |
| 表结构文件 | .frm             | .frm               |
| 表数据文件 | .idb（聚蔟索引） | .myd               |
| 索引文件   | .idb（聚蔟索引） | .myi（非聚蔟索引） |

#### 按数据结构角度分

##### B-Tree索引

###### BST

- **特点**：
  - Binary Sort Tree，二叉树查找树，左边的结点比右边的结点小，右边的结点比左边的结点大。
  - 查找效率取决于树的高度。
- **查找流程**：
  1. 从根结点出发比较要查找的关键字key。
  2. 如果根结点关键字等于key，则返回根结点。
  3. 如果根结点关键字比key小，则继续查找左子树。
  4. 如果根结点关键字比key大，则继续查找右子树。
- **缺点**：有可能会退化成链表，查询的时间复杂度也从O(logn)退化成O(n)。

![1630832978045](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630832978045.png)

###### AVL

- **特点**：
  - Self-balancing binary search tree，平衡二叉搜索树，每个结点的左子树和右子树的高度差不能超过1。
  - 对于n个结点，树的高度是logn，查询的时间复杂度为O(logn)。
- **缺点**：结点过多时，数的高度也会越来越大，最终导致查询效率较低。

###### B-Tree

- **特点**：
  - Balance Tree，平衡多路搜索树，根结点的子结点个数为 2 <= x <= m，m是树的阶。
    - 假设m=3，则根结点可以有2~3个孩子。
  - 中间结点的子结点个数为m/2 <= y <= m。
    - 假设m=3，中间结点至少有2个孩子，最多3个孩子。
  - 每个中间结点包含n个关键字，n为子结点个数-1，且按升序排序。
    - 如果中间结点有3个子结点，则中间结点里面会有**2个关键字，且按升序排序**。
  - Pi（i=1，...，n+1）为指向子树根结点的指针，其中P[1]指向关键字小于Key[1]的子树，P[i]指向关键字属于（Key[i-1]，Key[i]）的子树，P[n+1]指向关键字大于Key[n]的子树。
    - 如果中间结点有3个子结点，则中间结点里面会有3个指针，2个关键字。
    - P1、P2、P3为指向子树根结点的指针，P1指向关键字小于Key1的树，P2指向Key1~Key2之间的子树，P3指向大于Key2的树。
- **优点**：可以有效地降低树的高度，树的阶m越大，树的高度就越低，查询次数就越少，性能就越高。
  - 在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**，而造成磁盘IO读写过于频繁，进而导致效率低下的情况，此时，只要通过某种较好的树结构减少树的结构尽量减少树的高度，而B树与B+树每个结点可以有多个关键字，由于多路子树的存在，可以大大降低降低树的高度。
- **缺点**：范围查询时，需要多次从头遍历树，性能较低。

![1630833491913](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630833491913.png)

###### B+Tree

- **特点**：
  - B+Tree中，有n个子结点的结点，会含有n个关键字。
    - 而B-Tree中的是n-1个关键字。
  - B+Tree中，所有的叶子结点中包含了全部的关键字信息（会冗余父结点的关键字），且叶子结点按照关键字大小， 自小而大地顺序链接，构成一个有序链表。
    - 而B-Tree中的叶子结点不会包括全部的关键字。
  - B+Tree中，非叶子结点仅用于存放索引（即关键字），不保存数据记录（即data），记录都存放在叶子结点中。
    - 而B-Tree中的非叶子结点既保存索引，也保存数据记录。
- **优点**：
  - B+树是B树的升级版，B+树只有叶节点存放数据，其余节点用来索引，其索引节点可以全部加入内存，增加查询效率，叶子节点可以做双向链表，从而**提高范围查找的效率，增加的索引的范围**。
  - B+树的磁盘读写代价低，更少的查询次数，查询效率更加稳定，有利于对数据库的扫描。

![1630834501421](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630834501421.png)

- **磁盘预读原理**：将**一个节点的大小设为等于一个页**，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：
  - 每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。
- **页存储**：
  - 自mysql5.7后，提供了一个设定page大小的参数innodb_page_size，默认值是16K，可以通过来改变page的大小来**间接改变m阶**，来改变B+树的m的大小。
  - 比如要存20G大小的数据，那么page=16K和page=4K，树的高度是不一样的，也就是说，树的高度是根据要存下的数据是多少来决定的。

![1630915960707](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630915960707.png)

###### B+Tree VS B-Tree

| 场景     | B+Tree                                                    | B-Tree                             |
| -------- | --------------------------------------------------------- | ---------------------------------- |
| 等值查询 | 中间结点存储的索引多，树整体更加矮胖，磁盘I/O次数比较稳定 | 中间结点会存放数据，查询效率不稳定 |
| 范围查询 | 只需要遍历叶子结点的有序链表即可，性能较高                | 需要多次从根结点开始遍历，性能较低 |

###### InnoDB VS MyISAM

|                                      | InnoDB                                 | MyISAM                                           |
| ------------------------------------ | -------------------------------------- | ------------------------------------------------ |
| 索引数据结构                         | B+Tree                                 | B+Tree                                           |
| 主键索引                             | 叶子结点存储主键及数据记录（聚蔟索引） | 叶子结点存储的是指向数据记录的指针（非聚蔟索引） |
| 非主键索引（即二级索引或者辅助索引） | 叶子结点存储索引以及主键（非聚蔟索引） | 叶子结点存储的是指向数据记录的指针（非聚蔟索引） |

##### Hash索引

- **特点**：
  - 基于哈希表来实现，用索引列的值来计算hashCode，根据hashCode组成一个哈希表，同时在哈希表中存储了指向每个数据行的物理位置。
  - 由于使用哈希算法，因此时间复杂度为O（1），访问速度非常快，而当产生哈希冲突时，需要遍历指针数组或者指针链表，性能会下降一些，因此使用哈希索引需要尽量避免哈希冲突的发生。
- **缺点**：
  - 由于一个值只能对应一个hashCode，且根据哈希算法进行散列，哈希后的值不再具有比较意义，因此hash索引**不支持范围查找和排序，只支持等值匹配**，因此Hash索引只适合特殊场景下才使用。

![1630836502073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630836502073.png)

###### InnoDB VS MyISAM

| InnoDB                                                       | MyISAM                 |
| ------------------------------------------------------------ | ---------------------- |
| 1）自适应的hash索引，不支持显示创建Hash索引，当InnoDB发现某个索引值使用非常频繁，它会在B+Tree的基础上再建立一个哈希索引。2）可以使用show variables like 'innodb_adaptive_hash_index'查看开关是否打开。3）以及使用set global innodb_adaptive_hash_index = ‘OFF’，来关闭该功能（默认是打开的） | 支持显示地创建Hash索引 |

##### 空间索引

- **特点**：
  - 基于R-Tree构建，也叫R-Tree索引，用来存储GIS数据（地图数据）。
  - 在早期只有MyISAM引擎支持空间索引，在MySQL 5.7开始，InnoDB也开始支持空间索引了。

##### 全文索引

- **特点**：
  - 用于适应全文搜索的需求。
  - 在MySQL 5.7之前，全文索引不支持中文，经常搭配Sphinx的使用，而从5.7开始MySQL内置了ngram，支持中文。
  - 但是目前一般使用搜索引擎来解决全文搜索的需求，比如ES。

#### 按功能逻辑角度分

##### 普通索引

普通索引，是基础的索引，没有任何约束，主要用于提高查询效率。

```sql
CREATE INDEX index_name ON table(column(length))

```

##### 唯一索引

- 唯一索引，是在普通索引的基础上，增加了数据唯一性的约束，其索引列的值必须唯一，且允许为NULL值。
- 如果一个为唯一索引同时还是组合索引，那么表示列值组合必须唯一。
- 在一张数据表里可以有多个唯一索引。

```sql
CREATE UNIQUE INDEX indexName ON table(column(length))

```

##### 主键索引

主键索引，是一种特殊的唯一索引，其索引列不允许有NULL值，并且一张表最多只有一个主键索引。

##### 组合索引

组合索引，指多个字段上创建的索引，使用组合索引时需要遵循**最左前缀原则**。

```sql
CREATE index index_name ON table (column1, column2);

```

##### 全文索引

全文索引，用来检索文本中的关键字，用得很少，一般应对这种需求用ES或者Solr之类的全文搜索引擎比较好。

```sql
CREATE FULLTEXT INDEX ...

```

#### 按物理存储角度分

![1630845876331](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630845876331.png)

##### 聚蔟索引

聚蔟索引，**叶子结点就是数据结点**，将表数据和主键一起存储，其数据的物理存放顺序与索引顺序是一致的，即只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上，而由于无法同时把数据行同时存放在两个不同的地方，因此一张表只有一个聚蔟索引。

- InnoDB的主键索引使用的是聚蔟索引，如果创建的表没有主键，InnoDB则会隐式定义一个主键来作为聚蔟索引。
- **聚蔟索引的二级索引**：叶子结点不会保存引用行数据，而是保存行的主键值，然后根据主键值获取到数据，比如InnoDB的普通索引、联合索引。
- **优点**：
  - 查找效率理论上比非聚蔟索引的要高，因为数据就存放在索引上，且数据存储顺序就是索引的顺序。
  - 范围查询方便，因为只需要遍历索引的叶子结点即可。
- **缺点**：
  - 插入、修改、删除操作的性能比非聚蔟索引的要低，因为非聚蔟索引在更新时，数据行在表中的位置不会发生变化，而聚蔟索引的数据行需要重新移动位置。
  - **插入速度严重依赖于插入顺序**，因为按照主键顺序插入数据是InnoDB表中速度最快的插入方式，如果不是按照主键顺序插入数据，那么在插入完成后，最好使用**optimize table**命令重新组织一下表，因此，对于聚集索引，一般都会定义一个自增的ID列为主键。
  - **更新主键的代价很高**，因为会导致InnoDB移动被更新的行。
  - 另外，插入新行或者更新主键导致数据行被移动时，还有可能面临**页分裂**的问题，当行的主键值被要求必须插入行数据到某个已满的页中，InnoDB会将页分裂为两个页面来容纳这行，产生一次页分裂操作，这会**导致表占用更多的磁盘空间。**
  - 而由于页分裂导致数据存储不连续，或者本身行数据就存储得比较稀疏时，聚蔟索引可能导致**全表扫描变得更慢**。

##### 非聚蔟索引

非聚蔟索引，**叶子结点不存储数据**，而是指向对应数据块的指针，表数据和索引分开存储，查询时先找到索引，再根据索引找到对应的数据行。

- MyISAM的主键索引使用的是非聚蔟索引。

##### 聚蔟索引与自增主键？

1. **随机主键给聚蔟索引的坏处**：

   - 如果主键不是自增ID（比如UUID），会使得聚簇索引的插入变得随机，使得数据没有任何聚集特性。
   - 性能上，由于插入的随机性产生乱序写入，为了给新行分配空间，InnoDB不得不频繁做页分裂操作，导致需要移动大量数据，不断地调整数据的物理地址和分页，**影响写入的性能**。
   - 而由于**页分裂**导致数据存储不连续，或者本身行数据就存储得比较稀疏时，聚蔟索引可能导致**全表扫描变得更慢**。

   => 因此随机主键在插入完成后，最好使用**optimize table**命令，来重建表并优化页的填充。

2. **自增主键对聚蔟索引的好处**：对于聚蔟索引，叶子结点就是数据结点，将表数据和主键一起存储，其数据的物理存放顺序与索引顺序是一致的，即只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上。

   - 对于这种数据结构，如果按主键自增的顺序写入数据，InnoDB只需要一页一页地写，**索引结构相对紧凑，磁盘碎片少，效率也高**。

3. **自增主键对聚蔟索引的坏处**：对于高并发场景下，如果在InnoDB中按主键顺序插入，**可能会造成明显的锁争用**。这是因为：

   - **主键的上界（左边）会成为热点**：由于所有插入都发生在这里，所以并发插入可能会导致**间隙锁竞争**。
   - **另一个热点是自增锁机制**：如果遇到这个问题，则可能需要考虑重新设计表或者应用，比如应用层面生成单调递增的主键ID，插表不使用auto_increment机制。

### 2.8. MySQL创建索引的原则？

**创建索引的原则**：目的是让索引过滤更多的行，**快速定位记录，或者利用索引的有序性**。

- **where条件、分组、排序、去重、联表、唯一的字段**，一般建议创建索引。
- **更新多、查询少、表数据少、列重复数据多、不是where频繁使用的字段**，一般不建议创建索引。

#### 创建索引

```sql
CREATE [UNIQUE | FULLTEXT]  INDEX 索引名 ON 表名(字段名) [USING 索引方法]；
-- eg: CREATE index index_name ON table (column1, column2);

-- 说明：
-- UNIQUE: 可选。表示索引为唯一性索引。
-- FULLTEXT: 可选。表示索引为全文索引。
-- INDEX: 用于指定字段为索引，两者选择其中之一就可以了，作用是一样的。
-- 索引名: 可选。给创建的索引取一个新名称。
-- 字段名: 指定索引对应的字段的名称，该字段必须是前面定义好的字段。
-- 注： 索引方法默认使用B+TREE。

```

#### 哪些场景建议创建索引

1. **select语句中，频繁作为where条件的字段**，建议创建索引，可以快速定位行记录。
2. **update和delete语句中，where条件的字段**，建议创建索引，可以快速定位行记录。
3. **需要分组、排序的字段**，建议创建索引，可以利用索引的有序性，避免文件内排序和建立临时表。
4. **distinct所使用的字段**，建议创建索引，可以快速定位行记录。
5. **字段的值有唯一性约束**，可以创建主键或者唯一索引。
6. **对于多表查询，联接字段应创建索引**，且**类型务必保持一致**，因为如果不一致可能会出现**类型的隐式转换**，导致索引失效。

#### 哪些场景不建议创建索引

1. **where子句里用不到的字段**，不建议创建索引，索引作用是用来定位记录，如果查询条件里不需要这个字段，那么这个字段也不需要创建索引。
2. **表的记录非常少时**，不建议创建索引，因为这种情况下（比如100条数据），建立索引的作用并不大，没有必要创建索引。
3. **列里有大量重复数据时**，不建议创建索引，因为此时索引的选择性低，建立索引作用不大。
   - **唯一索引比普通索引效率高的原因**：索引选择性越高，查询的效率就越好，因为可以在查找时过滤掉更多的行，如果索引列重复的值过多，索引的选择性就低，查询能过滤掉的行就少，此时效率自然就不高。
4. **频繁更新的字段，想要建立要考虑索引维护的开销**，如果该字段查询得少，则没必要为它创建索引。

#### 索引性能评估公式

多数情况下，可以通过计算磁盘的搜索次数来估算查询性能。

- **对于比较小的表**：可以在一次磁盘搜索中找到，因为索引可能已经被缓存了。
- **对于更大的表**：可以使用B-Tree索引来进行估算，估算公式为：

```mysql
磁盘I/O次数 = log(row_count) / log(
          	index_block_length / 3 * 2 / (index_length + data_pointer_length)
           ) + 1
          
-- 其中，index_block_length=1024字节，data_pointer_length=4字节，则公式等于
磁盘I/O次数 = log(row_count) / log(
          	1024 / 3 * 2 / (index_length + 4)
           ) + 1 
           = log（row_count） / [ log(683 / (index_length + 4) ) ]
           = log（row_count） / [log683 - log(index_length + 4)]

-- => 可见，当row_count越大，index_length越大，内存中存放的索引就越少，需要的磁盘I/O次数就越多，性能就越差。

```

### 2.9. MySQL索引失效与解决方案？

#### 索引列不独立

- **独立**：是指列不能是**表达式**的一部分，也不能是**函数**的参数。
- **解决方案**：
  - 事先计算好结果，再传到SQL，避免在where条件等号左侧做表达式和函数运算。
  - 或者用等价的SQL去替代。

```sql
-- 示例1：索引字段不独立(索引字段进行了表达式计算)
explain
select *
from employees
where emp_no + 1 = 10003;
-- 解决方案：事先计算好表达式的值，再传过来，避免在SQLwhere条件 = 的左侧做计算

-- 示例2：索引字段不独立(索引字段是函数的参数)
explain
select *
from employees
where SUBSTRING(first_name, 1, 3) = 'Geo';
-- 解决方案：预先计算好结果，再传过来，在where条件的左侧，不要使用函数；或者使用等价的SQL去实现
explain
select *
from employees
where first_name like 'Geo%';

```

#### 使用了左模糊

- **解决方案**：尽量避免使用左模糊，如果避免不了，可以考虑使用搜索引擎去解决。

```sql
-- 示例3：使用了左模糊
explain
select *
from employees
where first_name like '%Geo%';
-- 解决方案：尽量避免使用左模糊，如果避免不了，可以考虑使用搜索引擎去解决
explain
select *
from employees
where first_name like 'Geo%';

```

#### 使用OR查询的部分字段没有索引

- **解决方案**：额外添加索引，使得or的两侧字段都走索引。
  - 添加后，explain#type会变成index_merge，表示索引合并（mysql的内部优化机制），合并了or两侧字段的索引。

```sql
-- 示例4：使用OR查询的部分字段没有索引
explain
select *
from employees
where first_name = 'Georgi'
   or last_name = 'Georgi';
-- 解决方案：分别为first_name以及last_name字段创建索引

```

#### 字符串条件未使用''引起来

- **解决方案**：实质上发生了类型的隐式转换，因此需要规范地编写SQL。

```sql
-- 示例5：字符串条件未使用''引起来
explain
select *
from dept_emp
where dept_no = 3;
-- 解决方案：规范地编写SQL
explain
select *
from dept_emp
where dept_no = '3';

```

#### 不符合最左前缀原则的查询

- **解决方案**：调整索引的顺序，使其满足最左前缀原则。

```sql
-- 示例6：不符合最左前缀原则的查询
-- 存在index(last_name, first_name)
explain select *
        from employees
        where first_name = 'Facello';
-- 解决方案：调整索引的顺序，变成index(first_name,last_name)/index(first_name)

```

#### 索引字段建议添加NOT NULL约束

- **原因**：**单列索引无法储null值，复合索引无法储全为null的值**，因此查询时，如果采用is null条件，则不能利用到索引，只能全表扫描。
- **解决方案**：索引字段设置成NOT NULL，甚至可以把所有字段都设置成NOT NULL并为字段设置默认值。

```sql
-- 示例7：索引字段建议添加NOT NULL约束
-- 单列索引无法储null值，复合索引无法储全为null的值
-- 查询时，采用is null条件时，不能利用到索引，只能全表扫描
-- MySQL官方建议尽量把字段定义为NOT NULL：https://dev.mysql.com/doc/refman/8.0/en/data-size.html
explain
select *
from `foodie-shop-dev`.users
where mobile is null;
-- 解决方案：把索引字段设置成NOT NULL，甚至可以把所有字段都设置成NOT NULL并为字段设置默认值

```

#### 隐式转换导致索引失效

- **解决方案**：在创建表的时候尽量规范一点，比如统一用int，或者bigint。

```sql
-- 示例8：隐式转换导致索引失效
-- 目前没这样的表，演示不了，同学们可以试试把de.emp_no的字段类型改成varchar
select emp.*, d.dept_name
from employees emp
         left join dept_emp de
                   on emp.emp_no = de.emp_no
         left join departments d
                   on de.dept_no = d.dept_no
where de.emp_no = '100001';
-- 解决方案：在创建表的时候尽量规范一点，比如统一用int，或者bigint

```

### 3.0. MySQL最左前缀原则与原理？

- **概念**：最左前缀原则，指的是索引按照**最左优先**的方式匹配索引，主要使用在**联合索引**中，其索引的数据结构在InnoDB中是B+Tree，它会按照第一个关键字、第二个关键字...**顺序进行索引排列**。
- **原理**：如果查询条件遵循最左前缀原则，那么MySQL会：
  1. 先根据第一个关键字查找联合索引树。
  2. 定位到索引树的叶子结点后，找出所有满足第一个关键字的叶子结点。
  3. 第一个关键字选择的叶子结点确定后，如果这些叶子结点对于**第二个关键字是存在且顺序**的，则MySQL会使用二分查找的方式查找这些叶子结点，接着该索引继续匹配下一个关键字。
  4. 如果这些叶子结点对于第二个关键字**不存在或者乱序**，此时则会在关键字上出现**索引失效**，导致后面的条件无法继续走上索引，而是根据之前选择的叶子结点上的**主键回表查找**。
- **联合索引失效场景**：这些场景都是因为匹配到某个关键字的叶子结点时，**不满足存在以及顺序性**。
  - 如果不是从索引的最左列开始查找，则无法使用索引。
  - 不能在中间跳过索引中的某个列，这样的查询只能使用到索引的前几列。
  - 如果查询中有某个列的范围查询，则该列右边的所有列都无法使用索引优化查找。

![1630924286192](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630924286192.png)

### 3.1. MySQL索引调优？

#### 长字段调优

- **背景**：

  - 索引字段类型范围过长，比如varchar(300)，会导致占用的空间大。
  - 而根据性能公式`磁盘I/O次数 = log（row_count） / [log683 - log(index_length + 4)]`可知，索引长度越大，一次磁盘I/O读取到的索引就越少，磁盘I/O次数就越多，性能就越差。

- **解决方案**：

  - **使用Hash算法减少B-Tree索引长度**：根据原索引字段建立一个新的字段，使用Hash算法计算原字段的Hash值，并在其上建立B-Tree索引，因此本质上依然是B-Tree索引，是"伪Hash索引"，并不是真正的哈希索引。另外还需要注意：

    - **Hash后的长度应该比较小**：SHA1/MD5是不合适的，因为它们Hash出来的值也是比较长的。
    - **应尽量避免hash冲突**：就目前来说，流行的Hash算法有CRC32（）和FNV64（）。

    ```sql
    -- Hash索引使用案例：
    -- 1) 如果直接使用B-Tree索引存储URL，由于URL一般都比较长，存储的内容就会很大。
    -- 2) 此时可以在表中新建一个列url_crc，把crc32(url)计算后的hashCode存到这个列，并在url_crc列上建立一个Hash索引，这样只需要很小的索引就可以为超长的列建立索引，性能会提高很多。
    -- 3) 但要注意，因为有可能会有哈希冲突，所以还要对url进行等值比较。
    
    ```

  - **使用前缀索引**：alter table employees add key (first_name(n))，其中n应调试到**最佳的索引选择性**，以提高索引的效益。

    - **索引选择性 = 不重复的索引值 / 数据表的总记录数**，结果越大，表示选择性越高，性能也越好。
    - 另外，翻转字符串存储 + 前缀索引，可以实现**后缀索引**。
    - **优点**：能节省空间，提高索引性能；优化对上层应用透明，落地成本小。
    - **缺点**：无法做order by和group by；也无法使用覆盖索引。

#### 单列索引调优

如果使用两个**单列索引**作为查询条件，则会导致MySQL合并索引，对两索引列匹配的结果求交集，导致产生额外的开销。

- 如果出现索引合并，往往说明存在的索引不够合理。
- 调优的目的是为了解决性能问题，如果SQL暂时没有性能问题，可以先放一边暂时不管。
- 必要时，可以将两列索引组合成为一个**组合索引**，可以节省额外的开销，但使用时需要注意**最左前缀原则**。

#### 覆盖索引调优

覆盖索引指的是，对于索引X，**SELECT的字段直接出现在从索引树上**，而无需回表数据里获取，换句话说就是，当SELECT的字段被使用的索引字段覆盖时，这种用法就是覆盖索引。

- **特点**：使用覆盖索引时，Explain#Extra结果会展示Using Index。
- **原理**：
  1. 如果索引是非主键索引，则索引树上只有对应数据行的主键，此后还需要根据主键，然后在主键索引树上定位到叶子结点后，才能返回对应的数据行（**回表查询**）。
     - **回表查询**，就是对于二级索引，需要先定位到主键值，然后再定位行记录，其性能比覆盖索引扫一遍索引树的低。
  2. 如果该索引满足覆盖索引，则在索引树上就找到需要的数据行的字段，此时直接返回即可，无需回表查询。
- **优点**：可以直接在索引树上获取到想要的数据，而无需回表查询，减少了回表的开销，提升性能。
  - 因此，编写SQL时，**尽量只返回想要的字段**，一来可以使用上覆盖索引，二来可以减少网络传输的开销，从而提升SQL的性能。

#### 重复索引调优

重复索引指的是，在相同的列上，按照相同的顺序创建的索引。

- 由于索引在增删改时是有开销的，所以**尽量避免重复索引**，如果发现则应该删除。

```sql
-- 重复索引
create table test_table
(
    id int not null primary key auto_increment,
    a  int not null,
    b  int not null,
    UNIQUE (id),
    INDEX (id)
) ENGINE = InnoDB;
-- 发生了重复索引，改进方案： 删掉唯一索引和普通索引

```

#### 冗余索引调优

冗余索引指的是，如果已经存在索引index（A，B），又创建了index（A），那么index（A）就是index（A，B）的冗余索引。

- 冗余索引针对的是联合索引，不是Hash索引和其他索引。
- 但冗余索引也有特例，特别是与**where + order by / group by主键**时。
  - 这种情况下，是利用了复合索引来定位叶子主键，然后order by / group by利用了主键索引的排序特性，来避免文件内排序。
  - 如果误删某个冗余索引，可能会出现问题。

```sql
-- 冗余索引: index(a)是index(a, b)的冗余索引
-- 冗余索引特例:
explain
select *
from salaries
where from_date = '1986-06-26'
order by emp_no;

-- 创建from_date索引: salaries_from_date_index
-- index(from_date): type=ref, extra=null，使用了索引
-- index(from_date) 某种意义上来说就相当于index(from_date, emp_no) => 因为emp_no是主键索引, 所以order by子句可以使用索引

-- 而index(from_date, to_date): type=ref, extra=Using filesort，order by子句无法使用索引
-- index(from_date, to_date)某种意义上来说就相当于index(from_date, to_date, emp_no) 
-- => 该复合索引跳过了to_date, 导致from_date定位到叶子主键时, 顺序是乱序的, 对于后面的order by就没办法利用上索引了, 所以出现了文件内排序Using filesort
-- 因此, 这种特例下: 在有了index(from_date, to_date)复合索引, 为了保证order by能走索引, 还需要创建冗余索引index(from_date)

```

#### 未使用的索引调优

未使用的索引指的是，某个索引根本未被使用。

- 这种索引就是累赘，应当删除。

### 3.2. MySQL索引条件下推优化？

- **概念**：索引条件下推， Index Condition PushDown，ICP，是针对MySQL**使用索引从表中检索行**情况的优化，其目标是**减少全行读取的次数，从而减少 I/O 操作**。

  - 在没有 ICP 的情况下，存储引擎遍历索引，以定位基表中的行，并将它们返回给 MySQL 服务器，该服务器评估`WHERE`行的条件。
    - 步骤⑥从存储引擎返回查找到的**多条元组**给MySQL Server，MySQL Server在⑦得到较多的元组。
    - 步骤⑦到⑧，MySQL Server依据WHERE子句条件进行过滤，得到满足条件的元组。
    - 因此，在无ICP方式下，是在MySQL Server层得到较多元组，然后才过滤，最终得到的是少量的、符合条件的元组。

  ![1630976765074](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630976765074.png)

  - 启用ICP后，如果`WHERE`可以仅使用索引中的列来评估部分条件，则MySQL服务器会推送这部分**`WHERE`条件下降到存储引擎**。然后，存储引擎使用索引条目评估推送的索引条件，并且仅当满足该条件时才从表中读取行。
    - 步骤③，不仅要在索引行进行索引读取，还要在该阶段依据MySQL Server下推过来的条件进行**条件判断**，不满足条件的则不去读取表中的数据，直接在索引树上进行下一个索引项的判断，直到有满足条件的，才进行步骤④。
    - 步骤⑥从存储引擎返回查找到的**少量元组**给MySQL Server，MySQL Server在⑦得到少量的元组。
    - 因此，在对比无ICP的方式，ICP方式返回给MySQL Server层的是**少量的、符合条件的元组**。

  ![1630976784073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630976784073.png)

- **特点**：当使用Explain进行分析时，如果使用了索引条件下推，Extra会显示**Using index condition**。

- **作用**：索引条件下推优化ICP，可以减少**存储引擎访问基表的次数**和**MySQL服务器访问存储引擎的次数**。

- **适用条件**：

  - **当需要全表扫描时**，比如range、ref、eq_ref、ref_or_null，适用于InnoDB引擎和MyISAM引擎的查询。
  - 对于InnoDB引擎，**只适用于二级索引**，因为其聚簇索引会将整行数据读到InnoDB缓冲区中，此时数据已经在内存中了，存储已经不再需要去I/O读取了，使得ICP减少I/O的目的失去意义，因此**ICP不适合聚蔟索引**。
  - 不能下推引用**子查询、存储函数、触发器函数**的条件。

```sql
-- 关闭索引下推条件优化
SET optimizer_switch = 'index_condition_pushdown=off';

-- 开启索引下推条件优化
SET optimizer_switch = 'index_condition_pushdown=on';

```

### 3.3. MySQL SQL生命周期？

![1630983427049](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1630983427049.png)

① 通过客户端/服务器通信协议与MySQL建立连接，并查询是否有权限。

② MySQL8.0之前需要先查看是否开启缓存，如果开启了Query Cache且命中完全相同的SQL语句，则将查询结果直接返回给客户端。

③ 由解析器进行语法语义解析，并生成解析树，如查询是select、表名tb_student、条件是id='1'等。

④ 由查询优化器生成执行计划，根据索引看看是否可以优化。

⑤ 由执行引擎执行SQL语句对应的执行计划，并根据存储引擎类型得到查询结果，如果开启了Query Cache，则还要把结果缓存起来，否则直接返回。

### 3.4. MySQL SQL执行顺序？

1. **FROM**：将数据从硬盘加载到数据缓冲区，方便对接下来的数据进行操作。
2. **WHERE**：从基表或视图中选择满足条件的元组。
3. **JOIN**：比如right left右连接，此时从右边表中读取某个元组，并且找到该元组在左边表中对应的元组或元组集。
4. **ON**：join on实现多表连接查询，**推荐该种方式进行多表查询，不使用子查询**。
5. **GROUP BY**：对满足条件的元组进行分组，一般与聚合函数一起使用。
6. **HAVING**：在以上元组的基础上进行筛选，选出符合条件的元组，一般与GROUP BY进行连用。
7. **SELECT**：从查询到得的所有元组中，获取需要展示的列。
8. **DISTINCT**：对查询得到的所有元组进行去重。
9. **UNION**：将多个查询结果合并，默认去掉重复的记录。
10. **ORDER BY**：对以上的元组结果进行相应的排序。
11. **LIMIT 1**：显示输出一条元组数据记录。

### 3.5. MySQL SQL语句调优？

#### JOIN优化 

##### 用法

![1631013588400](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631013588400.png)

从左到右，从上到下：

1. **A LEFT JOIN B**：左连接，返回A的全集。
2. **A RIGHT JOIN B**：右连接，返回B的全集。
3. **A INNER JOIN B**：内连接，返回A和B的交集。
4. **A LEFT JOIN B WHERE B.Key IS NULL**：返回A的独有集合。
5. **A RIGHT JOIN B WHERE A.Key IS NULL**：返回B的独有集合。
6. **A FULL OUTER JOIN B**：全连接，返回A和B的并集。
7. **A FULL OUTER JOIN B WHERE A.Key IS NULL OR B.Key IS NULL**：返回A和B独有集合的并集。
8. 另外，还有一种**A CROSS JOIN B**：笛卡尔连接，返回A和B的笛卡尔集，结果行数为 A *  B，如果有ON连接条件，则等于内连接。

##### 原理

联接操作的本质就是，把各个联接表中的记录都取出来，依次匹配的组合会加入结果集并返回给用户。

- 如果没有任何限制条件的话，多表联接起来产生的笛卡尔积可能是非常巨大的。比方说3个100行记录的表联接起来产生的笛卡尔积就有100×100×100=1000000行数据！

- 所以在联接的时候过滤掉特定记录组合是有必要的，在联接查询中的过滤条件可以分成两种，下面以一个JOIN查询为例：

  - **涉及单表的条件**：WHERE条件也可以称为搜索过滤条件，比如t1.m1 > 1是只针对t1表的过滤条件，t2.n2 < ‘d’是只针对t2表的过滤条件。
  - **涉及两表的条件**：比如t1.m1 = t2.m2、t1.n1 > t2.n2等。

  ```sql
  SELECT * FROM t1, t2 WHERE t1.m1 > 1 AND t1.m1 = t2.m2 AND t2.n2 < 'd';
  
  -- 查询结果
  +------+------+------+------+
  | m1   | n1   | m2   | n2   |
  +------+------+------+------+
  |    2 | b    |    2 | b    |
  |    3 | c    |    3 | c    |
  +------+------+------+------+
  
  ```

  - **联接过程**：
    1. 首先确定第一个需要查询的表，这个表称之为**驱动表**，这里使用t1作为驱动表，那么就需要到t1表中找满足t1.m1 > 1的记录，由于这里没有给t1字段添加索引，所以查询t1表的访问方法为all，也就是采用全表扫描的方式执行单表查询。
    2. 从驱动表t1产生的结果集中的每一条记录，分别需要到t2表中，查找符合过滤条件的记录。由于是根据t1表中的记录去找t2表中的记录，所以t2表也可以被称之为**被驱动表**。比如上一步骤从驱动表中得到了2条记录，所以需要查询2次t2表，此时涉及两个表的列的过滤条件t1.m1 = t2.m2就派上用场了。
    3. 当t1.m1 = 2时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 2，所以此时t2表相当于有了t1.m1 = 2、t2.n2 < ‘d’这两个过滤条件，然后到t2表中执行**单表查询**。
    4. 当t1.m1 = 3时，过滤条件t1.m1 = t2.m2就相当于t2.m2 = 3，所以此时t2表相当于有了t1.m1 = 3、t2.n2 < ‘d’这两个过滤条件，然后到t2表中执行**单表查询**。

  ![1631149759571](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631149759571.png)

  - **结论**：
    - 因此，这个两表联接查询共需要查询1次t1表，2次t2表，如果把t1.m1 > 1这个条件去掉，那么从t1表中查出的记录就有3条，就需要查询3次t2表了。
    - 也就是说在两表联接查询中，**驱动表只需要访问一次，被驱动表可能被访问多次**，这种方式在MySQL中有一个专有名词，叫**Nested-Loops Join**（嵌套循环联接）。

##### 算法

###### Nested-Loops Join

- **概念**：
  - 联接算法是，MySQL数据库用于处理联接的物理策略，当联接的表上有索引时，Nested-Loops Join是非常高效的算法。
  - 根据B+树的特性，其联接的时间复杂度为O（logn * logn），若没有索引，则可视为最坏的情况，时间复杂度为O(N²)。
  - MySQL数据库根据不同的使用场合，支持两种Nested-Loops Join算法实现，一种是**Simple Nested-Loops Join（SNLJ）**算法，另一种是**Block Nested-Loops Join（BNLJ）**算法。
- **算法思想**：
  1. **Join阶段**：
     - Join阶段是指，驱动表row scan过滤后的结果集中的每一条记录，需要分别到被驱动表中匹配关联条件的过程。
  2. **Fetch阶段**：
     - Fetch阶段是指，被驱动表根据过滤条件以及匹配的关联条件，进行回表查询数据的过程。
     - 如果关联条件的列是二级索引时，需要再访问主键索引才能得到表中数据（回表），其中MyISAM由于其二级索引存放的是指向记录的指针，所以回表速度要快点；而InnoDB是索引组织表，需要再次通过主键查找才能定位数据。
     - 然而，Fetch阶段也不是必须存在的，如果是覆盖索引联接，那么可以直接得到数据，无需回表，也就没有Fetch这个阶段。

![1631151245915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631151245915.png)

- **性能评估**：评判一个Join算法是否优劣，需要**Join开销成本**是否比较小、**I/O访问方式**是顺序还是随机等。

  | 开销统计                      | 含义                                            |
  | ----------------------------- | ----------------------------------------------- |
  | 驱动表的扫描次数（O）         | 通常都是1，即Join时扫描一次驱动表的数据即可     |
  | 被驱动表的扫描次数（I）       | 使用不同的Join算法，该值可能会不同              |
  | 联接过程读取的总记录数（R）   | 使用不同的Join算法，该值可能会不同              |
  | Join时的比较次数（M）         | 使用不同的Join算法，该值可能会不同              |
  | 被驱动表回表读取的记录数（F） | 如果Fetch为非覆盖索引，被驱动表可能需要回表查询 |

###### Simple Nested-Loops Join

Simple Nested-Loops Join，SNLJ，**简单直接的嵌套循环联接**，即驱动表中的**每一条记录**与被驱动表中的记录都需要进行比较判断，对于两表联接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍，具体访问几遍取决于对驱动表执行单表查询后的结果集中的记录条数。

- **执行过程**：

  ```sql
  For each row r in R do                         -- 扫描R表（驱动表）
      For each row s in S do                     -- 扫描S表（被驱动表）,全表扫描
          If r and s satisfy the join condition  -- 如果r和s满足join条件
              Then output the tuple <r, s>       -- 返回结果集
  
  ```

  ![1631152538991](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631152538991.png)

- **优点**：**算法最简单**。

- **缺点**：由于联接过程需要多次全表扫描被驱动表，所以**性能开销最大**。

  - 联接过程读取的总记录数的成本，和Join时的比较次数的成本都是SN*RN，也就是笛卡儿积。假设外表内表都是1万条记录，那么其读取的记录数量和Join的比较次数都需要上亿，因此实际上MySQL并不会使用到SNLJ算法。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         |
  | ----------------------------- | ------------ |
  | 驱动表的扫描次数（O）         | 1            |
  | 被驱动表的扫描次数（I）       | RN           |
  | 联接过程读取的总记录数（R）   | RN + RN * SN |
  | Join时的比较次数（M）         | RN * SN      |
  | 被驱动表回表读取的记录数（F） | 0            |

###### Index Nested-Loops Join

Index Nested-Loops Join，INLJ，**基于索引的嵌套循环联接**，为了降低SNLJ联接过程中多次全表扫描被驱动表的成本开销，可以在被驱动表中建立索引，减少被驱动表读取的记录数，其中MySQL中使用较多的是这种算法。

- **执行过程**：

  ```sql
  For each row r in R do                     -- 扫描R表
      lookup s in S index                    -- 查询S表的索引（固定3~4次IO，B+树高度）
          If find s == r                     -- 如果r匹配了索引s
              Then output the tuple <r, s>   -- 返回结果集
  
  ```

  ![1631157411686](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631157411686.png)

- **优点**：由于内表上有索引，所以Join比较时不再需要一条条记录进行比较，而可以通过索引来减少比较次数，从而加快查询速度。

  - 由于驱动表中每条记录会通过被驱动表的索引进行**二分查找匹配**，所以每次被驱动表的比较次数为**索引树的高度**。
  - 而一般B+树的高度为3~4层，也就是说匹配一次的I/O消耗也就3~4次，所以索引查询的成本是比较固定的，因此MySQL优化器会倾向于**使用记录数少的表作为驱动表**。

- **缺点**：

  - 如果被驱动表进行Join时，关联列使用的是**主键索引**，在大数据量的情况下，由于主键索引查找的开销非常小，且此时的访问模式也是比较顺序的，INLJ的效率也是相当不错的。
  - 如果被驱动表进行Join时，关联列使用的是**非覆盖的二级索引**，在大数据量的情况下，由于访问的是非覆盖的二级索引，需要通过主键索引进行回表查询，此时会产生**大量的随机I/O**，对比顺序I/O性能低下。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ                         |
  | ----------------------------- | ------------ | ---------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            |
  | 被驱动表的扫描次数（I）       | RN           | RN                           |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） |

###### Block Nested-Loops Join

Block Nested-Loops Join，BNLJ，**基于块的嵌套循环联接**，为了减少SNLJ联接过程中访问被驱动表的次数，使用一次性把多条驱动表中的记录去和被驱动表做匹配，可以大大减少重复从磁盘上加载被驱动表的代价。

- **Join Buffer使用原则**：

  - 每次联接使用一个Join Buffer，因此多表的联接可以使用多个Join Buffer。
  - Join Buffer在联接发生之前进行分配，在SQL语句执行完后进行释放。
  - Join Buffer只存储要进行查询操作的相关列数据，而不是整行的记录。
  - Join Buffer可被用于被驱动表的关联列为**ALL、index、和range**类型的联接查询。
  - 系统变量**Join_buffer_size**决定了Join Buffer的大小。
    - 当MySQL的Join有使用到Block Nested-Loop Join，调大后可以避免多次的内表扫描，从而提高性能；如果是Index Nested-Loop Join使用索引进行Join，那么调大这个变量则毫无意义。
    - Join_buffer_size默认值是256K，显然对于稍复杂的SQL是不够用的。
    - 建议在会话级别进行设置，但如果设置不好，则会容易导致因无法分配内存而宕机的问题。

- **执行过程**：

  ```sql
  For each tuple r in R do                             -- 扫描外表R
      store used columns as p from R in Join Buffer    -- 将部分或者全部R的记录保存到Join Buffer中，记为p
      For each tuple s in S do                         -- 扫描内表S
          If p and s satisfy the join condition        -- p与s满足join条件
              Then output the tuple                    -- 返回为结果集
  
  ```

  ![1631159874694](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631159874694.png)

- **优点**：

  - BNLJ算法较SNLJ算法的改进就在于，可以**减少被驱动表的扫描次数**，甚至可以和Hash Join算法一样，仅需扫描内表一次。
  - 可以使用增大**Join Buffer**（联接缓冲），或者只需要把驱动表关心的列放到查询列表，以支持一次性匹配更多的驱动表记录，来减少循环读取被驱动表的次数，从而提升Join的性能。

- **缺点**：仍然有可能会多次全表扫描被驱动表，占用磁盘 IO 资源。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ                         | BNLJ                                      |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         |

- **算法使用标记**：在BNLJ算法使用后，在SQL Explain#Extra中会提示 Using join buffer (Block Nested Loop)。

  - 在有索引的情况下，MySQL会尝试去使用Index Nested-Loop Join算法。
  - 但在Join列没有索引的情况下，MySQL不会去使用最简单的Simple Nested-Loop Join算法，而是使用Block Nested-Loop Join算法。

###### Batched Key Access Join

Batched Key Access Join，BKA，**批量键访问联接**，为了优化INLJ存在的大量随机I/O操作，在MySQL 5.6开始支持BKA算法，它是通过常见的空间换时间方式，将随机I/O转换为顺序I/O，以此来极大地提升Join的性能。

- **MRR**：Multi Range Read，**多范围读取**，MySQL 5.6的新特性，是BKA的重要支柱，目的是**为了减少磁盘的随机访问**。

  1. InnoDB由于索引组织表的特性，如果查询是使用非覆盖二级索引，则需要回表读取数据做后续处理，虽然二级索引是有序的，但对应的主键索引很可能是无效的，因此该程会随机的回表，并伴随着大量的随机I/O。

  2. 而MRR的优化在于，并不是每次都会通过二级索引直接回表读取记录，而是在范围扫描（Range Access）中，MySQL将扫描到的数据存入由**read_rnd_buffer_size**变量定义的内存大小中，默认256K。

  3. 然后对其按照**Primary Key（RowID）**排序，然后使用排序好的数据进行**顺序回表**，由于InnoDB中叶子节点数据，是按照PRIMARY KEY（ROWID）进行顺序排列的，所以可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，是能够提升读性能的，为SQL查询语句带来极大的性能提升。

  4. MRR能够提升性能的核心在于，这条查询语句在索引上做的是一个**范围查询**，可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出**顺序性**的优势，所以MRR优化可用于被驱动表关联列为**range，ref，eq_ref**类型的查询。

  5. **开启mrr的参数**：optimizer_switch#mrr和optimizer_switch#mrr_cost_based选项。

     - **optimizer_switch#mrr选项**：表示是否开启MRR优化，默认为on。
     - **optimizer_switch#mrr_cost_based**：表示通过基于成本的算法，来确定是否需要开启MRR特性，默认为off。然而，在MySQL当前版本中，基于成本的算法过于保守，导致大部分情况下优化器都不会选择MRR特性。因为如果强制开启MRR，由于MRR需要排序，在某些SQL语句下，假如排序的时间超过直接扫描的时间，那么性能可能会变差。

     ```sql
     set optimizer_switch='mrr=on,mrr_cost_based=off';
     
     ```

     

  ![1631178784100](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631178784100.png)

- **执行过程**：

  1. 将驱动表中相关的列放入Join Buffer中。
  2. 批量地将Key（索引键值）发送到MRR接口。
  3. MRR接口通过收到的Key，**根据其对应的主键ID进行排序**，然后再进行数据的读取操作。
  4. 最后返回结果集给客户端。

  ![1631176759460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631176759460.png)

- **优点**：

  - 与INLJ不同的地方在于，BKA不是从驱动表一行一行地取出 Join条件值，再到被驱动表去做Join，而是从驱动表里**一次性拿出多行存到join_buffer**，然后再一起传给被驱动表。
  - 而这个join_buffer，在BNLJ算法里的作用是暂存驱动表的数据，但在NLJ算法里并没有用，而此时刚好可以**复用join_buffer**到BKA算法中。
  - 如果扫描被驱动表的是主键，那么被驱动表中的记录访问都是比较有序的；如果扫描被驱动表的是非覆盖二级索引，那么对于被驱动表中记录的访问可能就是非常离散的。
  - 因此，对于非覆盖二级索引的join联接，BKA算法会调用MRR接口，通过**对索引对应的主键ID进行排序**，使得该索引能够以**顺序的I/O**读取数据，而不是以随机I/O读取，从而提高Join的执行效率。

- **缺点**：

  - 由于BKA算法本质上是通过MRR接口，将非覆盖二级索引对于记录的访问，转化为根据主键ID排序的较为有序地获取记录，所以要想通过BKA算法来提高性能，需要确保联接列为被驱动表的**非覆盖二级索引**。

  - **BKA参数**：optimizer_switch#batched_key_access选项。

    - 由于BKA使用MRR，因此MRR标志也必须打开，但目前MRR的成本估算过于悲观，必须关闭mrr_cost_based才能使用BKA。

    ```sql
    SET optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
    
    ```

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ/BKA                     | BNLJ                                      |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         |

- **算法使用标记**：EXPLAIN#Extra值包含Using join buffer（Batched Key Access），且类型值为**ref或eq_ref**时，表示使用了BKA。

###### Classic Hash Join

Classic Hash Join，CHJ，Hash Join不需要任何索引，而是在Join Buffer中**创建散列表**，然后被驱动表通过哈希算法进行查找，使得能够在BNLJ算法的基础上，**进一步减少了被驱动表的比较次数**，从而提升JOIN的查询性能。

- **执行过程**：
  1. build阶段：CHJ的第一个阶段，先将驱动表中的数据放入Join Buffer中，然后根据键值产生一张散列表。
  2. probe阶段：CHJ的第二个阶段，随后读取被驱动表中的一条记录，对其应用散列函数，将其和散列表中的数据进行比较。

![1631179295488](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631179295488.png)

- **优点**：

  - 如果Join Buffer能够缓存所有驱动表的查询列，那么驱动表和被驱动表的扫描次数都将只有1次，并且比较的次数也只是被驱动表的记录数（假设哈希算法冲突为0时）；反之则需要扫描多次内部表。因此，为了使Classic Hash Join更有效果，应该规划好Join Buffer的大小。

  - 要使用Classic Hash Join算法，需要将join_cache_level设置为大于等于4的值，并显示地打开优化器的选项，设置过程如下：

    ```sql
    set join_cache_join=4;
    set optimizer_switch='join_cache_hashed=on';
    
    ```

- **缺点**：

  - Classic Hash Join算法虽好，但是仅能用于**等值联接**，对于非等值联接的JOIN查询，就会显得无能为力了。
  - **创建散列表也是费时的工作**，不过一旦建立完成后，就能大幅提升JOIN的速度，因此，在通常情况下，大表之间的JOIN，Hash Join算法会比较有优势；小表通过索引查询，利用BKA Join就已经能很好的完成查询。
  - 此外，Hash Join需要在MySQL 8.0.18才会有支持，业界中使用该版本的公司还是比较少的，所以在生产应用得可能并不多。

- **性能评估**：记关联过程中，驱动表读取的记录数为RN，被驱动表读取的记录数为SN，则其开销统计为：

  | 开销统计                      | SNLJ         | INLJ/BKA                     | BNLJ                                      | CHJ                                       |
  | ----------------------------- | ------------ | ---------------------------- | ----------------------------------------- | ----------------------------------------- |
  | 驱动表的扫描次数（O）         | 1            | 1                            | 1                                         | 1                                         |
  | 被驱动表的扫描次数（I）       | RN           | RN                           | RN * used_col_size / join_buffer_size + 1 | RN * used_col_size / join_buffer_size + 1 |
  | 联接过程读取的总记录数（R）   | RN + RN * SN | RN + IndexMatches            | RN + SN * I                               | RN + SN * I                               |
  | Join时的比较次数（M）         | RN * SN      | RN * IndexHeight             | RN * SN                                   | SN / I                                    |
  | 被驱动表回表读取的记录数（F） | 0            | IndexMatches（非覆盖索引时） | 0                                         | 0                                         |

- **算法使用标记**：如果将Hash Join应用于Simple Nested-Loops Join中，则Explain#Extra列会显示BNLH；如果将Hash Join应用于Batched Key Access Join中，则Explain#Extra列会显示BKAH。

##### 优化方案

根据JOIN原理和每种JOIN的算法分析可得出，JOIN联接查询的成本开销占大头的是，**驱动表记录数 * 单次访问被驱动表的成本**，因此优化重点应该为这两个部分：

- **尽量减少驱动表的记录数**。
  - **小表驱动大表**：一般无需人工考虑，MySQL优化器会自动选择最优的执行方式，另外可以使用STRAIGHT_JOIN可以指定左右表顺序，使其不被优化器优化。
  - **尽量使用过滤条件先减少驱动表的记录数**：如果有where条件，应当要能够使用索引，并尽可能地减少驱动表的数据量。
- **对被驱动表的访问成本尽可能降低**。
  - **尽量在被驱动表的联接列上建立索引**：主键、唯一索引最优，其次是非唯一的二级索引，这样就可以使用eq_ref或ref的索引匹配类型来访问被驱动表，从而降低访问被驱动表的成本。
    - 注意，join字段的类型需要保持一致，以**避免索引失效**。
  - **合理设置join_buffer大小**：如果被驱动表的join字段用不了索引，且内存较为充足，可以考虑把join_buffer设置得大一些，以**减少被驱动表的扫描次数**，提高查询性能。
  - **尽量减少联接过程读取的总记录数**：经验之谈，如果能控制扫描驱动表和被驱动表的行数在**百万条以内**，效率还是可以接受的。
- **参与Join的表不要太多**：
  - 对于NLJ的算法实现，参与Join的驱动表越多，**循环嵌套也就越多**，导致访问被驱动表的次数也越多，性能自然就不会太高。
  - 再者，参与Join的表过多，会导致SQL变得复杂和臃肿，**不利于后期调优和维护**。
  - 在阿里变成规约中建议，**参与Join的表不能超过3张**，如果业务确实需要关联这么多表，可以抽取到应用层去实现，避免在SQL中Join过多的表。

#### GROUP BY优化

##### 执行过程分析

1. 如果group by和select字段都建立了索引，但不做任何优化，则会先扫描emp_no索引树上的每一个索引键。
2. 确定好emp_no后，再去扫描salary索引树的上每一个索引键，然后得出当前emp_no最小的salary。
3. 最后遍历每个emp_no的salary，得出最小的salary并返回。
4. 其中，如果group by和select字段没建立索引，则扫描的不是索引树，而是全表扫描。

```sql
/*
 * 分析这条SQL如何执行：
 * [emp_no, salary] 组合索引
 * [10001,50000]
 * [10001,51000]
 * ...
 * [10002,30000]
 * [10002,32000]
 * ...
 * 1. 先扫描emp_no = 10001的数据，并计算出最小的salary是多少，[10001,50000]
 * 2. 扫描emp_no = 10002，并计算出最小的salary是多少，[10002,30000]
 * 3. 遍历出每个员工的最小薪资，并返回
 */
 -- 查询每个员工拿到过的最少的工资是多少[比惨大会]
-- CREATE INDEX salaries_emp_no_salary_index ON salaries (emp_no, salary);
explain
select emp_no, min(salary)
from salaries
group by emp_no

```

##### 扫描模式

###### Loose Index Scan（松散索引扫描）

松散索引扫描，**无需扫描所有满足条件的索引键**，即可返回结果。

- **执行过程**：

  1. 在确定好emp_no后，由于此时salary索引是有序的，所以第一个salary正式当前emp_no最小的salary，因此，会直接返回第一个salary，跳过后面的salary索引树扫描。
  2. 接着继续遍历下一个emp_no，同样也是取第一个salary...
  3. 最后遍历每个emp_no的salary，得出最小的salary并返回。

- **特点**：

  - **性能最好**：由于索引树是有序的，获取MIN（）时，只需返回第一个索引即可，无需扫描所有满足条件的索引键，**性能最好**。
  - **标志**：Explain#Extra会显示Using index for group-by。

- **使用条件**：

  1. **查询作用在单张表上**：
     - 因为如果作用在多张表上，可能需要扫描整个索引树。
  2. **GROUP BY关键字都要符合最左前缀原则**：
     - 因为如果不符合最左前缀原则，会导致复合索引的索引失效，此时可能会全表扫描。
  3. **聚合函数只支持MIN（）和MAX（）**：
     - 由于其他聚合函数需要扫描所有索引键，因此只支持MIN（）和MAX（）。
     - 且如果MIN（）和MAX（）同时在一条SQL中使用，则必须作用在同一个字段，才能走松散索引扫描。
     - 且MIN（）和MAX（）的字段必须也符合最左前缀原则，保证索引不失效。
     - 另外，当查询中不存在GROUP BY和DISTINCT语句时，AVG（DISTINCT 单个参数）、SUM（DISTINCT 单个参数）、COUNT（DISTINCT 多个参数） 也可以使用松散索引扫描。
  4. **SELECT字段必须为GROUP BY关键字或者常量**：
     - 因为如果SELECT字段为非GROUP BY关键字、非常量，可能会导致回表查询（最左前缀索引等值查询除外），不符合松散索引扫描原则。
  5. **索引不能为前缀索引**：
     - 因为使用前缀索引无法让GROUP BY正常工作。

- **适用场景举例**：假设index（c1，c2，c3）作用在t1（c1，c2，c3，c4）表上。

  ```sql
  -- 符合最左前缀原则
  SELECT c1，c2 FROM t1 GROUP BY c1，c2；
  
  -- 等价与GROUP BY c1，c2，只不过DISTINCT取的是分组后的一条数据
  SELECT DISTINCT c1，c2 FROM t1；
  
  -- 聚合函数 + DISTINCT + 非GROUP BY和DISTINCT条件时，也可以走松散索引扫描
  SELECT COUNT(DISTINCT c1)，SUM(DISTINCT) FROM t1；
  SELECT COUNT(DISTINCT c1，c2)，COUNT(DISTINCT c2，c1) FROM t1；
  
  -- 符合最左前缀原则 + MIN（）
  SELECT c1，MIN（c2） FROM t1 GROUP BY c1；
  
  -- 范围查询 + 符合最左前缀原则
  SELECT c1，c2 FROM t1 WHERE c1 < const GROUP BY c1，c2；
  
  -- 范围查询 + 符合最左前缀原则
  SELECT c2 FROM t1 WHERE c1 < const GROUP BY c1，c2；
  
  -- 范围查询 + 符合最左前缀原则 + MIN（）& MAX（）作用在同一个字段上
  SELECT MAX（c3），MIN（c3），c1，c2 FROM t1 WHERE c2 > const GROUP BY c1，c2；
  
  -- 符合最左前缀原则 + 最左前缀索引等值查询
  SELECT c1，c2 FROM t1 WHERE c3 = const GROUP BY c1，c2；
  
  ```

- **不适用场景举例**：假设index（c1，c2，c3）作用在t1（c1，c2，c3，c4）表上。

  ```sql
  -- 聚合函数不是MIN（）或MAX（）
  SELECT c1，SUM（c2） FROM t1 GROUP BY c1；
  
  -- 不符合最左前缀原则
  SELECT c1，c2 FROM t1 GROUP BY c2，c3；
  
  -- SELECT查询了非GROUP BY关键字、非常量，且c3最左前缀索引没作等值查询
  SELECT c1，c3 FROM t1 GROUP BY c1，c2；
  -- => 改成下面语句，则可以走松散索引扫描
  -- 符合最左前缀原则 + 最左前缀索引等值查询
  -- SELECT c1，c2 FROM t1 WHERE c3 = const GROUP BY c1，c2；
  
  ```

###### Tight index Scan（紧凑索引扫描）

紧凑索引扫描，**需要扫描所有满足条件的索引键**，才可返回结果，如果一条SQL无法使用松散索引扫描，则会尝试使用紧凑索引扫描。

- **特点**：

  - **性能次好**：由于需要扫描整个索引树，因此，性能会比松散索引扫描差一些，不过还是可以接受的。
  - **标志**：Explain#Extra会显示Using index，表示覆盖索引，扫描了整个索引树。

- **适用场景举例**：

  ```sql
  -- 紧凑索引扫描，虽然emp_no和salary有索引，但使用了SUM聚合函数，需要遍历整个salary索引树
  -- CREATE INDEX salaries_emp_no_salary_index ON salaries (emp_no, salary);
  explain
  select emp_no, sum(salary)
  from salaries
  group by emp_no;
  
  ```

###### Temporary table（临时表）

当紧凑索引扫描也无法使用的话，MySQL会读取需要的数据，**创建一个临时表**，用临时表实现GROUP BY操作。

- **特点**：

  - **性能最差**：因为走了全表扫描以及创建了一个临时表。
  - **标志**：Explain#Extra会显示Using temporary，表示使用了临时表。

- **场景举例**：

  ```sql
  -- 出现临时表，hire_date没有索引
  explain
  select max(hire_date)
  from employees
  group by hire_date;
  
  ```

###### 扫描模式总结

| 扫描模式                         | 使用规则                             | Extra标识                | 性能 |
| -------------------------------- | ------------------------------------ | ------------------------ | ---- |
| Loose Index Scan（松散索引扫描） | 优先尝试使用                         | Using index for group-by | 最好 |
| Tight index Scan（紧凑索引扫描） | 使用不了松散索引扫描时，才会尝试使用 | Using index              | 次好 |
| Temporary table（临时表）        | 使用不了紧凑索引扫描时，才会使用     | Using temporary          | 最差 |

##### 优化方案

如果GROUP BY使用了临时表，则要想办法**走上索引**，即用上松散索引扫描，或者紧凑索引扫描，尽量避免临时表。

#### DISTINCT优化

- **原理**：DSITINCT本质上是在GROUP BY操作之后，**每组只取1条数据**。
- **优化方案**：和GROUP BY思路一样，如果使用了临时表，则要想办法**走上索引**，即用上松散索引扫描，或者紧凑索引扫描，尽量避免临时表。

#### ORDER BY优化

##### 索引使用规律

###### 全表扫描 VS 索引排序

|          | 场景                                | 标志                                   |
| -------- | ----------------------------------- | -------------------------------------- |
| 全表扫描 | 当MySQL优化器发现全表扫描开销更低时 | 此时Explain#Extra会显示Using File Sort |
| 索引排序 | 当MySQL优化器发现走索引开销更低时   | 此时Explain#Extra没有Using File Sort   |

###### 单列索引+范围查询

- **排序情况**：可以使用索引避免排序。
- **原理**：单列索引first_name是有序的，即使做了范围查询，也是可以利用索引避免排序的。

```sql
explain
select *
from employees
where first_name < 'Bader'
order by first_name;

```

###### 联合索引+等值查询

- **排序情况**：可以使用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name等值结果中的last_name是有序的，因此可以利用索引的有序性。

```sql
explain
select *
from employees
where first_name = 'Bader'
order by last_name;

```

###### 联合索引+范围查询

- **排序情况**：无法利用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name非等值结果集中，last_name是无序的，因此无法利用索引避免排序。

```sql
explain
select *
from employees
where first_name < 'Bader'
order by first_name;

```

###### 升降序不一致

- **排序情况**：无法利用索引避免排序。
- **原理**：对于联合索引（first_name，last_name），first_name等值结果中的last_name只是顺序的，如果再对last_name做反向排序，则利用不了last_name的有序性，因此无法利用索引避免排序。

```sql
explain
select *
from employees
order by first_name desc, last_name asc
limit 10;

```

###### 排序字段存在多个索引中

- **排序情况**：无法利用索引避免排序。
- **原理**：
  1. 虽然first_name和emp_no分别是普通索引和主键索引，它们都是有序的。
  2. 但如果先对first_name做排序再对主键做排序，由于普通索引是非聚蔟索引，会先去找主键，然后把找到的主键集做排序。
  3. 而在这种情况下，是不能保证这些主键集的有序性的，因此无法利用索引避免排序。

```sql
-- emp_no为主键
explain
select *
from employees
order by first_name, emp_no
limit 10;

```

##### 排序模式

Using File Sort，共有三种排序模式：

###### rowid排序（常规排序）

- **执行过程**：
  1. 从表中获取满足WHERE条件的记录。
  2. 对于每条记录，将记录的主键及排序键（id，order_column）取出来，放入sort buffer（排序缓存，由**sort_buffer_size**控制）。
  3. 如果sort  buffer能存放所有满足条件的（id，order_column），则直接在sort buffer内存中进行排序；否则，会进行多次sort buffer排序，并在每次在sort buffer满后，把排序后的结果写到**临时文件**中。
     - 这里sort buffer排序算法用的是，**快速排序**算法，O（n * logn）。
  4. 如果sort buffer排序后，产生了临时文件，则还需要对其使用**归并排序算法**，来保证记录是有序的。
  5. 循环执行上述过程，直到所有满足条件的路基全部参与排序。
  6. 扫描排好序的（id，order_column），并**使用id**去获得SELECT语句中其他需要返回的字段。
  7. 返回结果集。
- **特点**：
  - **可能会产生临时文件**：需要看sort buffer能否存放WHERE里面的所有（id，order_column），如果不满足，则会产生临时文件。
  - **一次排序需要两次I/O**：
    1. 第一次I/O发生在第2步，将（id，order_column）读取出来放入sort buffer中，且如果sort buffer满后，还会写出到临时文件中
    2. 第二次I/O发生在第6步，当（id，order_column）排序好后，需要根据主键ID获取其他字段，由于其结果是按照order_column进行排序的，只能保证order_column是顺序的，并不能保证主键ID的有序性，因此会存在随机I/O的问题。
       - **解决方案**：MySQL内部针对这种情况做了优化，在使用主键ID去获取数据之前，先对主键ID排好序并放入一个缓存里面，其大小由**read_md_buffer_size**控制（即MRR接口），默认256K，接着再去获取记录，从而把随机I/O转换为顺序I/O。

###### additional_fields排序（全字段排序）

- **执行过程**：
  1. 与rowid排序（常规排序）执行过程类似，不过排序的字段不仅仅只有（id，order_column），而是该SQL中**所有需要的字段都**会放入到sort buffer中参与排序。
  2. 由于sort buffer已经包含了查询需要的所有字段，因此，在sort buffer中排序完成后，即可直接返回。
- **优点**：排序完成后即可直接返回，无需两次I/O，从而获得了性能的提升。
- **缺点**：
  - 由于所有字段都参与排序，所以一行数据占用的空间会比rowid排序的多。
  - 如果sort buffer设置的比较小（默认256K），由于排序的字段多，在排序时会容易占满sort buffer，从而导致产生临时文件，而发生了写临时文件+归并排序，性能下降。
- **使用场景**：当order by中出现的**字段总长度小于max_length_for_sort_data**时，MySQL会使用全字段排序；否则，MySQL会使用rowid排序。

###### packed_additional_fields排序（打包字段排序）

- **执行过程**：
  1. 与全字段排序的工作原理一样，也是将所有需要的字段都放入到sort buffer中参与排序。
  2. 不同的地方在于，打包字段排序，会将**字段紧密地排列**在一起，而不是使用固定长度空间（字段总长度）。
     - 比如VARCHAR（255）"yes"字段，使用全字段排序会占用255字节的sort buffer，而使用打包字段排序则只占用2+3字节的sort buffer。
- **优点**：由于字段会紧密排列，一个sort buffer可以容纳下更多的字节，从而减少写临时文件的发生，减少性能下降的概率。

###### 排序与OPTIMIZER_TRACE

```json
    {
      # 3. 执行阶段的执行过程
      "join_execution": {
        "select#": 1,
        "steps": [
          {
            # 排序后特有的内容
            "sorting_table": "employees",
            "filesort_information": [
              {
                "direction": "asc",
                "expression": "`employees`.`last_name`"
              }
            ] /* filesort_information */,
            "filesort_priority_queue_optimization": {
              "limit": 502,
              "chosen": true
            } /* filesort_priority_queue_optimization */,
            "filesort_execution": [
            ] /* filesort_execution */,
            # 重点关注 filesort_summary
            "filesort_summary": {
              # 可用内存, 其实就是sort_buffer_size => 默认256k
              "memory_available": 262144,
              "key_size": 264,
              "row_size": 401,
              "max_rows_per_buffer": 503,
              "num_rows_estimate": 45208,
              # 本次排序一共参与排序的行数
              "num_rows_found": 22287,
              # 本次排序产生了几个临时文件, 0则代表是完全基于内存排序
              "num_initial_chunks_spilled_to_disk": 0,
              "peak_memory_used": 205727,
              "sort_algorithm": "std::sort",
              "unpacked_addon_fields": "using_priority_queue",
              # 使用的排序模式: 这里全字段排序 => rowid、additional_fields、packed_additional_fields
              "sort_mode": "<varlen_sort_key, additional_fields>"
            } /* filesort_summary */
          }
        ] /* steps */
      } /* join_execution */
    }

```

###### 排序模式总结

| 变量                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| sort_buffer_size         | 指定sort_buffer的大小                                        |
| read_rnd_buffer_size     | 默认256K，MRR接口主键ID排序后的缓存区大小                    |
| max_sort_length          | 指定排序时，排序字段最多取多少字节                           |
| max_length_for_sort_data | 当order by中出现的**字段总长度小于max_length_for_sort_data**时，MySQL会使用全字段排序；否则，MySQL会使用rowid排序。 |

##### 优化方案

- **使用索引**：最好的做法是，利用索引的有序性，让MySQL跳过filesort排序过程，以避免排序。
- **优化filesort**：如果发生了filesort，并且没有办法避免时，则需要想办法优化filesort。
  - **调大sort_buffer_size**：设置较大的sort buffer，可以减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
    - 当OPTIMIZER_TRACE#filesort_summary#**num_initial_chunks_spilled_to_disk**过大时，说明产生的临时文件过多，归并次数也就越多，此时可以调大sort buffer，以减少临时文件的产生，提升性能。
  - **调大read_rnd_buffer_size**：设置较大的MRR排序缓存区，可以接收更多来自MRR接口排序好的主键ID，从而让一次顺序I/O返回更多的结果。
  - **调小max_sort_length**：如果排序字段超长，减少取值的字段长度，可以减少sort buffer的占用，减少甚至避免临时文件的产生，从而减少归并操作的次数，或者避免归并操作的发生。
  - **设置合理的max_length_for_sort_data**：一般不建议随意调整。
    - 如果设置得过大，MySQL则会认为有足够的缓存容纳全部字段，使得各种排序SQL都走上全字段排序，从而导致**大量的内存占用**，当还发生写临时文件时，又会**占用大量的硬盘**。
    - 如果设置得太小，MySQL则会认为没有足够的缓存容纳全部字段，使得各种排序SQL都走上rowid排序，由于rowid排序需要走上两次I/O，并且会有随机I/O的发生，所以导致**各种排序SQL性能都比较低下**。

#### LIMIT优化

##### 用法

limit offset, size：

- **offset**：返回结果第一行的偏移量，即想要跳过多少行。
- **size**：指定返回多少条记录。

##### 优化需求

当offset过大时，会导致MySQL先扫描offset条行数据，从而可能使MySQL走向**全表扫描**。

```sql
-- 查询第30001页的时候，花费174ms
explain
select *
from employees
limit 300000,10;

```

##### 优化方案

###### 使用覆盖索引

可在只返回索引字段的场合下，让全表扫描ALL提升到**全索引树扫描Index**。

- **缺点**：只能返回单个字段。

```sql
-- 方案1：覆盖索引 (108ms)
explain
select emp_no
from employees
limit 300000,10;

```

###### 使用覆盖索引+Join

这种方式会先走一次方案1，不过由于方案一为全索引数扫描Index，满足了BNLJ的使用场景，因此可以使用覆盖索引 + Join的方式，来获取深度分页的**全字段查询结果**。

- **分析**：此时联接算法为**BNLJ**，由于t比较小，MySQL会使用t为驱动表，然后把t的查询结果存进join_buffer，接着e表一次性将join_buffer的结果进行匹配，由于联接字段是e的覆盖索引，可以在索引树上直接返回，不会产生大量的随机I/O，因此这种优化方式还是可以接受的。

```sql
-- 方案2：覆盖索引+join(109ms)
select *
from employees e
         inner join
     (select emp_no from employees limit 300000,10) t
     using (emp_no);

```

###### 覆盖索引+子查询

这种方式也是先需要走一次方案1，先查询达到深度分页最小的emp_no，再利用索引的有序性，往后再找10条记录。

- **分析**：利用了索引的有序性。

```sql
-- 方案3：覆盖索引+子查询（126ms）
select *
from employees
where emp_no >=
      (select emp_no from employees limit 300000,1)
limit 10;

```

###### 范围查询

- **优点**：扫描的行数永远只有10行，性能次优。
- **缺点**：需要先获取上一页最大的emp_no。

```sql
select *
from employees
where emp_no > #{last_max_emp_no}
limit 10;

```

###### 起始主键值 + 结束主键值

- **优点**：扫描的行数永远只有10行，且只在主键索引上查询，性能最优。
- **缺点**：需要先获取上一页最后一行的主键值。

```sql
-- 方案5：如果能获得起始主键值 & 结束主键值
select *
from employees
where emp_no between 20000 and 20010;

```

###### 禁止传入过大的页码

从业务的角度解决深度分页问题，比如百度搜索最多只显示76页的结果。

- **缺点**：需要业务的妥协。

#### COUNT优化

##### MySQL#count（？）区别

如果没有特殊要求，一般建议使用count（*）就好。

| 形式              | 性能上的区别                                                 | 业务上的区别                                   |
| ----------------- | ------------------------------------------------------------ | ---------------------------------------------- |
| count（业务字段） | 如果该字段存在索引，则会走上索引；否则只能全表扫描           | 只会对该字段进行统计，会排除字段值为NULL的行   |
| count（*）        | 与count（1）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键；InnDB >= 8.0.13，对于无条件count（*）做了优化 | 与count（1）没有区别，不会排除字段值为NULL的行 |
| count（1）        | 与count（*）没有区别，会优先选择最小字段长度的非主键索引，其次才是主键 | 与count（*）没有区别，不会排除字段值为NULL的行 |

##### MySQL#count（*）索引选择规律

1. 当没有非主键索引时，会使用主键索引。eg：PRIMARY => ken_len: 4。
2. 如果存在非主键索引的话，会使用非主键索引。eg：user_test_count_email_index => ken_len: 243。
3. 如果存在多个非主键索引，会使用一个最小的非主键索引。eg：user_test_count_birthday_index => ken_len: 4。

##### MySQL#count（*）索引选择原理

1. InnoDB的非主键索引叶子结点存储的是索引 + 主键，而主键索引存储的是主键+表数据。
2. 在MySQL#count时，如果使用非主键索引，可以比使用主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。
3. 同理，在MySQL#count时，如果使用key_len小的非主键索引，可以比使用key_len大的非主键索引，在一页里面容纳更多的关键字，节省索引树扫描次数，从而提升性能。

##### 优化方案

目的是减少count查询的性能开销。

###### 升级MySQL版本

InnDB >= 8.0.13，对于无条件count（*）做了优化，性能提升比较大。

- **缺点**：实际项目用的很少，一般不会升级MySQL版本。

###### 更换MyISAM引擎

把数据库引擎换成MyISAM，由于MyISAM引擎的表数据不存在索引树上，在遇到没有条件的count查询会直接返回结果。

- **缺点**：实际项目用的很少，一般不会修改数据库引擎。

###### 创建更小的非主键索引

- **缺点**：提升并不大。

###### 建立汇总表

分别记录每张业务表的表名以及表数量，当业务表发生变化时，更新汇总表，也可以使用触发器去维护汇总表。

- **优点**：结果比较准确、用法比较灵活。
- **缺点**：增加了维护的成本。

###### 使用sql_calc_found_rows

在做完limit语句后，紧跟found_rows()语句获取分页时sql_calc_found_rows统计的结果。

- **缺点**：需要分页；mysql 8.0.17已经废弃这种用法，且未来会被删除。
- **注意点**：需要在MYSQL终端执行，IDEA无法正常返回结果。

```sql
-- 在做完本条查询之后，自动地去执行COUNT
select sql_calc_found_rows * from salaries limit 0,10;
select found_rows() as salary_count;

```

###### 缓存+定时更新

使用定时器定时统计结果到缓存中。

- **优点**：性能比较高；结果比较准确，有误差但是比较小，除非在缓存更新的期间，新增或者删除了大量数据，这时无差才会比较大。
- **缺点**：引入了额外的组件，增加了架构的复杂度。

###### information_schema.tables

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
-- 方案6：information_schema.tables
select *
from `information_schema`.TABLES
where TABLE_SCHEMA = 'employees' and TABLE_NAME = 'salaries';

```

###### show table status

优缺点同information_schema.tables。

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
show table status where Name = 'salaries';

```

###### explain

优缺点同information_schema.tables。

- **优点**：不操作业务表，不论业务表有多少数据，都可以迅速地返回结果。
- **缺点**：是估算值，并不是准确值。

```sql
explain select * from salaries;

```

###### 反向查询

如果反向查询能够减少扫描的行数的话，可以考虑进行反向查询。

- **缺点**：针对的只是**特殊场合**下的范围统计查询。

```sql
select count(*) from salaries where emp_no > 10010;
-- 等价于 => 逆向查询
select count(*) - (select count(*) from salaries where emp_no <= 10010) from salaries;

```

#### 表结构优化

##### 数据库三范式

###### 第一范式（1NF）

- **概念**：
  - 字段具有**原子性**，即数据库表的每一个字段都是不可分割的原子数据项，不能是集合、数组、记录等非原子数据项。
  - 当实体中的某个属性有多个值时，必须拆分为不同的属性。
- **好处**：在统计比如address字段时，如果满足1NF的话，更加容易统计出省、市和具体地址的个数，粒度更细，字段具有原子性。
- **解决方案**：如果需要让表符合1NF，可以通过**拆字段**的方式来实现。

![1631344696874](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631344696874.png)

###### 第二范式（2NF）

- **概念**：在满足1NF的基础上，要求表中每一行数据具有**唯一性**，并且非主键字段完全依赖主键字段。
- **好处**：消除了部分依赖，每个非主键属性必须完全依赖于主键。
- **解决方案**：如果需要让表符合2NF，可以通过**垂直拆表**的方式来实现。

![1631345460201](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345460201.png)

![1631345039416](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345039416.png)

###### 第三范式（3NF）

- **概念**：在满足2NF的基础上，表中字段不能存在传递依赖。
- **好处**：消除了传递依赖。
- **解决方案**：如果需要让表符合3NF，可以通过**垂直拆表**的方式来实现。

![1631345416769](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345416769.png)

![1631345387480](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631345387480.png)

###### 反模式设计

- **概念**：出于性能的考虑，可以打破三范式的约束，将某些字段冗余起来，减少表之间的关联以提升查询效率。
- **好处**：灵活、不需要联表、性能较好。

![1631346021073](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631346021073.png)

##### 表设计原则

1. **字段应少而精**，建议20个以内（经验之谈） ，超过后可以拆分出去。
   - 把常用的字段放到一起。
   - 把不常用的字段独立出去。
   - 大字段（TEXT/BLOB/CLOB等）独立出去。
2. **尽量使用小型字段**。
   - 比如ip可以用int类型存储，而不是varchar类型，这样可以节省空间和提高性能。
3. **避免使用允许为NULL的字段**。
   - MySQL官方建议把字段设置为非NULL，因为允许为NULL的字段很难做查询优化，且索引需要额外的空间。
4. **合理平衡范式和冗余**。
   - 一般情况下都是要遵守三范式的，但必要时可以进行反模式设计，以提高查询效率。
5. 如果表数据量非常大，可以考虑**分库分表**。
6. 其他的量化建议：
   - 单表不超过40列。
   - 单表索引不超过5个。
   - 单表不超过500w数据。
   - 单库不超过200张表。

#### SQL语句优化建议总结

##### 避免使用子查询

```sql
-- 子查询在MySQL5.5版本里，内部执行计划器是先查外表再匹配内表，而不是先查内表t2，所以，当外表的数据很大时，查询速度会非常慢。
SELECT * FROM t1 WHERE id (SELECT id FROM t2 WHERE name='hechunyang');

-- 而在MariaDB10/MySQL5.6版本里，采用了Join关联方式对其进行了优化，该SQL会自动转换为：
-- SELECT t1.* FROM t1 JOIN t2 ON t1.id = t2.id；
-- 而JOIN语句会被MySQL优化器使用对应的Join算法优化，此时，相对于原本的子查询来说，有了一定的性能提升

-- 但还要注意的是：这种优化只针对SELECT有效，对UPDATE/DELETE的子查询是无效的，因此，生产环境应避免使用子查询！

```

##### 避免函数索引

```sql
-- 低效查询，MySQL不像Oracle那样支持函数索引，即使d字段有索引，也会直接全表扫描
SELECT * FROM t WHERE YEAR(d) >= 2016;

-- 高效查询，MySQL索引项不适用函数，避免索引失效
SELECT * FROM t WHERE d >= '2016-01-01'；

```

##### 使用IN来替换OR

```sql
-- 低效查询，回表3次
SELECT * FROM t WHERE LOC_ID = 10 OR LOC_ID = 20 OR LOC_ID = 30;

-- 高效查询，MRR接口优化
SELECT * FROM t WHERE LOC_IN IN (10,20,30);

```

##### LIKE双百分号无法使用到索引

```sql
-- 低效查询，索引失效
SELECT * FROM t WHERE name LIKE '%de%';

-- 高效查询，索引不失效
SELECT * FROM t WHERE name LIKE 'de%';

```

##### 使用LIMIT读取适当的记录

```sql
-- 低效查询，查询所有记录
SELECT * FROM t WHERE 1;

-- 低效查询，只查询10条记录
SELECT * FROM t WHERE 1 LIMIT 10;

```

##### 避免数据类型不一致

```sql
-- 低效查询，索引失效
SELECT * FROM t WHERE id = '19';

-- 高效查询，索引不失效
SELECT * FROM t WHERE id = 19;

```

##### 减少GROUP BY多余的排序

```sql
-- 低效查询，GROUP BY会对goods_id进行排序，因为只是想看统计结果而已，没必要排序
SELECT goods_id,count(*) FROM t GROUP BY goods_id;

-- 高效查询，使用ORDER BY NULL来禁止GROUP BY排序，避免排序结果的消耗
SELECT goods_id,count(*) FROM t GROUP BY goods_id ORDER BY NULL;

```

##### 禁止不必要的ORDER BY排序

```sql
-- 低效查询，因为只是想看统计结果而已，没必要排序
SELECT count(1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id WHERE 1 = 1 
ORDER BY u.create_time DESC;

-- 高效查询，禁止不必要的ORDER BY排序
SELECT count(1) FROM user u LEFT JOIN user_info i ON u.id = i.user_id;

```

### 3.6. MySQL主从复制？

#### 概念

- **原理**：把主节点的binlog日志，复制到从节点上执行一遍，从而达到主从数据一致的状态。

- **过程**：

  1. 主节点**binlog线程**，在每个事务更新数据完成之前，将该操作记录串行地写入到自己的binlog文件中。
     - **bin log**：主库的二进制日志。
  2. 在start slave开启主从同步后，从节点**I/O线程**，负责从master上拉取binlog内容，放在自己的relay log（中继日志）中，如果从节点读取的进度已经跟上了master，则会进入睡眠状态，并等待master产生新的事件。
     - **relay log**：从库的中继日志。
  3. 从节点另外开启一个**SQL线程**，把relay log中的语句，在自身机器上执行一遍，从而达到主从数据一致的状态。

  ![1631410904850](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631410904850.png)

- **优点**：

  - **数据分布**：可以作为**备用数据库**，避免单点故障。
  - **负载均衡**：可以做读写分离，一个写库，一个或多个读库，在不同的服务器上，充分发挥服务器和数据库的性能，但要保证**数据的一致性**。

- **开启主从配置**：

  ```sql
  -- 1. 修改主节点的/etc/my.cnf
  log-bin=imooc_mysql
  server-id=1
  
  -- 2. 编辑从节点的/etc/my.cnf
  server-id=2
  
  -- 3. 主节点创建备份账号
  mysql> CREATE USER 'repl'@'%' IDENTIFIED BY 'password'; 
  mysql> GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
  
  -- 4. 主节点表加读锁，阻止写入
  mysql> FLUSH TABLES WITH READ LOCK;
  
  -- 5. 主节点查看bin-log状态
  mysql > SHOW MASTER STATUS;
  
  -- 6. 主节点dump所有数据，用于初始化从节点
  mysqldump --all-databases --master-data > dbdump.db -uroot -p
  
  -- 7. 主节点解锁，允许写入
  mysql> UNLOCK TABLES;
  
  -- 8. 从节点导入主节点dump出来的数据
  mysql < aa.db -uroot -p
  
  -- 9. 从节点配置主从连接信息
  mysql> CHANGE MASTER TO
      -- 主节点地址
  	-> MASTER_HOST='master_host_name',
  	-- 主节点端口
  	-> MASTER_PORT=port_num
      -- 备份账户用户名
  	-> MASTER_USER='replication_user_name', 
  	-- 备份账户密码
  	-> MASTER_PASSWORD='replication_password', 	
      -- bin-log文件名
  	-> MASTER_LOG_FILE='recorded_log_file_name',
      -- bin-log位置
      -> MASTER_LOG_POS=recorded_log_position;
  
  -- 10. 从节点开启主从同步
  mysql> START SLAVE;
  
  -- 11. 主节点查看从节点状态
  show slave status;
  
  ```

#### bin log日志格式

- **三种日志格式**：statement、row、mixed。

  - **statement**：基于SQL语句的复制模式，每一条会修改数据的SQL都会记录在binlog中。
    - **优点**：不需要记录每一行的变化，减少了binlog日志量，**节约IO**，提高性能。
    - **缺点**：
      - 由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此，还必须记录每条语句在执行的时候的**一些相关信息**，以保证所有语句能让slave执行出**在master端执行时相同的结果**。
      - 像一些特定函数功能，slave可与master上要保持一致，则会有很多相关问题，比如sleep()， last_insert_id()，user-defined functions(udf)等，都可能会出现问题，**导致数据不一致**。
  - **row**：基于行的复制模式，不记录sql语句上下文相关信息，仅保存哪条记录被修改。
    - **优点**：**更能保证主从库数据的一致性**，因为row level的日志内容会非常清楚的记录下每一行数据修改的细节，而且不会出现某些特定情况下的存储过程、function、trigger的调用以及触发无法等无法被正确复制的问题。
    - **缺点**：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生**大量日志内容**，从而导致**从库延迟变大**。
  - **mixed**：基于SQL语句和行的混合复制模式，根据语句来选用是statement还是row模式。
    - 一般的语句修改使用statment格式保存binlog。
    - 而对于一些函数，statement无法完成主从复制的操作时，则采用row格式保存binlog。

- **应用场景**：

  - Mysql默认是使用statement日志格式，推荐使用mixed。
  - 而对于一些特殊使用，可以考虑使用row，比如自己通过binlog日志来同步数据的修改，使用row会节省很多相关操作。

- **配置方式**：

  ```sql
  -- 修改主节点的/etc/my.cnf
  -- binlog日志名称
  log_bin = mysql-bin.log
  -- binlog日志格式
  binlog_format = MIXED
  -- binlog过期时间
  expire_logs_days = 7
  -- binlog文件大小
  max_binlog_size = 100m
  
  ```

#### 主从复制模式

- **异步复制**：Asynchronous replication，MySQL默认的复制即是异步，主库在执行完客户端提交的事务后会**立即将结果返回**给给客户端，并不关心从库是否已经接收并处理。
  - **缺点**：主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时强行将从提升为主，可能导致新主上的数据不完整，从而导致数据的不一致。
- **全同步复制**：Fully synchronous replication，指当主库执行完一个事务，**所有的从库**都执行了该事务才返回给客户端。
  - **缺点**：由于需要等待所有从库执行完该事务才能返回，所以全同步复制的**性能必然会收到严重的影响**。
- **半同步复制**：Semisynchronous replication，介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待**至少一个**从库接收到并写到relay log中才返回给客户端。
  - **优点**：相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间，所以，半同步复制最好在**低延时**的网络中使用。

#### 数据一致性问题

- **原因**：
  1. **人为**：人为地在从库写入，导致从库与主库的数据不一致。
  2. **bin log格式**：使用了statement的bin log格式，某些特定函数功能在复制过程中出现问题，导致数据的不一致。
  3. **异常**：主从复制过程中，主库异常宕机了，数据还没及时同步到从库，主从切换导致的数据不一致。
  4. **延时**：主从复制有延时，如果在这个延时期间，应用程序读取从库，可能读到与主库不一致的数据。
- **解决方案**：
  1. **从库只读**：设置从库为只读模式。
  2. **row/mixed**：使用row或者mixed的复制模式。
  3. **非异步复制**：使用全同步复制，或者MySQL 5.7半同步复制。
  4. **缓存写key法**：在缓存中记录哪些行发生过写的操作，来路由到底读主库，还是读从库。
  5. **定期校验**：引入定期的主从数据校验，保证数据一致性。
- **数据强一致架构方案**：

##### SAN共享存储

![1631430708683](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430708683.png)

- **特点**：使用共享存储，MySQL服务器能够正常挂载文件系统并操作，如果主库发生宕机，备库可以挂载相同的文件系统，保证主库和备库使用相同的数据。
- **优点**：保证数据的强一致性，不会因为MySQL的逻辑错误发生数据不一致的情况。
- **缺点**：价格昂贵，且需要考虑共享存储的高可用。

##### DRBD磁盘复制

![1631430728718](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430728718.png)

- **特点**：当本地主机出现问题，远程主机上还保留着一份相同的数据，可以继续使用，保证了数据的安全。
  - DRBD是一种**基于软件、基于网络**的块复制存储解决方案，是linux内核模块实现的快级别的同步复制技术，可以与SAN达到相同的共享存储效果，主要用于对服务器之间的磁盘、分区、逻辑卷等进行数据镜像。当用户将数据写入本地磁盘时，还会将数据发送到网络中另一台主机的磁盘上，这样的本地主机(主节点)与远程主机(备节点)的数据就可以保证实时同步。
- **优点**：保证数据的强一致性，且相比于SAN储存网络，价格低廉。
- **缺点**：对io性能影响较大，且从库不提供读操作，造成服务器资源浪费。

##### 分布式协议方案 - MySQL Cluster

分布式协议可以很好解决**数据一致性**问题，比如Paxos、Raft、2PC算法等等，一系列成熟的产品如PhxSQL、MariaDB Galera Cluster、Percona XtraDB Cluster等越来越多的被大规模使用。

![1631430373534](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430373534.png)

- **特点**：MySQL Cluster是官方集群的部署方案，通过使用**NDB存储引擎**实时备份冗余数据，实现数据库的高可用性和数据一致性。
- **优点**：保证数据的强一致性，且全部使用官方组件，不依赖于第三方软件。
- **缺点**：配置较复杂，需要使用NDB储存引擎，与MySQL常规引擎存在一定差异，且**国内使用的较少**。

##### 分布式协议方案 - Galera

![1631430780963](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430780963.png)

- **特点**：基于Galera的MySQL高可用集群，是多主数据同步的MySQL集群解决方案，使用简单，没有单点故障，可用性高。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性。
  - 有自动故障转移功能，能够自动添加、剔除节点。
  - 有成熟的社区，有互联网公司在大规模的使用。
- **缺点**：需要为原生MySQL节点打wsrep补丁，且只支持InnoDB储存引擎。

##### 分布式协议方案 - PAXOS

![1631430935520](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430935520.png)

- **特点**：Paxos算法解决的问题是一个分布式系统如何就某个值（决议）达成一致，被认为是同类算法中**最有效**的，与MySQL相结合可以实现在分布式的MySQL数据的强一致性。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性；
  - 有自动故障转移功能，能够自动添加、剔除节点。
  - 也有成熟理论基础。
- **缺点**：只支持InnoDB储存引擎。

#### 高可用架构

在考虑MySQL数据库的高可用架构时，主要考虑以下方面：

- **可用性**：如果数据库发生了宕机或者意外中断等故障，能尽快恢复数据库的可用性，尽可能的减少停机时间，保证业务不会因为数据库的故障而中断。
- **数据一致性**：
  - 用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。
  - 当业务发生数据库切换时，切换前后的数据库内容应当一致，不会因为数据缺失或者数据不一致而影响业务。

常见的MySQL高可用方案有：

##### 双机高可用 | 主备

![1631430437735](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430437735.png)

- **特点**：
  1. A作为主库，负责读和写，B库作为备用库。
  2. A库故障后，B升级为主库，负责读写，A库作为备用库。
- **开发说明**：
  - 数据源配置中的数据库IP地址，采用虚拟的VIP地址，VIP由两台数据库机器上的keepalive配置，并互相检测心跳，当其中一台故障后，VIP自动漂移到另外一台正常的库上。
  - 数据库的主备配置、故障排除和数据补全，需要DBA和运维人员来维护，而程序代码或配置并不需要修改。
- **优点**：
  - 双节点，需求资源少，部署简单。
  - 架构比较简单，使用原生**半同步复制**作为数据同步的依据。
  - 保证可用性，一个机器故障了可以自动切换，没有主机宕机后的选主问题，直接切换即可。
- **缺点**：
  - 需要额外考虑haproxy、keepalived的高可用机制。
  - 完全依赖于**半同步复制**，如果半同步复制退化为异步复制，**数据一致性无法得到保证**。
    - 半同步复制机制是可靠的，如果半同步复制一直是生效的，那么便可以认为数据是一致的。
    - 但是如果由于**网络波动**等一些客观原因，导致半同步复制发生超时而切换为异步复制，那么这时便不能保证数据的一致性。
    - 所以尽可能的保证半同步复制，便可提高数据的一致性。
  - 只有一个库在工作，读写并未分离，并发有限制，且无故障时浪费服务器资源。
- **适用场景**：读和写都不高的场景（单表数据低于**500万**），双机高可用。

##### 一主一从 | 读写分离

![1631430468863](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430468863.png)

- **特点**： 
  1. A作为主库，负责写，B库作为从库，负责读。
  2. A库故障后，B负责读写。
  3. A库恢复后，B作为主库，负责写，A作为从库，负责读。
- **开发说明**：
  - 数据库的主主配置、故障排除和数据补全，依然需要DBA和运维人员来维护。
  - 而程序代码需要借助数据库中间件Mycat来实现，配置Mycat数据源，并实现对Mycat数据源的数据操作，数据库A和数据库B应该互为主从。
- **优点**：读写分离，并发有了很大的提升。
- **缺点**：
  - 完全依赖于**半同步复制**，如果半同步复制退化为异步复制，**数据一致性无法得到保证**。
  - 需要额外考虑Mycat的高可用机制，常规的解决方案是引入haproxy和keepalive对mycat做集群。
- **适合场景**：读和写都不是非常高的场景（单表数据低于**1000万**），但比方案一并发要高很多。

##### 一主多从 | 读写分离

![1631430498326](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631430498326.png)

- **特点**： 
  1. A作为主库，负责写，BCD库作为从库，负责读。
  2. A库故障后，选举B为主库，负责写，CD负责读。
  3. A库恢复后，B仍然作为主库，负责写，CD负责读，A加入从库，负责读。
- **开发说明**：
  - 主库A故障后，Mycat会自动把从B提升为写库，而C、D从库，则可以通过**MHA**等工具，自动修改其主库为B，进而实现自动切换的目地。
    - **MHA Manager**：可以单独部署在一台独立的机器上**管理多个MHA master-slave集群**，也可以部署在一台MHA slave节点上。
    - **MHA Node**：运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将**最新数据的slave**提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。
- **优点**：
  - 相比于双节点的MySQL复制，三节点/多节点的MySQL发生不可用的概率更低。
  - 由于配置了多个读节点，读并发的能力有了质的提高，理论上来说，读节点可以多个，可以负载很高级别的读并发。
  - 可扩展性较好，可以根据需要扩展MySQL的节点数量和结构。
- **缺点**：
  - 至少需要三节点，相对于双节点需要更多的资源，还有可能因为网络分区发生脑裂现象。
  - 数据一致性仍然靠原生半同步复制保证，仍然存在**数据不一致**的风险。
  - 需要额外考虑配置MHA集群保证MHA的高可用。
- **适合场景**：适合写并发不大，但是读并发大的很的场景。

##### MariaDB Galera Cluster

![1631431756775](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631431756775.png)

- **特点**：
  - 多个数据库，在负载均衡作用下，可同时进行写入和读取操作。
  - 各个库之间以Galera Replication的方法进行数据同步，即每个库理论上来说，数据是**完全一致**的。
- **开发说明**：
  - 应用程序做数据库读写时，只需要修改数据库读写IP为keepalive的虚拟节点即可。
  - 数据库配置方面相对比较复杂，需要引入haproxy、keepalive、Galaera等各种插件和配置。
- **优点**：
  - 多主写入，无延迟复制，能保证数据强一致性，可以在任意节点上进行读。
  - 有自动故障转移功能，能够自动添加、剔除节点。
- **缺点**：
  - 只支持InnoDB储存引擎，在处理事务时，会运行一个协调认证程序来保证事务的全局一致性，若该事务长时间运行，就会锁死节点中所有的相关表，导致插入卡住。
  - 整个集群的写入吞吐量是由最弱的节点限制，如果有一个节点变得缓慢，那么整个集群将是缓慢的，所以为了稳定的高性能要求，需要保证所有的节点使用统一的硬件。
  - Mysql数据库5.7.6及之后的版本才支持此种方案。
- **适合场景**：适合读写并发较大，但数据量不是非常大的场景。

##### 数据库分片 | 一主多从集群

![1631432218392](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631432218392.png)

- **特点**：
  - 采用Mycat进行分片存储，可以解决写负载均衡和**数据量过大**问题。
  - 每个分片配置多个读从库，可以减少单个库的读压力。
- **开发说明**： 配置和维护量都比较大，需要配置Haproxy、keepalive和mycat集群，每个分片上又需要配置一主多从的集群。
- **优点**：可以解决高并发高数据量的问题。
- **缺点**： 
  - 配置和维护都比较麻烦，需要的软硬件设备资源大。
  - 每个分片至少需要三节点，相对于双节点需要更多的资源，还有可能因为网络分区发生脑裂现象。
  - 数据一致性仍然靠原生半同步复制保证，仍然存在**数据不一致**的风险。
- **适用场景**：读写并发都很大，并且数据量非常大的场景。

##### 高可用架构总结

- 一些对数据**实时性要求不高**的业务场景，可以考虑使用读写分离。
  - 经验之谈，如果网络延迟在5ms以内，此时做读写分离是没有问题的，数据几乎是实时同步到读库，根本感觉不到延迟。
- 但是对数据**实时性要求比较高**的业务场景，比如订单支付状态场景，则不建议采用读写分离的方案，或者也可以在写程序时指定去写库读取数据。

### 3.7. MySQL分库分表？

- **背景**：
  - 关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到**1000W或100G**以后，由于查询维度较多，即使添加从库、优化索引，很多操作性下降严重。
  - 此时就要考虑对其进行切分了，切分的目的就在于**减少数据库的负担，缩短查询时间**。
- **概念**：
  - 数据库分库分表的核心内容是**数据切分**，以及切分后对**数据的定位和整合**。
    - **分库**：可以根据业务场景和地域分库，每个库并发量不超过2000。
    - **分表**：比如根据用户ID进行分表，每个表控制在300万数据。
  - **数据切分**：Sharding，指将数据分散存储到多个数据库中，使得单一数据库中的**数据量变小**，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。数据切分可以分为两种方式：**垂直切分**和**水平切分**。

#### 垂直切分

垂直切分，分为**垂直分库以及垂直分表**，由于垂直分表切分后，提升的只是表级性能，仍然存在单库并发瓶颈问题，所以，垂直切分一般指的是垂直分库。

##### 垂直分库

垂直分库，指根据业务耦合性，将关联度低的不同表，存储在不同的数据库中。从按照业务进行独立划分的角度来看，其做法与大系统拆分为多个小系统类似；从单独使用一个数据库的角度来看，其做法与微服务治理的做法类似。

- **优点**：
  - 解决业务系统层面的耦合，业务清晰。
  - 与微服务的治理类似，能对不同业务的数据进行分级管理、维护、监控、扩展等。
  - 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈。
- **缺点**：
  - 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度。
  - 分布式事务处理复杂。
  - 依然存在单表数据量过大的问题，此时需要水平切分。

![1631512512432](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631512512432.png)

##### 垂直分表

垂直分表，指基于数据库中的列进行切分，如果某个表字段较多，此时可以新建一张扩展表，将不经常用
的或者字段长度较大的字段，拆分到扩展表中。

- **优点**：
  - 在字段很多的情况下（比如一个大表有100多个字段），通过"大表拆小表"，更**便于开发与维护**，也能**避免MySQL跨页问题**。
    - MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。
  - 另外，数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，**减少了磁盘IO**，从而提升了数据库性能。
- **缺点**：
  - 对于应用层来说增加了开发成本，比如查询所有数据时，需要所有的表做Join操作。
  - 依然存在单库并发瓶颈问题，此时需要垂直分库。

![1631512742958](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631512742958.png)

#### 水平切分

- **背景**：当一个应用难以再细粒度的垂直切分，或切分后数据量行数仍然十分巨大，存在单库读写、存储性能瓶颈时，就需要进行水平切分了。
- **概念**：水平切分是指，根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。水平切分可以分为**库内分表**和**异库分表**。

![1631513461176](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631513461176.png)

##### 库内分表

库内分表，是指当数据库中的某张表由于数据库过大时，可以对该表按行进行拆分，由于拆分数据后的表数据量回到了正常水平，所以在一定程度上能够解决单表的性能问题。

- **特点**：
  - 虽然解决了单一表数据量过大的问题，但是并没有将表分布到不同机器的库上。
  - 而对于减轻MySQL数据库的压力来说，帮助不是很大，因为查询请求还是竞争同一个物理机的CPU、内存和网络IO，因此，水平切分最好还是通过**异库分表**来解决。

##### 异库分表

水平切分进行异库分表后，同一张表会出现在多个数据库/表中，每个库/表的内容不同，其中典型的数据分片规则为**根据数值范围**和**根据数值取模**。

- **优点**：
  - 不存在单库数据量过大、高并发的性能瓶颈，提升了系统稳定性和负载能力。
  - 应用端改造较小，不需要拆分业务模块。
- **缺点**：
  - 跨库的join关联查询性能较差。
  - 跨分片的事务一致性难以保证。
  - 数据多次扩展难度和维护量极大。

###### 根据数值范围切分

- **概念**：可以按照时间区间，或者按ID区间来切分。
  - 比如，按日期将不同月甚至是日的数据分散到不同的库中；将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。
  - 另外，某些系统中使用的**冷热数据分离**，其原理是将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。
- **优点**：
  - 单表大小可控。
  - **天然便于水平扩展**，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。
  - 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，**有效避免跨分片查询的问题**。
- **缺点**：容易出现**某分片过热**的问题，即切分后热点数据可能都落在同一分片上，成为系统性能的瓶颈。
  - 比如按时间字段分片时，有些分片存储了最近时间段内的数据，可能会被频繁的读写，为热点数据；而有些分片存储的历史数据，则很少被查询。

![1631514616880](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631514616880.png)

###### 根据数值取模切分

- **概念**：一般采用hash取模mod的切分方式。
  - 比如，将Customer表根据cusno字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。
- **优点**：分片相对比较均匀，不容易出现热点和并发访问的瓶颈。
- **缺点**：
  - 后期分片集群扩容时，需要迁移旧的数据。
    - 此时，使用**一致性hash算法**可以较好的避免这个问题。
  - 容易面临跨分片查询的复杂问题。
    - 比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。

![1631514925416](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631514925416.png)

#### 分库分表问题

##### 事务一致性问题

- **描述**：
  1. 数据切分前，一个事务处于一个数据库实例中，提交和回滚都能保持原子性。
  2. 但数据切分后，原本同一个事务的代码逻辑，可能需要被拆分成请求多个数据库实例，导致一个事务割裂成多个事务，从而失去了本来单个事务的原子性，出现事务一致性问题。
- **解决方案**：分布式事务和最终一致性。

###### 分布式事务

- **背景**：
  - 当更新内容同时分布在不同库中，不可避免地带来跨库事务问题。
  - 跨分片事务也是分布式事务，没有简单的方案，一般可使用**XA协议**和**两阶段提交**处理。
- **优点**：分布式事务能最大限度保证了数据库操作的原子性。
- **缺点**：
  - 但在提交事务时需要协调多个节点，延后了提交事务的时间点，延长了事务的执行时间，导致事务在访问共享资源时发生冲突或死锁的概率增高。
  - 随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。

###### 最终一致性

- **背景**：
  - 对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要
    在允许的时间段内达到最终一致性即可，可采用**事务补偿**的方式。
- **特点**：与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种**事后检查补救**的措施。
  - 事务补偿需要结合业务系统来考虑，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。

##### 跨节点关联查询Join问题

- **描述**：
  1. 数据切分前，系统中很多列表和详情页所需的数据可以通过SQL Join来完成。
  2. 而数据切分后，数据可能分布在不同的节点上，此时Join带来的问题就比较麻烦了，考虑到性能，应尽量避免使用Join查询。
- **解决方案**：全局表、字段冗余、数据组装以及ER分片。

###### 全局表

- 全局表，也可看做是**数据字典表**，指系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。
  - 由于这些数据通常很少会进行修改，所以也不担心一致性的问题。

###### 字段冗余

- 字段冗余，指一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。
  - 比如，订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询"买家user表"了。
- **缺点**：
  - 适用场景也有限，比较适用于依赖字段比较少的情况。
  - 而且，冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了userName后，是否需要在历史订单中同步更新呢？因此，这种方案要结合实际业务场景进行考虑。

###### 数据组装

数据组装，指在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次
请求得到关联数据，最后将获得到的数据进行字段拼装。

###### ER分片

- ER分片，指在关系型数据库中，如果可以先确定表之间的关联关系（ER关系），则可以将那些存在关联关系的表记录，按照ER关系存放在同一个分片上，这样能较好的避免跨分片join问题。
  - 在1:1或1:n的情况下，通常按照**主表的主键ID**切分。
  - 如下图，Data Node1上面的order订单表与orderdetail订单详情表，就可以通过orderId
    进行局部的关联查询了，而无需跨分片join了。同理，Data Node2上也一样。

![1631518097468](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631518097468.png)

##### 跨节点分页、排序、函数问题

- **描述**：

  - 跨节点多库进行查询时，会出现limit分页、order by排序等问题。
  - 比如，分页时需要按照指定字段进行排序：当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片。当排序字段非分片字段时，就变得比较复杂了，此时需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。
    - 如果只是取第一页的数据，对性能影响还不是很大。
    - 但是如果取得页数很大，情况则变得复杂很多，因为各分片节点中的数据可能是随机的，为了排序的准确性，需要将所有节点的前N页数据都排序好做合并，最后再进行整体的排序，这样的操作时很耗费CPU和内存资源的，所以，页数越大，系统的性能也会越差。
  - 另外，在使用Max、Min、Sum、Count之类的函数进行计算的时候，也需要先在每个分片上执行
    相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。

  ![1631520513150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631520513150.png)

- **解决方案**：全局表、缓存统计、应用内统计等。

##### 全局主键避重问题

- **描述**：
  - 在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，因为某个分区数据库自生成的ID无法保证全局唯一。
  - 因此，需要单独设计全局主键，以避免跨库主键重复问题。
- **解决方案**：UUID、MyISAM ID表、高可用ID服务器、Snowflake分布式自增ID算法。

###### UUID

UUID标准形式包含32个16进制数字，分为5段，形式为8­4­4­4­12的36个字符，例如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：UUID主键，是最简单的方案，且本地生成，性能高，没有网络耗时。
- **缺点**：
  - 由于UUID非常长，会占用大量的存储空间。
  - UUID作为主键，建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。

###### MyISAM ID表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();

```

- **概念**：
  - stub字段（存根）设置为**唯一索引**，同一stub值在sequence表中只有一条记录，可以同时为多张表生成全局ID。
  - 使用MyISAM存储引擎而不是 InnoDB，以获取更高的性能，因为MyISAM使用的是**表级锁**，对表的读写是串行的，所以不用担心在并发时两次读取同一个ID值。
  - 使用REPLACE INTO + SELECT获取自增ID，但必须保证两操作在同一事务内，其中REPLACE INTO会先删除旧数据再生成新数据，从而实现主键自增。
- **优点**：简单。
- **缺点**：
  - 存在单点问题，强依赖DB，当DB异常时，整个系统都不可用。
  - 虽然配置主从可以增加可用性，但当主库挂了，主从切换时，数据一致性在特殊情况下难以保证。
  - 另外，整个系统性能瓶颈限制在单台MySQL的读写性能上。

###### 高可用ID服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：flickr团队使用的一种主键生成策略，与上面的sequence表方案类似，但更好的解决了单点和性能瓶颈的问题。

- **思想**：

  - 建立2个以上的全局ID生成的服务器，每个服务器上只部署一个数据库，每个库有一张sequence表用于记录当前全局ID。
  - 表中ID增长的步长相同，等于库的数量，**起始值依次错开**，这样能将ID的生成散列到各个数据库上。
    - 比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...），可见ID是错开的。

- **优点**：生成ID的压力能够均匀分布在两台机器上，同时提供了系统容错，当第一台出现了错误，可以自动切换到第二台机器上获取ID。

- **缺点**：

  - 系统添加机器水平扩展时，需要停止原本正在运行的ID服务器，以修改步长。
  - 每次获取ID都要读写一次DB，DB的压力还是很大，只能靠堆机器来提升性能。

- **优化方案  **：批量获取ID。

  - 使用批量的方式降低数据库的写压力，每次获取一段区间的ID号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    1. 比如，还是使用两台DB保证可用性，数据库中只存储当前的最大ID。
    2. ID生成服务每次批量拉取6个ID，先将max_id修改为5，当应用访问ID生成服务时，就不需要访问数据库，从号段缓存中依次派发0~5的ID。
    3. 当这些ID发完后，再将max_id修改为11，下次就能派发6~11的ID。
    4. 可见，数据库的压力降低为原来的1/6。
  - **缺点**：ID生成服务需要维护最大ID值，再下次生成ID时，需要告诉DB M1、DB M2各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

###### Snowflake分布式自增ID算法

Twitter的snowflake算法，解决了分布式系统生成全局ID的需求，可以生成64位的Long型数字。

- **概念**：1 + 41 + 10 + 12  = 64位。
  - 第一位未使用。
  - 接下来41位是毫秒级时间，41位的长度可以表示**69年**的时间。
  - 5位datacenterId，5位workerId，这10位的长度最多支持部署**1024个节点**。
  - 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生**4096个ID序列**。
- **优点**：
  - 毫秒数在高位，生成的ID整体上按时间趋势**递增**。
  - 不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞。
  - 可根据自身业务灵活分配bit位。
- **缺点**：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

###### 美团点评分布式ID生成系统 - Leaf

Leaf，在美团点评公司内部服务包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在4C8G的机器上QPS能压测到近5w/s，TP999 1ms，已经能够满足大部分的业务的需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

- **Leaf-segment ID服务器方案**：

  - **思想**：
    1. 利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。
    2. 用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。
  - **实现**：
    1. biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。
       - 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。
       - 如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。
    2. 原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000，那么只有当1000个号被消耗完了之后才会去重新读写一次数据库，此时读写数据库的频率从1减小到了1/step。
    3. 比如，test_tag在第一台Leaf机器上是1~1000的号段，当这个号段用完时，会去加载另一个长度为step=1000的号段。如果另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是3001~4000，同时，数据库对应的biz_tag这条数据的max_id会从3000被更新成4000。
  - **优点**：
    - Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
    - ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
    - 容灾性高，Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
    - 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。
  - **缺点**：
    - TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，TP999数据会出现偶尔的尖刺。
    - DB宕机会造成整个系统不可用。
    - ID号码不够随机，能够泄露发号数量的信息，不太安全。

- **双buffer优化**：优化第一个缺点，当TP999号段使用完，线程取号时阻塞的问题。

  - **背景**：

    - Leaf 取号段的时机是在**号段消耗完**的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致**线程阻塞**。
    - 如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。

  - **思想**：

    - 为了让DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到**某个点时**就异步的把下一个号段加载到内存中，而不需要等到号段用尽的时候才去更新号段。

  - **实现**：

    1. 采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。
    2. 当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。
    3. 当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。

    ![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **高可用容灾**：解决第二个缺点，DB宕机会造成整个系统不可用的问题。

  - **DB高可用方案**：
    - 采用一主两从的方式，同时分机房部署，Master和Slave之间采用**半同步复制**方式同步数据。同时使用公司DBProxy（原Atlas）数据库中间件做主从切换。
    - 当然，这种方案在一些情况会退化成异步模式，甚至在**非常极端**情况下仍然会造成数据不一致的情况，但是出现的概率非常小。
    - 如果系统要保证100%的数据强一致，可以选择使用**类Paxos算法**实现的强一致MySQL方案，但是运维成本和精力都会相应的增加，应该根据实际情况进行选型。
  - **应用高可用方案**：
    - Leaf服务分IDC部署，内部的服务化框架是“MTthrift RPC”。
    - 服务调用的时候，根据负载均衡算法会优先调用同机房的Leaf服务。
    - 如果该IDC内Leaf服务不可用时，会选择其他机房的Leaf服务。
    - 同时，服务治理平台OCTO还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措施。

  ![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

- **Leaf-snowflake方案**：优化第三个缺点，ID号码不够随机，能够泄露发号数量的信息，不太安全。

  ![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

  - Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。

    - 对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置；当Leaf服务规模较大，动手配置成本太高，此时使用Zookeeper持久顺序节点的特性自动对snowflake节点**配置wokerID**。

  - Leaf-snowflake是按照下面几个步骤启动的：

    1. 启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。
    2. 如果有注册过，则直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。
    3. 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。
    4. 除了每次会去ZK拿数据以外，也会在本机文件系统上**缓存一个workerID文件**，当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对Zookeeper的**弱依赖**。一定程度上提高了SLA。

    ![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

  - **解决snowflake时钟回退问题**：由于snowflake依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。

    1. 服务启动时首先检查自己是否写过ZooKeeper leaf_forever节点，若写过，则用自身系统时间与leaf_forever/#{self}节点记录时间做比较。
    2. 若小于leaf_forever/​#{self}时间则认为机器时间发生了**大步长回拨**，服务启动失败并报警；若未写过，证明是新服务节点，直接创建持久节点leaf_forever/#{self}并写入自身系统时间。
    3. 接下来综合对比其余Leaf节点的系统时间来判断自身系统时间是否准确，具体做法是取leaf_temporary下的所有临时节点（所有运行中的Leaf-snowflake节点）的服务IP：Port。
    4. 然后通过RPC请求得到所有节点的系统时间，计算sum(time)/nodeSize。
    5. 若abs( 系统时间-sum(time)/nodeSize ) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点leaf_temporary/#{self} 维持租约；否则认为本机系统时间发生大步长偏移，启动失败并报警。
    6. 其中，leaf_temporary临时结点会每隔一段时间(3s)上报自身系统时间，并写入到leaf_forever/#{self}。

##### 数据迁移、扩容问题

当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。

- 一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。
  - 如果采用**数值范围分片**，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。
  - 如果采用的是**数值取模分片**，则考虑后期的扩容问题就相对比较麻烦。
- 此外，还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过**1000W**）。

#### 分库分表原则

能不切分尽量不要切分，不到万不得已不用轻易使用分库分表这个大招，**避免过度设计和过早优化**。

- 因为并不是所有表都需要进行切分，主要还是看数据的增长速度，切分后会在某种程度上提升业务的复杂度，数据库除了承载数据的存储和查询外，协助业务更好的实现需求也是其重要工作之一。
- 分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等，只有当数据量达到单表的瓶颈时候，才考虑分库分表。

#### 分库分表时机

##### 影响正常运维和业务访问时

数据量过大，影响到正常运维和业务访问时，需要进行分库分表，原因有：

- **备份风险高**：对数据库备份，如果单表太大，备份时需要大量的磁盘IO和网络IO，比如1T的数据，网络传输占50MB时候，需要20000秒才能传输完毕，整个过程的风险都是比较高的。
- **DDL修改锁表时间长**：对一个很大的表进行DDL修改时，MySQL会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大，在此操作过程中，都算为风险时间。此时，如果将数据表拆分，总量减少，则有助于降低这个风险。
- **访问压力高**：大表会经常访问与更新，就更有可能出现锁等待，如果将数据切分，用空间换时间，可以降低访问压力。

##### 业务快速发展，查询效益不高时

```sql
-- 项目初始阶段的user表
id                   bigint             #用户的ID 
name                 varchar            #用户的名字 
last_login_time      datetime           #最近登录时间 
personal_info        text               #私人信息 
.....                                   #其他信息字段

```

1. 在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。
2. 而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新last_login_name字段，使得user表被不断update，压力很大，而其他字段：id, name, personal_info 是不变的或很少更新的，
3. 此时，在业务角度，就需要将last_login_time拆分出去，新建一个user_time表。
4. 而由于personal_info 属性是更新和查询频率较低的，并且text字段占据了太多的空间，此时，也要垂直拆分出 user_ext 表了。

##### 数据量快速增长，性能出现瓶颈时

- 随着业务的快速发展，单表中的数据量会持续增长，当性能接近瓶颈时，就需要考虑水平切分，做分库分表了。
  - 经验数值参考，每个表控制在300万数据，每个库并发不超过2000。
- 此时，一定要选择合适的切分规则，提前预估好数据容量。

##### 出于安全性和可用性考虑时

鸡蛋不要放在一个篮子里。

- 在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。
- 利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。

#### 分库分表实现

##### MyCAT

- MyCAT，是一个开源的分布式数据库系统，是一个实现了MySQL协议的的Server，是基于**服务端代理模式**的分库分表实现。
- 前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问；而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信。
- 可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。

```xml
<!-- mycat/conf/schema.xml -->
<schema>:   表示的是在mycat中的逻辑库配置，逻辑库名称为:TESTDB
<table>:    表示在mycat中的逻辑表配置，逻辑表名称为:user,映射到两个数据库节点dataNode中,切分规则为:rule1(在rule.xml配置)
<dataNode>: 表示数据库节点,这个节点不一定是单节点，可以配置成读写分离.
<dataHost>: 真实的数据库的地址配置
<heartbeat>:用户心跳检测
<writeHost>:写库的配置
    
<!-- mycat/conf/rule.xml -->
<property name="count">2</property>: 配置有拆分了多个库(表)，需要和前面配置中的dataNode个数一致，否则会出错.
    
<!-- 至于Java应用层配置无需做任何变化，只需要连接MyCAT的逻辑库和逻辑名就好 -->

```

##### Sharding-JDBC

- Sharding-JDBC，是一个开源的分布式关系型数据库中间件，是基于**客户端代理模式**的分库分表实现。
- 可以定位为轻量级的Java框架，通过Jar包提供服务；可以理解为增强版的JDBC驱动，完全兼容各种ORM框架。

![1631587631799](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631587631799.png)

###### 配置实际数据源

```xml
<!-- 实际数据源1 -->
<bean id="ds0" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.142/sharding_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 实际从数据源1.1 -->
<bean id="slave0" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.141/sharding_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 实际数据源2 -->
<bean id="ms1" class="com.zaxxer.hikari.HikariDataSource" destroy-method="close">
    <property name="driverClassName" value="com.mysql.cj.jdbc.Driver"/>
    <property name="jdbcUrl" value="jdbc:mysql://192.168.1.143/shard_order?serverTimezone=Asia/Shanghai&amp;useSSL=false"/>
    <property name="username" value="imooc"/>
    <property name="password" value="Imooc@123456"/>
</bean>

<!-- 配置读写分离负载规则 -->
<master-slave:load-balance-algorithm id="msStrategy" type="RANDOM"/>

```

###### 配置实例分片规则

```xml
<!-- 配置Sharding JDBC数据源 以及 逻辑表与分片规则 -->
<sharding:data-source id="sharding-data-source">
    <sharding:sharding-rule data-source-names="ds0,slave0,ms1" default-data-source-name="ms0">
        <!-- 读写分离配置 -->
        <sharding:master-slave-rules>
            <sharding:master-slave-rule id="ms0" master-data-source-name="ds0" slave-data-source-names="slave0" strategy-ref="msStrategy"/>
        </sharding:master-slave-rules>

        <!-- 配置普通分片表 -->
        <sharding:table-rules>
            <sharding:table-rule logic-table="t_order" actual-data-nodes="ms$->{0..1}.t_order_$->{1..2}"
                                 database-strategy-ref="databaseStrategy" table-strategy-ref="tableStrategy" key-generator-ref="snowflake"/>

            <!-- 配置绑定表的分片表 -->
            <sharding:table-rule logic-table="t_order_item" actual-data-nodes="ms$->{0..1}.t_order_item_$->{1..2}"
                                 database-strategy-ref="databaseStrategy" table-strategy-ref="tableOrderItemStrategy" key-generator-ref="snowflake"/>
        </sharding:table-rules>

        <!-- 配置广播表(全局表) -->
        <sharding:broadcast-table-rules>
            <sharding:broadcast-table-rule table="area"/>
        </sharding:broadcast-table-rules>

        <!-- 配置绑定表(子表): 4.0.0-RC2版本会抛出空指针bug: 原因是源码中先创建了绑定表规则然后才是获取广播表 -->
        <sharding:binding-table-rules>
            <sharding:binding-table-rule logic-tables="t_order,t_order_item"/>
        </sharding:binding-table-rules>
    </sharding:sharding-rule>
</sharding:data-source>

```

###### 配置散列规则

```xml
<!-- 数据库分片规则: 根据user_id取模 -->
<sharding:inline-strategy id="databaseStrategy" sharding-column="user_id" algorithm-expression="ms$->{user_id % 2}"/>

```

###### 配置主键ID生成规则

```xml
<!-- 配置主键Key生成规则 -->
<!--<sharding:key-generator id="uuid" column="order_id" type="UUID"/>-->
<sharding:key-generator id="snowflake" column="order_id" type="SNOWFLAKE" props-ref="snow"/>
<bean:properties id="snow">
    <!-- DataCenterId + MachineId => 10bit -->
    <prop key="worker.id">678</prop>
    <!-- 最大容忍回调时间 -->
    <prop key="max.tolerate.time.difference.milliseconds">10</prop>
</bean:properties>

```

##### 总结

|      | MyCAT                                          | Sharding-JDBC                                            |
| ---- | ---------------------------------------------- | -------------------------------------------------------- |
| 区别 | 是服务端代理；不支持库内分表，只支持分异库分表 | 是客户端代理；既支持库内分表，也支持异库分表             |
| 优点 | 对于各个项目透明，应用层无需关心               | 不用部署，运维成本低；不需要服务代理层的二次转发，性能高 |
| 缺点 | 需要部署，运维成本高                           | 各个系统耦合Sharding-JDBC，给以后升级带来麻烦            |

#### 分库分表案例

比如，用户中心，是一个非常常见的业务，主要提供用户注册、登录、查询/修改等功能，其核心表为用户表。

```sql
-- 用户表
User(uid, login_name, passwd, sex, age, nickname)

```

1. 任何脱离业务的架构设计都是耍流氓，在进行分库分表前，需要对**业务场景**需求进行梳理：

   - **用户侧**：前台访问，访问量较大，需要保证高可用和高一致性。主要有两类需求：
     - **用户登录**：通过login_name/phone/email查询用户信息，1%请求属于这种类型。
     - **用户信息查询**：登录之后，通过uid来查询用户信息，99%请求属这种类型。
   - **运营侧**：后台访问，支持运营需求，按照年龄、性别、登陆时间、注册时间等进行分页的查询，是内部系统，访问量较低，对可用性、一致性的要求不高。

2. 水平切分方法，当数据量越来越大时，需要对数据库进行水平切分，切分方法有**根据数值范围**和**根据数值取模**：

   - **根据数值范围**：以主键uid为划分依据，按uid的范围将数据水平切分到多个数据库上。
     - **例如**：user­db1存储uid范围为0~1000w的数据，user­db2存储uid范围为1000w~2000w uid数据。
     - **优点**：扩容简单，如果容量不够，只要增加新db即可。
     - **缺点**：请求量不均匀，一般新注册的用户活跃度会比较高，所以新的user­ db2会比user­ db1负载高，导致**服务器利用率不平衡**。
   - **根据数值取模**：也是以主键uid为划分依据，按uid取模的值将数据水平切分到多个数据库上。
     - **例如**：user­ db1存储uid取模得1的数据，user­ db2存储uid取模得0的uid数据。
     - **优点**：数据量和请求量分布均均匀。
     - **不足**：扩容麻烦，当容量不够时，新增加db，需要rehash，同时需要考虑对数据进行平滑的迁移。

3. 水平切分后，对于按uid查询的需求能很好的满足，可以直接路由到具体数据库，但对于按**非uid**的查询，例如login_name，就不知道具体该访问哪个库了，此时需要**遍历所有库**，性能会降低很多。

   - **用户侧解决方案**：可以采用**建立非uid属性到uid的映射关系**的方案。

     - **非uid需求**：主要需求以单行查询为主，需要建立login_name/phone/email到uid的映射关系，可以解决这些字段的查询问题。

     - **映射关系**：

       1. 比如，login_name不能直接定位到数据库，可以建立**login_name→uid**的映射关系，用索引表或缓存来存储。
       2. 当访问login_name时，先通过映射表查询出login_name对应的uid，再通过uid定位到具体的库。
       3. 由于映射表只有两列，因此可以承载很多数据，当数据量过大时，还可以对映射表再做水平切分。同时，这类kv格式的索引结构，可以很好的使用cache来优化查询性能，而且映射关系不会频繁变更，缓存命中率会很高。

     - **分库基因优化**：上面的映射关系的方法需要额外存储映射表，按非uid字段查询时，还需要多一次数据库或cache的访问。

       ![1631583587908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631583587908.png)

       1. 假如通过uid分库，分为8个库，采用uid%8的方式进行路由，此时是由uid的最后3bit来决定这行User数据具体落到哪个库上，那么这3bit可以看为分**库基因**。
       2. 如果想要消除多余的存储和查询，可以通过**f函数取login_name的基因作为uid的分库基因**。
       3. 而生成uid可以参考分布式唯一ID的生成方案，来生成61big的全局唯一ID，再加上最后3位bit值=f(login_name)当做分库基金。
       4. 这样，当查询login_name时，只需计算f(login_name)%8的值，就可以定位到具体的库。
       5. 不过这样需要提前做好容量规划，预估未来几年的数据量需要分多少库，要预留一定bit的分库基因。

   - **运营侧解决方案**：可以采用**前台与后台分离**的方案。

     - **非uid需求**：很多批量分页且条件多样的查询，这类查询计算量大，返回数据量大，对数据库的性能消耗较高。此时，如果和用户侧公用同一批服务或数据库，可能因为后台的少量请求，占用大量数据库资源，而导致用户侧访问性能降低或超时。
     - **前台与后台分离**：
       1. 运营侧后台业务抽取**独立的service和db**，解决和前台业务系统的耦合。
       2. 由于运营侧对可用性、一致性的要求不高，可以不访问实时库，而是通过binlog异步同步数据到**运营库**进行访问。
       3. 另外，在数据量很大的情况下，还可以使用**ES搜索引擎或Hive**来满足后台复杂的查询方式。

#### 老数据迁移

双写（新老写库）不中断迁移：

1. 线上系统里所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改（**双写**）。
2. 系统部署以后，还需要跑程序**读老库数据写新库**，写的时候需要判断updateTime。
3. 循环执行，直至两个库的数据完全一致，最后重新部署分库分表的代码即可。

#### 系统性能评估与扩容

- **场景**：和家亲目前有1亿用户：场景 10万写并发，100万读并发，60亿数据量。
- **设计思路**：考虑极限情况，32库*32表~64个表，一共1000 ~ 2000张表。
  - 支持**3万**的写并发，配合MQ可以实现每秒**10万**的写入速度。
  - 读写分离**6万**读并发，配合分布式缓存可以实现每秒**100万**读并发。
  - 2000张表每张**300万**，可以最多写入**60亿**的数据。
  - 64张用户表，支撑**亿级**用户，后续最多也就扩容一次。
- **动态扩容步骤**：
  1. 推荐是32 库 * 32 表，对于我们公司来说，可能几年都够了。
  2. 配置路由的规则，uid % 32 = 库，uid / 32 % 32 = 表。
  3. 扩容的时候，申请增加更多的数据库服务器，呈倍数扩容。
  4. 由 DBA 负责将原先数据库服务器的库，迁移到新的数据库服务器上去。
  5. 修改一下配置，重新发布系统，上线，原先的路由规则变都不用变。
  6. 直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

### 3.8. 线上故障及优化？

#### 更新失败 | 主从同步延时

1. 以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。
2. 是这个么场景，有个同学是这样写代码逻辑的：先插入一条数据，再把它查出来，然后更新这条数据。
3. 在生产环境高峰期，写并发达到了 2000/s，这个时候，**主从复制延时**大概是在小几十毫秒，此时，线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。
4. 接着用户跟客服反馈，而客服就会反馈给我们。
5. 我们通过 MySQL 命令：`show slave status`，查看 `Seconds_Behind_Master` ，可以看到从库复制主库的数据落后了几 ms。一般来说，如果主从延迟较为严重，有以下解决方案：
   - **分库**：拆分为多个主库，每个主库的写并发就减少了几倍，主从延迟可以忽略不计。
   - **重写代码**：由于插入数据时立马查询可能查不到，如果确实需要立马要求就查询到，可以对这个查询**设置直连主库**或者**延迟查询**（主从复制延迟一般不会超过50ms）。

#### **应用崩溃 | 分库分表优化**

1. 我们有一个线上通行记录的表，由于数据量过大，进行了分库分表，当时分库分表初期经常产生一些问题。典型的就是通行记录查询中使用了深分页，通过一些工具如MAT、Jstack追踪到，是由于sharding-jdbc内部引用造成的。
2. 通行记录数据被存放在两个库中，如果没有提供**切分键**，查询语句就会被分发到所有的数据库中，比如查询语句是 limit 10、offset 1000，最终结果只需要返回 10 条记录，但是数据库中间件要完成这种计算，则需要 （1000+10）* 2 = 2020条记录来完成这个计算过程。
3. 如果 offset 的值过大，使用的内存就会暴涨，虽然sharding-jdbc使用归并算法进行了一些优化，但在实际场景中，深分页仍然引起了**内存和性能**问题。
4. 这种在中间节点进行**归并聚合**的操作，在分布式框架中非常常见，比如，在ElasticSearch中，就存在相似的数据获取逻辑，**不加限制的深分页**，同样会造成ES的内存问题。
5. **业界解决方案**：
   - **方法一 - 全局视野法**：
     - 将order by time offset X limit Y，改写成order by time offset 0 limit X + Y，直接返回X + Y条数据，然后服务层对得到的N *（X + Y）条数据后，N为数据库实例的数量，再在服务层进行内存排序，内存排序后再取偏移量X后的Y条记录。
     - **缺点**：随着翻页的进行，性能会越来越低。
   - **方法二 - 业务折衷法-禁止跳页查询**：
     - 用正常的方法取得第一页数据，并得到第一页记录的time_max，然后每次翻页，将order by time offset X limit Y，改写成order by time where time > #time_max limit Y以保证每次只返回一页数据。
     - **优点**：性能为常量。
     - **缺点**：由于每次记录上一页的time_max，所以不能跳页查询。
   - **方法三 - 业务折衷法-允许模糊数据**：将order by time offset X limit Y，改写成order by time offset X/N limit Y/N，N为数据库实例的数量，这样视所有数据库实例为一个整体，每个实例平均查询X/N偏移，Y/N数据量，汇总后可以达到X偏移量以及Y数据量。
     - **优点**：由于每个数据库实例平摊掉成本，所以查询性能较好。
     - **缺点**：由于每个数据库实例查询的都是平均偏移量和平均数据量，可能并不是真实想要的数据，所以需要业务允许这样模糊查询。

#### 查询异常 | SQL 调优

1. 分库分表前，有一段用用户名来查询某个用户的 SQL 语句：select * from user where name = "xxx" and community="other";
2. 为了达到动态拼接的效果，这句SQL语句被一位同事进行了如下修改select * from user where 1=1，他的本意是，当name 或者community 传入为空的时候，动态去掉这些查询条件，这种写法在 MyBaits 的配置文件中，也非常常见，在大多数情况下，这种写法是没有问题的，因为结果集合是可以控制的。
3. 但随着系统的运行，用户表的记录越来越多，当传入的 name 和 community 全部为空时，悲剧的事情发生了：数据库中的所有记录，都会被查询出来，载入到 JVM 的内存中。由于数据库记录实在太多，直接把内存给撑爆了。
4. 由于这种原因引起的内存溢出，发生的频率非常高，比如导入Excel文件时，通常的解决方式是**强行加入分页功能**，或者对一些**必填的参数进行校验**：
   - **Controller层优化**：
     - 现在很多项目都采用前后端分离架构，所以 Controller 层的方法，一般使用@ResponseBody 注解，把查询的结果，解析成 JSON 数据返回。这在数据集非常大的情况下，会**占用很多内存资源**。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用20M或者更多的内存。
     - 因此，**保持结果集的精简**，是非常有必要的，这也是 DTO（Data Transfer Object）存在的必要，互联网环境不怕小结果集的高并发请求，却非常恐惧大结果集的耗时请求，这是其中一方面的原因。
   - **Service层优化**：
     - Service 层用于处理具体的业务，更加贴合业务的功能需求，一个 Service可能会被多个 Controller 层所使用，也可能会使用多个dao结构的查询结果进行计算、拼装。
     - 比如List< User > users = dao.getAllUser();会导致全询user表全部的数据，在数据量达到一定程度后，才会暴露问题。
   - **ORM层优化**：
     - 比如使用Mybatis时，有一个批量导入服务，在 MyBatis 执行**批量插入**的时候，竟然产生了内存溢出，按道理这种插入操作是不会引起额外内存占用的，最后通过源码追踪到了问题。
     - 这是因为 MyBatis 循环处理batch的时候，操作对象是数组，而我们在接口定义的时候，使用的是 List；当传入一个非常大的 List 时，它需要调用 List 的 toArray 方法将列表转换成数组（浅拷贝）；在最后的拼装阶段，又使用了**StringBuilder**来拼接最终的 SQL，所以实际使用的内存要比 List 多很多。
     - 事实证明，不论是插入操作还是查询动作，只要涉及的数据集非常大，就容易出现问题，由于项目中众多框架的引入，想要分析这些具体的内存占用，就变得非常困难。因此，**保持小批量操作和结果集的干净**，是一个非常好的习惯。

# 五、Redis篇

### 1.1. 缓存原理与分类？

#### 概念

通过开辟一个新的数据交换缓冲区，来解决**原始数据获取代价太大**的问题，以让数据得到更快的访问。

- **狭义缓存**：缓存最初的含义，是指用于**加速 CPU 数据交换**的 RAM，即随机存取存储器，通常这种存储器使用更昂贵。
- **广义缓存**：其定义则更宽泛，任何用于**数据高速交换**的存储介质都可以是缓存，可以是硬件也可以是软件。

#### 原理

通过利用**时间局限性原理**，通过**空间换时间**来达到加速数据获取的目的。

1. **时间局限性原理**：被获取过一次的数据，在未来也可能会被多次引用。
   - 比如一条微博被一个人感兴趣并阅读后，它大概率还会被更多人阅读，当然如果变成热门微博后，会被数以百万/千万计算的更多用户查看。
2. **以空间换时间**：因为原始数据获取太慢，所以开辟了一块高速独立空间，提供高效访问，从而达到数据获取加速的目的。

#### 优势

1. **提升访问速度**：缓存存储了 DB 关键数据，数据存在缓存时，无需从 DB 获取，大大提升了访问速度。
   - 一般来讲，服务系统的全量原始数据存储在 DB 中（如 MySQL、HBase 等），所有数据的读写都可以通过 DB 操作来获取。
   - 但 DB 读写性能低、延迟高，如 MySQL 单实例的读写 QPS 通常只有千级别（线上可以到 **3000～6000**），读写平均耗时 **10～100ms** 级别，如果一个用户请求需要查 20 个不同的数据来聚合，仅仅 DB 请求就需要数百毫秒甚至数秒。
   - 而缓存读写性能高的特点，正好可以弥补 DB 的不足，比如 Memcached 的读写 QPS 可以达到 **10～100 万**级别，读写平均耗时在 **1ms** 以下，Redis 读写 QPS 也可以达到 **10万** 级别，结合并发访问技术，单个请求即便查上百条数据，也可以轻松应对。
2. **降低网络拥堵**：由于减少了频繁访问数据库的网络流量，降低了网络拥堵。
3. **减轻服务负载**：由于减少了解析和计算，调用方和存储服务的负载也可以大幅降低。
4. **增强可扩展性**：缓存的读写性能很高，预热快，在数据访问存在性能瓶颈或遇到突发流量，系统读写压力大增时，可以快速部署上线，同时在流量稳定后，也可以随时下线，从而使系统的可扩展性大大增强。

#### 代价

1. **增加了系统复杂度**：服务系统中引入缓存，会增加系统的复杂度。

2. **存在数据不一致**：由于一份数据同时存在缓存和 DB 中，甚至缓存内部也会有多个数据副本，多份数据就会存在一致性问题，同时，缓存体系本身也会存在可用性问题和分区的问题。

3. **缓存容量小**：只能存储部分访问频繁的热数据。

4. **部署成本比 DB 高**：由于缓存相比原始 DB 存储的成本更高，所以系统部署及运行的费用也会更高。

   - 由于缓存空间的成本较高，在实际设计架构中，还要考虑访问**读写延迟和成本**的权衡问题。

     - 系统的访问性能越高越好，访问延迟越低小越好，但要维持相同数据规模的存储及访问，性能越高延迟越小，成本也会越高，所以，在系统架构设计时，需要在系统性能和开发运行成本之间做取舍。
     - 比如相同成本的容量，SSD 硬盘容量会比内存大 10～30 倍以上，但读写延迟却高 50～100 倍。

     ![1631789780363](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631789780363.png)

#### 分类

##### 按宿主层次分类

- **浏览器缓存**：指客户端把服务器请求或响应资源缓存在本地，以加速用户访问，提升单个用户的体验。
  - **浏览器本地内存缓存：**专题活动，一旦上线，在活动期间是不会随意变更的。
  - **浏览器本地磁盘缓存：**Logo缓存，大图片懒加载。
- **CDN缓存**：CDN，Content Delivery Network，即内容分发网络，而CDN缓存指的是，CDN边缘节点将数据缓存起来，使得用户能够**就近获取**所需内容，降低网络拥塞，提高用户访问响应速度和命中率。
- **反向代理缓存**：比如Nginx缓存，可以提升访问上游服务器的速度。
- **本地缓存**：指服务器把数据缓存到本地，性能非常高，但会占用堆内存，影响垃圾回收、影响系统性能，且由于由于没有被持久化，重启后必定会被穿透。
  - 为什么不使用服务器本地磁盘做缓存？是因为当系统处理大量磁盘 I/O 操作的时候，由于 CPU 和内存的速度远高于磁盘，可能导致 CPU 耗费太多时间，来等待磁盘返回处理的结果，对于这部分 CPU 在 I/O 上的开销，称为 **I/O Wait**。
- **分布式缓存**：跨服务器建立通用的缓存系统，可以减轻数据库压力、提升响应速度和分布式处理数据。
  - 比如 Redis 等，针对穿透的情况，可以继续做缓存分层，必须保证数据库不被压垮。

##### 按存储介质分类

- **内存型缓存**：将数据存储在内存，读写性能很高，但缓存系统重启或 Crash 后，内存数据会丢失。
- **可持久化型缓存**：将数据存储到硬盘中，在相同成本下，这种缓存的容量会比内存型缓存大 1 个数量级以上，而且数据会持久化落地，重启不丢失，但读写性能相对低 1～2 个数量级。
  - 比如 Memcached 就是典型的内存型缓存，而 Redis 则属于可持久化型缓存。

### 1.2. 为什么使用Redis？

Redis，是开源的，数据结构存储于内存中，被用来作为数据库，缓存和消息代理。

- 支持多种数据结构，例如字符串（string）、哈希（hash）、列表（list）、集合（set）、带范围查询的排序集合（zset）、位图（bitmap）、hyperloglog、带有半径查询和流的地理空间索引。
- 具有内置的复制、Lua脚本、LRU逐出、事务和不同级别的磁盘持久性。
- 通过Redis Sentinel和Redis Cluster自动分区提供高可用性。

#### 读写速度快（Redis为什么这么快？）

1. **完全基于内存操作**：数据存在内存中，机器访问内存的速度远远大于访问磁盘的速度。

2. **采用单线程架构**：避免了多线程不必要的上下文切换和竞争条件，不存在加锁释放锁操作，减少了因为锁竞争导致的性能消耗。

   - **线程上下文切换场景**：

     - **抢占式**：一般跟锁竞争有关，可以减少锁争用，来减少线程上下文切换。
     - **时间片轮转**：一般跟时间片有关，可以减少线程数，来减少线程上下文切换。

   - **Redis 6.0版本支持多线程**：仍然使用单线程处理命令，但是读写网络数据使和协议解析使用了多线程。

     - **背景**：从 Redis 自身角度来说，因为读写网络的 Read/Write 系统调用占用了 Redis 执行期间大部分 CPU 时间，瓶颈主要在于**网络的 IO 消耗**。

     - **目的**：支持多线程可以充分利用服务器 CPU 资源，分摊 Redis 同步 IO 读写负荷。

     - **使用**：默认关闭，可以在 `io-threads-do-reads` 配置中打开，建议线程数一定要小于CPU核数。

     - **效果**：不严谨测试结论为，对比单线程性能提升**翻倍**。

     - **实现机制**：IO 线程只负责读写 Socket 解析命令，不负责命令处理，而是把命令交给主线程执行。

       1. 主线程负责接收建立连接请求，获取 Socket 放入到全局等待读处理队列。
       2. 主线程处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。
       3. 主线程阻塞，等待 IO 线程读取 Socket 完毕。
       4. 主线程通过单线程的方式，执行请求命令，请求数据读取并解析完成，但并不回写。
       5. 主线程阻塞，等待 IO 线程将数据回写 Socket 完毕。
       6. 解除绑定，清空等待队列。

       => 可以看到，Redis 6.0 多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行，因此无需去考虑控制 Key、Lua、事务、LPUSH/LPOP 等等的并发线程安全问题。

       ![1632104148793](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632104148793.png)

3. **使用I/O多路复用模型**：

   - **I/O交互方式**：
     - **BIO**：同步阻塞，早期传统的阻塞模型，一个连接对应一个线程，开销非常大。
     - **NIO**：同步非阻塞，在一个连接被创建时，Kernel会创建一个socket文件描述符fd，并提供非阻塞的select、poll、epoll多路复用器。
       - **select**：每次都会返回所有的fd，需要用户程序遍历全部的fd，然后找到有数据的fd进行读写，效率较低，最多只能监听1024个连接。
       - **poll**：实现和select基本一样，不过poll突破了1024个连接的监听限制。
       - **epoll**：epoll会返回有读写状态的fd，不再需要用户程序去全量遍历查找，epoll_create创建socket文件描述符fd，epoll_ctl注册事件，epoll_wait等待事件的fd。
     - **AIO**：异步非阻塞，无需一个线程去轮询所有I/O操作的状态改变，在I/O状态发生改变后，操作系统会通知对应的线程来处理。
   - **多路复用执行过程**：文件事件处理器是单线程的，采用多路复用的方式，来监听系统上多个socket，将socket上产生的事件压入队列中，由文件事件分派器从队列中取出一个socket，并根据事件类型发给相应的事件处理器。
     1. 客户端发起请求，向redis的server socket请求连接，这里命名为socket01。
     2. server socket产生一个**AE_READABLE事件**，IO多路复用程序监听到事件后，将这个socket01压入队列。
     3. 文件事件分派器从队列中取出socket01，交给连接应答处理器，连接应答处理器会将socket01的AE_READABLE事件与命令请求处理器相关联，然后压入队列中。
     4. 客户端执行set操作，此时命令请求处理器会从socket01读取key value，并在内存中完成key value的设置，接着在内存中完成设置后，会将socket01的**AE_WRITEABLE事件**与命令回复处理器相关联，然后压入队列中。
     5. 事件分派器拿到socket01后，交给命令回复处理器，由命令回复处理器向socket01写入本次操作的结果，比如OK，之后解除事件关联。

   ![1631793891157](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631793891157.png)

4. **基于C语言开发**：直接跟操作系统交互，命令执行飞快。

5. **使用专门设计的数据结构**：对string、list、set、zset、hash都专门设计了数据结构，使得某些操作的性能有所提升，比如获取string的长度，使用sds的时间复杂度为O（1），而c字符串的为O（n）。

#### 数据结构丰富

Redis不仅仅支持简单的key-value类型的数据结构，同时还提供了list，set，zset，hash等数据结构。

#### 支持持久化

Redis提供了RDB和AOF两种持久化策略，能最大限度地保证Redis服务器宕机重启后数据不会丢失。

#### 支持高可用

Redis可以使用主从模式、哨兵模式以及集群模式，来保证服务器的高可用。

#### 客户端语言多

由于Redis受到社区和各大公司的广泛认可，所以客户端语言涵盖了所有的主流编程语言，比如Java，C，C++，PHP，NodeJS等等。

#### 竞品对比

| 产品               | 优点                                                        | 缺点                                                         | 持久化        | 高可用               | 使用场景                                 |
| ------------------ | ----------------------------------------------------------- | ------------------------------------------------------------ | ------------- | -------------------- | ---------------------------------------- |
| Redis              | 单线程、支持K-V以及多种数据结构存储、支持持久化，适合热数据 | 容量受内存限制，不便于海量数据读写，不适合冷数据             | RDB、AOF      | 主从、哨兵、集群     | 缓存、最新回复、点赞数、共同好友、排行榜 |
| Memcahe            | 多线程、性能高、速度快，用于减轻数据库负载                  | 不支持持久化、只能存储K-V数据                                | 不支持        | 集群没有同步复制机制 | 前端缓存、用户信息、好友信息、文章信息   |
| Tair               | 淘宝开源，多线程、支持K-V以及多种数据结构存储、支持持久化   | -                                                            | MDB、RDB、LDB | 集群可以灵活配置     | 适合作为大数据量缓存                     |
| EvCache            | Netflix基于Memcached 实现的缓存方案，性能很高               | -                                                            | 支持          | 支持                 | 适合对强一致性没有必须要求的场合         |
| Google Guava Cache | 本地缓存，性能非常高                                        | 会占用堆内存，影响垃圾回收、影响系统性能；每台JVM都有自己的本地缓存，没有分布式一致性可言 | -             | -                    | 本地缓存                                 |

##### Memcache

Memcache，是一个高性能的分布式内存对象缓存系统，通过在内存里维护一个统一的**巨大的hash表**，用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等，数据存储在内存中，然后直接从内存中读取，从而大大提高读取速度。

- **使用场景**：
  1. 如果有持久方面的需求，或对数据类型和处理有要求的，应该选择redis。 
  2. 如果简单的key-value存储的，应该选择memcached。	

| redis                                 | Memcached                    |
| ------------------------------------- | ---------------------------- |
| 内存高速数据库                        | 高性能、分布式内存缓存数据库 |
| 支持hash、list、set、zset、string结构 | 只支持key-value结构          |
| 将大部分数据放到内存                  | 全部数据放到内存中           |
| 支持持久化、主从复制备份              | 不支持数据持久化及数据备份   |
| 数据丢失可通过AOF恢复                 | 挂掉后，数据不可恢复         |
| 单线程（2~4万TPS）                    | 多线程（20-40万TPS）         |

##### Tair

Tair，Taobao Pair，是淘宝开发的分布式Key-Value存储引擎，默认支持基于内存和文件的两种存储方式，分别与缓存和持久化存储对应，既可以做缓存，也可以做数据源。

- **三种引擎切换**：
  - **MDB**：基于Memcache，，属于内存型产品，支持KV和类HashMap结构，性能最优，不支持持久化存储。
  - **RDB**：基于Redis，支持List、Set、Zset等复杂的数据结构，性能次之，可提供缓存以及持久化存储两种模式。
  - **LDB**： 基于Google LevelDB，属于持久化产品，支持KV和类Hashmap结构，性能稍低，但持久化可靠性最高。
- **痛点**：在Redis集群中，如果程序想借用缓存资源，则必须得指明redis服务器地址去获取，增加了程序维护的复杂度，因为Redis服务器很可能是频繁变动的。
  - **中心化管理**：Tair使用中心节点代理缓存集群，借用Tair资源的程序只需要跟该中心节点交互，无需频繁更改服务器地址。同时，Tair还有服务器配置的功能，使得在改集群配置文件时，不需要一个个机器地去修改。

##### EVCache

EVCache，Ephemeral Volatile Cache，短暂易失缓存，是一个Netflflix开源的，基于Memcached实现的分布式缓存，用以构建超大容量、高性能、低延时、跨区域全球可用的缓存数据层，适合对**强一致性没有必须要求**的场合。

- **特性**：分布式键值存储、AWS跨域复制存储数据、注册和自动发现新节点或者新服务。

##### Google Guava Cache

- **Google Guva**：是google开源的一个公共java库，类似于Apache Commons，它提供了集合，反射，缓存，科学计算，xml，io等一些工具类库，而cache只是其中的一个模块，使用Guva cache能够方便快速的构建本地缓存。
- **Google Guava Cache**：是一种非常优秀本地缓存解决方案，提供了基于容量，时间和引用的缓存回收方式。
  - 缓存核心类LocalCache里面的内部类Segment，与jdk1.7及以前的ConcurrentHashMap非常相似，都继承于ReetrantLock，还有六个队列，以实现丰富的本地缓存方案。
- **优点**：
  - 作用在LocalCache上，相对于IO操作速度快，性能非常高效。
  - 对于Redis等分布式缓存，它们受限于网络IO、吞吐率以及缓存的数据大小等原因，远水救不了近火，而DB + Redis + LocalCache可以实现高效存储、高效访问。
- **缺点**：
  - 会占用堆内存，影响垃圾回收、影响系统性能。
  - 对于缓存一致性方面，每台JVM都有自己的本地缓存，没有分布式一致性可言；而使用分布式缓存则更好一点，因为集群环境下的节点都使用同一份缓存。
- **使用场景**：
  - 对性能有非常高的要求时。
  - 缓存数据需要不经常变化，且占用内存不能太大时。
  - 整个集合都需要被访问时。
  - 数据允许不实时一致时。
- **使用方法**：

```java
// 5. 构造LocalCache
private final LoadingCache<String,List<SysDictItem>> vendorDictItemCache = CacheBuilder.newBuilder()
    // 1. 设置缓存容量
    .maximumSize(1000)
    // 2. 设置超时时间
    .expireAfterWrite(10, TimeUnit.SECONDS)
    // 3. 设置缓存Key失效监听器
    .removalListener((RemovalListener<String, List<SysDictItem>>) notification -> {
        LOGGER.warn(notification.getKey() + "缓存已失效, 失效原因为: " + notification.getCause().name());
    })
    // 4. 提供缓存加载器 -> 缓存不存在时，会去查找数据库来设置缓存
    .build(new CacheLoader<String, List<SysDictItem>>() {
        @Override
        public List<SysDictItem> load(String code) {
            return getDictItemsByCodeAndTypeInDB(code);
        }
    });

// 6. 获取缓存
sysDictItems = vendorDictItemCache.get(dictCode);
```

- **自己设计本地缓存痛点：**
  - **并发处理能力差**：针对并发可以使用CurrentHashMap，但缓存的其他功能需要自行实现。
  - **缓存处理**：需要根据一定的规则进行淘汰数据，比如LRU、LFU、FIFO等，缓存加载和刷新都需要手工实现。
  - **回调通知实现**：清除数据时，需要触发回调通知，同样需要自己实现。
- **使用Google Guava Cache的优势**：
  - **并发处理能力**：
    - Google  Guava Cache类似CurrentHashMap，是线程安全的，提供了设置并发级别的API，使得缓存支持并发的写入和读取，采用分段锁机制，以减小锁力度，提升并发能力。
  - **缓存过期和淘汰机制**：在Google  Guava Cache中，可以设置Key的过期时间，包括访问过期和创建过期，会在缓存容量达到指定大小时，采用LRU的方式，将不常使用的键值从缓存中删除。
  - **防止缓存击穿**： Google  Guava Cache可以在CacheLoader#load方法中加以控制，对同一个key，只让一个请求去读源数据并回填缓存，其他请求阻塞等待，相当于集成了数据源，方便用户使用。
  - **监控统计能力**：另外，还提供了缓存加载以及命中情况统计信息的API。

##### 总结

| 对比               | Redis优势                             |
| ------------------ | ------------------------------------- |
| Memcache           | Redis支持多种数据结构存储、支持持久化 |
| Tair               | 业务量不大时，Redis简单高效、实用性好 |
| EvCache            | Redis社区活跃、使用最多               |
| Google Guava Cache | Redis缓存统一存储，分布式一致性好点   |

### 1.3. Redis数据类型与底层实现？

Redis，是一个Key-Value型的内存数据库，它所有的key都是字符串，而value常见的数据类型有五种：**String、Hash、List、Set、Zset**。

![1631850908728](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631850908728.png)

#### 基本类型API总结

http://redisdoc.com/、https://redis.io/topics/streams-intro

| String                    | Hash                  | List                     | Set                 | Zset                                    | Stream（5.0版本）        |
| ------------------------- | --------------------- | ------------------------ | ------------------- | --------------------------------------- | ------------------------ |
| SET、GET、GETSET          | HSET、HSETNX          | LPUSH、LPUSHHX、LPOP     | SADD                | ZADD                                    | XADD                     |
| SETNX、SETEX、PSETEX      | HGET、HGETALL         | RPUSH、RPUSHX、RPOP      | SISMEMBER           | ZINCRBY、ZSCORE                         | XLEN                     |
| APPEND                    | HEXSITS               | RPOPLPUSH                | SPOP、SRANDMEMBER   | ZCARD、ZCOUNT                           | XRANGE、XREVRANGE        |
| STRLEN                    | HDEL                  | LREM、LINSERT            | SREM、SMOVE         | ZRANGE、ZREVRANGE                       | XREAD、XREAD BLOCK       |
| SETRANGE、GETRANGE        | HLEN                  | LINDEX、LSET             | SCARD               | ZRANGEBYSCORE、ZREVRANGEBYSCORE         | XGROUP、XREADGROUP、XACK |
| INCR、INCRBY、INCRBYFLOAT | HSTRLEN               | LRANGE、LTRIM            | SMEMBERS            | ZRANK、ZREVRANK                         | XPENDING                 |
| DECR、DECBY               | HINCRBY、HINCRBYFLOAT | BLPOP、BRPOP、BRPOPLPUSH | SINTER、SINTERSTORE | ZREM、ZREMRANGEBYRANK、ZREMRANGEBYSCORE | XCLAIM、XAUTOCLAIM       |
| MSET、MSETNX、MGET        | HMSET、HMGET          |                          | SUNION、SUNIONSTORE | ZRANGEBYLEX、ZLEXCOUNT、ZREMRANGEBYLEX  | XINFO                    |
|                           | HKEYS、HVALS          |                          | SDIFF、SDIFFSTORE   | ZINTERSTORE、ZUNIONSTORE                | XTRIM、XDEL              |

#### 基本类型使用场景总结

| 类型              | 说明     | 使用场景                                       |
| ----------------- | -------- | ---------------------------------------------- |
| String            | 字符串   | 帖子、评论、热点数据、输入缓冲                 |
| Hash              | 哈希表   | 结构化数据，比如存储对象                       |
| List              | 列表     | 评论列表、商品列表、发布与订阅、慢查询、监视器 |
| Set               | 集合     | 交集、并集、差集，比如朋友关系                 |
| Zset              | 有序集合 | 去重后排序，适合排名场景                       |
| Stream（5.0版本） | 流       | 消息队列                                       |

#### Redis对象

```c
// Redis对象
typedef struct redisObjet {
    // 对象类型，取值范围有：REDIS_STRING、REDIS_HASH、REDIS_LIST、REDIS_SET、REDIS_ZSET
    unsigned type:4;
    // 对象编码，取值范围有：REDIS_ENCODING_INT、REDIS_ENCODING_EMBSTR、REDIS_ENCODING_RAW、REDIS_ENCODING_HT、REDIS_ENCODING_LINKEDLIST、REDIS_ENCODING_ZIPLIST、REDIS_ENCODING_INTSET、REDIS_ENCODING_SKIPLIST
    unsigned encoding:4;
    // 指向底层实现的数据结构的指针
    void *ptr;
    ...
}
```

使用Redis对象来表示key和Value，即每新建一个键值对，至少会创建有两个对象，而使用对象具有以下**好处**：

- **命令是否可执行判断**：在执行命令前，可以根据对象的类型来判断，一个对象是否可以执行该命令。
- **优化不同场景下的使用效率**：针对不同的使用场景，为对象设置不同的数据结构实现，从而优化对象的不同场景下的使用效率。
- **基于引用计数的内存回收**：可以基于引用计数的内存回收机制，自动释放对象所占用的内存。
- **对象内存共享**：可以让多个Key共享同一个对象，从而节约内存。
- **根据空转时长淘汰对象**：对象带有访问的时间记录信息，使用该信息可以进行优化空转时长较大的Key，从而进行删除。

#### Redis数据结构

Redis对象的**ptr指针**，指向对象底层实现数据结构，而这些数据结构由对象的**encoding属性**来决定，其**对应关系**为：

| RedisObject#encoding      | ptr指向的数据结构               | RedisObject#type                   |
| ------------------------- | ------------------------------- | ---------------------------------- |
| REDIS_ENCODING_INT        | redisObject + long型整数        | REDIS_STRING                       |
| REDIS_ENCODING_EMBSTR     | embstr（redisObject+优化的sds） | REDIS_STRING                       |
| REDIS_ENCODING_RAW        | raw（redisObject+sds）          | REDIS_STRING                       |
| REDIS_ENCODING_HT         | dict                            | REDIS_HASH、REDIS_SET              |
| REDIS_ENCODING_LINKEDLIST | linkedlist                      | REDIS_LIST                         |
| REDIS_ENCODING_ZIPLIST    | ziplist                         | REDIS_HASH、REDIS_LIST、REDIS_ZSET |
| REDIS_ENCODING_INTSET     | intset                          | REDIS_SET                          |
| REDIS_ENCODING_SKIPLIST   | skiplist+dict                   | REDIS_ZSET                         |

##### sds

```java
// 简单动态字符串
struct sdshdr{ 
  // 记录buf数组中已使用字节的数量，即实际使用的字节数 
  int len;
  // 记录buf数组中未使用字节的数量
  int free;
  // 字符数组，用于保存字符串
  char buf[];
}
```

![1631870815998](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631870815998.png)

- **概念**：sds，simple dynamic String，**简单动态字符串**，是Redis自己实现的一个字符串数据结构，在Redis中所有场景中，出现的字符串基本都是由SDS来实现的，包括所有的Key、非数字值、字符串类型的值。

- **特点**：

  - **空间预分配**：在进行修改之后，sds会对接下来可能需要的空间进行预分配，使用free属性来记录当前预分配了多少空间，来减少修改字符串带来的内存重分配次数，其分配策略如下：
    - 如果当前sds的长度小于1M，则分配等于len长的free空间。
    - 如果当前sds的长度大于1M，则分配1M的free空间。
  - **惰性释放内存**：为避免缩短字符串时的内存重分配操作，sds在数据减少时，并不会立刻释放空间，而是暂时留着，以备下次进行增长时使用。
    - 对于内存紧张的机器，sds也提供了对应的API，可以在需要的时候，来释放掉多余的未使用空间。
  - **SSD限制512M**：由于sds大小限制512M，所以Redis的Key以及字符串数据结构的值，最大大小也为 512M。

- **对比C字符串**：

  | SSD函数                | C字符串                                                      | SDS                                                  |
  | ---------------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
  | 高性能获取字符串长度   | 由于需要遍历整个字符数组，所以获取字符串长度需要O（N）       | 由于记录了len，所以获取字符串长度只需要O（1）        |
  | 杜绝字符数组缓冲区溢出 | 字符数组空间不会自动扩展，容易造成缓冲区溢出                 | 会先检查free是否足够，来自动扩展空间，避免缓冲区溢出 |
  | 减少内存重分配次数     | 每次修改字符串长度，都需要内存重新分配                       | 空间预分配、惰性释放内存，但最坏情况下，同C字符串    |
  | 二进制安全             | 由于使用空间符'0'来判断一个字符串的结尾，所以只能保存纯文本，非二进制安全 | 二进制安全，可以保存任意格式的二进制数据             |
  | 部分兼容C库函数        | 可以无缝使用所有C库函数                                      | 只兼容部分的C库函数                                  |

##### int

![1631878723017](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878723017.png)

long类型的整数，占8个字节。

##### embstr

![1631878253168](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878253168.png)

embstr，embstr编码的简单动态字符串，是对sds的一个小优化，将redisObject对象头和sds对象连续存在一起，一旦两者整体大小大于64字节时，Redis则认为是一个大字符串（即字符串为44字节时，3.2版本前是39字节），然后将会将字符串转为raw进行存储。

- 当使用sds时，程序需要调用两次内存分配，redisObject和sds各自分配一块空间；而由于embstr需要的空间很少，可以采用**连续的空间保存**，只需要一次内存分配，将sds的值和字符串对象的值放在一块连续的内存空间上，由于内存是连续的，减少了很多内存碎片和指针内存的占用，进而节约了内存，提高短字符串的内存分配效率和空间利用率。
- 另外，embstr是只读的形式，Redis并未对其提供任何修改的方式，因此，embstr需要转换为RAW才能进行修改。

##### raw

![1631878637658](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878637658.png)

raw，简单动态字符串，以sds形式存储，主要为了解决长度计算和追加字符效率的问题。

##### dict

```c
// 字典，持有两个哈希表，只是对hashtable做了一层封装
typedef struct dict{
  // 类型特定函数，配合*private以实现字典多态
  dictType *type;
  // 私有数据，配合*type以实现字典多态
  void *private;
  // 哈希表
  dictht ht[2];
  // rehash索引，当当前的字典不在rehash时，值为-1
  int trehashidx;
}

// 哈希表，是字典条目的数组
typedef struct dictht{
  // 哈希表的数组
  dictEntry **table;
  // 哈希表的大小
  unsigned long size;
  // 哈希表的大小的掩码，用于计算索引值，总是等于 size-1
  unsigned long sizemasky;
  // 哈希表中已有的节点数量
  unsigned long used;
}

// 字典条目，持有Key和Value
typedef struct dictEntry{
  // 键
  void *key;
  // 值
  union {
    void *val;
    uint64_tu64;
    int64_ts64;
  } v;

  // 指向下一个节点的指针
  struct dictEntry *next;
} dictEntry;
```

![1631878774943](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631878774943.png)

dict，字典，一种能够存储键值对的数据结构，在Redis中的字典实现中，它持有两张哈希表，一个为null，另一个存储实际键值对，在rehash时允许同时存在键值对。

- **hash算法**：在哈希表添加一个元素时，需要计算该键值的hash值，之后根据其hash值来定位被放入的槽，为了减少哈希冲突的发生，需要将key值打散的足够均匀，此时hash算法的选择尤其重要。Redis 选用了业内计算性能好的算法来实现hash过程：
  - **Redis 5.0 & 4.0版本**：siphash哈希算法，可以在输入的Key值很小的情况下，产生随机性比较好的输出。
  - **Redis 3.2、3.0 & 2.8版本**：Murmurhash2哈希算法，可以在输入值是有规律时，也能给出比较好的随机分布。
- **hash冲突**：hash算法计算结束之后，会根据当前哈希表的长度，来确定当前键值所在的index，而由于长度有限，迟早会产生两个键值要放到同一个位置的问题，即产生hash冲突。
  - **解决方案**：Redis的哈希表处理Hash冲突的方式，和Java中的HashMap一样，即链地址法，Hash表有两维，第一维度是个数组，第二维度是个链表，当发生了hash冲突的时，会将冲突的节点使用链表连接起来，放在同一个桶内。
    - **缺点**：由于第二维度是链表，如果hash冲突比较严重，导致单个链表过长，那么此时hash表的查询效率就会急速下降。
- **扩容与缩容**：当哈希表过于拥挤，查找效率就会下降，需要进行扩容操作；当哈希表过于稀疏，对内存就有点太浪费了，需要进行缩容操作。
  - **负载因子**：用于描述哈希表当前被填充的程度，计算公式是：`负载因子= 哈希表已保存的节点数量 / 哈希表的大小`，在Redis实现里，扩容缩容有三条规则：
    1. 当没有正在执行的`BGSAVE`和`BGREWRITEAOF`指令时，且**负载因子 >= 1**，才会对哈希表进行扩容。
    2. 当存在正在执行`BGSAVE`和`BGREWRITEAOF`指令时，且**负载因子 >= 5**，才会对哈希表进行扩容。
       - 这是因为在进行BGSAVE操作时，会存在**子进程**，Redis会尽量避免在存在子进程时进行扩容，以节省内存。
    3. 无论存不存`BGSAVE`和`BGREWRITEAOF`指令，只要**负载因子 < 0.1**时，会自动开始对哈希表进行缩容。
       - 而缩容过程中，由于申请的内存比较小，同时还会释放掉一些已经使用的内存，不会增大系统的压力，因此不需要在缩容时考虑是否正在进行`BGSAVE`和`BGREWRITEAOF`操作。
  - **扩容的目标数量**：第一个大于等于`ht[0].used * 2`的`2^n`，初始为4。
  - **缩容的目标数量**：第一个大于等于`ht[0].used`的`2^n`。
- **渐进式rehash**：在扩缩容期间，需要将当前哈希表中的所有节点，重新进行一次hash，即rehash。
  - **对比Java rehash**：
    - 在 Java的HashMap中，实现方式是，新建一个哈希表，一次性的将当前所有节点rehash完成，之后释放掉原有的 hash表，再持有新表。
    - 而Redis不是，由于rehash需要重新定位所有的元素，对数据量很大的字典执行此操作将比较耗时，这对于单线程的Redis说，是很难接受这种延时的，因此，Redis选择使用**一点一点搬的渐进式rehash**策略。
  - **渐进式rehash过程**：
    1. 如果当前数据在ht[0]中，则会首先为ht[1]分配足够的空间。
    2. 在字典中维护一个rehashindex变量，并更新rehashindex = 0，表示当前开始rehash操作。
    3. 在rehash期间，客户端每次对字典进行增删改查操作，在完成实际操作之后，redis都会对该字典进行一次rehash操作，将ht[0]在rehashindex对应位置上的值rehash到ht[1]上，然后把rehashindex 递增一位。
       - 为了让该字典在持有两个哈希表期间，仍然可以对外提供服务，对于添加操作，需要直接添加到 ht[1]上，让ht[0]的数量只会减少不会增加，保证rehash过程可以完结。
       - 而对于删除、修改以及查询操作，可以在ht[0]上进行，如果得不到结果，则会去ht[1]再执行一遍，保证rehash过程的推进。
    4. 随着字典不断被增删改查，原来的ht[0]上的数值会全部rehash完成，此时会将rehashindex置为-1，代表rehash结束。
    5. 而如果服务器很空闲，中间几小时没有被请求过，则Redis定时函数会加入帮助rehash的操作，从而加快rehash的过程。
  - **优点**：采用了分而治之的思想，将rehash操作，分散到每一个对该字典的操作上以及定时函数上，避免了集中式rehash带来的性能压力。
  - **缺点**：在 rehash 的时间内，需要同时持有两个哈希表，对服务器内存的占用稍大，如果此时服务器本来内存就不足时，突然进行的rehash，会使得Redis执行缓存淘汰策略，造成大量的Key被抛弃。

##### linkedlist

```c
// 双向链表
typedef struct list {
  // 表头结点
  listNode *head;
  // 表尾节点
  listNode *tail;
  // 链表所包含的节点数量
  unsigned long len;
  // 其他函数
  ...
} list;

// 双向链表结点
typedef struct listNode{
  // 前置节点
  struct listNode *prev;
  // 后置节点
  struct listNode *next;
  // 节点值
  void *value;
} listNode
```

![1631882244485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631882244485.png)

linkedlist，双向链表，由于经常需要使用，Redis自己实现了一个双向链表。

- **双向**：包含了头结点、尾结点，同时每个结点都有自己的前驱和后继，可以很方便地进行正向和反向的遍历。
- **无环**：头结点的prev指针和尾结点的next指针都指向null，是一个无环链表。
- **持有长度计数器**：len记录着当前链表的长度，获取的时间复杂度是O（1）。

##### ziplist

```c
// 压缩链表，底层是个结点数组
struct ziplist<T>{
    // 整个压缩列表占用字节数
    int32 zlbytes;
    // 最后一个节点到压缩列表起始位置的偏移量，可以用来快速定位到压缩列表中的最后一个元素
    int32 zltail_offset;
    // 压缩列表包含的元素个数
    int16 zllength;
    // 元素内容列表，用数组存储，内存上紧挨着
    T[] entries;
    // 压缩列表的结束标志位，值永远为0xFF.
    int8 zlend;
}

// 压缩链表结点
struct entry{
    // 前一个entry的长度，当其在254字节以内时，该值为1字节；否则为5字节
    int<var> prevlous_entry_length;
    // 编码方式，记录着结点content属性所保存数据的类型以及长度
    int<vat> encoding;
    // 内容，真正要保存的数据，类型和长度由encoding决定
    optional bute[] content;
}
```

![1631926865240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631926865240.png)

压缩列表，是由一系列连续内存块组成的顺序型数据结构，由于内存是连续的，减少了很多内存碎片和指针内存的占用，进而节约了内存。

- **prevlous_entry_length取值逻辑**：
  - 当前一个节点的长度小于254字节时，`previous_entry_length`长度为1字节。
  - 当前一个节点的长度大于等于254字节时，`previous_entry_length`长度为5字节。
- **遍历列表**：
  - **顺序遍历**：按顺序遍历`entries`数组。
  - **反向遍历**：首先拿到尾部节点的偏移量，找到最尾部的节点，然后调用`prevlous_entry_length`属性，就可以拿到前一个节点，接着不断向前遍历即可。
- **新增结点**：ziplist 是连续存储的数据结构，内存是没有冗余的（SDS中就有冗余空间）, 所以，每一次新增节点，都需要进行内存申请。
  - 如果当前ziplist所在的内存连续块够用，则将新节点添加即可。
  - 但如果申请到的是另外一块连续的内存空间，则需要将所有的内容拷贝到新的地址，当ziplist中存储的值太多，这样的内存拷贝将是一个很大的消耗。
  - 因此，Redis只在一些数据量小的场景下使用ziplist。
- **级联更新问题**：
  - **发生场景**：
    1. 假设有一个极端的场景，在这个ziplist内部，所有的节点的长度都是 253 字节，也就意味着所有节点的`prevlous_entry_length`属性都是一个字节。
    2. 此时，给压缩列表**最前端**插入一个大于 254 字节的节点，那么原来的第一个节点的`prevlous_entry_length`属性会从 1 个字节变成 5 个字节，这个节点的总长度也就来到了 257 字节，大于了254 字节，那么它的下一个节点（原来的第二个节点）的`prevlous_entry_length`属性也需要变成 5 个字节，这又会导致下一个节点的变化... 从而引起了连锁的变化，所有节点的`prevlous_entry_length`值都需要更新一遍。
    3. 同理，删除节点也有可能会造成级联更新的发生。
  - **缺点**：级联更新的时间复杂度很差，最多需要进行N次空间的重分配，每次空间的重分配最差也需要 O（N）, 所以，级联更新的时间复杂度最差是 O（N^2）。
    - 级联更新问题造成Redis性能压力的**概率极其低**：因为级联更新需要大范围连续的节点大小为250-253字节之间，出现的概率非常小，而且当只出现了3~5个结点的级联更新时，对Redis也不会造成性能压力。

##### quicklist（3.2版本）

```c
// 快速列表
struct quicklist{
    // 头结点
    quicklistNode* head;
    // 尾节点
    quicklistNode* tail;
    // 元素总数
    long count;
    // ziplist 节点的个数
    int nodes;
    // LZF 算法压缩深度
    int compressDepth;
}

// 快速列表结点
struct quicklistNode {
    // 快速列表前驱
    quicklistNode* prev;
    // 快速列表后继
    quicklistNode* next;
    // 指向压缩列表 ziplist
    ziplist* zi; 
    // ziplist 的字节总数
    int32 size;
    // ziplist 的元素总数
    int 16 count;
    // 存储形式，是原生的字节数组，还是 LZF 压缩存储
    // 为了进一步节约内存，quicklist 可使用 LZF 算法对 ziplist 进行压缩存储
    int2 encoding;
}
```

![1631929051582](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631929051582.png)

quicklist，快速列表，是 Redis 3.2 列表的底层实现，是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。（在 Redis 3.2 之前，Redis 采用双向链表 linkedlist 和压缩列表 ziplist 实现）

- **linkedlist缺点**：
  - **指针内存浪费**：每个节点都有自己的前后指针，指针所占用的内存有点多，太浪费了。
  - **内存碎片多**：每个节点单独的进行内存分配，当节点过多，造成的内存碎片太多了，影响内存管理的效率。
- **quicklist优点**：将 linkedlist 和 ziplist 结合起来，通过前后指针，互相连接多个 ziplist，可以在一定程度上缓解 linkedlist 指针内存浪费和内存碎片多的问题，同时解决 ziplist 数据量太大导致的性能变差问题。
- **ziplist切割大小**：
  - ziplist 太小的话（比如为1个元素时），quicklist 退化成了普通的链表，起不到应有的作用；ziplist 太大的话（比如 quicklist 只用一个 ziplist），quicklist 退化成了 ziplist，性能太差。
  - 因此，quicklist 内部默认定义的单个 ziplist 的大小为 `8k 字节`，可以由参数`list-max-ziplist-size`来控制，其作用是，如果分配结点时，发现 ziplist 超过了这个大小，则会重新分配一个 ziplist。
- **压缩深度**：
  - 为了进一步节约内存，quicklist 可使用 LZF 算法对 ziplist 进行压缩存储，同时可以指定压缩深度，由`list-compress-depth`参数决定，默认的压缩深度为 0，表示所有的节点都不进行压缩。
    - 当压缩深度为 1 时：quicklist 两端的第一个 ziplist 不进行压缩。
    - 当压缩深度为 2 时：quicklist 两端的各自2个 ziplist 不进行压缩。
  - 之所以只压缩两端的结点，是因为需要支持列表快速的 push/pop 操作：
    - 如果对两端的 ziplist 压缩了，那么要从列表里面读取值时，必然需要先解压，从而导致性能变差。
    - 因此可以将两端即将被操作的节点不压缩，其他的选择压缩。

##### listpack（5.0版本）

```c
// 紧凑列表类似于ziplist压缩链表，以下是它结点的一些属性：

// 编码方式，记录着结点content属性所保存数据的类型以及长度
int<vat> encoding;
// 内容，真正要保存的数据，类型和长度由encoding决定
optional bute[] content;
// 结点自身长度
int<var> length;
```

![1631943890480](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631943890480.png)

listpack，紧凑列表，是Redis 5.0 版本中新引入的一个数据结构，和 ziplist 极其相似，列表结点不再记录前一个结点的长度，而是记录自身的长度，从而解决ziplist的痛点问题。（在极小的概率下有可能发生级联更新，当连续规模较大的级联更新发生时，会对 Redis 的性能有比较大的影响）

- **优点**：
  - 不再需要 zltail_offset 属性也可以快速定位到最后一个节点，而是用`listpac总长度 - 最后一个结点的长度`。
  - 每个节点记录自己的长度，当本节点的值发生了改变，只需要更改自己的长度即可，不再需要更改别的节点的属性，彻底解决掉了级联更新的问题。
- **局限**：由于 ziplist 在 Reids 5.0版本前，内部使用得过于广泛，有一些兼容问题，listpack 替代 ziplist 需要一个逐步替换的过程，所以，在5.0版本中，listpack 只被 Stream 数据结构使用。

##### intset

```c
// 整数集合
typedef struct intset{
    // 编码方法，指定当前存储的是16位，还是32位，还是64位的整数数组
    int32 encoding;
    // 集合中的元素数量
    int32 length;
    // 保存元素的数组，具体是多少位整数的数组，取决encoding的值
    int<T> contents;
}
```

![1631932631768](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631932631768.png)

intset，整数集合，用于保存整数值集合的抽象数据结构，可以保存16、32、64位的整数且保证不重复。

- **整数集合升级**：每当一个整数被添加到整数集合时，都需要先去判断 `这个整数 是否大于 当前编码方式所能容放的最大整数`，如果大于，则需要对当前的整数集合进行升级（16 -> 32 -> 64位），同时，将原来的所有整数转换成新的编码。
  - **好处**：
    - **节约内存**：用能容纳数字的最小编码进行存储，可以有效的节约内存。
    - **提升操作的灵活性**：整数集合封装了对三种整数之间的转换，使得不用考虑类型错误，可以不断的向整数集合内添加整数，提升了操作的灵活性。
  - **不能降级**：与升级相对应的，当大的数字被删除之后，整数集合不会进行降级。

##### skiplist

```c
// 跳表
typedef struct zskiplist{
    // 表头结点和尾节点
    struct zskiplistNode *header, *tail;
    // 表中节点的数量
    unsigned int length;
    // 表中层数最大的节点的层数
    int level;
} zskiplist;

// 跳表结点
typedef struct zskiplistNode{
    struct zskiplistLevel{
        // 前进指针
        struct zskiplistNode *forward;
        // 跨度
        unsigned int span;
    } level[];
    // 后退指针
    struct zskiplistNode *backward;
    // 分值
    double score;
    // 成员对象
    robj *obj;
} zskiplistNode;
```

![1631933408583](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631933408583.png)

skiplsit，跳跃表，是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问元素的目的，支持平均`O(log N)`、最坏`O(N)`的节点查找，大部分情况下查找效率可以和红黑树媲美，并且相比红黑树可以更方便地实现并发操作（例如Java中的`ConcurrentSkipListMap`）。

- **跳表结点**：
  - **forward**： 前进指针，可以在当前层，继续向右走。
  - **span**：跨度，可以累加查找路径中的所有跨度，计算出当前结点在跳跃表中的一个排名，比如zset提供查看排名的功能。
  - **backward**：后退指针，如果在向右走的太多了，可以用后退指针来向反向操作。
  - **score & obj**：用于保存当前结点的value值以及分值。
- **层级问题**：
  - **计算方式**：
    - 在 Java 的`ConcurrentSkipListMap`的实现中，索引每一次向上升级或者不升级，都是随机的，一个结点是否是一级索引的概率是 50%，是否是二级索引的概率是 25%...
    - 而在 Redis 中，每新添加一个结点，都会给结点随机一个索引层数，而且概率是 25%，之后将该结点的各层索引与左右的索引相链接，即结点为level 1的概率为 1 - 0.25 = 0.75，level 2的概率为 0.75 * 0.25...
  - 由于level + 1的概率都是25%，Redis跳跃表相对于Java中的跳跃表，结构更加扁平一些，因此：
    - **优点**：Redis索引的数量并不是完全的等同于节点数，额外的内存只占用了50%，可以**节省内存**。
    - **缺点**：Redis在查找的时候，可能需要在同级上**多查询几个索引**。
- **顺序问题**：Redis 除了按照score分值排序之外，还会按照value值的字符串字典顺序来排序。
- **排名问题**：可以累加查找路径中的所有跨度，计算出当前结点在跳跃表中的一个排名，比如zset提供查看排名的功能。

###### skiplist vs 平衡树 vs 哈希表

| 比较点         | skiplist                                                     | 平衡树                                                       | 哈希表                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------- |
| 元素有序性     | 有序                                                         | 有序                                                         | 无序                                           |
| 单值查找       | O（logn）                                                    | O（logn）                                                    | 无哈希冲突时为O(1)                             |
| 范围查找       | 实现简单，只需要 O（logn）定位头尾结点，然后遍历链表即可，缓存局部性比平衡树的要好 | 实现困难，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]    | 只能做单值查找，不适合做范围查找               |
| 插入与删除操作 | 只需要修改相邻结点的指针，简单又快速，并发场景下需要使用volatile修饰指针，效果比平衡树的好 | 可能会引发子树的调整，逻辑复杂，并发场景下需要对根结点进行加锁 | 存在哈希冲突，并发场景下需要对桶头结点进行加锁 |
| 内存占用       | 每个结点平均包含`1/(1-p)`个指针，当p为25%概率时为**1.33**个指针，比平衡树少 | 每个结点平均包含左右子树，共2个指针                          | 无冲突时只有散列表数组                         |
| 缓存友好性     | 由于新结点插入的level是随机的，导致查找路径可能会发生变化，缓存友好性不如平衡树 | 插入新结点后，大部分老结点仍然处于原查找路径上               | 哈希冲突和扩容后，查找路径可能会发生变化       |
| 算法实现难度   | 比平衡树简单                                                 | 典型的有红黑树，实现麻烦                                     | 最简单，不过需要处理哈希冲突                   |

###### 为什么Redis使用skiplist？

- **范围查找效率高**：
  1. 对于 `ZRANGE` 和 `ZREVRANGE` 命令的范围查找，如果使用哈希表，则只能做单值查找，不适合做范围查找。
  2. 如果使用红黑树，需要中序遍历 [ 范围最小的后继，范围最大的前驱 ]，效率低且实现复杂。
  3. 而使用 skiplilst 只需要 O（logn）定位头尾结点，然后遍历链表即可，简单又高效，缓存局部性比红黑树的要好。
- **内存占用少**：Redis skiplist 索引的默认生成概率为 25%，即每个结点平均只包含1.33个指针，内存占用比红黑树的 2 个指针要少。
- **实现与调试容易**：使用 skiplist 比红黑树更容易实现与调试。

##### radix tree（5.0版本）

```c
// rax树
typedef struct rax {
    // rax树头节点
    raxNode *head;
    // 元素数量
    uint64_t numele;
    // rax树节点数量
    uint64_t numnodes;
} rax;

// rax树结点
typedef struct raxNode {
    // 表示这个节点是否包含key，0：没有，1:完整路径存储了key
    uint32_t iskey:1;
    // 是否有存储value值，比如存储元数据就只有key，没有value值，value值也是存储在data中
    uint32_t isnull:1;
    // 是否有前缀压缩，决定了data存储的数据结构，0:非压缩模式，1:压缩模式
    uint32_t iscompr:1;
    // 该节点存储的字符个数
    uint32_t size:29;
    // 存储子节点的信息
    unsigned char data[];
} raxNode;
```

![1631944112996](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631944112996.png)

raxid tree，Rax树，即基数树，是一棵有序字典树 ，按照 key 的字典序排列，可以快速地定位、插入和删除操作。

#### 基本类型底层实现

Redis自定义了一个Object系统，其中包含5种Object，每种至少有2种不同的编码，其**对应关系**：

| RedisObject#type | RedisObject#encoding      | 值保存条件                                                   |
| ---------------- | ------------------------- | ------------------------------------------------------------ |
| 字符串类型       |                           |                                                              |
| REDIS_STRING     | REDIS_ENCODING_INT        | long范围内的整数值                                           |
| REDIS_STRING     | REDIS_ENCODING_EMBSTR     | <= 39字节字符串值（3.2版本），<= 44字节字符串值（4.0版本）   |
| REDIS_STRING     | REDIS_ENCODING_RAW        | > 39字节字符串值（3.2版本），> 44字节字符串值（4.0版本）     |
| 哈希类型         |                           |                                                              |
| REDIS_HASH       | REDIS_ENCODING_ZIPLIST    | 键和值的长度都 < 64字节，且键值对个数 < 512个时              |
| REDIS_HASH       | REDIS_ENCODING_HT         | 存在键和值的长度 >= 64字节，或者键值对个数 >= 512个时        |
| 列表类型         |                           |                                                              |
| REDIS_LIST       | REDIS_ENCODING_ZIPLIST    | Redis 3.2版本前，所有元素长度都 < 64字节，且列表元素个数 < 512个时 |
| REDIS_LIST       | REDIS_ENCODING_LINKEDLIST | Redis 3.2版本前，存在元素长度 >= 64字节，或者列表元素个数 >= 512个时 |
| REDIS_LIST       | REDIS_ENCODING_QUICKLIST  | Redis 3.2版本后，列表使用统一格式                            |
| 集合类型         |                           |                                                              |
| REDIS_SET        | REDIS_ENCODING_INTSET     | long范围内的整数值，且集合元素数量 < 512个时                 |
| REDIS_SET        | REDIS_ENCODING_HT         | 存在long范围内的整数值元素，或者集合元素数量 >= 512个时      |
| 有序集合类型     |                           |                                                              |
| REDIS_ZSET       | REDIS_ENCODING_ZIPLIST    | 所有元素长度都 < 64字节，且有序集合元素个数 < 128个时        |
| REDIS_ZSET       | REDIS_ENCODING_SKIPLIST   | 存在元素长度 >= 64字节，或者有序集合元素个数 >= 128个时      |

##### String

| 命令        | 使用                                                  | 作用                                                         |
| ----------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| SET         | set key value [ex seconds] [px milliseconds] [nx\|xx] | 设置value，ex代表设置秒TTL，px代表设置毫秒TTL，nx代表只有键不存在时才设置，xx代表只有键存在时才设置 |
| GET         | get key                                               | 获取value                                                    |
| GETSET      | getset key value                                      | 设置value，并返回旧值                                        |
| SETNX       | setnx key value                                       | 如果key不存在，才新增key和value                              |
| SETEX       | setex key seconds value                               | 设置value，并原子设置TTL为seconds                            |
| PSETEX      | psetex key milliseconds value                         | 设置value，并原子设置TTL为milliseconds                       |
| APPEND      | append key value                                      | 在key值后面追加value                                         |
| STRLEN      | strlen key                                            | 返回key值的字符串长度                                        |
| SETRANGE    | setrange key offset value                             | value覆盖从offset开始的字符串                                |
| GETRANGE    | getrange key start end                                | 返回[start，end]部分的字符串                                 |
| INCR        | incr key                                              | value + 1                                                    |
| INCRBY      | incrby key increment                                  | value + increment                                            |
| INCRBYFLOAT | incrbyfloat key increment                             | value + increment                                            |
| DECR        | decr                                                  | value - 1                                                    |
| DECRBY      | decrby key decrement                                  | value - decrement                                            |
| MGET        | mget key[key...]                                      | 批量获取多个键的值                                           |
| MSET        | mset key value[key value...]                          | 批量设置多个键的值                                           |
| MSETNX      | msetnx key value[key value...]                        | 批量设置多个键的值，仅当所有键都不存在时，才会设置成功       |

###### int

- **值保存条件**：long范围内的整数值。
- **对应编码**：REDIS_ENCODING_INT。

![1631946982581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631946982581.png)

###### embstr

- **值保存条件**：<= 39字节字符串值（3.2版本），<= 44字节字符串值（4.0版本）。
- **对应编码**：REDIS_ENCODING_EMBSTR。

###### raw

- **值保存条件**：> 39字节字符串值（3.2版本），> 44字节字符串值（4.0版本）。
- **对应编码**：REDIS_ENCODING_RAW。

![1631947051873](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631947051873.png)

##### Hash

| 命令         | 使用                                   | 作用                                                         |
| ------------ | -------------------------------------- | ------------------------------------------------------------ |
| HSET         | hset hash field value                  | 把hash#field设置为value                                      |
| HSETNX       | hsetnx hash field value                | 把hash#field设置为value，仅当hash#field不存在时，才会设置成功 |
| HGET         | hget hash field                        | 获取hash#field的value                                        |
| HGETALL      | hgetall hash                           | 获取hash中所有的field和value                                 |
| HEXSITS      | hexists hash field                     | 检查hash#field是否存在                                       |
| HDEL         | hdel hash field[field..]               | 删除hash中一个或者多个field                                  |
| HLEN         | hlen hash                              | 获取hash中field的数量                                        |
| HSTRLEN      | hstrlen hash field                     | 获取hash#field的value长度                                    |
| HINCRBY      | hincrby hash field increment           | 把hash#field设置为value+increment                            |
| HINCRBYFLOAT | hincrbyfloat hash field increment      | 把hash#field设置为value+increment                            |
| HMSET        | hmset hash field value[field value...] | 批量把hash#field设置为对应的value                            |
| HMGET        | hmget hash field[field...]             | 批量获取hash#field的value                                    |
| HKEYS        | hkeys hash                             | 获取hash中所有的field                                        |
| HVALS        | hvals key                              | 获取hash中所有的和value                                      |

###### ziplist

- **值保存条件**：键和值的长度都 < 64字节，且键值对个数 < 512个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631950146881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950146881.png)

###### dict

- **值保存条件**：存在键和值的长度 >= 64字节，或者键值对个数 >= 512个时。
- **对应编码**：REDIS_ENCODING_HT。

![1631950298985](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631950298985.png)

##### List

| 命令       | 使用                                  | 作用                                                         |
| ---------- | ------------------------------------- | ------------------------------------------------------------ |
| LPUSH      | lpush key value[value...]             | 把一个或者多个value从表头插入，当key不存在时，会先创建列表再插入元素 |
| LPUSHX     | lpushx key value                      | 把value从表头插入，当key不存在时，则什么也不做               |
| LPOP       | lpop key                              | 移除并返回表头元素                                           |
| RPUSH      | rpush key value[value...]             | 把一个或者多个value从表尾插入，当key不存在时，会先创建列表再插入元素 |
| RPUSHHX    | rpushx key value                      | 把value从表尾插入，当key不存在时，则什么也不做               |
| RPOP       | rpop key                              | 移除并返回表尾元素                                           |
| RPOPLPUSH  | rpoplpush source destination          | 弹出source表尾元素，插入到destination表头，并返回该元素      |
| LREM       | lrem key count value                  | 移除列表count个与value相等的元素，count=0代表移除所有相等的元素；count<0代表从表头开始查找；count>0代表从表尾开始查找 |
| LINSERT    | linsert key before\|after pivot value | 把value插入到pivot前面或者后面，如果没找到pivot，则什么也不做 |
| LINDEX     | lindex key index                      | 获取下标为index的元素（-1代表最后一个元素）                  |
| LSET       | lset key index value                  | 设置index元素为value（-1代表最后一个元素）                   |
| LRANGE     | lrange key start stop                 | 获取列表中[start，stop]区间内的元素                          |
| LTRIM      | ltrim key start stop                  | 剪裁并保留列表中[start，stop]区间内的元素                    |
| BLPOP      | blpop key [key...] timeout            | 阻塞式移除并返回表头元素                                     |
| BRPOP      | brpop key [key...] timeout            | 阻塞式移除并返回表尾元素                                     |
| BRPOPLPUSH | brpoplpush source destination timeout | 阻塞式弹出source表尾元素，插入到destination表头，并返回该元素 |

###### ziplist

- **值保存条件**：Redis 3.2版本前，所有元素长度都 < 64字节，且列表元素个数 < 512个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631952569099](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952569099.png)

###### linkedlist

- **值保存条件**：Redis 3.2版本前，存在元素长度 >= 64字节，或者列表元素个数 >= 512个时。
- **对应编码**：REDIS_ENCODING_LINKEDLIST。

![1631952812216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631952812216.png)

###### quicklist

- **值保存条件**：Redis 3.2版本后，列表使用统一格式。
- **对应编码**：REDIS_ENCODING_QUICKLIST。

![1631953074136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631953074136.png)

##### Set

| 命令        | 使用                                 | 作用                                                         |
| ----------- | ------------------------------------ | ------------------------------------------------------------ |
| SADD        | sadd key member [member...]          | 把一个或者多个member加入到集合中，当key不存在时，会先创建列表再添加元素 |
| SISMEMBER   | sismember key member                 | 判断member元素是否为集合的成员                               |
| SPOP        | spop key                             | 移除并返回集合中的一个随机元素                               |
| SRANDMEMBER | srandmember key [count]              | 返回集合中的一个随机元素，count>0，返回集合的子集数组，其元素不重复；count<0，返回含重复元素的数组 |
| SREM        | srem key member [member...]          | 移除集合中一个或者多个member元素，不存在的member元素会被忽略 |
| SMOVE       | smove source destination member      | 把member元素从source集合移动到destination集合中，如果member元素不存在，则什么也不做 |
| SCARD       | scard key                            | 获取集合中元素的数量                                         |
| SMEMBERS    | smembers key                         | 获取集合中所有的成员                                         |
| SINTER      | sinter key [key...]                  | 获取所有给定集合的交集                                       |
| SINTERSTORE | sinterstore destination key [key...] | 获取所有给定集合的交集，并覆盖到destination中                |
| SUNION      | sunion key [key...]                  | 获取所有给定集合的并集                                       |
| SUNIONSTORE | sunionstore destination key [key...] | 获取所有给定集合的并集，并覆盖到destination中                |
| SDIFF       | sdiff key [key...]                   | 获取所有给定集合的差集                                       |
| SDIFFSTORE  | sdiffstore destination key [key...]  | 获取所有给定集合的差集，并覆盖到destination中                |

###### intset

- **值保存条件**：long范围内的整数值，且集合元素数量 < 512个时。
- **对应编码**：REDIS_ENCODING_INTSET。

![1631954240528](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954240528.png)

###### dict

- **值保存条件**：存在long范围内的整数值元素，或者集合元素数量 >= 512个时。
- **对应编码**：REDIS_ENCODING_HT。

![1631954355626](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954355626.png)

##### Zset

| 命令             | 使用                                                         | 作用                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ZADD             | zadd key score member [[score member] [score member] ..]     | 把一个或者多个member及其score加入有序集合中，如果key不存在，则会先创建有序集合再添加元素 |
| ZINCRBY          | zincrby key increment member                                 | 把member#score值+increment                                   |
| ZSCORE           | zscore key member                                            | 获取member#score值                                           |
| ZCARD            | zcard key                                                    | 获取有序集合中元素的个数                                     |
| ZCOUNT           | zcount key min max                                           | 获取有序集合中score在[min，max]之间的元素个数                |
| ZRANGE           | zrange key start stop [withscores]                           | 获取有序集合[start，stop]区间的元素，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序 |
| ZREVRANGE        | zrevrange key start stop [withscores]                        | 获取有序集合[start，stop]区间的元素，返回的元素会按score从大到小进行排序，相等时则再按字典逆序进行排序 |
| ZRANGEBYSCORE    | zrangebyscore key min max [withscores] [limit offset count]  | 获取有序集合中score在[min，max]之间的元素个数，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZREVRANGEBYSCORE | zrevrangebyscore key min max [withscores] [limit offset count] | 获取有序集合中score在[min，max]之间的元素个数，返回的元素会按score从大到小进行排序，相等时则再按字典逆序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZRANK            | zrank key member                                             | 获取member在有序集合中从大到小的排名                         |
| ZREVRANK         | zrevrank key member                                          | 获取member在有序集合中从小到大的排名                         |
| ZREM             | zrem key member [member...]                                  | 移除一个或者多个member，如果member不存在，则会被忽略         |
| ZREMRANGEBYRANK  | zremrangebyrank key start stop                               | 移除有序集合[start，stop]区间的元素，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序 |
| ZREMRANGEBYSCORE | zremrangebyscore key min max                                 | 移除有序集合中score在[min，max]之间的元素个数，返回的元素会按score从小到大进行排序，相等时则再按字典顺序进行排序；min/max语句中，-inf表示最低score，+inf表示最高score，（表示开区间，否则表示闭区间 |
| ZRANGEBYLEX      | zrangebylex key min max [limit offset count]                 | 获取有序集合[start，stop]区间的元素，仅当有序集合中的元素分数都相同时才有效；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZLEXCOUNT        | zlexcount key min max                                        | 获取有序集合中score在[min，max]之间的元素个数，仅当有序集合中的元素分数都相同时才有效；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZREMRANGEBYLEX   | zremrangebylex key min max                                   | 移除有序集合中score在[min，max]之间的元素个数；min/max语句中，-表示负无限，+表示正无限，（表示开区间，[ 表示闭区间 |
| ZINTERSTORE      | zinterstore destination numkeys key [key...] [weights weight [weight...]] [aggregate sum | 计算一个或者多个有序集合的交集，再把结果集覆盖到destination中，默认使用sum；sum会统计所有相同成员的score之和，min会取相同成员的最小score，max会取相同成员的最大score，作为该成员结果score |
| ZUNIONSTORE      | zunionstore destination numkeys key [key...] [weights weight [weight...]] [aggregate sum\|min\|max] | 计算一个或者多个有序集合的并集，再把结果集覆盖到destination中，默认使用sum；sum会统计所有相同成员的score之和，min会取相同成员的最小score，max会取相同成员的最大score，作为该成员结果score |

###### ziplist

- **值保存条件**：所有元素长度都 < 64字节，且有序集合元素个数 < 128个时。
- **对应编码**：REDIS_ENCODING_ZIPLIST。

![1631954526032](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631954526032.png)

###### skiplist+dict

- **值保存条件**：存在元素长度 >= 64字节，或者有序集合元素个数 >= 128个时。
- **对应编码**：REDIS_ENCODING_SKIPLIST。

![1631955510770](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955510770.png)

##### Stream（5.0版本）

（非网上资料，自己理解可能有差错）

| 命令        | 使用                                                   | 作用                                                         |
| ----------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| XADD        | xadd stream 0-1 field value                            | 添加field-value消息到stream中，0-1为指定的消息id，可以使用*，代表使用redis自增消息ID |
| XLEN        | xlen stream                                            | 获取stream中的消息个数                                       |
| XRANGE      | xrange stream min max                                  | 获取消息ID在[min，max]区间的消息，返回的消息按ID顺序排列；min/max语句中，-表示最x小的消息ID，+表示最大的消息ID |
| XREVRANGE   | xrevrange stream min max                               | 获取消息ID在[min，max]区间的消息，返回的消息按ID逆序排列；min/max语句中，-表示最x小的消息ID，+表示最大的消息ID |
| XREAD       | xread count n streams stream                           | 非阻塞式从stream获取n个消息                                  |
| XREAD BLOCK | xread block count n STREAMS stream                     | 阻塞式从stream获取n个消息                                    |
| XGROUP      | xgroup create stream group $                           | 为stream创建消费组group                                      |
| XREADGROUP  | xreadgroup GROUP group cousumer COUNT n STREAMS stream | consumer消费者从group消费组读取stream消费消息                |
| XACK        | xack stream group id                                   | 确认stream队列group消费组中序号为id的消息                    |
| XPENDING    | xpending stream group min max count                    | 获取stream队列group消费组中ID在[min，max]区间的消息总量      |
| XCLAIM      | xclaim stream group consumer id [id...]                | stream队列group消费组中consumer认领指定id消息的所有权        |
| XAUTOCLAIM  | xautoclaim stream group consumer id[id...]             | stream队列group消费组中consumer自动认领指定id消息的所有权    |
| XINFO       | xinfo STREAM stream                                    | 获取stream状态以及所有消费组的信息                           |
| XTRIM       | xtrim stream MAXLEN\|MINID n                           | MAXLEN，表示剪裁stream并最大保存10个消息；MINID，表示剪裁stream并只保留大于等于ID的消息 |
| XDEL        | xdel stream id                                         | 删除stream队列中指定id的消息                                 |

Redis Stream，消息流类型，底层主要使用了紧凑列表（listpack）和基数树（Rax树）。

- listpack，表示一个字符串列表的序列化，用于存储stream的消息内容。
- raxid tree，Rax树，即基数树，是一棵有序字典树 ，按照 key 的字典序排列，可以快速地定位、插入和删除操作。

![1631955983886](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631955983886.png)

### 1.4. Redis Bitmap与布隆过滤器？

#### BitMap

| 命令     | 使用                                                         | 作用                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| SETBIT   | set key offset value                                         | 设置offset位置为value（0或1），如果offset不存在，则字符串会自动扩展，空白位置以0填充；如果key不存在，则会先创建一个字符串再设置；时间复杂度为O（1），就跟操作数组一样 |
| GETBIT   | getbit key offset                                            | 获取offset位置的value（0或1），如果offset或者key不存在，则会返回0；时间复杂度为O（1），就跟操作数组一样 |
| BITCOUNT | bitcount key [start] [end]                                   | 计算[start，end]区间内为1的数量，默认计算整个字符串          |
| BITPOS   | bitpos key bit [start] [end]                                 | 获取[start，end]区间内value为bit的位置，默认比较整个字符串   |
| BITOP    | bitop operation destkey key [key...]                         | 对一个或者多个bitmap key进行位操作，最后把结果保存到destkey上；operation为AND代表与，OR代表或，NOT代表非，XOR代表异或 |
| BITFIELD | bitfield key get type offset] [set type offset value] [incrby type offset increment] [overflow wrap\|sat\|fail] | 把整个bitmap看作是一个二进制位数组，可以对指定偏移量的bit进行其他命令操作 |

![1632039188474](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632039188474.png)

Bitmap，位图，基本思想是，用一个bit位来标记某个元素对应的value，而key即是该元素。

##### 优点

由于采用了bit为单位来存储数据，因此，可以**大大节省存储空间**。比如，1G大约只可以存储1.34亿个int数值，但可以存储10.74亿个bit。

##### 使用场景

主要用于**检索大数据量关键字的状态**，比如大数据量的排序、查找、去重，以及登录表等实际场景。

- **大数据量计数排序**：把序列中所有的元素，一个一个等于自身数值的offset中，然后遍历一次bitmap即可拿出所有顺序的序列；如果序列中有重复的元素，则bitmap中元素需要更多bit来存储，以记录该元素一共出现多少次，在后续顺序遍历中，对于这种元素需要重复取多次。
  - **优点**：非比较排序算法，运算效率高；占用内存少。
- **大数据量快速去重**：使用2 bit 来表示元素的3种状态，00代表不存在，01代表出现1次，11代表出现了多次，接着把每个元素放入等于自身数值的offset中（2bit一个单位），最后遍历出每单位为01的数字即可。
- **大数据量快速查找**：把每个元素的2进制值对应存进bitmap中，最后根据bitmap长度对元素长度取余即可，比如int类型的数值，占4个字节，则应该对32取余 n % 32。
- **登录表**：用于记录用户每天的登录情况，可以一个用户一个bitmap，然后当前有登录则在对应天数offset上记为1，否则记为0，最后遍历bitmap，即可拿到该用户每天的登录情况了。

#### 布隆过滤器

Bloom filter，布隆过滤器，基础数据结构是一个bitmap 位图，可以用来判断集合中一个元**素一定不存在**，或者**可能存在**。

##### 优点

运行快速、内存占用小。

##### 缺点

- 对于元素的存在结果有误判，并且随着系统的不断运行，误判率会越来越高，此时可以**定期重建**布隆过滤器。
- 元素一旦存进布隆过滤器中，删除则十分困难，因为可能会删掉其他元素的 bit 结果，此时可以使用额外的删除标记变量进行**逻辑删除**。

##### 实现原理

1. 当一个元素被加入集合时，通过K个散列函数该元素映射成位图中的K个点，同时把这些点都置为1。
2. 在检索时，只要看看这些点是不是都为1，就可以知道该元素是否在集合中。
3. 如果这些点有任何一个为0，则该元素一定不在。
4. 如果这些点都为1，则该元素很可能在，因为散列函数存在哈希冲突，所以布隆过滤器存在对结果的误判。

![1632042655580](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632042655580.png)

##### 使用方式

| 实现方式      | 存储位置 | 优点                                   | 缺点                                                         |
| ------------- | -------- | -------------------------------------- | ------------------------------------------------------------ |
| Guava 实现    | JVM      | 可以减轻 Redis 内存与 I/O 的压力       | 应用有状态，水平复制麻烦，布隆过滤器重启即失效，也不支持大数据量的存储；本地缓存无分布式一致性可言，所以无法应用于分布式场景。 |
| Redisson 实现 | Redis    | 支持分布式场景、可以继续保持无状态应用 | 大量的布隆过滤器查询请求，会增加 Redis 的 I/O 压力，同时布隆过滤器还占用一定的 Redis 内存。 |

###### Guava实现

```java
// 构造布隆过滤器
BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01);
// 将号码10086插入到布隆过滤器中
bloomFilter.put("10086");
// 使用布隆过滤器进行判断
System.out.println(bloomFilter.mightContain("123456"));
System.out.println(bloomFilter.mightContain("10086"));
```

###### Redisson实现

```java
// 构造Redisson
RedissonClient redisson = Redisson.create(config);
// 构造布隆过滤器
RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
// 初始化布隆过滤器：预计元素为100000000L,误差率为3%
bloomFilter.tryInit(100000000L,0.03);
// 将号码10086插入到布隆过滤器中
bloomFilter.add("10086");
// 使用布隆过滤器进行判断
System.out.println(bloomFilter.contains("123456"));// false
System.out.println(bloomFilter.mightContain("10086"));// true
```

##### 使用场景

主要应用于大规模数据下，**不需要精确过滤**的场景，如检查垃圾邮件地址，爬虫URL地址去重，以及解决**缓存穿透**等问题：

###### 白名单 | 解决缓存穿透、开放转载权限

由于布隆过滤器的存在，可以拦截大部分非白名单内的key，基本解决**缓存穿透**问题。

- **执行过程**：

  1. 服务器启动时，会先把所有key加载到布隆过滤器中，然后客户端请求服务器，会先根据key查询布隆过滤器。
  2. 如果布隆过滤器查询结果为true，代表key可能存在白名单中，则查询Redis。
  3. 如果Redis查询结果不为null，说明该key存在缓存中，则直接返回缓存数据，不需要查询数据库了。
  4. 如果Redis查询结果为null，说明该key不存在缓存中，则继续查询数据库。
  5. 如果数据库查询结果不为null，说明该key是合法，且布隆过滤器没有误判，则把数据查询结果存进Redis中，更新缓存后再返回数据。
  6. 如果数据库查询结果为null，说明这个key是个非法的key（根据业务而定），此时按理应该把key从布隆过滤器删掉，但布隆过滤器存在误判，且删除困难，所以这里对其不做处理（业务允许时），最后返回null。

  ![1632043975276](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632043975276.png)

- **注意点**：服务器启动时，需要把所有key都存到布隆过滤器里，不然所有请求都会返回空数据。

- **局限**：布隆过滤器存在误判，会有少量请求穿透到数据库中。

  - **解决方案**：误判的几率很小，问题不大无需处理。

###### 黑名单 | 视频不重复推送

由于布隆过滤器的存在，可以拦截大部分黑名单内的key，而初次不能拦截，因为需要初始化。

- **执行过程**：与白名单类似，但不同的地方在于：

  1. 服务器启动后，布隆过滤器一开始为空，没有任何的key，需要判断到黑名单才会填充进来，而白名单的是必须在服务器启动前全部key都设置完成。
  2. 如果布隆过滤器判断到key不存在时，才允许查询Redis和数据库，而白名单的是存在才允许查询。
  3. 如果数据库查询结果为null，说明这个key是个非法的key（根据业务而定），这时需要填充回布隆过滤器中，待下次布隆过滤器判断时使用，而白名单的是不做任何处理。

  ![1632044944582](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632044944582.png)

- **局限**：

  - 黑名单要很全，不然一开始会存在大量的缓存穿透请求。
    - **解决方案**：在判断为非法key时，加入布隆过滤器的黑名单中。
  - 布隆过滤器存在误判，会有少量正常请求被意外拦截掉，返回空的数据。
    - **解决方案**：业务允许则无需处理，比如视频推送。

### 1.5. Redis事务？

#### 概念

- Redis事务，本质上是一组命令的集合，可以一次执行多个命令，在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会被插入到事务执行命令序列中。
- 总结来说就是，Redis事务是**一次性、顺序性、排他性地执行**一个队列中的一系列命令，整个操作是一个原子操作，事务中的命令要么全部被执行，要么全部都不执行。

#### 事务特性

- **隔离性**：
  - Redis的事务总是具有ACID中的**一致性和隔离性**。
  - 事务是一个单独的隔离操作，事务期间所有命令都会序列化、按顺序地执行，并且在执行的过程中，不会被其他客户端发送来的命令请求所打断。
- **一致性**：Redis的事务总是具有ACID中的**一致性和隔离性**。
- **持久性**：当服务器运行在AOF持久化模式下，并且 `appendfsync` 选项的值为 `always` 时，事务也具有持久性。
  - 如果Redis服务器因为某些原因被管理员杀死，或者遇上某种硬件故障，那么可能只有部分事务命令会被成功写入到磁盘中，这种情况下，Redis在重新启动时发现 AOF 文件出了这样的问题，那么它会退出，并汇报一个错误。
  - 可以使用 `redis-check-aof` 程序可以修复这一问题：它会移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。
- **不保证原子性**：虽然Redis事务操作是一个原子操作，但 EXEC执行过程中，如果有一条命令执行失败，其后的命令仍然会被执行，不会进行回滚，因此不保证事务的原子性。

事务命令

Redis事务功能是通过 `MULTI`、`EXEC`、`DISCARD` 和 `WATCH` 四个原语实现的。

- **MULTI**：用于开启一个事务，它总是返回OK，在 `MULTI` 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当 `EXEC`命令被调用时，所有队列中的命令才会被执行。
- **EXEC**：执行所有事务块内的命令，返回事务块内所有命令的返回值，按命令执行的先后顺序排列；当操作被打断时，返回空值 `nil` 。
- **WATCH** ：是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为，监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控会一直持续到 `EXEC` | `DISCARD` | `UNWATCH` 命令。
- **DISCARD**：调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。
- **UNWATCH**：命令可以取消 `WATCH` 命令对所有key的监控。

| 命令    | 使用               | 作用                                                         |
| ------- | ------------------ | ------------------------------------------------------------ |
| MULTI   | multi              | 开启事务，标记一个事务的开始                                 |
| EXEC    | exec               | 执行事务，一次执行事务内的所有命令，如果事务被打断，则返回nil，否则按顺序返回命令执行结果 |
| DISCARD | discard            | 取消事务，放弃执行事务块内的所有命令                         |
| WATCH   | watch key [key...] | 监视一个或者多个key，如果事务执行前，这些key被其他命令改动，那么事务将会被打断 |
| UNWATCH | unwatch            | 取消watch命令对key的监视，如果该事务执行了exec或者discard命令，则无需unwatch了 |

#### 事务中的错误

- **命令入队前出错**：事务在执行 `EXEC` 命令前，入队的命令可能会出错，比如命令可能会产生语法错误等，或者其他更严重的错误，比如内存不足等。
  - **Redis应对措施**：
    1. 在 Redis 2.6.5 以前， 客户端的做法是，检查命令入队所得的返回值：如果命令入队时返回`QUEUED` ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会**停止并取消**这个事务。
    2. 从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 `EXEC` 命令时，**拒绝执行**并自动放弃这个事务。
- **命令入队后出错**：命令可能在 EXEC 调用之后出错，比如事务中的命令可能处理了错误类型的键：列表命令用在了字符串键上面等等。
  - **Redis应对措施**：在事务中某些命令在 `EXEC` 执行时产生了错误，Redis并不会对它们进行特别处理，而是让其他命令**继续执行**，因而无法保证事务的原子性。

#### 为什么Redis事务不支持回滚？

- **描述**：当事务执行过程中，遇到入队后出错的命令，Redis 并不会进行回滚，而是继续执行其他命令。
- **原因**：
  - **从实用性的角度来说**：入队后出错的命令都是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。
  - **从回滚功能的角度来说**：回滚并不能解决编程错误带来的问题，比如程序员本来想通过 `INCR key` 命令将键的值加上 `1` ， 却不小心调用了两次加上了 `2`，或者对错误类型的键执行了`INCR key`，回滚是没有办法处理这些情况的。
  - 因此，鉴于没有任何机制能避免程序员**自己造成的错误**， 并且这类错误通常不会在生产环境中出现，所以，Redis 选择了更简单、更快速的无回滚方式来处理事务。
- **优点**：由于无需对回滚进行支持，所以 Redis 内部可以保持简单且快速。

### 1.6. Redis key过期机制？

- **永久 key**：在没有指定过期时间的情况下创建，这种 key 将永远存在，除非以明确的方式将其删除，比如使用 `DEL` 命令。

- **可过期 key**：`EXPIRE` 命令，通过增加一些额外的内存成本，为 key 指定一个过期时间，当一个 key 设置了过期时间后，Redis 将确保在指定的时间段过去后，删除这个 key。

- Redis 同时使用 2 种 **key 过期机制**：

  - **被动方式**：当客户端尝试访问某个 key 时，如果发现该 key 已超时，则该 key 才会被动地过期与删除。

    - **对内存不友好**：虽然存在 key 超时后，如果永远没有被访问，那么它就不会被删除，永远地占用着服务器的内存。

  - **主动方式**：Redis 默认每秒 10 次（可在 `hz 10` 中配置），进行以下随机测试：

    1. 在可过期 key 集合中，随机测试 20 个 key。
    2. 删除所有发现已过期的 key。
    3. 如果超过 25% 的 key 都已过期，则继续以上循环。

    => 这意味着在任何时刻，过期 key 所能占用的最大内存 = 每秒新写入 key 所占用的内存之和 / 4，即过期 key 最多只会占用 1/4 的内存。

### 1.7. Redis内存淘汰策略？

- **内存淘汰机制**：使用 Redis，可以方便地在客户端添加新数据时，自动淘汰旧数据。其中，LRU 是 Redis 支持的淘汰方法之一，从 Redis 4.0 版本开始，引入了新的 LFU 淘汰方法。

  - **LRU**：Least Recently Used，最近最少使用淘汰算法，用于淘汰**最长时间没有被访问**的旧数据。
  - **LFU**：Least Frequently Used，最不经常使用淘汰算法，用于淘汰**在一段时间内访问次数最少**的旧数据。

- **内存淘汰策略**：指当达到指定的 `maxmemory` （默认为 0，代表没有限制）内存量时，可以在不同的行为中进行选择需要淘汰的旧数据。

  - 当 `maxmemory` 达到限制时，发生的内存淘汰策略是根据 `maxmemory-policy` 配置来指定的。

  | 策略                     | 作用对象   | 客户端请求发现内存不足时                                     | 适用场景                                            |
  | ------------------------ | ---------- | ------------------------------------------------------------ | --------------------------------------------------- |
  | noeviction               | 全局 key   | 会返回错误                                                   | 常量字典，不能淘汰任何 key 时                       |
  | allkeys-lru              | 全局 key   | 会先尝试删除 LRU key                                         | 热点缓存，需要淘汰非热点 key 时                     |
  | volatile-lru             | 可过期 key | 会先尝试删除 LRU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 热点缓存，需要淘汰非热点 key，又需要保护永久 key 时 |
  | allkeys-random           | 全局 key   | 会随机淘汰 key                                               | 需要以相同概率去淘汰 key 时                         |
  | volatile-random          | 可过期 key | 会随机淘汰 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要以相同概率去淘汰 key ，又需要保护永久 key 时    |
  | volatile-ttl             | 可过期 key | 会先尝试删除剩余 TTL 最短的 key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要根据过期时间去淘汰 key 时                       |
  | allkeys-lfu（4.0 版本）  | 全局  key  | 会先尝试删除 LFU key                                         | 需要淘汰访问次数少的 key 时                         |
  | volatile-lfu（4.0 版本） | 可过期 key | 会先尝试删除 LFU key，但仅限于可过期 key，如果没有任何可过期 key，则会返回错误 | 需要淘汰访问次数少的 key，又需要保护永久 key 时     |

### 1.8. Redis分布式锁？

当发生高并发访问量激增时，虽然在系统会通过限流、异步、排队等方式优化，但整体的并发还是平时的数倍以上，为了避免并发问题，**防止库存超卖**，给用户提供一个良好的购物体验，这些系统中都会用到锁的机制。

- **背景**：

  - 对于单进程的并发场景，可以使用编程语言及相应的类库提供的锁，如 Java 中的 synchronized 语法以及 ReentrantLock 类等，来避免并发问题。

  ![1632658813782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632658813782.png)

  - 而如果在分布式场景中，实现**不同客户端**的线程对代码和资源的同步访问，保证在多线程下处理共享数据的安全性，就需要用到分布式锁技术。

  ![1632658861088](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632658861088.png)

- **概念**：分布式锁是指，控制分布式系统或者不同系统之间，**共同访问共享资源**的一种锁实现，在不同的系统或者同一个系统的不同主机之间共享了某个资源时，可以用来互斥地防止彼此干扰保证一致性。

- **特性**：

  - **互斥性**：互斥是锁的基本特征，同一时刻锁只能被一个线程持有，执行临界区操作。
  - **超时释放**：通过超时释放，可以避免死锁，防止不必要的线程等待和资源浪费。
  - **可重入性**：一个线程在持有锁的情况下，可以对其再次请求加锁。
  - **高性能和高可用**：加锁和释放锁的过程性能开销要尽可能的低，同时也要保证高可用，防止分布式锁意外失效。

- **实现方式**：

  - **通过数据库方式实现**：基于乐观锁和唯一索引实现。
  - **基于分布式缓存实现**： 基于 Memcached、Redis 单机、Redisson 和 Redis RedLock 实现。
  - **基于分布式一致性算法实现**：基于ZooKeeper、Chubby（google闭源实现）和 Etcd 实现。

#### 基于数据库实现 | 负担大

##### 基于乐观锁实现

- **原理**：根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。

##### 基于唯一索引实现

- **原理**：数据库建立唯一索引，当想要获得锁时，向数据库中插入一条记录，释放锁时则删除这条记录。
- **存在的问题**：
  1. 锁没有失效时间，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
  2. 只能是非阻塞锁，insert 失败直接就报错了，无法进入队列进行重试。
  3. 不可重入，同一线程在没有释放锁之前无法再获取到锁。

#### 基于分布式缓存实现 | 锁失效

##### 基于 Memcached 实现

- **原理**：利用 Memcached 的 `add` 命令，由于该命令原子性操作，只有在 key 不存在的情况下，才能 add 成功，也就意味着同一时刻只有一个线程获得锁。

##### 基于 Redis 单机实现

###### 1、使用 setnx 指令

- **原理**：

  ```shell
  setnx key value
  	do do something
  del key
  ```

- **存在的问题**：do something 有问题，锁一直不会释放，因此需要增加锁的过期时间。

###### 2、使用 setnx+expire 指令

- **原理**：

  ```shell
  setnx key value
  expire key 10
  	do do something
  del key
  ```

- **存在的问题**：`setnx` 与 `expire` 不是一个原子操作，如果在执行 `setnx` 和 `expire`  之间发生异常，`setnx` 执行成功，但 `expire` 没有执行，则会导致这把锁在长期存在，导致其他进程无法正常获取锁。

###### 3、使用 set 扩展指令

- **原理**：

  ```shell
  set key value NX EX 10
  	do something
  del key
  ```

- **存在的问题**：如果 do something 耗时过长，会出现锁被提前释放，甚至被别的进程误删。

- **解决方案**：

  1. do something 部分不要做过长时间的处理，但还是可能存在 STW 的停顿风险。
  2. 释放锁时，需要验证锁的持有者是否是自己。

###### 4、释放前判断值是否改变

- **原理**：

  ```shell
  set key random_value nx ex 10 # 加锁
  	do something
  if random_value == key.value  # 判断 value
  	del key 			      # 删除 key
  ```

- **存在的问题**：判断 value 和删除 key 两个操作不能保证原子性。

- **解决方案**：需要使用 Lua 脚本进行处理，因为 Lua 脚本可以保证连续多个指令的原子性执行。

###### 5、使用 lua 脚本

- **原理**：

  ```lua
  if redis.call("get", KEY[1]) === ARGV[1] then
      return redis.call("del", KEY[1])
  else 
      return 0
  end
  ```

- **存在的问题**：还是会出现，由于时钟漂移 或者 do something 耗时过长，导致的锁被提前释放，甚至被别的进程误删的问题。

- **解决方案**：锁租期续约。

##### 基于 Redisson 实现

Redisson，是一个在 Redis 的基础上实现的 Java 驻内存数据网格，是一个分布式、可扩展的 Java 数据结构。

- **原理**：
  1. 让获得锁的线程开启一个定时器的守护线程，每 expireTime/3 执行一次，去检查该线程的锁是否存在。
  2. 如果存在，则对锁的过期时间重新设置为 expireTime，即利用守护线程对锁进行**续约**，防止锁由于过期提前释放。
  3. 对于Redis 多机环境的分布式锁，Redisson 也提供了 Red Lock的算法实现。

##### 基于 Redis RedLock 实现

- **背景**：基于 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 的复制是异步的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下发生故障转移，此时其他客户端上的线程依然可以获取到锁，因此会丧失锁的安全性。
- **原理**：
  1. 获取当前 Unix 时间 `t1`，以毫秒为单位。
  2. 按顺序依次尝试从 5 个实例使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁自动失效时间 `expire`，客户端还应该设置响应超时时间 `timeout`，且这个超时时间 < 锁的失效时间 `expire` 。
     1. 比如锁自动失效时间 `expire` 为10秒，则超时时间 `timeout` 应该在5-50毫秒之间。
     2. 这样可以避免服务器端 Redis 已经挂掉的情况下，客户端还在一直等待响应结果，使得在服务器端没有在规定时间内响应时，客户端可以尽快尝试去另外一个 Redis 实例请求获取锁。
  3. 客户端使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从大多数（N/2+1，这里是3个节点）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` < 锁失效时间 `expire`时，锁才算获取成功。
  4. 如果取到了锁，key 的真正有效时间 `real_expire` 等于锁失效时间 `expire  `减去锁花费的总时间 `T`。
  5. 如果因为某些原因，获取锁失败（没有在至少N/2+1个 Redis 实例取到锁，或者取锁时间已经超过了锁失效时间 `expire），客户端应该在所有的 Redis 实例上使用 Redis Lua 脚本进行解锁。
     1. 原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端向服务器通信是正常的，但反方向却是有问题的。
     2. 虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功。
     3. 因此，释放锁的时候，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起请求。
     4. 除此之外，为了避免 Redis 节点发生崩溃重启后造成锁丢失，从而影响锁的安全性，Redis 官方还提出了**延时重启**的概念，即一个节点崩溃后不要立即重启，而是等待一段时间后再进行重启，这段时间应该大于锁失效时间 `expire  `。
- **局限**：
  - **性能过重**：使用 RedLock 维护那么多的Redis实例，提升了系统的维护成本。
  - **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生错误，会导致它持有的锁提前过期然后被释放，因此，RedLock 还是不能保证锁的安全性。

##### Redis 分布式锁总结

- **存在的问题**：
  - **客户端长时间阻塞导致锁失效问题**：比如执行业务时间过长，或者发生了 STW。
    - **解决方案**：锁租期续约，在锁有效时间内，异步启动另外一个线程去检查的问题，判断这个 key 是否超时，如果锁超时时间快到期且逻辑未执行完，则延长锁超时时间。
  - **服务器时钟漂移问题导致同时加锁**：由于 Redis 的过期时间是依赖系统时钟的，如果时钟漂移过大时，理论上是可能出现的会影响到过期时间的计算。
    - **解决方案**：根据时间来自动释放的分布式锁，都没办解决这个问题。
  - **单点实例故障，锁未及时同步导致锁丢失**：
    1. 虽然使用 RedLock 算法，可以通过多节点来防止 Redis 的单点故障，但效果一般，且仍然无法防止在**主从切换**导致的两个客户端同时持有锁的发生。
    2. 但在大部分情况下，主从切换持续时间极短，RedLock 会在切换的瞬间获取到节点的锁，虽然也是有问题发生的可能，但这已经是极低的概率了，无法避免。
    3. 因此，Redis 分布式锁适合**幂等性**事务，如果一定要保证安全，应该使用 Zookeeper、ETCD 或者 DB，但是，锁的性能会急剧下降。

#### 基于分布式一致性算法实现 | 强一致

##### 基于 Zookeeper 实现

Zookeeper，是一个为分布式应用提供一致性服务的软件，它内部是一个分层的文件系统目录树结构，规定统一个目录下**只能有一个唯一文件名**。

- **概念**：
  - **数据模型**：
    - **永久结点**：结点创建后，不会因为会话失效而消失。
    - **临时结点**：与永久结点相反，如果客户端连接失效，则立即删除结点。
    - **顺序结点**：与上述两个结点特性类似，如果指定创建这类结点时，ZK 会自动在结点名后加一个数字后缀，并且是有序的。
  - **监视器**：watcher，当创建一个节点时，可以注册一个该结点的监视器，当节点状态发生改变时，watcher 被触发时，ZooKeeper 会向客户端发送且仅发送一条通知（因为 watcher 只能被触发一次）。
- **原理**：
  1. 创建一个锁目录 lock。
  2. 希望获得锁的线程 A 就在 lock 目录下，创建**临时顺序结点**。
  3. 先获取锁目录下所有的子结点，再获取比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则 线程 A 获得锁。
  4. 接着，线程 B 获取所有结点，判断自己不是最小的结点，此时发现存在有更小的线程 A 的结点，则设置监听器 watcher，只监听比自己次小的结点 A（为了防止发生**羊群效应**）。
     - **分布式中的羊群效应**：也称惊群效应，指在分布式系统中，比如Zokeeper集群中，当某一结点 A 被大量 Client 进行Watch 时，当结点 A 发生变化时，可能只会对某一个 Client 有影响，但是由于所有 Client 都对该结点进行了 watch，其他没有影响的 Client 也会受到通知，因此，对于产生了这种**不必要的通知**就是分布式中的羊群效应。
  5. 当线程 A 处理完业务，会删除结点 A，释放掉，然后线程 B 监听到变更事件，判断到自己是最小的结点，成功获得锁。

##### 基于 Chubby 实现

- **原理**：Google 公司实现的**粗粒度**分布式锁服务，有点类似于 ZooKeeper，但也存在很多差异，通过 sequencer 机制解决了**请求延迟**造成的锁失效的问题。

##### 基于 Etcd 实现

- **概念**：
  - **Lease 机制**：租约机制，Etcd 可以为存储的 KV 对设置租约，当租约到期，KV 将失效删除，同时支持续约，即 KeepAlive。
  - **Revision 机制**：
    1. 每个 key 带有一个 Revision 属性值，Etcd 每进行一次事务对应的全局 Revision 值都会加 1。
    2. 因此，每个 key 对应的 Revision 属性值都是全局唯一的，通过比较 Revision 的大小就可以知道进行写操作的顺序。
    3. 在实现分布式锁时，多个程序同时抢锁，根据 **Revision 值大小**依次获得锁，可以避免**羊群效应**，实现公平锁。
  - **Prefix 机制**：前缀机制，也称目录机制，可以根据前缀（目录），来获取该目录下所有的 key 及对应的属性（包括 key, value 以及 revision 等）。
  - **Watch 机制**：监听机制，Watch 机制支持 Watch 某个固定的 key，也支持 Watch 一个前缀（目录），当被 Watch 的 key 或目录发生变化，客户端将收到通知。
- **原理**：
  1. **准备 key**：客户端连接 Etcd，以 `/lock/mylock` 为前缀创建**全局唯一**的 key。
     - 假设第一个客户端对应的 key="/lock/mylock/UUID1"，第二个为 key="/lock/mylock/UUID2"，客户端分别为自己的 key 创建租约 Lease，租约的长度根据业务耗时确定，假设为 15s；
  2. **写入 key**：进行 put 操作，将步骤 1 中创建的 key 绑定租约写入 Etcd，根据 Etcd 的 Revision 机制，假设两个客户端 put 操作返回的 Revision 分别为 1、2，客户端需记录 **Revision** 用以接下来判断自己是否获得锁。
  3. **获取锁**：
     1. 客户端以前缀 `/lock/mylock` 读取 keyValue 列表，其中 keyValue 中会带有 key 对应的 Revision。
     2. 接着判断自己 key 的 Revision 是否为当前列表中**最小**的，如果是则认为获得锁。
     3. 否则，需要监听列表中前一个 Revision 比自己小的 key 的**删除事件**，一旦监听到删除事件，或者因租约失效而删除的事件，则自己获得锁。
  4. **执行业务**：获得锁后，操作共享资源，执行业务代码。
  5. **心跳续约**：
     1. 当一个客户端持有锁期间，其它客户端只能等待，为了避免等待期间租约失效，持有锁的客户端需创建一个定时任务，作为**心跳**进行续约。
     2. 如果持有锁期间客户端崩溃，心跳停止，key 将因**租约到期**而被删除，从而锁释放，**避免死锁**。
  6. **释放锁**：完成业务流程后，删除对应的key释放锁。

#### 分布式锁总结

- **数据库锁**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：分布式系统大多数瓶颈都在数据库，使用数据库锁会增加数据库负担。
- **分布式缓存锁**：
  - **优点**：性能高，实现起来较为方便，在**允许偶发的锁失效**情况，不影响系统正常使用，建议采用分布式缓存锁。
  - **缺点**：通过锁超时机制不是十分可靠，当线程获得锁后，处理时间过长导致锁超时，就失去了锁的作用。
    - 当业务必须要数据的强一致性，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下请不要使用分布式缓存锁，此时可以使用 CP 模型实现，比如Zookeeper 和 Etcd。
- **分布式一致性算法锁**：
  - **优点**：不依靠超时时间释放锁，可靠性高，当系统要求高可靠性时，建议采用分布式一致性算法锁。
  - **缺点**：性能比不上分布式缓存锁，因为无论是 Zookeeper 还是 Etcd，都需要频繁的创建和删除结点。

|            | Redis    | Zookeeper                       | Etcd                            |
| ---------- | -------- | ------------------------------- | ------------------------------- |
| 一致性算法 | 弱一致性 | Paxos（ZAB）                    | Raft                            |
| CAP        | AP       | CP                              | CP                              |
| 高可用     | 主从集群 | n+1（保证奇数，过半存活即可用） | n+1（保证奇数，过半存活即可用） |
| 实现       | setnx    | createNode                      | restfulAPI                      |

### 1.9. Redis持久化？

持久化，就是把内存中的数据，持久化到本地磁盘中，防止服务器宕机了内存数据丢失。

- Redis 提供两种持久化机制 **RDB（默认）** 和 **AOF**，Redis 4.0 以后采用混合持久化，用 AOF 来**保证数据不丢失**，作为数据恢复的第一选择，用 RDB 来做不同程度的**冷备**。

#### RDB

RDB，Redis DataBase，是Redis**默认**的持久化方式，Redis 会按照一定的时间间隔，将内存的数据以**时间点快照、二进制**的形式保存到磁盘中。

##### 特点

- 只会产生一个数据文件，为dump.rdb。
- 可以通过配置文件中的 `save` 参数，来定义快照生成周期。

##### 生成方式

- **`SAVE` 命令**：会阻塞当前 Redis 主线程，直到持久化完成。线上应该禁止使用，要使用也需要先明确时间点，再关机维护。
- **`BGSAVE` 命令**：
  1. Redis 调用 `fork（） `一个子进程，同时拥有父进程和子进程。
  2. 父进程继续处理其他命令，子进程负责持久化过程，将数据集写入到一个临时 RDB 文件中。
     - **写时复制**：Copy On Write，COW，指的是，为了节约物理内存，操作系统在调用 `fork()` 生成子进程时，子进程与父进程会**共享同一内存区域**，只有当其中父子中任意一个进程进行写操作时，操作系统才会为其另外分配内存页面。其中，子进程与父进程是两个独立的进程，在父进程结束后，子进程并不会结束，而是会被 `init` 进程托管。**原理如下**：
       1. 当进程 A 使用系统调用 `fork()` 创建一个子进程 B 时，由于子进程 B 实际上是父进程A的一个拷贝，因此会拥有与父进程相同的物理页面。
       2. 为了节约内存和加快创建速度的目标，`fork()` 函数会让子进程 B 以**只读方式**共享父进程A的物理页面，同时，也将父进程 A 对这些物理页面的访问权限设置成**只读**。
       3. 这样，当父进程 A 或子进程 B 任何一方对这些已共享的物理页面执行写操作时，都会产生页面出错异常 `page_fault int14` 中断，此时 CPU 会执行系统提供的异常处理函数`do_wp_page()` 来解决这个异常。
       4. `do_wp_page()` 会对这块导致写入异常中断的物理页面进行**取消共享操作**，为写进程复制一新的物理页面，使父进程 A 和子进程 B 各自拥有一块内容相同的物理页面。
       5. 最后，在从异常处理函数中返回后，CPU会重新执行刚才导致异常的写入操作指令，使陷入异常的进程继续执行下去。
     - **Redis 与写时复制**：根据 Copy On Write 技术可知， `fork()` 操作并不会导致生成 RDB 时内存的暴涨。
       1. 因为只有父进程发生写操作修改内存数据时，才会真正去给子进程分配内存空间，并只是复制父进程中被修改过的内存页中的数据，并不是全部的内存数据。
       2. 对于那些没有写操作的数据，子进程会共享父进程同一段内存。
       3. 因此，`fork()` 操作是不会导致内存暴涨的。
  3. 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。

##### 生成周期配置

save参数。

```shell
# 900秒（15分钟）内数据集至少有1个改动
save 900 1
# 300秒（5分钟）内数据集至少有10个改动
save 300 10
# 60秒（1分钟）内数据集至少有10000个改动
save 60 10000
```

##### 其他参数

```shell
# save、bgsave期间，如果出错，是否停止继续生成RDB
# yes：停止
# no：不停止，但可能会造成数据不一致
stop-writes-on-bgsave-error

# 是否压缩RDB文件
# yes：开启
# no：关闭，可以节省CPU消耗，但可以减小RDB大小
rdbcompression

# 是否校验RDB文件
# yes：使用CRC 64算法对RDB数据进行校验，但会有10%左右的性能损耗
# no：不校验
rdbchecksum
```

##### 优点

- **适合备份**：RDB 保存了 Redis 在某个时间点上的数据集，非常适合用于备份。
- **适合灾备**：RDB 只有一个文件，并且内容都非常紧凑，可以远程传输到别的数据中心，灾备简单，非常适用于灾难恢复。
- **影响 Redis 性能小**：RDB 可以最大化减少对 Redis 性能的影响，在保存 RDB 文件时，父进程唯一要做的就是 `fork` 出一个子进程，然后交由子进程处理接下来所有的保存工作，父进程无须执行任何磁盘 I/O 操作，从而可以保证主进程继续处理命令，RDB 时只存在毫秒级不响应请求。
- **恢复速度快**：RDB 相对 AOF 来说，在恢复大数据集时，速度比 AOF 的恢复速度要快。

##### 缺点

**数据安全性低**，RDB 是间隔一段时间进行持久化，如果间隔前进，Redis 发生故障，则会发生数据丢失。

#### AOF

AOF，Append Only File，记录 Redis 服务器执行的所有**写操作命令**，并在服务器启动时，通过重新执行这些命令来还原数据集。

##### 特点

- AOF 文件中的命令，会全部以 Redis 协议的格式来保存，新命令会被**追加**到文件的末尾。 
- 可以在后台对 AOF 文件进行**重写**，使得 AOF 文件的体积，不会超出保存数据集状态所需的实际大小。

##### 写入与同步参数

```shell
# AOF默认关闭，yes可以开启
appendonly no
# AOF的文件名
appendfilename "appendonly.aof"

#appendfsync always
appendfsync everysec
#appendfsync no
```

- **appendfsync always**：命令写入 aof_buf 后，直接调用系统的 `fsync` 操作同步到 AOF 文件中，真正的把指令写入了磁盘中。
  - **aof_buf**：AOF 缓冲区，打开 AOF 开关后，每次执行完一个写命令后，都会把写命令以 Redis 协议的格式保存到 aof_buf 缓冲区中。
  - **特点**：由于 AOF 每次都会同步落盘，所以优点是**数据不会丢失**，缺点是**效率低**。
- **appendfsync everysec**：命令写入aof_buf 后，调用系统的 `write` 操作，把 aof_buf 缓冲区的内容写入到 AOF 文件中， 然后在`write` 操作完成后返回；而`fsync` 同步 AOF 文件的操作，将由专门的线程每秒调用一次。
  - **特点**：对 always 和 no 方案，在**数据安全性**和**性能**上做了折衷。
- **appendfsync no**：命令写入 aof_buf 后，调用系统的 `write` 操作，把 aof_buf 缓冲区的内容写入到 AOF 文件中，然后在`write` 操作完成后返回；不对 AOF 文件做 `fsync` 同步操作，交由操作系统负责。
  - **操作系统同步条件**：缓冲区被填满，或者，超过了同步周期限制，通常同步周期限制最长为30秒。
  - **特点**：与 always方案相反，是另一个极端，这种方案由于 Redis 不保证 AOF 的落盘，所以保证不了数据安全性。

![1632132586785](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632132586785.png)

##### 备份流程

1. 处理客户端**写命令**请求，处理完毕后，响应客户端请求。
2. 接着处理时间事件，Redis 将 `serverCron` 作为时间事件运行，定期自动运行一次，比如尝试进行 AOF 或者 RDB 持久化等操作。
3. 然后判断是否打开 `appendonly`，如果为是，则把**写命令**写入 aof_buf 缓冲区，并根据 `appendfsync` 策略同步到磁盘中；如果为否，则结束 AOF 备份流程。

![1632135630382](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632135630382.png)

##### 重写流程

```shell
# AOF重写机制的触发参数：
# 当前AOF文件的大小是上次AOF大小的100%，且文件体积达到64m时，则触发AOF重写
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

```

1. 当前 AOF 文件的大小是上次 AOF 文件大小的100%，且文件体积达到 64m时，则触发 AOF 重写；或者显示调用 `BGREWRITEAOF` 命令，也会触发 AOF 重写。
2. 此时，Redis 执行 `fork()` ，同时拥有父进程和子进程。
3. 子进程开辟 AOF 重写缓冲区，并开始执行 AOF 重写，根据 `fork()`写时复制机制，子进程只能共享 `fork()`时的内存数据，此时子进程会根据内存快照，按照**命令合并规则**把重写后的命令写入到新 AOF 文件。
4. 父进程继续处理其他命令，对于所有新执行的写入命令，父进程一边把这些改动，追加到旧 AOF 文件的末尾，并根据 `appendfsync` 策略同步到磁盘中，一边把它们累积到重写缓冲区中，这样即使在重写的中途发生了停机，旧 AOF 文件也还是安全的。
5. 当子进程完成重写工作时，会给父进程发送一个信号，父进程在接收到信号之后，阻塞服务器进程，拒绝所有命令，同时把重写缓冲区中的所有数据，追加到新 AOF 文件的末尾。
6. 最后原子地用新 AOF 文件替换旧 AOF 文件，再恢复服务器进程，之后所有命令都会追加到新 AOF 文件的末尾，完成一次 AOF 的重写。

![1632138509700](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632138509700.png)

##### 还原流程

1. Redis 服务启动时，会先创建 Fack Client 伪客户端，该客户端不会发送网络请求，只是用来读取 Redis 配置文件。
2. 接着判断 AOF 文件中是否存有数据，如果没有，则结束 AOF 还原流程。
3. 如果有，则分析、读取、执行 AOF 文件中的每一条指令，直到 AOF 中的指令全部被执行完毕后，则结束 AOF 还原流程。
4. Redis 还可以同时使用 AOF 和 RDB 持久化，在这种情况下，会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集，通常比 RDB 文件所保存的数据集更完整。

![1632138046711](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632138046711.png)

##### 优点

- **持久化实时性好**：AOF 可以根据不同的 fsync 策略来持久化，默认为 `always`，表示每秒钟 fsync 一次，Redis 仍然可以保持良好的性能，就算发生故障停机，最多也只是丢失一秒钟的数据。
- **顺序写，写入效率高**：AOF 文件是一个只进行追加操作的日志文件， 对 AOF 文件的写入不需要进行 seek，顺序写即可，所以写入效率高。
- **AOF重写**：Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的**最小命令集合**。 
- **简单易懂**：AOF 文件写入的命令，会以 Redis 协议的格式进行保存， 其内容非常容易被人读懂， 对文件进行分析会比较轻松。 

##### 缺点

- **体积较大，恢复速度慢**：对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积，且恢复速度也会比 RDB 的慢。
- **可能会影响 Redis 性能**：针对不同的同步机制，AOF 会比 RDB 慢，由于 AOF 每秒都会备份做日志写操作，这样相对比 RDB 来说，性能就略低，比如每秒备份 fsync，如果客户端每秒的写入都做一次 fsync 备份的话，那么 Redis 的性能就会下降。

#### RDB & AOF如何选择？

|                        | RDB                                           | AOF                                                  |
| ---------------------- | --------------------------------------------- | ---------------------------------------------------- |
| 文件内容               | 全量的二进制数据                              | 按Redis 协议格式保存的写命令                         |
| 文件体积               | 较小                                          | 较大，同时提供 AOF 重写                              |
| 数据恢复速度           | 快                                            | 慢                                                   |
| 对Redis 性能的影响程度 | 子进程备份时间间隔较远，对 Redis 性能影响较小 | 如果子进程每秒都做 AOF 同步，则对 Redis 性能影响较大 |
| 适用场景               | 按照时间间隔备份，适合冷备                    | 实时性好，适合热备                                   |

##### 仅使用 RDB

如果可以承受一段时间内的数据丢失， 那么可以只使用 RDB 持久化。

##### 仅使用 AOF

**不推荐**，因为定时生成 RDB 快照非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外，使用 RDB 还可以避免之前 AOF 程序的 bug 。

- AOF 在过去曾经发生过这样的 bug： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样，比如阻塞命令 `BRPOPLPUSH` 。
- 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。

##### 同时使用 AOF 和 RDB

如果对实时性数据比较关心，则应该同时使用两种持久化功能。

1. 使用 RDB 和 AOF 结合一起做持久化，**RDB 做冷备**，可以在不同时期对不同版本做恢复， **AOF 做热备**，保证数据仅仅只有1秒的损失。
2. 当 AOF 破损不可用时，那么再用 RDB 恢复，这样就做到了两者的相互结合，也就是说 Redis 恢复会先加载 AOF，当 AOF 有问题时再加载 RDB，从而达到**冷热备份**的目的。
   - **冷备份**：一般发生在数据库已经正常关闭的情况下，当正常关闭时，会提供给我们一个完整的数据库，但冷备份的数据往往不够实时。
   - **热备份**：是在数据库运行的情况下，采用archivelog mode（归档日志模式）方式备份数据库的方法，其备份的数据具有很好的实时性。
   - **冷热备份**：在发生问题时，如果同时存在一个冷备份和不久的热备份文件，那么就可以利用这些资料来恢复更多的信息。

### 2.0. Redis数据分区？

![1632400451957](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632400451957.png)

#### 分区概念

在Redis中，数据分区（分片），是一种在多个 Redis 实例之间拆分数据的技术，将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。

#### 分区优点

- **带宽与算力的提升**：单机 Redis 的网络 I/O 能力和计算资源都是有限的，把请求分散到多台机器，可以充分利用多台机器的计算能力与网络带宽，有助于提高 Redis 总体的服务能力。
- **内存的横向扩展**：即使 Redis 的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的内存，把数据分散到多台机器上存储，使得 Redis 内存可以横向扩展。

#### 分区缺点

- **不支持跨实例的命令与事务**：涉及多个 key 的操作通常不会被支持，比如不能直接使用交集指令来对两个集合求交集，因为这些 key 可能被存储到不同的 Redis 实例中，同理，操作多个key时也不能使用Redis事务。
- **大 Key 数据集无法再分片**：由于是基于 key 进行数据分区的，因此无法使用单个大 key 对数据集进行分区，比如一个很大的排序集或列表，只能作为一个 key 存储进一个 Redis 实例中，而不能对其再分片。
- **备份管理要复杂得多**：数据分区后，如果需要对数据进行备份，则必须从不同的 Redis 实例同时收集 RDB 和 AOF 文件。
- **扩缩容时可能需要对数据再平衡**：数据分区后，在集群运行时增加或者删除 Redis 节点，对于散列分区方式，需要对数据进行再平衡，使用预分片可以较好地解决这个问题。
  - **预分片**：可以在刚开始时就开启多个 Redis 实例，比如 32 或 64 个实例来作为我们的工作集群，当一台物理机器内存不够时，可以把其中一些实例移动到第二台存储更大的物理机上，这样就可以保证在集群Redis 实例数不变的情况下，又达到了扩充机器内存的目的。

#### 分区方案

##### 范围分区

- **特点**：将分片规则对象范围映射到 Redis 实例。
  - 比如，从 ID 0到 ID 10000的用户将进入实例 R0，而从 ID 10001到 ID 20000的用户将进入实例 R1 等。
- **优点**：
  - **简单有效**。
  - **分片可顺序访问**：使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。
- **缺点**：
  - **数据分散度容易倾斜**：容易出现某分片过热的问题，即切分后热点数据可能都落在同一分片上，成为系统性能的瓶颈。
  - **需要管理映射表**：每种分片规则对象都需要管理一个将范围映射到 Redis 实例的表，对比其他分区方案效率低得多，因此，Redis 中的范围分区通常是不可取的。

##### 哈希分区

- **特点**：采用 hash 取模的切分方式。
  1. 获取 Key 并使用散列函数（比如 `crc32` 散列函数）将其转换为数字值。
  2. 对这个数字值使用模运算，将它转换成一个 0 到 3 之间的数字，映射到 4个 Redis 实例的其中一个。
- **优点**：**数据分散度高**：不容易出现热点和并发访问的瓶颈。
- **缺点**：**分片无法顺序访问**：容易面临跨分片查询的复杂问题。

###### 节点取余 | 数据迁移率大

![1632448521969](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632448521969.png)

- **概念**：hash（key）% node。
- **优点**：简单。
- **缺点**：数据迁移率大，当节点数量变化时，数据节点的映射关系需要重新计算，会导致数据的重新迁移。
  - **翻倍扩容**：扩容时通常采用翻倍扩容，可以避免数据映射被全部打乱，导致全量迁移的情况。
  - **一致性哈希**：可以减小影响的范围。
- **适用场景**：常用于数据库的分库分表规则，**不推荐**用于 Redis 数据分区。
  - 一般采用预分区的方式，提前根据数据量规划好分区数，比如提前划分为 512 或 1024 张表，保证可支撑未来一段时间的数据容量，再根据负载情况将表迁移到其他数据库中。

###### 一致性哈希 | 数据不均匀

![1632447059227](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632447059227.png)

- **概念**：hash（key） + 顺时针优化取余。
  1. 一致性 Hash 可以很好的解决稳定问题，可以将所有的存储节点排列在**首尾相接**的 Hash 环上。
  2. 每个key 在计算 Hash 后，会**顺时针**找到遇到的第一组存储节点来存放。
  3. 而当有节点加入或退出时，仅影响该节点在 Hash 环上顺时针相邻的后续节点，将数据从该节点接收或者给予。
- **优点**：加减节点只影响 Hash 环中顺时针方向的相邻节点，对其他节点无影响。
- **局限**：
  - **数据不均匀**：在节点太少时，容易出现节点分布不均匀，从而导致数据倾斜。
  - **数据未命中**：增加节点时，会造成 Hash 环中部分数据无法命中，需要进行手动处理。
  - **数据有迁移**：虽然只影响邻近节点，但仍然有数据迁移。
  - **需翻倍扩容**：在加减节点时，需要增加一倍或者减少一半，才可以保证数据和负载的均衡。
- **适用场景**：当使用少量节点时，节点变化将大范围影响 Hash 环中的数据映射，且容易出现数据倾斜，因此，一致性哈希只适合**数据节点较多**的分布式方案。

###### 虚拟槽分区 | 数据可均匀分配

![1632450278219](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632450278219.png)

- **概念**：使用分散度良好的哈希函数，把所有数据映射到一个**固定范围**的整数集合中，每一个节点负责维护一部分槽以及该槽所映射的数据。
  - 把这个范围的整数定义为**槽**（slot），其范围一般远远大于节点数，比如 Redis Cluster 槽范围是 0 ~ 16383。
- **优点**：
  - **容易扩缩容**：因为解耦了数据和节点之间的关系，降低了节点扩缩容的难度。
    1. 如果增加一个节点 6，就需要从节点 1 ~ 5 获得部分槽分配到节点 6 上。
    2. 如果想移除节点 1，需要将节点 1 中的槽移到节点 2 ~ 5 上，然后将没有任何槽的节点 1 从集群中移除即可。
  - **数据可均匀分配**：由于槽位范围固定，选用合适的算法，可以将数据均匀分配。
- **适用场景**：比如 Redis Cluster。

#### 分区实现

##### 客户端分区

- **概念**：key 在 Redis 客户端就决定了要被存储在哪个 Redis 实例中。
- **实现**：Redis Cluster（客户端分区与查询路由分区的混合体）、Redis-rb、Predis 和 Jedis 等。

![1632451244550](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451244550.png)

##### 代理辅助分区

- **概念**：
  - 客户端将请求发送到能够使用 Redis 协议的代理，而不是直接将请求发送到正确的 Redis 实例。
  - 该代理将确保根据配置的分区模式，把请求转发到正确的 Redis 实例，并将回复发送回客户端。
- **实现**：
  - **Twemproxy**：Twitter 开源，轻量级，是客户端和 Redis 实例之间的中间层，支持在多个 Redis 实例之间自动分区，无法平滑地扩缩容，性能一般，在 Redis Cluster出现后便不再维护。
  - **Codis**：豌豆荚开源，支持水平拓展，运维平台完善，性能较 Twemproxy 快，在国内使用的较多，在 Redis Cluster出现后便不再维护。

![1632451320936](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451320936.png)

##### 查询路由分区

- **概念**：把查询发送到随机 Redis 实例，该实例会确保该查询转发到正确的 Redis 节点。
- **实现**：Redis Cluster（客户端分区与查询路由分区的混合体）。

![1632451413068](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632451413068.png)

### 2.1. Redis高可用架构？

#### 主从模式 | 无高可用 & 简单

![1632299571516](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632299571516.png)

##### 概念

Redis 支持简单易用的**主从复制**功能， 使得从服务器成为主服务器的精确复制品。

##### 特点

（>= Redis 2.8）

- 一个 Master 可以有多个 Slave，并且 Slave 也可以有自己的 Slave ， 多级 Slave 之间可以构成一个**图状结构**。
- 复制功能默认使用**异步复制**， Slave 会以每秒 1 次的频率向 Master 报告复制流的处理进度。
- 复制功能**不会阻塞 Master**，即使有一个或多个 Slave 正在进行初次同步， Master 也可以继续处理命令请求。
- 复制功能也**不会阻塞 Slave**，只要启用了 `slave-serve-stale-data` 设置，即使 Slave 正在进行初次同步， 也可以使用旧版本的数据集来处理命令查询，不过在 Slave 删除旧版本数据集并载入新版本数据集的那段时间内， 连接请求会被阻塞。
- 复制功能只是单纯地进行**数据冗余**， 可以通过 `slave-read-only` 配置**读写分离**，让多个 Slave 来处理只读请求来提升扩展性，比说繁重的 `SORT` 命令可以交给 Slave 去运行。
- **禁止**《关闭 Master 持久化 + 自动拉起 Master 服务》：强烈建议打开 Master 的持久化，否则可能会因为延迟等问题，叠加自动拉起 Master 服务的原因，造成数据的丢失：
  1. 比如 Master 节点 A 关闭了持久化，Slave 节点 B 和节点 C 从节点 A 进行复制数据。
  2. 此时，节点 A 崩溃，然后服务被自动拉起，重启了节点 A，由于节点 A 的持久化被关闭了，所以 A 重启之后没有任何数据。
  3. 接着，节点 B 和节点 C 将从节点 A 复制数据，但是 A 的数据是空的，于是 B 和 C就把自身保存的数据副本全部都删除掉。
  4. 这种情况下，即便使用 Sentinel 来实现Redis 高可用也是非常危险的， 因为 Master 可能拉起得非常快，以至于 Sentinel 在配置的心跳时间间隔内，还没有检测到 Master 已被重启，然后 Slave 还是会执行上面数据丢失的流程。

##### 配置参数

```shell
# Slave参数
# 配置主从复制Master的IP+端口
slaveof <masterip> <masterport>
# 如果Master通过requirepass配置密码，则Slave也需要进行相应的配置
masterauth <master-password>
# 默认允许，Slave初次同步未完成时，继续使用旧数据来响应客户端，配置no会阻塞初次同步期间的所有请求
slave-serve-stale-data yes
# 默认开启读写分离，Slave只能读取数据，不能写入数据
slave-read-only yes

# Master参数
# 默认关闭无磁盘化复制，Master磁盘不生成RDB文件，直接通过网络同步给Slave
repl-diskless-sync no
# 默认为3和10，如果至少有3个从服务器，并且这3服务器的延迟值都少于10秒，Master才会执行客户端请求的写操作
# min-slaves-to-write 3
# min-slaves-max-lag 10

```

##### 原理

（>= Redis 2.8）

1. 当建立一个 Slave 时， Slave 会向 Master 发送一个 `PSYNC master_run_id offset` 命令。
2. 如果 Slave 是首次连接，由于 Master 中不存在该 Slave 的复制偏移量，所以会触发一次**完整重同步**操作， 此时，Master 开始执行 `BGSAVE`， 并在保存操作执行期间， 将所有新执行的写入命令都保存到一个缓冲区里面。
   - **部分重同步**：
     1. Master 会为被发送的复制流创建一个缓冲区 `in-memory backlog`， 并且 Master 和所有 Slave 之间都记录一个复制偏移量 `replication offset` 和一个主服务器ID `master run id`，当出现网络连接断开时， Slave 重新连接后会向 Master 请求继续执行原来的复制进程。
     2. 如果 Slave 记录的主服务器ID `master run id` 和当前要连接的主服务器ID `master run id` 相同， 并且 Slave 记录的偏移量 `replication offset` 所指定的数据仍然保存在 Master 的复制流缓冲区 `in-memory backlog` 里面， 那么 Master 会向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
     3. 否则，Slave 就要执行**完整重同步**操作。
3. 当 Master  `BGSAVE` 执行完毕后， Master 将执行保存操作所得的 .rdb 文件发送给 Slave， Slave 接收这个 .rdb 文件， 并将文件中的数据载入到内存中。
4. 之后，Master 会以 Redis 命令协议的格式， 将写命令缓冲区中积累的所有内容都发送给 Slave，Slave 则实时同步这些数据。
5. 如果主从复制期间 Slave 断开连接，在自动重连后，会使用 `PSYNC master_run_id offset` 命令来进行同步，Master 会以**增量复制**的形式，向 Slave 发送断线时缺失的那部分数据， 然后复制工作可以继续执行。
   - Slave 会在连接断开后进行自动重连：
     - 在 Redis 2.8 版本之前， 断线之后重连的 Slave 总要执行一次**完整重同步**操作。
     - 从 Redis 2.8 版本开始， Slave 可以根据 Master 的情况来选择执行**完整重同步**还是**部分重同步**。
       1. 如果此时 Master 是 Redis 2.8 之前的版本，那么 Slave 使用 `SYNC` 命令来进行同步。
       2. 如果此时 Master 是 Redis 2.8 或以上版本，那么 Slave 使用 `PSYNC master_run_id offset` 命令来进行同步。

##### 优点

- **部署简单**，仅使用两个节点即可构成主从模式。
- 可以通过**读写分离**，来避免读和写同时不可用。

##### 缺点

- 一旦 Master 节点出现故障，主从节点就**无法自动切换**，直接导致 SLA 服务等级下降。
  - **解决方案**：添加哨兵监控。
- 所有的 Slave 节点数据的复制和同步都由 Master 节点来处理，会造成 Master节点压力过大。
  - **解决方案**：可以使用**主从从结构**，通过引入从从同步，以减少主从同步的次数。

##### 适用场景

一般适合业务**发展初期**，并发量低，运维成本低的情况。

#### 哨兵模式 | 高可用 & 多读

![1632320226337](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632320226337.png)

##### 概念

Sentinel，哨兵，是 Redis 高可用的解决方案，可以监视一个或者多个 Redis Master 服务，以及这些 Master 服务的所有从服务，当某个 Master 服务宕机后，会把这个 Master 下的某个从服务升级为 Master，从而替代已宕机的 Master 继续工作。

##### 特点

- Redis Sentinel 用于管理多个 Redis 服务器实例， 它会执行以下**三个任务**：
  1. **监控**：Monitoring，Sentinel 会不断地检查 Master 和 Slave 是否运作正常。
  2. **提醒**：Notification，当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。
  3. **自动故障迁移**：Automatic failover。
     - 当一个 Master 不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效 Master 的其中一个 Slave 升级为新的 Master， 并且让失效 Master 的其他 Slave 改为复制新的 Master。
     - 当客户端试图连接失效的 Master 时， 集群也会向客户端返回新 Master 的地址， 使得集群可以使用新 Master 代替失效 Master。
- Redis Sentinel 是一个分布式系统， 可以在一个架构中运行多个 Sentinel 进程， 这些进程会使用**流言协议**来接收关于 Master 是否下线的信息， 并使用**投票协议**来决定是否执行自动故障迁移， 以及选择哪个 Slave 作为新的 Master。
  - **流言协议**：gossip protocols，是一种计算机对计算机的沟通协议，是一种复制**没有强一致性**需求状态的方式，即使在通讯失败或消息丢失的情形下，更新也可以在期望的时间内传播，通常用来解决其它方式难以解决的分布式问题，比如底层的网络结构非常复杂，或者流言协议是最有效的解决方案等。
  - **投票协议**：agreement protocols，比如 Raft。
- 虽然 Redis Sentinel 释出为一个单独的可执行文件 `redis-sentinel`，但实际上只是一个运行在**特殊模式**下的 Redis 服务器， 可以在启动一个普通 Redis 服务器时通过给定 `--sentinel` 选项来启动 Redis Sentinel 。

##### 配置参数

```shell
# 配置监控 127.0.0.1：6379 的 mymaster 服务器，并且客观下线需要取得2个(quorum)哨兵的同意
# 但是无论该值配置了多少，都需要多数哨兵的选举后，才能发起一次自动故障转移
sentinel monitor mymaster 127.0.0.1 6379 2
# 配置Master服务器密码（如果Master有配置的话）
sentinel auth-pass <master-name> <password>
# 配置判定mymaster主观下线的毫秒数
sentinel down-after-milliseconds mymaster 60000
# 配置主从切换的超时时间，需要自动故障转移时，如果当前哨兵没有去执行，那么在超过这个时间后，会由其他的哨兵来进行处理
sentinel failover-timeout mymaster 180000
# 配置在执行故障转移时，同步新mymaster的最大Slave并行数，如果全部Slave一起对新Master进行同步，由于在Slave载入RDB时会阻塞客户端请求，所以可能会造成所有Slave在短时间内全部不可用的情况出现
sentinel parallel-syncs mymaster 1
```

##### 运行命令

```shell
# 启动命令
# 运行纯Sentinel服务器
redis-sentinel /path/to/sentinel.conf
# 在Redis Server上运行哨兵
redis-server /path/to/sentinel.conf --sentinel

# 运维命令
# 查看imooc-master下的master节点信息
sentinel master imooc-master
# 查看imooc-master下的slaves节点信息
sentinel slaves imooc-master
# 查看imooc-master下的哨兵节点信息
sentinel sentinels imooc-master

```

##### 自动发现原理

###### Sentinel 发现

一个 Sentinel 可以与其他多个 Sentinel 进行连接， 各个 Sentinel 之间可以互相检查对方的可用性， 并进行信息交换，通过**发布与订阅**功能，向频道 `__sentinel__:hello` 发送信息，来自动发现正在监视相同 Master 的其他 Sentinel ，无须为运行的每个 Sentinel 分别设置其他 Sentinel 的地址。

1. **发布**：每个 Sentinel 会以每两秒一次的频率， 通过发布与订阅功能， 向被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道发送一条信息， 信息中包含了 Sentinel 的 IP、端口和运行 ID `runid`。
   - Sentinel 发送的信息中还包括完整的 Master 当前配置。 如果一个 Sentinel 包含的 Master 配置比另一个 Sentinel 发送的配置要旧， 那么这个 Sentinel 会立即升级到新配置上。
2. **订阅**：每个 Sentinel 都订阅了被它监视的所有 Master 和 Slave 的 `__sentinel__:hello` 频道， 查找之前未出现过的 Sentinel，当一个 Sentinel 发现一个新的 Sentinel 时， 它会将新的 Sentinel 添加到一个列表中， 这个列表保存了已知的、正在监视同一个 Master 的所有其他 Sentinel 。
   - 在将一个新 Sentinel 添加到监视 Master 的列表上面之前， Sentinel 会先检查列表中是否已经包含了和要添加的 Sentinel 拥有相同运行 ID 或者相同地址（IP+端口）的 Sentinel ， 如果是，则 Sentinel 会先移除列表中已有的那些拥有相同运行 ID 或者相同地址的 Sentinel ， 然后再添加新 Sentinel 。

###### Slave 发现

与此类似，也不必在配置文件中，手动列出 Master 属下的所有 Slave， 因为 Sentinel 可以通过询问 Master 来获得所有 Slave 的信息。

- 在一般情况下， 每个 Sentinel 会以**每10秒1次**的频率向它已知的所有 Master 和 Slave 发送 `INFO [section]` 命令。 
- 当一个 Master 被 Sentinel 标记为客观下线时， Sentinel 向下线 Master 的所有 Slave 发送 `INFO [section]`命令的频率会从每10秒1次改为**每秒1次**。

##### 故障判定原理

###### Sentinel 定期任务

1. 每个 Sentinel 以**每秒1次**的频率向它所知的 Master、Slave 以及其他 Sentinel 实例发送一个 `PING` 命令。
2. 如果一个实例距离最后一次有效回复 `PING` 命令的时间超过 `down-after-milliseconds` 选项所指定的值， 那么这个实例会被 Sentinel 标记为**主观下线**。 
3. 如果一个 Master 被标记为主观下线， 那么正在监视这个 Master 的**所有 Sentinel** 要以每秒1次的频率确认Master 是否的确进入了主观下线状态。
   - 当 Master 重新向 Sentinel 的 `PING` 命令返回有效回复时，Master 的主观下线状态就会**被移除**。
4. 如果一个 Master 被标记为主观下线， 并且有足够数量（>= `quorum` ）的 Sentinel 在指定的时间范围内同意这一判断， 那么这个主服务器被标记为**客观下线**。
   - 当没有足够数量（>= `quorum` ）的 Sentinel 同意主服务器已经下线， Master 的客观下线状态就会**被移除**。

###### 主观下线

主观下线，Subjectively Down， 简称 **SDOWN**，指的是单个 Sentinel 实例对服务器做出的下线判断，如果一个服务器（Master、Slave 和其他 Sentinel）没有在 `master-down-after-milliseconds` 选项所指定的时间内， 对向它发送 `PING` 命令的 Sentinel 一直返回**无效回复**， 那么 Sentinel 就会将这个服务器标记为**主观下线**。

- 服务器对 PING 命令的**有效回复**，可以是以下三种回复的其中一种：
  - 返回 `+PONG` 。
  - 返回 `-LOADING` 错误。
  - 返回 `-MASTERDOWN` 错误。
- 如果服务器返回除以上三种回复之外的其他回复， 又或者在指定时间内**没有回复** `PING` 命令， 那么 Sentinel 认为服务器返回的**回复无效**。
- 只有一个 Sentinel 将服务器标记为**主观下线**，并不一定会引起服务器的自动故障迁移，只有在足够数量（>= `quorum` ）的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为**客观下线**， 这时**自动故障迁移**才会执行。

###### 客观下线

客观下线，Objectively Down， 简称 **ODOWN**，指的是多个 Sentinel 实例在对同一个服务器做出 **SDOWN** 判断， 并且通过  `SENTINEL is-master-down-by-addr` 命令互相交流之后， 得出的服务器下线判断。

- 一个 Sentinel 可以通过向另一个 Sentinel 发送 `SENTINEL is-master-down-by-addr` 命令来询问对方是否认为给定的服务器已下线。
- 从主观下线状态切换到**客观下线**状态，并没有使用严格的法定人数算法， 而是使用了**流言协议**：
  - 如果 Sentinel 在给定的时间范围内， 从其他 Sentinel 那里接收到了足够数量（>= `quorum` ）的 Master 下线报告， 那么 Sentinel 就会将 Master 的状态从主观下线改变为**客观下线**。 
  - 如果之后其他 Sentinel 不再报告 Master 已下线， 那么客观下线状态就会**被移除**。
- 客观下线条件只适用于 Master，对于任何其他类型的 Redis 实例， Sentinel 在将它们判断为下线前不需要进行协商， 所以  Slave 或者其他 Sentinel 永远不会达到客观下线的条件。
- 只要一个 Sentinel 发现某个 Master 进入了客观下线状态， 这个 Sentinel 就可能会被其他 Sentinel 推选出， 并对失效的 Master 执行自动故障迁移操作。

##### 自动故障转移

###### Leader Sentinel 选举

当一个 Master 被判定为**客观下线**后，监视这个 Master 的所有Sentinel会通过 `Raft` 选举算法，选出一个Leader Sentinel 去执行故障转移 `failover` 操作。

- **选举一致性保证**：
  1. 使用 Raft 算法来选举 Leader Sentinel，可以确保在一个给定的 `epoch`（纪元）里， **只有一个** Leader 产生，因为更高的 `epoch` 配置总是优于较低的 `epoch` 配置 ， 每个 Sentinel 都会主动使用更新的 `epoch` 来代替自己的配置。
  2. 当出现网络分区时， 一个 Sentinel 可能会包含了较旧的配置， 而当这个 Sentinel 接到其他 Sentinel 发来的版本更新的配置时， Sentinel 就会对自己的配置进行更新。
  3. 如果想要在出现网络分区时仍然保持一致性，可以使用 `min-slaves-to-write` 选项， 让 Master 在连接的 Slave 实例数**少于给定数量时，停止执行写操作**，并且在每个运行 Redis Master或 Slave 的机器上运行 Redis Sentinel 进程。

###### Raft 算法

http://thesecretlivesofdata.com/raft/#home、https://raft.github.io

![1632381533618](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632381533618.png)

Raft，是一种共识算法，旨在使其易于理解，在容错和性能上与Paxos媲美，不同之处在于它被分解为相对独立的子问题（Leader Election 和 Log Replation），并且清晰明了地解决了分布式系统实际所需的主要部分。

- **Leader Election**：领导者选举，这部分主要就是通过用随机 `election timeout` 的方式，使得能够很快地选出 Leader，并且通过 `heartbeat（AppendEntries RPC，心跳续约）` 周期性地通知 Follower，以维持 Leader 的状态。这大大简化了 Leader 选举的算法，加快了选举速度。**选举流程**为：
  1. 每个 Follower 或者 Candidate 都有一个 election timer，用来计算随机 `election timeout` 时间。
  2. 当 Follower 没有收到 Leader 的 `heartbeat（AppendEntries RPC，心跳续约）` 或者 Candidate 的 `RequestVote RPC（选举发起）`时，则等待 election timer 超时。
  3. 一旦 Follower 超时，则会立刻变为 Candidate 身份，令 `currentTerm++` 发起新一轮 election term 的选举，它会先给自己投票，并重置自己的 election timer，然后广播 `RequestVote RPC（选举发起）` 给所有 server。
  4. 这些 server 如果收到某个 Candidate 的 `RequestVote RPC（选举发起）` 时，会经过一系列规则来判断是否能够进行投票。
  5. 如果在 election timer 超时前，该 Candidate 能收到超过半数 server 的投票，则会立刻变为 Leader，并发送 `heartbeat`，以维持 Leader 身份。
- **Log Replation**：日志复制（自己写的，可能理解会有出入，在分布式章节再补充完整）。
  1. 在客户端请求 Leader 更改集群数据时，Leader 会在数据更改后，先把同步日志发送到它所有的 Follower。
  2. 当超过半数的 Follow 的同步日志写入成功后，Leader 才会对该数据的更改进行提交，并响应客户端。
  3. 最后，Leader 再把提交结果同步到它所有的 Follower，通知他们 Leader 数据的提交。

###### Master 选择

当选举出 Leader Sentinel 后，Leader Sentinel 会根据以下规则，在失效 Master 属下的 Slave 当中，选择出新的 Master：

1. 先淘汰主观下线 | 已断线 | 最后一次回复 `PING` 命令时间大于5秒钟 | 与失效 Master 断开连接时长超过 10 倍主观判断时长 `down-after-milliseconds` 的 Slave 节点。
2. 选择配置 `slave-priority` 最高的 Slave 节点，如果没有，则继续选择。
3. 选择复制偏移量 `replication offset` 最大的 Slave 节点，复制偏移量越大，说明数据复制的越完整。
4. 如果复制偏移量不可用，或者 Slave 的复制偏移量相同， 则选择运行 ID `run_id` 最小的 Slave 节点，`run_id` 越小，说明重启次数越少。

###### 故障转移流程

一次故障转移操作由以下步骤组成：

1. 某个 Sentinel 发现 Master 已经进入**客观下线**状态。
2. 该  Sentinel 对当前 `epoch` （纪元）进行自增， 并尝试在这个 `epoch` 中当选 Leader Sentinel 。
3. 如果 Leader Sentinel 当选失败， 则在设定的故障迁移超时时间 `failover-timeout` 的两倍之后， 会继续重新尝试当选。
4. 如果 Leader Sentinel 当选成功， 则根据Master选择规则，选出一个 Slave，向其发送 `SLAVEOF NO ONE` 命令，让它转变为 Master。
5. 然后， Leader Sentinel 通过**发布与订阅**功能， 将更新后的配置传播给所有其他 Sentinel，让其他 Sentinel 对它们自己的配置进行更新。
   - Sentinel 的状态会被持久化在 Sentinel 的配置文件中，每当 Sentinel 接收到一个新的配置， 或者当Leader Sentinel 为 Master 创建一个新的配置时， 这个配置会与 `epoch` 一起被保存到自己的磁盘里，意味着停止和重启 Sentinel 进程都是安全的。
6. 接着， Leader Sentinel 会向已下线 Master 的其他 Slave 发送 `SLAVEOF host port` 命令， 让它们去复制新的 Master。
   - 当Redis 实例被重新配置，无论是被设置成 Master，或者Slave，或者其他 Master 的 Slave，Sentinel 都会向这个被重新配置的实例发送一个 `CONFIG REWRITE` 命令， 从而确保这些配置会被这个实例持久化在它自己的硬盘里。
7. 最后，当所有 Slave 都已经开始复制新的 Master 时， Leader Sentinel 则结束这次故障迁移操作。

##### 优点

监控、提醒、自动故障转移，从而实现 Redis 的高可用。

##### 缺点

如果写请求较多，当集群 Slave 节点数量多了后，Master 节点同步数据的压力会非常大。

##### 适用场景

适合**读远多于写**的业务场景，比如在秒杀系统中，用来缓存活动信息。

#### 集群模式 | 高可用 & 多写

![1632464692288](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632464692288.png)

##### 概念

Redis Cluster，于 3.0 版本推出，是一个分布式容错的高可用实现。

##### 特点

- 采用**哈希虚拟槽**的数据分区方案，把 key 分布到各个 Master 节点上，每个 Master 后跟若干个 Slave 做主从切换。

- 采用**客户端查询分区+服务端查询路由**的分区实现，客户端可以连接任意 Master 节点，集群内部会按照不同的 key，把请求转发到不同的 Master 节点。

- 可使用的功能只是普通单机 Redis 所有功能的一个**子集**：

  - 不支持同时使用多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的行为。
  - 不支持多数据库功能， 只能使用默认的 `0` 号数据库， 并且不能使用 `SELECT index` 命令。

- Redis Cluster 的设计目标主要为高性能、高可用和高扩展，抛弃了一部分数据一致性，即 **AP**：

  - **数据一致性**：由于 Redis 主从复制使用的是异步复制，在某些情况下，如果 Master 宕机但未同步至 Slave，可能会导致丢失写入，可通过 `WAIT` 命令实现，使丢失写入的可能性大大降低。

    - **`wait` 命令不能保证 Redis 强一致性**：如果写操作已经被传送给一个或多个 Slave节点，当 Master 发生故障，虽然使用 `wait` 命令可以**极大概率**（不保证100%）地提升一个受到写命令的 Slave 节点为Master，但由于其他原因，比如 `slave-priority`， Sentinel 还是有可能去提升其他未同步写命令的 Slave 节点，造成同步写操作的丢失。

    |          | WAIT                                                         |
    | -------- | ------------------------------------------------------------ |
    | 出现版本 | Redis 3.0                                                    |
    | 命令格式 | wait numslaves timeout                                       |
    | 含义     | 阻塞当前客户端 timeout 毫秒，为 0 则代表永远阻塞，直到所有以前的写命令都成功传输并被指定数目的 Slave 确认，命令再返回；或者如果发生 timeout 超时，即使指定数目的 Slave 还没有确认，命令也会返回。 |
    | 返回值   | 返回已处理至该偏移量的 Slave 个数                            |

  - **高可用**：当集群中一部分节点故障后，集群整体依然能响应客户端读写请求。

    - **自动故障转移**：节点间定时互 `Ping` ，当超过一半 Master 判定某节点失败，则标记为 FAIL，然后向集群广播节点下线的消息，如果下线节点是带有哈希槽的 Master，则会在它的 Slave 中挑选出一个来进行主从替换。

  - **高性能**：操作某个 key 时，不会先找到节点再处理，而是直接重定向到目标 Redis 实例，相较代理分片少了 proxy 的连接损耗。

    - 但是在进行 multiple key 操作时，由于 keys 可能会散列到不同的 Redis 实例上，造成操作的非原子性，加之 Redis Cluster 本身就不支持 multiple key 操作，此时可以使用 **hash tags** 哈希标签， 将 keys 散列到同一个 slot 上，以满足进行 multiple key 的需求。
      - **hash tags**：哈希标签，使用 {} 确保两个 key 都在散列到同一个哈希槽，比如 key1 {user1000}.following 和 key2 {user1000}.followers，由于使用了哈希标签，Redis Cluster 在散列时，只会使用 { } 里的字符串进行计算，所以 key1 和 key2 将会落到同一个哈希槽中。

  - **高拓展**：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

##### 配置参数

```shell
# 开启集群模式
cluster-enabled yes
# 每一个节点都需要有这么一个配置文件，3主3从则一共需要6份，用于存储集群模式下的集群状态等信息，由Redis自己维护，而这些信息会相互告知其他所有节点。如果要重新创建集群，只需要把这个文件删除掉就行。
cluster-config-file nodes-201.conf
# 节点超时时限，如果发生超时则会被认定为PFAIL，如果超过半数其他Master认定为PFAIL，则会被集群认定为FIAL，然后会进行主从切换
cluster-node-timeout 5000
# 开启AOF
appendonly yes

```

##### 运行命令

```shell
# Redis3.x旧版集群构建方式，需要使用redis-trib.rb来构建集群，最新版使用C语言来构建了，这个要注意
# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005

# 新版Redis集群构建方式
# 创建集群，主节点和从节点比例为1，1-3为主，4-6为从，1和4，2和5，3和6分别对应为主从关系，这也是最经典用的最多的集群模式
redis-cli --cluster create ip1:port1 ip2:port2 ip3:port3 ip4:port4 ip5:port5 ip6:port6 --cluster-replicas 1

# 集群客户端
redis-cli -c -p 7000

# 检查集群信息
redis-cli --cluster check 127.0.0.1:6379

```

##### 集群节点

###### 节点属性

```shell
# 获取集群所有节点的描述信息
$ redis-cli --cluster nodes
# 结果：节点ID，IP，端口号，节点标志，最后PING发送时间，最后PONG接收时间，连接状态，哈希槽范围
d1861060fe6a534d42d8a19aeb36600e18785e04 :0 myself - 0 1318428930 connected 0-1364
```

- **节点ID**：
  1. 每个节点在集群中都有一个独一无二的 ID，是一个十六进制表示的 160 位随机数，用于标识集群中的每个节点，一个节点可以改变它的 IP 和端口号， 但重启的话不会改变它的节点 ID 。
  2. 节点ID，在节点**第一次启动**时由 `/dev/urandom` 生成，然后保存到配置文件中， 只要这个配置文件不被删除，该节点就会一直沿用这个 ID。 
  3. 集群可以自动识别出 IP + 端口号的变化， 并把这一信息通过 `Gossip` 协议广播让其他节点知道。
- 如果该节点是从节点的话，那么它会记录主节点的节点 ID 。 如果这是一个主节点的话，那么主节点 ID 这一栏的值为 `0000000` 。

###### 节点任务

- **保存数据**：持有键值对数据。
- **状态映射记录**：记录集群的状态，包括键到正确节点的映射。
- **自动发现与选举**：自动发现其他节点，识别工作不正常的节点，并在有需要时，在从节点中选举出新的主节点。

###### 节点通信

集群中的每个节点都会与其他节点建立起**集群连接**， 该连接是一个 TCP 连接， 使用二进制 `Gossip` 协议进行通讯，用于：

- **节点发现**：传播关于集群的信息，以此来发现新的节点。
- **心跳检测**：向其他节点发送 `PING` 数据包，以此来检查目标节点是否正常运作。
  - **集群内互通**：集群节点总是应答来自集群连接端口的连接请求。
  - **非集群内只允许PING**：可以对接收到的 `PING` 数据包进行回复， 即使这个 `PING` 数据包来自不可信的节点，但除了 `PING` 之外， 集群节点会拒绝其他所有非来自集群节点的数据包。
- **事件传播**：在特定事件发生时，发送集群信息。

###### 节点自动发现

如果将一个新节点添加到一个集群中， 只要管理员使用 `CLUSTER MEET` 命令显式地指定了可信关系， 集群就可以自动发现其他节点，最终该节点会与集群中已有的其他所有节点连接起来。

- **握手规则**：
  - A 节点刚加入集群中，B 为集群中的某个节点，此时如果管理员显式地向 A 发送 `CLUSTER MEET ip port` 命令， 那么 A 会向 B 发送 `MEET` 信息， 强制让 B 节点承认 A 属于集群中的一份子。
  - A、B为集群中的某个节点，A 刚承认 C 为集群中的一份子，此时如果 A 向 B 传播第三者 C 的信息， 那么 B 也会把 C 识别为集群中的一份子， 并尝试连接 C 。
- **作用**：可以防止不同的 Redis 集群由于 IP 地址的变更或者其他网络事件的发生，而产生意料之外的问题，从而使得集群更具健壮性。当节点的网络连接断开时， 它会主动连接其他已知的节点。

##### 分区实现原理

###### 虚拟哈希槽模型

Redis 集群的键空间被分割为 `16384` 个槽（slot）， 集群的最大节点数量也是 `16384` 个，但推荐的最大节点数量为 1000 个左右，每个主节点都负责处理 `16384` 个哈希槽的其中一部分，其键的映射算法为：

```shell
# CRC16 算法可以很好地将各种不同类型的键，平稳地分布到 16384 个槽里面
HASH_SLOT = CRC16(key) mod 16384
```

###### 为什么哈希槽数为16384个？

`CRC16` 算法产生的 hash 值有 16 bit，即可产生 2 ^ 16 = 65536 个值，换句话说，值是分布在 0 ~ 65535 之间，那 Redis 在做 `mod` 运算的时候，为什么不 `mod` 65536，而是选择 `mod` 16384 呢？

1. **槽位数不宜过大**：
   1. 如果槽位为 65536，那么节点发送 `PING/PONG` 心跳包消息头所占用的空间会达到 8k （65536 / 8），过于庞大，传输时浪费带宽。
   2. 而使用 16384 个槽位，心跳包消息头所占用的空间仅为 2k（16384 / 8），大小还能接受。
2. **槽位数不宜过小**：
   1. Redis Master 节点数量基本不可能大于 1000 个，因为集群节点越多，心跳数据包消息体携带的数据就越多，就越可能导致网络拥堵。
   2. 同时，Redis Master 的哈希槽配置，是通过一张 bitmap 的形式来保存的，其填充率为 slots / N，N为节点数目，在 N 最大为 1000 的情况下，如果槽位数越小，bitmap 填充率就越小，导致 bitmap 在传输过程中的压缩率就越高，越消耗 CPU 资源。
3. 因此，16384 个插槽可以确保在最大 1000 个 Master 的情况下，仍然有足够的插槽，使得哈希槽配置作为原始 bitmap 进行传播，是综合了心跳包大小、网络带宽、压缩率等方面考虑的结果，16384 个插槽处于**合适的范围**内，能够满足业务需求并且更有优势。

###### 请求路由原理

1. **服务端路由**：集群节点不能代理客户端的命令请求， 客户端应该在节点返回 `-MOVED` 或者 `-ASK` 转向错误时， 自行将命令请求转发至其他节点。
   - 当节点需要让一个客户端**长期地**将针对某个槽的命令请求发送至另一个节点时， 节点会向客户端返回 `-MOVED` 转向。
   - 当节点需要让客户端仅仅在**下一个命令**请求中转向至另一个节点时， 节点会向客户端返回 `-ASK` 转向。
2. **客户端路由**：如果客户端可以将键和节点之间的映射信息保存起来， 可以有效地减少可能出现的转向次数， 籍此提升命令执行的效率。

###### MOVED 转向

1. 一个 Redis 客户端可以向集群中的任意节点（包括从节点）发送 `GET key` 命令请求。

2. 集群节点会对命令请求进行分析， 如果该命令是集群可以执行的命令， 那么节点会查找这个命令所要处理的键所在的哈希槽。

3. 如果要查找的哈希槽正好就处于当前节点中，则接收到的命令由当前节点负责处理。

4. 如果所查找的哈希槽不处于当前节点中，则当前节点会先查看自身内部所保存的哈希槽到节点 ID 的**映射记录**，然后向客户端回复一个 `-MOVED` 转向错误。

   ```shell
   GET x
   # GET命令收到一个 -MOVED 转向错误
   # x真正所在的目标哈希槽，目标节点IP，目标节点端口号
   -MOVED 3999 127.0.0.1:6381
   
   ```

5. 客户端收到 `-MOVED` 转向错误后，根据目标节点 IP 与端口号，会再向目标节点重新发送一次 `GET key`命令请求。

   - 为了让客户端的转向操作**尽可能地简单**， 节点在 `-MOVED` 错误中直接返回了目标节点的 IP 和端口号， 而不是目标节点的 ID 。

6. 如果客户端在重新发送 `GET key` 命令时，集群刚好又更改了 key 的 slot 配置， 此时客户端请求目标哈希槽，会再次收到 `-MOVED` 转向错误， 需要再次向新的目标节点重新发送一次 `GET key`命令请求。

7. 客户端会循环以上操作，直到该命令请求成功，然后记录下该成功请求的哈希槽的目标节点信息，在下次执行相同 key 命令时，加快正确节点的寻找速度。

   - 当集群处于稳定状态时， 所有客户端最终都会保存有一个哈希槽至节点的映射记录，使得集群非常高效，此后客户端可以直接向正确的节点发送命令请求， 而无须转向、代理或者请求其他可能发生单点故障的 Redis 实例。

###### 集群重分片

Redis 集群支持在集群运行的过程中添加或者移除节点，无论是添加还是删除，都需要将哈希槽从一个节点移动到另一个节点，如果添加一个新节点到集群， 则需要将其他已存在节点的槽移动到一个空白的新节点里面；如果从集群中移除一个节点， 则需要将被移除节点的所有槽移动到集群的其他节点上面去。

- **使用 Cluster 子命令**：管理集群节点的哈希槽转换表。

| Cluster子命令                              | 作用                                                         |
| ------------------------------------------ | ------------------------------------------------------------ |
| CLUSTER ADDSLOTS slot1 [slot2] ... [slotN] | 用于添加并指派节点哈希槽，当哈希槽被添加并指派之后， 节点会把这一信息通过 Gossip 协议传播到整个集群，通常在新创建集群时， 作为一种快速地将各个槽指派给各个节点的手段来使用 |
| CLUSTER DELSLOTS slot1 [slot2] ... [slotN] | 用于删除节点哈希槽，当哈希槽被删除之后， 节点会把这一信息通过 Gossip 协议传播到整个集群 |
| CLUSTER SETSLOT slot NODE node             | 可以将指定的哈希槽指派给节点 node                            |
| CLUSTER SETSLOT slot MIGRATING node        | 用于将给定节点 node 中的哈希槽迁移出节点 node。当一个哈希槽被设置为 `MIGRATING` 状态时， 只有当哈希槽的键仍然存在于节点时，该节点才会继续处理关于这个槽的命令请求；如果哈希槽的键不存在于节点， 那么该节点会向客户端返回一个 `-ASK` 转向错误， 以告知客户端要把命令请求发送到 哈希槽迁移后的目标节点 |
| CLUSTER SETSLOT slot IMPORTING node        | 用于将给定哈希槽导入到节点 node 中。当一个槽被设置为 `IMPORTING` 状态时，节点仅在接收到 `ASKING` 命令之后， 才会接受关于这个槽的命令请求；如果客户端没有向节点发送 `ASKING` 命令， 那么节点会使用 `-MOVED` 转向错误，把命令请求转向至真正负责处理这个槽的节点 |

- **使用 redis-trib 客户端**：Redis3.x旧版命令，`./redis-trib.rb reshard <集群中任意结点的IP+端口号>`，不推荐，会阻塞客户端。
  1. 先执行 `CLUSTER GETKEYSINSLOT slot count` 命令，让节点返回 count 个 哈希槽中的键。
  2. 然后对于命令所返回的每个键， redis-trib 会向节点 A 发送一条 `MIGRATE host port key destination-db timeout [COPY] [REPLACE] ` 命令， 把所指定的键**原子地**从节点 A 移动到节点 B，并且在移动键期间，A 和 B两个节点都会处于**阻塞状态**，以免出现竞争条件。
     - `MIGRATE host port key destination-db timeout [COPY] [REPLACE]` ：
       1. 执行该命令的节点会连接到 target 节点， 并将序列化后的 key 数据发送给 target ， 一旦 target 返回 `OK` ， 节点就将自己的 key 从数据库中删除。
       2. 从一个外部客户端的视角来看， 在某个时间点上， 键 key 要么存在于节点 A ， 要么存在于节点 B ， 但不会同时存在于节点 A 和节点 B 。
       3. 由于 Redis 集群只使用 `0` 号数据库， 所以当该命令被用于执行集群操作时， target_database 的值总是 `0` 。
       4. 尽管该命令非常高效， 但对一个键非常多、并且数据量非常大的集群来说，该命令会占用大量的时间， 有可能会导致集群没办法适应那些对于响应时间有严格要求的应用程序。

###### ASK 转向

1. 节点 A 开始迁移 哈希槽8 的键到 节点 B，迁移过程中，客户端对 A 发起了请求。
2. 由于 A 的 哈希槽8 的键被迁移了一部分到 B，导致客户端在节点 A 中没找到某个键，A 节点会向客户端返回一个 `-ASK` 转向错误。
   - 这种转向仅仅会影响**一次命令**查询， 而不是让客户端每次都直接去查找节点 B，并且只针对 16384 个槽中的其中**一个槽**， 所以对集群造成的性能损耗是属于可接受范围的。
3. 客户端接收到 `-ASK` 转向错误后， 则将命令请求的发送对象，调整为转向所指定的节点 B。
4. 接着，客户端会先发送一个 `ASKING` 命令，然后再发送真正的命令请求，否则这个针对带有 `IMPORTING` 状态槽 8 的命令请求将会被节点 B 拒绝执行。
   - **先发送 `ASKING` 命令的好处**：如果客户端出现 Bug ， 过早地将槽8 映射到了节点 B 上面， 只要不先发送 `ASKING` 命令， 后面发送的命令请求就会被 B 返回 `-MOVED` 转向错误， 并将请求转回节点 A，从而保证了在槽8 转移期间，必须先请求节点 A。
5. 节点 B 接收到客户端 `ASKING` 命令后，会将为客户端设置一个一次性的标志， 使得客户端可以执行一次针对 `IMPORTING` 状态槽8 的命令请求。
6. 命令请求成功后，客户端不会去更新所记录的槽8 到节点的映射，此时槽8 仍然是映射到节点 A ， 而不是节点 B。
7. 接下来，在键转移期间，如果客户端继续发起 槽8 的请求，会重复以上操作。
8. 一旦节点 A 的 槽8 转移工作完成，当节点 A 再次收到针对槽8 的命令请求时，就会向客户端返回 `-MOVED` 转向， 把所有关于槽8 的命令请求**长期地**转向到节点 B中。
9. 至此，完成了一次 哈希槽**动态转移**的过程。

##### 高可用原理

###### 节点失效检测

简单来说就是，当一个节点 `PING` 不通另一个节点时，则会把它标记为 `PFAIL`；当一个节点要把另一个节点从 `PFAIL`标记为 `FAIL`时， 则必须得到大部分 Master 的同意才行。

1. 当一个节点 A 向另一个节点 B 发送 `PING` 命令， 但是 B 未能在 `cluster-node-timeout` 配置的节点超时时限内返回该 `PING` 命令的回复时， 那么 A 会将 B 标记为 `PFAIL` （possible failure，代表可能已失效）。
2. 然后下次在节点 A 对 C、D、E... 发送 `PING` 命令时， 都会随机地广播**3个**它所知道的节点的信息，其中一项说明了 B 节点是否已经被 A 标记为 `PFAIL` 或者 `FAIL` 。
3. 当节点 C、D、E... 接收到 A 发来的信息时，会记下那些被 A 标记为失效的节点 B，这操作称为**失效报告**。
4. 如果在Master F 将 B 标记为 `PFAIL` 时， 根据**最近接收到的**失效报告显式， 集群中的大部分其他 Master 都认为 B 已经进入了 `PFAIL` ， 那么 E 会将那个 B 的状态标记为 `FAIL`（failure，代表已失效） 。
5. 一旦 B 被标记为 `FAIL` ，关于它的已失效信息就会被广播到整个集群， 所有接收到这信息的节点都会将 B 标记为 `FAIL` 。
   - **Slave Fail**：当 B 为 Slave 时，在 B 重新上线时， 它的 `FAIL` 标记就会被移除。
     - 由于 Slave 不需要处理任何哈希槽，是否处于 `FAIL` 状态，只决定了它能否在有需要时被提升为 Master，所以保持 Slave 的 `FAIL` 状态是没有意义的。
   - **Master Fail**：当 B 为 Master 时，在 B 经过了 （**4 倍** `cluster-node-timeout` 配置的节点超时时限 +  **10 秒钟**）后，如果 Slave 的故障转移操作仍未完成，且 B 又发生了重新上线，那么 B 的 `FAIL` 标记会被移除，集群继续使用原来的 Master B。

###### 主从复制

为了在一部分节点下线，或者无法与集群的大多数节点进行通讯的情况下， 集群仍然可以正常运作， Redis 集群对节点使用了**主从复制**功能。

1. 集群中的每个节点都有 N 个复制品， 其中 1 个复制品为 Master， 而其余的 N-1 个复制品为 Slave。
2. 比如，在创建集群时，如果为 Master B 添加了 Slave B1 ， 那么当 Master B 下线时， 集群就会将 B1 设置为新的 Master， 并让它代替已下线的 Master B ， 继续处理原来的哈希槽， 这样集群就不会因为 Master B 的下线而无法正常运作了。
3. 但是，对于在这种场景下，如果节点 B 和 B1 都下线的话， 那么 Redis 集群还是会停止运作的。

###### 从节点选举

一旦某个 Master 进入 `FAIL` 状态， 如果这个 Master 有一个或多个 Slave 存在， 那么其中一个 Slave 会被升级为新的 Master， 而其他 Slave 则会开始对这个新的 Master 进行复制。

1. **新 Master 的选举条件**：
   1. 这个节点是已下线 Master 的 Slave。
   2. 已下线 Master 负责处理的槽数量为非空。
   3. Slave 的数据需要是可靠的， 即主从节点之间复制连接的断线时长，不能超过 （`cluster-node-timeout` 配置的节点超时时限 * `REDIS_CLUSTER_SLAVE_VALIDITY_MULT` 常量）得出的积。
2. 如果一个 Slave 满足了所有条件， 那么这个 Slave 将会向集群中的其他 Master **发送授权请求**， 询问它们， 是否允许自己升级为新的 Master。
3. 如果发送授权请求的 Slave 满足以下**授权要求**， 那么其他 Master 将向 Slave 返回 `FAILOVER_AUTH_GRANTED` 授权， 同意 Slave 的升级要求：
   1. 发送授权请求的是一个 Slave， 并且它所属的 Master 处于 `FAIL` 状态。
   2. 在已下线 Master 的所有 Slave 中， 这个 Slave 的节点 ID 在排序中是最小的。
   3. 这个 Slave 处于正常的运行状态，即没有被标记为 `FAIL` 状态， 也没有被标记为 `PFAIL` 状态。
4. 一旦某个 Slave 在给定的时限内得到大部分 Master 的 `FAILOVER_AUTH_GRANTED` 授权， 那么该 Slave 就会开始执行以下**故障转移**操作：显式地向所有节点广播一个 `PONG` 数据包， 加速其他节点识别这个节点的进度， 而不是等待定时的 `PING` / `PONG` 数据包。
   1. 告知其他节点， 自己现在是 Master了。
   2. 告知其他节点， 自己是一个已升级的 `PROMOTED` Slave。
      - 如果一个带有 `PROMOTED` 标识的 Master，由于某些原因又转变成回了 Slave，那么该节点将丢失它所带有的 `PROMOTED` 标识。
   3. 告知其他节点，自己接管了由那个已下线 Master 负责处理所有的哈希槽。
5. 所有其他节点都会根据新的 Master 对进行相应的**配置更新**：
   1. 所有被新的 Master 接管的槽会被更新。
   2. 已下线 Master 的所有 Slave 会察觉到 `PROMOTED` 标志， 并开始对新的 Master 进行复制。
   3. 如果已下线的 Master 重新回到上线状态， 那么它会察觉到 `PROMOTED` 标志， 并将自身调整为现任 Master 的 Slave。

###### 集群状态检测

1. 每当集群发生配置变化时（可能是哈希槽被更新，也可能是某个节点进入了 `FAIL` 状态），集群中的每个节点都会对它们自己所知道的节点进行扫描。
2. 配置扫描处理完毕后， 集群会进入以下两种状态的其中一种：
   - `OK` ： 集群可以正常工作，负责处理全部 `16384` 个槽的节点中， 没有一个节点被标记为 `FAIL` 状态。
   - `FAIL` ： 集群不能正常工作，当集群中有某个节点（该节点的所有主从）进入 `FAIL` 状态时， 集群不能处理任何命令请求， 对于每个命令请求， 集群节点都返回错误回复。
     - 说明即使集群中只有**一部分**哈希槽不能正常使用， 整个集群也会停止处理任何命令。
     - 不过节点从出现问题到被标记为 `FAIL` 状态的这段时间里， 集群仍然会**正常运作**， 所以集群在某些时候， 仍然有可能只能处理针对 `16384` 个槽的其中一个子集的命令请求。
3. 以下是集群进入 `FAIL` 状态的两种情况：
   - **出现至少有一个 哈希槽不可用时**：负责处理某个哈希槽的节点（该节点的所有主从）进入了 `FAIL` 状态。
   - **集群中的大部分 Master 进入了 `PFAIL` 状态时**：此时，集群可以在不请求大部分 Master 的意见下，快速地将某个节点判断为 `FAIL` 状态， 然后集群也会进入 `FAIL` 状态，从而让整个集群停止处理命令请求。

##### 数据弱一致性

Redis 集群**不保证数据的强一致性**，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令，**原因如下**：

- **异步复制**：Master 对命令的复制工作发生在返回客户端命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么 Master 处理命令请求的速度将极大地降低，因此 Redis 在性能和一致性之间做出了权衡，在复制工作上采取了异步复制。
  1. 客户端向 Master B 发送一条写命令。
  2. Master B 执行写命令，并向客户端返回命令回复。
  3. Master B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3。
  4. 如果写命令复制过程中，Master B 发生宕机的话，则会丢失这些被执行过的写命令。
- **集群内出现网络分区**：一个客户端与至少包括一个 Master 在内的少数实例被孤立。
  1. 举个例子，假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点，其中 A 、B 、C 为 Master，而 A1 、B1 、C1 分别为三个 Master 的 Slave，另外还有一个客户端 Z1 。
  2. 假设集群中发生网络分区，那么集群可能会分裂为两方，大多数的一方包含节点 A 、C 、A1 、B1 和 C1，而少数的一方则包含节点 B 和客户端 Z1 。
  3. 在这网络分区期间，主节点 B 仍然会接受 Z1 发送的写命令。
  4. 如果网络分区出现的时间很短，那么集群是可以继续正常运行的。
  5. 如果网络分区出现的时间足够长，使得大多数一方将 Slave B1 设置为新的 Master，那么当网络分区恢复时，原来的 Master B 就会被大多数一方的 Master B1 替代，成为 B1 的 Slave，导致原先 Z1 发送给 Master B 的写命令发生丢失。
     - 不过，在网络分区期间， 客户端 Z1 可以向 Master B 发送写命令的最大时间会被 `cluster-node-timeout` 配置的节点超时时限所限制：
       1. 对于大多数一方来说， 如果一个 Master 未能在 `cluster-node-timeout` 内重新联系上集群， 那么集群会将这个 Master 视为下线， 并使用它的 Slave 来代替自己继续工作。
       2. 对于少数一方来说， 如果一个 Master 未能在 `cluster-node-timeout` 内重新联系上集群， 那么它将停止处理写命令， 并向客户端**报告错误**。

##### 优点

- **高可用**：当集群中的一部分节点失效或者无法进行通讯时， 集群仍然可以继续处理命令请求的能力。
- **高性能**：操作某个 key 时，不会先找到节点再处理，而是直接重定向到目标 Redis 实例，相较代理分片少了 proxy 的连接损耗。
- **高拓展**：不存在中心节点或者代理节点，同时最大支持线性拓展 1000 个节点，把新节点加入集群后，可以通过命令平均分配已有节点的哈希槽。

##### 缺点

- **只可使用普通单机 Redis 所有功能的一个子集**：不支持同时使用多个键的 Redis 命令，不支持多数据库功能， 只能使用默认的 `0` 号数据库。
- **数据弱一致性**：与其他高可用方案一样，Redis 集群也**不保证数据的强一致性**，在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。
- **占用带宽**：虽然避免了 Master 单节点的问题，但集群内的数据同步、节点通信会占用一定的带宽。

##### 适用场景

只有在**写操作比较多**的情况下，集群模式才更有优势，相对于其他大多数情况，使用**哨兵模式**都能满足需求。

#### 高可用架构总结

##### AKF 拆分原则

![1632542719978](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542719978.png)

**AKF扩展立方体**，Scalability Cube，是在《The Art of Scalability》一书中被首次提出，旨在提供一个系统化的扩展思路。AKF 把系统扩展分为以下三个维度：

1. **X 轴**：代表无差别的克隆服务和数据，工作可以很均匀的分散在不同的服务实例上。
2. **Y 轴**：关注应用中职责的划分，比如数据类型、交易执行类型的划分。
3. **Z 轴**：关注服务和数据的优先级划分，如分地域划分。

=> X、Y、Z 轴的扩展并不是孤立的，可以同时对这 3 个维度进行扩展系统，分布式系统非常复杂，而 AKF 提供了一种自上而下的方法论，能够让我们针对不同场景下的性能瓶颈，以最低的成本去提升系统性能。

###### X 轴扩展 | 应用负载均衡

![1632542998175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542998175.png)

- **特点**：
  1. 在应用层做 X 轴扩展，需要处理业务的应用进程属于**无状态服务**，用户数据全部放在了关系数据库中。
  2. 此时可以在应用进程前加 1 个负载均衡服务，通过部署更多的应用进程，来获得更大的系统容量。
- **优点**：
  - 成本最低，实施简单：在搭建好负载均衡后，只需要在新的物理机、虚拟机或者微服务上复制程序，就可以让新进程分担请求流量，而且不会影响事务的处理。
  - 解决了**应用程序的单点故障**，提高了系统的可用性。
- **缺点**：只能扩展无状态服务，当有状态的数据库出现性能瓶颈时，应用层的 X 轴扩展就无能为力了。
  1. 当请求用户频率越来越高，这时可以把单实例数据库扩展为主备多实例，在数据库层沿 X 轴**读写分离**提升性能。
  2. 当业务持续发展，数据库的 CPU、网络带宽、内存、磁盘 IO 等某个指标率先达到上限后，系统的吞吐量就达到了瓶颈，这时可以在数据层库层沿 Y 轴`垂直分表` 提升性能。
  3. 当用户数据量持续增长，关系数据库中的表就会达到百万、千万行数据，SQL 语句会越来越慢，这时可以沿着 Z 轴**分库分表**提升性能。
- **适用场景**：发展初期，业务复杂度低，需要增大系统容量时。

###### X 轴扩展 | 读写分离

![1632544601407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632544601407.png)

- **特点**：
  - 把数据库按应用程序的读写操作拆分后，用复制的方式把数据库单机架构扩展为主从架构，让主库支持读写两种 SQL，而从库只支持读 SQL。
  - 如果读库性能达到了瓶颈，还可以继续沿着 X 轴扩展多个从库，提升读 SQL 的性能。
- **优点**：
  - 实现简单，读写分离成本由中间件承担。
  - 实现了**数据库的故障转移**，进一步提高了系统的可用性。
- **缺点**：应用中编写代码的成本有所增加，且主从复制存在数据一致性问题。
- **适用场景**：读频率远大于写频率，影响到系统性能时。

###### Y 轴扩展 | 垂直分表

![1632544928615](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632544928615.png)

- **特点**：当业务持续发展，数据库的 CPU、网络带宽、内存、磁盘 IO 等某个指标率先达到上限后，系统的吞吐量就达到了瓶颈，拆分系统功能，使得各组件的职责、分工更细，从而提升系统的效率。
- **优点**：
  - 每个后端的子应用更加聚焦于细分的功能，使得数据库规模会变小，更容易优化性能。
  - 实现了**数据库的故障隔离**，进一步提高了系统的可用性。
- **缺点**：拆分功能需要重构应用代码，成本对比较沿 X 轴的复制扩展要高得多。
- **适用场景**：业务复杂，代码耦合度高，非数据量导致的单库压力大时。

###### Z 轴扩展 | 分库分表

![1632547686194](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632547686194.png)

- **背景**：当用户数量上亿后，无论怎样基于 Y 轴的功能去垂直拆分表字段，都无法使得关系数据库单个表的行数在千万级以下，这样表字段的 B 树索引非常庞大，难以完全放在内存中，最后大量的磁盘 IO 操作会拖慢 SQL 语句的执行。
- **特点**：沿 Z 轴拆分关系数据库，进行**分库分表**操作。
  - 比如已经含有上亿行数据的 User 用户信息表，可以分成 10 个库，每个库再分成 10 张表，利用固定的哈希函数，就可以把每个用户的数据映射到某个库的某张表中。
  - 这样，单张表的数据量就可以降低到 1 百万行左右，如果每个库部署在不同的服务器上，它们处理的数据量减少了很多，却可以独占服务器的硬件资源，性能自然就有了提升。
- **优点**：
  - 是关系数据库中解决数据增长压力的最有效办法，可以降低数据持续增长的压力，提升系统性能。
  - 还可以从 `用户维度` 拆分系统，基于用户的地理位置获得额外收益。
    - 比如充分利用 IDC 与用户间的网速差，选择不同速度的 IDC，为不同的用户，提供不同性能的服务。
    - 再如将不同的用户分组，免费用户组与付费用户组，在业务上分离用户群体后，然后有针对性地为不同组的用户提供不同水准的服务。
- **缺点**：
  - 导致跨表的查询语句复杂许多，而跨库的事务几乎难以实现，应用程序代码编码成本高。
    - **解决方案**：使用某些厂商提供相应的中间件层，可以降低 Z 轴扩展的代价，同时，分片采用按照 ER 规则进行分片。
  - 当系统需要扩容时，一旦路由规则发生变化，会带来很大的**数据迁移成本**。
    - **解决方案**：使用一致性 hash 算法可以较好的避免这个问题。
  - 跨分片的事务一致性难以保证，当更新内容同时分布在不同库中，不可避免地带来跨库事务问题。
    - **解决方案**：分布式事务和最终一致性。
- **场景**：单表数据过大，影响系统性能时。

##### Redis AKF 拆分

![1632542544732](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632542544732.png)

###### X 轴扩展 | 主从复制

- **特点**：
  1. 按照主从设计，Master 负责读写， Slave 负责读。
  2. 再结合哨兵集群，在 Master 故障时，使用 Slave 进行切换，从而实现高可用。
- **优点**：
  1. 主从，解决了读并发压力大的问题。
  2. 哨兵，解决了单点故障问题。
- **缺点**：单机容量会有限制，并且会出现写并发压力大的问题。

###### Y 轴扩展 | 业务拆分

- **特点**：
  - 把 Redis 所有键，按照业务进行拆分，拆分到不同的 Redis 实例上。
  - 可以在 Y 轴的基础上，再进行 X 轴的主从复制的扩展，形成不同业务的 Redis 集群。
- **优点**：从分离不同业务数据的角度，暂时解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：当某个业务的集群达到一定规模后，如果数据量过大，仍然会出现单机容量受限，以及写并发压力大的问题。

###### Z 轴扩展 | 数据分区

- **特点**：
  - 将全部 Key 数据根据分区规则分成多个子集，并存储到 Redis 实例中。
  - 可以在 Z 轴的基础上，叠加 X 轴的主从复制，集群内进行数据分片，比如 Redis Cluster。
  - 可以再叠加 Y 轴的业务拆分，把整个 Redis 系统划分成多个不同业务的、数据分片过的 Redis Cluster。
- **优点**：增加了整个集群的算力、带宽和内存，从根本上解决了单机容量受限，以及写并发压力大的问题。
- **缺点**：
  - 数据分区后，不支持跨实例的命令与事务。
  - 备份管理要复杂得多。
  - 扩缩容时可能需要对数据再平衡。

### 2.2. Redis经典问题？

#### 缓存击穿

- **概念**：缓存中某一个热点数据，在某一时刻**失效**了，导致大量**并发**请求压垮数据库，就像被击穿了一样。
  - 说白了就是，某个数据在数据库中有，但是在缓存中没有。
- **解决方案**：
  1. **保证缓存一直存在**：以缓存**失效**作为切入点，通过保证缓存一直存在，避免或者减少击穿的发生。
     - **优点**：由于缓存长时间存在，且只在更新时才需要加互斥锁，整体吞吐量高。
     - **缺点**：缓存长期存在内存中，Redis 需要设置内存淘汰策略，淘汰非热点数据。
     - **实现方式**：
       - **不设置过期时间**：设置 key 永远不过期，在修改数据库时，同时更新缓存。
       - **定时任务更新**：后台起一个定时任务，每隔一段时间，在 key 快要失效时，提前将 key 刷新为最新数据。
       - **获取前更新**：每次获取前，检查 key 剩余过期时间，如果发现快过期了，则更新该 key。
       - **Redis 分级缓存**：缓存两份 Redis 数据，第 1 份数据用于被请求命中，第 2 份数据作为备份，生存时间设置得较第 1 份的长一点，如果第 2 份数据被命令则说明第 1 份数据已过期，此时要去查询数据库，更新这两级缓存。
  2. **保证数据库安全**：以**并发**请求数据库作为切入点，虽然保证了缓存一直存在，但在 Redis 发生内存淘汰时，还是可能发生击穿的，此时还需要保证数据库的安全。实现方式有：
     - **分布式锁**：只有获取到互斥锁的线程才能访问数据库，然后在释放锁前重新设置缓存；而其他获取锁失败的线程在唤醒后，不再访问数据库，而是查询缓存。
       - **优点**：可以在缓存更新时，实现互斥访问数据库，保证不被压垮。
       - **缺点**：
         1. 分布式锁本身也存在缺点。
         2. 需要搭配缓存一直存在机制使用，保证吞吐量。
         3. 如果只使用互斥锁来防止击穿，在获取锁失败时，快速返回默认值，也可以保证吞吐量。
     - **分级缓存**：Ehcache、Guava 本地缓存 + Hystrix限流、降级、熔断，避免 MySQL 被打死。
       - **优点**：有多级缓存和限流熔断机制来兜底。
       - **缺点**：增加了系统架构复杂度；本地缓存没有分布式一致性可言。
  3. **缓存预热**：见缓存预热。

#### 缓存雪崩

- **概念**：指大面积的 key 同时**失效**，导致大量**并发**请求压垮数据库。
  - 同样也是，某个数据在数据库中有，但是在缓存中没有。
- **缓存击穿与缓存雪崩**：
  1. 缓存击穿指的是，压垮数据库的所有并发请求都是只查同一条数据。
  2. 而缓存雪崩指的是，大量 key 同时失效，压垮数据库的所有并发请求，等于这些失效 key 的并发请求之和。
  3. 因此，可以把缓存雪崩中这些失效 key，拆成一个一个 key，从而把缓存雪崩看做成一个一个缓存击穿的集合。
- **解决方案**：
  1. **分散过期时间**：以缓存**失效**作为切入点，通过把 key 的过期时间设置成随机的，防止同一时间大量 key 同时失效的发生。
     - **优点**：简单有效。
     - **缺点**：不适合实时性要求比较高的业务，比如游戏的每日两点更新、财报记录等，它们都是需要在一个固定的时间，保证数据刷新，并且不允许出现旧数据。
  2. **分散并发请求**：同缓存击穿。

#### 缓存穿透

- **概念**：指由于请求了数据库也不存在的数据，导致缓存一直没有数据，大量并发绕过了缓存，从而压垮了数据库。
- **缓存击穿与缓存穿透**：
  1. 缓存击穿时，数据库里有请求所需数的据。
  2. 缓存穿透时，数据库里并不存在请求所需的数据。
- **解决方案**：
  1. **使用空 key**：对于这种在缓存获取不到，在数据库也获取不到的数据，可以把 key-null 设置到缓存中，这样下次访问时就可以走上缓存了。
     - **优点**：可以用于防止系统被恶意攻击。
     - **缺点**：只适用于数据能为空的 key；如果空 key 数量多且不重复时，则会造成很多无用 key 的存在。
  2. **使用布隆过滤器**：将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉。
     - **优点**：运行快速、内存占用小。
     - **缺点**：
       1. 对于元素的存在结果有误判，并且随着系统的不断运行，误判率会越来越高，此时可以**定期重建**布隆过滤器。
       2. 元素一旦存进布隆过滤器中，删除则十分困难，因为可能会删掉其他元素的 bit 结果，此时可以使用额外的删除标记变量进行**逻辑删除**。
  3. **后端接口增加校验**：比如用户鉴权校验、ID 基础校验等（ID <= 0的请求则直接拦截掉）。
     - **优点**：属于网关请求过滤，能过滤掉恶意请求。

#### 缓存预热

- **概念**：指在请求被缓存前，提早把相关的数据加载到缓存系统中，避免**初次击穿**问题的发生。
- **实现方式**：
  - **启动时加载**：在系统上线时，把相关可预期（比如排行榜）等热点数据，直接加载到缓存中。
  - **页面手动刷新**：也可以写一个缓存刷新页面，手动操作热点数据上下线（比如广告推广）。
- **优点**：保证了系统一开始就有缓存存在，能够在一定程度上避免**初次击穿**的发生。
- **缺点**：只能保证提前加载能够确定的热点数据，对于运行时的热点数据，还是需要靠以上两种方案。

#### 缓存降级

- **概念**：当访问量剧增、服务出现问题（如响应时间慢、甚至不响应），导致非核心服务影响到了核心流程的性能时，可以根据一些关键数据进行**自动降级**，也可以配置开关实现**人工降级**，从而保证核心服务可用性，即使是可能损害非核心服务。
- **实现方式**：比如基于日志级别实现的方案：
  1. **一般级别**：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以**自动降级**。
  2. **警告级别**：比如有些服务在一段时间内，成功率有所波动（比如在95~100%之间），可以**自动降级或人工降级**，并发送**告警**。
  3. **错误级别**：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阈值时，可以根据情况**自动降级或者人工降级**。
  4. **严重错误级别**：比如因为特殊原因数据错误了，此时需要**紧急人工降级**。
- **优点**：可以防止因非核心业务导致的 Redis 服务故障，从而保证核心服务的高可用，因此，对于**不重要的**缓存数据，可以采取缓存降级的策略。
- **缺点**：在进行降级之前，需要要对系统业务进行梳理，哪些可降级的，哪些是不可降级的（比如核心业务购物车、结算等）。

#### 缓存一致性

##### 一致性保证

- **概念**：在缓存机器的带宽被打满，或者机房网络出现波动时，**缓存更新失败**，新数据没有写入缓存，就会导致**缓存和DB**数据的不一致。
- **解决方案**：
  - **最终一致性保证**：
    1. Cache 更新失败后，可以进行重试，则将重试失败的 key 写入mq。
    2. 待缓存访问恢复后，将这些 key 从缓存**删除**。
    3. 然后 key 在再次被查询时，会重新从 DB 加载，从而保证数据的一致性。
    4. 另外，缓存 key 的过期时间可以适当地调短，让缓存数据及早过期，然后从 DB 重新加载，确保数据不一致的情况不会持续很长时间。
  - **强一致性保证**：读请求和写请求串行化，串到一个内存队列里去。
    - **缺点**：串行化之后，就会导致系统的吞吐量会大幅度的下降，正常情况下，需要多几倍的机器去支撑线上的一个请求。

##### 缓存模式

###### Cache-Aside

![1632829929514](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632829929514.png)

- **概念**：Cache-Aside，旁路缓存，缓存系统不和数据库直接进行交互，而是由应用程序同时和缓存以及数据库打交道，可能是项目中最常见的一种模式，是一种控制逻辑都实现在应用程序中的模式。
- **原理**：
  - **读数据时**：
    1. 应用程序需要判断缓存中是否已经存在数据。
    2. 当缓存中已经存在数据，也就是缓存命中时，则直接从缓存中返回数据。
    3. 当缓存中不存在数据，也就是缓存未命中时，则先从数据库里读取数据，并且存入缓存，然后返回数据。
  - **写数据时**：
    - **策略一**：先更新数据库，再更新缓存。
      - **缺点**：存在线程安全问题，当线程 A 先于 B 写入数据库，却后于 B 才更新缓存时，会导致数据库和缓存的数据不一致。
      - **解决方案**：加锁保证写入数据库和更新缓存操作的原子性。
    - **策略二**：先更新数据库，再删除缓存中的数据，下次在读取缓存时，才从数据库中重新加载。
      - **缺点**：数据最终一致性，在重新加载缓存时，数据库刚好被更新，此时就读到了旧的缓存，相当于发生了**脏读**。
      - **适合场景**：业务允许暂时不一致的场景。
  - **优点**：和 Write-Through 模式相比，避免了任何数据都被写入缓存，导致**缓存频繁更新**的问题。
  - **缺点**：
    - 当发生缓存未命中时，则从请求到成功获取缓存的过程会比较慢，因为需要经过三个步骤，先查询缓存，再数据库读取，最后写入缓存。
    - 复杂的逻辑都在应用程序中，如果实现微服务，多个微服务中会有这些重复的逻辑代码。
  - **使用场景**：适用于**不支持 Read-Through/Write-Through** 的缓存系统。

###### Read-Through/Write-Through

- **概念**：这种模式中，应用程序将**缓存**作为主要的数据源，而数据库对于应用程序是透明的，更新数据库和从数据库的读取的任务，都交给缓存来代理了，因此对于应用程序来说，实现时可以简单很多。

- **原理**：

  - **Read-Through**：

    1. 缓存配置了一个**读模块**，它知道如何将数据库中的数据写入缓存。
    2. 在数据被请求的时候，如果未命中，则将数据从数据库载入缓存。

    ![1632831602956](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632831602956.png)

  - **Write-Through**：

    1. 缓存配置了一个**写模块**，它知道如何将数据写入数据库。
    2. 当应用要写入数据时，缓存会先存储数据，并调用写模块将数据写入数据库。

    ![1632831718553](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632831718553.png)

- **优点**：

  - 缓存不存在脏数据，相较于Cache aside而言更适合**缓存一致**的场景。
  - 屏蔽了底层数据库的操作，使得只需要操作缓存，应用程序逻辑相对简单。

- **缺点**：写多读少时，Write-Through 会非常浪费性能，因为数据可能更改了很多次，却没有被读取，白白地每次都写入缓存，造成写入延迟。

- **使用场景**：适用于**写入之后经常被读取**的应用。

###### Write-Behind

![1632832224155](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632832224155.png)

- **概念**：又叫 Write-Back，和 Write-Through 写入的时机不同，Write-Back 将缓存作为可靠的数据源，每次都只写入缓存，而写入数据库则采用异步的方式，比如当数据要被移除出缓存时再存储到数据库，或者在一段时间后批量更新数据库。
- **优点**：
  - 写入和读取数据都非常的快，因为都是从缓存中直接读取和写入。
  - 对于数据库不可用的情况有一定的容忍度，即使数据库暂时不可用，系统也整体可用，在数据库恢复后，再将数据写入数据库。
- **缺点**：有数据丢失的风险，如果缓存挂掉而数据没有及时写到数据库时，则缓存中有些数据会永久的丢失。
- **使用场景**：读写效率都非常好，由于是异步存储到数据库，提升了写的效率，适用于**读写密集**的应用。
  - 比如微博对一些计数业务，一条 Feed 会被点赞 1万 次，如果每次都更新 DB，前后需要更新 1万 次 DB， 代价很大；但如果每次只更新缓存，再合并成一次请求 DB 直接加 1万，则是一个非常轻量的操作。

###### Write-Around

![1632832607368](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632832607368.png)

- **概念**：和 Write-Through 不同，与 Write-Behind 相反，Write Aroud 更新时只写入数据库，不写入缓存。
- **优点**：写效率高，对比 Write-Through，如果数据写入后很少被读取，缓存也不会被没用到的数据占满。
- **缺点**：如果数据被写入多次，则可能导致缓存和数据库的数据不一致。
  - 可以结合 Read-Through 或者 Cache-Aside读 一起使用，只在缓存未命中的情况下写缓存，保证数据的最终一致性。
- **使用场景**：适合于**只写入一次而很少被读取**的应用。

#### Hot Key 问题

- **概念**：指在某个时刻，大量并发请求访问同一个 Key，导致 Redis 服务器压力过大甚至压垮。

  - 明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618 等线上促销活动，都很容易出现 Hot Key 的情况。

- **如何提前发现 Hot Key**？提前找到 Hot Key，可以先进行缓存预热，避免**初次击穿**问题的发生。

  1. **提前评估**：对于重要节假日、线上促销活动这些提前已知的事情，可以**提前评估**出可能的 Hot key 来。
  2. **实时分析**：而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行**实时分析**，及时发现新发布的 Hot Key。而对于之前已发出的事情，逐步发酵成为 Hot Key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频 Hot Key。

- **解决方案**：

  1. **分散 Hot Key**：这 n 个 key 分散存在多个缓存节点，然后 Client 端请求时，随机访问其中某个后缀的 Hot Key，这样就可以把 Hot Key 的请求打散，避免一个缓存节点过载。
  2. **限制逃逸流量**：和缓存击穿一样，通过加锁或者分散的方式，来限制逃逸流量，使得只有一个请求进行数据回源，并刷新本地缓存与 Redis 缓存，其他请求则等待后直接从缓存中的读取。
  3. **水平+垂直扩容**：缓存集群可以单节点进行主从复制和业务拆分（垂直分表）。
  4. **应用本地缓存**：利用应用内的本地缓存，但是需注意需要设置上限。
  5. **定时刷新**：延迟不敏感，定时刷新，实时感知用主动刷新。

  => 无论如何设计，最后都要写一个**兜底逻辑**，千万级流量说来就来。

#### Big Key 问题

- **概念**：指 key 存放的 value 非常大，由于 Redis 是单线程运行的，如果一次操作的 value 很大，则会对 Redis

  服务器长时间进入网络 I/O 拥塞，响应时间增大。

  - 比如互联网系统中需要保存用户最新1万个粉丝的业务，常常会出现 Big Key，因为一个用户个人信息缓存，包括基本资料、关系图谱计数、发 feed 统计等。
  - 再如，微博的 feed 内容缓存也很容易出现 Big Key，一般用户微博在 140 字以内，但很多用户也会发表 1千字甚至更长的微博内容，这些长微博也就成了 Big Key。

- **解决方案**：将 value 要存的大对象，分拆为多个小对象，然后通过 `multiGet` 来获取，这样可以把单次操作的压力，**平摊**到多个 Redis 实例中，降低对单个 Redis 的 I/O 影响。

### 2.3. Redis调优？

Redis 调优，可以根据缓存架构设计过程中常见的考量点入手：

https://blog.csdn.net/hualaoshuan/article/details/102638188

![1632893948796](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1632893948796.png)

#### 缓存读写方式

- **考量内容**：value 读写方式，是选择全部整体读写，还是只部分读写及变更。

  - 比如，用户粉丝数，很多普通用户的粉丝有几千到几万，而大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表肯定不能采用整体读写的方式，**只能部分获取**。
  - 再如，在判断某用户是否关注了另外一个用户时，不需要拉取该用户的全部关注列表，可以直接在关注列表上进行**检查判断**，然后返回 True / False 或 0 / 1 的方式更为高效。

- **调优原则**：

  1. 避免使用 `keys`、`smembers` ，这些命令操作执行期间是阻塞其他客户端的，如果数据量大时，其阻塞的时间是不可接受的。

     - **解决方案**：生产上，可以使用增量式迭代命令 `scan`、`sscan`、`hscan`、`zscan` 命令来替代 `keys` 和 `smembers`，但增量迭代过程中 key 有可能会被修改，所以只能对被返回的元素提供有限的保证。

     | 命令  | 使用                                      | 作用                                                         |
     | ----- | ----------------------------------------- | ------------------------------------------------------------ |
     | SCAN  | SCAN cursor [MATCH pattern] [COUNT count] | 用于迭代当前数据库中的所有 key，返回的每个元素都是一个数据库键。cursor 使用 0，表示开始一次新的迭代，否则代表迭代时返回的游标，直到返回 0，则代表一次完整遍历；count 用于告知迭代命令需要返回的元素个数，默认为 10；pattern 与 `keys` 命令一样。 |
     | SSCAN | 用法同 `SCAN`                             | 用于迭代集合键中的元素，返回的每个元素都是一个集合成员。     |
     | HSCAN | 用法同 `SCAN`                             | 用于迭代哈希键中的键值对，返回的每个元素都是一个键值对，一个键值对由一个键和一个值组成。 |
     | ZSCAN | 用法同 `SCAN`                             | 用于迭代有序集合中的元素，返回的每个元素都是一个有序集合元素，一个有序集合元素由一个成员 member 和一个 score 组成。 |

  2. 批量添加多条数据时尽量选择 `pipline` ，减少发起多次客户端连接。

#### 缓存 KV Size

- **考量内容**：缓存键值对 key-value 所占用的内存。
- **调优原则**：
  1. 对于 key，尽量使用短的 key，有时可以不用刻意追求"见名知意"的目标，而导致拉大了 key 的长度。
  2. 对于 value，尽量也保持精简，比如性别可以用 0、1 表示。
  3. 对象实体可以尽量使用 `hash` 存储，因为如果使用 `string` 存储，每当要修改其中一项时，就需要把整个对象取回，效率低下，而使用 `hash` 可以很好地解决这个问题。
  4. 某些业务场景可以考虑使用 `bitmap` 来减少不必要的内存使用。

#### 缓存 Key 数量

1. 如果 key 数量不大，可以在缓存中存下**全量数据**，把缓存当 DB 存储来用，缓存读取 miss 时，则表明数据不存在，根本不需要再去 DB 查询。
2. 如果 key 数据巨大，则在缓存中尽可能只保留频繁访问的**热数据**，对于**冷数据**直接访问 DB。
3. 选择合适的内存回收策略，让 Redis 内存被填满了之后，尝试回收一部分key。

#### 缓存读写峰值

1. 对缓存数据的读写峰值，如果**小于 10 万**级别，简单分拆到独立 Redis 即可。
2. 而一旦数据的读写峰值**超过 10 万**甚至到达 100 万级的QPS，则可以同时使用 本地缓存 + Redis，甚至 Redis 缓存内部继续分层。

#### 缓存命中率

缓存的命中率，对整个服务体系的性能影响非常大，对于核心高并发访问的业务，需要预留**足够的容量**，减少内存淘汰的发生，确保核心业务缓存维持较高的命中率。

- 比如，微博中的 Feed Vector Cache，常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。

#### 缓存过期策略

1. 可以设置较短的过期时间，让冷 key 自动过期。
2. 也可以让 key 带上时间戳，同时设置较长的过期时间，比如 key_20191019，过了这个时间就可以把缓存删掉。

#### 缓存穿透时间

对于一些缓存穿透后，**加载时间特别长**或者需要**复杂计算**的数据，而且**访问量还比较大**的业务数据，要配置**更多容量**，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。

#### 缓存可运维性

需要考虑 Redis 的集群管理，如何进行一键扩缩容，如何进行 Redis 的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。

#### 缓存安全性

1. 一方面可以限制来源 IP，只允许内网访问。
2. 另一方面，对于一些**关键性指令**，需要增加**访问权限**，避免被攻击或误操作时，导致重大后果。

# 六、消息队列篇

### 1.1. 什么是消息队列？

#### 概念

- **消息**：Message，指在应用间传送的数据，消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。
- **消息队列**：Message Queue，MQ，是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。
  1. 消息发布者只管把消息发布到 MQ 中，而不用管谁来取。
  2. 消息使用者只管从 MQ 中取消息而不管是谁发布的。
  3. 这样发布者和使用者都不用知道对方的存在，解除了上下游调用的依赖关系，实现异步和解耦。
  4. MQ 作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。
  5. 目前主流的消息队列有 ActiveMQ、Kafka、RocketMQ、RabbitMQ 等。

#### 用途

- **异步处理**：把消息写入消息队列，使得**非必要**的业务逻辑能够以异步的方式运行，从而加快响应速度。

  ![1633838988599](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633838988599.png)

- **系统解耦**：解决不同重要程度、不同能力级别系统之间依赖导致一死全死的问题。

  ![1633838915140](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633838915140.png)

- **削峰填谷**：主要解决瞬时写压力大于应用服务能力，把瞬时的大数据量放到后面慢速消费掉，从而导致消息丢失、系统奔溃等问题。

- **蓄流压测**：线上有些链路不好压测，可以通过堆积一定量消息再放开来压测。

- **其他用途**：广播订阅、RPC 调用、日志收集、数据同步、数据采集、分布式事务支持等。

#### 局限

- **系统可用性降低**：本来系统运行好好的，如果加个消息队列进去，那消息队列挂了，系统可用性就可能会降低。
- **系统复杂性增加**：增加消息队列组件，要多考虑很多方面的问题，系统复杂性增大，比如一致性问题、如何保证消息不被重复消费、如何保证保证消息可靠传输等。

#### 技术选型

##### 基础对比

| 比较点     | Kafka                                                        | RocketMQ                                          | RabbitMQ                          |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------- | --------------------------------- |
| 设计定位   | 系统间的数据流管道，实时数据处理                             | 非日志的可靠性传输                                | 可靠消息传输                      |
| 使用场景   | 常规的消息系统、网站活性跟踪、监控数据、日志收集、处理等     | 订单、交易、充值、流计算、消息推送、binlog 分发等 | 类似于RocketMQ                    |
| 成熟度     | 日志领域成熟                                                 | 成熟                                              | 成熟                              |
| 所属社区   | Apache                                                       | Alibaba 开发，现已加入到 Apache下                 | Mozilla Public License            |
| 社区活跃度 | 高                                                           | 中                                                | 高                                |
| API完备性  | 高                                                           | 高                                                | 高                                |
| 文档完备性 | 高                                                           | 高                                                | 高                                |
| 开发语言   | Scala                                                        | Java                                              | Erlang                            |
| 支持协议   | 一套自行设计的基于TCP的二进制协议                            | 自定义的一套非JMS协议                             | AMQP                              |
| 客户端语言 | C/C++、Python、Go、Erlang、.NET、Ruby、Node.js、PHP、Java 等 | Java                                              | Java、C、C++、Python、PHP、Perl等 |

##### 功能对比

|                | Kafka                                        | RocketMQ                                                     | RabbitMQs                                                    |
| -------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 生产端负载均衡 | 可自由指定                                   | 可自由指定                                                   | 需要单独的Load balancer支持                                  |
| 生产端批量发送 | 支持，默认Producer缓存、压缩，然后批量发送   | 不支持                                                       | 不支持                                                       |
| 消费 失败重试  | 支持，offset存储在ZK中                       | 支持，offset存储在broker中                                   | 支持                                                         |
| 消费方式       | Consumer Pull                                | Consumer pull、Broker push                                   | Broker push                                                  |
| 消费并行度     | 消费并行度和分区数一致                       | 顺序消费：消费并行度和分区数一致；乱序消费：消费服务器的消费线程数之和 | 镜像模式下其实等价于从Master消费                             |
| 顺序消费       | 支持，但是一台broker宕机后，就会产生消息乱序 | 支持，在顺序消息场景下，消费失败时消息队列将会暂定           | 支持，但是如果一个消费失败，消息的顺序会被打乱               |
| 消息重新消费   | 支持，通过修改offset来重新消费               | 支持，按照时间重新消费                                       | -                                                            |
| 定时消息       | 不支持                                       | 开源版本仅支持定时Level                                      | 不支持                                                       |
| 事务消息       | 不支持                                       | 支持                                                         | 不支持                                                       |
| 消息过滤       | 不支持                                       | 支持，通过tag过滤，类似于子topic                             | 不支持                                                       |
| 消息查询       | 不支持                                       | 支持，根据MessageId查询，支持根据MessageKey查询信息          | 不支持                                                       |
| 消息清理       | 指定文件保存时间，过期删除                   | 指定文件保存时间，过期删除                                   | 默认可用内存40%触发GC，GC时找到相邻的两个文件，合并right文件到left |

##### 高可用对比

|            | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储方式   | 磁盘文件                                                     | 磁盘文件                                                     | 内存、文件                                                   |
| 部署依赖   | Zookeeper                                                    | NameServer                                                   | Erlang环境                                                   |
| 部署方式   | 单机、集群                                                   | 单机、集群                                                   | 单机、集群                                                   |
| 集群管理   | Zookeeper                                                    | NameServer                                                   | -                                                            |
| 选主方式   | 从 ISR 中自动选举一个 Leader                                 | 不支持自动选主，brokername相同，brokerid = 0时为Master了，其他为Slave | 最早加入集群的broker                                         |
| 主从切换   | 支持，一主多备，Master失效后自动从ISR中选择一个主            | 不支持，Master失效以后不能消费，Consumer默认30s可以感知此事，此后从Slave消费，如果Master无法恢复，异步复制时可能会丢失部分消息 | 支持，最早加入集群的Slave会成为Master，由于新加入的Slave不会同步Master之前的数据，所以可能会丢失部分数据 |
| 复制备份   | 消息写入到Leader的log，Followers从Leader中pull，pull到数据以后先ack Leader，然后写入log中，ISR中维护与Leader同步的列表，落后太多的Follower会被删除掉 | 同步双写、异步复制（Slave启动线程从Master中拉数据）          | 普通模式下不复制；镜像模式下，消息先到Master，然后镜像到Slave上，入集群之前的消息不会被复制到新的Slave上 |
| 可用性     | 非常高，分布式、主从                                         | 非常高，分布式、主从                                         | 高，主从、镜像模式（数据量大时可能产生性能瓶颈）             |
| 数据可靠性 | 很好，支持Producer单条发送、同步复制，但这种场景下性能明显下降 | 很好，Producer单条发送，broker端支持同步刷盘、异步刷盘、同步双写、异步复制 | 好，Producer支持同步、异步ACK，支持队列数据持久化，镜像模式中支持主从同步 |

##### 运维对比

|              | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                 |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | -------------------------------------------------------- |
| 系统维护     | Scala语言开发，维护成本高                                    | Java语言开发，维护成本低                                     | Erlang语言开发，维护成本高                               |
| 访问权限控制 | 无                                                           | 无                                                           | 支持配置用户名和密码                                     |
| 管理后台     | 官网不提供，第三方开源管理工具可供使用，不用重新开发         | 官方提供，rocketmq-console                                   | 官方提供，rabbitmqadmin                                  |
| 管理后台功能 | broker、topic、partition、logsize、consumer groups、offset、cluster | cluster、topic、connection、nameserv、message、broker、offset、consumer | overview、connection、channels、exchanges、queues、admin |

#### 技术选型总结

|                  | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                     | Java                      |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------- |
| 开发语言         | Scala                                                        | Java                                                         | Erlang                                                       | Java                      |
| 单机吞吐量       | 10w级别                                                      | 10w级别                                                      | 1w级别                                                       | 1w级别                    |
| 消息写入性能     | 非常好，每条10个字节测试下，100w/s                           | 很好，每条10个字节测试下，单机单broker约7w/s，单机3个broker约12w/s | RAM模式约为RocketMQ的1/2，Disk模式性能约为RAM模式的1/3       | -                         |
| 消息投递实时性   | 毫秒级，具体由Consumer轮询间隔时间决定                       | 毫秒级，支持pull、push两种模式，延时通常在毫秒级             | 毫秒级                                                       | 毫秒级                    |
| 单机支持的队列数 | 单机超过64个队列/分区，Load会发生明显的飙高，队列越多，Load越高，发送消息的响应时间越长 | 单机支持最高5w个队列，并且Load不会发生明显变化               | 依赖于内存                                                   | -                         |
| 堆积能力         | 非常好，消息存储在log中，每个分区一个log文件                 | 非常好，所有消息存储在同一个commit log中                     | 一般，生产者、消费者正常时，性能表现稳定；消费者不消费时，性能不稳定 | -                         |
| 性能稳定性       | 队列/分区多时，性能不稳定、明显下降；消息堆积时，性能稳定    | 队列较多、消息堆积时，性能都稳定                             | 消息堆积时，性能不稳定、明显下降                             | -                         |
| 可用性           | 非常高，分布式、主从                                         | 非常高，分布式、主从                                         | 高，主从、镜像模式                                           | 高，Master-Slave、Network |
| 数据可靠性       | 很好，支持Producer单条发送、同步复制，但这种场景下性能明显下降 | 很好，Producer单条发送，broker端支持同步刷盘、异步刷盘、同步双写、异步复制 | 好，Producer支持同步、异步ACK，支持队列数据持久化，镜像模式中支持主从同步 | 有较低概率丢失数据        |

##### 为什么使用 Kafka？

高可用，几乎所有相关的开源软件都支持，满足大多数的应用场景，尤其是**大数据和流计算**领域。

- **优势**：
  - 高性能，高吞吐，消息持久化，可伸缩，支持分区、副本和容错。
  - 对批处理和异步处理做了大量的设计，因此可以得到非常高的性能，每秒处理几十万异步消息，如果开启了压缩，最终可以达到每秒处理 2000w 消息的级别。
- **局限**：
  - 由于是异步的和批处理的，延迟也会高，不适合电商场景。
  - 不支持事务。
  - 消费集群数目受 Partition 数目限制。
  - 单机 Topic 多时，性能会明显降低。
- **使用建议**：
  1. Kafka 提供的消息中间件的功能明显较少一些，相对上述几款 MQ 中间件要少很多。
  2. 但是 Kafka 优势在于，专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。
  3. 因此，Kafka在大数据领域中配合实时计算技术（比如Spark Streaming、Storm、Flink）使用的较多，在传统的 MQ 中间件使用场景中较少采用。
  4. 如果是大数据领域的**实时计算、日志采集**等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

##### 为什么使用 RocketMQ？

借鉴了Kafka的设计并做了很多改进，几乎具备了消息队列应该具备的**所有特性和功能**。

- **优势**：
  - 主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。
  - 对电商领域的响应延迟做了很多优化，每秒处理**几十万**的消息，同时响应在毫秒级，如果应用很关注响应时间，可以使用RocketMQ，性能比RabbitMQ高一个数量级，同时，经过了历次的双11考验，性能，稳定性可靠性没的说。
  - Java开发，阅读源代码、扩展、二次开发很方便。
- **局限**：
  - 消息堆积、吞吐量上不如Kafka。
  - 不支持主从自动切换，master失效后，消费者需要一定的时间才能感知。
  - 客户端只支持Java，跟周边系统的整合和兼容不是很好。
- **使用建议**：
  1. RocketMQ，是阿里开源的，经过阿里的生产环境的超高并发、高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。
  2. 而且RocketMQ是基于Java语言开发的，适合深入阅读源码，有需要可以站在源码层面解决线上生产问题，包括源码的二次开发和改造。
  3. RocketMQ，确实很不错，但社区活跃度其实不算高，可能有突然黄掉的风险，如果对公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，毕竟 RabbitMQ 有活跃的开源社区，绝对不会黄，所以**大型公司，基础架构研发实力较强**，用 RocketMQ 是很好的选择。

##### 为什么使用 RabbitMQ？

RabbitMQ开始是用在电信业务的可靠通信的，也是少有的几款**支持AMQP**协议的产品之一。

- **优势**：
  - 轻量级、低延迟，快速，部署使用方便。
  - 支持灵活的路由配置，在生产者和队列之间有一个交换器模块，根据配置的路由规则，生产者发送的消息可以发送到不同的队列中，路由规则很灵活，还可以自己实现。
  - 客户端支持大多数的编程语言，支持**AMQP**协议。
- **局限**：
  - 消息吞吐能力有限，如果有大量消息堆积在队列中，性能会急剧下降，每秒处理**几万到几十万**的消息，如果应用要求高的性能，注意不要选择 RabbitMQ。
  - 不支持事务。
  - 集群不支持动态扩展，横向扩展能力不是那么好。
  - RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。
- **使用建议**：
  1. 好处在于可以支撑高并发、高吞吐、性能很高，同时有非常完善便捷的后台管理界面可以使用，还支持集群化、高可用部署架构、消息高可靠支持，功能较为完善。
  2. 经过调研，国内各大互联网公司落地大规模 RabbitMQ 集群支撑自身业务的 case 较多，国内各种中小型互联网公司使用 RabbitMQ 的实践也比较多，同时开源社区很活跃，较高频率的迭代版本，来修复发现的bug以及进行各种优化，因此综合考虑过后，可以采取 RabbitMQ。
  3. 但是 RabbitMQ 也有一点缺陷，就是它自身是基于 Erlang 语言开发，导致较为难以分析里面的源码，也较难进行深层次的源码定制和改造，毕竟需要较为扎实的 Erlang 语言功底才可以。
  4. RabbitMQ 的 Erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高，管理功能很丰富，所以**中小型公司，技术实力较为一般，技术挑战不是特别高**，用 RabbitMQ 是不错的选择。

##### 为什么使用 ActiveMQ？

ActiveMQ，是老牌的消息中间件，国内很多公司过去运用的还是非常广泛的，功能很强大。

- **使用建议**：
  1. 由于 ActiveMQ 无法支撑互联网公司的高并发、高负载以及高吞吐的复杂场景，因此，在国内互联网公司落地较少，使用较多的还是一些**传统企业**，用 ActiveMQ 进行异步调用和系统解耦。
  2. 一般的业务系统最早都用 ActiveMQ，但是现在确实用的不多了，而且没经过大规模吞吐量场景的验证，社区也不是很活跃，所以还是算了吧，不推荐使用。

#### 如何设计消息队列？

##### 生产端可靠性投递

如果涉及的是金融相关的业务， 需要保证消息一定不能丢失，做到生产端发出消息时跟数据库操作保持一个原子性操作。

##### 幂等性消费

由于生产者需要做到可靠性投递，可能会出现重复的消息，如果重复的消息被消费者消费了两次或者多次，可能会导致数据的不一致，所以，此时消费端一定要做到一个幂等性的验证。

##### 高可用性

如果MQ一个Broker挂掉了， 应该如何保证服务的高可用？ => HA

##### 低延迟

在MQ面对巨量的流量冲压下，应该如何消息写入的低延迟？是否会给系统带来瓶颈？

##### 可靠性

在消息落到MQ，应该如何保障肯定不会丢失？比如磁盘损坏 => 副本的方式

##### 堆积能力

某个业务场景下，到底有多少的数据量，大体预估消息高峰期会堆积到什么程度？MQ能不能抗住流量的冲击？

##### 可扩展性

MQ能否天然的支持无感知横向扩容？

### 1.2. 什么是 JMS？

#### 概念

- JMS，Java Message Service，Java 消息服务，定义了 Java 中访问消息中间件接口的规范，只是接口并没有给予实现，而实现 JMS 接口的消息中间件称为 JMS Provider。
- 目前知名的MOM（Message Oriented Middleware，消息中间件）包括： ActiveMQ、RocketMQ、Kafka 以及 RabbitMQ，他们都是**基本遵循**或者**参考**JMS规范，都有自己的特点和优势。

| 专业术语          | 释义                                                         |
| ----------------- | ------------------------------------------------------------ |
| JMS               | Java Message Service，实现 JMS 接口的消息中间件              |
| Provider          | Message Provider，消息的生产者                               |
| Consumer          | Message Consumer，消息的消费者                               |
| PTP               | Point to Point，点对点的消息模型                             |
| Pub/Sub           | Publish/Subscribe，发布/订阅模型                             |
| Queue             | 消息队列，一般都是会真正的进行物理存储                       |
| Topic             | 主题目标                                                     |
| ConnectionFactory | 连接工厂，JMS 用它来创建连接                                 |
| Connection        | JMS 客户端到 JMS Provider 的连接                             |
| Destination       | 消息的目的地，指对于生产者来说是消息发送目标，对于消息消费者来说是消息来源 |
| Session           | 会话，一个发送或接收消息的线程，好比Mybatis的Session         |

#### 消息投递模式

##### PTP模式

P2P模式，点对点模式，包含三个角色：消息队列（Queue），发送者（Sender），接收者（Receiver），每个消息都被发送到一个特定的队列，接收者从队列中获取消息，在这期间，队列保留着消息，直到他们被消费或超时。

- **特点**：
  - 每个消息只有一个消费者，即一旦被消费，消息就不再在消息队列中。
  - 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列。
  - 接收者在成功接收消息之后需向队列应答成功。
- **适用场景**：如果希望发送的**每个消息**都会被成功处理的话，那么需要P2P模式。

![1633184806569](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633184806569.png)

##### Pub/Sub模式

Pub/Sub模式，发布订阅模式，包含三个角色：主题（Topic），发布者（Publisher），订阅者（Subscriber） ，多个发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。

- **特点**：
  - 每个消息可以有多个消费者。
  - 发布者和订阅者之间有时间上的依赖性，针对某个主题的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。
  - 为了消费消息，订阅者必须保持运行的状态，另外，为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅，使得即使订阅者没有在运行，它也能接收到发布者的消息。
- **适用场景**：如果希望发送的消息可以**不被做任何处理**、或者**只被一个消息者处理**、或者可**以被多个消费者处理**的话，那么可以采用Pub/Sub模型。

![1633185288754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633185288754.png)

### 1.3. 详细介绍ActiveMQ？

##### 概念

- ActiveMQ，Apache出品，是当前最流行的、能力强劲的开源消息总线。
- ActiveMQ，是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。
- 如果想对大规模、高并发应用服务做消息中间件技术选型，譬如淘宝、京东这种大型的电商网站，尤其是双 11 这种特殊时间，ActiveMQ 可能就显得力不从心了。

##### 特点

1. 多种语言和协议编写客户端。
   - 语言：Java、C、C++、C#、Ruby、Perl、Python、PHP。
   - 应用协议：OpenWire、Stomp REST、WS Notification、XMPP、AMQP.
2. 完全支持 JMS1.1 和 J2EE 1.4 规范 
   - 持久化，XA消息，事务。
3. 对Spring的支持：
   - ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性。
4. 通过了常见 J2EE 服务器（如 Geronimo、JBoss 4、GlassFish、WebLogic）的测试：
   - 其中通过 JCA 1.5 resource adaptors 的配置，可以让 ActiveMQ可以自动的部署到任何兼容 J2EE 1.4 商业服务器上。
5. 支持多种传送协议：
   - in-VM、TCP、SSL、NIO、UDP、JGroups、JXTA。
6. 支持通过 JDBC 和 journal 提供高速的消息持久化。
7. 从设计上保证了高性能的集群：
   - 客户端-服务器，点对点。
8. 支持Ajax。
9. 支持与Axis的整合。
10. 可以很容易得调用内嵌 JMS provider，进行测试。

##### 指标

衡量一个 MOM 消息中间件，主要从三方面考虑即可，即服务性能、存储堆积能力（数据存储）和可扩展性（集群架构）。

- **服务性能**： ActiveMQ 的性能一般，在早期传统行业为王的时代比较流行，但现如今面对高并发、大数据的业务场景，往往力不从心。
- **数据存储**：默认采用 Kahadb（索引文件形式）存储，也可以使用高性能的 google leveldb（内存数据库存储），或者可以使用 MySQL、Oracle 关系型数据库进行消息存储。
- **集群架构**：ActiveMQ 可以与 Zookeeper 构建成主备集群模型，并且多套的主备模型直接可以采用 Network 的方式构建分布式集群。

##### 集群架构模式

ActiveMQ 最经典的两种集群架构模式为：Master-Slave、Network。

- **Master-Slave**：

  - **概念**：顾名思义，即主从，或者主备方式（双机热备机制），是目前 ActiveMQ 推荐的高可靠性和容错的解决方案。
  - **原理**：如果消息被复制到 Slave Broker后，即使 Master Broker 遇到了像硬件故障之类的错误，也可以立即切换到 Slave Broker 而不丢失任何消息。
  - **缺点**：做不到分布式的 topic 和 queue，当消息量巨大时，MQ 集群压力就会过大，没办法满足分布式的需求。

  ![1633244456251](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633244456251.png)

- **Network**：

  - **概念**：可以理解为网络通信方式，也可以叫 Network of Brokers，其消息会进行均衡，真正解决了分布式消息存储、故障转移和 Broker 切换的问题。
  - **原理**：一个 Broker 会相同对待所有的订阅，不管他们是来自本地的客户连接，还是来自远程 Broker，都会递送有关的消息拷贝到每个订阅，远程 Broker 得到这个消息拷贝后，会依次把它递送到其内部的本地连接上。
  - **缺点**：
    1. 部署非常麻烦，需要两套或者多套集群直接相互交叉配置，相互间能够感知到彼此的存在。
    2. 虽然解决了分布式消息队列的问题，但还有许多潜在的问题，比如资源浪费问题。
       - 通常采用 Master-Slave 模型是传统型互联网公司的首选，而互联网公司往往会选择开箱即用的消息中间件，从运维、部署、使用各个方面都要优于 ActiveMQ。

  ![1633244714673](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633244714673.png)

### 1.4. 什么是AMQP？

AMQP，Advanced Message Queuing Protocol，高级消息队列协议，是具有现代特征的二进制协议，是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个**开放标准**，为面向消息的中间件设计。

- **Publisher application**：生产者应用程序，与 Exchage 是多对多的关系。
- **Consumer application**：消费者应用程序，与 Queue 是多对多的关系。
- **Server**：消息队列服务器，物理机。
- **Virtual host**：虚拟主机，用于划分模型域。
- **Exchange**：交换机，类似于主题，是一个逻辑的概念，需要跟 Queue 绑定起来，与 Queue 是多对多的关系。
  - 生产者可以向 Exchange 投递消息，Exchange 会根据一定规则把消息路由到某几个队列中。
- **Message Queue**：消息队列，是一个逻辑的概念，与 Exchange 是多对多的关系。
  - 消费者可以从 Queue 消费消息。

![1633250094430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633250094430.png)

### 1.5. 详细介绍RabbitMQ？

#### 概念

RabbitMQ，是一个开源的、基于Erlang 语言编写的、实现了 AMQP 协议的分布式消息队列系统，采用经典和新颖的消息传递方式，进行跨应用共享数据，其消息路由的强大（广播、直连、主题、首部交换机等）以及容易使用（只需添加和删除消费者即可完成扩展和缩小），使得能够在 MQ 中脱颖而出。

- **通用用途**：异步处理、系统解耦、削峰填谷。
- **特色用途**：广播订阅、RPC 调用。

| 专业术语    | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Server      | 又称 Broker， 指消息队列服务器实体，用于接受客户端的连接     |
| Connection  | 连接，应用程序与 Broker 建立的网络连接                       |
| Channel     | 网络信道，几乎所有的操作都在 Channel 中进行，是进行消息读写的通道（通过 Connection是发送不了消息的），客户端可建立多个 Channel，每个 Channel 代表一个会话任务 |
| Message     | 消息，服务器和应用程序之间传递的数据，由 Properties 和 Body 组成，Properties 可以对消息进行修饰，比如消息的优先级、延迟等高级特性，Body 则是消息体的内容 |
| VHost       | Virtual host，虚拟地址，用于进行**逻辑隔离**，是最上层的消息路由，一个 Vhost 里面可以有若干个 Exchange 和 Queue，但它们的名称不能相同；Vhost 拥有独立的权限系统，可以做到 Vhost 范围的用户控制。 |
| Exchange    | 交换机，接收生产者投递的消息，生产者可以在发送消息时带上 Routing Key，交换机会根据 Routing Key 路由消息到绑定的队列 |
| Binding     | Exchange 和 Queue 之间的虚拟连接，可以包含 Routing Key，把 Exchange 和 Queue按照Routing Key 绑定起来 |
| Routing Key | 路由关键字，一个路由规则，虚拟机可以用来确定如何路由一个消息 |
| Queue       | 又称 Message Queue，消息队列，保存消息并将它们转发给消费者，每个消息可能会被路由到一个或者多个队列 |
| Producer    | 消息生产者，指投递消息的程序                                 |
| Consumer    | 消息消费者，指消费消息的程序                                 |

#### 原理

![1633680788174](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633680788174.png)

1. 一方面，生产者向 Exchange 发送消息。
2. Exchange （比如根据 RoutingKey ）把消息路由到 Queue 或者其他 Exchange中。
3. RabbitMQ Broker 在收到消息时，向生产者发送确认。
4. 另一方面，消费者与 RabbitMQ 保持 TCP 长连接，并声明所消费的 Queue。
5. 消息路由到 Queue 后，RabbitMQ 会向消费者**推送消息**。
   - **为什么推而不是拉？**
     1. 推比拉消息分布更均匀，更适合低延迟。
     2. 当某单个队列出现竞争消费者时，如果每个消费者都拉取消息，由于每个消息者拉取的数量不同，消息分布可能会变得非常不均匀。
     3. 消息分布越不均匀，延迟就越多，消费时消息排序的丢失就越严重。
6. 消息消费完毕，消费者会把消费结果（成功或者失败）返回给 RabbitMQ Broker。
7. RabbitMQ Broker 一旦发现消费者消费成功，就会把消息就从 Queue 中移除。

#### API

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>com.rabbitmq</groupId>
    <artifactId>amqp-client</artifactId>
    <version>3.6.5</version>
</dependency>
```

##### 生产者 | HelloWorld

```java
public static void main(String[] args) throws IOException, TimeoutException {
    // 1. 创建ConnectionFactory
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(HOST);
    connectionFactory.setPort(PORT);
    connectionFactory.setVirtualHost(VIRTUAL_HOST);

    // 2. 创建Connection
    Connection connection = connectionFactory.newConnection();

    // 3. 创建Channel
    Channel channel = connection.createChannel();

    // 4. 创建Queue: 一般不在Java中创建, 而是提前维护好队列
    // Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments) throws IOException;
    channel.queueDeclare(ROUTING_KEY, false, false, false, null);

    // 5. 构建消息
    AMQP.BasicProperties props = new AMQP.BasicProperties.Builder()
        .deliveryMode(2)
        .contentEncoding("UTF-8")
        .headers(new HashMap<String, Object>())
        .build();

    // 6. 发送消息到Queue中
    for(int i = 0; i < 5; i++){
        String msg = "Hello World RabbitMQ" + i;
        // 注意, 这里EXCHANGE_NAME为"", 表示采用了默认的交换机(Direct模式), 因此, 表示把消息路由到名称为ROUTING_KEY的Queue上
        // void basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException;
        channel.basicPublish("", ROUTING_KEY, props, msg.getBytes());
        System.out.println("发送消息完毕...");
    }
}
```

##### 消费者 | HelloWorld

```java
public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {
    // 1. 创建ConnectionFactory
    ConnectionFactory connectionFactory = new ConnectionFactory();
    connectionFactory.setHost(HOST);
    connectionFactory.setPort(PORT);
    connectionFactory.setVirtualHost(VIRTUAL_HOST);
    connectionFactory.setAutomaticRecoveryEnabled(true);
    connectionFactory.setNetworkRecoveryInterval(3000);

    // 2. 创建Connection
    Connection connection = connectionFactory.newConnection();

    // 3. 创建Channel
    Channel channel = connection.createChannel();

    // 4. 创建Queue: 生产者创建了消费者就不用创建了
    // channel.queueDeclare(ROUTING_KEY, false, false, false, null);

    // 5. 创建Consumer
    QueueingConsumer queueingConsumer = new QueueingConsumer(channel);
    // 由于采用了默认的交换机(Direct模式), 因此ROUTING_KEY的消息会路由到名为ROUTING_KEY的Queue中, 所以消费者去ROUTING_KEY队列中拿消息
    // String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;
    channel.basicConsume(ROUTING_KEY, true, queueingConsumer);

    // 6. 拉取 & 监听消息
    System.out.println("开始监听消息...");
    while (true){
        QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
        String msg = new String(delivery.getBody());
        System.out.println("收到消息: " + msg);
    }
}
```

##### Exchange 属性

Exchange，交换机，接收消息，并根据 ROUTING_KEY 转发消息所绑定的队列。

| 属性        | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Name        | 交换机名称                                                   |
| Type        | 交换机类型， direct、topic、fanout、headers                  |
| Durability  | Exchange 是否需要持久化，true表示需要持久化，一般生产都是需要持久化的 |
| Auto Delete | 当最后一个绑定到 Exchange 上的队列被删除后，是否自动删除该 Exchange，不常用，一般生产都是不需要自动删除的 |
| Internal    | 当前 Exchange 是否用于 RabbitMQ 内部使用，外部无法访问；默认为 False，代表外部使用，外部可以访问 |
| Arguments   | 扩展参数，用于扩展 AMQP 协议，来自动化使用，比如特殊功能、或者带延迟功能的交换机 |

###### Direct Exchange

![1633266272323](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633266272323.png)

Direct Exchange，直连交换机，所有发送到 Direct Exchange 的消息，都会被转发到 RoutingKey 指定的 Queue 中。

- 直连模式下，可以不需要对 Exchange 进行任何绑定 binding 操作，比如此时 Exchange 为 ""，则默认使用 RabbitMQ 自带的 Exchange（**AMQP.default**），此时 RoutingKey 为 Queue 的名称。
- 在其他消息传递时，发送时指定的 RoutingKey 必须和 Queue 名称完全匹配时，该消息才会被 Queue 接收，否则该消息会被抛弃。

```java
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, null, msg.getBytes());

// 消费者 - Queue绑定Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ROUTING_KEY);
// 消费者 - 绑定消费队列
// String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Topic Exchange

![1633329219405](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633329219405.png)

Topic Exchange，主题交换机，所有发送到 Topic Exchange 的消息，都会被转发到所有关心该 RoutingKey #Topic 的 Queue上。

- Queue 通过绑定一个 Topic，如果 Exchange 发现某个 RoutingKe 能够与该 Topic 进行**模糊匹配**，则会把消息投递到该 Queue 中。
  - `#` 表示匹配一个或多个词，比如 "log.info.oa" 能够匹配 `log.#`，则 RoutingKey 为 "log.info.oa" 的消息，将会被 Exchange 投递到 Topic 为 `log.#` 的 Queue 中。
  - `*` 表示只能匹配一个词，比如 "log.erro" 能够匹配 `log.*`，则 RoutingKey 为 "log.erro" 的消息，将会被 Exchange 投递到 Topic 为 `log.*` 的 Queue 中。
- Queue 和 Exchange 是多对多的关系，但如果业务上使用多对多的关系，会导致消息投递逻辑比较乱，建议一类消息只搞一种规则（比如 `test.#`），只投递到一个 Exchange 中，一个 Exchange 绑定多个 Queue，然后消费者从 Queue 消费消息。

```java
// 生产者 - topic类型交换机: 实际Routing_key
String routingKey1 = "user.save";
String routingKey2 = "user.update";
String routingKey3 = "user.delete.abc";
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, routingKey1, null, msg.getBytes());
channel.basicPublish(EXCHANGE_NAME, routingKey2, null, msg.getBytes());
channel.basicPublish(EXCHANGE_NAME, routingKey3, null, msg.getBytes());

// 消费者1 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true, false, false,null);
// 消费者1 - 可以匹配"user.save"、"user.update"、"user.delete.abc"的消息
String routingKey = "user.#"; 
// 消费者1 - Queue绑定Exchange: 表示EXCHANGE匹配"user.*"的消息会路由到QUEUE中
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
// 消费者1 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者1 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();

// 消费者2 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "topic", true, false, false,null);
// 消费者2 - 可以匹配"user.save"、"user.update"的消息
String routingKey2 = "user.*"; 
// 消费者2 - Queue绑定Exchange: 表示EXCHANGE匹配"user.*"的消息会路由到QUEUE中
channel.queueBind(QUEUE_NAME_2, EXCHANGE_NAME, routingKey2);
// 消费者2 - 绑定消费队列
channel.basicConsume(QUEUE_NAME_2, true, queueingConsumer);
// 消费者2 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Fanout Exchange

![1633329283915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633329283915.png)

Fanout Exchange，广播交换机，只需要简单的将 Queue 绑定到 Exchange 上，不处理任何 RoutingKey，发送到 Exchange 的消息，都会被转发到与该 Exchange **绑定**的所有 Queue 上，其消息转发效率是**最高**的。

- 从效率来讲，由于 key 匹配速度不同，Fanout Exchange > Direct Exchange > Topic Exchange，所以 Exchange 的选用应该尽量简单，没必要把时间花在 key 的解析和匹配上。

```java
// 生产者 - Fanout类型的交换机不走路由键，所以设不设置Routing_key都不起作用
String routingKey = "";
// 生产者 - 发送消息msg到EXCHANGE_NAME
channel.basicPublish(EXCHANGE_NAME, routingKey, null, msg.getBytes());

// 消费者 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_NAME, "fanout", true, false, false,null);
// 消费者 - Fanout类型的交换机不走路由键，所以设不设置Routing_key都不起作用
String routingKey = "";
// 消费者 - Fanout交换机，只需要Queue绑定到Exchange上即可
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
// 消费者 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### Headers Exchange

Headers Exchange，首部模式，不处理任何 RoutingKey，而是根据发送消息内容中的 `headers` 属性进行匹配。

**其工作原理为**：

1. 在绑定 Queue 与 Exchange 时，指定一组 Key-Value 作为 Header，其值可以是任意类型，而不像 fanout，direct，topic 的 RoutingKey 那样只能是字符串形式。
2. 当消息发送到 RabbitMQ 时，会取到该消息的 `headers` 与 Exchange 绑定时指定的 Key-Value 进行匹配。
3. 如果匹配，则消息会路由到该 Queue，否则不会路由到该 Queue，其匹配规则 `x-match` 有下列两种类型：
   - **x-match = all** ：表示所有的 Key-Value 全部匹配，才能接收到消息。
   - **x-match = any** ：表示只要有 Key-Value 存在匹配，就能接收到消息。

```java
// 生产者 - x-match = all，根据用户设置去通知用户，设置email的用户只接收email的消息，设置sms的用户只接收sms的消息，设置两种类型都设置的则两种消息都能收到。
String message = "email inform to user" + i;
Map<String,Object> headers =  new Hashtable<String, Object>();
headers.put("inform_type", "email");// 匹配email消费者绑定的header
// 生产者 -  headers.put("inform_type", "sms");// 匹配sms消费者绑定的header
AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder();
properties.headers(headers);
// 生产者 - email通知
channel.basicPublish(EXCHANGE_NAME, "", properties.build(), message.getBytes());

// 消费者 - 声明交换机(一般手动创建，不在Java代码中创建)
channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS);
// 消费者 - headers.put("inform_type", "sms");// 匹配sms消费者绑定的header
Map<String, Object> headers_email = new Hashtable<String, Object>();
headers_email.put("inform_email", "email");
// 消费者 - Headers交换机，不匹配任何RountingKey，根据Headers进行匹配
channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "", headers_email);
// 消费者 - 绑定消费队列
channel.basicConsume(QUEUE_NAME, true, queueingConsumer);
// 消费者 - 开始消费队列
QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
```

###### x-consistent-hash Exchange (>= 3.6.0版本)

![1633699257907](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633699257907.png)

x-consistent-hash Exchange，一致性哈希交换机，根据 RoutingKey 计算出一个 hash 值，然后使用**一致性哈希算法**，根据这个 hash 值，把消息分发到绑定在该交换机下的队列中。因此，如果没有交换机和队列发生绑定更改，具有相同 RoutingKey 的消息，具有相同的 hash 值，将被路由到同一个队列中。

- **背景**：x-consistent-hash Exchange，是在从 RabbitMQ 3.6.0 版本开始，才整合到 RabbitMQ 发布包中的，对于之前的版本，需要手动下载插件去安装。
- **权重**：绑定键 BindingKey 使用一个**数字字符串**，表示所绑定的权重，数字越大，绑定队列的权重就越大，分发消息时能接收到的消息就越多。
  - 绑定键 BindingKey 决定队列的权重。
  - 路由键 RoutingKey 决定消息的分发。
- **局限**：
  - **数据不均匀**：在节点太少时，容易出现节点分布不均匀，从而导致数据倾斜。

##### 常见工作模式

###### Point to Point | 点对点模式

![1633702087552](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702087552.png)

- 实现方法：Direct Exchange 直连交换机 +  Exchange  = "" + RountingKey = Queue_name + 一个消费者消费一个 Queue。

###### Work Queues |  工作队列模式

![1633700659483](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633700659483.png)

- **实现方法**：Direct Exchange 直连交换机 + Exchange  = "" + RountingKey = Queue_name + 多个消费者消费同一个队列 Queue。

###### Publish/Subscribe | 发布订阅模式

![1633700920376](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633700920376.png)

- **实现方法**：Fanout Exchange 广播交换机 + Exchange != "" + RountingKey = "" + 绑定 Exchange & Queue + 多个消费者消费同一个/多个 Queue。

###### Routing | 路由模式

![1633701310453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633701310453.png)

- **实现方法**：Direct Exchange 直连交换机 + Exchange != "" + 多个 RountingKey + 多个 Queue 分别通过 BiningKey = RountingKey 绑定Exchange + 多个消费者分别消费不同的 Queue。

###### Topics | 主题模式

![1633701632932](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633701632932.png)

- **实现方法**：Topic Exchange 主题交换机 + Exchange != "" + 多个 RoutingKey + 多个 Queue 分别通过BiningKey（模糊匹配）绑定Exchange + 多个消费者分别消费不同的 Queue。

###### Headers | 首部模式

![1633702207503](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702207503.png)

- **实现方法**：Headers Exchange 首部交换机 + Exchange != "" + RountingKey = "" + 多个 Queue 分别通过 Headers 绑定Exchange + 多个消费者消费不同的 Queue。

###### RPC 模式

![1633702404965](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633702404965.png)

- **实现方法**：RPC 模式，指客户端远程调用服务端的方法 ，使用 MQ 可以实现 RPC 的异步调用，基于 Direct Exchange **直连交换机**实现，流程如下：
  1. 客户端既是生产者也是消费者，它会向 RPC 请求队列发送 RPC 调用消息，同时监听 RPC 响应队列。
  2. 服务端监听 RPC 请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果后，再将 RPC 结果发送到 RPC 响应队列。
  3. 由于客户端（RPC 调用方）监听 RPC 响应队列，所以此时会接收到 RPC 调用结果，完成一次 MQ 的 RPC 异步调用。

###### 工作模式总结

- Exchange 交换机，类似于反向代理用的 Nginx 服务器，不过 Nginx 负责请求的转发， 而 Exchagne 负责消息的转发。
- RabbitMQ 消息的传递，整体流程为『 生产者 -> 交换机 -> 队列 -> 消费者 』的这么一个模式，其中的点对点模式和工作队列模式，可以理解成是一个**匿名的交换机**进行投递队列，此时 RoutingKey = Queue_name。

| 工作模式     | 应用场景                                           |
| ------------ | -------------------------------------------------- |
| 点对点模式   | 把消息固定投放到一个队列，且只需一个消费者         |
| 工作队列模式 | 把消息固定投放到一个队列，但需要多个消费端加快消费 |
| 发布订阅模式 | 把消息投递同时投递到多个队列一起消费               |
| 路由模式     | 把消息固定投放到多个队列                           |
| 主题模式     | 按照一定规则，把消息投递到多个队列                 |
| 首部模式     | 不处理任何 RoutingKey，而是根据 `headers` 进行匹配 |
| RPC 模式     | 发起异步的 RPC 调用                                |

##### Queue 属性

Queue，消息队列，实际存储消息数据。 

| 属性        | 释义                                                         |
| ----------- | ------------------------------------------------------------ |
| Durability  | Queue 是否需要持久化，Durable：是， Transient：否            |
| Auto Delete | Queue 是否自动删除，yes 代表是，当最后一个监听器被移除之后，该 Queue 会自动被删除 |

##### Message 属性

Message，服务器和应用程序之间传送的数据，本质上是一段数据，由 Properties 和 Payload（相当于 Body）组成。

| 属性               | 释义                                                         |
| ------------------ | ------------------------------------------------------------ |
| Delivery mode      | 1 代表非持久化，2 代表持久，一些客户端库将此属性公开为布尔值或枚举。 |
| Type               | 用于特定应用程序的消息类型，例如“orders.created”             |
| Headers            | Map类型，带有 Name-Value 的自定义映射                        |
| Content type       | 内容类型，例如“application/json”，由应用程序使用，而不是 RabbitMQ |
| Content encoding   | 内容编码，例如“gzip”，由应用程序使用，而不是 RabbitMQ        |
| Message ID         | 消息 ID（唯一 ID）                                           |
| **Correlation ID** | 操作 ID（唯一 ID），用于将请求与响应相关联，消费者可用于进行幂等性校验 |
| Reply To           | 携带响应队列名称，用于 RPC 模式                              |
| **Expiration**     | 每条消息的 TTL 过期时间                                      |
| Timestamp          | 应用程序提供的时间戳                                         |
| User ID            | 用户ID，如果设置则需要验证                                   |
| App ID             | 应用名称                                                     |

##### SpringBoot POM 依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

##### SpringBoot 生产者 | 配置

```properties
# RabbitMQ通用配置
spring.rabbitmq.addresses=192.168.1.111:5672,192.168.1.112:5672,192.168.1.113:5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
spring.rabbitmq.connection-timeout=15000ms

# RabbitMQ生产者配置
# 启动消息Confirm机制, 不需要和mandatory一起使用
spring.rabbitmq.publisher-confirms=true
# 启动消息Return机制, 需要和mandatory一起使用
#spring.rabbitmq.publisher-returns=true
#spring.rabbitmq.template.mandatory=true
```

##### SpringBoot 生产者 | HelloWorld

```java
/**
 * RabbitMQ: Producer
 */
@Component
public class RabbitSender {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    /**
     * 消息Confirm机制
     */
    final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() {
        @Override
        public void confirm(CorrelationData correlationData, boolean ack, String cause) {
            System.out.println("消息ACK结果:" + ack + ", correlationData: " + correlationData.getId());
        }
    };

    /**
     * 对外发送消息
     * @param message
     * @param properties
     */
    public void send(Object message, Map<String, Object> properties){
        // 封装Message
        MessageHeaders messageHeaders = new MessageHeaders(properties);
        Message<Object> msg = MessageBuilder.createMessage(message, messageHeaders);

        // 指定业务唯一ID
        CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString());

        // 设置消息发送后置处理器
        MessagePostProcessor messagePostProcessor = new MessagePostProcessor() {
            @Override
            public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message) throws AmqpException {
                System.out.println("post to do: " + message);
                return message;
            }

            @Override
            public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message, Correlation correlation) {
                System.out.println("post to do " + message + " and correlation: " + correlation);
                return message;
            }
        };

        // 设置消息Confirm回调函数
        rabbitTemplate.setConfirmCallback(confirmCallback);

        // 发送消息，"springboot.rabbit"作为RoutingKey，匹配消费者的"springboot.*"
        // 	public void convertAndSend(String exchange, String routingKey, final Object message, final MessagePostProcessor messagePostProcessor, @Nullable CorrelationData correlationData) throws AmqpException
        rabbitTemplate.convertAndSend("exchange-1", "springboot.rabbit", msg, messagePostProcessor, correlationData);
    }
}
```

##### SpringBoot 消费者 | 配置

```properties
# RabbitMQ通用配置
spring.rabbitmq.addresses=192.168.1.111:5672,192.168.1.112:5672,192.168.1.113:5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
spring.rabbitmq.connection-timeout=15000ms

# RabbitMQ消费者配置
spring.rabbitmq.listener.simple.acknowledge-mode=manual
spring.rabbitmq.listener.simple.concurrency=1
spring.rabbitmq.listener.simple.max-concurrency=5
spring.rabbitmq.listener.simple.prefetch=1

```

##### SpringBoot 消费者 | HelloWorld

```java
/**
 * RabbitMQ: Receiver
 */
@Component
public class RabbitReceiver {

    @RabbitListener(bindings = @QueueBinding(
            value = @Queue(value = "queue-1", durable = "true"),
            exchange = @Exchange(name = "exchange-1", durable = "true", type = "topic", ignoreDeclarationExceptions = "true"),
            key = "springboot.*"
    ))
    @RabbitHandler
    public void onMessage(Message message, Channel channel) throws IOException {
        // 1. 收到业务以后进行业务端消费处理
        System.out.println("-----------------------");
        System.out.println("消费消息:" + message.getPayload());

        // 2. 处理成功后进行手工ACK
        Long deliveryTag = (Long) message.getHeaders().get(AmqpHeaders.DELIVERY_TAG);
        // void basicAck(long deliveryTag, boolean multiple) throws IOException;
        channel.basicAck(deliveryTag, false);
    }
}

```

#### 高级特性

##### 生产端 Confirm 机制

![1633418219083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633418219083.png)

消息确认，指生产者投递消息后，如果 Broker 收到消息，则会给生产者一个应答，生产者接收应答，可以用于确定该消息是否已经正常地发送到了 Broker，是可靠性投递的核心保障。

- **原理**：

  1. RabbitMQ 不会在收到消息时立马把消息写入磁盘，而是在数百毫秒的范围内，定期写入消息。
  2. 当队列被镜像时，只有在所有镜像都把将消息副本写入磁盘时，才会发送 ACK 给生产者。
  3. 这意味着 Confirm 机制会增加更多延迟，但如果数据需要高可靠性，那么这是必要的。

- **实现方法**：

  1. 在 Channel 上开启确认模式 `channel.confirmSelect()`。
  2. 在 Channel 上添加监听 `addConfirmListener`，去监听消息投递结果（成功和失败），根据具体的结果对消息进行重新发送，或者记录日志等其他后续处理。

  ```java
  // 生产者 - 开启Confirm消息机制
  channel.confirmSelect();
  // 生产者 - 绑定Confirm监听器 => 异步监听
  channel.addConfirmListener(new ConfirmListener() {
      @Override
      public void handleAck(long deliveryTag, boolean multiple) throws IOException {
          System.out.println("------- ok ---------" + deliveryTag);
      }
  
      @Override
      public void handleNack(long deliveryTag, boolean multiple) throws IOException {
          System.err.println("------- error ---------" + deliveryTag);
      }
  });
  // 生产者 - 发送消息msg到EXCHANGE_NAME
  String routingKey1 = "confirm.save";
  channel.basicPublish(EXCHANGE_NAME, routingKey1, null, msg.getBytes());
  
  ```

##### 生产端  Return 机制

![1633419001204](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633419001204.png)

Return Listener，可以用于处理一些**不可路由的消息**，比如 RoutingKey 规则不对不可路由时，如果不做任何监听，RabbitMQ 会默认直接丢弃掉，而此时可以使用 Return Listener 进行监听、处理这些不可达的消息。

- **实现方法**：设置 `Mandatory`，如果为 true，则监听器会接收到路由不可达的消息，然后进行后续处理；如果为 false，则Broker 会自动删除该消息。

  ```java
  // 生产者 - 开启Return消息机制
  channel.addReturnListener(new ReturnListener() {
      @Override
      public void handleReturn(int replyCode,
                               String replyText,
                               String exchange,
                               String routingKey,
                               AMQP.BasicProperties properties,
                               byte[] body) throws IOException {
          System.out.println("**************handleReturn**********");
          System.out.println("replyCode: " + replyCode);
          System.out.println("replyText: " + replyText);
          System.out.println("exchange: " + exchange);
          System.out.println("routingKey: " + routingKey);
          System.out.println("body: " + new String(body));
      }
  });
  // 生产者 - 投递时，routingKey1路由不到任何队列，触发Return机制
  channel.basicPublish(EXCHANGE_NAME, routingKey1, false, null, msg.getBytes());
  
  ```

##### 消费端 QoS 限流

- **背景**：假设有一个场景，RabbitMQ 服务器有上万条未处理的消息堆积，巨量的消息瞬间全部推送过来，单个客户端无法同时处理它们。

- **概念**：RabbitMQ 提供了一种 QoS（Quality of Service，服务质量保证）功能，即在非自动确认消息的前提下，如果一定数目的消息未被 `ACK` 前，则不消费新的消息。

- **参数**：

  - **prefetchSize**：报文大小，RabbitMQ 没有相应的实现。
  - **prefetchCount**：一次性从 Broker 中获取 N 个消息，但不能多于 N 个消息，即消费者一旦有 N 个消息仍未 ACK，则该消费者将不再消费任何消息，直到有消息 ACK 掉。
  - **global**：是否把 QoS 设置应用于 Channel 级别，RabbitMQ 没有相应的实现。
    - **true**：代表应用于 Channel 级别，即 Channel 下面所有的消费者都会使用该配置。
    - **false**：代表应用于 Consumer 级别，即只有当前 Consumer 才有效。

- **原理**：

  1. 首先，`basic.qos` 是通过 Channel 进行设置的，即只有在 Channel 建立之后，才能发送 `basic.qos` 信令。
  2. 在 RabbitMQ 实现中，每个 Channel 对应一个 rabbit_limiter 进程，当收到 `basic.qos` 信令后，会记录信令中 `prefetch_count` 的值，以及该 Channel 未 ACK 的消息个数。
  3. 当 RabbitMQ 要将 Queue 中的一条消息投递给 Consumer 时，会先遍历该 Queue 上的 Consumer 列表，然后选出一个合适的 Consumer，再把消息投递出去。
  4. 其中挑选 Consumer 的一个依据就是，看 Consumer 对应的 Channel 上未 ACK 的消息数是否已经达到了设置的 `prefetch_count` 。
  5. 如果未 ACK 的消息数已经达到了 `prefetch_count` ，则该消费者不符合要求，继续遍历挑选，此时该消费者将不再收到消息的投递，直到它发生了消息 ACK。
  6. 当挑选到合适的消费者后，RabbitMQ 会中断后续的遍历挑选操作，把消息投递到该消费者中去。

- **用途**： 用于控制消息发送给消费者的速度，让 Consumer 能够保持饱和的工作状态。

  1. 如果没有设置 QoS，那么 RabbitMQ 会把队列所有的消息，都按照**网络和客户端允许的速度**，推送给客户端，Consumer 把所有接收到的消息都缓存在自己的内存中，从而导致该 Consumer 内存占用飞速上涨。

  2. 可见，没有设置 Qos 会为 Consumer 提供无限的缓冲区，导致不良行为和不良性能的发生，因此，设置合理的 Qos 对性能的提升十分重要。

     - **目的**：为了让 Consumer 能够保持**饱和的工作状态**，减少 Consumer 缓冲区大小，使得更多消息留在 Queue 而不是 Consumer 内存中，方便在添加新 Consumer 时能够接收到消息推送。

     - **合理的 Qos**：当网络正常时，合理的 Qos 应该等于比值 `q =（消息往返两次所花的时间 + 消息被处理所花的时间） / 消息被处理所花的时间`，以保证在 Qos 最后一个消息被消费完毕时，最早消息的 ACK 已经回到 Broker，并且 Broker 也已经把新消息投递到 Consumer 内存中，使得 Consumer 工作永远饱和，而不至于阻塞等待消息的接收。

       | 异常情况           | 影响                                                         |
       | ------------------ | ------------------------------------------------------------ |
       | 网络正常，Qos 过大 | 会导致堆积在 Consumer 内存中的消息过多，消费出现大量额外的延迟 |
       | 网络正常，Qos 过小 | 会导致 Consumer 出现阻塞等待消息接收的情况，浪费 Consumer 工作时间 |
       | 网络变慢，Qos 正常 | 消息往返时间变长，q 增大，此时 Qos 偏小，会导致 Consumer 出现阻塞等待消息接收的情况，浪费 Consumer 工作时间 |
       | 消费变慢，Qos 正常 | 消息被处理所花时间变长，q 减小，此时 Qos 偏大，会导致堆积在 Consumer 内存中的消息过多，消费出现大量额外的延迟 |

- **实现方法**：

  ```java
  // void basicQos(int prefetchSize, int prefetchCount, boolean global) throws IOException;
  // 消费者 - 开启消费限流 报文大小、限流阈值、是否设置为Channel级别
  channel.basicQos(0, 1, false);
  
  // 消费者 - 消费消息，只有使用手工ACK才可以进行消费流控
  while (true){
      QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
      String msg = new String(delivery.getBody());
      // void basicAck(long deliveryTag, boolean multiple) throws IOException;
      channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
  }
  
  ```

##### 消费端 ACK/NACK 与消息重回队列

消费端进行消费时，如果消费端返回 `NACK`，可以进行日志记录 + 失败补偿，**千万不要把消息重回队列**；而由于服务器宕机等问题，需要消费端进行手工 `ACK`，保证消费成功，一般不会选择自动 `ACK`。

- **消息重回队列**：指把那些没有处理成功的（即返回 `NACK` 的）消息，重新投递给 Broker。

  - **缺点**：如果该消息一直消费失败，会导致无限制地被重新投递、重新消费...，非常浪费性能，甚至可能会搞挂 MQ，所以在使用中，一般都会关闭消息重回队列的功能。

- **实现方法**：

  ```java
  // 消费者 - NACK时开启消息重回队列，一般不采用, 弄不好会搞挂MQ
  // void basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException;
  channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true);
  ```

##### TTL 消息与 TTL 队列

TTL，Time to Live，指消息或者队列的生存时间，即过期时间。

- **TTL 消息**：

  - 指超过过期时间后，消息仍未被消费，则会被 RabbitMQ 删除。
  - RabbitMQ 支持 TTL 消息，通过在消息发送时进行指定。

- **TTL 队列**：

  - 指队列中**所有消息**都为 TTL 消息，且过期时间为指定的队列 TTL。
  - RabbitMQ 支持 TTL 队列，从**消息入队开始**计算，只要超过了队列的超时时间配置，那么消息会自动被删除。

- **实现方法**：

  ```java
  // 生产者 - 设置TTL队列参数
  HashMap<String, Object> queueArguments = new HashMap<>();
  queueArguments.put("x-message-ttl", 6000);// 6s过期时间
  // 生产者 - 声明交换机
  channel.exchangeDeclare(EXCHANGE_NAME, EXCHANGE_TYPE, true, false, false, null);
  // 生产者 - 声明队列（由于有TTL参数，所以为TTL队列）
  channel.queueDeclare(QUEUE_NAME, false, false, false, queueArguments);
  // 生产者 - Queue绑定Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
  String routingKey = ROUTING_KEY;
  channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
  
  // 生产者 - 或者可以通过设置BasicProperties，来设置TTL消息
  AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
      .deliveryMode(2)
      .contentEncoding("UTF-8")
      // TTL消息
      // .expiration("6000")
      .headers(headers)
      .build();
  ```

##### 死信交换机与死信队列

RabbitMQ 中有死信交换机的概念，Dead Letter Exchange，DLX，当一个队列中的消息变成**死信**（Dead Message）之后，它能被重新投递到另一个 Exchange 中，此时这个 Exchange 被称为**死信交换机**，而与死信交换机绑定的队列被称为**死信队列**（Dead Letter Queue，DLQ），

- **死信产生条件**：

  - 消息被拒绝 `basic.rejec` 或者 `basic.nack`，且不重回队列时 `requeue = false`。
  - 消息 TTL 过期时。
  - 队列达到最大长度时。

- **原理**：

  1. DLX 本质上也是一个正常的 Exchange，和一般的 Exchange 没有区别，可以在任何队列上被指定，实际上只是设置了某个队列的属性而已。
  2. 当某个队列中有死信时，RabbitMQ 会自动将死信消息重新投递到设置的 DLX 上，进而被路由到另一个队列（**死信队列**）中。
  3. 通过监听这个死信队列中的消息，进行相应的处理。
     - 死信只能从队头被转发到 DLX，也就是说即是 TTL 消息已过期，如果还没出现在队头，那么该消息还会继续存留在队列中，直到出现在队头才会被转发到 DLX 中。

- **实现方法**：

  ```java
  // 生产者 - QueueArguments声明绑定的死信交换机、对应的RoutingKey、以及TTL队列参数
  HashMap<String, Object> queueArguments = new HashMap<>();
  queueArguments.put("x-dead-letter-exchange", DLX_EXCHANGE_NAME);
  queueArguments.put("x-dead-letter-routing-key", "123");// 任意RoutingKey
  queueArguments.put("x-message-ttl", 6000);// 6s过期时间
  // 生产者 - 声明普通交换机
  channel.exchangeDeclare(EXCHANGE_NAME, EXCHANGE_TYPE, true, false, false, null);
  // 生产者 - 声明普通队列（由于有TTL参数，所以为TTL队列）
  channel.queueDeclare(QUEUE_NAME, false, false, false, queueArguments);
  // 生产者 - 普通Queue绑定普通Exchange: 表示交换机EXCHANGE_NAME上ROUTING_KEY的消息会路由到QUEUE_NAME中
  String routingKey = ROUTING_KEY;
  channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, routingKey);
  // 直连式，发送到默认的交换机，由于为TTL队列且没有任何消费者消费，所以消息过期后被重新投递到DLX中
  channel.basicPublish("", QUEUE_NAME, properties, msg.getBytes());
  
  // 消费者 - 声明死信队列交换机(一般手动创建，不在Java代码中创建)
  channel.exchangeDeclare(DLX_EXCHANGE_NAME, DLX_EXCHANGE_TYPE, true, false, false,null);
  // 消费者 - 声明死信队列(一般手动创建，不在Java代码中创建)
  channel.queueDeclare(DLX_QUEUE_NAME, false, false, false, null);
  // 消费者 - 死信队列绑定死信交换机: 表示交换机DLX_EXCHANGE_NAME上ROUTING_KEY的消息会路由到DLX_QUEUE_NAME中
  channel.queueBind(DLX_QUEUE_NAME, DLX_EXCHANGE_NAME, DLX_ROUTING_KEY);
  // 消费者 - 开始消费死信队列DLX_QUEUE_NAME的消息
  channel.basicConsume(DLX_QUEUE_NAME, false, queueingConsumer);
  QueueingConsumer.Delivery delivery = queueingConsumer.nextDelivery();
  channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
  
  ```

##### 延迟消息

延迟消息，就是消息投递到 Broker 后，Broker 会经过根据设定的延迟时间后，才把消息真正的投递到目标的业务 Exchange 中。

- **方案一，TTL 消息 + 单个等待队列 + 死信队列**：设置消息 TTL ，然后把等待队列中已过期的死信，投递到目标的业务 Exchange 中，此时该 Exchange 扮演者 DLX 的角色。

  - **缺点**：由于死信仅会从队头被移除，如果队列头部有一条 TTL 为 10 分钟的消息，后面又有一条 TTL 为 1 分钟的消息，那么第二条消息将等待 10 分钟，导致延迟时间容易失准。

  ```java
  // 方案一，TTL 消息 + 死信队列
  // public static final String X_DELAY = "x-delay";
  // 底层调用 => this.headers.put(X_DELAY, delay);
  org.springframework.amqp.core.messageProperties.setDelay(message.getDelayMills());
  
  ```

- **方案二，TTL 消息 + 多个等待队列 + 死信队列**：类似于方案一，不过不同的是，需要创建多个等待队列，并在队列本身上设置 TTL，比如 1、5 和 15 分钟等，然后根据 TTL 投递消息到不同的等待队列中。

  - **缺点**：设置延迟时间的灵活性有限，如果出现一个不在等待队列已有的 TTL，那么就需要新增一个等待队列，或者允许延迟时间失准，把消息投放到 TTL 相差较小的等待队列中。

- **方案三，NServiceBus**：

  - **原理**：
    1. 基于方案二的思路，使用级联 Topic，通过死信配置和 Topic 路由链接在一起。
    2. 创建多个延迟级别，其中每个级别负责自己的固定 2 的幂次的延迟时间（28 个级别的延迟时间），比如级别 1 为 1 分钟，级别 2 为 2 分钟，级别 3 为 4 分钟，级别 4 为 8 分钟等。
    3. 然后使用二进制样式的路由规则 与 RoutingKey ，在延迟队列之间移动消息（最多 27 次的路由交换），从而实现消息延迟投递。
  - **优点**：可以以 1 分钟的分辨率实现**任何**延迟时间。

  ![1633596886819](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633596886819.png)

#### 高可用架构

##### 主备模式

![1633428088126](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633428088126.png)

warren，兔子窝，Master - Slave 主备方案，与 ActiveMQ 利用 Zookeeper 实现 Master -Slave 方案类似。

- **原理**：如果 Master 挂了，可以利用 HaProxy 自动切换为 Slave，继续提供服务，从而实现热备份。

- **缺点**：服务器利用率低，只能从 Master 进行消费。

- **主备 HaProxy 配置**：

  ```shell
  # 集群名称
  listen rabbitmq_cluster
  # HaProxy IP+端口
  bind 0.0.0.0:5672
  # 配置TCP模式
  mode tcp
  # 简单的轮询，一开始默认为主节点，主节点挂了后轮询到下一个节点作为主节点
  balance roundrobin
  # 主节点
  server bhz76 192.168.11.76：5672 check inter 5000 rise 2 fall 2
  # 备用节点
  server bhz76 192.168.11.76：5672 backup check inter 5000 rise 2 fall 2
  
  ```

##### 远程模式

![1633441813577](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633441813577.png)

**远距离**通信和复制，可以实现**异地双活**的一种模式，简称  Shovel 模式，用于早期版本的多活存储和异地容灾。

- **原理**：通过把消息进行不同数据中心的复制，跨地域地让**两个 MQ 集群互联**。

- **缺点**：由于配置麻烦，无法动态配置，比如加一个 Exchange 必须重启服务，**实际用得并不多**，而且可用性也有待提高。

- **集群配置步骤**：

  ```shell
  # Step1：启动rabbitmq_shovel插件
  rabbitmq-plugins enable amqp_client
  rabbitmq-plugins enable rabbitmq_shovel
  # Step2：创建rabbitmq.config文件
  touch /etc/rabbitmq/rabbitmq.config
  # Step3：添加rabbitmq.config配置（省略，非常复杂，包括需要同步的每一个交换机、队列等信息）
  # Step4：保证源服务器与目的服务器都使用相同的rabbitmq.config配置
  
  ```

##### 镜像模式

![1633442866041](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633442866041.png)

镜像模式，Mirror，是非常经典的一种集群架构，可以保证 100% 数据不丢失，在实际工作中用的最多，并且实现起来**非常简单**，一般大厂都会使用这种架构模式来构建集群。

- **缺点**：只起到高可用的效果，**无限横向扩展没有意义**，因为当消息堆积过多时，无论如何横向扩展机器，每台机器堆积的消息量还是保持不变，机器增多只会增加 RabbitMQ 集群的通信负担，因此，RabbitMQ 集群一般选用 3 个节点保证高可用。

- **原理**：当 Broker 收到投递的消息后，镜像模式会把消息同步到集群中所有的节点，由于使用 Erlang 语言实现，天然地以交换机的方式进行数据同步，保持与原生 Socket 一样的延迟，性能非常好。

  1. Queue 分为 Master 和 Slave 节点，其中 Master 和 Slave 是针对一个 Queue 而言的，即一个 Queue **第一次创建**的 RabbitMQ 节点为 Master，其它 RabbitMQ 节点作为 Slave；而不是某个 RabbitMQ 节点作为所有 Queue 的 Master，其它 RabbitMQ 节点作为 Slave。
  2. 对某个 Queue来说，只有 Master 对外提供服务，而其他 Slave 只提供备份服务，以提供消息冗余，在Master 不可用时，RabbitMQ 会选出一个 Slave 作为新 Master 继续对外提供服务。
  3. 无论 Client 请求打到 Master 还是 Slave，最终数据都是**从 Master 获取**：
  4. 当 Client 请求打到 Master 时，Master 会直接将消息返回给 Client，同时 Master 会通过 GM 协议，将 Queue 的最新状态广播到其他 Slave。
     - GM 协议：Guaranteed Multicast，保证了**广播消息的原子性**，即要么都更新要么都不更新。
  5. 当 Client 请求打到 Slave 时，Slave 需要将 Client 请求先重定向到 Master，Master 再将消息返回给Client，同时 Master 会通过 GM 协议，将 Queue 的最新状态广播到 Slave节点。
  6. 因此，多个 Client 连接不同的镜像队列，不会产生同一 Message 被多次接受的情况。

  ![1633599572589](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633599572589.png)

- **新增节点**：

  - 如果有新节点加入，RabbitMQ 不会同步之前的历史数据，只会复制该节点加入到集群之后新增的消息。
  - 另外，对于 RabbitMQ 节点的重启，也是按照新节点来处理的。

- **Master 选举**：

  - RabbitMQ 集群内部会维护节点的状态**是否已经同步**，使用 rabbitmqctl 的 `synchronised_slave_pids` 参数，就可以查看状态。
  - 如果 `slave_pids` 和 `synchronised_slave_pids` 里面的节点是一致的，那说明全都同步了。
  - 如果不一致，则很容易比较出来哪些还没有同步，集群会在**最老**的 Slave 之间，选一个出来作为新的Master 。
  - 所以，RabbitMQ 选举过程，是不会选择新增节点作为新 Master 的。

- **故障恢复**：假设两个节点 A 和 B，组成一个镜像队列，其中 B 为 Master，A 为 Slave。

  1. **场景1**：A 先停，B 后停。
     - **恢复方案**：先启动 B，再启动A；或者先启动 A，在 30 秒内启动 B，即可恢复镜像队列。
  2. **场景2**：A、B 同时停。
     - **解决方案**：该场景可能是由掉电等原因造成，只需在 30 秒内，连续启动 A、B，即可恢复镜像队列。
  3. **场景3**：A 先停，B 后停，且 A 无法恢复。
     - **解决方案**：该场景是场景 1 的加强版，只需在 B 起来后，调用 `rabbitmqctl forget_cluster_node A`，解除与 A 的 Cluster 关系，再将新 Slave 加入 B，即可重新恢复镜像队列。
  4. **场景4**：A 先停，B 后停，且 B 无法恢复。
     - **解决方案**：
       1. 该场景是场景 3 的加强版，比较难处理，早在 3.1.x 时代之前没什么好的解决方法，由于 B 是 Master，所以直接启动 A 是不行的，而 A 无法启动，也就无法在 A 节点上调用 `rabbitmqctl forget_cluster_node B` 了。
       2. 而在 3.4.2 版本中，`forget_cluster_node` 支持 `–offline` 参数，允许 `rabbitmqctl` 在离线节点上执行 `forget_cluster_node` 命令，迫使 RabbitMQ 在未启动的 Slave 中选择一个作为Master。
       3. 此时，可以在 A 节点执行 `rabbitmqctl forget_cluster_node –offline B` 时，将 B 剔出Cluster，然后 A 就能正常启动了，最后将新 Slave 加入 A，即可重新恢复镜像队列。
  5. **场景5**：A 先停，B 后停，且 A和B 都无法恢复，但是能得到 A 或者 B 的磁盘文件。
     - **解决方案**：
       1. 该场景是场景4的加强版，更加难处理。
       2. 将 A 或 B 的数据库文件（默认在 `$RABBIT_HOME/var/lib`目录中），拷贝至新节点 C 的对应目录下，再把 C的 `hostname` 改成 A 或 B 的 `hostname` 。
       3. 如果拷过来的是 A 节点磁盘文件，则按场景 4 进行处理；如果拷过来的是 B 节点磁盘文件，则按场景 3 进行处理。
       4. 最后将新 Slave 节点加入 C，即可重新恢复镜像队列。
  6. **场景6**：A 先停，B 后停，且 A 和 B 都无法恢复，还无法得到 A 和 B 的磁盘文件。
     - **解决方案**：无法恢复 A 和 B 中的内容。

##### 多活模式

![1633445011959](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633445011959.png)

多活模式，Federation，也是实现**异地数据复制**的主流模式，由于 Shovel 模式配置比较复杂，所以一般来说，实现**异地集群**都是使用双活或者多活模型来实现的。

- **特点**：RabbitMQ 部署架构采用双中心或者多中心模式，各数据中心都部署一套 RabbitMQ 集群，除了需要为业务提供正常的消息服务外，中心与中心之间还需要实现部分关键队列的消息共享。

- **原理**：需要依赖 RabbitMQ#federation 插件。

  - **Federation 插件**：基于镜像队列集群，不需要重新构建集群，使用 **AMQP 协议**通讯，可以在集群之间高效传输消息，同时接受不连续的消息传输，接的双方可以使用不同的 users、virtual hosts、RabbitMQ、甚至 Erlang 环境。

  - **Federation Exchanges**：

    1. 可以看成下游主从上游拉取消息，但并不是拉取所有消息，而是只拉取下游绑定了上游 Queue 的 Exchange 的 消息。
    2. 更新时，通过使用 AMQP 协议实施代理间通信，下游在后台绑定或者解绑，然后把绑定和解除绑定命令，发送到上游交换机，进行动态更新配置。
    3. 因此，Federation Exchange 只接收被订阅了的消息，即只拉取自己有绑定关系的消息。

    ![1633445945055](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633445945055.png)

#### 常见问题解决

##### 如何保证数据不丢失？

在使用 MQ 过程中，应做到消息不能多消费，也不能少消费，如果无法做到可靠性传输，可能会给公司带来千万级别的财产损失。

- **数据丢失场景**：生产端丢数据、MQ 丢数据、消费端丢数据。

###### 生产端丢数据

需要生产端保证可靠性投递，即要保证生产者投递的消息 100% 投递成功，不存在投递失败，比如核心业务，订单下单支付成功后，通知物流时需要 100% 通知成功，一单都不能丢。

- **解决方案**：RabbitMQ 提供 transaction 或者 confirm 机制，来确保生产者不丢消息。

  - **transaction 机制**：

    - **执行流程**：
      1. 发送消息前，开启事务 `channel.txSelect()`。
      2. 然后发送消息。
      3. 如果发送过程中出现什么异常，事务就会回滚 `channel.txRollback()`。
      4. 如果发送成功则提交事务 `channel.txCommit()`。
    - **缺点**：吞吐量会下降很多。

  - **confirm 机制**： 消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿 。

    ![1633339851782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633339851782.png)

    - **实现关键点**：
      1. 保障消息能够成功发出。
      2. 保障 MQ Broker 节点能够成功接收。
      3. 发送端收到 MQ Broker 节点能够确认应答。
      4. 有完善的消息补偿机制。
    - **执行流程**：
      1. **STEP 1**：业务落库 BIZ_DB。
      2. **STEP 2**：消息落库 MSG_DB，需要保证 MSG_DB 与 BIZ_DB 属于同源数据库，即一个 Connection 可以同时操作该地址下面的多个数据库，这样可以使业务和消息落库处于同一个事务内，**保证原子性**。
         - 如果不想单独建立消息库或者消息表，可以在业务表上新增一个字段，用于记录消息的状态。
      3. **STEP 3**：发送消息到 MQ 上。
      4. **STEP 4**：MQ Broker 接收消息成功后返回 ACK 应答。
      5. **STEP 5**：接收到 Broker 的 ACK 应答后，更新 MSG_DB 中对应的消息状态。
      6. **STEP 6**：
         1. 为了防止 MSG_DB 对应的消息状态一直未改变，且已发生超时，或者一次消息投递失败，需要启动一个定时任务，去 MSG_DB 扫出投递超时的、失败可再投递的消息，进行 STEP 7 重新投递。
         2. 同时，如果重新投递的次数超过了最大限制，则说明消息投递最终失败，需要进行**人工介入** 或者 **失败补偿**。
      7. **STEP 7**：定时任务重新投递消息。
      8. **STEP 8**：定时任务定期执行，扫出投递超时的、失败可再投递的消息。

###### MQ 丢数据

处理 MQ 丢数据，需要（**开启持久化**配置 + RabbitMQ confirm 机制）配合使用，在消息持久化后，才给生产者发送一个 ACK 信号，如果消息持久化之前，RabbitMQ 就阵亡了，此时生产者收不到 ACK 信号，生产者就会自动重发，从容防止 MQ 丢数据。

- **开启持久化**：
  1. 将 Queue 的持久化标识 `durable` 设置为 true，代表是一个持久的 Queue。
  2. 在生产者发送消息时，将 `deliveryMode` 设置为2，代表该消息需要被持久化。
  3. 这样设置以后，RabbitMQ就算挂了，重启后也能恢复数据。
- **为什么不对所有消息都开启持久化**？
  1. 是否要对消息进行持久化，需要综合考虑性能的差距，因为写磁盘要比写 RAM 慢得多，开启持久化必然会导致 RabbitMQ 性能的下降，之间的消息吞吐量可能会有 3 倍以上的差距。
  2. 如果想达到单 RabbitMQ 10w/s 以上的消息吞吐量，一种处理方法是，使用非常快速的存储系统，来支持写磁盘持久化消息（比如使用 SSD）。
  3. 另外一种处理方法是，根据业务重要程度，仅对**关键消息**作持久化处理，这时仅仅保证关键消息的持久化不会导致性能瓶颈即可。

###### 消费端丢数据

消费端丢数据，一般是因为采用了**消费者自动 ACK** 的模式，在这种模式下，消费者收到消息后会自动确认，然后 RabbitMQ 则立即将消息删除，如果此时消费者出现异常，确认后没能处理该消息，则会丢失该消息。

- **解决方案**：采用**消费者手工 ACK** 即可。

##### 如何防止重复消费？

这个问题换一种问法就是，如何保证消息队列的**幂等性消费**，即消费者多次消费的结果只会被消费一次。

- **原因**：
  1. 正常情况下，消费者在消费完毕后，会发送一个**确认信息**给消息队列，消息队列就知道该消息被消费了，然后会将该消息从消息队列中删除。
  2. 无论是哪种消息队列，造成重复消费原因其实都是类似的，只是不同的消息队列发送的**确认消息**的形式不同，比如 RabbitMQ 是发送一个 `ACK` 确认消息，RocketMQ是返回一个 `CONSUME_SUCCESS` 成功标志，kafka实际上有个 `offset` 的概念。
  3. 如果出现网络传输等故障，确认信息没有传送到消息队列，导致消息队列不知道该消息已经被消费过了，下次会把该消息，再次分发给其他的消费者进行消费，从而导致重复消费。
- **解决方案**：
  1. **数据库主键去重**：消费这个消息做数据库的 `insert` 操作时，可以给这个消息做一个**主键**，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
     - **局限**：并发时会导致大量的插入失败，浪费性能。
  2. **更新操作天然幂等**：消费这个消息做 Redis 的 `set` 操作时，无需做任何处理，因为无论 `set` 几次结果都是一样的。
     - **优点**：`set ` 操作天然幂等，无需做任何处理。
  3. **全局唯一 ID**：如果以上两种情况都不适合，那么可以准备一个第三方介质，用来做消费记录，以 Redis 为例，给消息分配一个**全局唯一 ID**，只要消费过该消息，可以吧 `ID-Message` 以 K-V 形式写入 Redis，当消费者开始消费前，需要先去 Redis 中查询有没消费记录，如果没有则消费，否则放弃消费。
     - **局限**：仅仅使用这种方案还是有可能重复消费的，因为当线程并发查询消费记录时，可能会导致并发通过消费记录的校验，从而重复创建订单。
  4. **全局唯一ID + 数据库主键去重**：由于高并发解决方案是不能加锁的，而仅仅使用全局唯一 ID，或者数据库主键去重，都是有幂等性缺陷的，因此，最终的解决方案是使用 **全局唯一ID + 数据库主键去重** ，利用消费记录校验来挡住大部分请求，利用数据库主键兜底剩余通过校验的并发请求，从而保证幂等性消费。
     - **优点**：简单有效。

##### 一致性与可用性保障？

###### 集群可调整参数

事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的**最终一致性**以及时刻都接受读取和写入的**高可用性**，因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个**范围的两端**。对此，RabbitMQ 提供了调整参数，以获得更高一致性或者更高可用性。

1. **持久化 Queue / Exchange**：见 Queue / Exchange 的 `Durability` 属性。

   - 开启持久化的 Queue / Exchange 都会被持久化到 Mnesia 数据库，其可以在系统崩溃或服务器故障后，重新启动时，这些 Queue / Exchange 基础设施会重新上线。
   - 而关闭持久队的 Queue / Exchange，在重新启动时，则会被删除。

2. **持久化消息**：Queue / Exchange 的持久化，并不意味着其消息的持久化，只有被生产者设置为 `Delivery mode=2` 的消息，重新启动后才会恢复。

   - **缺点**：持久消息会给代理带来更多负载，所以并不需要对所有消息都做持久化处理，而是根据业务重要程度，仅对**关键消息**作持久化处理，这时仅仅保证关键消息的持久化不会导致性能瓶颈即可。

3. **消息 Confirm 机制**：见《高级特性 - 生产端 Confirm 机制》与《高级特性 - 消费端 ACK/NACK 与消息重回队列 》。

4. **镜像同步策略**：`ha-sync-mode`：

   - **automatic**：自动同步，节点重新上线后，集群会为新节点上的每个队列创建一个镜像，并自动将新 镜像与 Master 进行同步，包括 Master 原始的消息。
     - **为什么不默认使用自动同步**？同步是一个阻塞操作，同步期间 Master 无法执行任何读取或者写入操作，如果 Queue 为一个大队列，原始消息的同步将会耗费大量的时间，保证了一致性，但牺牲了可用性。
   - **manual**：手动同步，默认，节点重新上线后，集群会为新节点上的每个队列创建一个镜像，但该镜像只是保持为空的镜像，不会复制 Master 原始的消息，而仅仅是同步 Master 新写入的消息。

5. **Master 选举策略**：`ha-promote-on-failure` ：

   - **always**：默认值，允许故障转移到**数据未完全同步**的镜像中。
     - **特点**：可能会导致 Master 的消息丢失，但可以保持 Queue 的高可用性。
   - **when-synced**：仅在**数据已完全同步**的镜像中进行故障转移，否则让 Queue 不可用；只当 Master 再次上线时，Queue 才恢复可用，数据未完全同步的镜像继续同步 Master 数据。
     - **特点**：牺牲了可用性，某个方面增加了数据安全；但如果重新上线的 Master 丢失了所有数据，则会导致 Queue 的所有数据**全部丢失**，即使有大部分追上同步进度的镜像也会被丢弃，去同步数据为空的 Master，所以该策略是非常危险的。

6. **脑裂处理策略**：一个集群由于网络链接切断，被一分为二的地方，在分区的每一侧，都有镜像都被提升为 Master，这意味着最终每个队列有不止一个的 Master，RabbitMQ 提供 `cluster_partition_handling` 作为脑裂的处理策略：

   - `Ignore`：忽略模式，默认，此模式选择了**可用性**，当分区发生时，发生了裂脑，而在分区解决后，由管理员来决定分区的哪一边获胜，让失败侧重新启动，并且仅存在于该分区的任何数据都将会丢失。
   - `Autoheal`：自动修复模式，与忽略模式相同，不过是交由集群**自动决定**分区的失败侧，失败的一方会重新加入集群，从而丢失所有未被消耗的消息。
   - `Pause Minority`：暂停少数派模式，**拒绝**对分区的少数方进行读写，这是禁止出现裂脑的**唯一选择**。
     1. Broker 会自动暂停位于分区的少数方，意味着它会关闭所有现有连接，并拒绝任何新连接。
     2. 同时，Broker 会每秒检查一次网络状态，以判断分区是否已自行解决。
     3. 一旦分区已自行解决，Broker 将会自行取消暂停，并让那些少数方重新加入集群。

   ![1633606547241](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633606547241.png)

7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

###### 集群缺陷

- **一致性**：重新加入集群的节点，会被迫丢弃它们自己的数据。
- **可用性**：镜像同步 Master 阻塞时，会导致队列暂时不可用。

###### 追求高可用性

1. **持久化 Queue / Exchange**：开启。
2. **持久化消息**：只持久化关键消息。
3. **生产端 Confirm**：允许投递迅速消息，无需进行消息 Confirm。
4. **镜像同步策略**：`ha-sync-mode=manual`，手动同步镜像。
5. **Master 选举策略**：`ha-promote-on-failure=always`，允许选举数据未完全同步的镜像作为 Master。
6. **脑裂处理策略**： `cluster_partition_handling=Ignore`，忽略模式或者 `cluster_partition_handling=Autoheal`，自动修复模式。
7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

###### 追求高一致性

1. **持久化 Queue / Exchange**：开启。
2. **持久化消息**：只持久化关键/所有消息。
3. **生产端 Confirm**：生产端可靠性投递（消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿） + 消费端幂等性消费 + 消费端手工 ACK。
4. **镜像同步策略**：`ha-sync-mode=automatic`，自动同步镜像，包括 Master 的原始消息。
   - 但对于大队列，由于镜像同步慢，还需要考虑**可用性导致的消息丢失**：生产端可靠性投递（消息状态打标 + 消息落库 + Broker ACK 回传 + 定时重发 + 人工介入/失败补偿） + 死信队列（超过最大投递次数） + 人工介入。
5. **Master 选举策略**：`ha-promote-on-failure=when-synced`，仅在数据已完全同步的镜像中进行故障转移，否则让 Queue 不可用；只当 Master 再次上线时，Queue 才恢复可用，数据未完全同步的镜像继续同步 Master 数据。
6. **脑裂处理策略**： `cluster_partition_handling=Pause Minority`，暂停少数派模式，**拒绝**对分区的少数方进行读写，只有当分区修复完成后，才会重新加入集群，开放读写。
7. **客户端轮训策略**：轮训集群中的所有节点，并执行连接，重试直到成功。

##### 如何重新平衡队列？

故障恢复后，现有的 Master 可能都落在同一个节点上，这是不理想的情况，需要 Master 重新平衡，以让其在节点之间均匀分布，而不幸的是，RabbitMQ Master 重新平衡没有很好的选择，而应该关注**如何重新平衡队列**： 

- 在 3.8.1 版本以前，可以使用 HA 策略来移动 Master，其工作原理是：

  1. 通过优先级高于现有 HA 策略的临时策略，来删除所有镜像。
  2. 将临时 HA 策略更改为使用 `nodes` 模式，指定要将 Master 迁移到的节点，然后强制**迁移同步队列**。
  3. 迁移完成后，删除临时策略，优先使用原始 HA 策略并创建所需数量的镜像。

  => **缺点**：如果有大队列，或者严格的冗余要求不能删除镜像时，则可能该方案不可行。

- 从 3.8.1 版本开始，可以使用 `rabbitmq-queues rebalance all` 命令，重新平衡镜像队列。

  ```shell
  rabbitmq-queues rebalance "all" --vhost-pattern "a-vhost" --queue-pattern ".*"
  
  ```

##### 如何保证顺序消费？

![1633703487247](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633703487247.png)

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个队列**，目的是防止消费者争抢消息导致乱序消费的情况发生。

- **解决方案**：

  - **多队列、多消费者**：可以使用一致性哈希交换机 `x-consistent-hash Exchange`，来保证同一个 RoutingKey 多次投递，只会顺序进入同一个队列，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。

    ![1633703914760](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633703914760.png)

  - **单队列、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单队列、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单队列、单消费者**：始终保证使用 一个 Queue + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

##### 如何优化消息积压？

###### 影响后果

消息积压在 Queue 中，可能会导致消息被丢弃、MQ 内存打满、MQ性能下降甚至停止服务，影响系统运行。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **提高 `prefetch_count`**：首先要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从等待消息阻塞的角度**入手。

   ![1633794700060](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794700060.png)

   1. 消息消费速度，主要受到 `发送消息时间`、`消息被处理时间`、`消息 ACK 时间` 的影响。
   2. 如果一个消息走完这个流程后，才发送另一个消息的话，整体效率将会非常的低。
   3. 此时，可以让消息在这几个时间内恰当的分配，让消息总是连续不断地被 Consumer 接收处理，确保 Consumer 能够保持饱和的工作状态，从而发挥出其本身真正的后端处理能力，整体上提升 Consumer 的消费速度。
   4. 只有设置 `prefetch_count` 到一个合理的值，才可以最大限度地提升消息的消费速度，这个值的设定可以参考《消费端 Qos 限流》。
   5. **小结**：需要消费端 ACK、需要设置的合理的 `prefetch_count`。

2. **Consumer 批量 ACK**：其次还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   ![1633795791575](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633795791575.png)

   1. 在每条消息分别被 ACK 的情况下，Consumer 需要多次发起 ACK 传输给 Broker，多次的 I/O 浪费了服务器性能与增加了带宽的占用。
   2. 通过批量 ACK 的方式，减少多次发起 ACK，以及结合 `prefetch_count` 批量一次性从 Broker 拉取消息，可以减少很多 I/O 浪费和带宽占用。
   3. 不过，如果 Consumer 在处理某条消息时失败了，而业务上又要求不能丢失任何消息，此时就不能对所有的消息进行批量 ACK，否则 RabbitMQ 就不会再次投递该消息了。
      - **解决方案**：可以跟踪所有消息的处理结果，如果全部成功，则使用批量 ACK；如果部分成功，则有两个选择：1）如果不需要顺序消费，则可以退化为每个消息分多次发送 ACK/NACK；2）如果需要顺序消费，则本次接收到的所有  `prefetch_count` 消息全部 NACK，否则这批消息重新投递时顺序就不一致了，但是需要做好幂等性消费。
   4. **小结**：Consumer 批量 ACK 的前提是，设置了 `prefetch_count` 批量一次性从 Broker 拉取消息，否则批量 ACK 将会失去意义。

   ```java
   // void basicAck(long deliveryTag, boolean multiple) throws IOException;
   // multiple：true表示采用批量ACK，凡是deliveryTag比e.DeliveryTag的消息都会被ACK。
   channel.BasicAck(e.DeliveryTag, true);
   
   ```

3. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手。

   ![1633794760275](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794760275.png)

   1. 多线程并发消费，不需要建立多个 RabbitMQ 连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，同样存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

4. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   ![1633794730033](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633794730033.png)

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个 Queue，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 启用 `prefetch_count`。
  2. 先单个 Consumer 消费，`prefetch_count` 设置为 1，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度不满足要求，则提高 `prefetch_count`，**1 次接收多条消息**，甚至批量 ACK，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  4. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，甚至批量 ACK，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则**多个消费者并发消费**，甚至批量 ACK，但要注意并发冲突和顺序消费的问题。
  6. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步，以及批量 ACK 遇到消费失败时进行全部 NACK。

###### 【线上】如何紧急处理消息积压？

如果日常系统正常运转，没有积压或者只有少量积压很快就能消费掉，但是某一个时刻，突然就开始积压消息，并且积压持续上涨，这种情况下需要在短时间内排查消息积压的原因，迅速解决问题才不至于影响业务。

- **排查思路**：能导致积压突然增加，最粗粒度的原因，只有两种，要么是**发送变快了**，要么就是**消费变慢了**。
- **发送变快了**：通过监控数据发现到是，单位时间内发送的消息增多了，即发送变快了，比如说是赶上大促或者抢购。
  - **解决方案**：保证消费速度 大于 提高后的发送速度。
    1. 这种情况，短时间内不太可能优化 Consumer 代码来提升消费性能，唯一的方法是通过扩容 Consumer 实例数来提升总体的消费能力。
    2. 如果没有足够服务器资源进行 Consumer  扩容，没办法的办法，可以考虑将系统降级，通过关闭一些不重要的业务，减少 Producer 发送的数据量，最低限度地让系统还能正常运转，服务一些重要业务。
    3. 当 MQ 快慢了时，如果也降级不了，可以临时写一个专门丢弃的 Consumer，接入不重要的业务进行消费，消费一个记录一个，然后丢弃掉，快速消费掉积压的消息，最后再在空闲时，根据记录到的消息重新补回数据。
- **消费变慢了**：通过监控数据发现到是消费编变慢了。
  - **解决方案**：保证消费速度回到以前的消费速度。
    1. 需要检查 Consumer 实例，分析一下是什么原因导致消费变慢，优先检查一下日志是否有大量的消费错误。
    2. 如果日志没有错误的话，可以通过 Dump 出堆栈信息，看一下消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。
- **其他原因**：还有一种不太常见的情况，就是通过监控发现，无论是发送速度，还是消费速度，都和原来的没什么变化。
  - **解决方案**：需要检查一下 Consumer，是不是存在一条消息消费失败然后导致反复重新投递 + 消费这种情况，因为这种情况也是会拖慢整个系统的消费速度的。

### 1.6. 什么是磁盘衡量指标？

![1634119681801](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634119681801.png)

1. **影响磁盘性能的关键因素**：磁盘服务时间，即磁盘完成一个 I/O 请求所花费的时间，由寻道时间、旋转延迟和数据传输时间三部分构成。
   - **寻道时间**：Tseek，指将读写磁头移动至正确的磁道上所需要的时间，寻道时间越短，I/O 操作越快，目前磁盘的平均寻道时间一般在3-15ms。
   - **旋转延迟**：Trotation，指盘片旋转将请求数据所在的扇区，移动到读写磁盘下方所需要的时间，旋转延迟取决于磁盘转速，通常用磁盘旋转一周所需时间的1/2表示。
     - 比如，7200rpm 的磁盘平均旋转延迟大约为 60*1000/7200/2 = 4.17ms，而转速为15000rpm 的磁盘其平均旋转延迟为 2ms。
   - **数据传输时间**：Ttransfer，指完成传输所请求的数据所需要的时间，取决于数据传输率，其值等于数据大小除以数据传输率。
     - 目前 IDE/ATA 能达到 133MB/s，SATA II 可达到 300MB/s 的接口数据传输率，数据传输时间通常远小于前两部分消耗时间，简单计算时**可忽略**。
2. **衡量磁盘的指标**：IOPS 和吞吐量。
   - **IOPS**：Input/Output Per Second，每秒输入输出量，也叫每秒读写次数，即指每秒内系统能处理的 I/O 请求数量，对于**随机读写频繁**的应用，比如小文件存储等，需要关注随机读写性能，此时 IOPS 则是关键衡量指标。
     - **公式**：IOPS = 1000ms / （Tseek + Trotation + Transfer）。
     - 如果忽略数据传输时间，理论上可以计算出随机读写最大的IOPS，常见磁盘的随机读写最大IOPS为：
       - 7200rpm 的磁盘 IOPS = 76 IOPS。
       - 10000rpm 的磁盘 IOPS = 111 IOPS。
       - 15000rpm 的磁盘 IOPS = 166 IOPS。
   - **Throughput**：吞吐量，指单位时间内成功传输的数据数量，对于**顺序读写频繁**的应用，如视频点播，关注连续读写性能、数据吞吐量是关键衡量指标，主要取决于磁盘阵列架构、数据通道大小以及磁盘的个数。
     - **磁盘阵列架构**：不同的磁盘阵列存在不同的架构，它们都有自己的内部带宽，一般情况下，内部带宽都设计足够充足，不会存在瓶颈。
     - **数据通道大小**：磁盘阵列与服务器之间的数据通道，对吞吐量影响很大，比如一个 2Gbps 的光纤通道，其所能支撑的最大流量仅为 250MB/s。
     - **磁盘个数**：磁盘越多，吞吐量也越大。

### 1.7. 什么是 Linux 磁盘读请求模型？

![1634136736890](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634136736890.png)

- **背景**：虽然 15000rpm 的磁盘计算出的理论最大 IOPS 仅为 166，但在实际运行环境中，磁盘的 IOPS 往往能够突破 200，甚至更高，这其实就是在系统调用过程中，**操作系统**进行了一系列的优化。
- **概念**：虚拟文件系统层 -> 具体的文件系统层 -> Cache 层 -> 通用块层 -> I/O 调度层 -> 块设备驱动层 -> 物理块设备层。

#### 虚拟文件系统层

VFS Layer，允许 Linux 中共存众多不同的文件系统，并且对文件的操作可以跨文件系统执行。

- **VFS**：Virtual File System，虚拟文件系统，是一种软件机制，扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中，其作用是，屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。

#### 具体的文件系统层

VFS的下一层即是具体的文件系统，一个文件系统一般使用块设备上一个独立的逻辑分区。

- 对于 Linux Ext2 文件系统来说，硬盘分区首先被划分为一个个的 Block，系统上的每个 Block 都是一样大小的，但是，不同 Ext2 文件系统，Block 大小可能不同，这是在创建 Ext2 系统决定的，一般为1k 或者 4k 。

#### Cache 层

- **目的**：为了提高 Linux 操作系统对磁盘访问的性能。

  - **提高读性能**：在内存中缓存了磁盘中的部分数据，当数据的请求到达时，如果在 Cache 中存在该数据且是最新的，则直接将数据传递给用户程序，避免了对底层磁盘的操作，提高了读性能，是磁盘 IOPS 能突破 200 的重要原因之一。
  - **提高写性能**：通过暂时将数据存在 Cache 里，然后统一**异步**写到磁盘中，通过这种异步的数据 I/O 模式，解决了程序中计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使写性能大大提高。

- **两大功能**：预读和回写。

  - **预读**：根据应用程序是否需要等待预读完成，可分为**同步预读和异步预读**，如果所请求的页面处于预读的页面之中，则进行异步预读；如果所请求的页面处于预读页面之外，则进行同步预读。

    1. **同步预读**：如果所读页面不在 Cache 中，此时操作系统读入所请求的页面，同时，利用局部性原理，继续读入紧随其后的少数几个页面（通常是三个页面），其中第一个读请求必定是同步预读。
    2. **异步预读**：如果所读页面在 Cache 中，则表明前次预读命中，此时操作系统会把预读页的大小扩大一倍，但该预读过程是异步的，应用程序无需等待预读完成即可返回，只需后台慢慢读页面即可。

  - **回写**：

    - Linux 2.6.32 内核之前，采用 `pdflush` 机制将脏页真正地写到磁盘中，其刷脏时机为：

      1. **脏页太多**：在空闲内存大小少于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。
      2. **脏页太久**：当脏页驻留内存时间超过一定的阈值时，内核必须将超时的脏页写回磁盘，以确保脏页不会无限期地驻留在内存中。
      3. 主动调用 `fsync`。

      而回写开始后，`pdflush` 会持续写数据，直到满足以下两个条件：

      1. 已经有指定的最小数目的页被写回到磁盘。
      2. 空闲内存页已经回升，超过了阈值。空闲内存页已经回升，超过了阈值。

    - Linux 2.6.32 内核之后，放弃了原有的 `pdflush` 机制，改成了 `bdi_writeback` 机制，解决了在多磁盘的系统中，由于 `pdflush` 管理了所有磁盘的 Cache 导致了一定程度的 I/O 瓶颈。

      - `bdi_writeback` 机制为每个磁盘都创建了一个线程，专门负责这个磁盘的 Page Cache 的刷脏工作，从而实现了每个磁盘的数据刷新在线程级别上分离，从而提高了 I/O 性能。

    - 回写机制存在的问题：回写不及时，会引发数据丢失，且回写期间读I/O 性能很差。

- **Linux 实现**：一是 Page Cache，另一个 Buffer Cache，每一个Page Cache 包含若干 Buffer Cache。

  - **Page Cache**：主要作为文件系统上的**文件数据缓存**来使用，尤其是针对当进程对文件有 `read/write` 操作的。
  - **Buffer Cache**：主要用来在系统对块设备进行读写时，作为**块进行数据缓存**来使用。

#### 通用块层

通用块层的主要工作是，接收上层发出的磁盘请求，并最终发出I/O请求，该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。

#### I/O 调度层

I/O 调度层的功能是，管理块设备的请求队列，即接收通用块层发出的 I/O 请求，缓存请求并试图合并相邻的请求，并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I/O请求。

- **目的**：
  1. 如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。
  2. 为了优化寻址操作，内核不会一旦接收到 I/O 请求后，就按照请求的次序发起块 I/O 请求，Linux 提供了几种 I/O 调度算法进行优化，其思想是通过合并和排序 I/O 请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。
- **常见的 I/O 调度算法**：
  - **Noop 算法**：No Operation，最简单的 I/O 调度算法，该算法仅适当合并用户请求，是为不需要寻道的块设备而设计的（如 SSD，SSD 没有所谓的寻道时间且 I/O 响应时间非常短），并不排序请求。
    1. 新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。
  - **CFQ 算法**：完全公正排队 I/O 调度算法，其主要目标是在触发 I/O 请求的所有进程中，确保磁盘 I/O 带宽的公平分配。
    1. 使用许多个排序队列，存放了不同进程发出的请求。
    2. 通过散列将同一个进程发出的请求插入同一个队列中。
    3. 采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。
  - **Deadline 算法**：截止时间调度算法，避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。
    1. 引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。
    2. 本质是一个超时定时器，当请求被传给电梯算法时开始计时，一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。
  - **AS 算法**：AS预测调度算法，本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。
    1. 算法统计每个进程I/O操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。
    2. 如果是，立即调度下一个请求。
    3. 否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。

#### 块设备驱动层

驱动层中的驱动程序，对应具体的物理块设备，从上层中取出 I/O 请求，并根据该请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。

#### 物理块设备层

具体的磁盘设备。

### 1.8. 什么是零拷贝技术？

#### 标准 I/O

传统 Linux 系统中，标准的 I/O 接口（比如 `File#read`、`File#write`）都是基于**数据拷贝**操作的，即是 I/O 操作会导致数据在内核地址空间的缓冲区，和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作**缓存 I/O**。

- **过程**：传统 I/O 中，读取一个文件并通过 socket 发送给用户的过程，数据经历了 2 次 DMA 数据拷贝，2 次用户空间与内核空间的 CPU 拷贝操作，以及 4 次上下文切换：

  ![1634173642699](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634173642699.png)

  - **2 次 DMA 数据拷贝**：
    1. 通过 DMA 把文件数据拷贝到内核缓存。
       - **DMA**：Direct Memory Access，直接存储器访问，是一种无需 CPU 参与，让外设和系统内存之间进行双向数据传输的硬件机制，使用DMA可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐量。
    2. 通过 DMA 把内核缓存拷贝并发送到网络。
  - **2 次用户空间与内核空间的 CPU 拷贝操作**：
    1. 从内核空间的内核缓存，读取文件数据，然后拷贝到用户空间的用户缓存。
    2. 用户程序调用 `Socket#write` ，从用户空间的用户缓存，读取文件数据，然后拷贝到内核空间的内核缓存。
  - **4 次上下文切换**：
    1. 用户程序调用 `File#read` 读取文件，需要从用户态切换到内核态。
    2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
    3. 用户程序调用 `Socket#write` 发送数据，需要从用户态切换到内核态。
    4. 文件发送完成后，用户程序又需要从内核态切换回用户态。

- **优点**：如果所请求的数据已经存放在内核的高速缓冲存储器中，就可以减少实际的 I/O 操作。

- **缺点**：数据拷贝的过程会导致 CPU 的开销。

#### 零拷贝技术

- **概念**：零拷贝技术，并不是不需要拷贝，而是减少不必要的拷贝次数，避免多余地将数据从一块存储拷贝到另外一块存储，从而节省数据拷贝带来的CPU开销。
- **分类**：目前零拷贝技术主要有三种类型：

##### 直接 I/O

![1634175610607](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634175610607.png)

数据直接跨过内核，在用户地址空间与 I/O 设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作。

- **实现方法**：采用直接 I/O，需要在调用 `open` 时，传入 `O_DIRECT` 标识符，让操作系统知道接下来对文件的读写操作是使用 直接 I/O 的方式。

  ```c
  // Linux Open函数
  int open(const char *pathname, int oflag, … /*, mode_t mode * / );
  
  ```

- **使用场景**：

  - 这种类型的零拷贝多用于**数据库系统**中，方便他们自己实现一套缓存机制，以更好的提供服务。
  - 再如 Java 的 **Direct Buffer**。

##### 避免内核和用户空间的数据拷贝

当应用程序不需要对数据进行访问时，则可以通过避免将数据从内核空间拷贝到用户空间，实现零拷贝。

###### mmap

`mmap`，Memory Mapped Files，内存映射机制，并不是提供用户进程直接操作内核地址空间的能力，而是把内核中的部分内存空间映射到用户空间的内存，使得用户空间和内核空间共享一块相同的物理内存，从而提供用户进程对内存的直接访问能力。

- **实现方法**：

  ```c
  void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
  
  ```

- **实现原理**：调用 `mmap` 之后，并不会立即读取文件内容并加载到物理内存中，而是会在虚拟内存中分配地址空间，等到实际要访问数据时，才会因为内存地址对应的物理内存中没有数据，产生缺页异常，然后触发数据的加载。

- **使用场景**：

  1. 有了 `mmap` 的支持，从文件中读取数据到内核空间的文件数据缓存后，就不会再拷贝到用户空间的用户缓存了。
  2. 当调用 `Socket#send` 时，数据会直接从内核缓存，直接拷贝到 Socket 缓冲区中，避免了在用户空间中多中转一次。
  3. 所以，在 I/O 过程中，使用 `mmap` 可以减少 2 次用户空间与内核空间的 CPU 拷贝操作，替代为一次内核空间的直接拷贝。

  ![1634177254260](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634177254260.png)

- **局限**：虽然 `mmap` 能减少一次数据拷贝，但是 I/O 过程还是需要 4 次上下文切换：

  1. 用户程序调用 `mmap` 读取文件，需要从用户态切换到内核态。
  2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
  3. 用户程序调用 `Socket#send` 发送数据，需要从用户态切换到内核态。
  4. 文件发送完成后，用户程序又需要从内核态切换回用户态。

###### sendfile

`sendfile` 内核调用，是在 Linux 2.1 版本开始引入的，主要功能是在内核态中，可以在两个文件描述符之间传递数据，避免了用户空间和内核空间之间的数据拷贝操作。

- **实现方法**：

  ```c
  /**
   * in_fd：数据源的文件描述符，必须是一个可以 mmap 的文件描述符，必须指向真实的文件，不能是socket
   * out_fd：待输出的文件描述符，必须是一个socket
   */
  ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
  
  ```

- **实现原理**：使用 `sendfile` 时，数据中转与 `mmap` 类似，不经过用户空间， `sendfile` 全程在内核态执行，一次 I/O 只需要 2 次上下文切换：

  1. 用户程序调用 `sendfile` 通过 socket 发送文件，需要从用户态切换到内核态。
  2. 文件发送完成后，用户程序又需要从内核态切换回用户态。

- **sendfile 优化**：

  1. 在 Linux 2.4 版本中，对 `sendfile` 进一步做了优化，无需 CPU 从文件数据缓存拷贝到 socket缓存，而是让 socket 缓存只存储在文件数据缓存中的位置和偏移量。

  2. 在进行实际发送时，只需根据位置和偏移量，直接将文件数据缓存中的数据通过 DMA 拷贝到网卡设备中，又省掉了一次 CPU 拷贝操作。

     ![1634179262531](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634179262531.png)

###### splice

```c
// 功能与sendfile类似，但fd_in和fd_out中，必须至少有一个是管道文件描述符（pipe）
ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags);
```

###### tee

```c
// 功能与sendfile类似，但fd_in和fd_out都必须是管道文件描述符（pipe）
ssize_t tee(int fd_in, int fd_out, size_t len, unsigned int flags);
```

###### sockmap

上面的几种方式，都不支持从 socket 到 socket 的转发，而 Linux 4.14 带来的 `sockmap`，可以支持在内核态中实现从 socket 到 socket 的数据转发。

##### Copy on Writes

- **概念**：写时复制技术，也算是一种零拷贝技术，其核心思想是，数据不需要提前拷贝，而是当需要修改时才进行部分拷贝。
- **原理**：
  1. 当有多个调用者都需要请求相同资源时，一开始资源只会有一份，多个调用者共同读取这一份资源。
  2. 当某个调用者需要修改数据的时候，才会分配一块内存，把数据拷贝过去，供这个调用者使用，而其他调用者依然还是读取最原始的那份数据。
  3. 每次有调用者需要修改数据时，就会重复一次拷贝流程，供调用者修改使用。
- **作用**：使用 `copy-on-write` 可以避免或者减少数据的拷贝操作，极大地提高性能。
- **实现**：其应用十分广泛，比如Linux 的 `fork` 调用、Linux 的文件管理系统、一些数据库服务、Java中的 CopyOnWriteArrayList、C++98/C++03中的std::string等等。

### 1.9. 详细介绍 Kafka？

#### 概念

![1634043435602](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634043435602.png)

Kafka 是一个分布式的、基于发布订阅模式的消息系统，可用于实现高性能数据管道、流分析、数据集成和关键任务等相关的应用程序，在大数据领域的实时计算、日志采集等场景表现出色。

- **通用用途**：异步处理、系统解耦、削峰填谷、蓄流压测。

- **特色用途**：日志收集、数据同步、数据采集。

  - **日志收集**：KafKa 做日志堆积，减轻 Logstash 压力。

    ![1633839541805](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839541805.png)

  - **数据同步**：MySQL 分库分表后，统一经过 Cannal + Kafka 同步到 ES 中，方便搜索查询。

    ![1633839719421](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839719421.png)

  - **数据采集**：实时计算分析平台，埋点采集数据，上报到 Kafka，Flink 周期性从 Kafka 获取数据进行分析。 

    - **用户活动跟踪**：Kafka 常常被用于记录 Web 用户或者 App 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 Kafka Topic 中，然后 Consumer 通过订阅这些 Topic来做运营数据的实时监控分析。

    ![1633839898897](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1633839898897.png)

| 专业术语       | 释义                                                         |
| -------------- | ------------------------------------------------------------ |
| Broker         | 服务器实体，用于连接 Producer 和 Consumer，单个 Kafka Broker 可以轻松处理数千个 Partition 以及百万级/s的消息量 |
| Message        | 消息，Kafka 中的数据单元，可以看成是数据库里的一个数据行或一条记录 |
| Topic          | 主题，每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic，Topic 是逻辑的概念，物理上不同 Topic 的消息会分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个Broker上，但用户只需指定消息的 Topic，即可生产或者消费数据，而无需关心数据存放在物理上的何处 |
| Partition      | 分区，Parition 是物理上的概念，每个 Topic 包含一个或多个 Partition |
| Replica        | 副本，每个 Partition 有多个 Replica，每个 Replica 都会分布在不同的 Broker 中，都有一个 Leader Replica 进行复制同步 |
| Producer       | 生产者，负责发布消息到 Broker，默认情况下 Broker 会把消息均衡地分布到 Topic 下的所有 Partition 上，另外，也可以通过直接指定、根据 Key 散列取模、轮询方式来得到消息要存放的 Partition |
| Consumer       | 消费者，负责向 Broker Partition 读取消息，Consumer 通过 Consume Offset 来区分已经读过的消息，消费未读过的消息，然后会把每个 Partition 最后读取的 Consume Offset 保存在 Zookeeper 或 Kafka上，使得即使 Consumer 被关闭或重启，当前的读取状态也不会丢失 |
| Consumer Group | 消费者组，每个 Consumer 属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则该 Consumer 属于默认的消费者组；消费者组可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会重新再平衡，接管已失效的 Consumer 的工作 |
| Consume Offset | 消费偏移量，不同消费者组的 Consumer，可以对同一个 Partition 存储不同的 Offset，它们之间互不影响，用于记录读取状态，区分已经读过的消息，消费未读过的消息；指向最后消费的消息，通过在客户端库维护这个偏移量，并且根据 Kafka 版本，存储在 ZooKeeper 或者 Kafka 中 |
| Log Offset     | 日志偏移量，消息写入时，每一个 Partition 都有一个 Offset，它是每个 Partition 中最新、最大的 Offset |
| Log Segment    | 一个 Partition 由多个 LogSegment 组成，一个 LogSegment 由 `.log`、`.index`、 `.timeindex` 组成，`.log` 是顺序追加写入的，其文件名是以文件中第一条 Message 的Offset 来命名的，`.Index` 可以在日志删除和数据查找时进行快速定位，`.timeStamp` 则可以根据时间戳查找对应的偏移量 |

#### 原理

##### 日志分区原理

![1634092563478](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634092563478.png)

###### Kafka 本质

Kafka 本质上是一个**分布式的、异步复制的提交日志**，本身并没有队列的概念：

- **分布式**：Kafka 集群可以实现容错和方便扩展。
- **异步复制**：Follow Replica 副本定时异步拉取 Leader Partition Offset，以实现消息跨多个节点复制。
- **提交日志**：消息存储在 Partition 中，附加到 Topic 的日志上。

###### 日志分区模型

1. **消息存储方面**：Kafka 不像 RabbitMQ 那样存储在 Queue 中，只是把消息追加到日志中，无论消息被消费一次还是一千次，消息都会保持原状，最后根据数据的保留策略，来决定是否被删除。
   - RabbitMQ 通过把消息放入 FIFO 的队列 Queue 上，并跟踪 Queue 中该消息的状态，当 Consumer 消费该消息后，无论该消息有没有被持久化，Queue 都会把该消息删除掉。
2. **消息消费方面**：Kafka 不像 RabbitMQ 那样通过 **Broker Push 模型**消费，而是让每个 Consumer 跟踪它自己在日志中的消费偏移量，通过 **Consumer Pull 模型**，每次都从消费偏移量位置开始消费消息。
   - **消费偏移量**：
     - Consume Offset，不同消费者组的 Consumer，可以对同一个 Partition 存储不同的 Offset，它们之间互不影响，用于记录读取状态，区分已经读过的消息，消费未读过的消息。
     - 指向最后消费的消息，通过在客户端库维护这个偏移量，并且根据 Kafka 版本，存储在 ZooKeeper 或者 Kafka 中。
   - **Broker Push VS Consumer Pull 模型**：
     - RabbitMQ 使用 Broker Push 模型，结合 Consumer 配置的预取限制，来防止单个 Consumer 负担过重，对于低延迟消息传递非常有用，适用于 RabbitMQ 基于队列的架构。
     - Kafka 使用 Consumer Pull 模型，Consumer 根据消费偏移量来批量拉取消息，由于 Kafka Partition 能够保证消息顺序，所以可以通过消息批量拉取，来实现更高效的消息传递，从而提供更高的吞吐量。
   - **消息日志优势**：
     1. **消息持久化时间长**：消息投递后，Kafka 会长时间持久化消息，直到删除策略触发，而 RabbitMQ 则是在消息被消费后就删除。 
     2. **允许消费先前消息**：对于 Kafka 而言，可以允许 Consumer 倒带并消费先前偏移量的消息，只需将 Consumer 的偏移量往先前方向移动 N 小时即可，而使用 RabbitMQ 需要以某种方式重新发布先前的消息。
3. **消息分区方面**：
   1. 生产者负责发布消息到 Broker，默认情况下 Broker 会把消息均衡地分布到 **Topic** 下的所有 Partition 上，另外，也可以通过直接指定、根据 Key 散列取模、轮询方式来得到消息要存放的 Partition。
   2. 每个**分区**（Partition ）都是一个单独的数据结构，可以保证消息顺序，但仅在单个 Partition 内得到保证，一个 Partition 不能支持竞争消费者，因此同一个消费者组内只能有一个 Consumer 去消费某个 Partition。
   3. 每个**消费者**（Consumer）属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则属于默认的消费者组。
   4. **消费者组**（Consumer Group）可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会重新再平衡，接管已失效的 Consumer 的工作。
      - 消费者组中的每个  Consumer  将处理 Topic 下所有消息的一个 Partition 子集，即从同一Topic 的不同分区消费。
      - 而 RabbitMQ 的竞争消费者，是从同一个 Queue 中消费，在这一点上，RabbitMQ 看起来更加灵活，因为它保证了队列中的消息顺序，并且能够应对不断变化的竞争消费者数量。

###### 分区分配策略

- **Broker 分区存储**：
  1. 先把所有 Broker 和 Partition 排好序。
  2. 然后把第 i 个 Partition 分配到第 **i mod n** 个 Broker 上。
- **Producer 消息投递**：
  1. 当 key 为空时，Producer 生产的消息，将随机发送到各个 Partition，不同的 Kafka 版本会有不同方式，比如轮训、随机、固定等。
  2. 当 key 不为空时，采取 **key#hash mod Partion#size** 的方式，来决定把消息发送到哪个 Partition 上。
- **Consumer 消息消费**：一个 Partition 只能被同一个 Consumer Group 内的一个 Consumer 消费。
  - **RangeAssignor**：默认，简单相除。
    - **原理**：
      1. 用 Partition#size / Consumer#size 来决定每个 Consumer 消费几个Partition。
      2. 当除不尽时，则前面的 Consumer 会比后面的 Consumer 多消费 Partition。
      3. 当 Consumer#size > Partition#size 时，会有空消费的 Consumer。
    - **缺点**：分配不均匀，可能会出现部分 Consumer 过载的情况。
  - **RoundRobinAssignor**：排序 + 轮训。
    - **原理**：
      1. 把 Consumer Group 内所有 Consumer，以及其所订阅的所有 Topic#Partition 按照字典顺序排好序。
      2. 然后通过轮询的方式，逐个把 Partition 分配给每个 Consumer。
      3. 如果同一个 Consumer Group 内所有 Consumer 订阅的信息都是相同的，那么该策略的分区分配会是均匀的。
      4. 如果同一个 Consumer Group 内所有 Consumer 订阅的信息都不相同，那么在执行分区分配时就不是完全的轮询分配了，可能会导致分区分配的不均匀。
         - 比如某个 Consumer 没有订阅某个Topic，但该 Topic 会被组内其他 Consumer 订阅，则会在分配分区时，该 Consumer 将分配不到该 Topic 的任何 Partition。
    - **缺点**：还是会出现分配均匀的情况。
  - **StickyAssignor**：粘性分配，0.11.x 版本开始引入。
    - **原理**：
      1. 分区的分配要尽可能地均匀。
      2. 分区的分配尽可能地与上次分配的保持相同。
         - 如果发生分区重分配，那么对于同一个  Partition 而言，有可能之前的 Consumer 新指派的 Consumer 不是同一个。
         - 此时，如果使用非粘性策略，则对于之前 Consumer 进行到一半的处理，还要在新指派的消费者中再次复现一遍，很浪费系统资源。
         - 但 StickyAssignor 策略具备一定的粘性，可以尽可能地让前后两次分配相同，进而减少系统资源的损耗，以及其它异常情况的发生。
      3. 当前面两点发生冲突时，第一个点优先于第二个点。
    - **缺点**：实现比较复杂。

##### 日志文件存储原理

![1634213772578](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213772578.png)

1. 在 Kafka 日志文件存储中，同一个 Topic 下会有多个不同的 Partition，每个 Partiton 为一个目录，所以，Partition 是实际物理上的概念，而 Topic 则是逻辑上的概念。
   - **Partition 目录命名规则**：Topic + 有序序号，第一个序号从 0 开始，最大的序号为 Partition 数量减 1。
   - **为什么不能以 Partition 作为存储单位**？
     1. 虽然 Kafka Consumer 能够根据 Consume Offset 查找到具体的某个消息，但是查找过程是顺序查找，如果数据量很大的话，查找效率依然很低，所以，Kafka 采用了**分段和索引**的方式，通过**二分查找**来解决查找效率问题。
     2. 而且，每个 Partition 被平均分配到多个 Segment 文件，也方便 Old Segment 的删除，即方便已消费消息的清理，提高磁盘的利用率。
   - **Segment 分段策略**：
     - **按大小分片**：当日志分段文件大小，超过了 Broker 参数 `log.segment.bytes` 配置的值时，则需要继续分段，默认为 `1073741824（1GB）`。
     - **按时间分片**：当日志分段文件中，消息的最大时间戳与当前系统时间戳的差值，大于 `log.roll.ms` 或者大于 `log.roll.hours` 配置的值时，则需要继续分段，默认为 `168（7天）`。
     - **按索引分片**：当 `.index` 或者 `.timeindex` 文件大小达到 Broker  `log.index.size.max.bytes` 配置的值时，则需要继续分段，默认为 `10MB`。
     - **按偏移量分片**：当新追加消息的偏移量 `offset`，与日志分段文件偏移量的差值 `baseOffset`，大于 `Integer.MAX_VALUE` 时，则需要继续分段。
2. 然后，Partition 还可以细分为多个**小文件段** Segment，一个 Partition 物理上由多个 Segment 组成，Segment 不是一个目录，而是由 3 部分组成，分别为 `.index` 文件、`.timeindex` 文件 和 `.log` 文件，分别表示偏移量索引文件、时间戳索引文件和日志数据文件。
   - **Segment 文件命名规则**：
     1. Partition 中第一个 Segment 从 `0` 开始，数值为 `20` 位数字字符长度，不够的用 `0` 填充。
     2. 后续每个 Segment 文件名，为上一个 Segment 文件**最后一条消息**的 `offset` 值。
   - **Segment 索引文件的作用**：为了进一步提高查找效率，Kafka 还为每个分段后的数据建立了**索引文件**，然后通过索引文件的**稀疏存储**，来降低 Partition 元数据的占用大小。
   - **如何查找偏移量为 118 的消息**？根据时间戳查找的方式同理。
     1. 首先，Kafka 会用一个 `ConcurrentSkipListMap` 跳跃表，来记录每个日志分段，通过它可以根据偏移量 `118` 定位到 Segment 在 00000000000000000000.index 中。
     2. 然后，通过**二分查找**在该 `.index` 文件中，找到**不大于 `offset:118`  的最大索引项**，即 `offset:116` 那栏，得到 `position:9679`。
     3. 接着，从 `.log` 文件中，物理位置为 `position:9679` 的位置，开始顺序查找 `offset:118` 的消息。

##### 生产者消息投递原理

![1634213881470](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213881470.png)

1. Producer 客户端分为两个线程，在创建时会创建一个 `Sender` 守护线程。
2. 主线程负责把生产的消息 -> 拦截器 -> 序列化器 -> 分区器 -> 缓存到消息累加器 -> 追加到每个分区 ProducerBatch 队列的队尾。
3. 其中，消息存放在 ProducerBatch 对象中，相当于 ProducerBatch 队列对消息进行了组装，在满足批次发送的条件时，则会通过 `Sender` 线程批次发送消息，减少网络资源消耗。
   - **批次发送的条件**：缓冲区数据大小达到 `batch.size` ，或者 `linger.ms` 达到上限时。
4. `Sender` 线程会从 ProducerBatch 队列的队头获取消息 -> 创建请求 -> 提交给 Selector 发送到 Broker 指定的分区，同时还会把请求缓存在 Node 结点，代表已发送但为收到 Broker ACK 确认的请求，如果 Producer 收到消息后，则会对其清理。
5. Broker 收到消息后，会根据 Producer 的 `acks` 配置参数，落盘消息到 Partition 中。
6. 如果 Producer 还配置了大于 0 的 `retrires` 参数，当未收到 Broker ACK 确认时，Producer 会对该消息进行重试。

##### 消费者消息消费原理

![1634213916345](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213916345.png)

1. Consumer 客户端负责向 Broker Partition 读取消息，通过 Consume Offset 来区分已经读过的消息，消费未读过的消息。
2. 然后会把每个 Partition 最后读取的 Consume Offset 保存在 Zookeeper 或 Kafka上，使得即使 Consumer 被关闭或重启，当前的读取状态也不会丢失。
3. 而对于消费者组，每个 Consumer 属于一个特定的消费者组，消费者组可为每个 Consumer 指定 group name，若不指定 group name，则该 Consumer 属于**默认的消费者组**。
4. 消费者组可以保证每个 Partition 只能被一个 Consumer 消费，如果组内一个 Consumer 失效，那么组内的其他 Consumer 会 Rebalance，接管已失效 Consumer 的工作。

##### 高性能原理 | 为什么 Kaka 这么快？

Kafka 对性能做了大量的优化，使得单个 Broker 就可以轻松处理数千个 Partition 以及百万级/s 的消息量，其高性能原理为：

###### 1、利用 Partition 实现并行处理

并行处理可以提升速度，因为多个人搬砖肯定比一个人搬得快。

- **集群优势**：每个 Topic 都包含一个或多个 Partition，不同 Partition 可以位于不同 Broker 节点，因此，可以充分利用集群优势，实现机器间的并行处理。
- **多磁盘优势**：另外，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个 Broker 节点，也可通过配置，让不同 Partition 落于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

###### 2、顺序写磁盘

在许多的开源框架，比如 Kafka、HBase，都通过追加写，即顺序写磁盘的方式，来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。

- **消息写入时**：每个 Partition 是一个有序的、不可变的消息序列，新消息只需不断追加到 Partition 的末尾，实现顺序写磁盘。
  - **顺序写性能高的原因**：机械硬盘的连续读写性能很好，但随机读写性能很差，主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要**不停的移动**，时间都浪费在了磁头寻址上，所以性能不高。
  - **顺序写的缺点**：当从文件中读一些数据时，需要倒序扫描，直到找到所需要的内容，这将会花费更多的时间。
    - **Kafka 解决方案**：日志分段 + 日志索引，见《日志索引原理》。
- **消息清除时**：
  1. 由于磁盘有限，不可能保存所有数据，所以 Kafka 还需要删除旧的数据。
  2. 又由于顺序写入的原因，Kafka 采用各种删除策略进行数据删除时，并非通过使用 `读 - 写` 模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个 Segment 的方式去删除 Partition 内的数据，从而避免了对文件随机写的操作。

###### 3、充分利用 Page Cache

![1634213586951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213586951.png)

- **对于读操作**：可直接在 Page Cache 内进行，避免了对底层磁盘的操作，提高了读性能。
  - 如果消费和生产速度相当，甚至不需要通过物理磁盘，而是直接通过 Page Cache 进行交换数据。
- **对于写操作**：
  1. Broker 收到数据后，写磁盘只是暂时把数据存在 Page Cache 中，然后交由操作系统来统一**异步**写到磁盘中，减少了 Broker 访问磁盘的次数，提高了写性能。
  2. 另外，根据 I/O 调度算法， I/O Scheduler 会把连续的小块写，组装成大块的物理写，同时会尝试将一些写操作重新按顺序排好，减少磁盘头的移动时间，进一步提高了写性能。
  3. **局限**：写磁盘只是把数据写入 Page Cache，并不保证数据一定完全写入磁盘，虽然 Kafka 进程重启时， Page Cache 仍然可用，但如果在机器宕机时，则可能会由于 Page Cache 内的数据未写入磁盘，从而导致数据的丢失。
     - **解决方案**：
       - **副本机制**：这种丢失只发生在机器断电等，造成操作系统不工作的场景里，可以由 Kafka Replication 机制去解决。
       - **强制刷脏**：Kafka 提供了 `flush.messages` 和 `flush.ms` 两个参数，可以把 Page Cache 中的数据强制 Flush 到磁盘中，但是 Kafka 并**不建议使用**，这是因为如果为了保证这写情况下的数据不丢失，而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。

###### 3、使用零拷贝技术

![1634213686949](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634213686949.png)

- **背景**：Kafka 存在大量的**网络数据持久化到磁盘**（Producer 到 Broker）和**磁盘文件通过网络发送**（Broker 到 Consumer）的过程，这些过程的性能直接影响 Kafka 整体的吞吐量。

- **Producer 到 Broker**：网络数据持久化到磁盘。

  1. **传统 I/O 模式**：数据从网络传输到文件，需要 4 次数据拷贝、4 次上下文切换和 2 次系统调用。

     ![1634181215053](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634181215053.png)

     - **4 次数据拷贝**：

       1. 首先，通过 DMA copy 将网络数据，拷贝到内核态 Socket Buffer。
       2. 然后，应用程序将内核态 Socket Buffer 数据，通过 CPU copy 读入用户态 Buffer。
       3. 接着，用户程序将用户态 Buffer 数据，再通过 CPU copy 拷贝到内核态 Buffer。
       4. 最后，通过 DMA copy 将数据拷贝到磁盘文件。
          - 这里的数据落盘，对于 Kafka的是**非实时**的，Kafka 充分利用了 Page Cache 来提高 I/O 效率。

     - **4 次上下文切换**：

       1. 用户程序调用 `Socket#read()` 读取网络数据，需要从用户态切换到内核态。
       2. 网络数据读取完成后，用户程序又需要从内核态切换回用户态。
       3. 用户程序调用 `File#write` 写入文件数据到磁盘，需要从用户态切换到内核态。
       4. 文件写入磁盘完成后，用户程序又需要从内核态切换回用户态。

     - **2 次系统调用**：socket#read、file#write。

       ```java
       data = socket.read()；// 读取网络数据 
       File file = new File()；
       file.write(data)；// 持久化到磁盘 
       file.flush()；
       
       ```

  2. **mmap 零拷贝优化 I/O**：

     ![1634181981080](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634181981080.png)

     - **优化思路**：
       1. Broker 读取到 Socket Buffer 的网络数据，其实可以直接在内核空间完成落盘，没有必要将其再拷贝到用户空间中。
       2. 所以，Kafka 采用了 `mmap` ，将内核中读缓冲区 read buffer 的地址与用户空间的缓冲区 user buffer 进行映射，实现内核缓冲区与应用程序内存的共享，省去了用户空间到内核空间复制的开销，减少了 2 次用户空间与内核空间的 CPU 拷贝操作，替代为一次内核空间的直接拷贝，提高了 I/O 性能。
     - **优化实现**：
       1. Kafka Java NIO，提供了一个 `MappedByteBuffer` 类可以用来实现内存映射。
       2. MappedByteBuffer 只能通过调用 `FileChannel#map（）` 抽象方法取得，具体实现是在 `FileChannelImpl.c` ，该方法底层正是调用了 Linux 内核 `mmap` 的API。
       3. 使用 `MappedByteBuffer` 类要注意的是，`mmap` 在 Full GC 时才会被进行释放，手动 Close 时，需要反射调用 `sun.misc.Cleaner` 方法来手动清除内存映射文件。

- **Broker 到 Consumer**：磁盘文件通过网络发送。

  1. **传统 I/O 模式**：数据从文件到网络传输，也需要 4 次数据拷贝、4 次上下文切换和 2 次系统调用。

     ![1634173642699](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634173642699.png)

     - **4 次数据拷贝**：
       1. 首先，调用 `File#read` ，通过 DMA 拷贝将文件数据读入到内核态 Buffer。
       2. 然后，应用程序通过 CPU 拷贝将内存态 Buffer 数据读入到用户态 Buffer。
       3. 接着，调用 `Socket#send `时，将用户态 Buffer 数据，通过 CPU 拷贝到内核态 Buffer。
       4. 最后，通过 DMA 拷贝将数据拷贝到 NIC Buffer。
     - **4 次上下文切换**：
       1. 用户程序调用  `File#read` 读取文件，需要从用户态切换到内核态。
       2. 文件读取完成后，用户程序又需要从内核态切换回用户态。
       3. 用户程序调用  `Socket#send` 发送数据，需要从用户态切换到内核态。
       4. 文件发送完成后，用户程序又需要从内核态切换回用户态。
     - **2 次系统调用**：file#read、socket#send。

     ```java
     buffer = File.read()；// 读取文件
     Socket.send(buffer)；// 发送文件
     
     ```

  2. **sendfile 零拷贝优化 I/O**：

     ![1634190319687](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634190319687.png)

     - **优化思路**：

       1. Linux 2.4+ 内核通过 `sendfile` 系统调用，提供零拷贝，使用 `sendfile` 时，数据中转与 `mmap` 类似，不经过用户空间， `sendfile` 全程在内核态执行，一次 I/O 只需要 2 次上下文切换，数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝，这也是零拷贝这一说法的来源，大大提高了性能。
       2. 在这里，Kafka Customer 从 Broker 读取数据，采用 `sendfile`，将磁盘文件读到内核缓冲区后，转到 NIO buffer 进行网络发送，无需 CPU 拷贝，减少了 CPU 消耗，提高 I/O 吞吐量。

     - **优化实现**：

       1. Java NIO 对 `sendfile` 的支持是 `FileChannel.transferTo()/transferFrom()`，把磁盘文件读取内核缓冲区 fileChannel 后，直接转给 socketChannel 进行发送。

          ```java
          // java.nio.channels.FileChannel
          public abstract long transferTo(long position, long count,
                           WritableByteChannel target) throws IOException;
          public abstract long transferFrom(ReadableByteChannel src,
                           long position, long count) throws IOException;
          ```

       2. Kafka 数据传输通过 `TransportLayer` 来完成，其子类 `PlaintextTransportLayer` 正是通过Java NIO 的 `FileChannel.transferTo()/transferFrom()` 方法实现零拷贝。

       3. 注意，`transferTo()/transferFrom()` 并不保证一定能使用零拷贝，实际上是否能使用零拷贝与操作系统相关，如果操作系统提供 `sendfile` 这样的零拷贝系统调用，则这两个方法会通过这样的系统调用充分利用零拷贝的优势，否则并不能通过这两个方法本身实现零拷贝。

###### 4、消息批处理

在很多情况下，系统瓶颈并不是 CPU 或磁盘，而是网络 I/O，所以，Kafka 的客户端和 Broker 还会在通过网络发送数据之前，在一个 Batch 中累积多条记录（包括读和写）再批次发送，分摊数据包网络往返的开销，使用更大的数据包提高带宽的利用率。

###### 5、数据压缩后传输

数据压缩，一般都和批处理作为优化手段配套使用，Producer 可将数据压缩后再传输给 Broker，可以减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4，可通过 `compression.type` 配置。

#### API

##### Server.properties 重要配置

| 属性                               | 释义                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| zookeeper.connect                  | 指明 Broker 要连接的 ZK 集群，多个节点用逗号分隔开，ZK 用于管理 Kafka集群的元数据，比如 Topic、Partition、Leader Partition、副本 Replicas 等 |
| listeners                          | 与客户端进行交互的端口，比如消息投递、消息创建，可结合 `listener.security.protocol.map` 指定具体传输的协议类型，比如有 PLAINTEXT 明文传输、SSL 加密传输等 |
| log.dirs                           | 日志存储路径，建议配置多个路径，因为多个不同磁盘的路径，Kafka 会在含有分区目录最少的文件夹下创建新的分区目录，一来可提高吞吐量，二来可提高磁盘的容错性 |
| log.retention.{hours\|minutes\|ms} | Broker 级别的日志留存寿命，默认为 hours=168                  |
| log.retenion.bytes                 | Broker 级别的日志留存大小，默认为 -1，表示没有限制           |
| message.max.bytes                  | Broker 级别的最大消息大小，默认为 976 KB                     |
| retention.ms                       | Topic 级别的日志留存寿命                                     |
| retention.bytes                    | Topic 级别的日志留存大小                                     |
| max.message.bytes                  | 消息级别的最大消息大小                                       |
| auto.create.topics.enable          | 是否允许自动创建 Topic，建议为 false                         |
| unclean.leader.election.enable     | 是否允许选举未完全同步的副本作为 Leader                      |
| auto.leader.rebalance.enable       | 是否允许一段时间后进行 Leader 重选举，重新更换 Leader，建议为 false |

##### Broker 增删改查

```bash
# 启动Kafka
./kafka-server-start.sh -daemon ../config/server.properties
# 关闭Kafka
./kafka-server-stop.sh ../config/server.properties
# 增
kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x 
								--partitions 1 --replication-factor 1
# 删
kafka-topics.sh --zookeeper localhost:2181/myKafka --delete --topic topic_x
# 改
kafka-topics.sh --zookeeper localhost:2181/myKafka --alter --topic topic_x
								--config max.message.bytes=1048576
# 查
kafka-topics.sh --zookeeper localhost:2181/myKafka --describe --topic topic_x

```

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka_2.12</artifactId>
</dependency>

```

##### Producer | HelloWorld

Producer 是线程安全的，允许多线程使用同一个 Producer 进行消息投递。

###### Producer 必要配置

| 属性              | 释义                                                         |
| ----------------- | ------------------------------------------------------------ |
| bootstrap.servers | Kafka Broker 地址，存在多个时使用逗号分隔，建议使用多个地址，提高容错性 |
| key.serializer    | 消息 Key 序列化器                                            |
| value.serializer  | 消息 Value 序列化器                                          |
| client.id         | 标记 kafka 客户端的 ID                                       |

```java
public static void main(String[] args) {
    // 1. 配置生产者启动的关键属性参数
    Properties properties = new Properties();
    /*1.1. 连接kafka集群的服务列表，如果有多个，使用逗号进行分隔*/
    properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.111:9092");
    /*1.2. 标记kafkaClient的ID*/
    properties.put(ProducerConfig.CLIENT_ID_CONFIG, "quickstart-producer");
    /*1.3. Key序列化器: kafka用于做消息投递计算具体投递到对应的主题的哪一个partition而需要的*/
    properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    /*1.4. Value序列化器: 实际发送消息的内容序列化*/
    properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    // 2. 传递properties属性参数集合, 构造kafka生产者对象
    KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
    for(int i = 0; i < 10; i++){
        // 3. 构造消息内容: topic, 实际消息体
        User user = new User("00" + i, "张三");
        ProducerRecord<String, String> record = new ProducerRecord<>(Const.TOPIC_QUICKSTART, JSON.toJSONString(user));

        // 4. 发送消息, 返回的是一个future对象
        producer.send(record);
        System.err.println("quickstart producer send....");
    }

    // 5. 关闭生产者
    producer.close();
}
```

##### Consumer | HelloWorld

Consumer 是非线程安全的，不允许多线程使用同一个 Consumer 进行消息投递。

- 因为在 `org.apache.kafka.clients.consumer.KafkaConsumer#acquire` 中，会校验同一个 Consumer 是否存在其他线程，如果是则会抛出 `ConcurrentModificationException`，Kafka Consumer 在执行任何都做都会先执行 `acquire` 方法来检测线程是否安全。

###### Consumer 必要配置

| 属性                    | 释义                                                         |
| ----------------------- | ------------------------------------------------------------ |
| bootstrap.servers       | Kafka Broker 地址，存在多个时使用逗号分隔，建议使用多个地址，提高容错性 |
| key.deserializer        | 消息 Key 反序列化器                                          |
| value.deserializer      | 消息 Value 反序列化器                                        |
| group.id                | 消费者所属的消费组，不配置时会使用默认的 `""` 消费者组       |
| subscribe               | 订阅消费的 Topic，支持集合方式（订阅多个 Topic）或者正则表达式（正则匹配 Topic） |
| assign                  | 指定消费 Topic 下的某个 Partition                            |
| enable.auto.commit      | 是否开启自动提交，默认为 true，实际工作中建议设置为 false，即手工提交，分为 `commitSync` 同步提交，以及 `commitAsync` 异步提交两种方式 |
| auto.commit.interval.ms | 自动提交周期，默认值为 5 s                                   |

```java
public static void main(String[] args) {
    // 1. 配置属性参数
    Properties properties = new Properties();
    /*1.1. 连接kafka集群的服务列表，如果有多个，使用逗号进行分隔*/
    properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.1.111:9092");
    /*1.2. 设置订阅组ID, 与消费者订阅组有关系*/
    properties.put(ConsumerConfig.GROUP_ID_CONFIG, "quickstart-group");
    /*1.3. Key反序列化器*/
    properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    /*1.4. Value反序列化器*/
    properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
    /*1.5. 设置常规属性: 会话连接超时时间*/
    properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);
    /*1.6. 设置常规属性: 自动提交与自动提交周期, 默认不用设置*/
    properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
    properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);

    // 2. 创建消费者对象
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);

    // 3. 订阅感兴趣的主题
    consumer.subscribe(Collections.singletonList(Const.TOPIC_QUICKSTART));
    System.err.println("quickstart consumer started...");

    /*监听消息*/
    try {
        while (true){
            // 4. 采用PULL的方式消费数据
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
            for (ConsumerRecord<String, String> record : records) {
                System.out.println(String.format("topic=%s, partition=%s, offset=%s, key=%s, value=%s",
                                                 record.topic(), record.partition(), record.offset(), record.key(), record.value()));
            }
        }
    } catch (Exception e){
        throw e;
    } finally {
        consumer.close();
    }
}

```

##### 客户端重要配置

###### Producer 重要配置

- 在请求完成之前，Producer 要求 Broker 返回 ACK 确认的策略， 同时也控制着所发送消息的持久性：
  - **acks=0**：如果设置为 0，那么 Producer 不会 Leader Broker 的任何 ACK 确认，该消息记录会被将立即添加到 socket 缓冲区并视为已发送。
    - 在这种情况下，不能保证 Broker 已经收到记录，并且 Producer 配置的重试机制也会生效，为每个记录返回的偏移量将始终设置为 -1。
  - **acks=1**：默认为 1，意味着 Leader Broker 会把记录写入其本地日志，然后做出 ACK 响应给 Producer，并不会等待所有 Follower 确认完。
    - 在这种情况下，如果 Leader Broker 在返回 ACK 确认后发生失败，Follower 被选举为新 Leader 时，由于该记录 Follower 还没完成同步，所以将导致丢失。
  - **acks=all**：相当于 `ack=-1`，意味着 Leader Broker 将等待 ISR 中所有的 Broker 确认后才返回 ACK 响应给 Producer。
    - 这是最高的可用保证，只要至少有一个同步副本保持活动状态，该记录就不会丢失。 

| 属性                    | 释义                                                         |
| ----------------------- | ------------------------------------------------------------ |
| acks                    | Broker ACK 确认策略，默认为 1                                |
| max.request.size        | 用于限制 Producer 发送消息的最大值                           |
| retries                 | 重试次数，默认为 0                                           |
| retry.backoff.msretries | 重试间隔，默认为 100                                         |
| compression.type        | 消息的压缩方式，默认为 none，支持 gzip、snappy、lz4 压缩格式 |
| connections.max.idle.ms | 用于指定在多久之后关闭限制的连接，默认为 540000 ms（9 分钟） |
| linger.ms               | 用于指定 Producer 批发送之前，等待消息加入 ProducerBatch Deque 时间，默认为 0 |
| batch.size              | 指定累加多少条消息，才进行一次批发送                         |
| buffer.memeory          | Producer 缓冲待批发送消息的大小，默认为 32 MB                |
| receive.buffer.bytes    | 用于设置 Socket 接收消息缓冲区 SO_RECBUF 的大小，默认为 32 KB |
| send.buffer.bytes       | 用于设置 Socket 发送消息缓冲区 SO_SNDBUF 的大小，默认为 128 KB |
| request.timeout.ms      | 用于设置 Producer 等待请求响应的最长时间，默认为 3000 ms     |

###### Consumer 重要配置

- 当 Kafka 中没有初始偏移量时，比如偏移量数据已被删除，可以根据以下策略进行设置：
  1. **earliest**：自动将偏移量重置为最早的偏移量。
  2. **latest**：自动将偏移量重置为最新的偏移量。
  3. **none**：如果没有找到之前的偏移量，则向 Consumer 抛出异常。

| 属性                      | 释义                                             |
| ------------------------- | ------------------------------------------------ |
| fetch.min.bytes           | 一次拉取的最小数据量，默认为 1 B                 |
| fetch.max.bytes           | 一次拉取的最大数据量，默认为 50 MB               |
| max.partition.fetch.bytes | 一次拉取一个 Partition 的最大数据量，默认为 1 MB |
| fetch.max.wait.ms         | 拉取请求的最大延迟等待时间，默认为 500 ms        |
| max.poll.records          | 每次拉取的消息最大条数                           |
| auto.offset.reset         | 偏移量丢失处理策略，默认为 latest                |

##### 客户端拦截器

###### Producer 拦截器

```java
// Kafka自定义Producer拦截器
public class CustomProducerInterceptor implements ProducerInterceptor<String, String> {
    // 消息发送前置拦截器
    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {...}
    
    // 消息发送后置拦截器
	@Override
    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {...}
    
    // 生产者关闭拦截器
    @Override
    public void close() {...}
    
    // 生产者初始化拦截器
    @Override
    public void configure(Map<String, ?> map) {...}
}

// Kafka Producer拦截器测试类
public class InterceptorProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加生产者拦截器属性: 可以配置多个拦截器
        properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, CustomProducerInterceptor.class.getName());
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        ... 
    } 
}
```

###### Consumer 拦截器

```java
// Kafka自定义消费者拦截器
public class CustomConsumerInterceptor implements ConsumerInterceptor<String, String> {
    // 消费消息前拦截器
    @Override
    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> consumerRecords) {...}
    
    // 消息消费完毕提交前拦截器: 默认配置了每5s轮训一次是否提交, 所有也会每5s执行该拦截器
    @Override
    public void onCommit(Map<TopicPartition, OffsetAndMetadata> map) {...}
    
    // 消费者关闭拦截器: 从控制台关闭的不会执行, 只有代码自动关闭的才会
    @Override
    public void close() {...}
    
    // 消费者初始化拦截器
    @Override
    public void configure(Map<String, ?> map) {...} 
}

// Kafka Consumer拦截器测试类
public class InterceptorConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加消费端拦截器属性: 可以配置多个拦截器
        properties.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, 	CustomConsumerInterceptor.class.getName());
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        ...
    }
}
```

##### 客户端序列化/反序列化器

###### Producer 序列化器

序列化，Producer 需要用序列化器  Serializer 把对象转换成字节数组，Kafka Broker 才能接受。 

```java
// Kafka自定义User序列化器
public class UserSerializer implements Serializer<User> {
    // User序列化器初始化方法
    @Override
    public void configure(Map<String, ?> map, boolean b) {...}
    
    // User序列化器序列化方法
	@Override
    public byte[] serialize(String s, User user) {
        ...
        // 分配需要传输的字节数组: 各属性字节数组长度 + 各属性实际字节数组
        ByteBuffer byteBuffer = ByteBuffer.allocate(4 + idBytes.length + 4 + nameBytes.length);
        
        // 设置ID属性: 字节数组长度 + 实际字节数组
        byteBuffer.putInt(idBytes.length);
        byteBuffer.put(idBytes);
        
        // 设置NAME属性: 字节数组长度 + 实际字节数组
        byteBuffer.putInt(nameBytes.length);
        byteBuffer.put(nameBytes);
        
        // 返回组装好的字节数组
        return byteBuffer.array();
        ...
    }
    
    // User序列化器关闭方法
    @Override
    public void close() {...}
}

// Kafka 自定义Producer序列化器测试类
public class SerializerProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // Key使用默认的序列化器
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // Value使用自定义的序列化器
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, UserSerializer.class.getName());
        KafkaProducer<String, User> producer = new KafkaProducer<>(properties);
        ...
    }
}

```

###### Consumer 反序列化器

反序列化，Consumer 需要把从 Broker 拉取出来的字节数组，使用反序列化器 Deserializer 转换成相应的对象。

```java
// Kafka自定义User反序列化器
public class UserDeserializer implements Deserializer<User> {
    // 自定义User反序列化器初始化方法
    @Override
    public void configure(Map<String, ?> map, boolean b) {...}
    
    // 自定义User反序列化器反序列化方法
 	@Override
    public User deserialize(String topic, byte[] data) {
        ...
        // 包装字节数组成ByteBuffer对象
        ByteBuffer byteBuffer = ByteBuffer.wrap(data);
        
        // 获取ID属性
        int idLen = byteBuffer.getInt();
        byte[] idBytes = new byte[idLen];
        byteBuffer.get(idBytes);

        // 获取NAME属性
        int nameLen = byteBuffer.getInt();
        byte[] nameBytes = new byte[nameLen];
        byteBuffer.get(nameBytes);
        ...
    }
    
    // 自定义User反序序列化器关闭方法: 从控制台关闭的不会执行, 只有代码自动关闭的才会
    @Override
    public void close() {...}
}

// Kafka 自定义Consumer反序列化器测试类
public class DeserializerConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // Key使用默认的序列化器
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        // Value使用自定义的序列化器
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, UserDeserializer.class.getName());
        KafkaConsumer<String, User> consumer = new KafkaConsumer<>(properties);
        ...
    }
}

```

##### Producer 客户端分区器

- **默认消息分区规则**：org.apache.kafka.clients.producer.internals.DefaultPartitioner

  1. key 为空时，默认为随机值取模。
  2. key 不为空时，默认为使用 `Utils,murmur2` 计算 Hash 值后取模。

- **使用场景**：根据业务 ID Hash 到指定的 Partition，然后根据不同的业务，使用不同的 Consumer 消费。

  ![1634463959870](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634463959870.png)

```java
// 自定义Producer Partition
public class CustomPartitioner implements Partitioner {
    
    // 自定义Producer Partition计算Partition方法
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {...}
    
    // 自定义Producer Partition关闭方法
    @Override
    public void close() {...}
    
    // 自定义Producer Partition自定义方法
    @Override
    public void configure(Map<String, ?> map) {...}
}

// Kafka Producer测试类: 自定义Producer Partition
public class PartitionProducer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 添加自定义分区器
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class.getName());
        KafkaProducer<String, User> producer = new KafkaProducer<>(properties);
        ...
    }
}

```

##### Consumer Group 消费者组

![1634464669407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634464669407.png)

- **Consumer Group 与 Consumer 的概念**：
  1. **Consumer Group 与 Consumer 是一对多的关系**：一个 Consumer Group 包含多个 Consumer，一个 Consumer 只能同时出现在一个 Consumer Group 中。
  2. **Partition 与 Consumer Group 是一对多的关系**：一个 Partition 可以被多个 Consumer Group 消费。
  3. **在同一个 Consumer Group 中，Partition 与 Consumer 是一对多的关系**：但同一个 Consumer Group 中，只允许一个 Partition 被 一个 Consumer 去消费，而一个 Consumer 又可以去消费多个 Partition。
     - 在不指定 `group.id` 时，Consumer 会使用默认的 `""` Consumer Group，所以，才会出现一个 Partition 只能被一个 Consumer 消费的规定。
- **应用场景**：得益于 Consumer 与 Consumer Group 的设计，Kafka 同时支持消息中间两种模型：

###### Piont to Piont | 点对点模式

- **概念**：点对点模式，是基于队列的，Producer 发送消息到队列，Consumer 从队列中消费消息，其中 Consumer 只能有一个。

- **Kafka 实现方式**：Consumer 都属于同一个 Consumer Group 时，此时一个 Partition 只能被一个 Consumer 消费，相当于点对点模式。

  ```java
  // Kafka Consumer1: 消费者+消费者组实现点对点模式
  public class ModuleConsumer1 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 同一个消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  // Kafka Consumer2: 消费者+消费者组实现点对点模式
  public class ModuleConsumer2 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 同一个消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  ```

###### Pub/Sub | 发布订阅模式

- **概念**：发布订阅模式，定义了如何向一个内容节点即主题 Topic，进行发布和订阅消息，Publisher 把消息发布到某个 Topic 上，Subscriber 从 Topic 中订阅消息，其中 Subscriber 可以有多个，类似于广播的模式。

- **Kafka 实现方式**：存在多个 Consumer Group 去消费 Partition，此时一个 Partition 可以被多个 Consumer Group 中的 Consumer 消费，相当于发布订阅模式。

  ```java
  // Kafka Consumer1: 消费者+消费者组实现发布订阅模式
  public class ModuleConsumer1 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 不同消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-1");
          ...
      } 
  }
  
  // Kafka Consumer2: 消费者+消费者组实现发布订阅模式
  public class ModuleConsumer2 {
      public static void main(String[] args) {
  		Properties properties = new Properties();
          // 不同消费者组
          properties.put(ConsumerConfig.GROUP_ID_CONFIG, "module-group-id-2");
          ...
      } 
  }
  
  ```

##### Consumer subscribe/assign

```java
// Kafka Consumer: 测试消费者订阅参数
public class CoreConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        
        /*1) 对于Consume消息的订阅subscribe方法: 可以订阅一个或者多个topic*/
//        consumer.subscribe(Collections.singletonList(Const.TOPIC_CORE));
        /*2) 对于Consume消息的订阅subscribe方法: 也可以支持正则表达式方式的订阅, 初次如果先执行Consumer会导致一开始找不到Topic的问题, 所以第一次Producer产生的消息会错过*/
//        consumer.subscribe(Pattern.compile("topic-.*"));
        /*3) 对于assign方法: 可以指定订阅某个主题下的某一个或者多个partition*/
//        consumer.assign(Arrays.asList(new TopicPartition(Const.TOPIC_CORE, 0), new TopicPartition(Const.TOPIC_CORE, 2)));
        /*4) 对于assign方法: 还拉取拉取主题下的所有partition*/
        List<TopicPartition> topicPartitionList = new ArrayList<>();
        List<PartitionInfo> partitionInfoList = consumer.partitionsFor(Const.TOPIC_CORE);
        for (PartitionInfo partitionInfo : partitionInfoList) {
            topicPartitionList.add(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()));
        }
        consumer.assign(topicPartitionList);
    }
}

```

##### Consumer 手工提交

###### 开启手工提交

```java
// Kafka Consumer: 测试消费者手工提交方式
public class CommitConsumer {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        /* 自动提交*/
//        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
//        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000);
        /* 手工提交*/
        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
        ...
    }
}

```

###### 整体同步提交

```java
// ... 所有消息都消费完后
/*1) 整体提交: 同步提交(线程阻塞)*/
consumer.commitSync();

```

###### 整体异步提交

```java
// ... 所有消息都消费完后
/*2) 整体提交: 异步提交(线程非阻塞), 可回调可不回调, 这里会轮训回调函数*/
consumer.commitAsync(new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> map, Exception e) {
        if(e != null) {
            System.err.println("error处理");
        }
        System.err.println("整体异步提交成功: " + map);
    }
});
```

###### 按消息同步提交

```java
// ... 遍历、消费每条消息完成后
/*3) 按消息做提交动作: 同步提交, 可靠*/
consumer.commitSync(Collections.singletonMap(consumerRecord.partition(), new OffsetAndMetadata(consumerRecord.offset() + 1)));
```

###### 按消息异步提交

```java
// ... 遍历、消费每条消息完成后
/*4) 在Partition内一条消息做一次提交动作: 异步提交, 可靠且高性能*/
consumer.commitAsync(Collections.singletonMap(consumerRecord.partition(), new OffsetAndMetadata(consumerRecord.offset() + 1))), new OffsetCommitCallback() {
    @Override
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> map, Exception e) {
        if(e != null) {
            System.err.println("error处理");
        }
        System.err.println("在Partition内一条消息做一次异步提交成功: " + map);
    }
});
```

##### Consumer Reblance

```java
// Kafka Consumer: 测试同组消费者再均衡
public class RebalanceConsumer1 {
    public static void main(String[] args) {
        ...
        /*测试同组消费者再均衡*/
        consumer.subscribe(Collections.singletonList(Const.TOPIC_REBALANCE), new ConsumerRebalanceListener() {
            // 撤销/回收已分配的Partition
            @Override
            public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
                System.err.println("Revoked Partitions:" + partitions);
            }

            // 重新分配Partition
            @Override
            public void onPartitionsAssigned(Collection<TopicPartition> partitions) {
                System.err.println("Assigned Partitions:" + partitions);
            }
        });
        ...
    }
}
```

##### Consumer 多线程消费

###### Consumer Group 多线程模型

![1634469825754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634469825754.png)

```java
// 一个Consumer一个线程，同属一个消费者组，消费不同的分区
public class ConsumerTest {
    public static void main(String[] args) {
        Properties properties = new Properties();
        ...
        // 通过消费者再均衡机制，保证5个分区被5个Consumer消费
        int coreSize = 5;
        ExecutorService executorService = Executors.newFixedThreadPool(coreSize);
        for(int i = 0; i < coreSize; i++){
            executorService.execute(new KafkaConsumerMt1(properties, Const.TOPIC_MT1));
        }
    }
}

// 一个Consumer一个线程，同属一个消费者组，消费不同的分区
public class KafkaConsumerMt1 implements Runnable{
    public KafkaConsumerMt1(Properties properties, String topic) {
        // 构建消费者
        this.consumerName = "KafkaConsumerMt1-" + counter.getAndIncrement();
        this.consumer = new KafkaConsumer<>(properties);

        /*查看同组消费者会再均衡情况*/
        this.consumer.subscribe(Arrays.asList(Const.TOPIC_MT1), new ConsumerRebalanceListener() {
            ...
        });
    }
    
    @Override
    public void run() {
        // 消费当前分区的消息
    }
}

```

###### Master-Worker 多线程模型

![1634470430311](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634470430311.png)

```java
private final KafkaConsumer<String, String> consumer;
private ExecutorService executors;
...

private int workerNum = ...;
executors = new ThreadPoolExecutor(
            workerNum, workerNum, 0L, TimeUnit.MILLISECONDS,
            new ArrayBlockingQueue<>(1000),
            new ThreadPoolExecutor.CallerRunsPolicy());
...

while (true) {
  // 单个Consumer拉取消息
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (final ConsumerRecord record : records) {
        // 多线程分发消息处理，可以包含调用Consumer进行手工提交
        executors.submit(new Worker(record));
    }
}

```

##### SpringBoot POM 依赖

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

```

##### SpringBoot 生产者配置

```properties
# Spring整合Kafka
spring.kafka.bootstrap-servers=192.168.1.111:9092
# Kafka Producer发送消息失败时的重试次数
spring.kafka.producer.retries=0
# 批量发送数据的配置
spring.kafka.producer.batch-size=16384
# 设置Kafka生产者内存缓冲区大小(32M)
spring.kafka.producer.buffer-memory=33554432
# Kafka消息序列化配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# Kafka可靠性投递配置: 是kafka生产端最重要的选项
# Acks = 0: 生产者在成功写入消息之前不会等待任何来自服务器的响应
# Acks = 1: 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应(推荐, 可以发挥Kafka真正的威力)
# Acks = -1: 表示分区leader必须等待消息被成功写入到所有的ISR副本(同步副本)中才认为producer请求成功. 这种方案提供最高的消息持久性保证, 但是理论上吞吐率也是最差的
spring.kafka.producer.acks=1

```

##### SpringBoot 生产者 | HelloWorld

```java
// SpringBoot生产者
@Component
@Slf4j
public class KafkaProducerServiceImpl implements KafkaProducerService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Override
    public void sendMessage(String topic, Object data) {
        ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, data);
        future.addCallback(new ListenableFutureCallback<SendResult<String, Object>>() {
            /**
             * 失败回调
             * @param throwable
             */
            @Override
            public void onFailure(Throwable throwable) {
                log.error("发送消息失败: " + throwable.getMessage());

            }

            /**
             * 成功回调
             * @param result
             */
            @Override
            public void onSuccess(SendResult<String, Object> result) {
                log.info("发送消息成功: " + result.toString());
            }
        });
    }
}

```

##### SpringBoot 消费者配置

```properties
# Spring整合Kafka
spring.kafka.bootstrap-servers=192.168.1.111:9092
# Consumer消息签收机制: 手工签收
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.listener.ack-mode=manual
# 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理:
# none: 抛出异常
# latest: (默认值)在偏移量无效的情况下, 消费者将从最新的记录开始读取数据(在消费者启动之后生成的记录)
# earliest: 在偏移量无效的情况下, 消费者将从起始位置读取分区的记录
spring.kafka.consumer.auto-offset-reset=earliest
# 序列化配置
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费并行数
spring.kafka.listener.concurrency=5

```

##### SpringBoot 消费者 | HelloWorld

```java
// SpringBoot消费者
@Component
@Slf4j
public class KafkaConsumer {
    @KafkaListener(groupId = "group02", topics = "topic02")
    public void onMessage(ConsumerRecord<String, Object> record, Acknowledgment acknowledgment, Consumer<?, ?> consumer){
        log.info("消费端接收消息: {}", record.value());
        acknowledgment.acknowledge();// 手工签收
    }
}

```

#### 高可用架构

1. Kafka 为分区引入了**多副本机制**，通过增加副本数量可以提升容灾能力，以及实现故障的自动转移，当集群中某个 Broker 失效时仍然能保证服务可用，副本处于不同的 Broker 中，当 Leader 副本出现故障时，Kafka 会从 Follower 副本中重新选举新的 Leader副本对外提供服务。
2. 同一分区的不同副本中保存的是相同的消息（不过同一时刻，副本之间可能并非完全一样），副本之间是**一主多从**的关系，Leader 副本负责处理读写请求，Follower 副本只负责与 Leader 副本的消息同步，很多时候Follower 副本中的消息相对 Leader 副本而言会有一定的滞后。
3. Kafka Consumer 也具备一定的容灾能力，Consumer 使用 Pull 模式从 Broker 拉取消息，并且保存消费的具体位置，当消费者宕机后恢复上线时，可以根据之前保存的消费位置，重新拉取需要的消息进行消费，不会造成消息丢失。

##### 分区多副本机制

1. Kafka 的复制单位是 Partition，每个 Topic 都有一个或多个 Partition，每个 Partition 都有一个 Leader 和零个或多个 Follower，这些 Leader 和 Follower 都可以称为 Replica 副本。
2. 在创建 Topic 时，可以指定分区数和复制因子，复制因子通常为 3，相当于一个 Leader 和两个 Follower。
3. 分区上的所有读取和写入都会转到 Leader Replica，Follower 会定期向 Leader 发送获取请求以获取最新消息，而 Consumer 不会从 Follower 那里消费，Follower 只是为了**冗余和故障转移**而存在。
4. 当 Broker 死亡时，对于那些失去 Leader 的 Partition，剩余节点上的 Follower 可以被提升为 Leader，但要看是否存在与 Leader 完成同步的 Follower，如果没有，还要看具体的配置策略，以决定是否允许故障转移到未完成同步的 Replica。

![1634973615452](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634973615452.png)

##### Leader 选举机制

- **概念**：每个 Kafka 节点集群都与 Zookeeper 集群一起部署，Zookeeper 是一种分布式共识服务，允许分布式系统围绕某个给定状态达成共识，由于本身是分布式的，并且选择了一致性而不是可用性（CP），所以需要过半的 Zookeeper 节点同意后，才能接受读取和写入。

- **Zookeeper 的作用**：Zookeeper 负责存储 Kafka 集群相关状态，总是会更新 Kafka 集群状态的任何变化，以便在故障转移的情况下，Follower 可以顺利过渡到 Leader。

  1. 记录Topic 列表、Partition、配置、Leader Replica、首选 Leader Replica。
  2. **记录集群成员**：每个 Broker 都会向 Zookeeper 集群发送心跳，当 Zookeeper 在一段时间后未能收到心跳时，Zookeeper 会认为 Broker 已失败或不可用。
  3. **记录控制器节点**：包括控制器死机时的故障转移节点。

- **控制器节点**：Electing the controller node，Controller 节点是 Kafka Broker 之一，负责在节点加入或离开集群时选举 Leader，在 Zookeeper 向 Controller 发送有关集群成员和主题更改的通知后， Controller 会对这些更改采取相关的行动，其关系如下：

  1. **创建 Partition**：比如，当创建具有 10 个 Partition 以及复制因子为 3 的新 Topic 时，Controller 会为每个 Partition 选出一个 Leader，尝试在 Broker 之间以最佳方式分配 Leader。
  2. **ISR 变化**：然后，Leader 负责维护 ISR 集合，使用 `replica.lag.time.max.ms` 来确定ISR 成员的资格，当 ISR 发生变化时，Leader 会更新其变化到 ZK，然后由 ZK 通知 Controller 节点。
  3. **Leader 宕机**：而当 Leader 宕机时，ZK 会向 Controller 发送选举新 Leader 的通知，Controller 会向所有 Broker 发送一个命令，通知 Leader 即将发生变化。
  4. 总之，Zookeeper 总是会更新状态的任何变化，以便在故障转移的情况下，**让新 Leader 可以顺利过渡**。

  ![1634979553992](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634979553992.png)

##### Leader Rebalance 方法

1. 虽然 Kafka 有首选副本 Leader（preferred replica leaders）的概念，当 Kafka 创建 Topic 的 Partition 时，会尝试将每个 Partition 的Leader Replica 均匀分布在节点上，并将这些第一个 Leader 标记为首选副本 Leader，但随着时间的推移，由于服务器重启、服务器故障和网络分区等原因，Leader Replica 可能最终都会落在同一个节点上。

2. 为了解决这个问题，Kafka 提供了两个选项：

   - 主题配置  `auto.leader.rebalance.enable=true` ：允许 Controller 节点将领导权重新分配回首选副本 Leader，从而恢复均匀分布。
   - 另外，管理员也可以使用 `kafka-preferred-replica-election.sh` 脚本手动恢复均匀分布。

   ![1634974526584](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634974526584.png)

##### ISR、OSR、AR 概念

- **目的**：Partition Replica 机制确实可以实现一定程度的可用性，但实际情况更加复杂，为了**平衡数据一致性与可用性**，Kafka 引入了 ISR 同步副本机制，允许在大多数副本失败时，仍然能够提供可用性，最大程度减少**死副本与慢副本**在延迟方面的影响。

  - 对比 RabbitMQ 镜像模式中，慢速镜像会引入更长的延迟，死镜像则会占用要检测的心跳时间。

- **概念**：

  - **ISR**：In Sync Replicas，分区中所有与 Leader 保持**一定程度同步**的副本集合，在 Kafka 中，消息会先发送到 Leader，然后 Follower 会以 `replica.fetch.wait.max.ms` 间隔发出 fetch 请求，默认为 500ms，从 Leader 中拉取消息进行同步，同步期间内 Follower 相对于 Leader 会存在**一定程度**的滞后，这种 “**一定程度**” 是指 Kafka **可以忍受**的滞后范围，可通过`replica.lag.time.max.ms` 进行配置。
    - **replica.lag.time.max.ms**：指 Follower 每次同步的最大延迟，默认为 10s，在使用 `acks=all` 时则代表每次客户端请求的最大延迟，如果 Follower 在该时间段内的某个时间点能够与 Leader 实现完全同步，则可以认为 Follower 是**一定程度同步**的，Leader 将允许该副本在 ISR 中。
      - 对比 RabbitMQ 的复制不是由镜像发起，而是由 Master 发起，再由 Master 把更改推送到其他镜像。
      - 如果发现死副本或者慢副本，则 Leader 会把它从 ISR 中剔除，而死副本与慢副本的判断与该值有关：
        - **死副本**：如果 Follower 在 `replica.lag.time.max.ms` 时间段内都没有发出 fetch 请求，则 Leader 会认为该 Follower 已经死了。
        - **慢副本**：如果 Follower fetch 时间超过了 `replica.lag.time.max.ms`，则 Leader 会认为该 Follower 是一个慢 Follower。
  - **OSR**：Out Sync Replicas，相对于 ISR 相反，与 Leader 同步滞后过度的副本组成 OSR 集合。
  - **AR**：Assigned Replicas，分区中所有的副本集合，即 AR = ISR + OSR，在正常情况下，所有 Follower 应该都与 Leader 保持**一定程度的同步**，即 AR = ISR，此时 OSR 为空。

  ![1635092377216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635092377216.png)

- **ISR与 OSR 的转换规则**：

  1. Leader 负责维护与跟踪 ISR 中所有 Follower 的滞后状态，当 Follower 落后太多或者失效时，Leader 会把它从 ISR 中剔除；而如果 OSR 中 Follower 追上了 Leader，则 Leader 会将它加入 ISR  集合。
  2. 只有在 ISR 中的副本才有资格被选举为 Leader，而在 OSR 中的副本则没有选举为 Leader 的资格，而这种规则可通过 `unclean.leader.election.enable` 进行配置。

- **局限**：当 ISR 缩小仅为 Leader Replica 时，如果 Leader 宕机，且没有任何同步副本时，则无法保证高可用。

  - **解决方案**：使用 `min.insync.replicas` 主题配置进行控制。

##### LEO、LW、HW、LSO 概念

- **概念**：ISR 与 HW、LEO 有紧密的关系，HW 可以辅助 Kafka 完成副本复制，而如果 LEO#Remote_LEO < Leader#LEO 的时间，不超过 `replica.lag.time.max.ms`，则可以认为该 Remote_LEO 对应的 Follower 处于**一定程度**上的同步，也就处于 ISR 集合中。

  - **LEO**：Log End Offset，日志结束偏移量，表示当前日志文件中下一条待写入消息的 offset。

    - 比如，LEO=15，表示当前日志记录的最后一条消息 offset=14，下一条写入的消息 offset=15。

  - **HW**：High Watermark，高水位标记，表示下一条能消费的 offset，Consumer 只能拉取到这个 offset 之前的消息。

    - 比如，HW=8，表示 Consumer 只能消费 offset < 8 的消息，而 offset=8 的消息对 Consumer 而言是不可见的。
    - 对于 ISR 而言，HW = MIN（LEO），即最小的 LEO 等于分区的 HW，小于等于 HW 的消息都可以被认为**已备份**。
    - **HW 作用**：用于标识哪些消息可以被消费，以及帮助 Kafka 完成副本同步。

    ![1634981204253](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1634981204253.png)

  - LW：Low Watermark，低水位标记，标识 AR 集合中最小的 logStartOffset。

    - 副本的拉取请求 FetchRequest，有可能触发新建日志分段以及旧分段的清理，进而导致logStartoffset 的增加，从而促使 LW 的增长。

  - LSO：Last Stable Offset，具体与 Kafka 事务有关，对于未完成的事务而言，LSO 等于事务中的第一条消息所在的位置；对于已经完成的事务而言，LSO 与 HW 相等，因此，LSO <= HW <= LEO。

- **复制流程**：

  1. **初始状态**：初始时，Leader#HW、Leader#LEO、Leader#Remote LEO、Follower#HW、Follower#LEO 都等于 0。

     ![1635137338175](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137338175.png)

  2. **Leader 消息持久化**：当 Leader 收到消息时，首先会在本地持久化，注意，这里的持久化，Kafka 只是将消息写入内存，而不是磁盘，此后，Leader#LEO=1。

     - 由于追求性能，Kafka 决定在消息进入内存后，就进行发送 ACK 确认给 Producer，然后每隔一段时间 `fsyncs` 内存中的消息到磁盘，通过**副本冗余**的机制，进行弥补消息未落盘的风险。
     - RabbitMQ 也会定期写入磁盘，但不同的是 RabbitMQ 只会在 Master 和所有镜像都将消息写入磁盘后，才发送 ACK 确认给 Producer。

     ![1635137428129](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137428129.png)

  3. **Follower 第一次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=0 给 Leader，Leader 接收到 Follower#LEO=0 后，则响应 offset=1 消息，以及 Leader#HW=0 给 Follower，此后，Follower#LEO=1，此时，Follower 和 Leader 的 LEO 都等于 1，但各自的 HW 还是为 0，需要在下一轮的拉取中才被更新。

     ![1635137604461](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137604461.png)

  4. **Follower 第二次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=1 给 Leader，Leader 接收到 Follower#LEO=1 后，更新 Leader#Remote LEO=1，然后如果判断到所有 Follower 都以该 offset 持久化完毕后，则会推进 Leader#HW，把 Leader#HW 更新为 1，响应下一条 offset 消息，以及 Leader#HW=1 给 Follower，以让它们更新 Follower#HW=1。

     ![1635137982950](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635137982950.png)

  | 更新对象          | 更新时机                                                     |
  | ----------------- | ------------------------------------------------------------ |
  | Leader#LEO        | Leader "持久化" Producer 消息后，会更新其本地的 LEO 值       |
  | Follower#LEO      | Follower 从 Leader 拉取消息并“持久化”后，会更新其本地的 LEO 值 |
  | Leader#Remote LEO | Follower 把自己本地的 Follower#LEO 传给 Leader，告知从哪个位移开始拉取，Leader 会使用这个值更新 Leader#Remote LEO |
  | Follower#HW       | Follower 更新完 Follower#LEO 后，会比较该值与收到的 Leader#HW，取两者中的最小值更新 Follower#HW |
  | Leader#HW         | Leader 更新完 Leader#LEO 或者 Leader#Remote LEO 后，会取 Leader#LEO 与 所有的 Leader#Remote LEO 中的最小值更新 Leader#HW |

- **数据丢失场景**：前提为 `min.insync.replicas=1`，即 ISR 集合只有一个副本也可以提供服务。

  1. **初始状态**：初始时，Leader#HW、Leader#LEO、Leader#Remote LEO、Follower#HW、Follower#LEO 都等于 1。
  2. **Leader 消息持久化**：某个时刻，有一个使用了默认 `acks=1` 设置的 Producer 向 A 发送了一条消息，A 持久化完毕后，会通知 Producer 消息已投递成功。
  3. **Follower 第一次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=1 给 Leader，Leader 接收到 Follower#LEO=1 后，则响应 offset=2 消息，以及 Leader#HW=1 给 Follower，此后，Follower#LEO=2。
     - 此时，Follower 和 Leader 的 LEO 都等于 2，但各自的 HW 还是为 1，需要在下一轮的拉取中才被更新。
  4. **Follower 第二次 Fetch**：Follower 定期发出一个 fetch 请求，发送 Follower#LEO=2 给 Leader，Leader 接收到 Follower#LEO=2 后，更新 Leader#Remote LEO=2，然后如果判断到所有 Follower 都以该 offset 持久化完毕后，则会推进 Leader#HW，把 Leader#HW 更新为 2，响应下一条 offset 消息，以及 Leader#HW=2 给 Follower，以让它们更新 Follower#HW=2。
  5. **Follower B 重启并截断**：然而，由于 Follower#HW 的更新时间与 Leader#HW 的更新时间有错配，在 Leader#HW 更新后，响应时 Follower#HW 才会更新，如果响应时 Follower B 发生重启，那么在 B 重启完成后，B 会根据当前的 HW=0 进行日志截断，把 LEO 调整为 0，导致之前更新 LEO=2 的消息在 B 上发生了丢失。
     - **日志阶段的原因**：确保副本之间没有分歧，在选举时截断到新 Leader 的 HW，保证每个 Follower 日志的一致性。
  6. **Leader A 重启并截断**：B 截断后 LEO=2 后，发生定期同步 Leader A 的日志，但此时 Leader A 也发生了重启，需要进行故障转移，如果 B 还在 A 的 ISR 集合中，则 A 会把故障转移到 B，B 就是成为了新的 Leader。当 A 重启恢复后，成为了 B 的 Follower，由于 Follower#HW 不能高于 Leader#HW，所以 A 会对 LEO=2 进行日志截断，导致 offset=2 的消息永久丢失。

  ![1635044350580](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635044350580.png)

- **数据不一致场景**：

  1. 假设有 A、B 两个Broker，初始时 A 是 Leader，B 是 Follower，首先 A 接收到消息 m2，但 B 还没来得及复制，B 就宕机了，然后 A#HW+1=1，A#LEO=1，B#LEO=0，B#HW=0。
  2. 过了一会，A 宕机了，B 却恢复了，B 成为了 Leader，然后又接收了消息 m3，由于 A 仍未恢复，所以 B#HW+1=1，B#LEO=1。
  3. 再过了一会，A 也恢复了，由于 A#HW=B#HW，所以，A 并不会进行日志截断，导致此时出现了消息不一致的情况。

- **Leader Epoch 机制**：出现上面数据丢失、数据不一致场景的根本原因是，Follower#HW 需要在第二轮 Fetch 响应时才被更新，如果在这期间出现 Follower 重启，会导致之前的 LEO 处的日志被截断，对此 Kafka 0.11 引入了 Leader Epoch 机制来取代 HW 的辅助复制工作， 修复这种在 Leader 连续变更场景下的数据丢失和数据不一致问题。

  - **概念**：大致可以认为是 Leader 的版本号，由两部分数据组成。

    - **Epoch**：一个单调增加的版本号，每当 Leader 发生变更时，都会增加该版本号，小版本号的 Leader 会被认为是过期的 Leader，不再行使 Leader 的权力。
    - **Start Offset**：起始位移，Leader 在该 Epoch 上，首条写入消息的 offset。

  - **原理**：

    1. 使用该机制后，每个消息都会包含一个 4 字节的 Epoch 数字，每个 log 目录会创建 **Leader Epoch Sequence File** 来存储 Epoch 和 Start Offset。
    2. 当一个副本**成为 Leader** 后，它会首先在 Leader Epoch Sequence File 末尾添加一个新的记录，并把该记录刷到磁盘中，以后在该 Leader 下每条新的记录就被 Epoch 标记。
    3. 而当一个副本**成为 Follower** 时（比如发生了重启），则会执行以下工作：
       1. 从 Leader Epoch Sequence File 中恢复所有的 Epoch，因为可能宕机太久，这期间换了好几次leader，所以才要把这些 Epoch 消息都恢复过来。
       2. 向 Leader 发送一个 LeaderEpochRequest，其中该请求包含了 Follower#Leader Epoch Sequence File 中最新的 Epoch。
    4. Leader 接收到 LeaderEpochRequest 后，会向 Follower 响应对应 LeaderEpoch 的 LastOffset，这个 **LastOffset** 有两种可能：
       1. 一种是，比 LeaderEpochRequest#Epoch 大 1 的 offset。
       2. 另一种是，如果 LeaderEpochRequest#Epoch 与 Leader#Epoch 相等，则返回 Leader#LEO。
    5. 如果有任何 Follower#StartOffset **大于**返回的 Leader#LastOffset，那么 Follower 会重置自己的 Leader Epoch Sequence File 来和 Leader 保持一致，然后**截断本地日志**到 Leader#LastOffset 位置，再开始从 Leader 获取数据。
    6. 而 Follower 在从 Leader 获取数据时，如果 Follower 发现 Leader#Epoch 比 Follower#Epoch **还大**，那么它会添加这个 Epoch 和 StartOffset 到 Leader Epoch Sequence File 文件，并刷写到磁盘，然后继续获取数据。

  - **解决数据丢失问题**：

    1. 假设有 A、B 两个Broker，初始时 B 为 Leader，首先，Follower A 从 Leader B 中取到消息 m2，此时 A#，但是 A#HW 只在下一轮 RPC 才会更新，所以此时 A#HW 没变。
    2. 这时候 A 重启并恢复，采用 Leader Epoch 机制，A 并不会根据 HW 进行截取自己的日志到 HW，而是向 Leader B 发送 **LeaderEpochRequest**，由于 B#Epoch 等于 LeaderEpochRequest#Epoch，所以 B 返回给 A 的是 B#LEO=2，同时也并不存在 A#StartOffset 大于返回的 B#LEO=2，所以 A 不会对日志进行截取。
    3. 接着，当 B 宕机时，A 成了新的 Leader，则A 会在 Leader Epoch Sequence File 文件中添加新的Epoch 和 StartOffset。
    4. 当 B 恢复时，B 也会采取 Leader Epoch 机制，向 Leader A 发送 **LeaderEpochRequest**，由于 A#Epoch 等于 LeaderEpochRequest#Epoch，所以 A 返回给 B 的是 A#LEO=2，同时也并不存在 B#StartOffset 大于返回的 A#LEO=2，所以 B 也不会对日志进行截取，因此，不会发生消息 m2 永久丢失的情况，即使用 Leader Epoch 机制解决了数据丢失的问题。

    ![1635155757877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635155757877.png)

  - **解决数据不一致问题**：（忽略 m1）

    1. 假设有 A、B 两个Broker，初始时 A 是 Leader，B 是 Follower，首先 A 接收到消息 m2，但 B 还没来得及复制，B 就宕机了，然后 A#HW+1=1，A#LEO=1，B#LEO=0，B#HW=0。
    2. 过了一会，A 宕机了，B 却恢复了，B 成为了 Leader，然后又接收了消息 m3，由于 A 仍未恢复，所以 B#HW+1=1，B#LEO=1，同时又因为采用了 Leader Epoch 机制，B#Epoch+1=1。
    3. 再过了一会，A 也恢复了，由于采用了 Leader Epoch 机制，A 并不根据 A#HW=B#HW 进行日志截断，而是向 B 发送 A#Epoch=0 < B#Epoch，B 返回 B#LEO=1 以及 m3。
    4. A 接收到 m3 后，发现自己的 A#LEO=2 > B#LEO=1 了，同时发现 B#Epoch=1 > A#Epoch，则重置自己的 Leader Epoch Sequence File 来和 B 保持一致，即Epoch=1 和 StartOffset=1，并刷写到磁盘，然后截断本地日志到 B#LEO=1 的位置，从而保证了消息的数据一致性，因此使用 Leader Epoch 机制解决了数据不一致的问题。

    ![1635156753134](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635156753134.png)

##### 节点新加入集群场景

|                  | Kafka                                      | RabbitMQ                        |
| ---------------- | ------------------------------------------ | ------------------------------- |
| 是否会拒绝写入   | 新节点异步获取日志消息，Master 无阻塞      | Master 拒绝任何客户端的读写操作 |
| 是否会读入旧消息 | 是，异步获取，直到追赶上 Leader 被加入 ISR | 会扔掉旧数据                    |
| 适用场景         | 大队列                                     | 小队列                          |

##### 网络分区场景

与 RabbitMQ 相比，Kafka 具有更多的组件，所以当 Kafka 集群出现网络分区时，会出现更复杂的场景，每一种场景都会 Kafka 都会表现出不同的行为：

###### 1. Follower 看不到 Leader，但能看到 ZK

- **分区现象**：

  1. 网络分区把 Broker 3 与 Broker 1、2 分开，但没有和 ZK 分开。
  2. 此时，Broker 3 不再能够发送 fetch 请求，且在由于 `replica.lag.time.max.ms` 被剔出 ISR 集合，将不能参与消息提交。
  3. 而 ZK 在整个过程中，可以继续接收 Leader 的心跳，始终被认为处于活动的状态且运行良好。

- **分区解决后**：一旦分区被解决，Broker 3 将恢复 fetch 请求，在赶上 Leader 一定程度后，会重新加入 ISR 集合。

- **优点**：对比 RabbitMQ，Kafka 分区并不会出现脑裂或暂停节点的现象。

- **缺点**：减少了某个副本的冗余。 

  ![1635238242566](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238242566.png)

###### 2. Leader 看不到 Followers，但能看到 ZK

- **分区现象**：

  1. 网络分区把 Leader 与其他所有 Follower 分开，但仍然可以看到 ZK。
  2. 类似于场景 1 一样，由于 Leader 维护着 ISR 集合，看不到任何 Follower 会导致 ISR 缩小到只有 Leader。
  3. 而 ZK 在整个过程中，可以继续接收 Leader 的心跳，始终被认为处于活动状态且运行良好。

- **分区解决后**：一旦分区被解决，所有 Follower 将恢复与 Leader 的同步，它们在赶上 Leader 一定程度后，会重新加入 ISR 集合。

- **优点**：同样没有裂脑或者暂停节点的发生。

  **缺点**：在分区解决之前，新写入的消息将会丢失所有的副本冗余，当 Leader 宕机，Kafka 将会**停止服务**。

  ![1635238385327](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238385327.png)

###### 3. Follower 能看到 Leader，但看不到 ZK

- **分区现象**：
  1. Follower 与 ZK 分开，但没有和 Leader 分开。
  2. 此时，Follower 可以继续发出 fetch 请求，并维持 ISR 成员的状态。
  3. 而 ZK 将不再接收 Follower 的心跳，会认为它已经死了，但由于它只是一个 Follower，因此不会受到任何影响。
- **分区解决后**：一旦分区被解决，该 Follower 将重新向 ZK 发送心跳包，ZK 则认为它重新上线。
- **优点**：同样没有裂脑或者暂停节点的发生，且没有副本冗余的丢失。

![1635238848539](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635238848539.png)

###### 4. Leader 能看到 Followers，但看不到 Zk

- **分区现象**：
  1. Leader 与 ZK 分开，但没有与 Followers 分开。
  2. 一段时间后，ZK 会该 Leader 标记为已死，并且通知 Controller 选举一个 Follower 成为新 Leader。
  3. 然而，旧 Leader 还继续认为它是 Leader，能够在短时间内继续接受 `ack=1` 的写入，而 Follower 则不再向该旧 Leader 发送 fetch 请求，旧 Leader 会认为 Followers 都发生死亡，并尝试把 ISR 缩小到旧 Leader 自身，但它又无法这么做，因为 ISR 的任何变化都会先给 ZK，而它没有与 ZK 相连，将停止接受写入。
  4. 而 `acks=all` 的消息 Producer 将不会得到 ACK 确认，因为旧 ISR 包括所有副本，Followers 不会返回消息确认给旧 Leader，旧 Leader 也就不会返回 ACK 给 Producer，而且 旧 Leader 在尝试把 Followers 都从 ISR 中删除时，由于没有与 ZK 相连，将导致它删除失败，因此会一直拒绝写入。
  5. 而客户端每 60 秒会更新一次最新的元数据，然后他们将被告知 Leader 发生变更，并开始发送消息给新 Leader。
- **分区解决后**：一旦网络分区得到解决，旧 Leader 将知道它自己不再是 Leader，然后会把自己的日志截断到新 Leader#HW 处，然后开始向新 Leader 发送 fetch 请求。
- **优点**：同样没有裂脑或者暂停节点的发生，且没有副本冗余的丢失。
- **缺点**：自网络分区开始以来，对旧 Leader 所做的 `ack=1` 确认写入都将丢失。
  1. 集群会在短时间内处于裂脑的状态，但前提是 `acks=1` 并且 `min.insync.replicas=1` ，当网络分区被解决时，裂脑会自动结束，旧 Leader 将会意识到它不再是 Leader，或者所有客户端都意识到 Leader 已经改变，并开始发送消息给新 Leader，但无论哪种方式，都会在短时间内发生一些消息丢失，但仅限于 `acks=1` 。
  2. 这种情况还有一个变体，就在网络分区之前，Follower 落后，Leader 将 ISR 缩小到自己，然后发生网络分区隔离了 Leader，同时还选举了一个新 Leader，但旧 Leader 仍继续接受写入，甚至 `acks=all` 也因为 ISR 只有旧 Leader 自己，当网络分区解决后，这些写入将发生丢失。
  3. 因此，为了避免这些情况，唯一的解决方案是使用 `min.insync.replicas = 半数节点`。

![1635239217734](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635239217734.png)

###### 5. Follower 完全分区

- **分区现象**： 
  1. Follower 与 Leader 和 ZK 完全隔离。
  2. Follower 只会被简单地从 ISR 中剔除。
- **分区解决后**：一旦网络分区得到解决，它将恢复 fetch 请求，在赶上 Leader 一定程度后，会重新加入 ISR 集合。
- **优点**：同样没有裂脑或者暂停节点的发生。
- **缺点**：减少了某个副本的冗余。

![1635240105377](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635240105377.png)

###### 6. Leader 完全分区

- **分区现象**：
  1. Leader 与 Followers、Controller 和 ZK 完全隔离。
  2. Leader 能够在短时间内继续接受 `ack=1` 的写入，但将不能接受 Followers#fetch 请求，此时会认为 Followers 都发生死亡，并尝试把 ISR 缩小到自身，但它又无法这么做，因为 ISR 的任何变化都会先给 ZK，而它没有与 ZK 相连，将停止接受写入。
  3. 而 `acks=all` 的消息 Producer 将不会得到 ACK 确认，因为旧 ISR 包括所有副本，Followers 不会返回消息确认给旧 Leader，旧 Leader 也就不会返回 ACK 给 Producer，而且 旧 Leader 在尝试把 Followers 都从 ISR 中删除时，由于没有与 ZK 相连，将导致它删除失败，因此会一直拒绝写入。
  4. 同时，一段时间后，ZK 会该 Leader 标记为已死，并且通知 Controller 选举一个 Follower 成为新 Leader。
  5. 而客户端每 60 秒会更新一次最新的元数据，然后他们将被告知 Leader 发生变更，并开始发送消息给新 Leader。
- **分区解决后**：一旦网络分区被解决，旧 Leader 将通过 ZK 发现它不再是 Leader，然后它将把日志截断到新 Leader#HW，并作为 Follower 开始发送 fetch 请求。
- **缺点**：自网络分区开始以来，对旧 Leader 所做的 `ack=1` 确认写入都将丢失。
  1. 集群会在短时间内处于裂脑的状态，但前提是 `acks=1` 并且 `min.insync.replicas=1` ，当网络分区被解决时，裂脑会自动结束，旧 Leader 将会意识到它不再是 Leader，或者所有客户端都意识到 Leader 已经改变，并开始发送消息给新 Leader，但无论哪种方式，都会在短时间内发生一些消息丢失，但仅限于 `acks=1` 。
  2. 这种情况还有一个变体，就在网络分区之前，Follower 落后，Leader 将 ISR 缩小到自己，然后发生网络分区隔离了 Leader，同时还选举了一个新 Leader，但旧 Leader 仍继续接受写入，甚至 `acks=all` 也因为 ISR 只有旧 Leader 自己，当网络分区解决后，这些写入将发生丢失。
  3. 因此，为了避免这些情况，唯一的解决方案是使用 `min.insync.replicas = 半数节点`。

![1635240417911](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635240417911.png)

###### 7. Controller 看不到 Broker

- **分区现象**：
  1. Controller 与 Broker 节点隔离，会导致 Controller 将无法向该 Broker 节点传达任何领导权的变更。
  2. 在最坏的情况下，可能会发生像场景 6 那样短期的裂脑，即 Controller 无法告诉旧 Leader 它已经不是 Leader了，从而使得它与新 Leader 共存，且在短时间内，旧 Leader 仍能接受 `ack=1` 的消息写入。
- **分区解决后**：一旦分区被解决，Controller 将恢复与该 Broker 的通信，该 Broker 也会意识到它不再是 Leader，然后它将把日志截断到新 Leader#HW，并作为 Follower 开始发送 fetch 请求。

###### 8. Controller 看不到 ZK

- **分区现象**：
  1. Controller 与 ZK 隔离。
  2. 由于 Controller 缺少心跳，ZK 会将 broker 标记为已死，并且选举一个新的 Broker 节点作为 Controller。
  3. 旧 Controller 可能会继续认为它自己是 Controller，但由于它无法接收来自 ZK 的任何通知，因此并不会执行任何操作。
- **分区解决后**：一旦分区被解决，它将会意识到它不再是 Controller，而只是一个普通的 Kafka 节点，因此不会造成什么影响。

###### 网络分区场景总结

1. 可以看到，Follower 发生网络分区，不会导致消息丢失，只是减少了 Follow 的副本冗余。
2. Leader 与 Follower 隔离，会丢失所有的副本冗余，当 Leader 还发生宕机，有较小概率发生不可用。
3. Leader 与 ZK 隔离，会发生短暂的脑裂，导致自网络分区开始以来，对旧 Leader 写入 `ack=1` 的消息都会丢失，解决方案为 `ack=all` ，而使用 `min.insync.replicas=半数节点` 可以提供额外的一致性保证，保证脑裂期间不会发生消息丢失，但会失去部分的可用性。
4. Controller 与 Broker 隔离，会导致 Broker 感知不到 Leader 的变化，当隔离的 Broker 刚好为 Leader 时，还可能会发生同 3 一样的短暂脑裂现象，而 Controller 与 ZK 隔离，则不会造成任何影响。

#### 常见问题解决

##### 如何保证数据不丢失？

参考《RabbitMQ - 如何保证数据不丢失》，数据丢失的场景有：生产端丢数据、MQ 丢数据、消费端丢数据：

- **解决方案**：
  1. **生产端丢数据**：生产消息可以通过 Comfirm 机制解决，消息状态打标 + 消息落库 + `ack=all` + 定时重发（`retries` + `retry.backoff.msretries`） + 人工介入/失败补偿 。
  2. **MQ 丢数据**：Broker 使用 ISR 副本机制保证高可用。
  3. **消费端丢数据**：可以关闭自动提交offset功能 `enable.auto.commit=false`，在消费完成后才提交offset。

##### 如何防止重复消费？

参考《RabbitMQ - 如何防止重复消费》。

##### 一致性与可用性保障？

详情见《Kafka - 高可用架构》

`acks=all` 是最安全的选项，但会引入额外的延迟。事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的**最终一致性**以及时刻都接受读取和写入的**高可用性**，因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个**范围的两端**。对此，Kafka 提供了调整参数，以让一致性和可用性适合需要的场景。

###### 集群可调整参数

1. **消息 Confirm 机制**：Producer `ack=all`，以及 Consumer `enable.auto.commit=false`。
2. **分区多副本机制**：在创建 Topic 时，可以指定分区数和复制因子，复制因子通常为 3，相当于一个 Leader 和两个 Follower。
   - 其中，复制因子为 5 且 `min.insync.replicas` 为 3 发生消息丢失，是一件非常罕见的事件。
3. **故障转移策略**：`unclean.leader.election.enable`：
   - **true**：允许故障转移到未完成同步的 Follower。
   - **false**：默认为false，禁止故障转移到未完成同步的 Follower，只允许转移到已经完成同步的 Follower，如果没有任何同步副本，则故障转移时会拒绝客户端所有的读取和写入操作。
4. **ISR 同步策略**：主题配置 `min.insync.replicas`，ISR 集合中最少的副本数量，如果客户端写入消息时，ISR 中的副本数量低于该数量，那么 Broker 以 NotEnoughReplicas 的错误响应给客户端，以拒绝写入。
5. **脑裂处理策略**：`ack=all` + `min.insync.replicas=半数节点` 可以提供最高级别的一致性。
6. **确保客户端连接**：在 Producer 和 Consumer `bootstrap.servers` 配置中，指定多个可以连接的 Broker，这样，即使其中一个 Broker 节点出现故障，客户端也有它知道的多个 Broker 节点，用于打开与 Broker 的连接，此时客户端可以询问出哪个节点，才是托管其想要读/写的分区 Leader。

###### 对比 RabbitMQ

|                      | Kafka                                                        | RabbitMQ                                                     |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 实现持久性与高可用性 | 主从复制                                                     | 主从复制                                                     |
| 持久性与可用性问题   | 异步非阻塞复制，不存在持久性与可用性问题，但复制需要占用大量的网络带宽 | 大队列持久性问题，要么减少冗余增加数据丢失风险，要么接受长时间不可用，可保持小队列，舍弃部分可用性，通过连接重试来处理，以保证冗余，减少数据丢失风险 |
| 集群同步发生故障     | 消息不落盘，效率高，但可能会消息丢失，通过副本冗余机制来减少风险 | 消息落盘，能够发挥出持久化优势，但增加了额外的延迟           |
| 总结                 | 处理大量消息、易扩展、一致性可调                             | 无大队列（大队列可拆成多个小队列）、用法灵活                 |

##### 如何实现 Consumer Rebalance？

Consumer Rebalance，本质上是一种协议，规定了一个 Consumer Group 下，所有 Consumer 如何达成一致，来分配订阅 Topic 下的每个 Partition。

###### 触发条件

Consumer Rebalance 的触发条件有3个：

- **组成员数量发生变化**：比如有新的 Consumer 加入或者离开 Consumer Group。
- **订阅的 Topic 数量发生变化**。
- **订阅 Topic 下的 Partition 数量发生变化**。

###### 对集群的影响

Consumer Rebalance 发生时，Consumer Group 下所有的 Consumer 都会协调在一起，共同参与，以让 Kafka 能够尽量达到最公平的分配，但是，这些 Consumer 都会停止工作，来等待 Consumer Rebalance 过程的完成，如果集群内节点较多，比如上百个，那该过程可能会非常耗时，导致数分钟到数小时，使得 kafka 基本处于不可用的状态，对 TPS 影响极大。

- 经过几轮本地测试，可以发现，每次 Consumer Rebalance 所消耗的时间，大概在 **80ms~100ms** 内，平均耗时在 **87ms** 左右。

###### Group Coordinator

1. Consumer Group Coordinator 是一个服务，每个 Broker 启动时都会启动一个该服务，用于存储 Consumer Group 相关的 Meta 信息，并将对应的 Partition#Offset 信息，记录到内置的 `Topic(__consumer_offsets) ` 中。

2. 而在 0.9 版本之前，Partition#Offset 是基于 ZK# `(consumers/{group}/offsets/{topic}/{partition})` 进行存储的，但由于 ZK 并不适合频繁的写操作，所以，在 0.9 版本之后，通过内置 Topic 的方式，来记录对应 Partition#Offset。

3. 每个 Consumer Group 都会选择一个 Coordinator，来完成组内各 Partition#Offset 信息，选择方式如下：

   1. 计算 Consumer Group 对应在 `Topic(__consumer_offsets)#Partition`。

      ```java
      // Topic(__consumer_offsets)#Partitio计算规则：hash(消费者组的ID) mod 50
      // groupMetadataTopicPartitionCount对应offsets.topic.num.partitions参数值，默认值是50个分区
      partition-Id(__consumer_offsets) = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)
      ```

   2. 根据该 Partition 寻找对应的 Leader Replica#Group Coordinator，作为该 Consumer Group#Coordinator。

###### 执行过程

Rebalance 过程分为两步：**Join 和 Sync**。

1. **Join**：

   1. 加入组，所有 Consumer 会向 Coordinator 发送 `JoinGroup` 请求，请求加入 Consumer Group。
   2. 一旦所有成员都发送了 `JoinGroup` 请求，Coordinator 会从中选择一个 Consumer 来担任 Leader 的角色，并把组成员信息以及订阅信息发给 Leader，由 Leader 来负责制定消费分配方案。
      - 注意，这里的 Leader 和 Coordinator 不是同一个概念，Leader 属于 Consumer，Coordinator 属于 Broker 中的一个服务。

   ![1635483089251](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483089251.png)

2. **Sync**：

   1. Leader 开始分配消费方案，即哪个 Consumer 负责消费哪些 Topic#Partition。
   2. 一旦完成分配，Leader 会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
      - Consumer 的分区分配策略，见《日志分区原理 - 分区分配原理》。
   3. 而非 Leader 也会发 `SyncGroup` 请求，只是内容为空。
   4. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给各个Consumer。
   5. 这样，Consumer Group 内的所有 Consumer 成员，就都知道自己应该消费哪些 Partition 了。

   ![1635483199299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483199299.png)

###### 场景分析

- **新成员加入组**：

  1. 成员 M1 原本就处于 Consumer Group#generation2，成员 M2 新加入 Consumer Group 中。
  2. Coordinator 收到 M2 的 `JoinGroup` 请求后，然后会告诉 M1 重新加入 Consumer Group#generation2 处于 Rebalance 中，需要重新加入。
  3. M1 向 Coordinator 发送 `JoinGroup` 请求。
  4. Coordinator 收到完 Consumer M1 和 M2 的 `JoinGroup` 请求后，则选择 M2 来担任 Leader 角色，并把组成员信息以及订阅信息发给 M2，由 M2 来负责制定消费分配方案，同时其他响应 `JoinGroup` 请求，告诉他们当前处于 Consumer Group#generation3 中的 Follower 角色。
  5. M2 制定方案完毕后，则会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
  6. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给 M1 和 M2，完成一次 Consumer Rebalance 操作。

  ![1635483703977](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635483703977.png)

- **组成员主动离开**：

  1. 成员 M1 和 M2 原本就处于 Consumer Group#generation2，成员 M1 请求主动离开。
  2. Coordinator 收到 M1 的 `LeaveGroup` 请求后，则会通过 `HeaderBeat` 响应 M1 同意结果，然后要求 M2 重新加入 Consumer Group。
  3. M2 向 Coordinator 发送 `JoinGroup` 请求。
  4. Coordinator 收到完 Consumer M2 的 `JoinGroup` 请求后，则选择 M2 来担任 Leader 角色，并把组成员信息以及订阅信息发给 M2，由 M2 来负责制定消费分配方案，同时其他响应 `JoinGroup` 请求，告诉他们当前处于 Consumer Group#generation3 中的 Follower 角色。
  5. M2 制定方案完毕后，则会将这个方案封装进 `SyncGroup` 请求中，然后发给 Coordinator。
  6. Coordinator 接收到分配方案后，会把方案塞进 `SyncGroup` 的 response 中，响应给 M2，完成一次 Consumer Rebalance 操作。

  ![1635484277208](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635484277208.png)

- **组成员崩溃**：

  1. 与组成员主动离开类似，但不同的是，在崩溃时，组成员并不会主动地告知Coordinator 离开组这件事。
  2. 而是 Coordinator 在一个完整的 `session.timeout.ms` 心跳周期后，才检测出组成员的这种崩溃，势必会造成消费滞后，因为期间 M1 停止了消费，而且 Rebalance 所有 Consumer 都会停止消费。
  3. 因此，可以说，主动离开组是主动发起 Consumer Rebalance，而组员崩溃则是被动发起 Consumer Rebalance。

  ![1635484185247](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635484185247.png)

###### 如何避免不必要的 Consumer Rebalance？

- **思路**：

  1. 要避免 Consumer Rebalance，还是要从触发条件入手：
     - **组成员数量发生变化**：比如有新的 Consumer 加入或者离开 Consumer Group。
     - **订阅的 Topic 数量发生变化**。
     - **订阅 Topic 下的 Partition 数量发生变化**。
  2. 对于后两个触发条件，可以人为地去避免，比如控制好 Topic 和 Partition 的数量。
  3. 所以，最常见的原因还是 Consumer Group 中的组成员发生了变化。
     1. Consumer 正常的添加、删除导致的 Rebalance，是无法避免的。
     2. 但是，在某些情况下是可以尽力避免的，比如，Consumer 可能会被 Coordinator 错误地认为已死亡，从而被错误地踢出 Group，导致多余的 Rebalance 发生。

- **调整参数**：

  - `session.timeout.ms`：Coordinator 判定 Consumer 已死亡的超时时间，可在 Consumer 端进行参数配置，默认为 10s。
    1. 当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会以 `heartbeat.interval.ms` 周期地向 Coordinator 发送心跳请求，表明它还存活着。
    2. 但如果某个 Consumer 实例在超过该超时时间，仍未能及时地发送这些心跳请求，那么 Coordinator 就会认为该 Consumer 已经死亡，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。
  - `heartbeat.interval.ms`：Consumer 心跳报发送周期，用于控制发送心跳请求频率，可在 Consumer 端进行参数配置。
    1. 这个值设置得越小，Consumer 发送心跳请求的频率就越高。
    2. 频率高的好处就是，能够更加 Consumer 快速地知晓当前是否开启 Rebalance，因为目前 Coordinator 通知各个 Consumer 开启 Rebalance 的方法，就是将 `REBALANCE_NEEDED` 标志封装进Heartbeat 心跳包的响应体中。
    3. 而坏处就是，会额外消耗带宽资源。
  - `max.poll.interval.ms`：Consumer#pull 方法之间的最大时间间隔，可在 Consumer 端进行参数配置，默认值为 5min，用于控制 Consumer 的实际消费能力。
    1. 如果 Consumer 在该时间间隔内，无法消费完上一次 pull 方法返回的消息，那么该 Consumer 会主动发起离开组的请求，然后 Coordinator 就会开启新一轮的 Rebalance。

- **优化结论**：

  1. **增大超时时间，减少心跳周期**：以减少 Consumer 未能及时发送，Coordinator 未能及时收到心跳，从而 导致 Consumer 被踢出 Group 的非必要 Rebalance 情况发生。

     ```shell
     # 加大超时时间，设置成6s主要是为了，让Coordinator能够更快地定位已经挂掉的Consumer，早日把它们踢出Group
     session.timout.ms=6s
     # 减少心跳周期，加大心跳频率，在Consumer实例在被判定为死亡之前，保证能够发送至少3轮的心跳请求，即session.timeout.ms >= 3*heartbeat.interval.ms
     heartbeat.interval.ms=2s
     
     ```

  2. 增大可消费的时间：以减少某些 Consumer 消费时间过长，超出两次 pull 消息间隔，从而导致 Coordinator 进行非必要的 Rebalance 的情况发生。

     ```shell
     # 增长可消费的时间，总之，要为业务处理逻辑留下充足的时间，这样Consumer就不会因为处理这些消息的时间太长而引发非必要的Rebalance
     max.poll.interval.ms=某个合理值
     
     ```

##### 如何保证顺序消费？

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个分区**，目的是防止消费者争抢消息导致乱序消费的情况发生。

  1. 与 RabbitMQ 保证单消费者消费单个队列不同，由于 Kafka#Consumer Group 机制，天然就能保证单个消费者消费，然后 Kafka 针对的不是队列，而是一个 Partition。

- **解决方案**：参考《RabbitMQ - 如何保证顺序消费》。

  - **多分区、多消费者**：类似于 RabbitMQ#一致性哈希交换机 `x-consistent-hash Exchange`，通过业务ID进行 hash，保证同一个业务 ID 的消息只落在同一个 Partition 中，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
    - **实现方法**：自定义 Producer 分区器与分区规则。

  - **单分区、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单分区、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单分区、单消费者**：始终保证使用 一个 Partition + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

    - **实现方法**：

      ```shell
      # topic_x 只创建一个分区，一个副本
      kafka-topics.sh --zookeeper localhost:2181/myKafka --create --topic topic_x 
                                      --partitions 1 --replication-factor 1
      
      ```

##### 如何优化消息积压？

###### 影响后果

1. 消息积压越多，Consumer 寻址的性能就越慢，最差的情况则会导致整个 kafka 对外提供服务的性能很差，从而影响其他服务的访问速度，最后造成雪崩效应。
2. 而且还可能发生磁盘被堆满，导致 Producer 消息无法写入磁盘，一直报错，然后引发连锁反应，同样会造成雪崩效应。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Partition、增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **Consumer 批量拉取消息与批量提交 offset**：这里要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   1. 对于每条消息分别拉取的情况，Consumer 需要多次从 Broker 上拉取消息，而对于每条消息分别被提交的情况，Consumer 需要多次发起提交 offset 传输给 Broker，这样的多次 I/O，浪费了服务器性能与增加了带宽的占用。
   2. 通过批量拉取消息+批量提交 offset 的方式，减少多次发起 Broker 请求，可以减少很多 I/O 浪费和带宽占用。
   3. 不过，如果 Consumer 在处理某条消息时失败了，而业务上又要求不能丢失任何消息，此时就不能对所有的消息进行批量提交，因为消费失败的需要重新消费。
      - **解决方案**：可以跟踪所有消息的处理结果，如果全部成功，则使用批量提交 offset；如果部分成功，则有两个选择：1）如果不需要顺序消费，则可以退化为每个消息分多次发送提交 offset；2）如果需要顺序消费，则本次消费失败之后的消息全部重新消费，保证重新消费时消息顺序保持一致。
   4. **小结**：Consumer 批量提交的前提是，设置了批量拉取消息，否则将会失去意义。

   ```java
   // Consumer参数：批量拉取消息
   // 一次拉取的最小数据量，默认为 1 B
   // fetch.min.bytes
   // 一次拉取的最大数据量，默认为 50 MB
   // fetch.max.bytes
   // 一次拉取一个 Partition 的最大数据量，默认为 1 MB
   // max.partition.fetch.bytes
   // 每次拉取的消息最大条数
   // max.poll.records
   
   /* Consumer开启手工提交*/
   properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
   /*1) 整体提交: 同步提交(线程阻塞)*/
   // consumer.commitSync();
   /*2) 或者整体提交: 异步提交(线程非阻塞), 可回调可不回调, 这里会轮训回调函数*/
   consumer.commitAsync(new OffsetCommitCallback() {...}
   ```

2. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手，代码实现见《Kafka API - Consumer 多线程消费》。

   1. 多线程并发消费，不需要建立多个 Kafka 客户端连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

3. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个分区，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 先单个 Consumer 消费，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  2. 如果消费速度不满足要求，则提高 `max.poll.records`，**1 次接收多条消息**，甚至批量提交 offset，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，甚至批量提交 offset，但要注意并发冲突和顺序消费的问题。
  4. 如果消费速度还是不满足要求，则**多个消费者并发消费**，甚至批量提交 offset，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步，以及批量 ACK 遇到消费失败时进行全部 NACK。

###### 【线上】如何紧急处理消息积压？

参考《RabbitMQ - 【线上】如何紧急处理消息积压》。

对于 Kafka 而言，由于 Partition 机制与 RabbitMQ Queue 并不相同，所以除了参考，还有以下的处理方式：

1. **提高 Partition 分区数**：分区数足够，可以提高消费的并行度，并且也决定者同组 Consumer 的最大数量。
2. **临时 Topic + Consumer 进行消息转储消费**：
   1. 如果消息积压的 Topic 在建立时，就没有建立足够多的 Partition，导致同一个 Consumer Group 中的 Consumer#size 已经增加到 Partition#size，却仍有大量的消息积压。
   2. 此时，可以建立一个临时的 Topic、设置足够多的 Partition 以及上线一批足够多的 Consumer ，然后把所有原 Topic 的 Consumer 拉取到的消息统统转储到临时 Topic 上，供新上线那批 Consumer 去消费。
   3. 这样，消费速度上去了，消息积压的问题才有机会解决掉，解决掉后再视实际情况，来决定是否恢复原状。

### 2.0. 什么是系统可用性？

- **概念**：系统可用性，Availability，是信息工业界用来衡量一个信息系统提供**持续服务**的能力，表示在给定时间区间内，系统或者系统某一能力，在特定环境下能够正常工作的**概率**。
- **公式**：系统可用性 = （平均故障间隔时间 MTBF）/ （平均故障间隔时间 MTBF  + 平均故障修复时间 MTTR）
- **应用**：通常，业界习惯用 N 个 9 来表征系统可用性，表示系统可以**正常使用时间与 1 年总时间之比**，比如：
  1. **99.9%**：代表 3 个 9 的可用性，意味着全年不可用时间在 `8.76h` 以内，表示该系统在连续运行 1 年时间里，最多可能的业务中断时间是 `8.76h` 。
  2. **99.99%**：代表 4 个 9 的可用性，意味着全年不可用时间在 `52.6min` 以内，表示该系统在连续运行 1 年时间里，最多可能的业务中断时间是 `52.6min` 。
  3. **99.999%**：代表 5 个 9 的可用性，意味着全年不可用时间在 `5.26min` 以内，缺少故障**自动恢复机制**的系统是很难达到 5 个 9 高可用性的。
  4. 而对于 1、2、6 个 9，它们的不可用时长分别为 36.5D、3.65D、31s，均不符合实际情况（时间太久或者实现成本太高），所以用于表征系统可用性并不合适。

### 2.1. 详细介绍RocketMQ？

#### 概念

RocketMQ 是一款分布式、队列模型的消息中间件，由阿里巴巴自主研发的一款适用于高并发、高可靠性、海量数据场景的消息中间件，其消息路由、存储、集群规划上都参考借鉴了 Kafka 的设计思路，并结合双十一场景进行合理的扩展和丰富了API。

- **通用用途**：异步处理、系统解耦、削峰填谷、蓄流压测。
- **特色用途**：
  1. **支持事务消息**：消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 都不支持。
  2. **支持延迟消息**：RabbitMQ 支持，Kafka 不支持。
  3. **支持 Consumer#tag 过滤**：以减少不必要的网络传输，RabbitMQ 和 Kafka 都不支持。
  4. **支持重复消费**：RabbitMQ 不支持，Kafka 支持。

| 专业术语       | 释义                                                         |
| -------------- | ------------------------------------------------------------ |
| Broker         | 消息核心服务，作为中转角色，用于消息存储与生产消费的转发，通过 Name Server 暴露统一的集群入口给客户端 |
| Name Server    | Name Server 充当路由信息提供者，供生产者与消费者客户端查找 topic，以找到相应的 Broker 列表 |
| Producer       | 消息生产者，负责生产消息，一般由业务系统负责产生消息，完全无状态，可集群部署 |
| Producer Group | 生产者集合，一般用于发送一类消息，防止原始生产者在事务后崩溃 |
| Consumer       | 消息消费者，负责消费消息，一般是后台系统负责异步消费         |
| Consumer Group | 消费者集合，一般用于接受一类消息进行消费，实现消费的负载平衡与容错，消费者组中的消费者必须具有完全相同的 topic 订阅 |
| Push Consumer  | Consumer 的一种，需要向 Broker 注册监听，被动接受推送过来的消息 |
| Pull Consumer  | Consumer 的一种，需要主动请求 Broker 拉取消息                |
| Topic          | 主题，是生产者传递消息和消费者拉取消息的类别，一个主题可能有零个、一个或多个生产者向它发送消息，生产者也可以发送不同主题的消息；一个主题可能被零个、一个或多个消费者组订阅，消费者组也可以订阅一个或多个主题，只要该组的实例保持订阅一致即可 |
| Message        | 消息，是要传递的信息，一条消息必须有一个主题，一条消息也可能有一个可选的标签和额外的键值对 |
| Message Queue  | 消息队列，是逻辑上存储消息的队列，物理上存储消息的是 CommitLog，其中 topic 被划分为一个或多个 tag，每个 tag 对应着一个消息队列 |
| Tag            | 标签，也可以说是子主题，为用户提供了额外的灵活性，使用标签有助于保持代码的整洁和连贯，也方便消息的查询 |

#### 原理

##### 技术架构原理

![1635853277989](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635853277989.png)

###### NameServer 集群

1. 轻量级的配置中心，是一个几乎无状态的节点，只做集群元数据存储和心跳工作。
2. 可集群部署，节点之间没有任何信息同步，不需要保证节点间数据的强一致性。

###### Broker

1. 消息核心服务，作为中转角色，用于消息存储与生产消费的转发，通过 NameServer 暴露统一的集群入口给客户端。
2. Broker 分为 Master 和 Slave，一个Master 可以对应多个 Slave，一个 Slave 只对应一个 Master，可通过指定相同的 BrokerName + 不同的BrokerId 来定义主从关系，即 BrokerId 为 0 的表示 Master 节点，非 0 的表示 Slave 节点。而 Master 也可以多节点部署，从而构成多主多从的集群架构。
3. 每个 Broker 与 Name Server **所有节点**建立长连接，隔 30s 定期地注册 Topic 信息到所有Name Server 节点，Name Server 也会每隔 10s 定时地扫描所有存活的 Broker 连接，如果 Name Server 超过 2min 没有收到 Broker 心跳，则会与 Broker 断开连接。

###### Producer 集群

- Producer，消息生产者，负责生产消息，一般由业务系统负责产生消息，完全无状态，可集群部署。
- Producer 会在 Name Server 集群中**随机选择一个节点**建立长连接，并与提供 Topic 服务的 Master Broker 节点建立长连接。
  1. **每隔 30s 定期地从 Name Server 获取所有 Topic 的最新情况**：可由 `ClientConfig#pollNameServerInterval` 指定。
     - 意味着如果 Broker 不可用，那么 Producer 最多只需要 30s 就能感知到，然后负载均衡到其他 Broker 上，但在此期间内，发往该 Broker 的所有消息都会失败。
  2. **还会每隔 30s 向所有关联的 Broker发送心跳**：可由 `ClientConfig#heartbeatBrokerInterval` 指定。
     - Broker 每隔 10s 会扫描所有存活的连接，如果 Broker 在 2min 内没有收到心跳数据，则会关闭与该 Producer 的连接。

###### Consumer 集群

- 消息消费者，负责消费消息，一般是后台系统负责异步消费，会被标识为 `{IP}@{consumer group}{topic}{tag}`，比如 x.x.x.x@mqtest_producer-group_2m2sTest_tag-zyk，其中任何一个元素不同，都会被认为是不同的 Consumer。
- Consumer 会在 Name Server 集群中**随机选择一个节点**建立长连接，并与提供 Topic 服务的 Master、Slave Broker 节点建立长连接。
  1. **每隔 30s 从 Name server 获取所有 Topic 的最新情况**：
     - 这意味着如果 Broker 不可用，那么 Consumer 最多只需要 30s 就能感知到，然后负载均衡到其他 Broker 上，但在此期间内，消费该 Broker 的所有消息都会失败。
  2. **还会每隔 30s 向所有关联的 Broker发送心跳**：可由 `ClientConfig#heartbeatBrokerInterval` 指定。
     - Broker 每隔 10s 会扫描所有存活的连接，如果 Broker 在 2min 内没有收到心跳数据，则会关闭与该 Consumer 的连接，并向该 Consumer Group 的所有 Consumer 发出通知，让 Group 内的 Consumer 重新分配队列，然后继续消费。
- Consumer 既可以从 Master 订阅消息，也可以从 Slave 订阅消息，订阅规则由 Broker 配置决定。
  - 当 Consumer 收到 Master 宕机通知后，会转向 Slave 进行消费，由于 Slave 不能保证 Master 消息100% 的同步，因此会有少量的消息丢失，但是一旦 Master 恢复，未同步过去的消息最终还是会被消费掉。

##### 消息存储原理

RocketMQ 消息存储是由 Comsume Queue + cimmitlog 配合完成的。

###### CommitLog

1. 在 RocketMQ 中，所有 Topic 消息都存储在一个称为 CommitLog 的文件中，该文件默认最大为 1GB，超过 1GB 后消息就会写到下一个 CommitLog 文件。
2. 通过 CommitLog，RocketMQ 把所有消息存储在一起，以顺序 I/O 的方式写入磁盘，充分利用了磁盘
   顺序写，减少了 I/O 争用，提高了数据存储的性能。
3. 消息在 CommitLog 中的存储格式如下：

![1635674975794](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635674975794.png)

| 属性                       | 长度  | 作用                                                         |
| -------------------------- | ----- | ------------------------------------------------------------ |
| msgLen                     | 4字节 | 消息的长度，为整个消息体所占用的字节数大小                   |
| magicCode                  | 4字节 | 魔数，固定值，分为 MESSAGE_MAGIC_CODE 和 BLANK_MAGIC_CODE    |
| bodyCRC                    | 4字节 | 消息体校验码，用于防止网络、硬件等故障导致数据与发送时不一样带来的问题 |
| queueId                    | 4字节 | 消息 ID，表示消息发到了哪个 MessageQueue，相当于 Kafka#partition |
| flag                       | 4字节 | 消息 flag，是创建 Message 时由 Producer 通过构造器设置的 flag 值 |
| queueOffset                | 8字节 | 消息在 queue 中的偏移量                                      |
| physicalPosition           | 8字节 | 消息在存储文件中的偏移量                                     |
| sysFlag                    | 4字节 | 生产者相关的信息标识                                         |
| msg born timestamp         | 8字节 | 消息创建时间                                                 |
| msg host                   | 8字节 | 消息 Producer 主机地址                                       |
| store timestamp            | 8字节 | 消息存储时间                                                 |
| store host                 | 8字节 | 消息存储机器的主机地址                                       |
| reconsume times            | 4字节 | 消息被重复消费的次数                                         |
| prepare transaction offset | 8字节 | 消息事务相关的偏移量                                         |
| body length                | 4字节 | 消息体长度                                                   |
| msg body                   | N字节 | 消息体，非固定长度，实际长度等于前面标示的4字节消息体长度    |
| topic length               | 1字节 | topic 长度，<= 127 字节，由于有前置校验，超过存储则会报错    |
| topic                      | N字节 | 存储 topic，非固定长度，实际长度等于前面标示的1字节 topic 长度 |
| properties length          | 2字节 | properties 长度，添加在消息中的 poperties 不能太多太大，要保证所有的properties 的 KV 对在拼接成 string 后，占用的字节数 <= 2^15-1 |
| properties                 | N字节 | properties 内容，非固定长度，实际长度等于前面标示的2字节 properties 长度 |

###### Consume Queue

1. 消息逻辑队列，相当于字典的目录，类似于二级索引，用来指定消息在物理文件 commit log 上的位置。
2. 在 Consumer 第一次连接时创建，每个 Consumer 都会拥有一份自己的 Consume Queue，新挂载的 Consume Queue 会拥有 CommitLog 中所有的数据。
3. 一个 Consume Queue 表示 topic#queue，类似于 Kafka#partition，但是 RocketMQ 在消息存储上与 Kafka 有着非常大的不同，RocketMQ#ConsumeQueue 不存储具体的消息，具体的消息由 CommitLog 存储，Consume Queue 中只存储路由到该 queue 中消息在 CommitLog 中的 offset，整个数据包如下，一共只占20个字节：

![1635678633250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678633250.png)

| 属性    | 长度  | 作用                                           |
| ------- | ----- | ---------------------------------------------- |
| offset  | 8字节 | 消息，在 CommitLog 中的 offset，类似于二级索引 |
| size    | 4字节 | 消息大小                                       |
| tagCode | 8字节 | 消息所属的 tagCode，即 tag 的 hash             |

###### 消息存储方式

RocketMQ 消息存储，由 CommitLog + ConsumeQueue 两部分组成，其中 CommitLog 用于存储原始的消息，ConsumeQueue 用于存储投递到某一个 queue 中消息的位置信息，其消息存储方式如下图所示：

1. Consumer 在读取消息时，会先读取 Consume Queue，再通过 Consume Queue 中的 offset，读取
   CommitLog，从而得到原始的消息。

![1635678882127](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635678882127.png)

###### 对比 Kafka

1. 在 Kafka 中，每个 Partition 有独立的消息存储，投递到每个 Partition 的消息，会存储在 Partition 自己的文件中，示意图如下：

   ![1635741207241](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635741207241.png)

2. RocketMQ 与 Kafka 消息存储上的对比：

|          | RocketMQ                                                     | Kafka                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 消息存储 | 将所有消息存储在同一个 CommitLog 中，且 Consume Queue 中只存储20个字节每个消息的位置信息 | 将每个 Partition的消息分开存储                               |
| 影响     | 单个 Broker 能支持更多的 Topic 和 Consume Queue，单机支持最高5w个队列，并且Load不会发生明显变化 | 单机超过64个 Partition，Load 会发生明显的飙高，发送消息的响应时间变长，但对于少 Partition 场景， 由于利用了 Partition 并行处理，使得此时的写性能高于 RocketMQ |
| 原因     | 所有消息都存储在同一个文件中，使得消息存储是磁盘顺序写       | 将消息按 Partition 存储在不同的文件中，使得消息存储是磁盘随机写，当 Partition 数量非常大时，随机IO非常多，导致所有 Broker 性能明显下降 |

##### 生产者消息投递原理

Producer 轮询某 Topic 下所有队列的方式来实现**发送方的负载均衡**，如下图所示：

```java
private SendResult sendDefaultImpl(Message msg,......) {
    // 检查Producer状态是否是RUNNING
    this.makeSureStateOK();
    // 检查msg是否合法：是否为null、topic & body是否为空、body是否超长
    Validators.checkMessage(msg, this.defaultMQProducer);
    // 获取topic路由信息
    TopicPublishInfo topicPublishInfo = 
this.tryToFindTopicPublishInfo(msg.getTopic());
    // 从路由信息中选择一个消息队列
    MessageQueue mq = topicPublishInfo.selectOneMessageQueue(lastBrokerName);
    // 将消息发送到该队列上去
    sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, 
timeout);
}
```

![1635741977981](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635741977981.png)

##### 消费者消息消费原理

- **消费方的负载均衡**：

  1. 遍历 Consumer 下所有的 Topic，然后根据 Topic 订阅消息。
  2. 获取同一 Topic 和 Consume Group 下所有的 Consumer。
  3. 然后根据具体的分配策略，来分配消费队列，比如平均分配、消费端配置等。

  ![1635742208490](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635742208490.png)

- **两种消息订阅模式**：但无论是哪种模式，在实现上都是 Consumer 到 Broker 上主动拉取消息。

  1. 一种是 push 模式，即 Broker 主动向 Consumer 推送消息，是通过**长轮询**方式来实现的：

     1. Consumer 通过一个线程，将 LinkBlockingQueue 中的 PullRequest，每隔一段时间主动发送到Broker 去拉取消息（这样可以防止 Consumer 一直被阻塞）。
     2. Broker 在收到 PullRequest 时，如果队列里有消息，就立即返回数据，Consumer 在收到消息后，然后回调设置的 Listener 方法。
     3. Broker 在收到 PullRequest 时，如果队列里没有数据，则 Broker 会**阻塞该请求**，把 PullRequest 扔到 ConcurrentHashMap 中缓存起来，后台会有个线程不停地从 ConcurrentHashMap 取出PullRequest 进行检查，直到有数据投递过来或者发生超时后，才响应返回给 Consumer。

     ![1635742907979](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635742907979.png)

  2. 另一种是 pull 模式，即 Consumer **在需要时**，主动到 Broker 上拉取消息。

##### 事务消息实现原理

###### 单机事务

![1635743492688](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743492688.png)

- **优点**：可以保证数据一致性，耗时正常。
- **缺点**：系统规模变大时，可能会演变成分布式事务。

###### 分布式事务

![1635743625395](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743625395.png)

- **优点**：满足系统规模变大的需求。
- **缺点**：数据一致性的实现复杂，且需要经过网络，导致整体耗时成倍增加。

###### 小事务 + 异步消息

![1635743951460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635743951460.png)

- **优点**：将大事务拆分成多个小事务，然后异步执行，基本把分布式事务的执行效率优化到与单机的一致。

- **注意点**：图中执行本地事务（Bob 账户扣款）和发送异步消息，应该保证同时成功或者同时失败，也就是扣款成功了，发送消息也一定要成功，如果扣款失败了，就不能发送消息。那么问题来了，是要先扣款还是先发送
  消息呢？

  1. **先发送消息**：

     - **存在问题**：如果消息发送成功，但是扣款失败，Consumer 就会消费此消息，进而向 Smith 账户加钱，不可取。

     ![1635744186519](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744186519.png)

  2. **先扣款**：

     - **存在问题**：如果扣款成功，发送消息失败，就会出现 Bob 扣钱了，但是 Smith 账户未加钱。
       - **解决方案**：把发消息放到 Bob 扣款的事务中去，如果发送失败，就抛出异常，事务回滚，从而保证 Bob 钱是正确的，也没有发送到消息。

     ![1635744257263](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744257263.png)

###### 事务消息

![1635744412458](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635744412458.png)

事务消息，可以被认为是**两阶段提交**的消息实现，确保本地事务的执行和消息的发送可以原子地执行，实现分布式系统的最终一致性，使用事务消息，可以从框架 API 层面，实现分布式事务的需求，减少编程工作量。

- **事务消息执行时，程序分三个阶段**：
  1. **第一阶段**：发送 Prepared 消息，拿到消息的地址。
     1. RocketMQ 会定期扫描消息集群中的事务消息，如果发现了 Prepared 消息，则会向 Producer 确认，Bob 钱到底是减了还是没减，如果没减，则会继续等待。
     2. 如果减了，还要根据 Producer 设置的策略，来决定到底是回滚，还是会继续发送确认消息。
     3. 从而保证消息发送与本地事务同时成功或者同时失败。
  2. **第二阶段**：执行本地事务。
  3. **第三阶段**：通过第一阶段拿到的地址，去访问消息，并修改消息的状态。
- **存在问题**：Consumer 消费可能会失败，或者发生超时。

###### 事务消息 + 消费重试

![1635747736118](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635747736118.png)

- **优点**：通过不断消费重试，可以解决消费超时的问题，但需要注意重复消费的问题。
- **缺点**：但解决不了消费失败的问题。
  - **解决方案**：人工解决。
    1. 如果按照事务的流程，这种由于 Smith 加款失败，是需要回滚整个流程的。
    2. 而消息系统要实现这个回滚流程，系统的复杂度将大大提升，并且很容易出现 Bug，估计出现 Bug 的概率，都会比消费失败的概率大很多，这也是 RocketMQ 目前暂时没有解决这个问题的原因。
    3. 在设计实现消息系统时，需要衡量是否值得花这么大的代价，来解决一个出现概率非常小的问题。
    4. 因此，对于这种小概率问题人工解决就好，比如阿里的网上银行，发生补钱的流程通过自家的银行人工补偿就好。

#### API

##### 原生 POM 依赖

```xml
<dependency>
    <groupId>org.apache.rocketmq</groupId>
    <artifactId>rocketmq-client</artifactId>
    <version>4.9.2</version>
</dependency>
```

##### Producer | HelloWorld

###### 同步发送

可靠的同步发送，应用于广泛的场景，比如重要通知消息、短信通知、短信营销系统等。

| SendResult.sendStatus | 释义                                                         |
| --------------------- | ------------------------------------------------------------ |
| SEND_OK               | 消息发送成功，不过发送成功并不意味着可靠性投递，要想确保不丢，还要启用同步刷盘 `SYNC_FLUSH` 与同步复制 `SYNC_MASTER` |
| FLUSH_DISK_TIMEOUT    | 消息发送成功但 Master 刷盘超时，当 Master 启用了同步刷盘，却未能在同步刷盘时间内（默认 5s）完成刷盘，则会返回该状态 |
| FLUSH_SLAVE_TIMEOUT   | 消息发送成功但 Slave 同步超时，当 Master 启用了同步复制，Slave 却未能在同步复制时间内（默认 5s）完成与 Master 的同步，则会返回该状态 |
| SLAVE_NOT_AVAILABLE   | 消息发送成功但 Slave 不可用，当 Master 启用了同步复制，却没有配置任何 Slave，则会返回该状态 |

```java
public class SyncProducer {
    public static void main(String[] args) throws Exception {
        DefaultMQProducer producer = new
            DefaultMQProducer("please_rename_unique_group_name");
        producer.setNamesrvAddr("localhost:9876");
        producer.start();
        for (int i = 0; i < 100; i++) {
            Message msg = new Message("TopicTest", "TagA", 
            ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
            // 同步发送: 只要这个方法不抛出任何异常，就代表消息已经发送成功
            SendResult sendResult = producer.send(msg);
            System.out.printf("%s%n", sendResult);
        }
        producer.shutdown();
    }
}

```

###### 异步发送

异步发送，适用于链路耗时较长，对响应时间敏感的业务场景。

```java
public class AsyncProducer {
    public static void main(String[] args) throws Exception {
        ...
        // 异步发送
        producer.send(msg, new SendCallback() {
            @Override
            public void onSuccess(SendResult sendResult) {
                countDownLatch.countDown();
                System.out.printf("%-10d OK %s %n", index, sendResult.getMsgId());
            }

            @Override
            public void onException(Throwable e) {
                countDownLatch.countDown();
                System.out.printf("%-10d Exception %s %n", index, e);
                e.printStackTrace();
            }
        });
        ...
    }
}

```

###### 单向发送

单向发送，用于需要中等可靠性的情况，比如日志收集。

```java
public class OnewayProducer {
    public static void main(String[] args) throws Exception{
        ...
		producer.sendOneway(msg);
        ...
    }
}
```

##### Consumer | HelloWorld

```java
public class Consumer {
    public static void main(String[] args) throws InterruptedException, MQClientException {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name");
        consumer.setNamesrvAddr("localhost:9876");
        consumer.subscribe("TopicTest", "*");
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
                ConsumeConcurrentlyContext context) {
                System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        consumer.start();
        System.out.printf("Consumer Started.%n");
    }
}
```

##### Producer | 自定义路由

```java
public class OrderedProducer {
    public static void main(String[] args) throws Exception {
        SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
            @Override
            public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                // 自定义路由 -> 队列数量取模
                Integer id = (Integer) arg;
                int index = id % mqs.size();
                return mqs.get(index);
            }
        }, orderId);
    }
}
```

##### Consumer | 广播订阅

```java
public class BroadcastConsumer {
    public static void main(String[] args) throws Exception {
        ...
        // 广播订阅
        consumer.setMessageModel(MessageModel.BROADCASTING);
        consumer.subscribe("TopicTest", "TagA || TagC || TagD");
        ...
    }
}
```

##### Producer | 延迟消息

```java
 public class ScheduledMessageProducer {
     public static void main(String[] args) throws Exception {
         Message message = new Message("TestTopic", ("Hello scheduled message " + i).getBytes());
         // 延迟消息: This message will be delivered to consumer 10 seconds later.
         message.setDelayTimeLevel(3);
         producer.send(message);
     }
        
 }
```

##### Producer | 批量发送

```java
String topic = "BatchTest";
List<Message> messages = new ArrayList<>();
messages.add(new Message(topic, "TagA", "OrderID001", "Hello world 0".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID002", "Hello world 1".getBytes()));
messages.add(new Message(topic, "TagA", "OrderID003", "Hello world 2".getBytes()));
try {
    producer.send(messages);
} catch (Exception e) {
    e.printStackTrace();
}

```

##### Consumer | Tag 过滤器

```java
DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("CID_EXAMPLE");
// 只消费topic为TOPIC，tag为TAGA、TAGB、TAGC的消息
// consumer.subscribe("TOPIC", "TAGA || TAGB || TAGC");
// 只消费topic为TopicTest，tag为 0<=a<=3 的消息
consumer.subscribe("TopicTest", MessageSelector.bySql("a between 0 and 3");

```

##### Producer | 事务消息

```java
public class TransactionProducer {
    public static void main(String[] args) throws MQClientException, InterruptedException {
        TransactionListener transactionListener = new TransactionListenerImpl();
        TransactionMQProducer producer = new TransactionMQProducer("please_rename_unique_group_name");
        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {
            @Override
            public Thread newThread(Runnable r) {
                Thread thread = new Thread(r);
                thread.setName("client-transaction-msg-check-thread");
                return thread;
            }
        });

        // 设置自定义线程池来处理检查本地事务状态
        producer.setExecutorService(executorService);
        producer.setTransactionListener(transactionListener);
        producer.start();

        String[] tags = new String[] {"TagA", "TagB", "TagC", "TagD", "TagE"};
        for (int i = 0; i < 10; i++) {
            try {
                Message msg =
                    new Message("TopicTest1234", tags[i % tags.length], "KEY" + i,
                        ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
                SendResult sendResult = producer.sendMessageInTransaction(msg, null);
                System.out.printf("%s%n", sendResult);
                
                Thread.sleep(10);
            } catch (MQClientException | UnsupportedEncodingException e) {
                e.printStackTrace();
            }
        }

        for (int i = 0; i < 100000; i++) {
            Thread.sleep(1000);
        }
        
        producer.shutdown();
    }
}

// 实现TransactionListener接口
public class TransactionListenerImpl implements TransactionListener {
    private AtomicInteger transactionIndex = new AtomicInteger(0);
    // transactionId-status
    private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();

    // 在发送半消息成功时，执行本地事务，返回三种事务状态之一
    @Override
    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
        int value = transactionIndex.getAndIncrement();
        int status = value % 3;
        localTrans.put(msg.getTransactionId(), status);
        return LocalTransactionState.UNKNOW;
    }

    // 检查本地事务状态，并响应MQ检查请求，返回三种事务状态之一
    @Override
    public LocalTransactionState checkLocalTransaction(MessageExt msg) {
        Integer status = localTrans.get(msg.getTransactionId());
        if (null != status) {
            switch (status) {
                case 0:
                    // 中间状态，表示需要MQ回检来确定状态
                    return LocalTransactionState.UNKNOW;
                case 1:
                    // 提交事务，表示允许消费者消费这条消息
                    return LocalTransactionState.COMMIT_MESSAGE;
                case 2:
                    // 回滚事务，表示消息将被删除，不允许消费
                    return LocalTransactionState.ROLLBACK_MESSAGE;
            }
        }
        return LocalTransactionState.COMMIT_MESSAGE;
    }
}
```

#### 常见问题解决

##### 如何保证数据不丢失？

参考《RabbitMQ - 如何保证数据不丢失》，数据丢失的场景有：生产端丢数据、MQ 丢数据、消费端丢数据：

- **解决方案**：

  1. **生产端丢数据**：生产消息可以通过 Comfirm 机制解决，消息状态打标 + 消息落库 + 定时重发 + 人工介入/失败补偿（同步发送时根据 SendResult.sendStatus 判断，异步发送时在回调函数里判断）。

     ```java
     // 同步发送消息的重试次数, 默认为2
     producer.setRetryTimesWhenSendFailed(3);
     // 异步发送消息的重试次数, 默认为2
     // producer.setRetryTimesWhenSendAsyncFailed(3);
     
     ```

  2. **MQ 丢数据**：同步刷盘 + 同步复制（也叫同步双写）。

     1. **同步刷盘**：
        1. 默认情况下，刷盘策略为 `flushDiskType=ASYNC_FLUSH`，表示异步刷盘，消息到了 Broker 将会优先保存到内存中，然后立刻返回确认响应给 Producer。
        2. Broker 再定期批量地把一组消息，从内存异步刷入到磁盘中。
        3. 虽然这种方式减少了 I/O 次数，可以取得更好的性能，但如果机器发生断电、异常、宕机等情况，导致消息未能及时刷入磁盘，就会出现消息丢失。
        4. 如果要 Broker 不丢消息，保证消息可靠性，需要把刷盘机制修改为同步刷盘方式 `flushDiskType = SYNC_FLUSH`，当消息存入到磁盘成功后，才返回响应给 Producer。
     2. **同步复制**：
        1. 为了保证 RocketMQ 的可用性，Broker 通常采用一主多从的部署方式，Slave 会从 Master 复制消息。
        2. 默认情况下，复制策略为 `brokerRole=ASYNC_MASTER`，表示异步复制，消息写入 Master 成功后，就可以返回响应给 Producer 了，接着消息才会异步复制到 Slave 节点。
        3. 但如果复制期间，Master 发生宕机且不可恢复，那么未复制到 Slave 的消息将可能会发生丢失。
        4. 为了进一步提高消息可靠性，可以采用同步复制的方式 `brokerRole=SYNC_MASTER`，消息写入 Master 时，会同步等待 Slave 节点复制完成后，才返回响应给 Producer。

  3. **消费端丢数据**：

     1. Consumer 从 Broker 拉取消息，然后执行相应的业务逻辑。
     2. 如果执行成功，将返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS` 消费成功状态给 Broker。
     3. 而如果执行失败或者发生异常，则返回 `ConsumeConcurrentlyStatus.RECONSUME_LATER` 稍后重试状态给 Broker。
     4. 如果 Broker 未收到 Consumer 响应，或者收到除消费成功外的其他状态，那么 Consumer 下次还会再次拉取到该条消息进行重试。
     5. 这样有效避免了 Consumer 消费过程发生异常，或者消息在网络传输中丢失的情况。

- **总结**：

  1. 虽然提高了消息的可靠性，但会降低 MQ 的性能，生产实践中需要综合实际情况进行选择。
  2. 另外，还可能导致消息重发、Consumer 重复消费的情况，所以，对于 Consumer 而言，需要注意保证消费的**幂等性**。

##### 如何防止重复消费？

RocketMQ 不保证消息不重复，如果业务系统需要保证严格的不重复消息，需要自己在业务端进行去
重，具体解决方案参考《RabbitMQ - 如何防止重复消费》。

##### 一致性与可用性保障？

###### 集群部署方案

1. **单 Master 模式**：也就是只有一个 Master 节点。
   - **缺点**：如果 Master 节点挂了，则会导致整个服务不可用，线上不宜使用，只适用于个人学习使用。
2. **多 Master 模式**：多个 Master 节点组成集群。 
   - **优点**：所有模式中性能最高，且单个 Master 节点宕机或者重启，对应用没有影响。
   - **缺点**：单个 Master 节点宕机期间，未被消费的消息在节点恢复之前不可用，消息实时性受到影响。
     - **解决方案**：使用同步刷盘可以保证消息不丢失，同时 Topic 相对应的 Queue 应该分布在集群中各个 Master 节点，而不是只在某 Master 节点上，否则，该节点宕机会对订阅该 Topic 的应用造成影响。
3. **多 Master 多 Slave + 异步复制**：在多 Master 模式的基础上，让每个 Master 节点都有至少一个对应的 Slave，其中 Master 节点可读可写，而 Slave 只能读不能写，类似于 MySQL 的主从模式。
   - **优点**： 在 Master 宕机时，消费者可以从 Slave 读取消息，消息实时性不会受影响，性能几乎和多 Master 一样。 
   - **缺点**：使用异步复制有可能会发生消息丢失的问题。
4. **多 Master 多 Slave + 同步双写**： 与多 Master 多 Slave + 异步复制类似，但区别在于 Master 和 Slave 之间的数据同步方式为同步复制。
   - **优点**：同步双写能保证数据不丢失。 
   - **缺点**：发送单个消息 RT 会略长，性能相比异步复制低10%左右，即要保证数据可靠，需要采用同步刷盘和同步复制的方式，但性能会较其他方式低。

###### 可用性

![1635853268227](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635853268227.png)

1. **Name Server 高可用**：
   1. 由于 Name Server 节点是无状态的，且各个节点直接的数据是一致的，没有任何节点通信，每个 Broker 对接所有 Name Server 节点。
   2. 因此，在多个 NameServer 节点的情况下，当部分 Name Server 不可用时，也可以保证 MQ 服务正常运行。
2. **Broker 高可用**：
   1. Broker 通过 Master 和 Slave 的配合，达到模块的高可用，即一个 Master 可以配置多个 Slave 的一主多从模式，以及配置多个 Master-Slave 的多主多从模式。
   2. 当其中一个 Master 出现问题时：
      - **一主多从模式**：由于 Slave 只负责读，当 Master 不可用时，Slave 仍能保证消息被正常消费。
      - **多主多从模式**：由于配置了多组 Master-Slave，当 Master 不可用时，其他的 Master-Slave 还会保证消息的正常发送和消费。
   3. 新版本的 RocketMQ，支持 Slave 自动转成 Master，而老版本则要手动停止 Slave Broker，更改配置文 件，用新的配置文件启动 Broker，把 Slave 转成 Master。
3. **Consumer 高可用**：
   1. Consumer 高可用依赖于 Master-Slave 配置，由于 Master 能够支持读写消息，Slave 支持读消息，当 Master 不可用时， Consumer 会被自动切换到从 Slave 进行读取。
   2. 此时，Master 发生机器故障时，消息仍可从 Slave 中被消费。
4. **Producer 高可用**：
   1. 在创建 Topic 时，把 Topic 的多个 Message Queue 创建在多个 Master Broker 上。
   2. 这样，当其中一个 Master Broker 不可用后，其他的 Master Broker 仍然可用，Producer 可以继续发送消息。

###### 一致性（可靠性）

**4 可靠性**

- **异步刷盘**：Broker 在返回 Producer 消息写成功时，消息可能只是被写入了内存的 PageCahce，这样的写操作返回快，吞吐量大，当内存里的消息量积累到一定程度时，会统一触发写磁盘操作，快速批量写入。
  - **优点**：减少了多次写磁盘的 I/O，性能高。
  - **缺点**：当 Master 宕机，或者在磁盘损坏的情况下，会丢失少量的消息，导致 MQ 的消息状态和 Producer、Consumer 的消息状态不一致。
  - **配置参数**：默认，`flushDiskType=ASYNC_FLUSH` 。
- **同步刷盘**：Broker 在返回 Producer 消息写成功前，消息已经被真正地写入了磁盘，具体流程是，消息写入内存的 PageCache后，会立刻通知刷盘线程进行刷盘，在等待刷盘线程刷盘完成后，才唤醒等待的写消息线程，返回消息写成功的状态给 Producer。
  - **优点**：可以保持 MQ 的消息状态和 Producer、Consumer 的消息状态一致。
  - **缺点**：性能比异步的低。
  - **配置参数**：`flushDiskType = SYNC_FLUSH` 。
- **异步复制**：Broker 只要在 Master 写成功后，即可返回消息写成功状态给 Producer。
  - **优点**：复制具有较低的延迟和较高的吞吐量。
  - **缺点**：如果 Master 出现故障，有些数据会因为没有被写入 Slave，而丢失少量消息。
  - **配置参数**：默认，`brokerRole=ASYNC_MASTER` 。
- **同步复制**：Broker 会等到 Master 和 Slave 都写成功后，才返回消息写成功状态给 Producer。
  - **优点**：如果 Master 出现故障，Slave 有全部的备份数据，消息不丢失，容易实现完整恢复。
  - **缺点**：增大了复制的写入延迟，降低了系统吞吐量，性能比异步复制略低，大约低 10% 左右。
  - **配置参数**：`brokerRole=SYNC_MASTER` 。

###### 总结

1. **Master + Slave + 同步刷盘 + 同步双写**是最安全的方案，但会引入额外的延迟。
2. 事实证明，在所有的故障模式下，分布式系统不可能同时保证无数据丢失的最终一致性，以及时刻都接受读取和写入的高可用性。
3. 因此需要做的是，选择要针对其中的一些进行优化，让一致性和可用性处于一个范围的两端。

##### 如何实现 Consumer Rebalance？

###### 概念

Consumer Rebalance，消费者再均衡机制，指将一个 Topic 下的多个 Queue，在同一个 Consumer Group下的多个 Consumer 之间进行重新分配。 

1. Consumer Rebalance 机制，目的是为了提升消息的并行处理能力。
2. 比如，一个 Topic 下有 5 个 Queue，在只有 1 个 Consumer 的情况下，那么该 Consumer 将会负责处理这 5 个队列的消息。
3. 如果此时增加了一个 Consumer，那么则可以给其中一个 Consumer 分配 2 个 Queue，给另一个分配 3 个 Queue，从而提升消息的并行处理能力。

![1635925188314](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1635925188314.png)

###### 局限与危害

- **空消费**：由于一个 Queue 最多分配给一个 Consumer，因此，当某个 Consumer Group 下的 Consumer#size > Queue#size 时，多余的 Consumer 将分配不到任何 Queue。
- **消费暂停**：
  1. 在只有 Consumer 1 负责消费所有 5 个 Queue 的情况下，在新增 Consumer 2，触发 Consumer Rebalance 时，需要分配 2 个Queue 给 Consumer 2 消费。
  2. 那么，此时 Consumer 1 就需要停止这 2 个 Queue 的消费，等到这 2 个 Queue 分配给 Consumer 2 后，这 2 个 Queue 才能被继续消费。
- **重复消费**：
  1. Consumer 2 在消费分配给自己的 2 个 Queue 时，必须接着从 Consumer 1 之前已经消费到的 offset 继续开始消费。
  2. 然而，默认情况下，offset 是异步提交的，比如 Consumer 1 当前消费到 offset=10，但是异步提交给Broker#offset=8。
  3. 那么，如果 Consumer 2 从 offset=8 开始消费，那么就会有 2 条消息被重复消费，也就是说，Consumer 2 并不会等待 Consumer 1 提交完 offset 后，再进行 Rebalance，因此，Consumer 1 提交间隔越长，可能造成的重复消费就越多。 
- **消费突刺**：由于 Consumer Rebalance 可能导致重复消费，如果需要重复消费的消息过多，或者因为Consumer Rebalance 暂停时间过长，导致 MQ 积压了较多消息，导致在 Consumer Rebalance 结束之后的瞬间，Consumer 需要消费很多消息。

###### 触发条件

Consumer Rebalance 的触发条件有 2 个：

1. 订阅了 Topic 的 Queue 信息发生变化。
2. Consumer Group 信息发生变化。

| 订阅了 Topic 的 Queue 信息发生变化 | Consumer Group 信息发生变化                |
| ---------------------------------- | ------------------------------------------ |
| Broker 宕机                        | Consumer 发布过程中的停止与启动            |
| Broker 升级等运维操作              | Consumer 异常宕机                          |
| Queue 扩容或者缩容                 | 网络异常，导致 Consumer 与 Broker 断开连接 |
|                                    | Consumer 扩容或者缩容                      |
|                                    | Topic 订阅信息发生变化                     |

###### 场景分析

对于 Consumer Group 信息发生变化，具体场景有，Consumer 在启动/运行/停止时，都有可能触发 Consumer Rebalance。

- **启动时**：
  1. Consumer 启动后会立即向所有 Broker 发送一次发送 `HEART_BEAT` 心跳请求。
  2. Broker 收到该请求后，则会将 Consumer 添加到由 ConsumerManager 维护的某个消费者组中。
  3. 然后该 Consumer 自己会触发一次 Consumer Rebalance。
- **运行时**：Consumer 接收到 Broker Rebalance 通知后，会立即触发一次 Consumer Rebalance，同时为了避免 Rebalance 通知丢失，还会周期性触发 Consumer Rebalance。
- **停止时**：
  1. Consumer 向所有 Broker 发送 `UNREGISTER_CLIENT` 命令。
  2. Broker 收到后，则将 Consumer 从 ConsumerManager 中移除，并通知其他 Consumer 进行 Consumer Rebalance。

###### 执行过程

- **单 Topic 队列分配**：调用 `RebalanceImpl#rebalanceByTopic`。

  1. 获得 Rebalance 元数据信息：即当前消费者组订阅 Topic 的 Queue 信息，以及当前消费者组所有 Consumer#ID 集合。

  2. 调用 `AllocateMessageQueueStrategy#allocate` 根据具体的**队列分配策略**，进行队列分配，此时需要传入消费者组、当前 Consumer#ID、当前消费者组可分配的队列集合、当前消费者组所有 Consumer#ID 集合。

     | 队列分配策略实现                      | 实现原理       |
     | ------------------------------------- | -------------- |
     | AllocateMessageQueueAveragely         | 默认，平均分配 |
     | AllocateMessageQueueAveragelyByCircle | 循环分配       |
     | AllocateMessageQueueConsistentHash    | 一致性哈希分配 |
     | AllocateMessageQueueByConfig          | 根据配置分配   |
     | AllocateMessageQueueByMachineRoom     | 根据机房分配   |
     | AllocateMachineRoomNearby             | 就近分配       |

  3. 调用 `RebalanceImpl#updateProcessQueueTableInRebalance` 进行队列的实际分配。

- **多 Topic 分配**：每个 Topic 都会调用一次 `RebalanceImpl#rebalanceByTopic`，触发一次队列分配策略。

###### 对比 Kafka Consumer Rebalance

- **相同点**：二者的 Rebalance 都是在 Consumer 客户端进行。
- **不同点**：
  1. Kafka 会在 Consumer Group 中，选出一个 Consumer 作为 Group Leader，再由这个 Group Leader 来进行分区分配，最后的分配结果通过 Cordinator Broker 同步给其他 Consumer，即 Kafka 分区分配只有一个大脑 Group Leader。
  2. 而 RocketMQ 则是，通过 Broker 通知每个 Consumer 各自进行 Consumer Rebalance，每个Consumer 自己给自己重新分配队列，而不是 Broker 将分配好的结果告知 Consumer，即每个 Consumer 都是一个大脑。
- **RocketMQ#Consumer Rebalance 一致性保证原理**：
  - **定时 Rebalance 保证**：每个 Consumer 都会定时触发 Rebalance，避免 Rebalance 通知丢失。
  - **队列分配策略保证**：
    1. 每个 Consumer 在调用 `AllocateMessageQueueStrategy#allocate` 时，会传入自身实例#ID，用于获取在当前消费组所有 Consumer#ID 集合中的索引位置。
    2. 然后根据具体的策略实现，可以使得每个索引所处的 Consumer 分配的队列各不相同。
    3. 这样可以让 RocketMQ 即使没有一个中心节点做统一的队列分配，也能完成 Consumer Rebalance。

##### 如何保证顺序消费？

- **问题场景**：

  - 业务上产生三条消息，分别是对数据的 add、update 和 delete，如果没有保证顺序消费，结果可能是delete ->  update -> add，本来数据最终是要 delete 掉的，结果却变成 add。
  - 再如电商平台，先付钱，然后生成订单，最后通知物流，如果顺序改变了，则可能出现不用先付钱了，却通知物流送货。

- **解决思路**：必须要使用**单消费者消费单个队列**，类似于 Kafka 的单消费者单个分区，目的是防止消费者争抢消息导致乱序消费的情况发生。

  1. 与 RabbitMQ 保证单消费者消费单个队列不同，但与 Kafka 类似，由于 RocketMQ#Consumer Group 机制，天然就能保证单个消费者消费，虽然 RocketMQ 针对的是 Queue，但却类似于一个 Kafka#Partition。

- **解决方案**：参考《RabbitMQ - 如何保证顺序消费》。

  - **多队列、多消费者**：类似于 RabbitMQ#一致性哈希交换机 `x-consistent-hash Exchange`，通过业务ID进行 hash，保证同一个业务 ID 的消息只落在同一个 Queue 中，然后被同一个 Consumer 顺序消费。

    - **局限**：消息不是全局保证顺序的，而只是相关消息才保证顺序；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。

    - **实现方法**：

      ```java
      // 通过MessageQueueSelector中实现的算法，来确定消息发送到哪一个Queue上
      SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
          @Override
          public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) 
      {
              Integer id = (Integer) arg;
              int index = id % mqs.size();
              return mqs.get(index);
          }
      }, orderId);
      
      ```

  - **单队列、多消费者**：多个 Consumer 消费。

    - **局限**：需要保证并发同步，引入了同步机制，可能会降低消费速度。

  - **单消费者、多线程**：一个 Consumer + 一个内存队列 + 多线程消费，即 Master - Worker 模式。

    - **局限**：与单分区、多消费者模式类似，只不过在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

  - **单队列、单消费者**：始终保证使用 一个 Queue + 一个 Consumer 消费。

    - **局限**：Consumer 不能水平扩展，消费能力有限。

    - **实现方法**：

      ```shell
      # -b : broker地址,表示topic建在该broker
      # -c : cluster名称,表示topic建在该集群
      # -n : nameserve服务地址列表
      # -r : 可读队列数(默认为8)
      # -w : 可写队列数(默认为8)
      # -t： topic名称
      mqadmin updateTopic -b localhost:10911 -t TopicTest
      ```

##### 如何优化消息积压？

###### 影响后果

1. 消息积压越多，Consumer 寻址的性能就越慢，最差的情况则会导致整个 RocketMQ 对外提供服务的性能很差，从而影响其他服务的访问速度，最后造成雪崩效应。
2. 而且还可能发生磁盘被堆满，导致 Producer 消息无法写入磁盘，一直报错，然后引发连锁反应，同样会造成雪崩效应。

###### 原因分析

如果 Consumer 消费速度跟不上 Producer 生产速度，就会造成消息积压。

- Consumer 消费速度跟不上 Producer 生产速度，一般是业务逻辑没设计好，导致 Consumer 和 Producer 之间的效率不平衡。
  - **解决思路**：增加 Partition、增加 Consumer 等，以提高消费速度。
- Consumer 出现异常，导致一直无法接收新的消息。
  - **解决思路**：优化消费程序，解决异常。

###### 优化思路

一定要保证 Consumer 的消费性能要高于 Producer 的发送性能，这样系统才能健康、持续地运行。

###### 优化方案

这里的优化方案，针对的是**消费速度低于生产速度**，而不是 Consumer 异常。

1. **Consumer 批量拉取消息**：这里要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以从**减少 I/O 的角度**入手。

   1. 对于每条消息分别拉取的情况，Consumer 需要多次从 Broker 上拉取消息，这样的多次 I/O，浪费了服务器性能与增加了带宽的占用。
   2. 通过批量拉取消息的方式，减少多次发起 Broker 请求，可以减少很多 I/O 浪费和带宽占用。

   ```java
   // 每次拉取10条
   consumer.setConsumeMessageBatchMaxSize(10);
   
   ```

2. **多线程并发消费**：接着还要考虑的是，Consumer 有没有已经发挥出其本身真正的后端处理能力，如果没有，可以**从多线程并发消费**入手，参考《Kafka API - Consumer 多线程消费》。

   1. 多线程并发消费，不需要建立多个 RocketMQ 客户端连接，在收到消息后，可以将其放入不同的线程中进行消费，这样进程中就会同时消费多个消息，增加了消费的吞吐量，从而提升消费速度。
   2. **小结**：与增加 Consumer 类似，存在并发冲突和顺序消费的问题，只不过在多线程并发消费是在同一个 Consumer 进程中，处理并发同步的成本可能要比不同进程的更低一些。

3. **增加 Consumer**：这个道理比较容易理解，多个人搬砖的速度肯定比一个人要快很多，不过实际情况还需要面对一些技术挑战，比如后端处理能力瓶颈、并发消费冲突，以及保持顺序消费三个问题。

   - **后端处理能力瓶颈**：
     1. 比如多个 Consumer 都要操作数据库，那么数据库连接的并发数和读写吞吐量就是后端处理能力。
     2. 如果达到了**数据库的最大处理能力**，出现了瓶颈，增加再多的 Consumer 也没有用，甚至会因为加剧了数据库拥塞，从而导致整体消费速度的进一步下降。
   - **并发消费冲突**：
     1. 比如两个 Consumer 都要去修改用户的积分，如果同时取出了相同的数据，并发处理的话就会出现并发安全问题。
     2. 此时需要保证**并发同步**，比如可以搞一个分布式锁，对于具体的某个用户，确保同时只能有一个消费者来处理其积分。
   - **保持顺序消费**：
     1. 由于增加了多个 Consumer，不再是单个 Consumer 消费单个队列，可能会出现乱序消费的情况。
     2. 如果仍需要保证顺序消费，那么可以参考一致性哈希的做法，搞成多队列、多消费者模式，不过只能保证相关消息顺序消费；如果确实要保证顺序消费，则需要并发同步，比如搞分布式锁。
   - **小结**：
     1. 解决并发消费冲突、保持顺序消费两个问题，常常需要引入多个 Consumer 之间的**并发同步**机制，如果这些机制设计得不好，还会给消费速度带来很大的影响。
     2. 因此，多人搬砖速度快的前提，是多个人搬砖时不需要大家频繁的坐下来协调谁搬哪块砖，否则，就会浪费很多时间在相互协调上，反而不能提升搬砖的速度。
     3. 所以，想要通过增加 Consumer，来提升消费速度，需要确保 Consumer **并发处理能力**要留有余地，Consumer 依赖的**后端服务处理能力**也要留有余地。

###### 方案总结

- **优化思路**：通过分析上边的这些方法，在进行消费优化时，可以遵循这样一个路径，以保证最大消费速度。
  1. 先单个 Consumer 消费，**1 次只接收 1 条消息**，消息消费完毕后再消费下一条，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  2. 如果消费速度不满足要求，则提高 `consumer.setConsumeMessageBatchMaxSize(10)`，**1 次接收多条消息**，单线程按顺序消费，避免并发冲突和顺序消费的问题，减少同步机制的消耗。
  3. 如果消费速度还是不满足要求，则 **1 次接收多条 + 多线程消费**，但要注意并发冲突和顺序消费的问题。
  4. 如果消费速度还是不满足要求，则**多个消费者并发消费**，但要注意并发冲突和顺序消费的问题。
  5. 如果消费速度还是不满足要求，则考虑**改需求**，或者**换别的中间件**。
- **优化注意点**：
  1. **程序性能优化优先**：需要始终优先优化 Consumer 处理能力，以及其依赖的后端程序处理能力，比如要去优化 SQL 语句、使用缓存、使用负载均衡等，来加快消费速度，因为消息积压常常都是程序处理太耗时导致的。
  2. **幂等性消费**：由于不只 Producer 可能会重复发送消息，Consumer 也可能会触发消息的重复投递，所以，Consumer 要保证幂等性消费。
  3. **并发同步**：如果使用了多线程消费，或者多 Consumer 消费，则会存在并发冲突以及顺序消费的问题，此时需要保证并发同步，比如使用分布式锁。
  4. **顺序消费**：最好能做到无需顺序消费，否则需要在多线程消费，或者多 Consumer 消费时保证并发同步。

###### 【线上】如何紧急处理消息积压？

参考《RabbitMQ - 【线上】如何紧急处理消息积压》。

对于 RocketMQ 而言，由于 Queue 机制与 RabbitMQ Queue 并不相同，所以除了参考，还有以下的处理方式：

1. **提高 Queue 队列数**：队列数足够，可以提高消费的并行度，并且也决定者同组 Consumer 的最大数量。
2. **临时 Topic + Consumer 进行消息转储消费**：
   1. 如果消息积压的 Topic 在建立时，就没有建立足够多的 Queue，导致同一个 Consumer Group 中的 Consumer#size 已经增加到 Queue#size，却仍有大量的消息积压。
   2. 此时，可以建立一个临时的 Topic、设置足够多的 Queue 以及上线一批足够多的 Consumer ，然后把所有原 Topic 的 Consumer 拉取到的消息统统转储到临时 Topic 上，供新上线那批 Consumer 去消费。
   3. 这样，消费速度上去了，消息积压的问题才有机会解决掉，解决掉后再视实际情况，来决定是否恢复原状。

# 七、Dubbo篇

### 1.1. 什么是集群、分布式、SOA、微服务架构？

#### 总结

| 架构   | 概念                                                         | 本质                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 集群   | 不同服务器部署**同一套应用**服务对外提供访问，实现服务的负载均衡，或者主从等，指同一种组件的多个实例，形成逻辑上的整体，其中的单个节点就可以提供完整服务。 | 节点的物理形态                                               |
| 分布式 | 服务的**不同模块**部署在不同的服务器上，其中的单个节点并不能提供完整服务，需要多个节点间通过交换信息协调提供服务 | 节点间的工作方式                                             |
| SOA    | Service Oriented Architecture，**面向服务的架构**，一种设计方法，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能，一个服务通常以独立的形式存在于某个操作系统进程中，各个服务之间通过网络进行调用 | ESB **中心化实现**，各服务通过 ESB 进行交互，解决**异构系统**之间的连通性，通过协议转换、消息解析、消息路由把服务提供者的数据传送到服务消费者；但由于所有服务都依赖于 ESB，最终会导致其承压过重，成为整体系统的一个瓶颈 |
| 微服务 | 微服务强调业务需要彻底的**组件化和服务化**，使原有的单个业务系统被拆分成多个可以独立开发、设计、运行的小应用，而这些小应用之间通过服务完成交换和集成 | SOA 架构的一种变体，其中**去中心化实现**是在 SOA 上做的升华  |

#### SOA VS 微服务

|      | SOA                          | 微服务                       |
| ---- | ---------------------------- | ---------------------------- |
| 目标 | 强调异构服务之间的协作与集成 | 拆分模块、快速拓展、快速开发 |
| 管理 | 着重中央管理                 | 重在分散管理                 |
| 粒度 | 通常粒度粗                   | 拆分粒度更细，职责单一       |

### 1.2. 详细介绍 RPC？

#### 背景概念

- **背景**：部署在 A 服务器的一个应用，想要调用 B 服务器上应用提供的方法，由于两个程序不在同一个内存空间，所以不能直接发起调用，需要通过网络来表达调用的语义和传达调用的数据，而 RPC 正是用来解决这种调用过程。
- **概念**：RPC，Remote Procedure Call，远程过程调用，是⼀种**技术思想**，⽽⾮⼀种规范或协议，是一种通过网络，使得程序能够像访问本地系统资源一样，去访问远端系统资源。

#### 架构组件

一个基本的 RPC 架构里面应该至少包含以下 4 个组件：

- **Client**：客户端，即服务调用方，也叫服务消费者。
- **Client Stub**：客户端存根，存放服务端地址信息，将客户端的请求参数打包成网络消息，再通过网络传输发送给服务端。
- **Server Stub**：服务端存根，接收客户端发送过来的请求消息，然后进行解包，再调用本地服务进行处理。
- **Server**：服务端，服务的真正提供者。

![1636547867858](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636547867858.png)

#### 实现基础

1. **高效的网络通信**：比如一般选择 Netty 作为网络通信框架。
   - **NIO 通信**：出于并发性能的考虑，传统阻塞式 IO并不合适，因此需要非阻塞的 NIO，比如可以选择 Netty 或者 MINA 来解决 NIO 数据传输的问题。
2. **高效的序列化框架**：比如 Kryo、FastJson 和 Protobuf 序列化框架。
   - **序列化和反序列化**：在网络中，所有数据都将会被转化为**字节**进行传送，所以为了能够使参数能在网络中进行传输，需要对这些参数进行序列化和反序列化操作。
     - **序列化**：把对象转换为字节序列的过程称为**对象的序列化**，也就是编码的过程。
     - **反序列化**：把字节序列恢复为对象的过程称为**对象的反序列化**，也就是解码的过程。
3. **可靠的寻址方式**：指服务发现，比如可以使用 Zookeeper 来注册服务等。
   - **服务注册中心**：比如 Redis、Zookeeper、Consul 、Etcd 等，一般使用 ZooKeeper 来提供服务注册与发现功能，以及解决注册中心单点故障和分布式部署的问题。
4. **会话和状态保持**：如果是带会话（状态）的 RPC 调用，还需要有会话和状态保持的功能。
   - **长连接**。
5. **接口动态代理**：生成客户端存根 `Client Stub` 和服务端存根 `Server Stub` 时，需要用到动态代理技术，比如JDK 动态代理、CGLib 动态代理、Javassist 字节码生成。

![1636299221043](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636299221043.png)

#### 调用过程

1. **客户端调用**：服务消费方通过调用本地服务的方式调用需要消费的服务。
2. **将方法入参等信息序列化**：客户端存根接收到调用请求后，负责将方法、入参等信息序列化，组装成能够进行网络传输的消息体。
3. **通过网络发送消息**：客户端存根找到远程的服务地址，并且将消息通过网络发送给服务端。
4. **发序列化操作**：服务端存根收到消息后进行反序列化解码操作。
5. **调用本地服务**：服务端存根根据解码得到的结果，调用本地的服务进行相关处理。
6. **服务端处理业务逻辑**：服务端本地服务执行具体业务逻辑。
7. **返回处理结果**：服务端把业务处理结果返回给服务端存根。
8. **返回消**息：服务端存根将返回结果重新序列化，打包成消息，并通过网络发送至消费方。
9. **反序列化操作**：客户端存根接收到消息，并进行反序列化解码操作。
10. **返回调用结果**：客户端存根返回解码得到的结果给服务消费方，服务消费方得到最终结果，完成一次 RPC 调用。

![1636298416654](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636298416654.png)

#### 实现目标

RPC 框架的实现目标是，把以上调用过程的第 2~10 步，调用、编码/解码的过程给封装起来，让开发人员使用时，在感觉上就像调用本地服务一样地调用远程服务。

#### 常⻅框架

RPC 常见框架实现有：阿里 Dubbo & HSF、当当 Dubbox、京东 JSF、Google GRPC、Facebook 的 Thrift、Twitter Finagle、Spring Cloud 等。

- **Dubbo**：阿⾥集团开源的⼀个极为出名的 RPC 框架，底层使用 Netty 框架，基于 TCP 协议传输的，配合 Hession 序列化完成 RPC 通信，在很多互联⽹公司和企业应⽤中⼴泛使⽤，其协议和序列化框架都可以插拔是极其鲜明的特⾊。
- **Dubbox**：当当网基于 Dubbo 做的一个扩展项目，比如加了服务可 Restful 调用，更新了开源组件等。
- **GRPC**：Google 开源 RPC 框架，基于 HTTP 2.0 协议，底层使⽤ Netty 框架，⽀持常⻅的众多编程语⾔。
- **Thrift**：Facebook 开源 RPC 框架，主要是⼀个跨语⾔的服务开发框架，⽤户只要在其之上进⾏⼆次开发就⾏，应⽤对于底层的 RPC 通讯等都是透明的，不过这个对于⽤户来说需要学习特定领域语⾔这个特性，还是有⼀定成本的。
- **Spring Cloud**：基于 Http 协议 REST 接口调用进行远程过程通信，相对来说 TCP 实现的  RPC 请求会有更大的报文，占的带宽也会更多，但是 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖。
  - Dubbo 是 SOA 时代的产物，以服务治理作为目标，关注点主要在于服务调用、流量分发、流量监控以及服务熔断。
  - Spring Cloud 诞生于微服务架构时代，依托了 Spring、Spring Boot，考虑的是微服务治理的方方面面，目的是打造一个生态。

#### RPC 与 HTTP 的区别

在大型网站内部子系统和接口都非常多的情况下，RPC 对比 Http 接口的优势有：

1. **长链接**：不必每次通信都要像 Http 那样去 3 次握手，减少了网络开销。
2. **服务治理**：RPC 框架一般都有注册中心，也有丰富的监控管理，来发布、下线接口、动态扩展等，这些对调用方来说是无感知、统一化的操作。

|              | RPC                                                          | HTTP                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 概念         | 远程过程调用，是⼀种**技术思想**，⽽⾮⼀种规范或协议         | 超长文本传输协议，是一种网络传输协议                         |
| 传输协议     | 基于 TCP 协议（网络 4 层），也可以基于 HTTP 协议             | 基于 HTTP 协议（网络 7 层）                                  |
| 传输效率     | 传输效率高，使⽤⾃定义的 TCP 协议，请求报⽂体积更⼩；或者使⽤ HTTP2 协议，也可以很好的减少报⽂的体积 | 如果是 HTTP1.1 协议，请求中会包含很多⽆⽤的内容；如果是 HTTP2.0 协议，进行简单封装可以作为⼀个 RPC 来使⽤，但对比标准 RPC 框架缺少了服务治理 |
| 性能消耗     | 可以基于 thrift 协议，实现⾼效的⼆进制传输                   | ⼤部分通过 json 来实现，字节⼤⼩和序列化都⽐ thrift 要更消耗性能 |
| 负载均衡     | RPC 框架基本都⾃带了负载均衡策略                             | 需要配置Nginx、HAProxy来实现                                 |
| 服务故障转移 | 能做到⾃动通知，不影响上游                                   | 需要事先通知，以修改下游的 Nginx、HAProxy 配置               |
| 总结         | 主要⽤于公司内部的服务调⽤，性能消耗低、传输效率⾼、服务治理⽅便 | 主要⽤于对外的异构环境，浏览器接⼝调⽤、APP接⼝调⽤、第三⽅接⼝调⽤等 |

### 1.3. 为什么要用 Dubbo？

#### 单一应用架构

- **背景**：当⽹站流量很⼩时，只需⼀个应⽤，将所有功能都部署在⼀起，以减少部署节点和成本。
- **关键点**：此时，⽤于简化增删改查⼯作量的数据访问框架 **ORM** 是关键。

![1636254754534](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254754534.png)

#### 垂直应用架构

- **背景**：当访问量逐渐增⼤，单⼀应⽤增加机器带来的加速度越来越⼩，提升效率的⽅法之⼀是将应⽤拆成
  互不相⼲的⼏个应⽤，以提升效率。
- **关键点**：此时，⽤于加速前端⻚⾯开发的Web框架 **MVC** 是关键。

![1636254796925](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254796925.png)

#### 分布式服务架构

- **背景**：当垂直应⽤越来越多，应⽤之间交互不可避免，将核⼼业务抽取出来，作为独⽴的服务，逐渐形成
  稳定的服务中⼼，使前端应⽤能更快速的响应多变的市场需求。
- **关键点**：此时，⽤于提⾼业务复⽤及整合的分布式服务框架 **RPC** 是关键。

![1636254855881](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254855881.png)

#### 流动计算架构（SOA）

- **背景**：随着服务化的进⼀步发展，服务越来越多，服务之间的调⽤和依赖关系也越来越复杂，诞⽣了⾯向
  服务的架构体系（SOA），也因此衍⽣出了⼀系列相应的技术，如对服务提供、服务调⽤、连接处理、通信协议、序列化⽅式、服务发现、服务路由、⽇志输出等⾏为进⾏封装的**服务治理框架**，比如 Dubbo。

![1636254950341](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636254950341.png)

### 1.4. 什么是 Dubbo？

Apache Dubbo，是一款高性能、轻量级的开源服务框架，提供了六大核心能力：面向接口代理的高性能 RPC 调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度、可视化的服务治理与运维。

#### 1、面向接口代理的高性能RPC调用

提供高性能的、基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用的底层细节。

- 默认使用 **Dubbo 协议**，基于 TCP 协议实现，有着报文小占用带宽小、基于网络 4 层通信效率高的优点。

#### 2、智能负载均衡

内置多种负载均衡策略，可以智能感知下游节点的健康状况，显著减少了调用延迟，提高了系统的吞吐量。

- **负载均衡**：当服务越来越多时，F5 硬件负载均衡器的单点压⼒也越来越⼤，通过在消费⽅获取服务提供⽅地址列表，实现软负载均衡和集群容错。

#### 3、服务自动注册与发现

支持多种注册中心服务，能够做到服务实例上下线的实时感知。

- **地址维护**：当服务越来越多时，服务 URL 配置管理变得⾮常困难，这时候需要⼀个服务注册中⼼，来动态注册和发现服务，使服务的位置透明。

#### 4、高度可扩展能力

遵循微内核+插件的设计原则，Microkernel 只负责组装 Plugin，其所有核心能力如 Protocol、Transport、Serialization 都被设计为扩展点，能够平等对待内置实现和第三方实现。

- **微内核**：Micro kernel，是提供操作系统核心功能的内核精简版本，设计成在很小的内存空间内增加移植性，提供模块化设计，以使用户安装不同的接口，如 DOS、Workplace OS、Workplace UNIX 等。

#### 5、运行期流量调度

内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现灰度发布、同机房优先等功能。

- 比如服务限流、服务降级、蓝绿发布、金丝雀发布、权重路由、同区域优先等。

#### 6、可视化的服务治理与运维

提供丰富服务治理、运维工具，可以随时查询服务元数据、服务健康状态以及调用统计，实时下发路由策略、调整配置参数。

1. 当调⽤量越来越⼤，服务容量问题就会暴露出来，服务需要多少机器⽀撑？什么时候该加机器？
2. 为了解决这些问题，第⼀步，要将服务当前每天的调⽤量、响应时间都统计出来，作为容量规划的参考指标。
3. 其次，进行动态调整权重，在线上将某台机器的权重⼀直加⼤，并在加⼤的过程中记录其响应时间的变化，直到响应时间到达阈值时，记录此时的访问量，再以此访问量乘以机器数反推总容量。

### 1.5. 什么是蓝绿发布、金丝雀发布、灰度发布、滚动发布？

| 发布类型   | 概念                                                         |
| ---------- | ------------------------------------------------------------ |
| 蓝绿发布   | 在线上老版本继续运行的前提下，直接发布新版本，然后进行测试；当新版本测试通过后，再将流量切到新版本，最后将老版本同时也升级到新版本 |
| 金丝雀发布 | 在线上版本可用的情况下，同时发布一个新版本应用作为**金丝雀**；测试该新版本的性能和表现，在保障整体系统稳定的前提下，可以尽早发现问题并及时做出调整 |
| 灰度发布   | 只升级部分服务，让一部分用户继续用老版本，一部分用户开始用新版本；如果用户对新版本没什么意见，再逐步扩大范围，最后将所有用户都迁移到新版本上面来 |
| 滚动发布   | 每次只升级一个或多个服务，升级完成后加入生产环境，不断执行这个过程，直到集群中的全部旧版本都升级到新版本为止 |

### 1.6. 什么是 Dubbo 核心组件？

![1636292050935](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636292050935.png)

#### 节点角色

| 节点      | 角色                                 |
| --------- | ------------------------------------ |
| Container | 服务运行容器                         |
| Provider  | 暴露服务的服务提供方                 |
| Registry  | 服务注册与发现的注册中心             |
| Consumer  | 调用远程服务的服务消费方             |
| Monitor   | 统计服务调用次数和调用时间的监控中心 |

#### 调用关系

1. 服务容器负责启动、加载、运⾏服务提供者。
2. 服务提供者在启动时，向注册中⼼注册⾃⼰提供的服务。
3. 服务消费者在启动时，向注册中⼼订阅⾃⼰所需的服务。
4. 注册中⼼返回服务提供者地址列表给消费者，如果有变更，注册中⼼将会基于⻓连接推送变更数据给消费者。
5. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选⼀台服务提供者进⾏调⽤，如果调⽤失败，再选另⼀台调⽤。
6. 服务消费者和提供者，在内存中累计调⽤次数和调⽤时间，定时每分钟发送⼀次统计数据到监控中⼼。

#### 架构优点

Dubbo 架构具有以下⼏个优点，分别是连通性、健壮性、伸缩性、以及面向未来架构的升级性。

##### 1、连通性

注册中⼼，服务提供者，服务消费者三者之间均为⻓连接，监控中⼼除外，而注册中⼼和监控中⼼都是可选的，服务消费者可以直连服务提供者。

- **服务提供者**：向注册中⼼注册其提供的服务，并汇报调⽤时间到监控中⼼，此时间不包含⽹络开销。
- **注册中⼼**：
  1. 负责服务地址的注册与查找，相当于⽬录服务，服务提供者和消费者只在启动时与注册中⼼交互，不转发客户端请求，压⼒较⼩。
  2. 通过⻓连接感知服务提供者的存在，当服务提供者宕机时，注册中⼼会⽴即推送事件通知消费者。
- **服务消费者**：向注册中⼼获取服务提供者地址列表，并根据负载算法直接调⽤提供者，同时汇报调⽤时间到监控中⼼，此时间包含⽹络开销。
- **监控中⼼**：负责统计各服务调⽤次数，调⽤时间等，统计先在内存汇总后每分钟⼀次发送到监控中⼼服务器，并以报表展示。

##### 2、健壮性

- 任意⼀台**注册中⼼**宕掉后，将会⾃动切换到另⼀台，全部宕掉后，服务提供者和服务消费者仍能通过本地缓存进行通讯，但不能注册新服务。
- ⽆任意⼀台**服务提供者**宕掉后，不会影响使⽤，全部宕掉后，服务消费者将⽆法使⽤，并⽆限次重连等待，直到服务提供者恢复。
- **监控中⼼**宕掉后，不影响使⽤，只是丢失部分采样数据而已。

##### 3、伸缩性

- **注册中心集群**：注册中⼼是对等集群，可动态增加机器部署实例，所有客户端将会⾃动发现新的注册中⼼。
- **服务提供者集群**：服务提供者⽆状态，可动态增加机器部署实例，注册中⼼将推送新的服务提供者信息给消费者。

##### 4、面向未来架构的升级性

当服务集群规模进⼀步扩⼤，带动 IT 治理结构进⼀步升级，需要实现动态部署，进⾏流动计算，而基于现有分布式服务架构，那时将不会带来阻⼒。下图是未来可能的⼀种架构：

![1636293350069](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636293350069.png)

###### 节点角色

| 节点           | 角色                                           |
| -------------- | ---------------------------------------------- |
| **Admin**      | 统一管理控制台                                 |
| **Scheduler**  | 调度中心，可以基于访问压力，自动增减服务提供者 |
| **Deployer**   | 自动部署服务的本地代理                         |
| **Repository** | 版本仓库，用于存储服务应用发布所有代码包       |
| Container      | 服务运行容器                                   |
| Provider       | 暴露服务的服务提供方                           |
| Registry       | 服务注册与发现的注册中心                       |
| Consumer       | 调用远程服务的服务消费方                       |
| Monitor        | 统计服务调用次数和调用时间的监控中心           |

###### 调用关系

1. 统一管理控制台，不仅可以发布服务提供者的代码包到版本仓库，还可以通过大盘获取路由、流量统计等信息。
2. 调度中心会基于监控中心聚合过来的信息，进行动态增减服务提供者。
3. 当需要动态增加服务提供者时，会拉起新的服务运行容器。
4. 服务容器会先到版本仓库，拉取对应的代码包，然后负责启动、加载、运⾏服务提供者。
5. 服务提供者在启动时，向注册中⼼注册⾃⼰提供的服务。
6. 服务消费者在启动时，向注册中⼼订阅⾃⼰所需的服务。
7. 注册中⼼返回服务提供者地址列表给消费者，如果有变更，注册中⼼将会基于⻓连接推送变更数据给消费者。
8. 服务消费者，从提供者地址列表中，基于软负载均衡算法，选⼀台服务提供者进⾏调⽤，如果调⽤失败，再选另⼀台调⽤。
9. 服务消费者和提供者，在内存中累计调⽤次数和调⽤时间，定时每分钟发送⼀次统计数据到监控中⼼。

### 1.7. Dubbo 基本使用方式？

#### 原生 POM 依赖

```xml
<!-- Dubbo -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 注册中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-registry-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 数据上报监控中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-metadata-report-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>
```

#### Provider | HelloWorld

##### XML 配置环境 & 接口

```xml
<beans "...">
    <!-- 应用配置 -->
    <dubbo:application name="demo-xml-provider" />
    <!-- 注册中心配置 -->                                         
    <dubbo:registry id="registry" address="zookeeper://127.0.0.1:2181"/>
    <!-- 协议配置 -->                                                         
    <dubbo:protocol name="dubbo" port="20880"/>
    <!-- 接口配置 -->
    <dubbo:service interface="com.end.dubbo.api.service.OrderService" ref="orderService"/>
   	<!-- SpringBean注入 -->
    <bean id="orderService" class="com.end.dubbo.service.OrderServiceImpl"/>
    <!-- 监控中心元数据上报配置 -->
    <dubbo:metadata-report address="zookeeper://127.0.0.1:2181"/>
</beans>
```

##### 实现类

```java
// 服务提供方
public class DubboXMLProvider {
    public static void main(String[] args) throws Exception {
        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("dubbo-provider.xml");
        context.start();

        System.out.println("xml provider 启动ing");
        System.in.read();
    }
}

// 订单服务
public class OrderServiceImpl implements OrderService {
    @Override
    public OrderDTO getOrder(String orderNo) {
        System.out.println("Provider OrderService getOrder start, orderNo:" + orderNo);
        OrderDTO orderDTO = new OrderDTO(1L, "no1", "订单1");
        System.out.println("Provider OrderService getOrder end, orderNo:" + orderNo + ", orderDTO:" + orderDTO.toString());
        return orderDTO;
    }
}
```

#### Consumer | HelloWorld

##### XML 配置环境 & 引用

```xml
<beans "...">
    <!-- SpringBean扫描 -->
    <context:component-scan base-package="com.end.dubbo.user.impl" />
	<!-- 应用配置 -->
    <dubbo:application name="demo-xml-consumer" />
	<!-- 注册中心配置 -->
    <dubbo:registry address="zookeeper://127.0.0.1:2181"/>
	<!-- 接口配置 -->
    <dubbo:reference id="orderService" interface="com.end.dubbo.api.service.OrderService" check="false"/>
</beans>
```

##### 调用类

```java
// user服务：服务消费方
public interface UserService {
    String getOrderInfo(String orderNo);
}
@Service
public class UserServiceImpl implements UserService {
    @Autowired
    private OrderService orderService;

    @Override
    public String getOrderInfo(String orderNo) {
        System.out.println("Consumer UserService getOrderInfo start, orderNo:" + orderNo);

        // 远程服务调用
        OrderDTO orderDTO = orderService.getOrder(orderNo);
        System.out.println("Consumer orderService.getOrderInfo end, orderNO:" + orderNo + ",orderDTO:" + orderDTO);
        return orderDTO.toString();
    }
}
```

#### SpringBoot POM 依赖

```xml
<!-- Dubbo、Spring整合 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-spring-boot-starter</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 注册中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-registry-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>

<!-- 数据上报监控中心 -->
<dependency>
    <groupId>org.apache.dubbo</groupId>
    <artifactId>dubbo-metadata-report-zookeeper</artifactId>
    <version>2.7.3</version>
</dependency>
```

#### SpringBoot Provider | HelloWorld

##### YML 配置环境

当然也可以用 XML 进行统一配置。

```yaml
dubbo:
  # 应用配置
  application:
    name: dubbo-annotation-provider
  # 注册中心配置
  registry:
    address: zookeeper://127.0.0.1:2181
  # 协议配置
  protocol:
    name: dubbo
    port: 20882
  # 数据上报监控中心
  metadata-report:
    address: zookeeper://127.0.0.1:2181
```

##### 注解配置接口

```java
// 订单服务
@org.apache.dubbo.config.annotation.Service(version = "1.0.0", group = "end1", methods = { 
    @Method(name = "getOrder", timeout = 1) 
})
public class OrderServiceImpl implements OrderService {
    @Override
    public OrderDTO getOrder(String orderNo) {
        System.out.println("Provider OrderService getOrder 2 start, orderNo:" + orderNo);
        OrderDTO orderDTO = new OrderDTO(1L, "no1", "订单11");
        System.out.println("Provider OrderService getOrder 2 end, orderNo:" + orderNo + ", orderDTO:" + orderDTO.toString());
        return orderDTO;
    }
}

// 服务提供方，启用Dubbo
@SpringBootApplication
@EnableDubbo
public class DubboAnnotationConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(DubboAnnotationConsumerApplication.class, args);
    }
}
```

#### SpringBoot Consumer | HelloWorld

##### YML 配置环境

```yaml
dubbo:
  # 应用配置
  application:
    name: dubbo-annotation-consumer
  # 注册中心配置
  registry:
    address: zookeeper://127.0.0.1:2181
  # 协议配置
  protocol:
    name: dubbo
    port: 20882
  # 数据上报监控中心
  metadata-report:
    address: zookeeper://127.0.0.1:2181

```

##### 注解配置引用

```java
// user服务
@Service
public class UserServiceImpl implements UserService {
    @org.apache.dubbo.config.annotation.Reference(
        group = "end1", version = "1.0.0", timeout = 2000, loadbalance = "roundrobin", cluster = ""
    )
    private OrderService orderService;

    @Override
    public String getOrderInfo(String orderNo) {
        System.out.println("annotation Consumer UserService getOrderInfo start, orderNo:" + orderNo);

        OrderDTO orderDTO = orderService.getOrder(orderNo);
        System.out.println("annotation Consumer orderService.getOrderInfo end, orderNO:" + orderNo + ",orderDTO:" + orderDTO);
        return orderDTO.toString();
    }
}

// 服务消费方，启用Dubbo
@SpringBootApplication
@EnableDubbo
public class DubboAnnotationConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(DubboAnnotationConsumerApplication.class, args);
    }
}

```

#### SpringBoot | Java Bean 配置1

```java
// 服务提供方Java Bean 配置1：注入实现类
@Configuration
@DubboComponentScan(basePackages = "com.end.dubbo.service.impl")
public class DubboDemoOtherProviderAPIConfig {
    @Bean
    public ServiceConfig<OrderService> orderServiceConfig(OrderService orderService){
        // 应用配置
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-demo-other-provider-api");

        // 注册中心配置
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("127.0.0.1:2181");

        // 协议配置
        ProtocolConfig protocolConfig = new ProtocolConfig();
        protocolConfig.setName("dubbo");
        protocolConfig.setPort(20881);

        // 元数据上报配置
        MetadataReportConfig metadataReportConfig = new MetadataReportConfig();
        metadataReportConfig.setAddress("zookeeper://127.0.0.1:2181");

        // 接口方法配置
        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName("getOrder");
        methodConfig.setTimeout(1);
        
        // 接口配置
        ServiceConfig<OrderService> serviceConfig = new ServiceConfig<>();
        serviceConfig.setInterface(OrderService.class);
        serviceConfig.setRef(orderService);
        serviceConfig.setVersion("1.0.0");
        serviceConfig.setGroup("end4");
        serviceConfig.setApplication(applicationConfig);
        serviceConfig.setRegistry(registryConfig);
        serviceConfig.setProtocol(protocolConfig);
        serviceConfig.setMetadataReportConfig(metadataReportConfig);
		serviceConfig.setMethods(Lists.newArrayList(methodConfig));
        
        // 服务暴露
        serviceConfig.export();
        return serviceConfig;
    }
}

```

#### SpringBoot | Java Bean 配置2

```java
// 服务提供方Java Bean 配置2：注入实现类
@Configuration
@DubboComponentScan(basePackages = "com.end.dubbo.service.impl")
public class DubboDemoOtherProviderConfig {
    // 应用配置
    @Bean
    public ApplicationConfig applicationConfig(){
        ApplicationConfig applicationConfig = new ApplicationConfig();
        applicationConfig.setName("dubbo-demo-other-provider-api");
        return applicationConfig;
    }

    // 注册中心配置
    @Bean
    public RegistryConfig registryConfig(){
        RegistryConfig registryConfig = new RegistryConfig();
        registryConfig.setProtocol("zookeeper");
        registryConfig.setAddress("127.0.0.1:2181");
        return registryConfig;
    }

    // 协议配置
    @Bean
    public ProtocolConfig protocolConfig(){
        ProtocolConfig protocolConfig = new ProtocolConfig();
        protocolConfig.setName("dubbo");
        protocolConfig.setPort(20881);
        return protocolConfig;
    }

    // 元数据上报配置
    @Bean
    public MetadataReportConfig metadataReportConfig(){
        MetadataReportConfig metadataReportConfig = new MetadataReportConfig();
        metadataReportConfig.setAddress("zookeeper://127.0.0.1:2181");
        return metadataReportConfig;
    }

    // 服务配置
    @Bean
    public ServiceConfig<OrderService> orderServiceConfig(OrderService orderService){
        ServiceConfig<OrderService> serviceConfig = new ServiceConfig<>();
        serviceConfig.setInterface(OrderService.class);
        serviceConfig.setRef(orderService);
        serviceConfig.setVersion("1.0.0");
        serviceConfig.setGroup("end3");

        MethodConfig methodConfig = new MethodConfig();
        methodConfig.setName("getOrder");
        methodConfig.setTimeout(1);
        serviceConfig.setMethods(Lists.newArrayList(methodConfig));

        return serviceConfig;
    }
}
```

### 1.8. Dubbo 常用高级配置？

#### 开发与测试

##### 启动时检查

1. `check="true"` 默认会在应用启动时，检查依赖的服务是否可用，不可用则会抛出异常，阻止 Spring 初始化完成，以便上线前，能及早发现问题。
2. 可以通过 `check="false"` 关闭检查，比如测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动时。
3. 如果 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请设置 `check=false`，否则由于拿到 null 引用，代表服务临时不可用时，会抛出异常，而如果 `check="false"`，当服务恢复时，能自动连上，总是会返回引用，而不会报错。

| 标签            | 属性  | 作用                                           |
| --------------- | ----- | ---------------------------------------------- |
| dubbo:reference | check | 关闭**某个服务**的启动时检查，没有提供者时报错 |
| dubbo:consumer  | check | 关闭**所有服务**的启动时检查，没有提供者时报错 |
| dubbo:registry  | check | 关闭**注册中心**启动时检查，注册订阅失败时报错 |

##### 点对点直连

点对点直连方式，可以以服务接口为单位，忽略注册中心的提供者列表，另外，A 接口配置点对点，并不影响 B 接口从注册中心获取列表。

- 在**开发及测试**环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连。
- 为了避免复杂化线上环境，不要在线上使用这个功能，只应在**测试阶段**使用。

| 标签            | 属性 | 作用                                                  |
| --------------- | ---- | ----------------------------------------------------- |
| dubbo:reference | url  | 配置 url 指向提供者，绕过注册中心，多个地址用分号隔开 |

##### 多版本

- 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。
- 升级时，可以按照以下的步骤进行版本迁移：
  1. 在低压力时间段，先升级一半提供者为新版本。
  2. 再将所有消费者升级为新版本。
  3. 然后将剩下的一半提供者升级为新版本。

| 标签            | 属性    | 作用                         |
| --------------- | ------- | ---------------------------- |
| dubbo:service   | version | 提供服务的版本号，比如 1.0.0 |
| dubbo:reference | version | 消费服务的版本号，比如 1.0.0 |

##### 服务分组

当一个接口有多种实现时，可以用 group 区分，区分服务接口的不同实现。

| 标签            | 属性  | 作用           |
| --------------- | ----- | -------------- |
| dubbo:service   | group | 提供服务的分组 |
| dubbo:reference | group | 消费服务的分组 |

##### 泛化调用

Dubbo 支持 Json 字符串参数的泛化调用，即直接传递字符串来完成一次调用，无需具体的 JAR 包或接口。

- **优点**：扩展性、跨语⾔、轻量级。
- **使用场景**：⼀般使⽤在⽹关类项⽬中，在平常业务开发中基本不会使⽤。

###### API 方式

```java
// API方式 引用远程服务
// 该实例很重要，里面封装了所有与注册中心及服务提供方连接，请缓存
ReferenceConfig<GenericService> reference = new ReferenceConfig<GenericService>();
// 弱类型接口名
reference.setInterface("com.end.dubbo.api.service.OrderService");
// 声明为泛化接口
reference.setGeneric(true);
// 用com.alibaba.dubbo.rpc.service.GenericService可以替代所有接口引用
GenericService genericService = reference.get();
Object result = genericService.$invoke("getOrder", new String[] { "java.lang.String" }, new Object[]{ "ccc" });

```

###### Spring 注入方式

| 标签            | 属性    | 作用                                                      |
| --------------- | ------- | --------------------------------------------------------- |
| dubbo:reference | generic | 默认为 false，代表不启用泛化调用，true 则代表启用泛化调用 |

```java
// <dubbo:reference id="orderService"  // interface="com.end.dubbo.api.service.OrderService" generic="true"/>

// 通过spring
ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("dubbo-generic-consumer.xml");
GenericService orderService = (GenericService) context.getBean("orderService");

```

#### 服务高可用

##### 服务超时

| 标签            | 属性    | 作用                                                  |
| --------------- | ------- | ----------------------------------------------------- |
| dubbo:service   | timeout | 远程服务调用的超时时间，默认为 1000ms                 |
| dubbo:reference | timeout | 服务方法调用的超时时间，默认为 dubbo:consumer#timeout |
| dubbo:consumer  | timeout | 服务方法调用的超时时间，默认为 1000ms                 |

##### 重试次数

Dubbo 服务在尝试调用一次之后，如出现非业务异常，比如服务突然不可用、超时等，默认会进行额外的最多 2 次的重试。

| 标签           | 属性    | 作用              |
| -------------- | ------- | ----------------- |
| dubbo:consumer | retries | 默认额外重试 2 次 |

##### 集群容错

在集群**调用失败**时，Dubbo 提供 6 种集群容错方案，缺省为 `failover` 失败自动切换，可通过 SPI 自行扩展。

| 标签            | 属性    | 作用                   |
| --------------- | ------- | ---------------------- |
| dubbo:service   | cluster | 服务提供方配置集群模式 |
| dubbo:service   | weight  | 服务权重               |
| dubbo:reference | cluster | 消费方配置集群模式     |

##### 负载均衡

在集群负载均衡时，Dubbo 提供了  4 种负载均衡策略，缺省为 `random` 随机调用，可通过 SPI 自行扩展。

| 标签                         | 属性        | 作用           |
| ---------------------------- | ----------- | -------------- |
| dubbo:service                | loadbalance | 服务端服务级别 |
| dubbo:service#dubbo:method   | loadbalance | 服务端方法级别 |
| dubbo:reference              | loadbalance | 客户端服务级别 |
| dubbo:reference#dubbo:method | loadbalance | 客户端方法级别 |

##### 服务降级

服务降级，可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。

```java
RegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();

Registry registry = registryFactory.getRegistry(URL.valueOf("zookeeper://10.20.153.10:2181"));

// 向注册中心写入动态配置覆盖规则
registry.register(URL.valueOf("override://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&mock=force:return+null"));

```

| 降级策略               | 作用                                                         | 适用场景                                 |
| ---------------------- | ------------------------------------------------------------ | ---------------------------------------- |
| mock=force:return+null | 表示消费方对该服务的方法调用，都直接强制返回 null 值，不发起远程调用 | 用于屏蔽不重要服务不可用时对调用方的影响 |
| mock=fail:return+null  | 表示消费方对该服务的方法调用在失败后，才返回 null 值，而不抛异常 | 用来容忍不重要服务不稳定时对调用方的影响 |

##### 服务限流

| 标签            | 属性     | 作用                                                         |
| --------------- | -------- | ------------------------------------------------------------ |
| dubbo:service   | executes | 服务提供者的，每个服务的，每个方法的，最大可**并行**执行请求数 |
| dubbo:reference | actives  | 每个服务消费者的，每个服务的，每个方法的，最大**并发**调用数 |

#### 服务高性能

##### 请求派发策略

Dubbo 中的线程模型，可以通过不同的**请求派发策略**，和不同的**线程池类型**的组合，来应对不同的场景:

1. 如果事件处理的逻辑能**迅速完成**，并且不会发起新的 IO 请求，比如只是在内存中记个标识，则直接在 IO 线程上处理更快，因为减少了线程池调度。
2. 但如果事件处理**逻辑较慢**，或者需要发起新的 IO 请求，比如需要查询数据库，则必须派发到线程池，否则 IO 线程阻塞，将导致不能接收其它请求。
3. 如果用 IO 线程处理事件，又在事件处理过程中**发起新的 IO 请求**，比如在连接事件中发起登录请求，会报**“可能引发死锁”异常**，但不会真死锁。

| 标签           | 属性       | 作用         |
| -------------- | ---------- | ------------ |
| dubbo:protocol | dispatcher | 请求派发策略 |

##### 线程池类型

| 标签           | 属性       | 作用       |
| -------------- | ---------- | ---------- |
| dubbo:protocol | threadpool | 线程池类型 |
| dubbo:protocol | threads    | 最大线程数 |

##### 服务协议

###### 配置方式

| 标签          | 属性     | 作用                                                         |
| ------------- | -------- | ------------------------------------------------------------ |
| dubbo:service | protocol | 使用指定的协议暴露服务，在多协议时使用，值为 dubbo:protocol 的引用，并用逗号分隔 |

###### 协议汇总

| 协议       | 说明                                                         | 适用场景                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Dubbo      | 单一长连接和 NIO 异步通讯，基于 TCP 协议，默认采用 Hessian 序列化，是 Dubbo 推荐使用的协议 | 适合大并发、小数据量的服务调用，消费者远大于提供者的场景     |
| RMI        | JDK 标准的 RMI 协议实现，采用 Java 标准序列化机制，传输参数和返回参数对象都需要实现 Serializable 接口，阻塞式短连接，基于 TCP 协议，数据包大小混合，可支持传输文件 | 多个短连接同步传输，适用常规的远程服务调用以及 RMI 互操作，但在依赖低版本的 Common-Collections 包时，Java 序列化存在安全漏洞 |
| WebService | 基于 HTTP#WebService 协议，需要集成 CXF 实现，提供与原生 WebService 的互操作 | 多个短连接同步传输，适用于系统集成和跨语言调用               |
| HTTP       | 基于 Http 协议，使用 Spring#HttpInvoke 实现                  | 适用于多个短连接、数据包大小混合、提供者个数多于消费者、需要给应用程序和浏览器 JS 调用的场景 |
| Hessian    | 集成 Hessian 服务，基于 HTTP 协议，采用 Servlet 暴露服务，Dubbo 内嵌 Jetty 作为服务器时的默认实现，提供与 Hession 服务互操作，采用 Hessian 序列化 | 多个短连接同步传输，适用于传入参数较大、提供者大于消费者、提供者压力较大的场景，比如传输文件 |
| Memcache   | 基于 Memcache实现的 RPC 协议                                 | -                                                            |
| Redis      | 基于 Redis 实现的RPC协议                                     | -                                                            |

###### 性能压测

1. 1k string 场景，压测得到的平均响应时间为：dubbo 2 > dubbo 1 > hessian > rmi > http。 

   ![1636884067979](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636884067979.png)

2. 200k string 场景，压测得到的平均响应时间为：rmi > http > hessian > dubbo 2 > dubbo 1。 

   ![1636884139136](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636884139136.png)

3. 因此，可见，小数据包传输时，Dubbo 2/Dubbo 1 性能最高，RMI/Http 性能最低；大数据包传输时，Http/RMI 性能最高，Dubbo 2/Dubbo 1 性能最低。

#### 配置总结

##### 配置方式汇总

XML 配置、注解配置、属性⽂件 properties/yaml 配置、-D JVM 参数配置、代码编码⽅式配置、配置中心配置。

##### XML 标签汇总

| 标签                   | 用途         | 解释                                                         |
| ---------------------- | ------------ | ------------------------------------------------------------ |
| 方法参数配置：         |              |                                                              |
| `<dubbo:argument/>`    | 参数配置     | 用于指定方法参数配置                                         |
| `<dubbo:method/>`      | 方法配置     | 用于 ServiceConfig 和 ReferenceConfig 指定方法级的配置信息   |
|                        |              |                                                              |
| 服务提供方配置：       |              |                                                              |
| `<dubbo:service/>`     | 服务配置     | 用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心 |
| `<dubbo:provider/>`    | 提供方配置   | 当 ProtocolConfig 和 ServiceConfig 某属性没有配置时，采用此缺省值，可选 |
| `<dubbo:protocol/>`    | 协议配置     | 用于配置提供服务的协议信息，协议由提供方指定，消费方被动接受 |
|                        |              |                                                              |
| 服务消费方配置：       |              |                                                              |
| `<dubbo:reference/>`   | 引用配置     | 用于创建一个远程服务代理，一个引用可以指向多个注册中心       |
| `<dubbo:consumer/>`    | 消费方配置   | 当 ReferenceConfig 某属性没有配置时，采用此缺省值，可选      |
|                        |              |                                                              |
| 其他应用级配置：       |              |                                                              |
| `<dubbo:application/>` | 应用配置     | 用于配置当前应用信息，不管该应用是提供者还是消费者           |
| `<dubbo:registry/>`    | 注册中心配置 | 用于配置连接注册中心相关信息                                 |
| `<dubbo:monitor/>`     | 监控中心配置 | 用于配置连接监控中心相关信息，可选                           |
| `<dubbo:module/>`      | 模块配置     | 用于配置当前模块信息，可选                                   |

##### 配置方式覆盖策略

精确优先（比如方法大于全局等）、就近优先（比如 JVM 大于配置文件、消费者大于提供者等）。

1. **配置中心/-D JVM参数 优先**：这样可以使用户在部署和启动时，进行参数重写，比如在启动时需改变协议的端口。
2. **XML/注解/代码配置 次之**：如果在 XML 中有配置，则 dubbo.properties 中的相应配置项无效。
3. **properties/yml 最后**：相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。

![1636881626159](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636881626159.png)

##### XML  标签覆盖顺序

精确优先（比如方法大于全局等）、就近优先（比如 JVM 大于配置文件、消费者大于提供者等）。

1. **⽅法级优先**：当级别⼀样时，消费⽅优先，提供⽅次之。
   - 下面与这类似，提供方配置就像是消费方的缺省值，只有在无消费方配置时才会生效，这样可以留机会给消费方做配置改写。
   - 而全局配置就像是接口级的缺省值，接口级配置就像是方法级的缺省值，这样可以留机会到接口、方法层面做配置改写。
2. **接⼝级次之**：级别⼀样时，消费⽅优先，提供⽅次之。
3. **全局配置再次之**：级别⼀样时，消费⽅优先，提供⽅次之。

![1636882183556](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636882183556.png)

### 1.9. 详细介绍 Dubbo 架构设计？

#### 整体设计

- 图中左边淡蓝背景的为**服务消费方**使用的接口，右边淡绿色背景的为**服务提供方**使用的接口，位于中轴线上的为双方都用到的接口。
- 图中从下至上分为十层，各层均为单向依赖，右边的黑色箭头代表层之间的**依赖关系**，每一层都可以剥离上层被复用，其中，Service 和 Config 层为 API，其它各层均为 SPI。
- 图中绿色小块的为**扩展接口**，蓝色小块为**实现类**，图中只显示用于关联各层的实现类。
- 图中蓝色虚线为**初始化过程**，即启动时组装链，红色实线为**方法调用过程**，即运行时调时链，紫色三角箭头为**继承**，可以把子类看作父类的同一个节点，线上的文字为调用的方法。

![1636607155860](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636607155860.png)

#### 各层说明

1. **Service**：业务接⼝层，与业务逻辑相关，是**用户**根据 Provider 和 Consumer 的业务，设计对应的接⼝ `Interface` 和对应的实现 `Implement` 。
2. **config**：配置层，对外配置接口，可以直接初始化配置类，也可以通过 Spring 解析配置生成配置类。
3. **proxy**：服务代理层，服务接口透明代理，生成客户端和服务器端存根，封装了所有接口的透明化代理，再暴露给用户使用时，消费方使用 Proxy 将 `Invoker` 转成接口，提供方将接口实现转成 `Invoker`，所以，去掉 Proxy 层，RPC 是可以 Run 的，只是不那么透明，不那么看起来像调本地服务一样调远程服务而已。
4. **registry**：注册中心层，封装服务地址的注册与发现，Registry 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
5. **cluster**：路由层，封装多个提供者的路由及负载均衡，并桥接注册中心，该层是一个外围概念，即将多个 `Invoker` 伪装成一个 `Invoker`，使得用户只要关注 Protocol 层 `Invoker` 即可，而加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，另外，只有一个提供者时，是不需要 Cluster 的。
6. **monitor**：监控层，记录 RPC 调用次数和调用时间的监控，Monitor 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
7. **protocol**：远程调用层，核心层，封装 RPC 调用，只要有该层的 `Invoker` + `Exporter` 就可以完成非透明的 RPC 调用。
8. **exchange**：信息交换层，封装请求响应模式、同步转异步，在 transport 层上封装了 Request-Response 的语义，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
9. **transport**：网络传输层，负责消息传输，是对 Mina、Netty、Grizzly 的抽象，也可以扩展为 UDP 传输，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
10. **serialize**：数据序列化层，提供一些相关工具，默认序列化使用 Hessian2Serialization，另外还有 FastJsonSerialization、JavaSerialization、ProtostuffSerialization 等序列化方式。

#### 模块分包

![1636636045364](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636636045364.png)

- **dubbo-common**：公共逻辑模块，包括 Util 类和通用模型。
  - `serialize` 层放在 common 模块中，以便更大程度复用。
- **dubbo-remoting**：远程通讯模块，Dubbo 协议的实现，如果 RPC 用 RMI协议，则不需要使用此包。
  - `transport` 层和 `exchange` 层都放在 remoting 模块中，作为 rpc 调用的通讯基础，由于 Remoting 实现是 Dubbo 协议，如果选择了 RMI 协议，则整个 Remoting 都不会用上。
- **dubbo-rpc**：远程调用模块，抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。
  - `protocol` 层和 `proxy` 层都放在该模块中，这两层是 rpc 的核心，在不需要集群即只有一个提供者时，只使用这两层即完成 rpc 调用。
- **dubbo-cluster**：集群模块，将多个服务提供方伪装为一个提供方，包括：负载均衡、容错、路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发的。
  - `cluster` 层，属于一个外围概念，即加上 Cluster 或者去掉 Cluster 对其它层都不会造成影响，另外，只有一个提供者时，是不需要 Cluster 的。
- **dubbo-registry**：注册中心模块，基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。
  - `Registry` 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
- **dubbo-monitor**：监控模块，统计服务调用次数、调用时间和调用链跟踪。
  - `Monitor` 实际上不算一层，而是一个独立的节点，只是为了全局概览，用层的方式画在了一起。
- **dubbo-config**：配置模块，Dubbo 对外的 API，隐藏 Dubbo 所有细节，用户可通过 Config 使用 Dubbo。
  - `config` 配置层，对外配置接口，可以直接初始化配置类，也可以通过 Spring 解析配置生成配置类。
- **dubbo-container**：容器模块，是一个可独立启动的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性，因此没必要用 Web 容器去加载服务。
  - container 是服务容器，用于部署运行服务，所以没有在分层架构中画出。

#### 架构原理

![1636876443919](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636876443919.png)

- Provider 启动时，把所有接口注册到注册中心，并且订阅动态配置 configurators，以及后台启动定时器，定时发送统计数据给 Monitor。
- Consumer 启动时，会订阅 providers、configurators、routers，在这些订阅内容发生变化时，ZK 会推送相关订阅的信息，并且与 Provider 建立长连接，方便以后数据通信，以及后台启动定时器，定时发送统计数据给 Monitor。

### 2.0. Dubbo 源码术语汇总？

| 术语          | 作用                                                         | 分类                                                         |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| @Adaptive     | 动态扩展一个类或者一个方法，1）注解在类上，代表类本身就是一个装饰类，只经过人工编码，不会生成代理类；2）注解在方法上，代表会自动生成和编译一个动态类，比如 Protocol$Adaptive，该类使用代码模板技术，通过 javassist 动态代理，生成装饰方法，该方法添加了根据URL参数获取 SPI 扩展类的逻辑 | 两种注解方式，注解在类上和注解在方法上                       |
| ObjectFactory | 为 Dubbo IOC 提供所有对象                                    | 1）ExtensionLoader 的ObjectFactory 为 null；2）其余的在 Spring 环境下为SpringExtensionFactory |
| proxyFatory   | 获取一个接口的代理类，有两个方，getInvoker()：针对Server端，用于把实现类包装成一个Invoker javasist代理对象，getProxy()：针对Client端，用于创建服务引用接口的代理对象 | JavassistProxyFactory、JdkProxyFactory                       |
| Wrapper       | 包装一个接口或者类，以实现通过wrapper复制或者定制方法调用    | 多种 Wrapper 结尾的扩展类                                    |
| Protocol      | 服务域，是 Invoker 暴露和引⽤的主功能⼊⼝，负责 Invoker 的⽣命周期管理，有两个方法：1）export：针对Server端，暴露远程服务，把实现类代理Invoker通过协议、打开Netty服务器暴露外部；2）refer：针对客户端，？？？ | InjvmProtocol、RegistryProtocol、DubboProtocol、MockProtocolRedisProtocol、ThriftProtocol、MemcachedProtocol 等 |
| Invoker       | 实体域，是 Dubbo 的核⼼模型，一个可执行对象，能够根据方法的名称、参数得到相应的结果 | 多种实现类，但主要包括3种类型：1）本地执行类型的Invoker；2）远程通信类型的Invoker；3）包含多个远程通信Invoker聚合成的集群类型Invoker |
| Invocation    | 会话域，持有调⽤过程中的变量，⽐如⽅法名、参数等             | RpcInvocation                                                |
| exporter      | 维护Invoker的生命周期，可在exporters缓存map中获取各种包装了Invoker的exporters | InjvmExporter、DubboExporter、DestroyableExporter            |
| exchanger     | 信息交换层，封装请求响应模式，比如利用Netty NIO特性，把同步操作转换为I/O监听的异步操作 | HeaderExchanger                                              |
| transporter   | 网络传输层，用来抽象Netty和Mina的统一接口                    | netty.NettyTransporter、netty4.NettyTransporter、MinaTransporter、GrizzlyTransporter |
| ZK 结点       | 持久化结点：一旦被创建，除非主动删除掉，否则一直存储在 ZK 中；临时结点：与客户端会话绑定，一旦客户端会话失效，该客户端所创建的所有临时结点都会被删除，进而触发监听器事件的回调 | CreateMode.PERSISTENT（持久化结点）、CreateMode.EPHEMERAL（非持久化结点） |
| Directory     | 目录服务，装载各种Invoker，为提供Cluster查找的数据           | StaticDirectory，静态目录服务，Invoker是固定的，用于最外层的固定封装；RegistryDirectory，注册目录服务，Invoker来源于ZK，由于实现了NotifyListener接口，在ZK 通知服务信息发生变更时，会回调notify方法，然后刷新对应的Invoker集合 |

### 2.1. 什么是 Dubbo SPI？

#### API 与 SPI 的区别？

![1636461572100](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636461572100.png)

|          | API                                             | SPI                                                     |
| -------- | ----------------------------------------------- | ------------------------------------------------------- |
| 概念     | Application Programming Interface，应用程序接口 | Service Provider Interface，服务提供接口                |
| 接口实现 | 服务提供方，提供接口的不同实现                  | 客户消费方，不同消费方对同一接口，会提供不同的实现      |
| 接口调用 | 客户消费方，根据不同接口选择不同的实现          | 服务提供方，提供统一的接口                              |
| 应用场景 | 开发框架等提供的 API 支持                       | 数据库驱动、日志框架、Dubbo 扩展点、SpringBoot 自动装配 |

#### JDK SPI

##### 概念

一个简单的 JDK 服务提供者加载工具 `ServiceLoader`：

1. 通过在资源目录 `META-INF/services` 中，放置以 Provider 接口名作为配置文件名称，来标识 SPI 扩展点。
2. 其中，重复的扩展项将会被忽略。
3. 但是，`ServiceLoader` 非线程安全，不适用于多个并发线程。

##### 例子

###### 1、统一接口

```java
package jdk.spi;

// 动物接口
public interface Animal {
    void say();
}

```

###### 2、不同实现类

```java
// 猫实现类
public class Cat implements Animal {
    @Override
    public void say() {
        System.out.println("cat saying");
    }
}

// 狗实现类
public class Dog implements Animal {

    @Override
    public void say() {
        System.out.println("dog saying");
    }
}

```

###### 3、SPI 扩展配置

```properties
#./resources/META-INF/services/jdk.spi.Animal
jdk.impl.Dog
jdk.impl.Cat

```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ServiceLoader<Animal> serviceLoader = ServiceLoader.load(Animal.class);
        // dog saying，cat saying
        serviceLoader.forEach(Animal::say);
    }
}

```

##### 原理

1. 在 `ServiceLoader#load` ⽅法中，⾸先，会获取上下⽂类加载器，然后构造⼀个 `ServiceLoader`，而在 `ServiceLoader` 中有⼀个懒加载器，懒加载器会通过 `BufferedReader` 从 `META-INF/services` 路径下找到**对应的接⼝名**的全路径名⽂件，也就是SPI 扩展配置的⽂件。
2. 然后，通过⽂件的类解析器，读取⽂件中的内容。
3. 接着，再通过类加载器加载类的全路径，把所扩展的类加载到内存中。

```java
package java.util;

public final class ServiceLoader<S> implements Iterable<S>
{
	private static final String PREFIX = "META-INF/services/";

    // 1、使用当前线程的{@linkplain java.lang.Thread＃getContextClassLoader上下文类加载器}，为给定的服务类型创建一个新的服务加载器
    public static <S> ServiceLoader<S> load(Class<S> service) {
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        return ServiceLoader.load(service, cl);
    }
    
    // 2、为给定的服务类型和类加载器创建一个新的服务加载器。
    public static <S> ServiceLoader<S> load(Class<S> service,
                                            ClassLoader loader)
    {
        return new ServiceLoader<>(service, loader);
    }
    
    // 3、重新加载 -> 没作并发同步，所以非线程安全
    private ServiceLoader(Class<S> svc, ClassLoader cl) {
        service = Objects.requireNonNull(svc, "Service interface cannot be null");
        loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl;
        acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null;
        reload();
    }
    public void reload() {
        providers.clear();
        lookupIterator = new LazyIterator(service, loader);
    }
    
    // 4、SPI迭代器
    private class LazyIterator implements Iterator<S> {
        Class<S> service;
        ClassLoader loader;
        
        private LazyIterator(Class<S> service, ClassLoader loader) {
            this.service = service;
            this.loader = loader;
        }
        
        // 5、迭代器遍历时调用
        private S nextService() {
            if (!hasNextService())
                throw new NoSuchElementException();
            String cn = nextName;
            nextName = null;
            Class<?> c = null;
            try {
            	// 6、加载SPI扩展类
                c = Class.forName(cn, false, loader);
            } catch (ClassNotFoundException x) {
                fail(service, "Provider " + cn + " not found");
            }
            if (!service.isAssignableFrom(c)) {
                fail(service, "Provider " + cn  + " not a subtype");
            }
            try {
            	// 7、实例化SPI扩展类，实例化完成后并加入缓存
                S p = service.cast(c.newInstance());
                providers.put(cn, p);
                return p;
            } catch (Throwable x) {
                fail(service,
                     "Provider " + cn + " could not be instantiated",
                     x);
            }
            throw new Error();          // This cannot happen
        }
    }
}

```

#### Dubbo SPI

##### 例子 | 无 IOC

###### 1、统一接口

```java
package dubbo.spi;

// 人类接口 => 只有@SPI接口才会被SPI到
@org.apache.dubbo.common.extension.SPI
public interface Person {
    void say();
}

```

###### 2、不同实现类

```java
// 男人实现类
public class Man implements Person {
    @Override
    public void say() {
        System.out.println("man saying");
    }
}

// 女人实现类
public class Woman implements Person {
    @Override
    public void say() {
        System.out.println("woman saying");
    }
}

```

###### 3、SPI 扩展配置

```properties
# ./resources/META-INF/services/dubbo.spi.Person => 支持键值对形式配置
man=dubbo.impl.Man
woman=dubbo.impl.Woman

```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ExtensionLoader<Person> extensionLoader = ExtensionLoader.getExtensionLoader(Person.class);
        // 支持只加载某个键下的扩展类 => man saying
        Person man = extensionLoader.getExtension("man");
        man.say();
    }
}

```

##### 例子 | 有 IOC

###### 1、依赖 woman、cat

```java
public class Man implements Person {
    // 测试 Person IOC 注入
    private Person personDelegate;
    public void setWoman(Person personDelegate) {
        this.personDelegate = personDelegate;
    }
    
    // 测试 Animal IOC 注入
    private Animal animalDelegate;
    public void setCat(Animal animalDelegate) {
        this.animalDelegate = animalDelegate;
    }

    @Override
    public void say() {
        // 测试 Person IOC 注入 => woman saying
        personDelegate.say();
        // 测试 Animal IOC 注入 => cat saying
        animalDelegate.say();
    }
}

```

###### 2、注入 woman

$@Adaptive 动态代理类，代码生成模板格式：根据URL参数获取SPI扩展类。

![1636878858821](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636878858821.png)

```java
// .resources/META-INF/services/dubbo.spi.Person
// woman=dubbo.impl.Woman
@SPI
public interface Person {
    @Adaptive
    void say();
}

// @Adaptive注解在类上：代表类本身就是一个装饰类，只经过人工编码，不会生成代理类
// @Adaptive注解在方法上：代表会自动生成和编译一个动态的$Adaptive类，比如Protocol$Adaptive，该类使用代码模板技术，通过javassist动态代理，生成装饰方法，该方法添加了根据URL参数获取SPI扩展类的逻辑
@Adaptive
public class Woman implements Person {
    // 这里的Woman类明显不是装饰类，只是用于测试而已，下面的Cat类也一样
    @Override
    public void say() {
        System.out.println("woman saying");
    }
}

```

###### 3、注入 cat

```java
// .resources/META-INF/services/dubbo.spi.Animal
// cat=jdk.impl.Cat

@SPI
public interface Animal {
    void say();
}

@Adaptive
public class Cat implements Animal {
    @Override
    public void say() {
        System.out.println("cat saying");
    }
}

```

###### 4、测试方法

```java
public class SpiTest {
    public static void main(String[] args) {
        ExtensionLoader<Person> personExtensionLoader = ExtensionLoader.getExtensionLoader(Person.class);
        Person man = personExtensionLoader.getExtension("man");
        man.say();// woman saying、cat saying
    }
}

```

##### 原理

![1636877812612](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636877812612.png)

```java
package org.apache.dubbo.common.extension;

public class ExtensionLoader<T> {
    // 1、获取type对应的getExtensionLoader
    public static <T> ExtensionLoader<T> getExtensionLoader(Class<T> type) {
        ...// SPI注解校验
        ExtensionLoader<T> loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);
        if (loader == null) {
            // 2、创建type对应的getExtensionLoader
            EXTENSION_LOADERS.putIfAbsent(type, new ExtensionLoader<T>(type));
            loader = (ExtensionLoader<T>) EXTENSION_LOADERS.get(type);
        }
        return loader;
    }
    
    // 3、根据key获取SPI扩展类
    public T getExtension(String name) {
        return getExtension(name, true);
    }
    public T getExtension(String name, boolean wrap) {
        ...// 4、先从缓存中获取
        // 5、缓存获取不到，则用双重检查锁实例化 => 线程安全
        if (instance == null) {
            synchronized (holder) {
                instance = holder.get();
                if (instance == null) {
                    instance = createExtension(name, wrap);
                    holder.set(instance);
                }
            }
        }
    }

    // 6、实例化key对应的SPI扩展类
    private T createExtension(String name, boolean wrap) {
        // 11、根据key从key-Classes形式缓存中获取对应的class
        Class<?> clazz = getExtensionClasses().get(name);
        ... 
        // 12、利用Dubbo SPI IOC 注入接口实现类的实例 -> 接口上要有@SPI、注入的实现类上要有@Adaptive
        injectExtension(instance);
        
        if (wrap) {
            ...
            // 13. 通过wrapper包装类实现 Dubbo SPI 对 AOP 的支持，即将instance作为参数传递给wrapper，通过反射创建wrapper，再向wrapper实例中注入依赖，最后把包装后的实例作为instance返回
            instance = injectExtension((T) wrapperClass.getConstructor(type).newInstance(instance));
        }
        ...
        return instance;
    }

    // 12.1、Dobbo SPI IOC 注入核心方法
    private T injectExtension(T instance) {
        // 反射获取所有方法
        for (Method method : instance.getClass().getMethods()) {
            // 12.2、要有set方法
            if (!isSetter(method)) {
                continue;
            }
            
            // 12.3、可以注入
            if (method.getAnnotation(DisableInject.class) != null) {
                continue;
            }
            
            // 12.4、如果参数是基础类型就不注入, 因为这里注入指的是将加载的对象注入进来
            Class<?> pt = method.getParameterTypes()[0];
            if (ReflectUtils.isPrimitives(pt)) {
                continue;
            }
            
            // 12.5、获取要注入的属性名 -> 从@SPI扩展类中，获取对应接口和有@Adaptive的实现类
            String property = getSetterProperty(method);
            // ObjectFactory的作用是，为Dubbo IOC提供所有对象
            Object object = objectFactory.getExtension(pt, property);
            if (object != null) {
                // 12.6、反射调用set方法，完成注入
                method.invoke(instance, object);
            }
        }
    }
    
    private Map<String, Class<?>> getExtensionClasses() {
        ...
        // 7、加载SPI目录中所有的类，key-Classes形式放入缓存再返回
        classes = loadExtensionClasses();
        ...
    }
    
    // 8、SPI类加载核心方法
    private Map<String, Class<?>> loadExtensionClasses() {
        // 设置注解名称
        cacheDefaultExtensionName();
        
        // 9、加载读取配置文件：META-INF/services/、META-INF/dubbo/、META-INF/dubbo/internal/
         Map<String, Class<?>> extensionClasses = new HashMap<>();
        for (LoadingStrategy strategy : strategies) {
      		// 10、底层调用loadResource -> loadClass -> 加载对应Class -> extensionClasses
            loadDirectory(extensionClasses, strategy.directory(), type.getName(), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages
            // com.alibaba => org.apache
            loadDirectory(extensionClasses, strategy.directory(), type.getName().replace("org.apache", "com.alibaba"), strategy.preferExtensionClassLoader(), strategy.overridden(), strategy.excludedPackages());
        }
        
        // key-Classes形式
        return extensionClasses;
    }
}

```

#### JDK SPI 与 Dubbo SPI 的区别？

|                | JDK SPI                                                      | Dubbo SPI                                                    |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 按需加载       | 不能按需加载，只能一次性加载所有的扩展实现，有的扩展加载很耗时，如果后面没用上，会很浪费资源，所以若想只加载某个扩展类的实现，使用 JDK SPI 就不现实了 | 可以按需加载，只加载⾃⼰想要加载的扩展实现，通过 key-全限定类名 配置扩展文件，最后用 key 来获取指定的扩展类 |
| IOC和 AOP 支持 | 类之间的依赖关系无法解决，无法把⼀个实现类，注⼊到容器中，不支持 IOC 和 AOP | 对扩展点支持 IOC 和 AOP，一个扩展点可以直接 `setter` 注⼊其它扩展点，可以很好的⽀持第三⽅ IOC 容器，比如`Spring Bean`，另外通过 Wrapper 包装类实现 Dubbo SPI 对 AOP 的支持 |
| 线程安全       | `ServiceLoader` 非线程安全，会有线程安全的问题，即并发时扩展类可能会加载错误 | `ExtensionLoader` 线程安全，对扩展类进行实例化时，使用双重检查锁保证线程安全 |

### 2.2. Dubbo 与 Spring 融合原理？

![1636889489122](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636889489122.png)

#### 1、Spring 解析 XML 回调

基于 dubbo.jar 内的 `META-INF/spring.handlers` 配置，Spring 在遇到 Dubbo XML 配置的名称空间 `http\://dubbo.apache.org/schema/dubbo` 时，会回调 `DubboNamespaceHandler` ，而 `http\://dubbo.apache.org/schema/dubbo/dubbo.xsd` 则定义了 Dubbo XML 的标签语法。

```properties
# ../dubbo-2.7.3.jar!/META-INF/spring.handlers
http\://dubbo.apache.org/schema/dubbo=org.apache.dubbo.config.spring.schema.DubboNamespaceHandler

# ../dubbo-2.7.3.jar!/META-INF/spring.schemas
http\://dubbo.apache.org/schema/dubbo/dubbo.xsd=META-INF/dubbo.xsd

# Dubbo XML配置头内容
<beans ... 
# DubboNamespaceHandler
http://dubbo.apache.org/schema/dubbo
# dubbo.xsd
http://dubbo.apache.org/schema/dubbo/dubbo.xsd">
</bean>

```

#### 2、 XML 标签解析成 Bean 

所有 dubbo 的标签，都统一用 `DubboBeanDefinitionParser` 进行解析，基于一对一属性映射，将 XML 标签解析为 Bean 对象。

```java
package org.apache.dubbo.config.spring.schema;

// Dubbo XML配置统一解析器
public class DubboNamespaceHandler extends NamespaceHandlerSupport {
    @Override
    public void init() {
        ...
        // 这里主要看ServiceBean和ReferenceBean，其他的Dubbo配置解析也类似
        registerBeanDefinitionParser("service", new DubboBeanDefinitionParser(ServiceBean.class, true));
        registerBeanDefinitionParser("reference", new DubboBeanDefinitionParser(ReferenceBean.class, false));
        ...
    }
}

```

#### 3、Spring 加载时机回调

1. 在 `ServiceConfig.export()` 或 `ReferenceConfig.get()` 初始化时，将 Bean 对象转换 URL 格式，所有 Bean 属性转成 Dubbo#URL 的参数。
2. 然后将 Dubbo#URL 传给 Protocol 扩展点，基于扩展点的 SPI 机制，根据 Dubbo#URL 的协议头，进行不同协议的服务暴露或引用。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
    ...
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if (!isExported() && !isUnexported()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            // 实现Provider的服务发布
            export();
        }
    }
    ...
}

// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {
	...
    @Override
    public Object getObject() {
        // 实现Consumer的服务引用
        return get();
    }
    ...
}

```

### 2.3. Dubbo 服务发布原理？

![1636896497908](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896497908.png)

1. `ServiceConfig` 类拿到对外提供实现类 ref。

2. 然后通过 `ProxyFactory#getInvoker（）` 为 ref 生成一个 `AbstractProxyInvoker` 实例，到这一步就完成具体服务到 `Invoker` 的转化。

3. 接下来就是 `Invoker` 转换到 `Exporter` 的过程，而**服务暴露的关键**就这个过程，即图中红色的部分，其转换分为两种类型：

   - **暴露本地服务**：指服务暴露和引用都在同一个 JVM 里，自己调用自己接口，没必要进行远程通信。
     1. `InjvmProtocol#export（）` 把 invoker 转换为 `InjvmExporter`，并存进 exporters 缓存中。
   - **暴露远程服务**：指服务暴露给远程客户端IP和端口号，以实现远程通信。
     1. `DubboProtocol#export（）`  把 invoker 转换为 `DubboExporter`，然后打开 Netty 服务器暴露服务，并存进 exporters 缓存中。
     2. `RegistryProtocol#register（）`，使用 Curator 客户端建立 ZK 连接，注册 provider 持久化结点、service 非持久化结点、configurators 非持久化结点，并设置监听器，当非持久化结点发生变更，则会回调监听器的 `notify（）`，修改 invoker 信息。

   ![1637067703250](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637067703250.png)

#### 1、本地暴露服务

1. 构建实现类的动态代理对象，基于扩展点自适应机制，调用 `InjvmProtocol#export()` 方法获取 `InjvmExporter`，并存入 `exporters` 缓存中。

```java
// 1. ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
    ...
    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        if (!isExported() && !isUnexported()) {
            if (logger.isInfoEnabled()) {
                logger.info("The service ready on spring started. service: " + getInterface());
            }
            // 实现Provider的服务发布
            export();
        }
    }
    
    @Override
    public void export() {
        // 2. 实现Provider的服务发布
        super.export();
        publishExportEvent();
    }
}

// ServiceBean父类
public class ServiceConfig<T> extends AbstractServiceConfig {
    public synchronized void export() {
        ...
		doExport();
    }
    
    protected synchronized void doExport() {
        ...
        doExportUrls();
    }
    
    private void doExportUrls() {
        // 3. 获取dubbo.properties registry url配置
        List<URL> registryURLs = loadRegistries(true);
        
        // 4. 循环协议，说明一个服务支持多种协议
        for (ProtocolConfig protocolConfig : protocols) {
            String pathKey = URL.buildKey(getContextPath(protocolConfig).map(p -> p + "/" + path).orElse(path), group, version);
            ProviderModel providerModel = new ProviderModel(pathKey, ref, interfaceClass);
            ApplicationModel.initProviderModel(pathKey, providerModel);
            
            // 5. 根据协议配置，发布注册url
            doExportUrlsFor1Protocol(protocolConfig, registryURLs);
        }
    }
    
    private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 6. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 7. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            ...// 放在暴露远程服务中展开
        }
        ...
    }
    
    private void exportLocal(URL url) {
        ...
        // 9. 通过InjvmProtocol#export获取InjvmExporter
        Exporter<?> exporter = protocol.export(
            // 8. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, local));
        
        // 10. 最终目的：缓存每个服务的exporter到exporters中
        exporters.add(exporter);
        ...
    }
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        // 8.获取interfaceClass的javasist动态代理Wrapper包装类
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 动态代理调用实现类方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
}

// 9. 通过InjvmProtocol#export获取InjvmExporter
public class InjvmProtocol extends AbstractProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        return new InjvmExporter<T>(invoker, invoker.getUrl().getServiceKey(), exporterMap);
    }
}
```

#### 2、打开 Netty 服务器，远程暴露服务

![1636889534944](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636889534944.png)

1. 基于扩展点自适应机制，通过提供者 URL 的 `dubbo://` 协议头识别，就会调用 `DubboProtocol` 的 `export()` 方法，打开 Netty 服务器，利用 Netty NIO 特性，把同步操作转换为 I/O 监听的异步操作，以打开本地 Dubbo 服务，最后把 `DubboExporter` 缓存到 `exportes` 中。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
   	private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 1. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 2. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            // 3. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString()));
            DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);
            
            // 4. 通过RegistryProtocol#export暴露远程服务，获取对应的exporter
            Exporter<?> exporter = protocol.export(wrapperInvoker);
            
            // 18. 最终目的：缓存每个服务的exporter到exporters中
            exporters.add(exporter);
        }
        ...
    }
}    

public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 5. 打开Netty服务器，利用Netty NIO特性，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // ... 连接、订阅、监听ZK
    }
    
    private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
        String key = getCacheKey(originInvoker);
        return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
            Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
            // 6. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
            return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
        });
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 7. ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER));
    }
}

public class ProtocolListenerWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 8. ProtocolListenerWrapper监听扩展链装饰
        return new ListenerExporterWrapper<T>(protocol.export(invoker),            Collections.unmodifiableList(ExtensionLoader.getExtensionLoader(ExporterListener.class) .getActivateExtension(invoker.getUrl(), EXPORTER_LISTENER_KEY)));
    }
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
		...
        // 9. 组装（key=xxx.DemoService：20880，value=DubboExporter）到exporterMap
        DubboExporter<T> exporter = new DubboExporter<T>(invoker, key, exporterMap);
        exporterMap.put(key, exporter);
        ...
        // 10. 打开Netty服务器，暴露本地Dubbo服务
        openServer(url);
        ...
    }
    
    private void openServer(URL url) {
        ...
        serverMap.put(key, createServer(url));
        ...
    }
    
    private ExchangeServer createServer(URL url) {
        ...
        // 11. 调用Exchangers绑定端口，打开Netty服务器
        server = Exchangers.bind(url, requestHandler);
    }
}

public class Exchangers {
   public static ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {
        ...
        // 12. SPI获取HeaderExchanger来绑定端口
        return getExchanger(url).bind(url, handler);
    }
}

public class HeaderExchanger implements Exchanger {
    @Override
    public ExchangeServer bind(URL url, ExchangeHandler handler) throws RemotingException {
        return new HeaderExchangeServer(
             // 13. 调用Transporters绑定端口，打开Netty服务器
            Transporters.bind(url, new DecodeHandler(new HeaderExchangeHandler(handler))));
    }
}

public class Transporters {
    public static Server bind(URL url, ChannelHandler... handlers) throws RemotingException {
        ...
        // 14. SPI获取remoting.transport.netty4.NettyTransporter来绑定端口
        return getTransporter().bind(url, handler);
    }
}

public class NettyTransporter implements Transporter {
    @Override
    public Server bind(URL url, ChannelHandler listener) throws RemotingException {
        // 15. 打开Netty服务器
        return new NettyServer(url, listener);
    }
}

// NettyServer抽象父类
public abstract class AbstractServer extends AbstractEndpoint implements Server {
    public AbstractServer(URL url, ChannelHandler handler) throws RemotingException     {
        ...
        // 16. 父类模板模式多态调用NettyServer#doOpen
        doOpen();
    }
    
    protected abstract void doOpen() throws Throwable;
}

public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 17. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

```

#### 3、建立连接并监听 ZK

1. `ServiceConfig` 解析出的 URL 的格式为: `registry://registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode("dubbo://service-host/com.foo.FooService?version=1.0.0")`。
2. 基于扩展点自适应机制，通过 URL 的 `registry://` 协议头识别，就会调用 `RegistryProtocol` 的 `export()` 方法，将 `export` 参数中的提供者 URL，注册到注册中心。

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0. 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 1. 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
    }
    
    private Registry getRegistry(final Invoker<?> originInvoker) {
        URL registryUrl = getRegistryUrl(originInvoker);
        return registryFactory.getRegistry(registryUrl);
    }
}

public abstract class AbstractRegistryFactory implements RegistryFactory {
    @Override
    public Registry getRegistry(URL url) {
        ...
        // 2. 如果缓存中没有注册中心，则构建连接注册中心的客户端
        registry = createRegistry(url);
        ...
    }
    
    // 3. 父类模板模式多态调用RegistryFactory#createRegistry
    protected abstract Registry createRegistry(URL url);
}

public class ZookeeperRegistryFactory extends AbstractRegistryFactory {
    @Override
    public Registry createRegistry(URL url) {
        // 4. ZookeeperRegistryFactory子类构建ZK客户端
        return new ZookeeperRegistry(url, zookeeperTransporter);
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    public ZookeeperRegistry(URL url, ZookeeperTransporter zookeeperTransporter) {
        // 5. 调用父类加载、保存注册地址缓存文件
        super(url);
        
        // 7. 调用CuratorZookeeperTransporter#createZookeeperClient创建ZK客户端（Curator语法省略），并设置DISCONNECTED、CONNECTED、RECONNECTED事件的监听器
        zkClient = zookeeperTransporter.connect(url);
        
        // 8. 设置RECONNECTED事件的监听器 => 失败重连
        zkClient.addStateListener(state -> {
            if (state == StateListener.RECONNECTED) {
                try {
                    // 失败重连
                    recover();
                } catch (Exception e) {
                    logger.error(e.getMessage(), e);
                }
            }
        });
    }
}

public abstract class AbstractRegistry implements Registry {
    public AbstractRegistry(URL url) {
        ...
        // 6. 加载C：\Users\dubbo\.dubbo\dubbo-registry-192.168.48.117.cache缓存文件内容
        loadProperties();
        ...
    }
}

```

#### 4、注册 Provider、创建 ZK 结点

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.1 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 0.2 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
        // 1. 注册Provider到ZK注册中心
        register(registryUrl, registeredProviderUrl);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void register(URL url) {
        ...
        // 2. 注册Provider到ZK注册中心
        doRegister(url);
        ...
    }
    
    // 3. 父类模板模式多态调用ZookeeperRegistry#doRegister
    public abstract void doRegister(URL url);
}

public class ZookeeperRegistry extends FailbackRegistry {
    @Override
    public void doRegister(URL url) {
        // 4. Curator ZK客户端创建 /dubbo/xxx.DemoService/providers/... 前面的为持久化结点，后面的（...）为非持久化结点（Curator语法省略）
        zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true));
    }
}

```

#### 5、订阅 ZK 配置信息

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.1 利用Netty NIO特性，打开Netty服务器，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // 0.2 获取注册中心 => 这里用的是ZK作为注册中心
        final Registry registry = getRegistry(originInvoker);
        ...
        // 0.3. 注册Provider到ZK注册中心
        register(registryUrl, registeredProviderUrl);
        ...
        // 1. 订阅ZK配置信息，当有变更时自动推送
        registry.subscribe(overrideSubscribeUrl, overrideSubscribeListener);
        ...
        return new DestroyableExporter<>(exporter);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void subscribe(URL url, NotifyListener listener) {
        ...
        // 2. 向服务器端发送订阅请求
        doSubscribe(url, listener);
        ...  
    }
    
    @Override
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        // 5. 通知、写入缓存文件
        doNotify(url, listener, urls);
    }
    
    protected void doNotify(URL url, NotifyListener listener, List<URL> urls) {
        // 6. 通知、写入缓存文件
        super.notify(url, listener, urls);
    }
}

public abstract class AbstractRegistry implements Registry {
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        // 7. 刷新配置和Invoker列表
        listener.notify(categoryList);
        
        // 11. 线程池异步写入C：\Users\dubbo\.dubbo\dubbo-registry-192.168.48.117.cache缓存文件内容
        saveProperties(url);
    }
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        // 8. 刷新配置和Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 9. 刷新configurators配置
        overrideDirectoryUrl();
        
        // 10. 刷新RegistryDirectory中的Invoker列表
        refreshInvoker(urls);
    }
    private void overrideDirectoryUrl() {
        ...
        doOverrideUrl(localDynamicConfigurators);
    }
    private void doOverrideUrl(List<Configurator> configurators) {
        if (CollectionUtils.isNotEmpty(configurators)) {
            for (Configurator configurator : configurators) {
                this.overrideDirectoryUrl = configurator.configure(overrideDirectoryUrl);
            }
        }
    }
    private void refreshInvoker(List<URL> invokerUrls) {
        Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls);
        ...
        this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers;
        this.urlInvokerMap = newUrlInvokerMap;
        destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap);
        ...
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    protected void doSubscribe(final URL url, final NotifyListener listener) {
        // 3. 创建configurators配置信息（非持久化结点）
        zkClient.create(path, false);
        
        // 4. 通知、写入缓存文件
        notify(url, listener, urls);
    }
}

```

### 2.4. Dubbo 服务引用原理？

![1636896718809](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896718809.png)

1. 首先 `ReferenceConfig#init（）` ，调用 `Protocol#refer（）`生成 `Invoker` 实例（图中的红色部分），这是**服务消费的关键**。
   - **本地服务引用**：如果为本地暴露服务，则 `InjvmProtocol` 生成 `serviceType` 本地执行的 `InjvmInvoker` 。
   - **直连服务引用**：如果为直连服务，则 `DubboProtocol` 创建 Netty 客户端，连接 url 服务，构建 `DubboInvoker` 。
   - **远程服务引用**：如果为非直连的远程服务引用，则 `RegistryProtocol` 注册、订阅 ZK，拉取相关 url 和 配置信息，当有发生变更时，则触发监听器的回调函数，实际调用 `DubboProtocol#refer()` 生成 `DubboInvoker` ，并加入集群，最后默认伪装返回一个 `FailoverClusterInvoker`。
2. 接下来是利用动态代理，把 `Invoker` 转换为客户端需要的接口实现类。

![1637149757299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637149757299.png)

#### 1、本地服务引用

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {
	...
    @Override
    public Object getObject() {
        // 0. 实现Consumer的服务引用
        return get();
    }
}

public class ReferenceConfig<T> extends AbstractReferenceConfig {
    public synchronized T get() {
        checkAndUpdateSubConfigs();

        if (destroyed) {
            throw new IllegalStateException("The invoker of ReferenceConfig(" + url + ") has already destroyed!");
        }
        if (ref == null) {
            // 1. 实现Consumer的服务引用
            init();
        }
        return ref;
    }
    
    private void init() {
        ...
        // 2. 创建服务引用的动态代理
        ref = createProxy(map);
        ...
    }
    
    private T createProxy(Map<String, String> map) {
        // 3. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            ...
    	}
        
        // 5. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class InjvmProtocol extends AbstractProtocol implements Protocol {
    // 4. 生成本地执行的Invoker
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
        return new InjvmInvoker<T>(serviceType, url, url.getServiceKey(), exporterMap);
    }
}

```

#### 2、直连服务引用

1. 在没有注册中心，直连提供者的情况下，`ReferenceConfig` 解析出的 URL 的格式为：`dubbo://service-host/com.foo.FooService?version=1.0.0` 。
2. 基于扩展点自适应机制，通过 URL 的 `dubbo://` 协议头识别，直接调用 `DubboProtocol` 的 `refer()` 方法，建立 Netty 客户端连接，构建 `DubboInvoker`，并加入 invokers 缓存。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 21. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public abstract class AbstractProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 2. 调用protocolBindingRefer
        return new AsyncToSyncInvoker<>(protocolBindingRefer(type, url));
    }
    
    // 3. 模板方法，多态调用DubboProtocol#protocolBindingRefer
    protected abstract <T> Invoker<T> protocolBindingRefer(Class<T> type, URL url) throws RpcException;
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
		...
        //  19. 生成serviceType的invoker
        DubboInvoker<T> invoker = new DubboInvoker<T>(serviceType, url, 
                                                      // 4. 根据url获取客户端连接
                                                      getClients(url), invokers);
        
        // 20. 加入invokers缓存
        invokers.add(invoker);
        return invoker;
    }
    
    private ExchangeClient[] getClients(URL url) {
        ...
        // 5. 初始化客户端连接
        clients[i] = initClient(url);
        ...
    }
    
    private ExchangeClient initClient(URL url) {
        // 6. 进入Exchanger层，连接url服务
        ExchangeClient client = Exchangers.connect(url, requestHandler);
    }
}

public class Exchangers {
    public static ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {
        ...
        // 7. 进入Exchanger层，连接url服务
        return getExchanger(url).connect(url, handler);
    }
}

public class HeaderExchanger implements Exchanger {
    @Override
    public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException {
        return new HeaderExchangeClient(
            // 8. 进入Transporter层，连接url服务
            Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true);
    }
}

public class Transporters {
    public static Client connect(URL url, ChannelHandler... handlers) throws RemotingException {
        // 9. 进入Transporter层，连接url服务
        return getTransporter().connect(url, handler);
    }
}

public class NettyTransporter implements Transporter {
    @Override
    public Client connect(URL url, ChannelHandler listener) throws RemotingException {
        // 10. 默认打开Netty客户端，连接url服务
        return new NettyClient(url, listener);
    }
}

public class NettyClient extends AbstractClient {
    public NettyClient(final URL url, final ChannelHandler handler) throws RemotingException {
        // 11. 默认打开Netty客户端，连接url服务
        super(url, wrapChannelHandler(url, handler));
    }
    
    @Override
    protected void doOpen() throws Throwable {
        // 14. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
    
    @Override
    protected void doConnect() throws Throwable {
        ...
        // 18. 利用Netty语法，发起url连接
        ChannelFuture future = bootstrap.connect(getConnectAddress());
        ...// 省略Netty语法
    }
}

public abstract class AbstractClient extends AbstractEndpoint implements Client {
    public AbstractClient(URL url, ChannelHandler handler) throws RemotingException {
        ...
        // 12. 打开Netty客户端
        doOpen();
        ...
        // 15. 发起url连接
        connect();
        ...
    }
    
    // 13. 模板方法，多态调用子类NettyClient#doOpen
    protected abstract void doOpen() throws Throwable;
    
    protected void connect() throws RemotingException {
        ...
        // 16. 发起url连接
        doConnect();
        ...
    }
    
    // 17. 模板方法，多态调用子类NettyClient#doConnect
    protected abstract void doConnect() throws Throwable;
}

```

#### 3、远程服务引用

![1637068993216](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637068993216.png)

1. 在有注册中心，通过注册中心发现提供者地址的情况下，`ReferenceConfig` 解析出的 URL 的格式为： `registry://registry-host/org.apache.dubbo.registry.RegistryService?refer=URL.encode("consumer://consumer-host/com.foo.FooService?version=1.0.0") `。
2. 基于扩展点自适应机制，通过 URL 的 `registry://` 协议头识别，就会调用 `RegistryProtocol` 的 `refer()` 方法，基于 `refer` 参数中的条件，查询提供者 URL，如： `dubbo://service-host/com.foo.FooService?version=1.0.0` 。
3. 当订阅内容发生更新时，触发监听器回调，里面调用 `protocol.refer()`，基于扩展点自适应机制，通过提供者 URL 的 `dubbo://` 协议头识别，就会调用 `DubboProtocol#refer()` 方法，得到提供者引用。
4. 然后 `RegistryProtocol` 将多个提供者引用，通过 `Cluster` 扩展点，伪装成单个提供者引用 `FailoverClusterInvoker` 返回。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 28. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(url.getProtocol())) {
            return protocol.refer(type, url);
        }
        // 1.1 ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER);
    }
}

public class RegistryProtocol implements Protocol {
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        ...
        // 2. 建立zk的连接，和服务端发布一样（省略代码）
        Registry registry = registryFactory.getRegistry(url);
        ...
        // 3. 引用远程服务
        return doRefer(cluster, registry, type, url);
    }
    
    private <T> Invoker<T> doRefer(Cluster cluster, Registry registry, Class<T> type, URL url) {
        // 4. 建立url Invoker目录
        RegistryDirectory<T> directory = new RegistryDirectory<T>(type, url);
        ...
        // 5. 和服务端发布一样，注册ZK，创建zk的节点
        registry.register(directory.getRegisteredConsumerUrl());
        ...
        // 9. 和服务端发布一样，订阅ZK节点：/dubbo/com.alibaba.dubbo.demo.DemoService/providers，/dubbo/com.alibaba.dubbo.demo.DemoService/configurators，/dubbo/com.alibaba.dubbo.demo.DemoService/routers，url发生变化，则刷新Invoker
        directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY,
                                                      PROVIDERS_CATEGORY + "," + CONFIGURATORS_CATEGORY + "," + ROUTERS_CATEGORY));
        
        // 25. 根据directory，加入集群路由
        Invoker invoker = cluster.join(directory);
        ...
        return invoker;
    }
    
    public void subscribe(URL url) {
        ...
        // 10. 订阅ZK节点
        registry.subscribe(url, this);
    }
}

public abstract class FailbackRegistry extends AbstractRegistry {
    @Override
    public void register(URL url) {
        // 6. 注册ZK，创建zk的节点
        doRegister(url);
    }
    
    // 7. 模板方法，多态调用ZookeeperRegistry#doRegister
    public abstract void doRegister(URL url);
    
    @Override
    public void subscribe(URL url, NotifyListener listener) {
        ...
        // 11. 订阅ZK节点
        doSubscribe(url, listener);
    }
    
    // 12. 模板方法，多态调用ZookeeperRegistry#doSubscribe
    public abstract void doSubscribe(URL url, NotifyListener listener);
    
    @Override
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 14. 通知更新url配置
        doNotify(url, listener, urls);
        ...
    }
    
    protected void doNotify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 15. 通知更新url配置
        super.notify(url, listener, urls);
        ...
    }
}

public class ZookeeperRegistry extends FailbackRegistry {
    @Override
    public void doRegister(URL url) {
        // 8. 创建ZK持久化：dubbo/com.alibaba.dubbo.demo.DemoService/consumers
        zkClient.create(toUrlPath(url), url.getParameter(DYNAMIC_KEY, true));
    }
    
    @Override
    public void doSubscribe(final URL url, final NotifyListener listener) {
        ...
        // 13. 通知更新url配置 
        notify(url, listener, urls);
    }
}

public abstract class AbstractRegistry implements Registry {
    protected void notify(URL url, NotifyListener listener, List<URL> urls) {
        ...
        // 19. 通知更新url配置，生成新的Invoker
        listener.notify(categoryList);
        // 29. 通过线程池，异步把服务端的注册url信息更新到C:\Users\bobo\.dubbo\dubbo-registry-192.168.48.117.cache
        saveProperties(url);
    }
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        ...
        // 16. 通知更新url配置，刷新Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 17. 更新configurators配置（和服务端一样，省略代码）
        overrideDirectoryUrl();
        // 18. 刷新Invoker列表
        refreshInvoker(urls);
    }
    
    private void refreshInvoker(List<URL> invokerUrls) {
        // 19. 根据url生成新的Invoker
        Map<String, Invoker<T>> newUrlInvokerMap = toInvokers(invokerUrls);
        List<Invoker<T>> newInvokers = Collections.unmodifiableList(new ArrayList<>(newUrlInvokerMap.values()));
        routerChain.setInvokers(newInvokers);
        this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers;
        this.urlInvokerMap = newUrlInvokerMap;
    }
    
    private Map<String, Invoker<T>> toInvokers(List<URL> urls) {
        // 20. 调用父类AbstractProtocol#refer
        invoker = new InvokerDelegate<>(protocol.refer(serviceType, url), url, providerUrl);
        ...
    }
}

public abstract class AbstractProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 21. 调用protocolBindingRefer
        return new AsyncToSyncInvoker<>(protocolBindingRefer(type, url));
    }
    
    // 22. 模板方法，多态调用DubboProtocol#protocolBindingRefer
    protected abstract <T> Invoker<T> protocolBindingRefer(Class<T> type, URL url) throws RpcException;
}

public class DubboProtocol extends AbstractProtocol {
    @Override
    public <T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url) throws RpcException {
        // 23. 和服务端一样，根据接口class和url，生成DubboInvoker
        DubboInvoker<T> invoker = new DubboInvoker<T>(serviceType, url, getClients(url), invokers);
        // 24. 加入invokers缓存
        invokers.add(invoker);
        return invoker;
    }
}

public class MockClusterWrapper implements Cluster {
    @Override
    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {
        return new MockClusterInvoker<T>(directory,
                // 26. MockCluster包装类
                this.cluster.join(directory));
    }
}

public class FailoverCluster implements Cluster {
    @Override
    public <T> Invoker<T> join(Directory<T> directory) throws RpcException {
        // 27. 默认构建失败重试集群Invoker（省略构造函数）
        return new FailoverClusterInvoker<T>(directory);
    }
}

```

#### 4、生成接口的动态代理类

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 1. 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        
        // 2. 生成Invoker的动态代理
        return (T) PROXY_FACTORY.getProxy(invoker);
    }
}

public class StubProxyFactoryWrapper implements ProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker) throws RpcException {
        // 3. 调用父类AbstractProxyFactory#getProxy
        T proxy = proxyFactory.getProxy(invoker);
        ...
        return proxy;
    }
}

public abstract class AbstractProxyFactory implements ProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker) throws RpcException {
        // 4. 调用非泛化方法生成代理对象
        return getProxy(invoker, false);
    }
    
    @Override
    public <T> T getProxy(Invoker<T> invoker, boolean generic) throws RpcException {
        ...
        // 5. 调用实现类#getProxy生成代理对象
        return getProxy(invoker, interfaces);
    }
    
    // 6. 模板方法，多态调用JavassistProxyFactory#getProxy生成代理对象
    public abstract <T> T getProxy(Invoker<T> invoker, Class<?>[] types);
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 7. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

```

### 2.5. Dubbo 服务调用原理？

![1636896757166](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636896757166.png)

1. 消费方使用的接口动态代理实现类，就是图中服务消费端的 proxy，用户代码通过这个 proxy 调用其对应的 `Invoker`，而该 `Invoker` 实现了真正的远程服务调用。

2. 而提供方的实现类，则会被封装成为一个 `AbstractProxyInvoker` ，然后生成一个 `Exporter` ，当服务提供方收到一个请求后，则会找到对应的 `Exporter` 实例，并调用它所对应的 `AbstractProxyInvoker` 实例，从而真正调用了服务提供者的代码。

3. 整个**消费方调用提供方**的调用链架构如下：

   ![1637150417647](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637150417647.png)

   1. **服务引用**：通过 Javassist 反向代理，代理调用 InvokerInvocationHandler#invoke 方法。
   2. 服务本地调用、**降级**、缓存。
   3. **集群容错与负载均衡**：非 mock Invoker 筛选，Invoker 目录查找，根据容错策略、负载均衡策略，挑选唯一的 Invoker。
   4. 服务**过滤链**、监听器、包装类 SPI 扩展。
   5. **服务协议**：根据协议，使用不同的 Invoker 调用不同的网络传输底层。
   6. **网络传输**：抽象 Netty、Mina 等统一接口，把消息序列化后发送到网络，传输给 Server 端。
   7. **消息接收与异步处理**：Server 端接收到消息后，经过反序列化后，交由线程池异步处理。
   8. **服务协议**：根据协议，选择不同的 Exporter 进行调用。
   9. 服务**过滤链**、监听器、包装类 SPI 扩展。
   10. **服务调用**：最后调用真正的接口实现类，得到方法执行结果。

4. 而**提供方响应消费方**的顺序为：

   1. **服务响应**：在得到方法执行结果后，通过网络传输底层，序列化后发送响应报文给客户端。
   2. **结果接收**：客户端接收到响应报文后，交由线程池异步处理程序，经过反序列化后塞回到 Future 对象中，完成一次服务调用。

#### 1、消费方发起服务请求

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 0. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

public class InvokerInvocationHandler implements InvocationHandler {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        ...
        // 1. 动态代理执行
		return invoker.invoke(new RpcInvocation(method, args)).recreate();
    }
}

public class MockClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        ...
        // 2. 交由抽象父类执行
        result = this.invoker.invoke(invocation);
        ...
    }
}

public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(final Invocation invocation) throws RpcException {
        ...
        // 3. 进入目录查找，从this.methodInvokerMap里面查找一个Invoker
        List<Invoker<T>> invokers = list(invocation);
        ...
        
        // 11. 进入集群，交由集群路由执行
        return doInvoke(invocation, invokers, loadbalance);
    }
    
    protected List<Invoker<T>> list(Invocation invocation) throws RpcException {
        // 4. 从this.methodInvokerMap里面查找一个Invoker
        return directory.list(invocation);
    }
    
    // 12. 模板方法，交由FailoverClusterInvoker#doInvoke执行
    protected abstract Result doInvoke(Invocation invocation, List<Invoker<T>> invokers,LoadBalance loadbalance) throws RpcException;
    
    protected Invoker<T> select(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
		// 14. 进入负载均衡
        Invoker<T> invoker = doSelect(loadbalance, invocation, invokers, selected);
        ...
    }
    
    private Invoker<T> doSelect(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
        // 15. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        Invoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);
        ...
    }
}

public abstract class AbstractDirectory<T> implements Directory<T> {
    @Override
    public List<Invoker<T>> list(Invocation invocation) throws RpcException {
        ...
        // 5. 从this.methodInvokerMap里面查找一个Invoker
        return doList(invocation);
    }
    
    // 6. 模板方法，多态调用子类RegistryDirectory#doList
    protected abstract List<Invoker<T>> doList(Invocation invocation) throws RpcException;
}

public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public List<Invoker<T>> doList(Invocation invocation) {
        ...
        // 7. 进入路由 
        List<Invoker<T>> invokers = routerChain.route(getConsumerUrl(), invocation);
        ...
    }
}

public class RouterChain<T> {
    public List<Invoker<T>> route(URL url, Invocation invocation) {
        List<Invoker<T>> finalInvokers = invokers;
        for (Router router : routers) {
            // 8. 进入路由 
            finalInvokers = router.route(finalInvokers, url, invocation);
        }
        return finalInvokers;
    }
}

public class MockInvokersSelector extends AbstractRouter {
    @Override
    public <T> List<Invoker<T>> route(final List<Invoker<T>> invokers,
                                      URL url, final Invocation invocation) throws RpcException {
        ...
		// 9. 获取正常路径的Invoker
        return getNormalInvokers(invokers);
    }
    
    private <T> List<Invoker<T>> getNormalInvokers(final List<Invoker<T>> invokers) {
        if (!hasMockProviders(invokers)) {
            return invokers;
        } else {
            List<Invoker<T>> sInvokers = new ArrayList<Invoker<T>>(invokers.size());
            for (Invoker<T> invoker : invokers) {
                // 10. 过滤掉非正常路径的Invoker，即mock协议路径的Invoker不需要
                if (!invoker.getUrl().getProtocol().equals(MOCK_PROTOCOL)) {
                    sInvokers.add(invoker);
                }
            }
            return sInvokers;
        }
    }
}

public class FailoverClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, final List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        // 13. 进入负载均衡
        Invoker<T> invoker = select(loadbalance, invocation, copyInvokers, invoked);
        ...
        
        // 20. 使用负载均衡得到的Invoker执行
        Result result = invoker.invoke(invocation);
        return result;
    }
}

public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 16. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 17. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
}

public class RandomLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 18. 根据随机权重得到Invoker索引
        int offset = ThreadLocalRandom.current().nextInt(totalWeight);
        ...
        // 19. 根据Invoker索引获取对应的Invoker
        return invokers.get(ThreadLocalRandom.current().nextInt(length));
    }
}

public class InvokerWrapper<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 21. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        last = new Invoker<T>() {
            public Result invoke(Invocation invocation) throws RpcException {
                ...
                // 22. 负载均衡得到的Invoker执行前，被过滤器拦截，用于添加一系列过滤器链
                Result asyncResult = filter.invoke(last, invocation);
                return asyncResult;
            }
        }
        ...
    }
}

// ... 可扩展一大堆包装类和过滤器

public class ConsumerInvokerWrapper<T> implements Invoker {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 23. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public class ListenerInvokerWrapper<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 24. 负载均衡得到的Invoker执行前，被包装类拦截
        return invoker.invoke(invocation);
    }
}

public abstract class AbstractInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation inv) throws RpcException {
        ...
        // 25. 负载均衡得到的Invoker执行前，先执行父类方法
        return doInvoke(invocation);
    }
    
    // 26. 模板方法，多态调用DubboInvoker#doInvoke => DubboInvoker为多态实例的原因见：RegistryDirectory.refreshInvoker.toInvokers#protocol.refer
    protected abstract Result doInvoke(Invocation invocation) throws Throwable;
}

public class DubboInvoker<T> extends AbstractInvoker<T> {
    @Override
    protected Result doInvoke(final Invocation invocation) throws Throwable {
        ...
        // 27. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        CompletableFuture<Object> responseFuture = currentClient.request(inv, timeout);
        ...
    }
}

final class ReferenceCountExchangeClient implements ExchangeClient {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        // 28. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        return client.request(request, timeout);
    }
}

public class HeaderExchangeClient implements ExchangeClient {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        // 29. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        return channel.request(request, timeout);
    }
}

final class HeaderExchangeChannel implements ExchangeChannel {
    @Override
    public CompletableFuture<Object> request(Object request, int timeout) throws RemotingException {
        ...
        // 30. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        channel.send(req);
        ...
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void send(Object message) throws RemotingException {
        // 31. 如果不为oneway单向传输，则向远程服务发起consumer#request请求
        send(message, url.getParameter(Constants.SENT_KEY, false));
    }
}

final class NettyChannel extends AbstractChannel {
    @Override
    public void send(Object message, boolean sent) throws RemotingException {
        ...
        // 32. 最后使用Netty客户端channel，向远程服务发起consumer#request请求
        ChannelFuture future = channel.writeAndFlush(message);
        ...
    }
}

```

#### 2、提供方接收并响应

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

public class NettyServerHandler extends ChannelDuplexHandler {
    // 1. Netty读事件
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler);
        // 2. 当有请求数据时，则调用handler进行接收、处理
        handler.received(channel, msg);
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void received(Channel ch, Object msg) throws RemotingException {
        ...
        // 3. 当有请求数据时，则调用handler进行接收、处理
        handler.received(ch, msg);
    }
}

public class HeartbeatHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 4. 当有请求数据时，则调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        // 4. 当有请求数据时，使用线程池异步接收、处理
        executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        ...
    }
}

public class ChannelEventRunnable implements Runnable {
    @Override
    public void run() {
        // 5. 数据接收事件，继续调用handler进行接收、处理
        if (state == ChannelState.RECEIVED) {
            handler.received(channel, message);
        } else {
           .... 
        }
    }
}

public class DecodeHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 6. 继续调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class HeaderExchangeHandler implements ChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 7. 如果报文属于来回传输类型，则调用handleRequest接收、处理，并响应客户端
        if (request.isTwoWay()) {
            handleRequest(exchangeChannel, request);
        }
        // 而如果报文属于onoWay单程传输类型，则调用received只接收、处理，不会响应客户端
        else {
            handler.received(exchangeChannel, request.getData());
        }
        ...
    }
    
    void handleRequest(final ExchangeChannel channel, Request req) throws RemotingException {
        ...
        // 8. 调用reply处理方法，得到返回结果future
        CompletionStage<Object> future = handler.reply(channel, msg);
        future.whenComplete((appResult, t) -> {
            try {
                if (t == null) {
                    res.setStatus(Response.OK);
                    res.setResult(appResult);
                } else {
                    res.setStatus(Response.SERVICE_ERROR);
                    res.setErrorMessage(StringUtils.toString(t));
                }
                
                // 20. 最后把结果返回写回给客户端，发送流程类似于客户端请求流程（代码略）
                channel.send(res);
            } catch (RemotingException e) {
                logger.warn("Send result to consumer failed, channel is " + channel + ", msg is " + e);
            }
        });
        ...
    }
}

public class DubboProtocol extends AbstractProtocol {
    private ExchangeHandler requestHandler = new ExchangeHandlerAdapter() {
        @Override
        public CompletableFuture<Object> reply(ExchangeChannel channel, Object message) throws RemotingException {
            ...
			// 9. 先根据报文，提取对应的Invoker
            Invoker<?> invoker = getInvoker(channel, inv);
            ...
            // 13. 调用提取到的Invoker#invoker方法
            Result result = invoker.invoke(inv);
            
            // 19. 最后把结果返回到外层
            return result.completionFuture().thenApply(Function.identity());
        }
    }
    
    Invoker<?> getInvoker(Channel channel, Invocation inv) throws RemotingException  {
        ...
        // 10. 端口+url+版本号+组号，组装成servicekey
        String serviceKey = serviceKey(port, path, inv.getAttachments().get(VERSION_KEY), inv.getAttachments().get(GROUP_KEY)); 
        // 11. 根据servicekey从之前缓存起来的exports中，提取出exporter
        DubboExporter<?> exporter = (DubboExporter<?>) exporterMap.get(serviceKey);
        ...
        // 12. 然后返回exporter中的Invoker
        return exporter.getInvoker();
    }
}

public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        last = new Invoker<T>() {
            public Result invoke(Invocation invocation) throws RpcException {
                // 14. invoker方法调用前，被过滤器拦截
                Result asyncResult = filter.invoke(last, invocation);
                return asyncResult;
            }
        }
    }
}

public class EchoFilter implements Filter {
    @Override
    public Result invoke(Invoker<?> invoker, Invocation inv) throws RpcException {
        ...
        // 15. invoker方法调用前，被过滤器拦截
        return invoker.invoke(inv);
    }
}

// ... 可扩展一大堆包装类和过滤器

public abstract class AbstractProxyInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        // 16. invoker方法调用前，过滤器、监听器、包装类执行后，还需要先执行父类的doInvoke方法
        Object value = doInvoke(proxy, invocation.getMethodName(), invocation.getParameterTypes(), invocation.getArguments());
        ...
    }
    
    // 17. 模板方法，多态调用AbstractProxyInvoker#doInvoke方法
    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;
}

public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 18. 最后才调用回实际接口实现类的方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
}

```

#### 3、消费方接收服务响应

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

public class NettyClientHandler extends ChannelDuplexHandler {
    // 1. Netty读事件
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        NettyChannel channel = NettyChannel.getOrAddChannel(ctx.channel(), url, handler);
        // 2. 读事件触发后，调用handler进行接收、处理
        handler.received(channel, msg);
        ...
    }
}

public abstract class AbstractPeer implements Endpoint, ChannelHandler {
    @Override
    public void received(Channel ch, Object msg) throws RemotingException {
        ...
        // 3. 调用handler进行接收、处理
        handler.received(ch, msg);
    }
}

public class MultiMessageHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 4. 调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class HeartbeatHandler extends AbstractChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ...
        // 5. 调用handler进行接收、处理
        handler.received(channel, message);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getExecutorService();
        // 6. 利用线程池，异步调用handler进行接收、处理
        executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        ...
    }
}

public class ChannelEventRunnable implements Runnable {
    @Override
    public void run() {
        // 7. 如果为数据接收类型，则继续调用handler进行接收、处理
        if (state == ChannelState.RECEIVED) {
            handler.received(channel, message);
        } else {
            ...
        }
    }
}

public class HeaderExchangeHandler implements ChannelHandlerDelegate {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        if (message instanceof Request) {
            ...
        } else {
            // 8. 如果为响应报文，则继续调用handleResponse进行接收、处理
            handleResponse(channel, (Response) message);
        } else {
            ...
        }
    }
    
    static void handleResponse(Channel channel, Response response) throws RemotingException {
        if (response != null && !response.isHeartbeat()) {
            // 9. 如果为响应报文，则继续调用received进行接收、处理
            DefaultFuture.received(channel, response);
        }
    }
}

public class DefaultFuture extends CompletableFuture<Object> {
    public static void received(Channel channel, Response response) {
        // 10. 继续调用received进行接收、处理
        received(channel, response, false);
    }
    
    public static void received(Channel channel, Response response, boolean timeout) {
        ...
        // 11. 继续调用received进行接收、处理
        future.doReceived(response);
        ...
    }
    
    private void doReceived(Response res) {
 		...
        if (res.getStatus() == Response.OK) {
            // 12. 如果报文响应OK=20，则取出响应数据，设置到之前返回的future中
            this.complete(res.getResult());
        } else {
            ...
        }
    }
}

```

### 2.6. Dubbo 协议编解码原理？

#### 1、协议格式

![1637153667359](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637153667359.png)

Dubbo 协议，通过消息头（16 字节 = 4 + 8 + 4）+ 消息体（不限），来解决 TCP 拆包、粘包的问题。

| 头属性           | 长度   | 作用                                                         |
| ---------------- | ------ | ------------------------------------------------------------ |
| Magic            | 16 bit | 魔数，标识 Dubbo 协议                                        |
| Req/Res          | 1 bit  | 标识报文是请求（1）还是响应（0）                             |
| 2 Way            | 1 bit  | 双向或单向的标记 ，仅当 Req/Res 为 1（请求）时才有用，如果需要来自服务器的返回值，则会设置为 1 |
| Event            | 1 bit  | 标识事件消息与否，比如心跳事件，如果这是一个事件，则设置为 1，而请求是没有的 |
| Serialization ID | 5 bit  | 标识序列化类型，比如 fastjson 的值为 6                       |
| Status           | 8 bit  | 仅在 Req/Res 为 0（响应）时有用，标识响应状态：20 - OK，30 - CLIENT_TIMEOUT，31 - SERVER_TIMEOUT，40 - BAD_REQUEST，50 - BAD_RESPONSE，60 - SERVICE_NOT_FOUND，70 - SERVICE_ERROR，80 - SERVER_ERROR，90 - CLIENT_ERROR，100 - SERVER_THREADPOOL_EXHAUSTED_ERROR |
| Request ID       | 64 bit | 请求 ID，标识唯一的请求，long 类型数字                       |
| Data Length      | 32 bit | 请求体序列化后的长度，以字节为单位，int 类型数字             |
| Variable Part    | 不限   | 请求体，长度可变，每个部分是序列化后的字节数组，由序列化ID标识，最大长度为 Integer.MAX_VALUE |

#### 2、消费方编码请求

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalEncoder extends MessageToByteEncoder {
        @Override
        protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception {
            ...
            // 1. 调用codec进行编码
            codec.encode(channel, buffer, msg);
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 2. 调用codec进行编码
        codec.encode(channel, buffer, msg);
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 3. 如果消息为请求类型，则对请求进行编码
        if (msg instanceof Request) {
            encodeRequest(channel, buffer, (Request) msg);
        } else if (msg instanceof Response) {
            ...
        } else {
            ...
        }
    }
    
    protected void encodeRequest(Channel channel, ChannelBuffer buffer, Request req) throws IOException {
        ...
        // 4. 初始化消息头=16字节长的字节数组
        byte[] header = new byte[HEADER_LENGTH];
        
        // 5. 2字节长的魔数
        Bytes.short2bytes(MAGIC, header);
        
        // 6. 1字节长的请求标识、来回标识、序列化类型
        header[2] = (byte) (FLAG_REQUEST | serialization.getContentTypeId());
        if (req.isTwoWay()) {
            header[2] |= FLAG_TWOWAY;
        }
        // 7. 消费请求报文，没有Event事件标识，也没有status状态标识
        if (req.isEvent()) {
            header[2] |= FLAG_EVENT;
        }
        
        // 8. 8字节长的请求唯一ID
        Bytes.long2bytes(req.getId(), header, 4);
        ...
        // 9. 4字节长的请求体序列化后的长度
        int len = bos.writtenBytes();
        checkPayload(channel, len);
        Bytes.int2bytes(len, header, 12);
        ...
        // 10. write header.
        buffer.writeBytes(header); 
        ...
    }
}

```

#### 3、提供方解码请求

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalDecoder extends ByteToMessageDecoder {
        @Override
        protected void decode(ChannelHandlerContext ctx, ByteBuf input, List<Object> out) throws Exception {
            ...
            // 1. 调用codec解码
            Object msg = codec.decode(channel, message);
            ...
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        ...
        // 2. 调用codec解码
        Object obj = codec.decode(channel, buffer);
        ...
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        int readable = buffer.readableBytes();
        
        // 3. 读取16字节长的消息头
        byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];
        buffer.readBytes(header);
        
        // 4. 校验消息头，并解码消息体
        return decode(channel, buffer, readable, header);
    }
}

```

#### 4、提供方编码响应

```java
public class NettyServer extends AbstractServer implements Server {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，打开Netty服务器，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyServerHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalEncoder extends MessageToByteEncoder {
        @Override
        protected void encode(ChannelHandlerContext ctx, Object msg, ByteBuf out) throws Exception {
            ...
            // 1. 调用codec编码
            codec.encode(channel, buffer, msg);
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        // 2. 调用codec编码
        codec.encode(channel, buffer, msg);
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public void encode(Channel channel, ChannelBuffer buffer, Object msg) throws IOException {
        if (msg instanceof Request) {
            ...
        } 
        // 3. 如果消息为响应类型，则对响应进行编码
        else if (msg instanceof Response) {
            encodeResponse(channel, buffer, (Response) msg);
        } else {
            ...
        }
    }
    
    protected void encodeResponse(Channel channel, ChannelBuffer buffer, Response res) throws IOException {
        // 4. 初始化消息头=16字节长的字节数组
        byte[] header = new byte[HEADER_LENGTH];
        
        // 5. 2字节长的魔数
        Bytes.short2bytes(MAGIC, header);
        
        // 6. 1字节长的请求标识、来回标识、序列化类型、Event事件标识（响应报文才有）
        header[2] = serialization.getContentTypeId();
        if (res.isHeartbeat()) {
            header[2] |= FLAG_EVENT;
        }
        
        // 7. 1字节长的响应状态码(响应报文才有)
        byte status = res.getStatus();
        header[3] = status;
        
        // 8. 8字节长的请求唯一标识
        Bytes.long2bytes(res.getId(), header, 4);
        ...
        // 9. 4字节长的请求体序列化后的长度
        int len = bos.writtenBytes();
        checkPayload(channel, len);
        Bytes.int2bytes(len, header, 12);
        ...
        // 10. write header.
        buffer.writeBytes(header); 
        ...
    }
}

```

#### 5、消费方解码响应

```java
public class NettyClient extends AbstractClient {
    @Override
    protected void doOpen() throws Throwable {
        // 0. 利用Netty语法，使用客户端连接url连接服务，同时指定InternalDecoder解码器、InternalEncoder编码器、NettyClientHandler通道处理器
        ...// 省略Netty语法
    }
}

final public class NettyCodecAdapter {
    private class InternalDecoder extends ByteToMessageDecoder {
        @Override
        protected void decode(ChannelHandlerContext ctx, ByteBuf input, List<Object> out) throws Exception {
            ...
			// 1. 调用codec解码
            Object msg = codec.decode(channel, message);
            ...
        }
    }
}

public final class DubboCountCodec implements Codec2 {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        ...
        // 2. 调用codec解码
        Object obj = codec.decode(channel, buffer);
        ...
    }
}

public class ExchangeCodec extends TelnetCodec {
    @Override
    public Object decode(Channel channel, ChannelBuffer buffer) throws IOException {
        int readable = buffer.readableBytes();
        
        // 3. 读取16字节长的消息头
        byte[] header = new byte[Math.min(readable, HEADER_LENGTH)];
        buffer.readBytes(header);
        
        // 4. 校验消息头，并解码消息体
        return decode(channel, buffer, readable, header);
    }
}

```

### 2.7. Dubbo 集群容错原理？

#### 集群容错策略

在集群**调用失败**时或者**发起调用前**，Dubbo 提供 6 种集群容错方案，缺省为 `failover` 失败自动切换，可通过 SPI 自行扩展。

| 集群模式          | 作用                                               | 适用场景                                                     |
| ----------------- | -------------------------------------------------- | ------------------------------------------------------------ |
| Failover Cluster  | 默认配置，失败自动切换，当出现失败，重试其它服务器 | 通常用于读操作，但重试会带来更长延迟，可通过 `retries="2"` 来设置额外重试次数（不含第一次） |
| Failfast Cluster  | 快速失败，只发起一次调用，失败则立即报错           | 通常用于非幂等性的写操作，比如新增记录                       |
| Failsafe Cluster  | 安全失败，出现异常时，会直接忽略                   | 通常用于写入审计日志等操作                                   |
| Failback Cluster  | 失败自动恢复，后台记录失败请求，然后定时重发       | 通常用于消息通知操作                                         |
| Forking Cluster   | 并行调用多个服务器，只要一个成功即返回             | 通常用于实时性要求较高的读操作，但需要浪费更多服务资源，可通过 `forks="2"` 来设置最大并行数 |
| Broadcast Cluster | 广播调用所有提供者，逐个调用，任意一台报错则报错   | 通常用于通知所有提供者更新缓存或者日志等本地资源信息，可以通过 `broadcast.fail.percent` 配置节点调用失败的比例，当达到这个比例后，将不再调用其他节点，而是直接抛出异常，取值范围为 0 ~ 100，默认情况下当全部调用失败后，才会抛出异常 |

#### 策略实现原理

```java
public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(final Invocation invocation) throws RpcException {
        ...
        // 0.1. 进入目录查找，从this.methodInvokerMap里面查找一个Invoker
        List<Invoker<T>> invokers = list(invocation);
        ...
        
        // 0.2. 进入集群，交由集群路由执行
        return doInvoke(invocation, invokers, loadbalance);
    }
    
    // 0.3. 模板方法，交由*ClusterInvoker#doInvoke执行
    protected abstract Result doInvoke(Invocation invocation, List<Invoker<T>> invokers,LoadBalance loadbalance) throws RpcException;
}

```

##### Failover | 失败重试

```java
public class FailoverClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, final List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        // 1. 获取retries参数，默认额外重试2次
        int len = getUrl().getMethodParameter(methodName, RETRIES_KEY, DEFAULT_RETRIES) + 1;

        // 2. 这里retries再加1，代表共尝试3次
        for (int i = 0; i < len; i++) {
            try {
                Result result = invoker.invoke(invocation);
                return result;
            } catch (RpcException e) {
                if (e.isBiz()) { // biz exception.
                    throw e;
                }
                le = e;
            } catch (Throwable e) {
                // 3. catch住异常，然后循环重试
                le = new RpcException(e.getMessage(), e);
            } finally {
                providers.add(invoker.getUrl().getAddress());
            }
        }
        
        // 4. 重试完毕后，如果还没返回结果，说明全部都失败了，则抛出异常
        throw new RpcException(...);
    }
}

```

##### Failfast | 快速失败

```java
public class FailfastClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        ...
        try {
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            if (e instanceof RpcException && ((RpcException) e).isBiz()) { // biz exception.
                throw (RpcException) e;
            }
            
            // 1. 发生异常直接抛出
            throw new RpcException(...);
        }
    }
}

```

##### Failsafe | 安全失败

```java
public class FailsafeClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        try {
            ...
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            // 1. 发生异常只打印到日志中，然后返回null
            logger.error("Failsafe ignore exception: " + e.getMessage(), e);
            return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore
        }
    }
}

```

##### Failback | 失败自动恢复

```java
public class FailbackClusterInvoker<T> extends AbstractClusterInvoker<T> {

    @Override
    protected Result doInvoke(Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        Invoker<T> invoker = null;
        try {
            ...
            return invoker.invoke(invocation);
        } catch (Throwable e) {
            // 1. 发生异常不仅打印到日志中
            logger.error(...);
            
            // 2. 还设置定时任务，重试执行，并返回null，后面的重试再无返回值
            addFailed(loadbalance, invocation, invokers, invoker);
            return AsyncRpcResult.newDefaultAsyncResult(null, null, invocation); // ignore
        }
    }
    
    private void addFailed(LoadBalance loadbalance, Invocation invocation, List<Invoker<T>> invokers, Invoker<T> lastInvoker) {
        // 3. 双重检查锁创建定时器
        if (failTimer == null) {
            synchronized (this) {
                if (failTimer == null) {
                    failTimer = new HashedWheelTimer(
                            new NamedThreadFactory("failback-cluster-timer", true),
                            1,
                            TimeUnit.SECONDS, 32, failbackTasks);
                }
            }
        }
        
        // 4. 创建重试任务，每5s执行一次
        RetryTimerTask retryTimerTask = new RetryTimerTask(loadbalance, invocation, invokers, lastInvoker, retries, RETRY_FAILED_PERIOD);
        try {
            failTimer.newTimeout(retryTimerTask, RETRY_FAILED_PERIOD, TimeUnit.SECONDS);
        } catch (Throwable e) {
            logger.error("Failback background works error,invocation->" + invocation + ", exception: " + e.getMessage());
        }
    }
    
    private class RetryTimerTask implements TimerTask {
        @Override
        public void run(Timeout timeout) {
            try {
                ...
                // 5. 发起重新执行，无返回值，会一直重试！
                retryInvoker.invoke(invocation);
            } catch (Throwable e) {
                logger.error(...);
                if ((++retryTimes) >= retries) {
                    logger.error(...);
                } else {
                    // 6. 超过了最大重试次数retries，默认共3次，则重新添加定时任务，继续重试
                    rePut(timeout);
                }
            }
        }
        
        private void rePut(Timeout timeout) {
            if (timeout == null) {
                return;
            }

            Timer timer = timeout.timer();
            if (timer.isStop() || timeout.isCancelled()) {
                return;
            }

            // 7. 超过了最大重试次数retries，默认共3次，则重新添加定时任务，继续重试
            timer.newTimeout(timeout.task(), tick, TimeUnit.SECONDS);
        }
    }
}

```

##### Forking | 并行调用

```java
public class ForkingClusterInvoker<T> extends AbstractClusterInvoker<T> {
    
    // 0. 并行调用的缓存线程池
    private final ExecutorService executor = Executors.newCachedThreadPool(
            new NamedInternalThreadFactory("forking-cluster-timer", true));
    
    @Override
    public Result doInvoke(final Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        final List<Invoker<T>> selected;
        
        // 1. 获取并行调用数量，默认为2
        final int forks = getUrl().getParameter(FORKS_KEY, DEFAULT_FORKS);
        
        // 2. 设置并行调用的Invoker列表
        selected = new ArrayList<>();
        for (int i = 0; i < forks; i++) {
            Invoker<T> invoker = select(loadbalance, invocation, invokers, selected);
            if (!selected.contains(invoker)) {.
                selected.add(invoker);
            }
        }
        
        // 3. 遍历并行调用的Invoker列表，交由线程池并行调用
        final BlockingQueue<Object> ref = new LinkedBlockingQueue<>();
        for (final Invoker<T> invoker : selected) {
            executor.execute(new Runnable() {
                @Override
                public void run() {
                    try {
                        Result result = invoker.invoke(invocation);
                        
                        // 4. 执行结果添加到LinkedBlockingQueue中
                        ref.offer(result);
                    } catch (Throwable e) {
                        int value = count.incrementAndGet();
                        if (value >= selected.size()) {
                            ref.offer(e);
                        }
                    }
                }
            });
        }
        
        try {
            // 5. 超时阻塞式从LinkedBlockingQueue中，取出第一个结果并返回，如果结果异常则抛出
            Object ret = ref.poll(timeout, TimeUnit.MILLISECONDS);
            if (ret instanceof Throwable) {
                Throwable e = (Throwable) ret;
                throw new RpcException(...);
            }
            return (Result) ret;
        } catch (InterruptedException e) {
            throw new RpcException(...);
        }
        
        ...
    }
}

```

##### Broadcast | 逐个广播式调用

```java
public class BroadcastClusterInvoker<T> extends AbstractClusterInvoker<T> {
    @Override
    public Result doInvoke(final Invocation invocation, List<Invoker<T>> invokers, LoadBalance loadbalance) throws RpcException {
        RpcException exception = null;
        Result result = null;
        
        // 1. 不做任何的负载均衡
        for (Invoker<T> invoker : invokers) {
            try {
                // 2. 每个Invoker都执行一遍
                result = invoker.invoke(invocation);
            } catch (RpcException e) {
                exception = e;
                logger.warn(e.getMessage(), e);
            } catch (Throwable e) {
                exception = new RpcException(e.getMessage(), e);
                logger.warn(e.getMessage(), e);
            }
        }
        
        // 2. 任何一台报错则报错
        if (exception != null) {
            throw exception;
        }
        
        // 3. 只返回最后一次执行成功的结果
        return result;
    }
}

```

### 2.8. Dubbo 负载均衡原理？

#### 负载均衡策略

在集群负载均衡时，Dubbo 提供了 5 种负载均衡策略，缺省为 `random` 随机调用，可通过 SPI 自行扩展。

1. ⼀个请求从客户端发起，⽐如查询订单列表，要选择服务器进⾏处理，但是集群环境提供了 5 个服务器，每个服务器都有处理这个请求的能⼒，此时，客户端就必须选择⼀个服务器来进⾏处理，说⽩了，负载均衡就是⼀个选择的问题。
2. 当请求多了，负载均衡的优点则得以体现：可以均衡各服务器的负载，避免单个服务器响应同⼀请求，而导致的服务器宕机、崩溃等问题。

| 负载均衡策略                 | 作用                                                         | 特点                                                         |
| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Random LoadBalance           | 默认策略，随机，按权重设置随机概率                           | 在一个截面上碰撞的概率高，但调用量越大分布越**均匀**，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重 |
| RoundRobin LoadBalance       | 轮训，按公约后的权重设置轮训比率                             | 存在慢的提供者**累积请求**的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上 |
| LeastActive LoadBalance      | 最少活跃调用数，相同活跃数的则随机，活跃数指并发调用的数量   | 使并发少的提供者收到**更多请求**，因为并发越少的提供者，压力更小；使并发多的提供者收到**更少请求**，因为并发越的多提供者，压力更大 |
| ShortestResponse LoadBalance | 最短响应负载，优先选择平均调用成功时长短、响应效率高，而相同响应时长的则随机选取 | 使快的提供者收到**更多请求**，因为越快的提供者，调用的平均成功时长越小；使慢的提供者收到**更少请求**，因为越慢的提供者，调用的平均成功时长越大 |
| ConsistentHash LoadBalance   | 一致性 Hash，相同参数的请求总是发到同一提供者，缺省用 160 份虚拟节点，可通过 `dubbo:parameter` 进行修改 | 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，**不会引起剧烈变动** |

#### 策略实现原理

```java
public abstract class AbstractClusterInvoker<T> implements Invoker<T> {
    
    // 0.1. 从具体的ClusterInvoker#doInvoke中回调
    protected Invoker<T> select(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
		// 0.2. 进入负载均衡
        Invoker<T> invoker = doSelect(loadbalance, invocation, invokers, selected);
        ...
    }
    
    private Invoker<T> doSelect(LoadBalance loadbalance, Invocation invocation,
                                List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {
        ...
        // 0.3. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        Invoker<T> invoker = loadbalance.select(invokers, getUrl(), invocation);
        ...
    }
}

public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 0.4. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 0.5. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
    
    // 0.6. 根据会话状态获取路由权重
    int getWeight(Invoker<?> invoker, Invocation invocation) {
        int weight;
        URL url = invoker.getUrl();

        // 0.7. 当有多个注册地址时,根据注册地址key 获取对应服务权重
        if (REGISTRY_SERVICE_REFERENCE_PATH.equals(url.getServiceInterface())) {
            weight = url.getParameter(REGISTRY_KEY + "." + WEIGHT_KEY, DEFAULT_WEIGHT);
        } else {
            // 0.8. 从url获取权重，默认100
            weight = url.getMethodParameter(invocation.getMethodName(), WEIGHT_KEY, DEFAULT_WEIGHT);
            if (weight > 0) {
                // 以下过程主要是，判断机器的启动时间和预热时间的差值(默认为10min), 为什么要预热? 
                // 1、服务预热是一个优化手段，与此类似的还有 JVM 预热，主要目的是让服务启动后“低功率”运行一段时间，使其效率慢慢提升至最佳状态，避免由此引发的调用超时问题。

                // 0.9. 获取启动时间
                long timestamp = invoker.getUrl().getParameter(TIMESTAMP_KEY, 0L);
                if (timestamp > 0L) {
                    // 0.91. 获取运行时间
                    long uptime = System.currentTimeMillis() - timestamp;
                    if (uptime < 0) {
                        return 1;
                    }
                    // 0.92. 获取服务预热时间，默认为10分钟
                    int warmup = invoker.getUrl().getParameter(WARMUP_KEY, DEFAULT_WARMUP);
                    if (uptime > 0 && uptime < warmup) {
                        // 0.93. 重新计算服务权重
                        weight = calculateWarmupWeight((int)uptime, warmup, weight);
                    }
                }
            }
        }

        return Math.max(weight, 0);
    }
    
    // 0.94. 重新计算服务权重，当服务运行时长小于服务预热时间时，则会对服务进行降权，以避免让服务在启动之初就处于高负载状态
    static int calculateWarmupWeight(int uptime, int warmup, int weight) {
        // 0.95. 计算权重，下面代码逻辑上形似于 (uptime / warmup) * weight，可见，随着服务运行时间 uptime 增大，权重计算值 ww 会慢慢接近配置值 weight
        int ww = (int) ( uptime / ((float) warmup / weight));
        return ww < 1 ? 1 : (Math.min(ww, weight));
    }
}

```

##### Random | 随机

1. 遍历 invokers 列表，获取它们降权后的路由权重，并累加它们的权重，然后比较它们的权重值是否相等。
2. 如果它们权重不相等，则根据权重和，求出一个**随机数**，并计算看该数落在权重数组的哪个区间段，然后取该区间段权重最大的 invoker 索引，去 invokers 集合中获取返回。
3. 如果它们权重都相等，则随机返回一个 invoker 即可。

```java
public class RandomLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        int length = invokers.size()
        boolean sameWeight = true;
        int[] weights = new int[length];
        int totalWeight = 0;
        
        // 1. 累加总权重
        for (int i = 0; i < length; i++) {
            // 2. 获取路由权重（包括预热降权）
            int weight = getWeight(invokers.get(i), invocation);
            totalWeight += weight;
            weights[i] = totalWeight;
            if (sameWeight && totalWeight != weight * (i + 1)) {
                sameWeight = false;
            }
        }
        
        // 3. 如果服务路由中，存在不一样的权重，根据权重和求出一个随机数,然后计算看该数落在哪个区间段
        if (totalWeight > 0 && !sameWeight) {
            int offset = ThreadLocalRandom.current().nextInt(totalWeight);
            for (int i = 0; i < length; i++) {
                if (offset < weights[i]) {
                    // 4. 只取区间中最大权重的一个invoker
                    return invokers.get(i);
                }
            }
        }
        
        // 5. 如果权重相同或总权重为0，则随机选一个，多线程产生随机数，然后取对应索引的invoker
        return invokers.get(ThreadLocalRandom.current().nextInt(length));
    }
}

```

##### RoundRobin | 轮训

1. 遍历 invokers 列表，累加它们的权重。
2. 如果它们权重不相等，则返回**权重最大**的一个 invoker。
3. 如果它们权重都相等，则返回第一个 invoker。

```java
public class RoundRobinLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 1. 遍历所有invoker
        for (Invoker<T> invoker : invokers) {
            ...
            // 2. 计算胡最大的路由权重，并取其invoker
            if (cur > maxCurrent) {
                maxCurrent = cur;
                selectedInvoker = invoker;
                selectedWRR = weightedRoundRobin;
            }
            totalWeight += weight;
        }
        if (selectedInvoker != null) {
            selectedWRR.sel(totalWeight);
            
            // 3. 返回权重最大的路由
            return selectedInvoker;
        }
        
        // 4. 如果所有路由权重都相同，则取第一个invoker
        return invokers.get(0);
    }
}

```

##### LeastActive | 最不活跃调用数

1. 遍历 invokers 列表，寻找**活跃数最小**的 Invoker。
2. 如果有多个 Invoker 具有相同的最小活跃数，则记录下这些 Invoker 在 invokers 集合中的下标，并累加它们的权重，比较它们的权重值是否相等。
3. 如果只有一个 Invoker 具有最小的活跃数，此时直接返回该 Invoker 即可。
4. 如果有多个 Invoker 具有最小活跃数，且它们的权重不相等，此时处理方式和 RandomLoadBalance 一致。
5. 如果有多个 Invoker 具有最小活跃数，但它们的权重相等，此时随机返回一个即可。

```java
public class LeastActiveLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        int length = invokers.size();
        // 1. 最小的活跃数
        int leastActive = -1;
        // 2.具有相同“最小活跃数”的服务者提供者（以下用 Invoker 代称）数量
        int leastCount = 0;
        // 3. leastIndexs 用于记录具有相同“最小活跃数”的 Invoker 在 invokers 列表中的下标信息
        int[] leastIndexes = new int[length];
        int[] weights = new int[length];
        int totalWeight = 0;
        // 4. 第一个最小活跃数的 Invoker 权重值，用于与其他具有相同最小活跃数的 Invoker 的权重进行对比， 以检测是否“所有具有相同最小活跃数的 Invoker 的权重”均相等
        int firstWeight = 0;
        boolean sameWeight = true;

        // 5. 遍历 invokers 列表
        for (int i = 0; i < length; i++) {
            Invoker<T> invoker = invokers.get(i);
            // 6. 获取 Invoker 对应的活跃数，记录方式见《限流原理》
            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive();
            // 7. 获取降权后的服务权重
            int afterWarmup = getWeight(invoker, invocation);
            weights[i] = afterWarmup;
            // 8. 对比查找更小的活跃数，重新开始
            if (leastActive == -1 || active < leastActive) {
                // 9. 使用当前活跃数 active 更新最小活跃数 leastActive
                leastActive = active;
                // 10. 更新 leastCount 为 1
                leastCount = 1;
                // 11. 记录当前下标值到 leastIndexs 中
                leastIndexes[0] = i;
                totalWeight = afterWarmup;
                firstWeight = afterWarmup;
                sameWeight = true;
            } 
  			// 12. 当前 Invoker 的活跃数 active 与最小活跃数 leastActive 相同
            else if (active == leastActive) {
                // 13. 在 leastIndexs 中记录下当前 Invoker 在 invokers 集合中的下标
                leastIndexes[leastCount++] = i;
                // 14. 累加权重
                totalWeight += afterWarmup;
                // 15. 检测当前 Invoker 的权重与 firstWeight 是否相等，不相等则将 sameWeight 置为 false
                if (sameWeight && afterWarmup != firstWeight) {
                    sameWeight = false;
                }
            }
        }

        // 16. 当只有一个 Invoker 具有最小活跃数，此时直接返回该 Invoker 即可
        if (leastCount == 1) {
            return invokers.get(leastIndexes[0]);
        }

        // 17. 有多个 Invoker 具有相同的最小活跃数，但它们之间的权重不同
        if (!sameWeight && totalWeight > 0) {
            // 18. 则随机生成一个 [0, totalWeight) 之间的数字
            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);
            // 19. 循环让随机数减去具有最小活跃数的 Invoker 的权重值， 当 offset 小于等于0时，返回相应的 Invoker
            for (int i = 0; i < leastCount; i++) {
                int leastIndex = leastIndexes[i];
                // 20. 获取权重值，并让随机数减去权重值
                offsetWeight -= weights[leastIndex];
                if (offsetWeight < 0) {
                    return invokers.get(leastIndex);
                }
            }
        }

        // 21. 如果权重相同或权重为0时，随机返回一个 Invoker
        return invokers.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]);
    }
}

```

##### ShortestResponse | 最短响应负载

1. 找到服务下，所有提供者中**响应时间最短**的⼀个或多个，并计算其权重和。
2. 如果响应时间最短的服务提供者只有⼀个，则直接返回给服务。
3. 如果响应时间最短的服务提供者⼤于1个，则分为以下 2 种情况：
   1. 如果所有服务权重值不同，则按 RandomLoadBalance（2） 过程，选出服务提供者。
   2. 如果所有服务权重相同，则随机返回⼀个。

```java
public class ShortestResponseLoadBalance extends AbstractLoadBalance {
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
		...
        // 1. 遍历所有invoker
        for (int i = 0; i < length; i++) {
            // 2. 获取每个invoker的rpcStatus（记录着各种调用统计）
            Invoker<T> invoker = invokers.get(i);
            RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName());
            // 3. 获取平均成功调用时长 = 成功调用的总时长 / 成功调用总次数，记录方式见《限流原理》
            long succeededAverageElapsed = rpcStatus.getSucceededAverageElapsed();
            // 4. 获取此时并发调用数（活跃数，指从请求到未响应结果的调用），记录方式见《限流原理》
            int active = rpcStatus.getActive();
            // 5. 计算总响应时长 = 平均成功调用时长 * 并发调用数
            long estimateResponse = succeededAverageElapsed * active;
            // 6. 获取路由权重（包括预热降权）
            int afterWarmup = getWeight(invoker, invocation);
            weights[i] = afterWarmup;
            // 7. 判断路由最短响应时长、路由权重都相同
            if (estimateResponse < shortestResponse) {
                shortestResponse = estimateResponse;
                shortestCount = 1;
                shortestIndexes[0] = i;
                totalWeight = afterWarmup;
                firstWeight = afterWarmup;
                sameWeight = true;
            } else if (estimateResponse == shortestResponse) {
                shortestIndexes[shortestCount++] = i;
                totalWeight += afterWarmup;
                if (sameWeight && i > 0 && afterWarmup != firstWeight) {
                    sameWeight = false;
                }
            }
        }
        
        // 8. 如果路由最短响应时长的路由只有1个，则只返回第一个invoker
        if (shortestCount == 1) {
            return invokers.get(shortestIndexes[0]);
        }
        // 9. 如果不存在相同最短响应时长、相同权重的路由
        if (!sameWeight && totalWeight > 0) {
            // 10. 则随机计算权重
            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);
            // 11. 然后取响应时长中，某个区间内最响应时长最小的一个invoker
            for (int i = 0; i < shortestCount; i++) {
                int shortestIndex = shortestIndexes[i];
                offsetWeight -= weights[shortestIndex];
                if (offsetWeight < 0) {
                    return invokers.get(shortestIndex);
                }
            }
        }
        
        // 12. 如果所有路由最短响应时长、路由权重都相同，则随机取一个Invoker
        return invokers.get(shortestIndexes[ThreadLocalRandom.current().nextInt(shortestCount)]);
    }
}

```

##### ConsistentHash | 一致性哈希

- **概念**：⼀致性 hash 算法，由麻省理⼯学院的 Karger 及其合作者于 1997 年提出的，算法提出之初是⽤于⼤规模缓存系统的**负载均衡**。

- **⼯作过程**：

  ![1637325363460](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637325363460.png)

  1. ⾸先根据 ip 或者其他的信息为缓存节点⽣成⼀个 hash，并将这个 hash 投射到 [0, 232 - 1] 的圆环上。
  2. 当有查询或写⼊请求时，则为缓存项的 key ⽣成⼀个 hash 值，然后查找**第⼀个**⼤于或等于该 hash 值的缓存节点，并到这个节点中查询或写⼊缓存项。
  3. 如果那个节点挂了，则在下⼀次查询或写⼊缓存时，为缓存项查找**另⼀个**⼤于其 hash 值的缓存节点即
     可。
  4. ⼤致效果如图所示，每个缓存节点在圆环上占据⼀个位置，如果缓存项的 key 的 hash 值⼩于缓存节点 hash 值，则到该缓存节点中存储或读取缓存项。
  5. ⽐如绿⾊点对应的缓存项将会被存储到 cache-2 节点中，而如果 cache-3 挂了，则原本应该存到该节点中的缓存项，最终会存储到 cache-4 节点中。

- **一致性 hash 在 Dubbo 中的应用**：

  ![1637325455225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637325455225.png)

  1. 首先把一致性 hash 环的缓存节点替换成 Dubbo#Invoker，相同颜色的则代表同属于同一个服务。
  2. ⽐如 Invoker1-1，Invoker1-2，……, Invoker1-160，这样做的⽬的是通过**引⼊虚拟节点**，让 Invoker 在圆环上分散开来，通过虚拟节点均衡各个节点的请求量，**避免数据倾斜问题**。
     - 所谓**数据倾斜**是指，由于节点不够分散，导致⼤量请求落到了同⼀个节点上，⽽其他节点只会接收到了少量请求的情况。

```java
public class ConsistentHashLoadBalance extends AbstractLoadBalance {
    
    private final ConcurrentMap<String, ConsistentHashSelector<?>> selectors = new ConcurrentHashMap<String, ConsistentHashSelector<?>>();
    
    @Override
    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        String methodName = RpcUtils.getMethodName(invocation);
        String key = invokers.get(0).getUrl().getServiceKey() + "." + 
methodName;
 
        // 1. 获取 invokers 原始的 hashcode，
        int identityHashCode = System.identityHashCode(invokers);
        ConsistentHashSelector<T> selector = (ConsistentHashSelector<T>) 
selectors.get(key);
        // 2. 由于 invokers 是⼀个新的 List 对象，如果selector.identityHashCode != identityHashCode，则意味着服务提供者数量发⽣了变化，因为正常情况下，key-Invokers是保持不变的
        if (selector == null || selector.identityHashCode != 
identityHashCode) {
            // 3. 则创建新的ConsistentHashSelector
            selectors.put(key, new ConsistentHashSelector<T>(invokers, 
methodName, identityHashCode));
            
            // 4. 更新为刚创建的selector
            selector = (ConsistentHashSelector<T>) selectors.get(key);
        }
        
        // 18. 调⽤ ConsistentHashSelector 的 select ⽅法选择 Invoker
        return selector.select(invocation);
    }
}

private static final class ConsistentHashSelector<T> {
    // 5. 使⽤ TreeMap 存储 Invoker 虚拟节点
    private final TreeMap<Long, Invoker<T>> virtualInvokers;
    // 6. 虚拟节点数量，默认为160
    private final int replicaNumber;
	// 7. selector的hashCode，用来标志invokers是否发生变化
    private final int identityHashCode;
	// 8. 方法参数索引，用于对指定某个方法实参进行hash
    private final int[] argumentIndex;
    
    ConsistentHashSelector(List<Invoker<T>> invokers, String methodName, 
                           int identityHashCode) {
		this.virtualInvokers = new TreeMap<Long, Invoker<T>>();
        this.identityHashCode = identityHashCode;
        URL url = invokers.get(0).getUrl();
        this.replicaNumber = url.getMethodParameter(methodName, 
"hash.nodes", 160);
        
        // 9. 获取参与 hash 计算的参数下标值，默认对第1个参数进⾏ hash 运算，可通过hash.arguments配置多个比如"0,1,2"等等
        String[] index = 
Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, 
"hash.arguments", "0"));
        argumentIndex = new int[index.length];
        for (int i = 0; i < index.length; i++) {
            argumentIndex[i] = Integer.parseInt(index[i]);
        }
        
        // 10. 遍历Invokers，准备建立虚拟节点
        for (Invoker<T> invoker : invokers) {
            String address = invoker.getUrl().getAddress();
            for (int i = 0; i < replicaNumber / 4; i++) {
                // 11. 对 address + i 进⾏ md5 运算，得到⼀个⻓度为16的字节数组
                byte[] digest = md5(address + i);
                // 12. 对 digest 部分字节进⾏ 4 次 hash 运算，得到四个不同的 long 型正整数
                for (int h = 0; h < 4; h++) {
                    // 13. h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进⾏位运算
                    // 14. h = 1 时，取 digest 中下标为 4 ~ 7 的4个字节进⾏位运算
                    // 15. h = 2 时，取 digest 中下标为 8 ~ 11 的4个字节进⾏位运算
                    // 16. h = 3 时，取 digest 中下标为 12 ~ 15 的4个字节进⾏位运算
                    long m = hash(digest, h);
                    // 17. 将（计算好的落环 hash 值 -> invoker 的映射关系）存储到 virtualInvokers 中，使用 TreeMap 提供⾼效的查询操作
                    virtualInvokers.put(m, invoker);
                }
            }
        }
    }
    
    // 13、14、15、16、23、虚拟节点哈希落环规则
    private long hash(byte[] digest, int number) {
        return (((long) (digest[3 + number * 4] & 0xFF) << 24)
                | ((long) (digest[2 + number * 4] & 0xFF) << 16)
                | ((long) (digest[1 + number * 4] & 0xFF) << 8)
                | (digest[number * 4] & 0xFF))
            & 0xFFFFFFFFL;
    }
    
    // 19. 调⽤ ConsistentHashSelector 的 select ⽅法选择 Invoker
    public Invoker<T> select(Invocation invocation) {
        // 20. 将参数转为 key
        String key = toKey(invocation.getArguments());
        // 22. 生成JDK MD5消息摘要
        byte[] digest = Bytes.getMD5(key);
        // 24. 根据落环后的hash值，寻找合适的 Invoker
        return selectForKey(
            // 23. h = 0 时，取 digest 中下标为 0 ~ 3 的4个字节进⾏位运算
            hash(digest, 0));
    }
    
    private String toKey(Object[] args) {
        StringBuilder buf = new StringBuilder();
        // 21. 根据hash.arguments配置的hash参数索引，进行拼凑成key，因此，同服务的Dubbo一致性哈希的负载均衡逻辑，只受参数值影响，具有相同参数值的请求将会被分配到同一个服务提供者，且没有权重的概念
        for (int i : argumentIndex) {
            if (i >= 0 && i < args.length) {
                buf.append(args[i]);
            }
        }
        return buf.toString();
    }
    
    private Invoker<T> selectForKey(long hash) {
        // 25. 根据落环的hash值，到 TreeMap 中查找第⼀个⼤于或等于当前 hash 的 Invoker
        Map.Entry<Long, Invoker<T>> entry = virtualInvokers.ceilingEntry(hash);
        // 26. 如果没找到，说明落环的 hash 值，已经⼤于所有 Invoker 在圆环上最⼤的位置，此时需要将 TreeMap 的头节点赋值给 entry，表示获取第一个 Invoker
        if (entry == null) {
            entry = virtualInvokers.firstEntry();
        }
        // 27. 最后返回找到的 Invoker，完成Dubbo一致性hash的负载均衡
        return entry.getValue();
    }
}
```

### 2.9. Dubbo 线程派发模型？

#### 请求派发策略

| 请求派发策略 | 特点                                                         | 对应 Netty Boss-Worker 模型                                  |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| all          | 全部派发，**默认**的请求派发策略，所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等 | Worker 线程接收到事件后，只会把事件提交到线程池，⾃⼰去处理其他事情 |
| direct       | 直接执行，所有消息都不派发到线程池，全部在 IO 线程上直接执行 | Worker 线程接收到事件后，只会由自己执⾏到底                  |
| message      | 派发请求和响应，只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在 IO 线程上执行 | Worker 线程接收到事件后，只会把请求和响应消息派发到线程池，其他消息由自己执行到底 |
| execution    | 派发请求，只有请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在 IO 线程上执行 | Worker 线程接收到事件后，只会把请求消息派发到线程池，其他消息由自己执行到底 |
| connection   | 在 IO 线程上执行连接与断开事件，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池 | Worker 线程接收到事件后，只会把连接和断开消息加入队列自己处理，其他消息则会派发到线程池 |

#### 策略实现原理

![1636383507769](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1636383507769.png)

1. 上图是 Dubbo Server 端的请求派发流程，在 Dispatcher 节点，接收到 Client 请求后，根据不同的策略，派发到 ThreadPool 业务线程池中。

```java
public class NettyTransporter implements Transporter {
    @Override
    public Server bind(URL url, ChannelHandler listener) throws RemotingException {
        // 0. 打开Netty服务器
        return new NettyServer(url, listener);
    }
}

public class NettyServer extends AbstractServer implements RemotingServer {
    // 1. 构造NettyServer
    public NettyServer(URL url, ChannelHandler handler) throws RemotingException {
        super(ExecutorUtil.setThreadName(url, SERVER_THREAD_POOL_NAME), 
              // 2. 使用请求派发策略包装 ChannelHandler
              ChannelHandlers.wrap(handler, url));
    }
}

public class ChannelHandlers {
    
    private static ChannelHandlers INSTANCE = new ChannelHandlers();

    protected ChannelHandlers() {
    }
    
    public static ChannelHandler wrap(ChannelHandler handler, URL url) {
        // 3. 获取ChannelHandlers单例，并根据请求派发策略包装ChannelHandler
        return ChannelHandlers.getInstance().wrapInternal(handler, url);
    }
    
    protected static ChannelHandlers getInstance() {
        return INSTANCE;
    }
    
    protected ChannelHandler wrapInternal(ChannelHandler handler, URL url) {
        return new MultiMessageHandler(new HeartbeatHandler(
             	// 4. SPI扩展请求派发策略
                ExtensionLoader.getExtensionLoader(Dispatcher.class)
                .getAdaptiveExtension()
                .dispatch(handler, url)));
    }
}

```

##### all | 全部派发

```java
public class AllDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建AllChannelHandler对ChannelHandler事件进行派发
        return new AllChannelHandler(handler, url);
    }
}

public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void connected(Channel channel) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 1. 连接事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 2. 断开连接事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 3. 接收事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
        	...
        }
    }
    
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 4. 异常事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));
        } catch (Throwable t) {
            ...
        }
    }
}

```

##### direct | 全不派发

```java
public class DirectDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建DirectChannelHandler对ChannelHandler事件进行派发
        return new DirectChannelHandler(handler, url);
    }
}

public class DirectChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        if (executor instanceof ThreadlessExecutor) {
            try {
                // 1. 接收事件，使用 ThreadlessExecutor，将回调直接委托给发起调用的线程。
                executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
            } catch (Throwable t) {
                ...
            }
        } 
        // 2. 否则，判断后交由ChannelHandler IO线程去执行
        else {
            handler.received(channel, message);
        }
    }
}

public class WrappedChannelHandler implements ChannelHandlerDelegate {
    
    // 3. 连接事件，交由ChannelHandler IO线程去执行
    @Override
    public void connected(Channel channel) throws RemotingException {
        handler.connected(channel);
    }
    
    // 4. 断开连接事件，交由ChannelHandler IO线程去执行
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        handler.disconnected(channel);
    }
    
    // 5. 接收事件，交由ChannelHandler IO线程去执行，对于DirectChannelHandler不会执行，因为它重写了该方法
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        handler.received(channel, message);
    }
    
    // 6. 发送事件，交由ChannelHandler IO线程去执行
    @Override
    public void sent(Channel channel, Object message) throws RemotingException {
        handler.sent(channel, message);
    }
    
    // 7. 异常事件，交由ChannelHandler IO线程去执行
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        handler.caught(channel, exception);
    }
}

```

##### message | 只派发请求和响应

```java
public class MessageOnlyDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建MessageOnlyChannelHandler对ChannelHandler事件进行派发
        return new MessageOnlyChannelHandler(handler, url);
    }
}

public class MessageOnlyChannelHandler extends WrappedChannelHandler {
   @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 1. 接收事件，派发到业务线程池，其余地均交由ChannelHandler IO线程去执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
            ...
        }
    }
}

```

##### execution | 只派发请求

```java
public class ExecutionDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建ExecutionChannelHandler对ChannelHandler事件进行派发
        return new ExecutionChannelHandler(handler, url);
    }
}

public class ExecutionChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);

        // 1.只有请求接收事件，才会派发到业务线程池
        if (message instanceof Request) {
            try {
                executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
            } catch (Throwable t) {
                ...
            }
        } 
        // 2. 其余接收事件，使用 ThreadlessExecutor，将回调直接委托给发起调用的线程
        else if (executor instanceof ThreadlessExecutor) {
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } 
        // 3. 否则，判断后交由ChannelHandler IO线程去执行，与DirectChannelHandler类似
        else {
            handler.received(channel, message);
        }
    }
}

```

##### connection | 串行处理连接和断开事件

```java
public class ConnectionOrderedDispatcher implements Dispatcher {
    @Override
    public ChannelHandler dispatch(ChannelHandler handler, URL url) {
        // 0. 构建ConnectionOrderedChannelHandler对ChannelHandler事件进行派发
        return new ConnectionOrderedChannelHandler(handler, url);
    }
}

public class ConnectionOrderedChannelHandler extends WrappedChannelHandler {
    
    protected final ThreadPoolExecutor connectionExecutor;
    
    public ConnectionOrderedChannelHandler(ChannelHandler handler, URL url) {
        ...
        // 1. 构造一个只有1个线程的无界阻塞队列线程池
        connectionExecutor = new ThreadPoolExecutor(1, 1,
                0L, TimeUnit.MILLISECONDS,
                new LinkedBlockingQueue<Runnable>(url.getPositiveParameter(CONNECT_QUEUE_CAPACITY, Integer.MAX_VALUE)),
                new NamedThreadFactory(threadName, true),
                new AbortPolicyWithReport(threadName, url)
        );  
    }
    
    @Override
    public void connected(Channel channel) throws RemotingException {
        try {
            ...
            // 2. 连接事件，派发到队列中，串行执行
            connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void disconnected(Channel channel) throws RemotingException {
        try {
            ...
            // 3. 断开连接事件，派发到队列中，串行执行
            connectionExecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.DISCONNECTED));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 4. 接收事件，派发到业务线程池执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
            ...
        }
    }
    
    @Override
    public void caught(Channel channel, Throwable exception) throws RemotingException {
        ExecutorService executor = getExecutorService();
        try {
            // 5. 异常事件，派发到业务线程池执行
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));
        } catch (Throwable t) {
            ...
        }
    }
}

```

### 3.0. Dubbo 线程池类型？

#### 线程池类型

![1637247042637](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1637247042637.png)

以默认的 all 派发策略，以及 Netty4 同步调用为例：

1. 客户端主线程，发出⼀个请求后获得 future 实例，在执⾏ get（）时，进⾏阻塞等待。
2. 服务端使⽤ worker 线程（Netty 通信模型），接收到请求后，会将请求提交到 Dubbo#Server 业务线程池中进⾏处理。
3. Dubbo#Server 业务线程，处理完成之后，将相应结果返回给客户端的 worker 线程池（Netty 通信模型）。
4. 最后，客户端的 worker 线程，将响应结果提交到 Dubbo#Client 业务线程池进⾏处理。
5. Dubbo#Client 业务线程，把响应结果填充到之前的 future 实例中，然后唤醒等待的客户端主线程。
6. 最后客户端主线程获取到结果，然后返回给客户端，完成一次 RPC 调用。

| 线程池类型 | 特点                                                         |
| ---------- | ------------------------------------------------------------ |
| fixed      | 默认类型，固定大小线程池，启动时建立线程，不关闭，一直持有   |
| cached     | 缓存线程池，空闲一分钟自动删除，需要时重建                   |
| limited    | 可伸缩线程池，但池中的线程数只会增长不会收缩，只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题 |
| eager      | 正常类型的线程池，即优先创建 `Worker` 线程池，在任务数量大于 `corePoolSize` 、小于 `maximumPoolSize` 时，优先创建 `Worker` 来处理任务。当任务数量大于 `maximumPoolSize` 时，将任务放入阻塞队列中。阻塞队列充满时抛出 `RejectedExecutionException`，相比于`cached` 缓存线程池，在任务数量超过 `maximumPoolSize` 时，不会抛出异常，而是将任务放入阻塞队列 |

#### 线程池实现原理

```java
public class AllChannelHandler extends WrappedChannelHandler {
    @Override
    public void received(Channel channel, Object message) throws RemotingException {
        // 0.1. 获取线程池
        ExecutorService executor = getPreferredExecutorService(message);
        try {
            // 0.2. 接收事件，派发到业务线程池
            executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
        } catch (Throwable t) {
        	...
        }
    }
}

public class WrappedChannelHandler implements ChannelHandlerDelegate {
    public ExecutorService getPreferredExecutorService(Object msg) {
        ...
        // 1. 获取Server端和Client端共享的业务线程池
        return getSharedExecutorService();
    }
    
    public ExecutorService getSharedExecutorService() {
        // 2. 获取线程池仓库DefaultExecutorRepository
        ExecutorRepository executorRepository =
  ExtensionLoader.getExtensionLoader(ExecutorRepository.class).getDefaultExtension();
        ExecutorService executor = executorRepository.getExecutor(url);
        if (executor == null) 
            // 3. SPI构造线程池
            executor = executorRepository.createExecutorIfAbsent(url);
        }
        return executor;
    }
}

public class DefaultExecutorRepository implements ExecutorRepository {
    public synchronized ExecutorService createExecutorIfAbsent(URL url) {
        ...
        // 4. SPI构造线程池
        executor = createExecutor(url);
        ...
    }
    
    private ExecutorService createExecutor(URL url) {
        // 5. SPI构造线程池，默认为fixed类型
        return (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class).getAdaptiveExtension().getExecutor(url);
    }
}

```

##### fixed | 固定大小型

```java
public class FixedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取threads配置参数，默认为200
        int threads = url.getParameter(THREADS_KEY, DEFAULT_THREADS);
        // 3. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 4. 默认构造200个固定线程、同步阻塞队列的线程池
        return new ThreadPoolExecutor(threads, threads, 0, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}

```

##### cached | 缓存型

```java
public class CachedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为Integer.MAX_VALUE，表示无界
        int threads = url.getParameter(THREADS_KEY, Integer.MAX_VALUE);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 读取alive配置参数，默认为60 * 1000，表示60s最大空闲时间，即空闲时最大缓存时间为60s
        int alive = url.getParameter(ALIVE_KEY, DEFAULT_ALIVE);
        // 6. 默认构造核心数为0，最大线程数为Integer.MAX_VALUE，60s最大空闲时间的同步阻塞队列的线程池
        return new ThreadPoolExecutor(cores, threads, alive, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}

```

##### limited | 可伸缩型（线程数只能增加不能减少）

```java
public class LimitedThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为200
        int threads = url.getParameter(THREADS_KEY, DEFAULT_THREADS);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 默认构造核心数为0，最大线程数为200，用不过期的，线程数只能增加不能减少的线程池
        return new ThreadPoolExecutor(cores, threads, Long.MAX_VALUE, TimeUnit.MILLISECONDS,
                queues == 0 ? new SynchronousQueue<Runnable>() :
                        (queues < 0 ? new LinkedBlockingQueue<Runnable>()
                                : new LinkedBlockingQueue<Runnable>(queues)),
                new NamedInternalThreadFactory(name, true), new AbortPolicyWithReport(name, url));
    }
}

```

##### eager | 正常型

```java
public class EagerThreadPool implements ThreadPool {
    @Override
    public Executor getExecutor(URL url) {
        // 1. 读取threadname配置参数，默认为Dubbo
        String name = url.getParameter(THREAD_NAME_KEY, DEFAULT_THREAD_NAME);
        // 2. 读取corethreads配置参数，默认为0
        int cores = url.getParameter(CORE_THREADS_KEY, DEFAULT_CORE_THREADS);
        // 3. 读取threads配置参数，默认为Integer.MAX_VALUE，表示无界
        int threads = url.getParameter(THREADS_KEY, Integer.MAX_VALUE);
        // 4. 读取queues配置参数，默认为0
        int queues = url.getParameter(QUEUES_KEY, DEFAULT_QUEUES);
        // 5. 读取alive配置参数，默认为60 * 1000，表示60s最大空闲时间，即空闲时最大缓存时间为60s
        int alive = url.getParameter(ALIVE_KEY, DEFAULT_ALIVE);
        // 6. 默认构造1容量的TaskQueue
        TaskQueue<Runnable> taskQueue = new TaskQueue<Runnable>(queues <= 0 ? 1 : queues);
        // 8. 根据参数正常构造EagerThreadPoolExecutor
        EagerThreadPoolExecutor executor = new EagerThreadPoolExecutor(cores,
                threads,
                alive,
                TimeUnit.MILLISECONDS,
                taskQueue,
                new NamedInternalThreadFactory(name, true),
                new AbortPolicyWithReport(name, url));
        
        // 10. 最后还回写线程池实例到阻塞队列中（与正常线程池不同的地方，用于在添加任务时，获取线程池的线程数量，然后判断是否阻塞）
        taskQueue.setExecutor(executor);
        return executor;
    }
}

public class TaskQueue<R extends Runnable> extends LinkedBlockingQueue<Runnable> {
    public TaskQueue(int capacity) {
        // 7. TaskQueue等同于LinkedBlockingQueue
        super(capacity);
    }
}

public class EagerThreadPoolExecutor extends ThreadPoolExecutor {
    public EagerThreadPoolExecutor(int corePoolSize,
                                   int maximumPoolSize,
                                   long keepAliveTime,
                                   TimeUnit unit, TaskQueue<Runnable> workQueue,
                                   ThreadFactory threadFactory,
                                   RejectedExecutionHandler handler) {
        // 9. EagerThreadPoolExecutor等同于ThreadPoolExecutor
        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);
    }
}

```

### 3.1. Dubbo 限流原理？

```java
// 1. 使用ProtocolFilterWrapper#buildInvokerChain构造过滤器链，在服务端的export方法和消费端refer方法都会用到
public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        if (!filters.isEmpty()) {
            for (int i = filters.size() - 1; i >= 0; i--) {
                final Filter filter = filters.get(i);
                final Invoker<T> next = last;
                last = new Invoker<T>() {
                    ...
                    @Override
                    public Result invoke(Invocation invocation) throws RpcException {
                        Result asyncResult;
                        try {
                            // 2. 根据服务端和消费端，构造不同的过滤器
                            asyncResult = filter.invoke(next, invocation);
                        } catch (Exception e) {
                            ...
                        }
                        return asyncResult;
                    }
                    ...
                };
            }
        }
        ...
    }
}

// 3. 限流统计用到的核心类（服务端和消费端限流都会用到）
public class RpcStatus {
    // 4. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
    public static boolean beginCount(URL url, String methodName, int max) {
        max = (max <= 0) ? Integer.MAX_VALUE : max;
        // 5、 取出应用级别、方法级别的统计信息
        RpcStatus appStatus = getStatus(url);
        RpcStatus methodStatus = getStatus(url, methodName);
        // 6. 如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (methodStatus.active.get() == Integer.MAX_VALUE) {
            return false;
        }
        // 7. 否则进行自旋+1，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        for (int i; ; ) {
            i = methodStatus.active.get();
            if (i + 1 > max) {
                return false;
            }
            if (methodStatus.active.compareAndSet(i, i + 1)) {
                break;
            }
        }
        // 8. 最后不需要限流的，则应用级别的自旋+1，然后返回true
        appStatus.active.incrementAndGet();
        return true;
    }

    // 9. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
    public static void endCount(URL url, String methodName, long elapsed, boolean succeeded) {
        // 10. 结束应用级别单次调用的统计
        endCount(getStatus(url), elapsed, succeeded);
        // 11. 结束方法级别单词调用的统计
        endCount(getStatus(url, methodName), elapsed, succeeded);
    }

    private static void endCount(RpcStatus status, long elapsed, boolean succeeded) {
        // 12. 活跃数-1
        status.active.decrementAndGet();
        // 13. 调用总数+1
        status.total.incrementAndGet();
        // 14. 累加单次调用花费时间
        status.totalElapsed.addAndGet(elapsed);
        if (status.maxElapsed.get() < elapsed) {
            status.maxElapsed.set(elapsed);
        }
        // 15. 如果调用成功，则累加单次成功调用花费时间
        if (succeeded) {
            if (status.succeededMaxElapsed.get() < elapsed) {
                status.succeededMaxElapsed.set(elapsed);
            }
        } 
        // 16. 如果调用失败，则累加调用失败次数，以及累加单次失败调用花费的时间
        else {
            status.failed.incrementAndGet();
            status.failedElapsed.addAndGet(elapsed);
            if (status.failedMaxElapsed.get() < elapsed) {
                status.failedMaxElapsed.set(elapsed);
            }
        }
    }
}

```

#### 服务端限流

1. ExecuteLimitFilter 继承了 Filter.Listener，本质上也是一个监听器，提供 `onResponse()` 监听响应成功的方法，`onError` 监听响应异常的方法。
2. ExecuteLimitFilter 的 `invoke()` 先调⽤ `RpcStatus#beginCount()` 来判断是否可以通过，不通过则**抛出RpcException**。
3. 通过则记录开始执⾏的时间，则记录 `execute_limit_filter_start_time` 值，然后执⾏ `invoker.invoke()` 。
4. 执⾏结束时会回调 Listener 的`onResponse()` 或 `onError()` ，而它们都会调⽤ `RpcStatus#endCount()`，该⽅法会通过 `getElapsed()` ，取出 `execute_limit_filter_start_time` 值，以计算执⾏耗时。

```java
// ServiceBean实现了ApplicationListener，在ContextRefreshedEvent发布，即Spring上下文准备完毕时，会回调onApplicationEvent方法，拉起ServiceBean
public class ServiceBean<T> extends ServiceConfig<T> implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware, ApplicationEventPublisherAware {
   	private void doExportUrlsFor1Protocol(ProtocolConfig protocolConfig, List<URL> registryURLs) {
        ...
        // 0.1. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_REMOTE.equalsIgnoreCase(scope)) {
            exportLocal(url);
        }
        ... 
        // 0.2. 如果不是只暴露远程服务（一般不配），则暴露本地服务
        if (!SCOPE_LOCAL.equalsIgnoreCase(scope)) {
            // 0.3. 这里是Server端，获取interfaceClass的javasist动态代理Wrapper包装类Invoker
            Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString()));
            DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);
            
            // 0.4. 通过RegistryProtocol#export暴露远程服务，获取对应的exporter
            Exporter<?> exporter = protocol.export(wrapperInvoker);
            ...
        }
        ...
    }
}    

public class RegistryProtocol implements Protocol {
    @Override
    public <T> Exporter<T> export(final Invoker<T> originInvoker) throws RpcException 	  {
       	// 0.5. 打开Netty服务器，利用Netty NIO特性，把同步操作转换为I/O监听的异步操作，以打开本地Dubbo服务，最后把DubboExporter缓存到exportes中
        final ExporterChangeableWrapper<T> exporter = doLocalExport(originInvoker, providerUrl);
        // ... 连接、订阅、监听ZK
    }
    
    private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
        String key = getCacheKey(originInvoker);
        return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
            Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
            // 0.6. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
            return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
        });
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Exporter<T> export(Invoker<T> invoker) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(invoker.getUrl().getProtocol())) {
            return protocol.export(invoker);
        }
        // 0.7. ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return protocol.export(buildInvokerChain(invoker, SERVICE_FILTER_KEY, CommonConstants.PROVIDER));
    }
}

// 1. 服务端限流，则构造ExecuteLimitFilter
@Activate(group = CommonConstants.PROVIDER, value = EXECUTES_KEY)
public class ExecuteLimitFilter implements Filter, Filter.Listener {
    
    private static final String EXECUTE_LIMIT_FILTER_START_TIME = "execute_limit_filter_start_time";
    
    @Override
    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {
        // 2. 获取invoker的url和响应的方法名称
        URL url = invoker.getUrl();
        String methodName = invocation.getMethodName();
        // 3. 获取参数配置的executes，默认为0，表示服务提供者的，每个服务的，每个方法的，最大可并行执行请求数
        int max = url.getMethodParameter(methodName, EXECUTES_KEY, 0);
        // 4. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (!RpcStatus.beginCount(url, methodName, max)) {
            // 4.1. 如果进行了限流，则抛出异常
            throw new RpcException(...)
        }
        // 5. 远程调用前，先记录当前时间execute_limit_filter_start_time
        invocation.put(EXECUTE_LIMIT_FILTER_START_TIME, System.currentTimeMillis());
        try {
            // 6. 进行本地实现类的动态代理类的方法调用
            return invoker.invoke(invocation);
        } catch (Throwable t) {
            if (t instanceof RuntimeException) {
                throw (RuntimeException) t;
            } else {
                throw new RpcException(...);
            }
        }
    }

    // 7. 根据记录的execute_limit_filter_start_time，算出本地方法调用总共花费的时间
    private long getElapsed(Invocation invocation) {
        Object beginTime = invocation.get(EXECUTE_LIMIT_FILTER_START_TIME);
        return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0;
    }
                                   
    @Override
    public void onResponse(Result appResponse, Invoker<?> invoker, Invocation invocation) {
        // 8. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), true);
    }

    @Override
    public void onError(Throwable t, Invoker<?> invoker, Invocation invocation) {
        ...
  		// 9. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(invoker.getUrl(), invocation.getMethodName(), getElapsed(invocation), false);
    }
}

```

#### 消费端限流

1. ActiveLimitFilter 继承了 Filter.Listener，本质上也是一个监听器，提供 `onResponse()` 监听响应成功的方法，`onError` 监听响应异常的方法。
2. ActiveLimitFilter 的 `invoke()` 先调⽤ `RpcStatus#beginCount()` 来判断是否可以通过，不通过则**阻塞当前线程**。
3. 通过则记录开始执⾏的时间，则记录 `activelimit_filter_start_time` 值，然后执⾏ `invoker.invoke()` 。
4. 执⾏结束时会回调 Listener 的`onResponse()` 或 `onError()` ，而它们都会调⽤ `RpcStatus#endCount()`，该⽅法会通过 `getElapsed()` ，取出 `activelimit_filter_start_time` 值，以计算执⾏耗时，并**唤醒单例rpcStatus阻塞的所有线程**。

```java
// ReferenceBeans实现了FactoryBean，在注入Dubbo#ref接口接口时，Spring会回调getObject方法，拉起ReferenceBean
public class ReferenceBean<T> extends ReferenceConfig<T> implements FactoryBean, ApplicationContextAware, InitializingBean, DisposableBean {

    private T createProxy(Map<String, String> map) {
        // 0. 如果为本地暴露服务，则生成本地执行的Invoker
    	if (shouldJvmRefer(map)) {
            URL url = new URL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName()).addParameters(map);
            invoker = REF_PROTOCOL.refer(interfaceClass, url);
            ...
        } else {
            for (URL url : urls) {
                // 0.1 如果不是本地暴露服务，则生成远程服务引用的Invoker
                invokers.add(REF_PROTOCOL.refer(interfaceClass, url));
            }
            ...
    	}
        ...
    }
}

public class ProtocolFilterWrapper implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        if (REGISTRY_PROTOCOL.equals(url.getProtocol())) {
            return protocol.refer(type, url);
        }
        // 0.2 ProtocolFilterWrapper过滤扩展链装饰（8个过滤器）
        return buildInvokerChain(protocol.refer(type, url), REFERENCE_FILTER_KEY, CommonConstants.CONSUMER);
    }
}

// 1. 消费端限流，则构造ActiveLimitFilter
@Activate(group = CONSUMER, value = ACTIVES_KEY)
public class ActiveLimitFilter implements Filter, Filter.Listener {
    
    private static final String ACTIVELIMIT_FILTER_START_TIME = "activelimit_filter_start_time";
    
    @Override
    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {
        // 2. 获取url和方法名称
        URL url = invoker.getUrl();
        String methodName = invocation.getMethodName();
        // 3. 获取参数配置的actives，默认为0，表示每个服务消费者的，每个服务的，每个方法的，最大并发调用数
        int max = invoker.getUrl().getMethodParameter(methodName, ACTIVES_KEY, 0);
        // 4. 从缓存中获取方法级别的单例rpcStatus（多个线程共享，用于synchronized）
        final RpcStatus rpcStatus = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName());
        // 5. 开始统计，如果方法活跃数，即并发调用数，等于了最大值则返回false，表示进行了限流
        if (!RpcStatus.beginCount(url, methodName, max)) {
            // 6. 获取参数配置的timeout，默认为0，表示超时时间
            long timeout = invoker.getUrl().getMethodParameter(invocation.getMethodName(), TIMEOUT_KEY, 0);
            long start = System.currentTimeMillis();
            long remain = timeout;
            synchronized (rpcStatus) {
                while (!RpcStatus.beginCount(url, methodName, max)) {
                    try {
                        // 7. 如果进行了限流，则阻塞当前线程，直到别的线程调用响应或者异常后，才会被唤醒
                        rpcStatus.wait(remain);
                    } catch (InterruptedException e) {
                        // ignore
                    }
                    // 8. 线程被唤醒后，则计算剩余超时时间，如果为负数，则抛出异常，代表调用超时
                    long elapsed = System.currentTimeMillis() - start;
                    remain = timeout - elapsed;
                    if (remain <= 0) {
                        throw new RpcException(...);
                    }
                }
            }
        }
        // 9. 如果没被进行限流，或者仍没有超时，则先记录activelimit_filter_start_time
        invocation.put(ACTIVELIMIT_FILTER_START_TIME, System.currentTimeMillis());
		// 10. 进行远程调用
        return invoker.invoke(invocation);
    }

    // 11. 根据记录的activelimit_filter_start_time，算出远程调用总共花费的时间
    private long getElapsed(Invocation invocation) {
        Object beginTime = invocation.get(ACTIVELIMIT_FILTER_START_TIME);
        return beginTime != null ? System.currentTimeMillis() - (Long) beginTime : 0;
    }
    
    @Override
    public void onResponse(Result appResponse, Invoker<?> invoker, Invocation invocation) {
        ...
		// 12. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(url, methodName, getElapsed(invocation), true);
        // 13. 当前线程响应成功，则唤醒单例rpcStatus阻塞的所有线程
        notifyFinish(RpcStatus.getStatus(url, methodName), max);
    }

    @Override
    public void onError(Throwable t, Invoker<?> invoker, Invocation invocation) {
        ...
		// 15. 结束统计，活跃数-1，以及累加调用总数、失败调用总数、成功和失败调用花费的时间
        RpcStatus.endCount(url, methodName, getElapsed(invocation), false);
        // 16. 当前线程响应失败，则唤醒单例rpcStatus阻塞的所有线程 
        notifyFinish(RpcStatus.getStatus(url, methodName), max);
    }
    
    // 14. 唤醒单例rpcStatus阻塞的所有线程
    private void notifyFinish(final RpcStatus rpcStatus, int max) {
        if (max > 0) {
            synchronized (rpcStatus) {
                rpcStatus.notifyAll();
            }
        }
    }
}

```

### 3.2. Dubbo 降级原理？

#### 容错 | 失败处理

1. 当系统出现非业务异常（不可知、不可预测的异常），比如并发数太高导致的服务超时、网络异常等。
2. 为保证核心链路不受此异常影响，可对**该接口**进行降级处理，采用控制台动态配置 `mock=fail:return null`，失败时不对接口进行处理。

#### 屏蔽 | 强制屏蔽

1. 而对于大促、促销、双 11 等一些可预知、可预测的情况下，为保证核心链路不受非核心接口的影响，可以提前对**非核心接口**进行降级处理，采用控制台动态配置 `mock=force:return null` ，强制屏蔽接口。

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 0. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

public class InvokerInvocationHandler implements InvocationHandler {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        ...
        // 0.1 动态代理执行
		return invoker.invoke(new RpcInvocation(method, args)).recreate();
    }
}

public class MockClusterInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        Result result = null;
        // 1. 获取参数配置的mock，默认为false
        String value = directory.getUrl().getMethodParameter(invocation.getMethodName(), MOCK_KEY, Boolean.FALSE.toString()).trim();
        // 2. 默认值不进行降级，则直接进行invoker调用
        if (value.length() == 0 || value.equalsIgnoreCase("false")) {
            result = this.invoker.invoke(invocation);
        } 
        else if (value.startsWith("force")) {
            ...
            // 3. 如果有值，且以force开头，说明为屏蔽，则调用doMockInvoke(invocation, null)
            result = doMockInvoke(invocation, null);
        } else {
            try {
                result = this.invoker.invoke(invocation);
            } catch (RpcException e) {
                ...
                // 4. 如果有值，但不以force开头，说明为容错，则异常时才调用doMockInvoke(invocation, e)，其中e是用来记录原始异常信息的，并没有其他作用
                result = doMockInvoke(invocation, e);
            }
        }
        
        // 9. 因此，对于屏蔽来说，则直接返回null；对于容错来说，则先远程调用，在调用异常时才进行降级处理，然后返回null
        return result;
    }
    
    private Result doMockInvoke(Invocation invocation, RpcException e) {
        ...
        try {
            // 5. 调用MockInvoker#invoker方法进行降级
            result = minvoker.invoke(invocation);
        } catch (RpcException me) {
            ...
        } catch (Throwable me) {
            ...
        }
        
        // 8. 降级后返回null
        return result;
    }
}

final public class MockInvoker<T> implements Invoker<T> {
    @Override
    public Result invoke(Invocation invocation) throws RpcException {
        ...
        // 6. 提取参数配置的mock内容（降级的为return null），如果为return开头
        if (mock.startsWith(RETURN_PREFIX)) {
            mock = mock.substring(RETURN_PREFIX.length()).trim();
            try {
                Type[] returnTypes = RpcUtils.getReturnTypes(invocation);
                Object value = parseMockValue(mock, returnTypes);
                /// 7. 则直接返回null
                return AsyncRpcResult.newDefaultAsyncResult(value, invocation);
            } catch (Exception ew) {
                throw new RpcException(...);
            }
        } else if (mock.startsWith(THROW_PREFIX)) {
            ...
        } else {
            ...
        }
    }
}

```

### 3.3. Dubbo 设计模式？

#### 1、责任链模式

1. 责任链模式，在 Dubbo 中发挥的作⽤举⾜轻重，就像是 Dubbo 框架的⻣架。
2. Dubbo 调⽤链组织是⽤责任链模式串连起来的，责任链中的每个节点实现 Filter 接⼝，然后由
   **ProtocolFilterWrapper**，将所有 Filter 串连起来。
3. 通过 Filter 扩展实现了 Dubbo 许多功能，⽐如监控、⽇志、缓存、安全、telnet 以及 RPC 本身都是。
4. 如果把 Dubbo ⽐作⼀列⽕⻋，那么责任链就像是⽕⻋的各⻋厢，每个⻋厢的功能不同，如果需要加⼊新的功能，增加⻋厢就可以了，⾮常容易扩展。

```java
// 1. 使用ProtocolFilterWrapper#buildInvokerChain构造过滤器链，在服务端的export方法和消费端refer方法都会用到
public class ProtocolFilterWrapper implements Protocol {
    private static <T> Invoker<T> buildInvokerChain(final Invoker<T> invoker, String key, String group) {
        ...
        if (!filters.isEmpty()) {
            for (int i = filters.size() - 1; i >= 0; i--) {
                final Filter filter = filters.get(i);
                final Invoker<T> next = last;
                last = new Invoker<T>() {
                    ...
                    @Override
                    public Result invoke(Invocation invocation) throws RpcException {
                        Result asyncResult;
                        try {
                            // 2. 根据服务端和消费端，构造不同的过滤器
                            asyncResult = filter.invoke(next, invocation);
                        } catch (Exception e) {
                            ...
                        }
                        return asyncResult;
                    }
                    ...
                };
            }
        }
        ...
    }
}
```

#### 2、观察者模式

1. Dubbo 使⽤观察者模式最典型的例⼦是 RegistryService。
2. 消费者在初始化的时候回调⽤ subscribe ⽅法，会注册⼀个观察者，如果观察者引⽤的服务地址列表发⽣改变，就会通过 NotifyListener 通知消费者。
3. 此外，Dubbo的 InvokerListener、ExporterListener 也实现了观察者模式，只要实现该接⼝，并注册，就可以通知到 consumer 端调⽤ refer（）、provider 端调⽤ export（） 。

```java
public class RegistryDirectory<T> extends AbstractDirectory<T> implements NotifyListener {
    @Override
    public synchronized void notify(List<URL> urls) {
        ...
        // 1. 通知更新url配置，刷新Invoker列表
        refreshOverrideAndInvoker(providerURLs);
    }
    
    private void refreshOverrideAndInvoker(List<URL> urls) {
        // 2. 更新configurators配置（和服务端一样，省略代码）
        overrideDirectoryUrl();
        // 3. 刷新Invoker列表
        refreshInvoker(urls);
    }
}
```

#### 3、模板方法模式

1. 模板方法模式，指把通用的方法写到抽象父类，然后交由不同子类去实现，从而在不改变算法结构的情况下，重新定义具体的实现。
2. Dubbo 中比如 AbstractProtocol#protocolBindingRefer、AbstractProxyFactory#getProxy、AbstractClusterInvoker#doInvoke、AbstractDirectory#doList、AbstractLoadBalance#doSelect、AbstractInvoker#doInvoke、AbstractProxyInvoker#doInvoke 等，都是使用了模板方法模式，再结合 SPI 动态扩展机制，更改配置策略，就可以实现不同的算法效果，比如负载均衡、集群容错等。

```java
public abstract class AbstractLoadBalance implements LoadBalance {
    @Override
    public <T> Invoker<T> select(List<Invoker<T>> invokers, URL url, Invocation invocation) {
        ...
        // 1. 交由AbstractLoadBalance决定哪个路由规则进行负载均衡
        return doSelect(invokers, url, invocation);
    }
    
    // 2. 模板方法，默认交由RandomLoadBalance进行负载均衡
	protected abstract <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation);
}

```

#### 4、装饰者模式

1. Dubbo 中⼤量⽤到了修饰器模式。
2. ⽐如 ProtocolFilterWrapper 类是对 Protocol 类的修饰，在 export 和 refer ⽅法中，配合责任链模式，把Filter 组装成责任链，实现对 Protocol 功能的修饰。
3. 其他还有ProtocolListenerWrapper、 ListenerInvokerWrapper、InvokerWrapper等。
4. 不过，修饰器模式是⼀把双刃剑，⼀⽅⾯⽤它可以⽅便地扩展类的功能，⽽且对⽤户⽆感；但另⼀⽅⾯，过多地使⽤修饰器模式不利于理解，因为⼀个类可能经过层层修饰，最终的⾏为已经和原始⾏为偏离较⼤。

```java
private <T> ExporterChangeableWrapper<T> doLocalExport(final Invoker<T> originInvoker, URL providerUrl) {
    String key = getCacheKey(originInvoker);
    return (ExporterChangeableWrapper<T>) bounds.computeIfAbsent(key, s -> {
        Invoker<?> invokerDelegate = new InvokerDelegate<>(originInvoker, providerUrl);
        // 1. 通过ProtocolFilterWrapper过滤扩展链装饰->ProtocolListenerWrapper监听扩展链装饰->DubboProtocol#export，暴露本地Dubbo服务，打开Netty服务器
        return new ExporterChangeableWrapper<>((Exporter<T>) protocol.export(invokerDelegate), originInvoker);
    });
}

```

#### 5、代理模式

1. Dubbo 服务端，使用 Proxy 类来创建本地实现类的动态代理，对调用前做一定的包装，比如 Filter、Listener 等。
2. 而 Dubbo 消费端， 使⽤ Proxy 类来创建远程服务的动态代理，从而屏蔽⽹络通信的细节，使得⽤户在使⽤本地代理的时候，感觉和使⽤本地服务⼀样。

```java
public class JavassistProxyFactory extends AbstractProxyFactory {
    // Dubbo 服务端代理
    @Override
    public <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) {
        final Wrapper wrapper = Wrapper.getWrapper(proxy.getClass().getName().indexOf('$') < 0 ? proxy.getClass() : type);
        // 1.获取interfaceClass的javasist动态代理Wrapper包装类
        return new AbstractProxyInvoker<T>(proxy, type, url) {
            @Override
            protected Object doInvoke(T proxy, String methodName,
                                      Class<?>[] parameterTypes,
                                      Object[] arguments) throws Throwable {
                // 2. 动态代理调用实现类方法
                return wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);
            }
        };
    }
    
    // Dubbo 消费端代理
    @Override
    public <T> T getProxy(Invoker<T> invoker, Class<?>[] interfaces) {
        // 3. 生成代理对象，织入InvokerInvocationHandler
        return (T) Proxy.getProxy(interfaces).newInstance(new InvokerInvocationHandler(invoker));
    }
}

```

#### 6、适配器模式

1. 为了让⽤户根据⾃⼰的需求选择⽇志组件，Dubbo ⾃定义了⾃⼰的 Logger 接⼝，并为常⻅的⽇志组件，比如 jcl、jdk、log4j、slf4j 提供了相应的适配器。
2. 同时利⽤简单⼯⼚模式提供⼀个 LoggerFactory，客户可以创建抽象的 Dubbo ⾃定义Logger，⽽⽆需关⼼实际使⽤的⽇志组件类型。
3. 在 LoggerFactory 初始化时，客户通过设置系统变量的⽅式，来选择⾃⼰所⽤的⽇志组件，提供了很⼤的灵活性。

```java
// 实现类有：JclLoggerAdapter、JdkLoggerAdapter、Log4j2LoggerAdapter、Log4jLoggerAdapter、Slf4jLoggerAdapter
@SPI
public interface LoggerAdapter {
    Logger getLogger(Class<?> key);
    Logger getLogger(String key);
    Level getLevel();
    void setLevel(Level level);
    File getFile();
    void setFile(File file);
}

```

#### 7、工厂方法模式

1. CacheFactory 采⽤⼯⼚⽅法模式实现，它定义 getCache ⽅法，然后定义⼀个 AbstractCacheFactory 抽象类实现 CacheFactory，并将实际创建 cache 的 createCache（）分离出来，并设置为抽象⽅法，这样具体 cache 的创建⼯作，就留给具体的⼦类去完成。

```java
@SPI("lru")
public interface CacheFactory {
    @Adaptive("cache")
    Cache getCache(URL url, Invocation invocation);
}

public abstract class AbstractCacheFactory implements CacheFactory {
    ...
    // 模板方法，交由实现类去实现：ExpiringCacheFactory、JCacheFactory、LfuCacheFactory、LruCacheFactory、ThreadLocalCacheFactory
    protected abstract Cache createCache(URL url);
}

```

#### 8、抽象工厂模式

> 工厂方法模式，针对的是多个产品系列结构（同一个抽象产品角色, 同一个产品族）。
> 抽象工厂模式，针对的是多个产品族结构（多个抽象产品角色,多个产品族），一个产品族内有多个产品系列（同一个抽象产品角色, 同一个产品）。

1. ProxyFactory 及其⼦类，是Dubbo 中使⽤抽象⼯⼚模式的典型例⼦。
2. ProxyFactory 提供 getProxy（） 和 Invoker（），getProxy（）需要传⼊⼀个 Invoker 对象，针对的是消费端获取接口的动态代理；⽽ getInvoker（）需要传⼊⼀个 proxy 对象，针对的是服务端用于获取本地实现类的代理 invoker，从而创建对应的 exporter。
3. AbstractProxyFactory 实现了 ProxyFactory 接⼝，作为具体实现类的抽象⽗类，提供通用的实现。
4. 然后还定义了 JavassistProxyFactory 和 JdkProxyFactory 两个实现类，分别⽤来⽣产基于 javassist 代理机制和 jdk 代理机制的 Proxy 和 Invoker。

```java
@SPI("javassist")
public interface ProxyFactory {
    @Adaptive({PROXY_KEY})
    <T> T getProxy(Invoker<T> invoker) throws RpcException;
    
    @Adaptive({PROXY_KEY})
    <T> T getProxy(Invoker<T> invoker, boolean generic) throws RpcException;
    
    @Adaptive({PROXY_KEY})
    <T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url) throws RpcException;
}

public abstract class AbstractProxyFactory implements ProxyFactory {
    ...
    // 1. 模板方法，多态调用doInvoke方法，实现类：JavassistProxyFactory和JdkProxyFactory
    protected abstract Object doInvoke(T proxy, String methodName, Class<?>[] parameterTypes, Object[] arguments) throws Throwable;
}

```

#### 9、单例模式

1. 另外，在类创建方式方面，对于一些缓存变量，常常用单例模式实例化（线程安全+单例保证），比如 AbstractProxyFactory#INTERNAL_INTERFACES，ExtensionLoader#EXTENSION_LOADERS、EXTENSION_INSTANCES 等。

```java
public abstract class AbstractProxyFactory implements ProxyFactory {
    // 1. 饿汉式创建缓存单例
    private static final Class<?>[] INTERNAL_INTERFACES = new Class<?>[]{
            EchoService.class, Destroyable.class
    };
}

public class ExtensionLoader<T> {
    ...
    // 2. 饿汉式创建缓存单例
    private static final ConcurrentMap<Class<?>, ExtensionLoader<?>> EXTENSION_LOADERS = new ConcurrentHashMap<>();
    private static final ConcurrentMap<Class<?>, Object> EXTENSION_INSTANCES = new ConcurrentHashMap<>();
    ...
}

```

#### 10、建造者模式

1. 另外，在类创建方式方面，对于一些多参数变量，比如 org.apache.dubbo.common.URL 对象，则可以通过建造者模式构造出来（易于阅读、方便扩展）。

```java
public class RegistryProtocol implements Protocol {
    @Override
    public <T> Invoker<T> refer(Class<T> type, URL url) throws RpcException {
        // 1. 通过URLBuilder来创建URL对象
        url = URLBuilder.from(url)
                .setProtocol(url.getParameter(REGISTRY_KEY, DEFAULT_REGISTRY))
                .removeParameter(REGISTRY_KEY)
                .build();
        Registry registry = registryFactory.getRegistry(url);
        ...
    }
}

```

### 3.4. Dubbo 最佳实践？

#### 1、Provider 多配置接口参数

1. 作为服务提供⽅，自己⽐消费⽅更清楚服务的这些接口参数的取值，比如超时时间、重试次数、负载均衡策略等。
2. 由于配置覆盖策略存在，在 Provider 端配置后，Consumer 端不配置则会使⽤ Provider 端配置，即 Provider 配置可以作为 Consumer 的缺省值。
3. 而如果 Provider 不配置，Consumer 也不直接配置，则会使⽤ Consumer 端的全局设置，这对于 Provider 是不可控的，并且往往是不合理的。
4. 因此，Provider 端尽量多配置、完善这些接口参数，让 Provider 实现者⼀开始就思考 Provider 端的服
   务特点和服务质量等问题。

#### 2、Provider 合理配置性能参数

比如，**threads**（服务线程池⼤⼩）、**executes**（服务提供者并发请求的上限）。

#### 3、服务使用固定端口

使⽤固定端⼝来暴露服务，不要使⽤随机端⼝，这样在注册中⼼推送延迟的情况下，消费端仍然能够通过缓存列表，调⽤到原地址+原端口的服务，保证调⽤成功。

#### 4、推荐使用 XML 进行配置

XML 配置优先级高于 properties 和 yml，且标签的配置方式更加容易阅读和理解。

#### 5、应用配置负责人参数

配置 `dubbo:application#owner` 负责人参数，这些可以在运维平台上看到，以便于在发现问题时，找到对应服务负责⼈。

# 八、SpringCloud篇

### 1.1. 如何权衡微服务的利弊？

#### 优点

![1638067092432](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638067092432.png)

##### 1、快速响应变更

1. 得益于微服务架构遵循了单一职责的架构理念，每块微服务都划进了自身的势力范围，再也不像单体应用那样改一发而动全身，天然适用于小步快跑的开发节奏。
2. 同时，每块微服务都可以独立部署，这样就可以不受限于单体应用的发布节奏与发布窗口等条件，特别适合互联网公司糙快猛的开发模式。

##### 2、独立拓展

微服务与微服务间有非常清晰的边界，且不过度受制于技术栈，可以在当前微服务的技术栈上，有更多的话语权，能够在保持整体技术栈相对统一情况下，给到各个微服务最大的技术自由度。

##### 3、精粒度业务控制

比如说，可以把某段特定的降级熔断逻辑，放在某个特定的微服务上，然后为其指定合理的调用策略和重试策略，还可以更精粒度的局部限流，提高利用率。

##### 4、面向业务和领域模型

1. 使用微服务架构，不再依赖于底层的数据模型，而是依赖于业务和领域模型，并不会暴露给底层数据模型给其他微服务，而只是暴露业务接口和业务对象，在对底层数据模型进行更改时，不会影响到其他业务方。
2. 同时基于业务模型也非常易于抽象，比如抽象到中台等。

#### 缺点

![1638067123418](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638067123418.png)

##### 1、部署结构复杂

微服务架构模块众多，每个微服务部署、中间件千差万别，并且天生就引入了一堆额外的组件，这样就会使得部署结构变得复杂，提高了运维的成本。

##### 2、依赖平台支撑

1. 微服务架构也考验着公司的整体技术实力，非常依赖于平台的支撑，比如注册中心、配置中心、调用链路分析、服务网关等。
2. 另外，在把单体架构拆分成微服务架构时，也需要投入额外的研发成本。

##### 3、分布式问题

1. 在微服务架构下会存在一致性问题，比如串联调用了多个上下游的微服务，来共同完成一个事务，这时就需要在强一致性、弱一致性和最终一致性方案间做出选择。
2. 如果采用了最终一致性方案，还需要考虑如果做好异常补偿。

##### 4、拆分的水平

1. 微服务的拆分强依赖于当前业务，如果架构师对业务理解不到位，导致微服务拆分的粒度过粗或者过细，使得微服务的优越性大打折扣，甚至王者变青铜。 

#### 考虑要点

##### 1、从业务角度考虑

微服务拆分，不能为了微服务而微服务，需要结合自身业务，围绕业务进行拆分，而在拆之前可以从一下两个业务角度去思考：

| 思考角度     | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| 业务规模     | 比如两个极端，在业务发展得非常大时拆，和在一开始就使用微服务，此时，微服务拆分则需要考虑，在这两个极端之间，评估所要支出的成本和所能带来的收益，**决定着微服务的拆还是不拆**。 |
| 理解业务领域 | 深入理解业务架构、业务流、未来的业务规划等，**决定着如何去拆微服务**。 |

##### 2、从技术角度考虑

微服务架构落地需要亲身躬行，靠实践经验的积累才能做好，在改造过程中，需要去攻克的技术难点有：

| 技术难点   | 含义                                                         |
| ---------- | ------------------------------------------------------------ |
| 服务治理   | 服务与服务间的调用，是微服务架构第一个需要解决的问题，而**服务治理**指的是，在集群中虚机的日常上下线、扩缩容情况下，动态探知各个服务节点的状态变化，了解哪些节点可以正常提供服务、哪些节点已下线等信息。 |
| 负载均衡   | **负载均衡**指的是，面对茫茫多的服务器，如何根据实际情况，把海量用户请求分发到不同的机器，同时考虑各机器性能强弱、各机房带宽大小、网络响应快慢等实际条件。 |
| 服务调用   | 从 Java 代码发起调用，需要构造 Header 和 Body，非常麻烦，需要解决服务通信的代码编写问题，使得调用一个服务就像调用本地接口一样方便 |
| 服务容错   | 在高并发场景下，有的服务会承担较大的访问请求，可能导致响应时间过慢，甚至超时，如果调用方经常发起重试，那么势必会进一步增加被调用应用的压力，导致一个恶性循环，而解决方案就是**降级和熔断**这两种服务容错技术。 |
| 配置管理   | **服务配置管理**，可以使得随时动态调整应用配置，而无需重启机器。 |
| 服务网关   | **服务网关**，可以在微服务架构下，把用户请求转发到每个不同的服务器上。 |
| 调用链追踪 | **调用链追踪**，可以从前到后展示整个微服务调用链的全景数据。 |
| 消息驱动   | 消息组件不仅可以用于**削峰填谷**，还可以用于微服务间的**系统解耦**。 |
| 服务限流   | 再厉害的系统也有性能瓶颈，而限流则可以通过在源头处削减系统压力，是最经济高效的稳定手段，而微服务后台的服务节点数量庞大，单机版的限流远不能解决问题，因此，需要在集群范围内引入**分布式限流**。 |

### 1.2. 微服务架构设计模式？

#### 1、聚合器模式 | 少见

![1638003414651](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638003414651.png)

1. 聚合器调用多个服务，从而实现系统所需的功能，每个服务都有自己的缓存和数据库。
2. 它可以是一个简单的 WEB 页面，把检索到的数据进行处理后再展示。
3. 它也可以是一个更高层次的组合服务，对检索到的数据增加业务逻辑后，进一步发布成一个新的微服务（**DRY 原则**），也有自己的缓存和数据库，可以沿 X轴（负载均衡、读写分离） 和 Z轴（分库分表） 独立扩展。
   - **DRY 原则**：
     1. Don't Repeat Yourself，不做重复的事，指在一个设计里，对于任何东西，都应该有且只有一个表示，其它的地方都应该引用这一处。
     2. 这样需要改动的时候，只需调整这一处，所有的地方就都变更过来了。
     3. 而在降低可管理单元复杂度的一个基本策略就是，将他们拆解成更小的单元。

#### 2、代理模式 | 网关

![1638003975019](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638003975019.png)

1. 类似聚合器模式，但是客户端并不聚合数据，而是会根据业务需求的差别，调用不同的微服务。
2. 代理模式可以仅仅是委派请求，也可以进行数据转换工作。

#### 3、链式模式 | 少见

![1638004098621](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004098621.png)

1. ServiceA 接收到请求后，会与 ServiceB 进行通信，类似地，ServiceB 也会同 ServiceC 进行通信。
2. 所有服务都使用同步消息传递，在整个链式调用完成之前，客户端会一直阻塞，因此，服务调用链不宜过长，以免客户端长时间等待，是一个**同步串行处理**过程，无法进行并行处理。

#### 4、分支模式 | 常见

![1638004209220](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004209220.png)

1. 允许同时调用两个微服务链，效率更高，适合于并行调用处理。

#### 5、数据共享模式 | 过渡

![1638004289487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638004289487.png)

1. 自治是微服务的设计原则之一，就是说微服务是全栈式服务，但在重构现有的单体应用时，SQL 数据库反规范化拆分，可能会导致数据重复和不一致。
2. 因此，在单体应用到微服务架构的**过渡阶段**，可以使用这种设计模式，在这种情况下，部分微服务可能会共享缓存和数据库存储，不过，也只有在两个服务之间，存在**强耦合关系**时才可以。
3. 但这对于基于微服务的新建应用程序而言，是一种反模式，在正常的情况下，不推荐这么设计。

#### 6、异步消息模式 | 常见

![1638005387692](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638005387692.png)

1. RestFul 设计模式非常流行，但它是同步的，会造成阻塞。
2. 因此，部分基于微服务的架构，可能会选择使用消息队列，来代替 RESTFul 请求和响应，以提升吞吐量。

### 1.3. 微服务拆分原则？

1. **单一职责原则**：每个服务独立出去，有界限地工作，只需关注自身的业务，做到高内聚。
2. **服务自治原则**：每个服务做到独立开发、独立测试、独立构建、独立部署、独立运行，与其他服务解耦。
3. **轻量级通信原则**：每个服务间的调用是轻量级的，并且能够跨平台、跨语言，比如采用 Restful、消息队列等进行通信。
4. **粒度进化原则**：每个服务的粒度没有统一的标准，需要结合具体的业务问题，并且随着业务发展而进化，不要进行过度设计。

### 1.4. 微服务拆分经验方案？

微服务拆分没有一个绝对正确的方案，服务拆分的粒度完全要根据业务场景来规划，而随着业务的发展，原先的架构方案也需要做调整，其常见的拆分方案有：

#### 按压力模型拆分

压力模型，简单来说就是用户访问量，需要识别出某些**超高并发量**的业务，尽可能把这部分业务独立拆出来，其业务场景分类有：

##### 1、高频高并发场景

比如商品详情页，它是一个高频场景，同时也是一个高并发场景。

- **建议**：通常建议将高频高并发场景隔离出来，单独作为一个微服务模块，典型的就是商品详情页的后台服务。

##### 2、低频突发流量场景

比如秒杀，虽然它并不是高频场景，但是会产生突发流量。

- **建议**：对于低频突发流量场景，条件允许也可以剥离出来，但如果必须和其他业务包在一个微服务下，那一定要做好**流控**措施（比如削峰），同时还要考虑异常情况的补偿机制。

##### 3、低频流量场景

多为后台运营团队的服务接口，比如商品图文编辑、添加新的优惠计算规则、上架新商品等，即发生的频率比较低，而且不会造成很高的并发量。

- **建议**：对于低频流量场景，根据业务模型拆分就好。

#### 按业务模型拆分

业务模型拆分的维度有很多，在实际项目中应该综合各个不同维度做考量，其分类有：

##### 1、主链路拆分

主链路是正面战场，必须力保主链路不失守，比如电商中的，商品搜索 => 商品详情页 => 购物车模块 => 订单结算 => 支付业务等，其拆分的目的有：

- **异常容错**：可为主链路建立层次化的多级降级策略，以及合理的熔断策略。
- **调配资源**：主链路通常来讲都是高频场景，自然需要更多的计算资源，最主要的体现就是集群里分配的虚机数量多，因此，把主链路服务单独隔离出来，有利于根据需要指定不同的资源计划。
- **服务隔离**：主链路是主打输出的 C 位，把主链路与其他打辅助的业务隔离开来，可以避免边缘服务的异常情况影响到主链路。

##### 2、领域模型拆分

所谓领域模型，其实就是一套各司其职的服务集合，在做微服务规划时，需要确保各个领域之间有清晰的界限，比如商品服务和订单服务等。

##### 3、用户群体划分

1. 对每个不同的用户群体来说，即便是相同的业务领域，也有该群体独有的业务场景，比如运营、采购、客服、买家、卖家等。
2. 因此，用户群体相当于一个二级域，建立先根据主链路和领域模型一级域的拆分，再结合具体的业务分析，看是否需要在用户领域方向上做更细粒度的拆分。

##### 4、前后台业务分离

在实际项目中，通常会将前台业务和后台业务做一个隔离，符合高频业务（前台）和低频业务（后台）的隔离策略，比如手淘 APP 前台和后台商品管理系统等。

### 1.5. 什么是 SpringCloud？

#### 概念

- SpringCloud 是一系列**框架的有序集合**，利用 SpringBoot 的开发便利性，巧妙地简化了分布式系统基础设施的开发，如**服务注册与发现、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控**等，可以用 SpringBoot 的开发风格做到一键启动和部署。
- SpringCloud 并没有重复制造轮子，只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过SpringBoot 风格进行再封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署、易维护的**分布式系统开发工具包**。

|          | SpringCloud                                                  | SpringBoot                                         |
| -------- | ------------------------------------------------------------ | -------------------------------------------------- |
| 目标     | 关注全局的微服务协调整理治理框架，把 SpringBoot 开发的一个个微服务整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等集成服务 | 专注于快速方便地开发单个微服务                     |
| 依赖关系 | SpringCloud 离不开SpringBoot ，属于依赖的关系                | 可以离开SpringCloud 独立使用开发项目，没有依赖关系 |

#### 整体架构

![1638089272529](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638089272529.png)

- **Netflix**：奈非，一家大名鼎鼎的互联网传媒公司，经过自身业务漫长的微服务改造过程，沉淀出了一系列优秀的微服务组件，再经过 Pivotal（主导 Cloud Foundry）一系列封装后构成了初代的 SpringCloud。
- **Alibaba**：阿里巴巴，凭借 996 + 鸡血文化加持 + 国内互联网行业特有的糙快猛精神，在开源软件上不断开疆拓土，贡献了 SpringCloud Alibaba 组件库。
- **Spring Open Source**：Spring，独家挂牌开源，即**原配**组件。

| 应用功能       | Netfilx                           | Alibaba                  | Spring                   | 其他厂商                                                  |
| -------------- | --------------------------------- | ------------------------ | ------------------------ | --------------------------------------------------------- |
| **服务治理**   | **Eureka**                        | Nacos、Dubbo             | -                        | Google Consul                                             |
| **负载均衡**   | **Ribbon**                        | -                        | springcloud-loadbalancer | -                                                         |
| **服务调用**   | Fegin/**Open Feign**              | -                        | -                        | -                                                         |
| **服务容错**   | **Hystrix** + Turbine + Dashboard | **Sentinel** + Dashboard | -                        | -                                                         |
| **配置管理**   | Archaius                          | Alibaba Cloud ACM、Nacos | **Config**               | 携程 Apollo                                               |
| **服务网关**   | Zuul                              | -                        | **Gateway**              | -                                                         |
| **调用链追踪** | -                                 | -                        | **Sleuth**               | Elasticsearch B.V. ELK、Twitter Zipkin、Apache Skywalking |
| **消息驱动**   | -                                 | RocketMQ                 | **Stream**               | Apache Kafka、VMware RabbitMQ                             |
| **服务限流**   | -                                 | Sentinel + Dashboard     | **Gateway**              | -                                                         |
| 分布式任务调度 | -                                 | Alibaba Cloud SchedulerX | springcloud-task         | 当当网 Elastic-Job                                        |
| 分布式事务     | -                                 | Seata                    | -                        | -                                                         |

#### 优点

1. **系统耦合度低**：不会影响其他模块的开发。
2. **减轻团队的成本**：可以并行开发，不用关注其他人怎么开发，先关注自己的开发。
3. **配置比较简单**：基本用注解就能实现，不用使用过多的配置文件。
4. **微服务跨平台**：可以用任何一种语言开发。
5. **独立部署**：每个微服务可以有自己的独立的数据库也有用公共的数据库。
6. **前后端分离**：直接写后端的代码，不用关注前端怎么开发，直接写自己的后端代码即可，然后暴露接口，通过组件进行服务通信。

#### 缺点

1. **部署比较麻烦**：给运维工程师带来一定的麻烦。
2. **数据管理比较麻烦**：因为微服务可以每个微服务使用一个数据库。
3. **系统集成测试比较麻烦**：一个功能可能涉及多个微服务。
4. **性能监控比较麻烦**：最好开发一个大屏监控系统。

#### SpringCloud VS Dubbo

|              | SpringCloud                          | Dubbo                        |
| ------------ | ------------------------------------ | ---------------------------- |
| 框架定位     | 微服务解决方案，打造微服务生态       | 分布式服务治理框架           |
| 服务通信方式 | Rest API（轻量、灵活、支持 Swagger） | RPC 远程调用（高效、但耦合） |
| 注册中心     | Eureka、Nacos                        | Zookeeper                    |
| 优点         | 使用方便                             | 性能好                       |

### 1.6. 什么是服务治理？

#### 背景

1. 在传统的系统部署中，服务运行在一个固定的已知的IP和端口上，如果一个服务需要调用另一个服务，那么可以通过地址直接调用。
2. 但是，在虚拟化或者容器化的环境中，服务实例的启动和销毁是很频繁的，那么服务地址也是在动态变化的，因此，就产生了服务治理的概念。

#### 概念

![1638094365495](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638094365495.png)

服务治理就是，在微服务架构中，提供各微服务实例快速上下线、保持各服务正常通信能力的方案总称，可以实现各微服务实例的**自动化注册与服务发现**。

1. **高可用性**：在服务治理麾下的所有微服务节点，不论是被闪电击中，还是被挖掘机铲掉了电源，即使战至最后一个存活节点，服务治理框架也要保证服务的可用性。
2. **分布式调用**：
   1. 微服务节点通常散落在不同的网络环境中，要求服务治理框架具备即使在复杂网络环境下，也能准确获知服务节点的网络地址的能力。
   2. 作为服务消费者，也可以借助服务治理框架的精准制导能力，向服务节点发起请求。
3. **生命周期管理**：服务治理贯穿每个微服务的生命周期，包括从服务上线，持续运行，到服务下线。
4. **健康度检查**：服务治理框架要精准识别"不健康"的微服务节点，然后将其从服务列表中剔除。

#### 实现方案

1. **服务注册**：服务提供方自报家门。
2. **服务发现**：服务消费方拉取注册数据。
3. **心跳检测、服务续约、服务剔除**：一套由服务提供方和注册中心配合完成的去伪存真的过程。
4. **服务下线**：服务提供方发起主动下线。

#### 技术选型

|                  | Eureka   | Consul    | Nacos                        | Zookeeper               | Etcd           |
| ---------------- | -------- | --------- | ---------------------------- | ----------------------- | -------------- |
| SpringCloud 集成 | 支持     | 支持      | 支持                         | 支持                    | 支持           |
| 性能             | 快       | 较慢      | 快                           | 较慢                    | 较慢           |
| 一致性           | 弱一致   | raft      | raft                         | paxos                   | raft           |
| CAP              | AP       | CP        | AP、CP                       | CP                      | CP             |
| 网络协议         | http     | http、dns | http、dns、udp               | 客户端                  | http、grpc     |
| KV 存储服务      | 不支持   | 支持      | 支持                         | 支持                    | 支持           |
| 本质             | 服务     |           | Jar 包                       | 进程                    | Service        |
| 特点             | 节点平等 |           | AP/CP切换、注册/配置中心通用 | Leader 选举、Watch 监听 | 云原生         |
| 用途             | 注册中心 |           | 注册中心和配置中心           | 分布式协调              | 云原生注册中心 |

### 1.7. 详细介绍 Eureka？

#### 背景 

1. 在传统应用组件间调用，是通过接口规范约束来实现的，从而实现不同模块间良好协作。
2. 但是在被拆分成微服务后，每个微服务实例的网络地址和数量都可能**动态变化**，导致使用原来硬编码地址的方式极不方便，因此，需要一个中心化的组件来进行服务的登记和管理。

#### 概念

Eureak，是 SpringCloud 服务治理的一种具体解决方案，是 Netflix 开源微服务框架一系列项目中的一个，Spring Cloud 对其进行了 SpringBoot 二次封装，形成了 Spring Cloud Netflix 子项目。

- **Eureka Server**：
  1. 一个公共注册中心服务，为 Eureka Client 提供服务注册和服务发现的功能，维护已注册到自身的Eureka Client 的相关信息。
  2. 同时，提供接口给 Eureka Client 获取注册表中其他服务的信息，使得动态变化的Eureka Client 能够进行服务间的相互调用，实现服务治理。
- **Eureka Client**：
  1. **作为服务提供者**，可以将自己的服务信息，通过 Restful 的方式注册到 Eureka Server上，并在正常范围内维护自己信息一致性，方便其他服务发现自己。
  2. **作为服务消费者**：可以通过 Eureka Server 获取到自己依赖的其他服务信息，完成服务调用，并且内置了负载均衡器，用来进行基本的负载均衡。

=> 因此，Eureka 是**服务注册和服务发现**的基础组件，屏蔽了 Eureka Server 和 Eureka Client 的交互细节，使得开发者能够不再重点关注服务治理，从而把精力放在业务上。

#### 架构原理

![1638234417008](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638234417008.png)

**注册中心本质**，是存储每个服务客户端的注册信息，EurekaClient 从 EurekaServer 同步获取服务注册列表，通过一定的规则选择一个服务进行调用。

- **服务注册中心**：提供服务注册和发现的功能。每个Eureka Client向Eureka Server注册自己的信息，也可以通过Eureka Server获取到其他服务的信息达到发现和调用其他服务的目的。
- **服务提供者**：是一个 Eureka client，向 Eureka Server 注册和更新自己的信息，同时可以从 Eureka Server 注册表中获取到其他服务的信息。
  1. **服务注册**：服务提供者向 Eureka Server，注册自身的元数据以供服务发现。
  2. **服务续约**：通过发送心跳到 Eureka Server，维持和更新注册表中服务实例元数据的**有效性**，如果在一定时长内，Eureka Server 没有收到 Eureka Client的心跳信息，则默认认为它已下线，会把该服务实例信息从注册表中删除。
  3. **服务下线**：服务提供者在关闭时，主动向 Eureka Server 注销服务实例元数据，此时，该服务实例数据将会从 Eureka Server 注册表中删除。
- **服务消费者**：也是一个 Eureka client，通过从 Eureka Server 注册表中获取到其他服务的信息，找到所需要的服务，然后发起远程调用。
  1. **服务发现**：获取注册表信息，Eureka Client 向 Eureka Server 请求注册表信息，以供发起远程调用。

#### 使用方式

##### Eureka Server

###### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>

```

###### 配置文件

```properties
spring.application.name=eureka-server
server.port=20000

# 注册中心自己不需要服务注册和服务拉取(默认需要拉取)
eureka.instance.hostname=localhost
eureka.client.register-with-eureka=false
eureka.client.fetch-registry=false

# 强制关闭注册中心服务自保功能(关闭后服务自保的自动开关不起作用)
eureka.server.enable-self-preservation=false
# 注册中心每隔多久触发一次服务剔除(服务端定时任务执行服务剔除操作)
eureka.server.eviction-interval-timer-in-ms=10000

```

###### 启动类

```java
// Eureka Server测试启动类
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

```

##### Eureka Client

###### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>

```

###### 配置文件

```properties
spring.application.name=eureka-client
server.port=30000

# Eureka注册中心地址: defaultZone是serviceUrl中的一个map属性, /eureka/为默认写法(可以更改)
#eureka.client.serviceUrl.defaultZone=http://localhost:20000/eureka/

# 测试Eureka集群+互备: 只配置单注册中心
#eureka.client.serviceUrl.defaultZone=http://localhost:20011/eureka/
# 测试Eureka集群+互备: 只配置双注册中心
eureka.client.serviceUrl.defaultZone=http://peer1:20000/eureka/,http://peer2:40000/eureka/

# 高可用服务改造(服务提供者): 客户端每个X秒钟, 向注册中心发送一条续约指令(服务续约)
eureka.instance.lease-renewal-interval-in-seconds=5
# 高可用服务改造(服务提供者): 如果X秒内, 注册中心依然没有收到客户端的续约请求, 则判定客户端服务过期(客户端声明服务剔除周期判定时间)
eureka.instance.lease-expiration-duration-in-seconds=10

```

###### 启动类

```java
// Eureka Client测试启动类(服务提供者，而消费者也类似)
@SpringBootApplication
@EnableDiscoveryClient
public class EurekaClientApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaClientApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

```

##### Portal UI

![1638107108492](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638107108492.png)

![1638107129321](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638107129321.png)

![1638108556248](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638108556248.png)

| 模块                    | 属性                              | 释义                                                         |
| ----------------------- | --------------------------------- | ------------------------------------------------------------ |
| System Status           | Environment                       | 当前环境，默认值为 test，一般不用修改，为默认值就好          |
|                         | Data Center                       | 当前数据中心，默认值为 default，一般不用修改，为默认值就好   |
|                         | Current time                      | 当前系统时间，并不会主动刷新，只当浏览器刷新页面时才刷新     |
|                         | Uptime                            | 指 Eureka Server 从启动到至今所经历的时间，比如 01：30 表示已经运行了 1 小时 30 分钟 |
|                         | Lease expiration enabled          | 是否启用租约过期，跟服务续约、服务剔除、服务自保都有一定关系 |
|                         | Renews threshold                  | 每分钟最少的续约数，比如 3 表示每分钟至少收到 3 个续约请求   |
|                         | Renews（last min）                | 最近一分钟的续约数（不包括目前的一分钟）                     |
| EMERGENCY红字           | 情况一                            | 表示由于最近一分钟续约数小于每分钟最少的续约数，从而已进入自保状态 |
|                         | 情况二                            | 自我保护机关已被强制关闭                                     |
|                         | 情况三                            | 出现多数节点与 Eureka 续约出现问题                           |
| DS Replicas             | Application                       | 服务的应用名称，没指定时默认为 UNKOWN                        |
|                         | AMIs                              | 心跳检测机制                                                 |
|                         | Availability Zones                | （1）表示可用分区数                                          |
|                         | Status                            | 服务实例可用状态，（1）表示可用实例数                        |
| General Info            | total-avail-memory                | 当前 Eureka 实例可用内存                                     |
|                         | environment                       | 当前环境，默认值为 test，一般不用修改，为默认值就好          |
|                         | num-of-cpus                       | 当前 CPU 核数                                                |
|                         | current-memory-usage              | 当前已使用内存，44% 表示当前机器已使用 44% 的内存            |
|                         | server-uptime                     | 指 Eureka Server 从启动到至今所经历的时间，比如 01：30 表示已经运行了 1 小时 30 分钟 |
|                         | registered-replicas               | 其他已注册的 Eureka 集群副本                                 |
|                         | unavailable-replicas              | 其他不可用的 Eureka 集群副本                                 |
|                         | available-replicas                | 其他可用的 Eureka 集群副本                                   |
| Instance Info           | ipAddr                            | 当前机器的 IP 地址                                           |
|                         | status                            | 当前服务的状态，UP 表示已上线                                |
| LAST 1000 SINCE STARTUP | Last 1000 cancelled leases        | 过去最近 1000 个被取消的实例租约                             |
|                         | Last 1000 newly registered leases | 过去最近 1000 个新注册的实例租约                             |

##### 常用 Rest 接口

| 用途                     | URL                                                          |
| ------------------------ | ------------------------------------------------------------ |
| 查看所有服务的注册列表   | GET http://localhost:1001/eureka/apps                        |
| 查看某一个服务的注册列表 | GET http://localhost:1001/eureka/apps/SERVICE-NAME           |
| 服务下线                 | PUT http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME/status?value=OUT_OF_SERVICE |
| 服务下线后恢复           | PUT http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME/status?value=UP |
| 服务剔除                 | DELETE http://localhost:1001/eureka/apps/SERVICE-NAME/INSTANCE-NAME |

#### 注册中心启动原理 | Eureka Server

##### 1、导入配置类

```java
// 1、@EnableEurekaServer
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Import(EurekaServerMarkerConfiguration.class)
public @interface EnableEurekaServer {

}

@Configuration
public class EurekaServerMarkerConfiguration {

    // 2、构造Marker实例，以标识注册中心允许启动
	@Bean
	public Marker eurekaServerMarkerBean() {
		return new Marker();
	}

	class Marker {

	}
}

```

##### 2、Spring SPI 配置

```properties
# ..\spring-cloud-netflix-eureka-server-2.1.1.RELEASE.jar\META-INF\spring.factories
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
  org.springframework.cloud.netflix.eureka.server.EurekaServerAutoConfiguration

```

##### 3、初始化 Bean 配置类

```java
// 1、标识当前类为配置类
@Configuration
// 2、注入Eureka Server启动核心类
@Import(EurekaServerInitializerConfiguration.class)
// 3、标识为true，才进行初始化
@ConditionalOnBean(EurekaServerMarkerConfiguration.Marker.class)
// 4、使没有@Component的配置类生效
@EnableConfigurationProperties({ EurekaDashboardProperties.class,
		InstanceRegistryProperties.class })
// 5、注入properties配置，属性需从Environment中获取
@PropertySource("classpath:/eureka/server.properties")
public class EurekaServerAutoConfiguration extends WebMvcConfigurerAdapter {

    ....
	// 6、注入Eureka服务端相关配置
	@Autowired
	private EurekaServerConfig eurekaServerConfig;
	// 7、注入Eureka客户端相关配置
	@Autowired
	private EurekaClientConfig eurekaClientConfig;
    
	// 8、初始化集群注册表——PeerAwareInstanceRegistry
	@Bean
	public PeerAwareInstanceRegistry peerAwareInstanceRegistry(ServerCodecs serverCodecs) {
		...
	}
    
	// 9、初始化集群节点集合——PeerEurekaNodes
	@Bean
	@ConditionalOnMissingBean
	public PeerEurekaNodes peerEurekaNodes(PeerAwareInstanceRegistry registry, ServerCodecs serverCodecs,
			ReplicationClientAdditionalFilters replicationClientAdditionalFilters) {
		...
	}
    
	// 10、Eureka服务端上下文——EurekaServerContext
	@Bean
	@ConditionalOnMissingBean
	public EurekaServerContext eurekaServerContext(ServerCodecs serverCodecs, PeerAwareInstanceRegistry registry, PeerEurekaNodes peerEurekaNodes) {
		...
	}
    
	// 11、 Eureka服务端启动类——EurekaServerBootstrap
	@Bean
	public EurekaServerBootstrap eurekaServerBootstrap(PeerAwareInstanceRegistry registry,EurekaServerContext serverContext) {
		...
	}
    
	// 12. jersey过滤器——FilterRegistrationBean
	@Bean
    public FilterRegistrationBean<?> jerseyFilterRegistration(javax.ws.rs.core.Application eurekaJerseyApp) {
        ...
    }
}


```

##### 4、LifecycleProcessor#onRefresh 回调

```java
package org.springframework.context.support;

public abstract class AbstractApplicationContext extends DefaultResourceLoader
implements ConfigurableApplicationContext {
	// 1、SpringBoot/Spring启动时调用
	@Override
    public void refresh() throws BeansException, IllegalStateException {
    	...
    	// 2、最后一步，完成最后的上下文刷新
    	finishRefresh();
    	...
    }
    
    protected void finishRefresh() {
   		...
    	// 3、上下文刷新的通知，比如用于自动启动组件
    	getLifecycleProcessor().onRefresh();
    	..
    }
}

public class DefaultLifecycleProcessor implements LifecycleProcessor, BeanFactoryAware {
	// 4、使用默认的生命周期后置处理器
	@Override
	public void onRefresh() {
		startBeans(true);
		this.running = true;
	}
	
    private void startBeans(boolean autoStartupOnly) {
    	...
    	// 5、启动每一个生命周期方法
    	phases.get(key).start();
    	...
    }
    
    // 维护一组应该启动的Lifecycle bean的Helper类
    private class LifecycleGroup {
        public void start() {
        	...
        	// 6、启动每一个生命周期方法
			doStart(this.lifecycleBeans, member.name, this.autoStartupOnly);
			...
        }
    }
    
    private void doStart(Map<String, ? extends Lifecycle> lifecycleBeans, String beanName, boolean autoStartupOnly) {
   		...
   		// 7、启动生命周期方法
    	bean.start();
    	...
    }
}

// 8、由于实现了SmartLifecycle接口，因此SpringBoot启动时会回调start方法
public class EurekaServerInitializerConfiguration
    implements ServletContextAware, SmartLifecycle, Ordered {
    
	@Override
    public void start() {
         // 9、异步启动任务
		new Thread(new Runnable() {
			@Override
			public void run() {
                // 10、初始化Eureka Server上下文
                eurekaServerBootstrap.contextInitialized(
                    EurekaServerInitializerConfiguration.this.servletContext);
                log.info("Started Eureka Server");
                ...// 发布完成事件等等
			}
		}).start();
    }
}


```

##### 5、初始化 Eureka Server 上下文

```java
public class EurekaServerBootstrap {
	public void contextInitialized(ServletContext context) {
        ...
		// 1、初始化Eureka环境
        initEurekaEnvironment();
        // 2、初始化Eureka上下文
        initEurekaServerContext();
        ...
	}
    
    protected void initEurekaServerContext() throws Exception {
        ...
		log.info("Initialized server context");

		// 3、向其他Eureka Server同步租约实例，如果已经注册了的，则在当前Eureka Server注册一次
		int registryCount = this.registry.syncUp();
        // 4、初始化启动变量，以及启动服务剔除定时任务
		this.registry.openForTraffic(this.applicationInfoManager, registryCount);
		// 5、注册所有监视统计信息
		EurekaMonitors.registerAllStats();
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
		// 4.1. 初始化启动变量，以及启动服务剔除定时任务
		super.openForTraffic(applicationInfoManager,
				count == 0 ? this.defaultOpenForTrafficCount : count);
	}
}

public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
    	// 4.2. 设置期望的客户端数量，这里为1
    	this.expectedNumberOfClientsSendingRenews = count;
    	// 4.3. 设置最小续租阈值数量 = (int) 1 * (60/30) * 0.85 = 1，用于开启自保开关
    	updateRenewsPerMinThreshold();
    	// 4.4. 设置系统启动时间
    	this.startupTime = System.currentTimeMillis();
    	...
    	// 4.5. 设置UP实例状态
    	applicationInfoManager.setInstanceStatus(InstanceStatus.UP);
    	// 4.6. 设置完毕，上下文后置初始化处理
    	super.postInit();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void postInit() {
   		// 4.7. 设置服务剔除任务
        evictionTaskRef.set(new EvictionTask());
        // 4.8. 默认延迟60s后开始执行任务，且每60s执行一次
        evictionTimer.schedule(evictionTaskRef.get(),
                serverConfig.getEvictionIntervalTimerInMs(),
                serverConfig.getEvictionIntervalTimerInMs());
    }
}


```

#### 客户端启动原理 | Eureka Client

##### 1、导入配置类

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
// 2. 导入配置类EnableDiscoveryClientImportSelector
@Import(EnableDiscoveryClientImportSelector.class)
public @interface EnableDiscoveryClient {
    // 1. 默认为true，所以不设置@EnableDiscoveryClient，服务也能完成注册和发现
    boolean autoRegister() default true;
}

// 3. ImportSelector接口的返回值会递归进行解析，把解析到的类全名按照@Configuration进行处理
@Order(Ordered.LOWEST_PRECEDENCE - 100)
public class EnableDiscoveryClientImportSelector
    extends SpringFactoryImportSelector<EnableDiscoveryClient> {
	@Override
    public String[] selectImports(AnnotationMetadata metadata) {
        ...
		if (autoRegister) {
			List<String> importsList = new ArrayList<>(Arrays.asList(imports));
            // 4. 指定导入AutoServiceRegistrationConfiguration
			importsList.add(
					"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationConfiguration");
			imports = importsList.toArray(new String[0]);
		}
        ...
    }
}

@Configuration
// 5. 读取spring.cloud.service-registry.auto-registration文件，并允许注入属性
@EnableConfigurationProperties(AutoServiceRegistrationProperties.class)
// 6. 默认设置spring.cloud.service-registry.auto-registration.enabled开关为true
@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
public class AutoServiceRegistrationConfiguration {

}


```

##### 2、Spring SPI 配置

```properties
# .../spring-cloud-netflix-eureka-client/2.1.1.RELEASE/spring-cloud-netflix-eureka-client-2.1.1.RELEASE.jar!/META-INF/spring.factories
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
# Eureka client自动配置类，负责client中关键beans的配置和初始化
org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\
# Ribbon负载均衡自动配置类
org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\
# 服务注册和健康检查器自动配置类
org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration


```

##### 3、服务注册 & 健康检查自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnClass(EurekaClientConfig.class)
// 1、默认设置eureka.client.enabl=true
@ConditionalOnProperty(value = "eureka.client.enabled", matchIfMissing = true)
@ConditionalOnDiscoveryEnabled
public class EurekaDiscoveryClientConfiguration {
    
    class Marker {

	}
    
    // 2、注入服务启动标识
	@Bean
	public Marker eurekaDiscoverClientMarker() {
		return new Marker();
	}
    
    // 3、默认关闭健康检查
    @Configuration
	@ConditionalOnProperty(value = "eureka.client.healthcheck.enabled", matchIfMissing = false)
    protected static class EurekaHealthCheckHandlerConfiguration {
        ...
    }
    
    // 4、注册Spring上下文刷新完毕监听器
    @Configuration
	@ConditionalOnClass(RefreshScopeRefreshedEvent.class)
	protected static class EurekaClientConfigurationRefresher
        implements ApplicationListener<RefreshScopeRefreshedEvent> {
        
		@Autowired(required = false)
		private EurekaClient eurekaClient;

		@Autowired(required = false)
		private EurekaAutoServiceRegistration autoRegistration;

		public void onApplicationEvent(RefreshScopeRefreshedEvent event) {
			...
            // 5、确保在Spring上下文刷新事件后不为空，否则将重新注册
			if (autoRegistration != null) {
				this.autoRegistration.stop();
				this.autoRegistration.start();
			}
		}
    }
}


```

##### 3、Eureka Client 自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnClass(EurekaClientConfig.class)
@Import(DiscoveryClientOptionalArgsConfiguration.class)
// 1、需要有服务启动标识，默认有
@ConditionalOnBean(EurekaDiscoveryClientConfiguration.Marker.class)
// 2、默认设置eureka.client.enabl=true
@ConditionalOnProperty(value = "eureka.client.enabled", matchIfMissing = true)
// 3、默认设置spring.cloud.discovery.enabled=true
@ConditionalOnDiscoveryEnabled
// 4、该类注入在下面这些类注入之前
@AutoConfigureBefore({ NoopDiscoveryClientAutoConfiguration.class,
		CommonsClientAutoConfiguration.class, ServiceRegistryAutoConfiguration.class })
// 5、该类注入在下面这些类注入之后
@AutoConfigureAfter(name = {
		"org.springframework.cloud.autoconfigure.RefreshAutoConfiguration",
"org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration",	"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationAutoConfiguration" })
public class EurekaClientAutoConfiguration {
    
    // 6、注入EurekaClient配置类
	@Bean
	@ConditionalOnMissingBean(value = EurekaClientConfig.class, search = SearchStrategy.CURRENT)
    public EurekaClientConfigBean eurekaClientConfigBean(ConfigurableEnvironment env) {
        ...
    }
    
    // 7、注入EurekaClient配置管理类
	@Bean
	@ConditionalOnMissingBean
	public ManagementMetadataProvider serviceManagementMetadataProvider() {
		return new DefaultManagementMetadataProvider();
	}
    
    // 8、读取eureka.instance.hostname、eureka.instance.prefer-ip-address、eureka.instance.ip-address、server.servlet.context-path、server.port等配置，注入EurekaInstanceConfigBean instance实例
    @Bean
	@ConditionalOnMissingBean(value = EurekaInstanceConfig.class, search = SearchStrategy.CURRENT)
	public EurekaInstanceConfigBean eurekaInstanceConfigBean(InetUtils inetUtils,
                                                             ManagementMetadataProvider managementMetadataProvider) {
        ...
    }
    
    // 9、注入DiscoveryClient，用于包装EurekaClient
    @Bean
	public DiscoveryClient discoveryClient(EurekaClient client,
			EurekaClientConfig clientConfig) {
		return new EurekaDiscoveryClient(client, clientConfig);
	}
    
    // 10、注入EurekaServiceRegistry
    @Bean
	public EurekaServiceRegistry eurekaServiceRegistry() {
		return new EurekaServiceRegistry();
	}
    
    // 11、注入EurekaAutoServiceRegistration，对应上面所说的《确保在Spring上下文刷新事件后不为空，否则将重新注册》
    @Bean
	@ConditionalOnBean(AutoServiceRegistrationProperties.class)
	@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
	public EurekaAutoServiceRegistration eurekaAutoServiceRegistration(
			ApplicationContext context, EurekaServiceRegistry registry,
			EurekaRegistration registration) {
		return new EurekaAutoServiceRegistration(context, registry, registration);
	}
    
    // #重点#
    @Configuration
	@ConditionalOnMissingRefreshScope
    protected static class EurekaClientConfiguration {
        ...
        // 12、注入EurekaClient核心类，且在销毁时调用EurekaClient#shutdown，进行服务下线
		@Bean(destroyMethod = "shutdown")
		@ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT)
		public EurekaClient eurekaClient(ApplicationInfoManager manager,
				EurekaClientConfig config) {
			return new CloudEurekaClient(manager, config, this.optionalArgs,
					this.context);
		}
        
        // 13、注入app管理器
		@Bean
		@ConditionalOnMissingBean(value = ApplicationInfoManager.class, search = SearchStrategy.CURRENT)
		public ApplicationInfoManager eurekaApplicationInfoManager(
				EurekaInstanceConfig config) {
			InstanceInfo instanceInfo = new InstanceInfoFactory().create(config);
			return new ApplicationInfoManager(config, instanceInfo);
		}
        
        // 14、注入服务注册实例
		@Bean
		@ConditionalOnBean(AutoServiceRegistrationProperties.class)
		@ConditionalOnProperty(value = "spring.cloud.service-registry.auto-registration.enabled", matchIfMissing = true)
		public EurekaRegistration eurekaRegistration(EurekaClient eurekaClient,
				CloudEurekaInstanceConfig instanceConfig,
				ApplicationInfoManager applicationInfoManager,
				@Autowired(required = false) ObjectProvider<HealthCheckHandler> healthCheckHandler) {
			return EurekaRegistration.builder(instanceConfig).with(applicationInfoManager)
					.with(eurekaClient).with(healthCheckHandler).build();
		}
    }
    ...// 15、注入一些支持配置刷新的EurekaClient相关类、以及健康检查指标类等等
}


```

##### 4、注入 EurekaClient 核心类

```java
// 0. 在EurekaClientAutoConfiguration进行了自动注入，这里介绍如何创建EurekaClient核心类
public class CloudEurekaClient extends DiscoveryClient {
	public CloudEurekaClient(ApplicationInfoManager applicationInfoManager,
			EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs<?> args,
			ApplicationEventPublisher publisher) {
        // 1、调用父类DiscoveryClient构造器
		super(applicationInfoManager, config, args);
		...
	}
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    public DiscoveryClient(ApplicationInfoManager applicationInfoManager, final EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args) {
        // 2、调用其他构造器
        this(applicationInfoManager, config, args, new Provider<BackupRegistry>() {
            private volatile BackupRegistry backupRegistryInstance;

            @Override
            public synchronized BackupRegistry get() {
                ...
            }
        });
    }
    
    // 3、注入构造器参数实例ApplicationInfoManager、EurekaClientConfig config和AbstractDiscoveryClientOptionalArgs
    @Inject
    DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,
                    Provider<BackupRegistry> backupRegistryProvider) {
		...// 4、初始化一些配置参数
        try {
            // 5、构建2c、无边界线程、无边界容量的后台延迟线程池DiscoveryClient-n，用于定时执行
            scheduler = Executors.newScheduledThreadPool(2,
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-%d")
                            .setDaemon(true)
                            .build());
            // 6、构建1c、2max、0空闲、0容量的后台线程池DiscoveryClient-HeartbeatExecutor-n，用于执行心跳检测
            heartbeatExecutor = new ThreadPoolExecutor(
                    1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,
                    new SynchronousQueue<Runnable>(),
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-HeartbeatExecutor-%d")
                            .setDaemon(true)
                            .build()
            );
            
			// 7、构建1c、2max、0空闲、0容量的后台线程池DiscoveryClient-CacheRefreshExecutor-n，用于执行缓存刷新
            cacheRefreshExecutor = new ThreadPoolExecutor(
                    1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,
                    new SynchronousQueue<Runnable>(),
                    new ThreadFactoryBuilder()
                            .setNameFormat("DiscoveryClient-CacheRefreshExecutor-%d")
                            .setDaemon(true)
                            .build()
            );

            ...
        } catch (Throwable e) {
            throw new RuntimeException("Failed to initialize DiscoveryClient!", e);
        }
        
        // 8、根据fetch-registry配置参数，增量拉取拉取注册表信息
        if (clientConfig.shouldFetchRegistry() && !fetchRegistry(false)) {
            // 8.1. 由于拉取没发生异常，所以不会返回false，这里也就不会进来了
            fetchRegistryFromBackup();
        }
        
        ...// 先初始化一些注册前的信息
        
        // 9、根据register-with-eureka配置参数向服务端注册，这里由于客户端初始化无需强制执行初始注册，所以也不会进行先注册
        if (clientConfig.shouldRegisterWithEureka() && clientConfig.shouldEnforceRegistrationAtInit()) {
            try {
                if (!register() ) {
                    throw new IllegalStateException("Registration error at startup. Invalid server response.");
                }
            } catch (Throwable th) {
                logger.error("Registration error at startup: {}", th.getMessage());
                throw new IllegalStateException(th);
            }
        }
        
        // 10、最后，初始化调度任务（例如集群解析器、心跳、instanceInfo 复制器、获取注册表）
        initScheduledTasks();
        
        ...// 注册到监控中心、注册DiscoveryClient实例 & 配置实例到管理器中、设置initTimestampMs、打印日志等操作
    }
    
    // 初始化调度任务（例如集群解析器、心跳、instanceInfo 复制器、获取注册表）
    private void initScheduledTasks() {
        // 10.1、默认需要拉取注册表信息
        if (clientConfig.shouldFetchRegistry()) {
            ...
            // 10.2、启动超时时间30s，最大超时300s，延迟30s执行，交由cacheRefreshExecutor线程池处理的，以指定的时间间，隔获取注册表信息任务（服务发现）
            scheduler.schedule(
                    new TimedSupervisorTask(
                            "cacheRefresh",
                            scheduler,
                            cacheRefreshExecutor,
                            registryFetchIntervalSeconds,// 30s，超时时间
                            TimeUnit.SECONDS,
                            expBackOffBound,// 10s，30*10，用于计算最大超时时间
                            // 以指定的时间间，隔获取注册表信息任务
                            new CacheRefreshThread()
                    ),
                    // 30s，延迟执行时间
                    registryFetchIntervalSeconds, TimeUnit.SECONDS);
        }
        
        // 10.3、默认需要注册服务到Eureka
        if (clientConfig.shouldRegisterWithEureka()) {
            ...

            // 10.4、非默认参数，启动续租超时时间5s，最大超时50s，延迟5s执行，交由heartbeatExecutor线程池处理的，在给定的时间间隔内，更新租约的心跳任务（心跳检测）
            scheduler.schedule(
                    new TimedSupervisorTask(
                            "heartbeat",
                            scheduler,
                            heartbeatExecutor,
                            renewalIntervalInSecs,// 5s，续租超时时间
                            TimeUnit.SECONDS,
                            expBackOffBound,// 10s，5*10，用于计算最大超时时间
                        	// 在给定的时间间隔内，更新租约的心跳任务
                            new HeartbeatThread()
                    ),
               		 // 5s，延迟执行时间
                    renewalIntervalInSecs, TimeUnit.SECONDS);

            // 10.5、构建更新和复制本地实例信息到远程服务器的任务，副本同步周期30s
            instanceInfoReplicator = new InstanceInfoReplicator(
                    this,
                    instanceInfo,
                    clientConfig.getInstanceInfoReplicationIntervalSeconds(),// 30s
                    2);

            // 10.6、构造服务实例监听器
            statusChangeListener = new ApplicationInfoManager.StatusChangeListener() {
                ...// getId()
                    
                @Override
                public void notify(StatusChangeEvent statusChangeEvent) {
                    ...// 打印日志
                    // 10.7、在应用状态发生变化时，刷新服务实例信息，在服务实例信息发生改变时，向server注册 => 底层调用instanceInfoReplicator#run方法
                    instanceInfoReplicator.onDemandUpdate();
                }
            };
            
            // 10.8、默认设置监听器
            if (clientConfig.shouldOnDemandUpdateStatusChange()) {
       applicationInfoManager.registerStatusChangeListener(statusChangeListener);
            }

            // 10.9、启动服务实例更新任务，默认第一次延迟40s运行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp，表示第一次需要注册
            instanceInfoReplicator.start(
               clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()// 40s
            );
        } else {
            logger.info("Not registering with Eureka server per configuration");
        }
    }
    
    // 10.10、启动服务实例更新任务，默认第一次延迟40s执行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp脏时间戳（后面用于服务续约），表示第一次需要注册
    public void start(int initialDelayMs) {
        if (started.compareAndSet(false, true)) {
            instanceInfo.setIsDirty();
            Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS);
            scheduledPeriodicRef.set(next);
        }
    }
}


```

#### 服务注册原理

##### 发起请求 | Eureka Client

###### 1、第一次调用 InstanceInfoReplicator#run

| 配置                                  | 默认 | 说明                               |
| ------------------------------------- | ---- | ---------------------------------- |
| eureka.registration.enabled           | true | Eureka Client 是否开启服务注册     |
| eureka.appinfo.replicate.interval     | 30s  | 服务实例副本同步周期               |
| eureka.appinfo.initial.replicate.time | 40s  | 服务实例服务副本同步的初始延迟时间 |

```java
// 1、在构造EurekaClient时，调用了instanceInfoReplicator#start，来启动服务实例更新任务，默认第一次延迟40s运行，并设置isInstanceInfoDirty=true和lastDirtyTimestamp（后面用于服务续约），表示第一次需要注册
class InstanceInfoReplicator implements Runnable {
    public void run() {
        try {
            // 2、刷新当前本地instanceInfo，在观察到更改的有效刷新后，instanceInfo#isDirty会被设置为true，并且更新lastDirtyTimestamp脏时间戳（用于后面的服务续约）
            discoveryClient.refreshInstanceInfo();

            // 3、获取lastDirtyTimestamp，如果存在，则需要当前服务重新发起注册
            Long dirtyTimestamp = instanceInfo.isDirtyWithTime();
            if (dirtyTimestamp != null) {
                // 4、重新发起注册，第一次调用InstanceInfoReplicator#run则必定发起注册
                discoveryClient.register();
                // 5、重新注册成功，则清空isDirty，设置isInstanceInfoDirty=false
                instanceInfo.unsetIsDirty(dirtyTimestamp);
            }
        } catch (Throwable t) {
            logger.warn("There was a problem with the instance info replicator", t);
        } finally {
            // 6、最后再延迟30s后重新执行该任务
            Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS);
            scheduledPeriodicRef.set(next);
        }
    }
}


```

###### 2、调用 DiscoveryClient#register

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 4.1、通过进行适当的 REST 调用来注册 eureka 服务
    boolean register() throws Throwable {
        logger.info(PREFIX + "{}: registering service...", appPathIdentifier);
        EurekaHttpResponse<Void> httpResponse;
        try {
            // 4.2、调用EurekaHttpClient#register进行服务注册
            httpResponse = eurekaTransport.registrationClient.register(instanceInfo);
        } catch (Exception e) {
            logger.warn(..., e);
            throw e;
        }
        if (logger.isInfoEnabled()) {
            logger.info(...);
        }
        // 4.24、响应成功，状态码等于NO_CONTENT(204, "No Content"),代表服务注册成功
        return httpResponse.getStatusCode() == Status.NO_CONTENT.getStatusCode();
    }
}

public abstract class EurekaHttpClientDecorator implements EurekaHttpClient {
    
    // 4.4、多态调用SessionedEurekaHttpClient#execute
    // 4.8、多态调用RetryableEurekaHttpClient#execute
    // 4.13、多态调用RedirectingEurekaHttpClient#execute
    // 4.17、多态调用MetricsCollectingEurekaHttpClient#execute
    protected abstract <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor);
     
    @Override
    public EurekaHttpResponse<Void> register(final InstanceInfo info) {
        // 4.3、调用模板execute方法
        // 4.7、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        // 4.12、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        // 4.16、多态调用前又会先调用抽象父类的register方法，然后又会去调用模板execute方法
        return execute(new RequestExecutor<Void>() {
            @Override
            public EurekaHttpResponse<Void> execute(EurekaHttpClient delegate) {
                // 4.6、多态调用RetryableEurekaHttpClient#execute
                // 4.11、多态调用RedirectingEurekaHttpClient#execute
                // 4.15、多态调用MetricsCollectingEurekaHttpClient#execute
                return delegate.register(info);
            }

            @Override
            public RequestType getRequestType() {
                return RequestType.Register;
            }
        });
    }
}


```

###### 3、多态调用 SessionedEurekaHttpClient#execute

```java
public class SessionedEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        long now = System.currentTimeMillis();
        long delay = now - lastReconnectTimeStamp;
        
        // 4.4、更新session时间currentSessionDurationMs
        if (delay >= currentSessionDurationMs) {
            logger.debug("Ending a session and starting anew");
            lastReconnectTimeStamp = now;
            currentSessionDurationMs = randomizeSessionDuration(sessionDurationMs);
            TransportUtils.shutdown(eurekaHttpClientRef.getAndSet(null));
        }

        ...
        
        // 4.5、调用装饰者requestExecutor#execute
        // 4.23、响应成功，则直接返回结果
        return requestExecutor.execute(eurekaHttpClient);
    }
}


```

###### 4、多态调用 RetryableEurekaHttpClient#execute

```java
public class RetryableEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.9、默认最大重试3次
        for (int retry = 0; retry < numberOfRetries; retry++) {
            ...
            try {
                // 4.10、调用装饰者requestExecutor#execute
                EurekaHttpResponse<R> response = requestExecutor.execute(currentHttpClient);
                // 4.22、响应成功，设置当前客户端为调用成功的客户端，然后返回响应结果
                if (serverStatusEvaluator.accept(response.getStatusCode(), requestExecutor.getRequestType())) {
                    delegate.set(currentHttpClient);
                    if (retry > 0) {
                        logger.info("Request execution succeeded on retry #{}", retry);
                    }
                    return response;
                }
                logger.warn(...);
            } catch (Exception e) {
                logger.warn(...);
            }

            // 如果超过了最大重试次数，仍没调用成功，则会来到这里，则设置调用成功的客户端为null，代表没有调用成功过
            delegate.compareAndSet(currentHttpClient, null);
            // 然后把当前currentEndpoint加入失败列表
            if (currentEndpoint != null) {
                quarantineSet.add(currentEndpoint);
            }
        }
        throw new TransportException("Retry limit reached; giving up on completing the request");
    }
}


```

5、多态调用 RedirectingEurekaHttpClient#execute

```java
public class RedirectingEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.14、底层调用装饰者requestExecutor#execute
     	EurekaHttpResponse<R> response = executeOnNewServer(requestExecutor, currentEurekaClientRef);
        ...
        // 4.21、响应成功，无需重定向
        return response;
        ...
    }
}


```

###### 6、多态调用 MetricsCollectingEurekaHttpClient#execute

```java
public class MetricsCollectingEurekaHttpClient extends EurekaHttpClientDecorator {
    @Override
    protected <R> EurekaHttpResponse<R> execute(RequestExecutor<R> requestExecutor) {
        ...
        // 4.18、最后调用AbstractJerseyEurekaHttpClient#register方法
        EurekaHttpResponse<R> httpResponse = requestExecutor.execute(delegate);
        // 4.20、响应成功，记录调用结果
        requestMetrics.countersByStatus.get(mappedStatus(httpResponse)).increment();
        return httpResponse;
    }
}


```

###### 7、最后调用 AbstractJerseyEurekaHttpClient#register

```java
public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    @Override
    public EurekaHttpResponse<Void> register(InstanceInfo info) {
        // urlPath => apps/EUREKA-CLIENT
        String urlPath = "apps/" + info.getAppName();
        ClientResponse response = null;
        try {
            Builder resourceBuilder = jerseyClient.resource(serviceUrl).path(urlPath).getRequestBuilder();
            addExtraHeaders(resourceBuilder);
            
            // 4.19、正式发起post请求进行服务注册 => 这里返回NO_CONTENT(204, "No Content"),代表服务注册成功（此时在Eureka Portal中已经能看到该服务实例了）
            response = resourceBuilder
                    .header("Accept-Encoding", "gzip")
                    .type(MediaType.APPLICATION_JSON_TYPE)
                    .accept(MediaType.APPLICATION_JSON)
                    .post(ClientResponse.class, info);
            return anEurekaHttpResponse(response.getStatus()).headers(headersOf(response)).build();
        } finally {
            if (logger.isDebugEnabled()) {
                logger.debug(...);
            }
            if (response != null) {
                response.close();
            }
        }
    }
}


```

##### 响应请求 | Eureka Server

###### 1、请求分发到 addInstance 接口

```java
// jersey server resource，相当于MVC中的Controller
@Produces({"application/xml", "application/json"})
public class ApplicationResource {
    // 1、服务注册接口，相当于MVC中的RequestMapping
    @POST
    @Consumes({"application/json", "application/xml"})
    public Response addInstance(InstanceInfo info,
                                @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        ...// 一大堆校验
        // 2、调用注册方法，然后返回204给Eureka Client
        registry.register(info, "true".equals(isReplication));
        return Response.status(204).build();
    }
}


```

###### 2、调用 register，开始注册

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void register(final InstanceInfo info, final boolean isReplication) {
		...// 获取租约过期时间（默认为90s），打印日志等
		// 3、注册有关InstanceInfo信息，并复制将此信息发送给所有对等的Eureka节点，但如果这是来自其他副本节点的，那么不会再复制 => 这里是服务注册，所以isReplication为false
		super.register(info, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void register(final InstanceInfo info, final boolean isReplication) {
    	...// 获取租约过期时间（默认为90s）
        // 4、注册具有给定持续时间的新实例
        super.register(info, leaseDuration, isReplication);
        replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);
    }
}


```

###### 3、执行注册 & 写入服务实例

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
	// 服务实例ID instance-id="host：appnNme:port"
	// Eureka Server服务列表双重Map缓存=>{"appName"：{instance-id:InstanceInfo}}
    private final ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry = new ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>>();
            
	// 注册具有给定持续时间的新实例
    public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {
        try {
        	// 5、获取读锁
            read.lock();
            
            // 6、如果为第一次注册，则创建appName：空Map（服务实例的状态变化时，Server可能会收到多次，来自同一个实例的注册请求）
            Map<String, Lease<InstanceInfo>> gMap = registry.get(registrant.getAppName());
            REGISTER.increment(isReplication);
            if (gMap == null) {
                final ConcurrentHashMap<String, Lease<InstanceInfo>> gNewMap = new ConcurrentHashMap<String, Lease<InstanceInfo>>();
                gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap);
                if (gMap == null) {
                    gMap = gNewMap;
                }
            }
            
            // 如果已经有租约，则保留最后一个脏时间戳而不覆盖它
            Lease<InstanceInfo> existingLease = gMap.get(registrant.getId());
            if (existingLease != null && (existingLease.getHolder() != null)) {
            	// 7、如果双重Map缓存中的lastDirtyTimestamp比新传过来的lastDirtyTimestamp还要大/新，说明注册请求的时间落后，则继续使用缓存而不发生替换
                ...
            } else {
                // 8、租约不存在，因此是新注册
                synchronized (lock) {
                    if (this.expectedNumberOfClientsSendingRenews > 0) {
                        // 9、由于客户端要注册，增加客户端发送更新的数量
                        this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1;
                        // 10、更新每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
                        updateRenewsPerMinThreshold();
                    }
                }
                logger.debug(...);
            }
            
            // 9、如果租约不存在，或者租约是最新的租约，则设置或者更新到双重Map缓存中
            Lease<InstanceInfo> lease = new Lease<InstanceInfo>(registrant, leaseDuration);
            if (existingLease != null) {
                lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp());
            }
            gMap.put(registrant.getId(), lease);
            
            // 10、加入最新注册队列中
            synchronized (recentRegisteredQueue) {
                recentRegisteredQueue.add(new Pair<Long, String>(
                        System.currentTimeMillis(),
                        registrant.getAppName() + "(" + registrant.getId() + ")"));
            }
           
			...// 更新租约等状态
			// 11、更新租约最后更新时间
            registrant.setLastUpdatedTimestamp();
            // 12、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已重新加入服务列表，所以只读缓存也重新加入它，不过有一定的延迟（默认30s同步一次）
            invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress());
            logger.info(...);
        } finally {
        	// 13、释放读锁
            read.unlock();
        }
    }
}


```

#### 服务发现原理

##### 概念

服务发现分为两种实现方式，分别是客户端和服务端的服务发现，而 Eureka 正是客户端实现的服务发现。

###### 客户端服务发现

![1639056166351](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639056166351.png)

- **优点**：客户端知道所有可用服务的实际网络地址，可以非常方便的实现负载均衡功能。
- **缺点**：语言耦合性很强，针对不同的语言，每个服务的客户端都得实现一套服务发现的功能。

###### 服务端服务发现

![1639056226782](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639056226782.png)

- **优点**：服务发现逻辑对客户端是透明的，客户端只管向 LOAD BALANCER 负载均衡器发送请求即可。
- **缺点**：需要关心 LOAD BALANCER 负载均衡器组件的高可用。

##### 发起请求 | Eureka Client

###### 1、调用服务列表拉取1 | 构建 DiscoveryClient 时

```java
@Singleton
public class CloudEurekaClient extends DiscoveryClient {
    @Inject
    DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,
                    Provider<BackupRegistry> backupRegistryProvider) {
        ...
        // 1、根据fetch-registry配置参数，增量拉取拉取注册表信息
        if (clientConfig.shouldFetchRegistry() && !fetchRegistry(false)) {
            // 2、 由于拉取没发生异常，所以不会返回false，这里也就不会进来了
            fetchRegistryFromBackup();
        }
        ...
    }
}


```

###### 2、调用服务列表拉取2 | 默认30s 定时拉取

| 配置                                               | 默认 | 说明                                |
| -------------------------------------------------- | ---- | ----------------------------------- |
| eureka.shouldFetchRegistry                         | true | Eureka Client 是否需要拉取服务列表  |
| eureka.client.refresh.interval                     | 30s  | 服务列表拉取周期                    |
| eureka.client.cacheRefresh.exponentialBackOffBound | 10倍 | 10 * 30，表示最大的服务拉取周期乘数 |

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、启动超时时间30s，最大超时300s，延迟30s执行，交由cacheRefreshExecutor线程池处理的，以指定的时间间，隔获取注册表信息任务（服务发现）
    class CacheRefreshThread implements Runnable {
        public void run() {
            refreshRegistry();
        }
    }
    @VisibleForTesting
    void refreshRegistry() {
        ...
        // 2、如果currentRemoteRegions不等于latestRemoteRegions，说明region发生了变化，则remoteRegionsModified=true，代表进行全量拉取；否则，默认按增量拉取
    	boolean success = fetchRegistry(remoteRegionsModified);
        ...
    }
}


```

###### 3、服务列表拉取

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、获取注册表信息，除非在协调Eureka服务器和客户端注册表信息时出现问题，否则，此方法尝试仅在第一次获取后获取增量，forceFullRegistryFetch 强制获取完整的注册表
    private boolean fetchRegistry(boolean forceFullRegistryFetch) {
        Stopwatch tracer = FETCH_REGISTRY_TIMER.start();

        try {
            Applications applications = getApplications();

            if (// 2、是否禁用了增量拉取，默认为false
                clientConfig.shouldDisableDelta() 
                // 3、是否关注某个VIP地址，默认为否
                ||                 (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress()))
                	// 4、是否需要拉取全量服务列表，默认为false
                    || forceFullRegistryFetch
                	// 5、apps是否为null，默认不为null
                    || (applications == null)
                	// 6、apps是否为空，注册时的拉取确实为空，定时拉取的一般不为空
                    || (applications.getRegisteredApplications().size() == 0)
                	// 7、客户端应用程序没有支持增量的最新库，默认支持
                    || (applications.getVersion() == -1))
            {
                ...// 日志打印
                // 8、全量拉取服务列表
                getAndStoreFullRegistry();
            } else {
                // 9、增量拉取服务列表
                getAndUpdateDelta(applications);
            }
            ...
        } catch (Throwable e) {
            logger.error(...);
            // 10、服务列表拉取异常，则返回false
            return false;
        } finally {
            if (tracer != null) {
                tracer.stop();
            }
        }

        // 11、更新实例远程状态前，通知缓存刷新
        onCacheRefreshed();

        // 12、根据缓存中保存的刷新数据，更新远程状态
        updateInstanceRemoteStatus();

        // 13、注册表已成功获取，因此返回 true
        return true;
    }
}


```

###### 4、全量拉取服务列表

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 全量拉取注册表信息
    private void getAndStoreFullRegistry() throws Throwable {
        ...     
        EurekaHttpResponse<Applications> httpResponse = 
            // 1、先判断是否对某个VIP地址感兴趣，这里没有配置
            clientConfig.getRegistryRefreshSingleVipAddress() == null?
            // 2、则拉取Regions的注册表，但这里没有任何已注册的信息
            eurekaTransport.queryClient.getApplications(remoteRegionsRef.get()): eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get());
        ...
        // 6、设置为本地服务列表
        localRegionApps.set(this.filterAndShuffle(apps));
        ...
    }   
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 4、最后实际调用AbstractJerseyEurekaHttpClient#getApplications方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Applications> getApplications(String... regions) {
        return getApplicationsInternal("apps/", regions);
    }
    
    private EurekaHttpResponse<Applications> getApplicationsInternal(String urlPath, String[] regions) {
		...
        try {
            // serviceUrl=http://localhost:20000/eureka/，urlPath=apps/
            WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);
            ...
            // 5、真正发起请求 => 响应 Client response status: 200
            response = requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class);
			...
        } finally {
            ...
        }
    }
}


```

###### 5、增量拉取服务列表

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    private void getAndUpdateDelta(Applications applications) throws Throwable {
        ...
        // 1、增量拉取Regions的注册表
        EurekaHttpResponse<Applications> httpResponse = eurekaTransport.queryClient.getDelta(remoteRegionsRef.get());
        ...// 5、如果拉取结果为null，还会全量去拉取一遍
        // 6、根据增量更新本地服务列表
        updateDelta(delta);
        ...
    }
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 2、最后实际调用AbstractJerseyEurekaHttpClient#getDelta方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Applications> getDelta(String... regions) {
        return getApplicationsInternal("apps/delta", regions);
    }
    
    private EurekaHttpResponse<Applications> getApplicationsInternal(String urlPath, String[] regions) {
		...
        try {
            // serviceUrl=http://localhost:20000/eureka/，urlPath=apps/delta
            WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);
            ...
            // 4、真正发起请求 => 响应 Client response status: 200
            response = requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class);
			...
        } finally {
            ...
        }
    }
}


```

##### 响应请求 | Eureka Server

###### 1、全量更新接口

```java
@Path("/{version}/apps")
@Produces({"application/xml", "application/json"})
public class ApplicationsResource {
    @GET
    public Response getContainers(@PathParam("version") String version,
                                  @HeaderParam(HEADER_ACCEPT) String acceptHeader,
                                  @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding,
                                  @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept,
                                  @Context UriInfo uriInfo,
                                  @Nullable @QueryParam("regions") String regionsStr) {
        ...
        Response response;
        if (acceptEncoding != null && acceptEncoding.contains(HEADER_GZIP_VALUE)) {
            // 1、从缓存中获取gzip部分（见两级缓存原理），eg：entity_name=ALL_APPS，hash_key=ApplicationALL_APPSJSONV2full
            response = Response.ok(responseCache.getGZIP(cacheKey))
                    .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE)
                    .header(HEADER_CONTENT_TYPE, returnMediaType)
                    .build();
        } else {
            // 2、否则直接从缓存中获取
            response = Response.ok(responseCache.get(cacheKey))
                    .build();
        }
        return response;
    }
}


```

###### 2、增量拉取接口

```java
@Path("/{version}/apps")
@Produces({"application/xml", "application/json"})
public class ApplicationsResource {
    @Path("delta")
    @GET
    public Response getContainerDifferential(
            @PathParam("version") String version,
            @HeaderParam(HEADER_ACCEPT) String acceptHeader,
            @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding,
            @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept,
        @Context UriInfo uriInfo, @Nullable @QueryParam("regions") String regionsStr) {
        if (acceptEncoding != null
                && acceptEncoding.contains(HEADER_GZIP_VALUE)) {
            // 1、从缓存中获取gzip部分（见两级缓存原理），eg：entity_name=ALL_APPS_DELTA，hash_key=ApplicationALL_APPS_DELTAJSONV2full
            return Response.ok(responseCache.getGZIP(cacheKey))
                    .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE)
                    .header(HEADER_CONTENT_TYPE, returnMediaType)
                    .build();
        } 
        // 2、否则直接从缓存中获取
        else {
            return Response.ok(responseCache.get(cacheKey))
                    .build();
        }
    }
}


```

#### 服务列表缓存原理

![1638705242665](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1638705242665.png)

##### 两级缓存机制 | Eureka Server

###### 概念

1. 服务注册到注册中⼼后，服务实例信息存储在 `AbstractInstanceRegistry#registry` 中，即内存中。
2. 但 Eureka 为了提⾼响应速度，在内部做了优化，加⼊了两层的缓存结构，将 Client 需要的实例信息，直接缓存起来，获取时直接从缓存中拿数据，然后响应给 Client。 
   1. 第⼀层缓存是 `ResponseCacheImpl#readOnlyCacheMap`，采⽤ ConcurrentHashMap 来存储数据，定时与 ` ResponseCacheImpl#readWriteCacheMap` 进⾏数据同步，默认同步时间为 30s ⼀次。
   2. 第⼆层缓存是 `ResponseCacheImpl#readWriteCacheMap`，采⽤ Guava 来实现缓存，缓存过期时间默认为 180s，当服务下线、过期、注册、状态变更等操作，都会清除该缓存中的数据。
   3. 如果两级缓存都无法查询，则会触发 Guava 缓存的加载 `CacheLoader#load`，从存储层  `AbstractInstanceRegistry#registry`  拉取数据到二级缓存中，然后再返回给 Client。

###### 优点

两级缓存机制，提⾼了 Eureka Server 的响应速度，避免了同时读写 `registery` 内存造成的并发冲突问题。

###### 缺点

两级缓存机制，会导致数据⼀致性很薄弱，造成 Eureka Client 获取不到**最新**的服务实例信息（**AP 模型**），⽆法快速发现**新的服务和已下线的服务**。

1. 新服务上线后，服务消费者不能**立即访问**到刚上线的新服务，需要过⼀段时间后才能访问。
2. 或者服务下线后，服务还是会被调⽤到，⼀段时候后才彻底停⽌服务，访问前期会导致**频繁的报错**。

###### 解决方案

- **针对只读缓存**：
  1. 缩短更新时间 `eureka.server.responseCacheUpdateIntervalMs`，让服务发现变得更加及时。
  2. 或者直接关闭 `eureka.server.useReadOnlyResponseCache=false`。
- **针对读写缓存**：
  1. 缩短过期时间 `eureka.server.responseCacheAutoExpirationInSeconds`。
  2. 缩短服务剔除周期 `eureka.server.evictionIntervalTimerInMs`，让服务下线后，能够及时把其从注册表中清除。

###### 相关配置

| 配置                                               | 默认  | 说明                                                         |
| -------------------------------------------------- | ----- | ------------------------------------------------------------ |
| eureka.server.useReadOnlyResponseCache             | true  | true 代表 Eureka Client 会从 `readOnlyCacheMap` 更新数据，而 false 则代表跳过 `readOnlyCacheMap`，直接从`readWriteCacheMap` 中更新 |
| eureka.server.responseCacheUpdateIntervalMs        | 30000 | `readWriteCacheMap` 更新至`readOnlyCacheMap` 的时间周期      |
| eureka.server.responseCacheAutoExpirationInSeconds | 180   | `readWriteCacheMap` Guava 缓存的过期时间                     |
| eureka.server.evictionIntervalTimerInMs            | 60000 | 清理未续约节点的服务剔除周期                                 |

###### 源码分析 - registry

服务注册时添加，服务剔除时删除。

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
	// 服务实例ID instance-id="host：appnNme:port"
	// Eureka Server服务列表双重Map缓存=>{"appName"：{instance-id:InstanceInfo}}
    private final ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry = new ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>>();
            
	// 1、服务注册，注册具有给定持续时间的新实例
    public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {
        try {
            // 如果为第一次注册，则创建appName：空Map（服务实例的状态变化时，Server可能会收到多次，来自同一个实例的注册请求）
            Map<String, Lease<InstanceInfo>> gMap = registry.get(registrant.getAppName());
            REGISTER.increment(isReplication);
            if (gMap == null) {
                final ConcurrentHashMap<String, Lease<InstanceInfo>> gNewMap = new ConcurrentHashMap<String, Lease<InstanceInfo>>();
                gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap);
                if (gMap == null) {
                    gMap = gNewMap;
                }
            }
        }
    }
    
    // 2、服务剔除：剔除已过期的服务实例
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
        Map<String, Lease<InstanceInfo>> gMap = registry.get(appName);
        Lease<InstanceInfo> leaseToCancel = null;
        if (gMap != null) {
            leaseToCancel = gMap.remove(id);
        }
    }
}


```

###### 源码分析 - readWriteCacheMap

自动装配时构造，一级缓存找不到时加载，从 `registry` 或者 `recentlyChangedQueue` 中加载。

```java
...
// 1、自动装配时构造
public class EurekaServerAutoConfiguration extends WebMvcConfigurerAdapter {
    ....
	// Eureka服务端上下文——EurekaServerContext
	@Bean
	@ConditionalOnMissingBean
	public EurekaServerContext eurekaServerContext(ServerCodecs serverCodecs, PeerAwareInstanceRegistry registry, PeerEurekaNodes peerEurekaNodes) {
		return new DefaultEurekaServerContext(this.eurekaServerConfig, serverCodecs,
				registry, peerEurekaNodes, this.applicationInfoManager);
	}
    ...
}

@Singleton
public class DefaultEurekaServerContext implements EurekaServerContext {
    // 2、自动装配时构造
    @PostConstruct
    @Override
    public void initialize() {
        ...
        registry.init(peerEurekaNodes);
		...
    }
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    
    // 2、自动装配时构造
    @Override
    public void init(PeerEurekaNodes peerEurekaNodes) throws Exception {
		...
        initializedResponseCache();
        ...
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    // 3、自动装配时构造
    @Override
    public synchronized void initializedResponseCache() {
        if (responseCache == null) {
            responseCache = new ResponseCacheImpl(serverConfig, serverCodecs, this);
        }
    }
}

public class ResponseCacheImpl implements ResponseCache {
    ...
    // 读写缓存
    private final LoadingCache<Key, Value> readWriteCacheMap;
    
    // 4、自动装配时构造
    ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) {
        ...
        this.readWriteCacheMap = 
            CacheBuilder.newBuilder()
            .initialCapacity(serverConfig.getInitialCapacityOfResponseCache())
            .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS)
            .removalListener(new RemovalListener<Key, Value>() {...})
            .build(new CacheLoader<Key, Value>() {
                // 5、一级缓存找不到时加载
                @Override
                public Value load(Key key) throws Exception {
                    if (key.hasRegions()) {
                        Key cloneWithNoRegions = key.cloneWithoutRegions();
                        regionSpecificKeys.put(cloneWithNoRegions, key);
                    }
                    // 6、从registry/recentlyChangedQueue中加载
                    Value value = generatePayload(key);
                    return value;
                }
            });
        ...
    }
    
    private Value generatePayload(Key key) {
        ...
        if (ALL_APPS.equals(key.getName())) {
            ...
            // 7、全量拉取时，从registry中加载
            payload = getPayLoad(key, registry.getApplications());
        } else if (ALL_APPS_DELTA.equals(key.getName())) {
            ...
            // 8、全量拉取时，从recentlyChangedQueue中加载
            payload = getPayLoad(key, registry.getApplicationDeltas());
        } else {
            ...
        }
        ...
    }
}


```

###### 源码分析 - readOnlyCacheMap

自动装配时构造，定时同步读写缓存，服务发现时更新（有延迟）。

```java
public class ResponseCacheImpl implements ResponseCache {
    ...
    // 1、只读缓存，实例变量，自动装配时构造
    private final ConcurrentMap<Key, Value> readOnlyCacheMap = new ConcurrentHashMap<Key, Value>();
    
    ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) {
        ...
        if (shouldUseReadOnlyResponseCache) {
            // 2、定时同步读写缓存，默认延后30秒执行，执行周期为30s
            timer.schedule(getCacheUpdateTask(),
                    new Date(((System.currentTimeMillis() / responseCacheUpdateIntervalMs) * responseCacheUpdateIntervalMs)
                            + responseCacheUpdateIntervalMs),
                    responseCacheUpdateIntervalMs);
        }
        ...
    }
    
    private TimerTask getCacheUpdateTask() {
        return new TimerTask() {
            @Override
            public void run() {
                ...
                for (Key key : readOnlyCacheMap.keySet()) {
                    ...
                    try {
                        CurrentRequestVersion.set(key.getVersion());
                        Value cacheValue = readWriteCacheMap.get(key);
                        Value currentCacheValue = readOnlyCacheMap.get(key);
                        // 3、定时同步读写缓存
                        if (cacheValue != currentCacheValue) {
                            readOnlyCacheMap.put(key, cacheValue);
                        }
                    } catch (Throwable th) {
                        ...
                    }
                }
            }
        };
    }
    
    // 4、服务发现时更新（有延迟）：获取有关应用程序的压缩信息
    public byte[] getGZIP(Key key) {
        // 5、是否读取只读缓存，默认开启
        Value payload = getValue(key, shouldUseReadOnlyResponseCache);
        if (payload == null) {
            return null;
        }
        // 9、只返回gzip部分
        return payload.getGzipped();
    }
    
    @VisibleForTesting
    Value getValue(final Key key, boolean useReadOnlyCache) {
        Value payload = null;
        try {
            // 6、如果启动用了读取只读缓存，则先从只读缓存中获取（ConcurrentHashMap）
            if (useReadOnlyCache) {
                final Value currentPayload = readOnlyCacheMap.get(key);
                if (currentPayload != null) {
                    payload = currentPayload;
                } 
                // 7、如果只读缓存中获取不到，则还会从读写缓存中获取（com.google.common.cache.LoadingCache）
                else {
                    payload = readWriteCacheMap.get(key);
                    readOnlyCacheMap.put(key, payload);
                }
            }
            // 8、否则直接从读写缓存中获取（com.google.common.cache.LoadingCache）
            else {
                payload = readWriteCacheMap.get(key);
            }
        } catch (Throwable t) {
            ...
        }
        return payload;
    }
}


```

##### 本地内存缓存 | Eureka Client

###### 全量更新

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    
    // 本地服务列表内存缓存
    private final AtomicReference<Applications> localRegionApps = new AtomicReference<Applications>();
    
    // 1、全量更新
	private void getAndStoreFullRegistry() throws Throwable {
        ...// 2、服务列表全量拉取
        if (apps == null) {
            ...
        } 
        // 3、CAS更新服务列表版本
        else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            // 4、去除非UP服务列表，然后设置到本地内存缓存
            localRegionApps.set(this.filterAndShuffle(apps));
            ...
        } else {
            ...
        }
    }
}  


```

###### 增量更新

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    
    // 本地服务列表内存缓存
    private final AtomicReference<Applications> localRegionApps = new AtomicReference<Applications>();
    
    // 5、增量更新
    private void getAndUpdateDelta(Applications applications) throws Throwable {
        ...
        // 6、服务列表增量拉取
        if (delta == null) {
            ...
            // 7、如果结果为null，则还要重新发起全量拉取
            getAndStoreFullRegistry();
        } 
        // 8、CAS更新服务列表版本
        else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            ...
            if (fetchRegistryUpdateLock.tryLock()) {
                try {
                    // 9、去除非UP服务列表
                    updateDelta(delta);
                    reconcileHashCode = getReconcileHashCode(applications);
                } finally {
                    fetchRegistryUpdateLock.unlock();
                }
            } else {
                ...
            }
            // 10、服务列表的hashcode不同，则还要更新服务列表
            if (!reconcileHashCode.equals(delta.getAppsHashCode()) || clientConfig.shouldLogDeltaDiff()) {
                reconcileAndLogDifference(delta, reconcileHashCode);
            }
        } else {
            ...
        }
    }
    
    private void reconcileAndLogDifference(Applications delta, String reconcileHashCode) throws Throwable {
        // ... 11、服务列表的hashcode不同，则再全量拉取一次，用于更新服务列表
        // 12、CAS更新服务列表版本
        if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {
            // 13、设置到本地内存缓存
            localRegionApps.set(this.filterAndShuffle(serverApps));
            ..
        } else {
            ...
        }
    }
}


```

##### 服务调用缓存 | Ribbon

LoadBalancerClient 每选择一次不同的服务，则 RibbonClientConfiguration 就会构造一次，触发 updateAction#doUpdate 的服务调用缓存更新，详情见《服务调用原理 - 6、服务调用缓存实现》。

| 配置                                        | 默认 | 说明                                                       |
| ------------------------------------------- | ---- | ---------------------------------------------------------- |
| xxxService.ribbon.serverListRefreshInterval | 30s  | Ribbon 服务调用缓存，与 Eureka Client 服务列表缓存同步周期 |

```java
public class PollingServerListUpdater implements ServerListUpdater {
    @Override
    public synchronized void start(final UpdateAction updateAction) {
        if (isActive.compareAndSet(false, true)) {
            final Runnable wrapperRunnable = new Runnable() {
                @Override
                public void run() {
                    // 2、每次执行updateAction#doUpdate
                   	updateAction.doUpdate();
                }
            };
			
            // 1、延迟10s，默认周期为30s定时执行任务
            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(
                    wrapperRunnable,
                    initialDelayMs,
                    refreshIntervalMs,
                    TimeUnit.MILLISECONDS
            );
        } else {
            logger.info(...);
        }
    }
}


```

#### 服务调用原理 | Eureka Client

##### 1、Eureka 依赖 Ribbon 

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
</dependency>
<dependency>
    <groupId>com.netflix.ribbon</groupId>
    <artifactId>ribbon-eureka</artifactId>
</dependency>


```

##### 2、Spring SPI 配置

```properties
# .../spring-cloud-netflix-eureka-client/2.1.1.RELEASE/spring-cloud-netflix-eureka-client-2.1.1.RELEASE.jar!/META-INF/spring.factories
# Ribbon负载均衡自动配置类
org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\


```

##### 3、客户端负载均衡自动装配

```java
@Configuration
@EnableConfigurationProperties
@ConditionalOnRibbonAndEurekaEnabled
// 1、客户端负载均衡，自动装配
@AutoConfigureAfter(RibbonAutoConfiguration.class)
// Eureka客户端负载均衡预处理器，自动装配
@RibbonClients(defaultConfiguration = EurekaRibbonClientConfiguration.class)
public class RibbonEurekaAutoConfiguration {

}

@Configuration
@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)
@RibbonClients
// 3、在Eureka Client初始化之后，才注入当前类
@AutoConfigureAfter(name = "org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration")
// 4、loadbalancer自动装配
@AutoConfigureBefore({ 
    LoadBalancerAutoConfiguration.class,
	AsyncLoadBalancerAutoConfiguration.class 
 })
// 5、读取Ribbon配置
@EnableConfigurationProperties({ RibbonEagerLoadProperties.class,
		ServerIntrospectorProperties.class })
public class RibbonAutoConfiguration {
    ...  
	@Bean
	public SpringClientFactory springClientFactory() {
        // 6、配置负载均衡客户端的上下文工厂
		SpringClientFactory factory = new SpringClientFactory();
		factory.setConfigurations(this.configurations);
		return factory;
	}

	@Bean
	@ConditionalOnMissingBean(LoadBalancerClient.class)
	public LoadBalancerClient loadBalancerClient() {
        // 9、构造LoadBalancerClient实例RibbonLoadBalancerClient
		return new RibbonLoadBalancerClient(springClientFactory());
	}
    ...
}

// 创建客户端、负载均衡器和客户端配置实例的工厂，为每个客户端名称创建一个Spring ApplicationContext，并从那里提取需要的bean
public class SpringClientFactory extends NamedContextFactory<RibbonClientSpecification> {
    ...
    // 7、调用父类构造器，RibbonClientConfiguration在每个负载均衡客户端Bean实例构造时注入
	public SpringClientFactory() {
		super(RibbonClientConfiguration.class, NAMESPACE, "ribbon.client.name");
	}
    ...
}

// 创建一组子上下文，允许一组规范定义每个子上下文中的 bean，从spring-cloud-netflix FeignClientFactory和SpringClientFactory移植，实现DisposableBean，代表工厂用于构造一次性Bean
public abstract class NamedContextFactory<C extends NamedContextFactory.Specification>
implements DisposableBean, ApplicationContextAware {
	// 8、上下文工厂构造器，RibbonClientConfiguration在每个负载均衡客户端Bean实例构造时注入
	public NamedContextFactory(Class<?> defaultConfigType, String propertySourceName,
			String propertyName) {
		this.defaultConfigType = defaultConfigType;
		this.propertySourceName = propertySourceName;
		this.propertyName = propertyName;
	}
}


```

##### 4、Controller 注入 LoadBalancerClient

```java
// 1、Eureka Consumer测试前端控制类
@RestController
@Slf4j
public class ConsumerController {
    @Autowired
    private LoadBalancerClient loadBalancerClient;
    @Autowired
    private RestTemplate restTemplate;
    
    /**
     * 测试消费Post服务
     * @return
     */
    @PostMapping("/hello")
    public Friend helloPost(){
        // 2、使用loadBalancerClient，指定服务名，选择一个具体的服务实例
        ServiceInstance instance = loadBalancerClient.choose("eureka-client");
        if(instance == null){
            return null;
        }
        
        // 3、根据服务名拉取服务信息
        String targetUrl = String.format("http://%s:%s/sayHi", instance.getHost(), instance.getPort());
        log.info("url is {}", targetUrl);

        Friend friendParam = new Friend();
        friendParam.setName("Eureka Consumer");

        // 4、根据IP+端口发起远程调用
        return restTemplate.postForObject(targetUrl, friendParam, Friend.class);
    }
}


```

##### 5、LoadBalancerClient 服务实例选择原理

```java
public class RibbonLoadBalancerClient implements LoadBalancerClient {
    // 1、指定服务名，选择一个具体的服务实例，serviceId="eureka-client"
	@Override
	public ServiceInstance choose(String serviceId) {
		return choose(serviceId, null);
	}
    
	public ServiceInstance choose(String serviceId, Object hint) {
        // 3、根据服务名选择一个具体的服务实例
		Server server = getServer(
            // 2、根据服务名选择一个具体的负载均衡器
            getLoadBalancer(serviceId), hint
        );
		if (server == null) {
			return null;
		}
        // 4、构造RibbonServer返回
		return new RibbonServer(serviceId, server, isSecure(server, serviceId),
				serverIntrospector(serviceId).getMetadata(server));
	}
    
	protected ILoadBalancer getLoadBalancer(String serviceId) {
        // 2.1、使用SpringClientFactory负载均衡客户端的上下文工厂，构造一个负载均衡器Bean实例
		return this.clientFactory.getLoadBalancer(serviceId);
	}

    protected Server getServer(ILoadBalancer loadBalancer, Object hint) {
		if (loadBalancer == null) {
			return null;
		}
		// 3.1、选择默认的服务实例
		return loadBalancer.chooseServer(hint != null ? hint : "default");
	}
}

public class ZoneAwareLoadBalancer<T extends Server> extends DynamicServerListLoadBalancer<T> {
    @Override
    public Server chooseServer(Object key) {
     if (!ENABLED.get() || getLoadBalancerStats().getAvailableZones().size() <= 1) {
            logger.debug(...);
         	// 3.2、调用父类方法，选择默认的服务实例
            return super.chooseServer(key);
            ...
        }
    }
}

public class BaseLoadBalancer extends AbstractLoadBalancer implements
    PrimeConnections.PrimeConnectionListener, IClientConfigAware {
    public Server chooseServer(Object key) {
        ...
        // 3.3、以循环方式，从过滤列表中返回服务实例
        return rule.choose(key);
        ...
    }
    
    // 3.5、返回只可读的服务调用缓存（缓存实现见第6点）
    @Override
    public List<Server> getAllServers() {
        return Collections.unmodifiableList(allServerList);
    }
}

public abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule {
    @Override
    public Server choose(Object key) {
        ILoadBalancer lb = getLoadBalancer();
        // 3.6、根据服务名过滤服务列表
        Optional<Server> server = getPredicate().chooseRoundRobinAfterFiltering(
            //3.4、使用ZoneAwareLoadBalancer获取所有服务列表（服务调用缓存）
            lb.getAllServers(), key
        );
        if (server.isPresent()) {
            // 3.7、返回最后选择的服务实例
            return server.get();
        } else {
            return null;
        }       
    }
}

public class SpringClientFactory extends NamedContextFactory<RibbonClientSpecification> {
    
    // 2.2、构造一个负载均衡器ILoadBalancer Bean实例
	public ILoadBalancer getLoadBalancer(String name) {
		return getInstance(name, ILoadBalancer.class);
	}
    
	@Override
	public <C> C getInstance(String name, Class<C> type) {
        // 2.3、构造一个负载均衡器ILoadBalancer Bean实例并返回
		C instance = super.getInstance(name, type);
		if (instance != null) {
			return instance;
		}
		IClientConfig config = getInstance(name, IClientConfig.class);
		return instantiateWithConfig(getContext(name), type, config);
	}
}

public abstract class NamedContextFactory<C extends NamedContextFactory.Specification>
implements DisposableBean, ApplicationContextAware {

	public <T> T getInstance(String name, Class<T> type) {
		// 2.4、根据服务名获取对应的上下文配置
		AnnotationConfigApplicationContext context = getContext(name);
		if (BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context,
				type).length > 0) {
			// 2.7、Spring AbstractApplicationContext#getBean构造ILoadBalancer Bean实例ZoneAwareLoadBalancer
			return context.getBean(type);
		}
		return null;
	}
	
	protected AnnotationConfigApplicationContext getContext(String name) {
		if (!this.contexts.containsKey(name)) {
			synchronized (this.contexts) {
				if (!this.contexts.containsKey(name)) {
					// 2.5、第一次构造对应的上下文，然后服务名做key缓存起来
					this.contexts.put(name, createContext(name));
				}
			}
		}
		return this.contexts.get(name);
	}

	protected AnnotationConfigApplicationContext createContext(String name) {
		...
		// 2.6、底层调用Spring AbstractApplicationContext#refresh，触发RibbonClientConfiguration注入
		context.refresh();
		return context;
	}
}


```

##### 6、服务调用缓存实现

```java
// 1、RibbonClientConfiguration，每个服务名对应的服务均衡器构造时，都会重新refresh注入
@SuppressWarnings("deprecation")
@Configuration
@EnableConfigurationProperties
@Import({ HttpClientConfiguration.class, OkHttpRibbonConfiguration.class,
		RestClientRibbonConfiguration.class, HttpClientRibbonConfiguration.class })
public class RibbonClientConfiguration {
    ...
	@Bean
	@ConditionalOnMissingBean
	public ServerListUpdater ribbonServerListUpdater(IClientConfig config) {
        // 1、构造服务列表自动拉取的Updater
		return new PollingServerListUpdater(config);
	}
    
	@Bean
	@ConditionalOnMissingBean
	public ILoadBalancer ribbonLoadBalancer(IClientConfig config,
			ServerList<Server> serverList, ServerListFilter<Server> serverListFilter,
			IRule rule, IPing ping, ServerListUpdater serverListUpdater) {
		if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) {
			return this.propertiesFactory.get(ILoadBalancer.class, config, name);
		}
        // 2、根据Updater构造负载均衡器实例ZoneAwareLoadBalancer
		return new ZoneAwareLoadBalancer<>(config, rule, ping, serverList,
				serverListFilter, serverListUpdater);
	}
	...
}

public class PollingServerListUpdater implements ServerListUpdater {
    // 1.1、调用父类构造器，设置延迟10s，默认周期为30s定时执行任务的参数
    this(LISTOFSERVERS_CACHE_UPDATE_DELAY, getRefreshIntervalMs(clientConfig));
}

public class PollingServerListUpdater implements ServerListUpdater {
     // 1.2、设置延迟10s，默认周期为30s定时执行任务的参数
    public PollingServerListUpdater(final long initialDelayMs, final long refreshIntervalMs) {
        this.initialDelayMs = initialDelayMs;
        this.refreshIntervalMs = refreshIntervalMs;
    }
}

public class ZoneAwareLoadBalancer<T extends Server> extends DynamicServerListLoadBalancer<T> {
    public ZoneAwareLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList<T> serverList, ServerListFilter<T> filter, ServerListUpdater serverListUpdater) {
        // 2.1、调用父类构造器，启动调用服务缓存更新的定时任务
        super(clientConfig, rule, ping, serverList, filter, serverListUpdater);
    }
}

public class DynamicServerListLoadBalancer<T extends Server> extends BaseLoadBalancer {
     // DynamicServerListLoadBalancer构造器
     public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping, ServerList<T> serverList, ServerListFilter<T> filter, ServerListUpdater serverListUpdater) {
        ...
        // 2.2、启动调用服务缓存更新的定时任务
        restOfInit(clientConfig);
    }
    
    void restOfInit(IClientConfig clientConfig) {
        ...
        // 2.3、启动调用服务缓存更新的定时任务
        enableAndInitLearnNewServersFeature();
        
		// 2.8. 第一次不等定时执行，立即执行一次updateAction#doUpdate，同步EurekaClient服务实例缓存，到调用缓存中
        updateListOfServers();
        ...
    }

    public void enableAndInitLearnNewServersFeature() {
        LOGGER.info(...);
        // 2.4、启动调用服务缓存更新的定时任务
        serverListUpdater.start(updateAction);
    }
    
    // 2.7、定时任务成员变量
    protected final ServerListUpdater.UpdateAction updateAction = new ServerListUpdater.UpdateAction() {
        @Override
        public void doUpdate() {
            // 2.8. updateAction#doUpdate每次都同步EurekaClient服务实例缓存，到调用缓存中
            updateListOfServers();
        }
    };

    @VisibleForTesting
    public void updateListOfServers() {
        List<T> servers = new ArrayList<T>();
        if (serverListImpl != null) {
            // 2.9、拉取最新的EurekaClient服务实例缓存
            servers = serverListImpl.getUpdatedListOfServers();
            ...
        }
        // 2.14、更新服务调用缓存
        updateAllServerList(servers);
    }
    
    protected void updateAllServerList(List<T> ls) {
        if (serverListUpdateInProgress.compareAndSet(false, true)) {
            ...
            // 2.15、更新服务调用缓存
            setServersList(ls);
            ...
        }
    }
    
    @Override
    public void setServersList(List lsrv) {
        ...
        // 2.16、更新服务调用缓存
        super.setServersList(lsrv);
        ...
    }
}

public class BaseLoadBalancer extends AbstractLoadBalancer implements
    PrimeConnections.PrimeConnectionListener, IClientConfigAware {
    public void setServersList(List lsrv) {
        // 2.17、更新服务调用缓存
        ...
        allServerList = allServers;
        ...
    }
}

public class PollingServerListUpdater implements ServerListUpdater {
    @Override
    public synchronized void start(final UpdateAction updateAction) {
        if (isActive.compareAndSet(false, true)) {
            final Runnable wrapperRunnable = new Runnable() {
                @Override
                public void run() {
                    // 2.6、每次执行updateAction#doUpdate
                   	updateAction.doUpdate();
                }
            };
			
            // 2.5、延迟10s，默认周期为30s定时执行任务
            scheduledFuture = getRefreshExecutor().scheduleWithFixedDelay(
                    wrapperRunnable,
                    initialDelayMs,
                    refreshIntervalMs,
                    TimeUnit.MILLISECONDS
            );
        } else {
            logger.info(...);
        }
    }
}

public class DomainExtractingServerList implements ServerList<DiscoveryEnabledServer> {
	@Override
	public List<DiscoveryEnabledServer> getUpdatedListOfServers() {
		List<DiscoveryEnabledServer> servers = setZones(
            	// 2.10、拉取最新的EurekaClient服务实例缓存
				this.list.getUpdatedListOfServers());
		return servers;
	}
}

public class DiscoveryEnabledNIWSServerList extends AbstractServerList<DiscoveryEnabledServer>{
    @Override
    public List<DiscoveryEnabledServer> getUpdatedListOfServers(){
        // 2.11、拉取最新的EurekaClient服务实例缓存
        return obtainServersViaDiscovery();
    }
    
    private List<DiscoveryEnabledServer> obtainServersViaDiscovery() {
        ...
        // 2.12、获取EurekaClient中的服务实例缓存
        List<InstanceInfo> listOfInstanceInfo = eurekaClient.getInstancesByVipAddress(vipAddress, isSecure, targetRegion);
        ...
    }
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    @Override
    public List<InstanceInfo> getInstancesByVipAddress(String vipAddress, boolean secure, @Nullable String region) {
        ...
        // 2.13、从原子变量中获取服务实例缓存
        applications = this.localRegionApps.get();
        ...
    }
}


```

#### 服务续约原理

##### 发起请求 | Eureka Client

###### 1、定时心跳检测 | 默认周期 30s

| 配置                                            | 默认 | 说明                                |
| ----------------------------------------------- | ---- | ----------------------------------- |
| eureka.instance.lease.renewalInterval           | 30s  | 服务实例续约周期                    |
| eureka.client.heartbeat.exponentialBackOffBound | 10倍 | 10 * 30，表示最大的服务续约周期乘数 |

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    // 1、非默认参数，启动续租超时时间5s，最大超时50s，延迟5s执行，交由heartbeatExecutor线程池处理的，在给定的时间间隔内，更新租约的心跳任务（心跳检测）
    private class HeartbeatThread implements Runnable {
        public void run() {
            if (renew()) {
                // 2、续约成功，则更新最后续约成功时间
                lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis();
            }
        }
    }
}


```

###### 2、发送续约心跳包

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    boolean renew() {
        EurekaHttpResponse<InstanceInfo> httpResponse;
        try {
            // 1、发送续约心跳包
            httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null);
            logger.debug(...);
            // 2、如果响应结果为 NOT_FOUND(404, "Not Found")
            if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) {
                REREGISTER_COUNTER.increment();
                logger.info(...);
                // 3、则设置isInstanceInfoDirty=true，刷新最后脏时间戳，并重新发起服务注册
                long timestamp = instanceInfo.setIsDirtyWithTime();
                boolean success = register();
                if (success) {
                    // 4、如果重新注册成功，则清除isInstanceInfoDirty（设置为false）
                    instanceInfo.unsetIsDirty(timestamp);
                }
                // 5、重新注册成功则返回true，否则返回false
                return success;
            }
            // 6、如果响应结果为 OK(200, "OK")，则直接返回 true
            return httpResponse.getStatusCode() == Status.OK.getStatusCode();
        } catch (Throwable e) {
            logger.error(...);
            // 7、处理异常，则也返回 false
            return false;
        }
    }  
}


```

###### 3、最后调用 AbstractJerseyEurekaHttpClient#sendHeartBeat

```java
public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
    // 最后实际调用AbstractJerseyEurekaHttpClient#getDelta方法，中间经历的代理跟注册的类似：
    // 1) 多态调用SessionedEurekaHttpClient#execute
    // 2) 多态调用RetryableEurekaHttpClient#execute
    // 3) 多态调用RedirectingEurekaHttpClient#execute
    // 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<InstanceInfo> sendHeartBeat(String appName, String id, InstanceInfo info, InstanceStatus overriddenStatus) {
        String urlPath = "apps/" + appName + '/' + id;
        ClientResponse response = null;
        try {
            // 1、serviceurl=http://localhost:20000/eureka/
            WebResource webResource = jerseyClient.resource(serviceUrl)
                	// 2、urlPath=apps/service-name/host:service-name:ip
                    .path(urlPath)
                	// 3、status=UP
                    .queryParam("status", info.getStatus().toString())
                	// 4、lastDirtyTimestamp=1638885398794
                    .queryParam("lastDirtyTimestamp", info.getLastDirtyTimestamp().toString());
            ...
            // 5、真正发起心跳包到Eureka Server
            response = requestBuilder.put(ClientResponse.class);
            ...
        } finally {
            ...
        }
    }
}


```

##### 响应请求 | Eureka Server

###### 1、续约心跳包接收接口

| 配置                                   | 默认 | 说明                             |
| -------------------------------------- | ---- | -------------------------------- |
| eureka.server.syncWhenTimestampDiffers | true | 检查是否在脏时间戳不同时同步实例 |

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    @PUT
    public Response renewLease(
            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication,
            @QueryParam("overriddenstatus") String overriddenStatus,
            @QueryParam("status") String status,
        @QueryParam("lastDirtyTimestamp") String lastDirtyTimestamp) {
        // 1、执行服务续约
        boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode);
        
        // 2、续约失败，返回404，代表客户端服务找不到，让客户端重新发起注册
        if (!isSuccess) {
            logger.warn("Not Found (Renew): {} - {}", app.getName(), id);
            return Response.status(Status.NOT_FOUND).build();
        }
        
        // 3、对比Eureka Server中的租约，检查是否需要根据脏时间戳进行同步，以及客户端实例是否可能已经更改了某些值
        Response response;
        if (lastDirtyTimestamp != null && serverConfig.shouldSyncWhenTimestampDiffers()) {
            // 4、租约验脏，如果需要在脏时间戳不同时，重新同步实例，则校验客户端传过来的脏时间戳
            response = this.validateDirtyTimestamp(Long.valueOf(lastDirtyTimestamp), isFromReplicaNode);
            // 5、如果是副本间同步，且租约状态发生变化，则覆盖租约实例
            if (response.getStatus() == Response.Status.NOT_FOUND.getStatusCode()
                    && (overriddenStatus != null)
                    && !(InstanceStatus.UNKNOWN.name().equals(overriddenStatus))
                    && isFromReplicaNode) {
                registry.storeOverriddenStatusIfRequired(app.getAppName(), id, InstanceStatus.valueOf(overriddenStatus));
            }
        } 
        // 6、如果无需重新同步，则直接返回ok
        else {
            response = Response.ok().build();
        }
        logger.debug(...);
        return response;
    }
}


```

###### 2、执行服务续约

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public boolean renew(final String appName, final String serverId,
			boolean isReplication) {
		log(...);
		// 1、获取Eureka Server缓存中的所有租约
		List<Application> applications = getSortedApplications();
		// 2、根据服务名获取对应的租约
		for (Application input : applications) {
			if (input.getName().equals(appName)) {
				InstanceInfo instance = null;
				for (InstanceInfo info : input.getInstances()) {
					if (info.getId().equals(serverId)) {
						instance = info;
						break;
					}
				}
				publishEvent(new EurekaInstanceRenewedEvent(this, appName, serverId,
						instance, isReplication));
				break;
			}
		}
		// 3、调用父类进行续租
		return super.renew(appName, serverId, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    public boolean renew(final String appName, final String id, final boolean isReplication) {
    	// 4、再调用父类进行续租
        if (super.renew(appName, id, isReplication)) {
        	// 7、如果续约成功，则还要将所有eureka操作复制到对等的其他eureka节点
            replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);
            return true;
        }
        return false;
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    public boolean renew(String appName, String id, boolean isReplication) {
    	...
    	// 5、租期续约
		leaseToRenew.renew();
		return true;
    }
}

public class Lease<T> {
    public void renew() {
    	// 6、租期续约，当前时间+客户端设置的租约过期时间（eureka.instance.lease-expiration-duration-in-seconds）
        lastUpdateTimestamp = System.currentTimeMillis() + duration;
    }
}


```

###### 3、租约验脏

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    private Response validateDirtyTimestamp(Long lastDirtyTimestamp,
                                            boolean isReplication) {
        // 1、获取Eureka Server缓存的服务租约
        InstanceInfo appInfo = registry.getInstanceByAppAndId(app.getName(), id, false);
        if (appInfo != null) {
            // 2、如果脏时间戳不一致
            if ((lastDirtyTimestamp != null) && (!lastDirtyTimestamp.equals(appInfo.getLastDirtyTimestamp()))) {
                Object[] args = {id, appInfo.getLastDirtyTimestamp(), lastDirtyTimestamp, isReplication};
				// 3、如果传过来的脏时间戳大，则认为Eureka Server中的租约落后，需要重新注册服务，则返回404给客户端，让其重新注册
                if (lastDirtyTimestamp > appInfo.getLastDirtyTimestamp()) {
                    logger.debug(...);
                    return Response.status(Status.NOT_FOUND).build();
                } 
                else if (appInfo.getLastDirtyTimestamp() > lastDirtyTimestamp) {
                    // 4、如果传过来的脏时间落后，且是副本间同步的话，则将注册表中的当前实例信息，发送给复制节点以与该节点同步
                    if (isReplication) {
                        logger.debug(...);
                        return Response.status(Status.CONFLICT).entity(appInfo).build();
                    } 
                    // 5、否则，返回ok，代表租约正常
                    else {
                        return Response.ok().build();
                    }
                }
            }
        }
        return Response.ok().build();
    } 
}


```

#### 服务剔除原理 | Eureka Server

##### 1、初始化 Eureka Server 上下文

| 配置                                    | 默认  | 说明                   |
| --------------------------------------- | ----- | ---------------------- |
| eureka.server.evictionIntervalTimerInMs | 60000 | 服务剔除任务的执行周期 |

```java
public class EurekaServerBootstrap {
	public void contextInitialized(ServletContext context) {
        ...
        // 1、注册中心启动时，初始化Eureka上下文，详情见《注册中心启动原理》
        initEurekaServerContext();
        ...
	}
    
    protected void initEurekaServerContext() throws Exception {
        ...
        // 2、初始化启动变量，以及启动服务剔除定时任务
		this.registry.openForTraffic(this.applicationInfoManager, registryCount);
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
		// 3. 初始化启动变量，以及启动服务剔除定时任务
		super.openForTraffic(applicationInfoManager,
				count == 0 ? this.defaultOpenForTrafficCount : count);
	}
}

public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) {
    	...
    	// 4.设置完毕，上下文后置初始化处理
    	super.postInit();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void postInit() {
   		// 5. 设置服务剔除任务
        evictionTaskRef.set(new EvictionTask());
        // 6. 默认延迟60s后开始执行任务，且每60s执行一次
        evictionTimer.schedule(evictionTaskRef.get(),
                serverConfig.getEvictionIntervalTimerInMs(),
                serverConfig.getEvictionIntervalTimerInMs());
    }
}


```

##### 2、执行服务剔除

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    
    class EvictionTask extends TimerTask {
        private final AtomicLong lastExecutionNanosRef = new AtomicLong(0l);

        @Override
        public void run() {
            try {
                // 1、计算补偿时间，定义为自上次迭代以来执行此任务的实际时间，与配置的执行时间量。 这对于时间变化（例如由于时钟偏差或 gc）导致实际驱逐任务执行晚于根据配置的周期所需的时间的情况很有用
                long compensationTimeMs = getCompensationTimeMs();
                logger.info(...);
                // 2、执行服务剔除
                evict(compensationTimeMs);
            } catch (Throwable e) {
                logger.error(...);
            }
        }
    }
    
    // additionalLeaseMs补偿时间，默认为0
    public void evict(long additionalLeaseMs) {
        logger.debug("Running the evict task");
        
        // 3、如果自我保护已经打开了（动态变化），则不进行服务剔除，直接返回
        if (!isLeaseExpirationEnabled()) {
            logger.debug("");
            return;
        }
        ...
        // 4、先收集所有过期的租约，判断租期是否已经过期，如果已经过期则加入过期列表
        if (lease.isExpired(additionalLeaseMs) && lease.getHolder() != null) {
            expiredLeases.add(lease);
        }
        ...
        // 6、然后随机顺序驱逐它们，对于大型驱逐集，如果我们不这样做，我们可能会在自我保护开始之前清除整个应用程序，而通过随机化它们，剔除后租约应该可以均匀分布在各个应用程序中
        int next = i + random.nextInt(expiredLeases.size() - i);
        Collections.swap(expiredLeases, i, next);
        Lease<InstanceInfo> lease = expiredLeases.get(i);
        String appName = lease.getHolder().getAppName();
        String id = lease.getHolder().getId();
        EXPIRED.increment();
        logger.warn("DS: Registry: expired lease for {}/{}", appName, id);
        // 7、取消服务租约
        internalCancel(appName, id, false);
    }
}

public class Lease<T> {
    public boolean isExpired(long additionalLeaseMs) {
        // 5、如果该租约经过过期了，或者最后心跳时间+最长续约时间+时间补偿，还大于了当前时间，则也认为该租约过期了
        return (evictionTimestamp > 0 || System.currentTimeMillis() > (lastUpdateTimestamp + duration + additionalLeaseMs));
    }
}

public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	protected boolean internalCancel(String appName, String id, boolean isReplication) 
		// 8、记录日志、发布租约取消事件
		handleCancelation(appName, id, isReplication);
		// 9、调用父类，取消服务租约
		return super.internalCancel(appName, id, isReplication);
	}
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
    	...
    	// 10、删除对应的服务列表
		leaseToCancel = gMap.remove(id);
		// 11、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已从服务列表删除，所以只读缓存也会清空该服务列表，不过有一定的延迟（默认30s同步一次）
		invalidateCache(appName, vip, svip);
		...
    }
}


```

#### 服务自保原理 | Eureka Server

##### 1、服务剔除

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    // 1、只有服务剔除才会触发服务自保，服务下线并不会有这判断
    public void evict(long additionalLeaseMs) {
       	...
        
        // 2、如果自我保护已经打开了（动态变化），则不进行服务剔除，直接返回
        if (!isLeaseExpirationEnabled()) {
            logger.debug("");
            return;
        }
        ...
    }
}


```

##### 2、服务自保判断

| 配置                                  | 默认 | 说明                         |
| ------------------------------------- | ---- | ---------------------------- |
| eureka.server.enableSelfPreservation  | true | 是否开启自我保护             |
| eureka.instance.lease.renewalInterval | 30s  | 服务实例续约周期             |
| eureka.server.renewalPercentThreshold | 0.85 | 服务实例续约到服务自保的阈值 |

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean isLeaseExpirationEnabled() {
        // 1、读取开关配置
        if (!isSelfPreservationModeEnabled()) {
            // 3、服务自保开关已被关闭，所以返回true，代表允许服务剔除，而不再判断自保条件
            return true;
        }
        // 4、如果服务自保开关已开启，则还需要判断自保条件，实例数量大于0，且上一分钟最少续约数 > 每分钟最少收到租约阈值（=实例数 * （60/续租周期）* 0.85）
        return numberOfRenewsPerMinThreshold > 0 && getNumOfRenewsInLastMin() > numberOfRenewsPerMinThreshold;
    }
    
    @Override
    public boolean isSelfPreservationModeEnabled() {
        // 2、eureka.server.enableSelfPreservation，默认为true，代表开启服务自保
        return serverConfig.shouldEnableSelfPreservation();
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    protected void updateRenewsPerMinThreshold() {
        // 4.1. 每分钟最少收到租约阈值=实例数 * （60/续租周期）* 0.85
        this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfClientsSendingRenews
                * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds())
                * serverConfig.getRenewalPercentThreshold());
    }
}


```

#### 服务下线原理

##### 发起请求 | Eureka Client

###### 1、Eureka Client 自动装配

```java
public class EurekaClientAutoConfiguration {
    ...
    @Configuration
	@ConditionalOnMissingRefreshScope
    protected static class EurekaClientConfiguration {
        ...
        // 1、注入EurekaClient核心类，且在销毁时调用EurekaClient#shutdown，进行服务下线
		@Bean(destroyMethod = "shutdown")
		@ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT)
		public EurekaClient eurekaClient(ApplicationInfoManager manager,
				EurekaClientConfig config) {
			return new CloudEurekaClient(manager, config, this.optionalArgs,
					this.context);
		}
    }
    ...
}


```

###### 2、服务手动下线

```java
@SpringBootApplication
@EnableDiscoveryClient
public class EurekaClientApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(EurekaClientApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
        LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(61));
        // 1、服务手动下线
        DiscoveryManager.getInstance().shutdownComponent();
    }
}

@Deprecated
public class DiscoveryManager {
    public void shutdownComponent() {
        if (discoveryClient != null) {
            try {
                // 2、服务手动下线
                discoveryClient.shutdown();
                discoveryClient = null;
            } catch (Throwable th) {
                logger.error("Error in shutting down client", th);
            }
        }
    }
}

@Singleton
public class DiscoveryClient implements EurekaClient {
    @PreDestroy
    @Override
    public synchronized void shutdown() {
        if (isShutdown.compareAndSet(false, true)) {
            logger.info("Shutting down DiscoveryClient ...");

            // 3、取消监听服务状态变更事件
            if (statusChangeListener != null && applicationInfoManager != null) {
applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId());
            }

            // 4、销毁instanceInfoReplicator（本地刷新）、heartbeatExecutor（服务续约）、cacheRefreshExecutor（服务发现）、scheduler（DiscoveryClient定时器）
            cancelScheduledTasks();

            if (applicationInfoManager != null
                    && clientConfig.shouldRegisterWithEureka()
                    && clientConfig.shouldUnregisterOnShutdown()) {
                // 5、标记服务状态为DOWN
                applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN);
                
                // 6、发起取消注册请求
                unregister();
            }

            // 7、销毁各种Client
            if (eurekaTransport != null) {
                eurekaTransport.shutdown();
            }

            // 8、销毁心跳失效、服务租约失效监视器
            heartbeatStalenessMonitor.shutdown();
            registryStalenessMonitor.shutdown();

            logger.info("Completed shut down of DiscoveryClient");
        }
    }
}


```

###### 3、发起取消注册请求

```java
@Singleton
public class DiscoveryClient implements EurekaClient {
    void unregister() {
        ...
        // 1、发起取消注册请求
        EurekaHttpResponse<Void> httpResponse = eurekaTransport.registrationClient.cancel(instanceInfo.getAppName(), instanceInfo.getId());
        ...
    }
}

public abstract class AbstractJerseyEurekaHttpClient implements EurekaHttpClient {
// 2、最后实际调用AbstractJerseyEurekaHttpClient#cancel方法，中间经历的代理跟注册的类似：
// 1) 多态调用SessionedEurekaHttpClient#execute
// 2) 多态调用RetryableEurekaHttpClient#execute
// 3) 多态调用RedirectingEurekaHttpClient#execute
// 4) 多态调用MetricsCollectingEurekaHttpClient#execute
    @Override
    public EurekaHttpResponse<Void> cancel(String appName, String id) {
        // 3、urlPath=apps/service-name/host:service-name:port
        String urlPath = "apps/" + appName + '/' + id;
        ...
        try {
            ...
            // 4、真正发起取消注册的请求
            response = resourceBuilder.delete(ClientResponse.class);
            ...
        } finally {
            ...
        }
    }
}


```

##### 响应请求 | Eureka Server

###### 1、取消注册接口

```java
@Produces({"application/xml", "application/json"})
public class InstanceResource {
    @DELETE
    public Response cancelLease(
            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {
        try {
            // 1、取消服务注册
            boolean isSuccess = registry.cancel(app.getName(), id,
                "true".equals(isReplication));

            // 2、取消成功，则返回200，客户端打印状态
            if (isSuccess) {
                logger.debug("Found (Cancel): {} - {}", app.getName(), id);
                return Response.ok().build();
            } 
            // 3、取消失败，则返回404，客户端打印状态
            else {
                logger.info("Not Found (Cancel): {} - {}", app.getName(), id);
                return Response.status(Status.NOT_FOUND).build();
            }
        } 
        // 4、发生异常，则返回500，客户端打印状态
        catch (Throwable e) {
            logger.error("Error (cancel): {} - {}", app.getName(), id, e);
            return Response.serverError().build();
        }
    }
}


```

###### 2、取消服务注册

```java
public class InstanceRegistry extends PeerAwareInstanceRegistryImpl
implements ApplicationContextAware {
	@Override
	public boolean cancel(String appName, String serverId, boolean isReplication) {
		// 1、打印日志、发布服务实例取消事件
		handleCancelation(appName, serverId, isReplication);
		// 2、调用父类方法，取消服务注册
		return super.cancel(appName, serverId, isReplication);
	}

	@Override
	protected boolean internalCancel(String appName, String id, boolean isReplication) {
		// 5、打印日志，发布服务租约取消事件
		handleCancelation(appName, id, isReplication);
		// 6、调用父类方法，取消服务租约（与服务剔除调用的是同一个方法）
		return super.internalCancel(appName, id, isReplication);
	}
}

@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean cancel(final String appName, final String id,
                          final boolean isReplication) {
        // 3、调用父类方法，取消服务注册
        if (super.cancel(appName, id, isReplication)) {
        	// 9、租约取消成功，则将所有eureka操作，复制到对等的其他eureka节点
            replicateToPeers(Action.Cancel, appName, id, null, null, isReplication);
            // 10、减少每分钟最少续租的阈值
            synchronized (lock) {
                if (this.expectedNumberOfClientsSendingRenews > 0) {
                    this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews - 1;
                    updateRenewsPerMinThreshold();
                }
            }
            // 11、返回true，代表取消注册成功
            return true;
        }
        // 12、返回false，代表取消注册失败
        return false;
    }
}

public abstract class AbstractInstanceRegistry implements InstanceRegistry {
    @Override
    public boolean cancel(String appName, String id, boolean isReplication) {
    	// 4、调用子类实现，取消服务租约
        return internalCancel(appName, id, isReplication);
    }
    
    // 取消服务租约，与服务剔除调用的是同一个方法
    protected boolean internalCancel(String appName, String id, boolean isReplication) {
    	...
    	// 7、删除对应的服务列表
		leaseToCancel = gMap.remove(id);
		// 8、清空对应服务列表的读写缓存，在下次只读缓存与读写缓存同步时，会触发一次读写缓存的加载，由于该服务已从服务列表删除，所以只读缓存也会清空该服务列表，不过有一定的延迟（默认30s同步一次）
		invalidateCache(appName, vip, svip);
		...
    }
}


```

#### 集群同步原理 | Eureka Server

##### 1、服务注册后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public void register(final InstanceInfo info, final boolean isReplication) {
        ...
        // 1、服务注册完毕
        super.register(info, leaseDuration, isReplication);
        // 2、集群服务实例同步
        replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);
    }
}


```

##### 2、服务续约后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    public boolean renew(final String appName, final String id, final boolean isReplication) {
        // 1、服务续约
        if (super.renew(appName, id, isReplication)) {
            // 2、如果服务续约成功，则进行集群服务实例同步
            replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);
            return true;
        }
        return false;
    }
}


```

##### 3、服务取消后同步

```java
@Singleton
public class PeerAwareInstanceRegistryImpl extends AbstractInstanceRegistry implements PeerAwareInstanceRegistry {
    @Override
    public boolean cancel(final String appName, final String id,
                          final boolean isReplication) {
        // 1、取消服务注册
        if (super.cancel(appName, id, isReplication)) {
            // 2、如果取消成功，则进行集群服务实例同步
            replicateToPeers(Action.Cancel, appName, id, null, null, isReplication);
            ...
            return true;
        }
        return false;
    }
}


```

##### 4、集群同步请求处理 & 发送

```java
// 1、将所有当前Eureka操作，复制到对等的其他Eureka节点
private void replicateToPeers(Action action, String appName, String id,
                              InstanceInfo info /* optional */,
                              InstanceStatus newStatus /* optional */, boolean isReplication) {
    Stopwatch tracer = action.getTimer().start();
    try {
        // 2、期望副本数量加1
        if (isReplication) {
            numberOfReplicationsLastMin.increment();
        }
        // 3、如果该请求已经是一个集群同步请求，则直接返回即可，代表不再发起集群同步请求
        if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) {
            return;
        }
        // 4、否则需要发起集群同步请求
        for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) {
            // 5、如果url代表此主机，则直接跳过，不能发送同步请求到当前副本自己
            if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) {
                continue;
            }
            // 6、将所有实例的更改操作，复制到对等的其他Eureka节点
            replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);
        }
    } finally {
        tracer.stop();
    }
}

// 将所有实例的更改操作，复制到对等的其他Eureka节点
private void replicateInstanceActionsToPeers(Action action, String appName,
String id, InstanceInfo info, InstanceStatus newStatus,PeerEurekaNode node) {
    try {
        InstanceInfo infoFromRegistry = null;
        CurrentRequestVersion.set(Version.V2);
        switch (action) {
            case Cancel:
                // 7、如果为服务取消后同步，则调用最终调用AbstractJerseyEurekaHttpClient#cancel发送取消注册请求（同步客户端请求类似，但isReplication=true）
                node.cancel(appName, id);
                break;
            case Heartbeat:
                 // 8、如果为服务续约后同步，则调用最终调用AbstractJerseyEurekaHttpClient#sendHeartBeat发送服务续约请求（同步客户端请求类似，但isReplication=true）
                InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id);
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false);
                break;
            case Register:
                // 9、如果为服务注册后同步，则调用最终调用AbstractJerseyEurekaHttpClient#register发送服务注册请求（同步客户端请求类似，但isReplication=true）
                node.register(info);
                break;
            case StatusUpdate:
                // 10、手工接口调用操作，略
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.statusUpdate(appName, id, newStatus, infoFromRegistry);
                break;
            case DeleteStatusOverride:
                // 11、手工接口调用操作，略
                infoFromRegistry = getInstanceByAppAndId(appName, id, false);
                node.deleteStatusOverride(appName, id, infoFromRegistry);
                break;
        }
    } catch (Throwable t) {
        logger.error(...);
    }
}


```

### 1.8. 详细介绍 Ribbon？

#### 背景

![1639058178382](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639058178382.png)

1. **负载均衡**，在系统架构中是非常重要的一个不得不做的事情，因为这是系统高可用、网络压力缓解和处理能力扩容的重要手段之一，比如有了负载均衡后，系统最大容量就可以近似于**单机容量 * 集群机器数**了。

2. 负载均衡，按**实现手段**分，可以分为硬件负载均衡和软件负载均衡：

   - **硬件负载均衡**：通过在服务器节点间，安装专门的设备来实现负载均衡。
   - **软件负载均衡**：只需要安装一些模块或者软件，即可完成请求分发等负载均衡工作，

3. 负载均衡，按**实现位置**分，可以分为客户端负载均衡和服务端负载均衡：但大型应用通常是客户端+服务端负载均衡搭配使用的。

   - **客户端负载均衡**：所有客户端节点，都维护着自己要访问的服务列表清单（来自注册中心），并且通过定时或者订阅等方式，维护服务列表清单的健康性。

     ![1639192959329](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639192959329.png)

   - **服务端负载均衡**：需要一个中间节点来实现请求的转发，比如 Nginx，此时需要考虑该节点的高可用。

     ![1639193020487](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639193020487.png)

| 负载均衡 | 原理                                                         |
| -------- | ------------------------------------------------------------ |
| Ribbon   | 客户端负载均衡，从注册中心定时读取服务列表，根据策略挑选出目标服务器进行访问 |
| Dubbo    | 客户端负载均衡，拉取 + 订阅 ZK 上的服务列表，根据策略挑选出目标服务器进行访问 |
| Nginx    | 反向代理实现，通过拦截客户端请求，根据策略和 upstream 配置进行转发 |

#### 概念

Ribbon，前身 Netflix Ribbon，通过封装后，成为 Spring Cloud 中一个基于 HTTP 实现的客户端均衡组件，主要功能是提供**客户端的负载均衡算法**，简单来说，就是 Ribbon 基于某种规则（如简单轮询，随即连接等），自动让服务去连接这些机器。

| Ribbon 组件接口   | 默认实现                       | 作用                                                         |
| ----------------- | ------------------------------ | ------------------------------------------------------------ |
| ILoadBalancer     | ZoneAwareLoadBalancer          | 负载均衡器，定义了一系列的操作接口，比如选择服务实例         |
| IRule             | ZoneAvoidanceRule              | 负载均衡策略，内置了很多算法，用于为服务实例的选择提供策略   |
| ServerList        | ConfigurationBasedServerList   | Ribbon 服务列表，负责服务实例的获取和存储，可以从配置文件中读取，也可以从注册中心获取 |
| ServerListFilter  | ZonePreferenceServerListFilter | Ribbon 服务列表过滤器，过滤指定的或者动态获得的服务实例      |
| ServerListUpdater | PollingServerListUpdater       | Ribbon 服务列表更新器，负责更新 Ribbon 缓存的服务实例        |
| IPing             | DummyPing                      | 服务实例检查器，负责检查服务实例是否存活                     |
| IClientConfig     | DefaultClientConfigImpl        | Ribbon 客户端配置类，用于初始化 Ribbon 客户端和 LoadBalancer |

#### 架构原理

![1639281718549](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639281718549.png)



1. Ribbon 本质上使用 BaseLoadBalancer 存储 ServerList，IPing 机制进行服务实例的健康检查，ServrListFilter 进行服务实例过滤，ServrListUpdater 进行服务列表的更新。
2. 在客户端使用 ILoadBalancer 发起服务调用时，会根据 IRule 负载均衡策略，到 BaseLoadBalancer#ServerList 进行服务实例的筛选， 然后才发起对应的服务调用，从而实现负载均衡。

#### 使用方式

##### POM 依赖

```xml
<!-- spring-cloud-starter-netflix-eureka-client默认自带Ribbon依赖 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>
</dependency>


```

##### 负载均衡调用方式

###### 直接使用 LoadBalancerClient

```java
@RestController
@Slf4j
public class ConsumerController {
    @Autowired
    private LoadBalancerClient loadBalancerClient;
    
    @PostMapping("/hello")
    public Friend helloPost(){
        // 1、使用LoadBalancerClient，根据服务名获取服务实例信息
        ServiceInstance instance = loadBalancerClient.choose("eureka-client");
        if(instance == null){
            return null;
        }

        // 2、获取服务地址进行参数组装
        String targetUrl = String.format("http://%s:%s/sayHi", instance.getHost(), instance.getPort());
        log.info("url is {}", targetUrl);

        Friend friendParam = new Friend();
        friendParam.setName("Eureka Consumer");

        // 3、最后使用原生RestTemplate进行服务调用
        return restTemplate.postForObject(targetUrl, friendParam, Friend.class);
    }
}


```

###### RestTemplate + @LoadBalanced

```java
// 1、RestTemplate配置类
@Configuration
public class RestTemplateConfig {
	// 2、配置@LoadBalanced注解
    @Bean("restTemplate")
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}

@RestController
public class RibbonConsumerController {
    // 3、注入配置好的RestTemplate
    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/sayHi")
    public String sayHi() {
        // 4、使用配置了@LoadBalanced注解的RestTemplate，直接发起服务调用，Ribbon底层会choose对应的服务实例进行调用
        return restTemplate.getForObject("http://eureka-client/sayHi", String.class);
    }
}


```

###### Feign + Ribbon

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启Feign
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

// 2、配置Feign要调用的服务
@FeignClient("eureka-client")
public interface IService {
	// 3、远程调用eureka-client服务提供者的方法
    @GetMapping("/sayHi")
    String sayHi();
}

@RestController
public class FeignConsumerController {
    // 4、注入对应的Fegin动态代理类
    @Resource
    private IService iService;

    @GetMapping("/sayHi")
    public String sayHi(){
        // 5、发起Feign代理请求，默认集成Ribbon来实现负载均衡
        return iService.sayHi();
    }
}


```

##### 负载均衡策略配置

###### 配置文件配置

```properties
# 配置文件配置，指定Ribbon某个服务的负载均衡策略(先加载, 优先级低)(=> xml->yml->yaml>properties)
eureka-client.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RoundRobinRule


```

###### Java Bean 注入

```java
// Ribbon配置类
@Configuration
public class RibbonConfiguration {
    // 1、指定Ribbon全局的负载均衡策略
    @Bean("defaultLBStrategy")
    public IRule defaultLBStrategy(){
        // 2. RandomRule: 随机访问服务结点
        return new RandomRule();
    }
}


```

###### @RibbonClient 注解配置

```java
@Configuration
// 注解方式配置，指定Ribbon某个服务的负载均衡策略(后加载, 优先级高)
@RibbonClient(name = "eureka-client", configuration = RandomRule.class)
public class RibbonConfiguration {

}


```

#### 负载均衡调用原理

##### LoadBalancerClient 原理

见《详细介绍 Eureka - 服务调用原理》

##### RestTemplate + @LoadBalanced 原理

###### 1、@LoadBalanced 注解打标

```java
@Target({ ElementType.FIELD, ElementType.PARAMETER, ElementType.METHOD })
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
// 0、@LoadBalanced继承于@Qualifier
@Qualifier
public @interface LoadBalanced {

}

// 1、（非源码）RestTemplate配置类
@Configuration
public class RestTemplateConfig {
	// 2、配置@LoadBalanced注解，表示打标一个Bean，并且打标的Bean名称等于@Bean配置的restTemplate
    @Bean("restTemplate")
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}


```

###### 2、Spring SPI 配置

```properties
# ./spring-cloud-commons/2.1.1.RELEASE/spring-cloud-commons-2.1.1.RELEASE.jar!/META-INF/spring.factories
# AutoConfiguration
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
# ...
org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration,\
# ...


```

###### 3、LoadBalancer  自动装配

```java
@Configuration
@ConditionalOnClass(RestTemplate.class)
@ConditionalOnBean(LoadBalancerClient.class)
@EnableConfigurationProperties(LoadBalancerRetryProperties.class)
public class LoadBalancerAutoConfiguration {
    
	@Configuration
	@ConditionalOnMissingClass("org.springframework.retry.support.RetryTemplate")
    static class LoadBalancerInterceptorConfig {
        // 1、注入LoadBalancerInterceptor，依赖之前RibbonAutoConfiguration注入的LoadBalancerClient和LoadBalancerRequestFactory
		@Bean
		public LoadBalancerInterceptor ribbonInterceptor(
				LoadBalancerClient loadBalancerClient,
				LoadBalancerRequestFactory requestFactory) {
			return new LoadBalancerInterceptor(loadBalancerClient, requestFactory);
		}
        
        // 2、注入RestTemplateCustomizer，依赖上面注入的LoadBalancerInterceptor
		@Bean
		@ConditionalOnMissingBean
		public RestTemplateCustomizer restTemplateCustomizer(
				final LoadBalancerInterceptor loadBalancerInterceptor) {
			return restTemplate -> {
				List<ClientHttpRequestInterceptor> list = new ArrayList<>(
						restTemplate.getInterceptors());
				list.add(loadBalancerInterceptor);
				restTemplate.setInterceptors(list);
			};
		}
    }
    
    // 3、注入List<RestTemplate>，依赖上面@LoadBalanced注解打标的RestTemplate
	@LoadBalanced
	@Autowired(required = false)
	private List<RestTemplate> restTemplates = Collections.emptyList();
    
	@Bean
	public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated(
			final ObjectProvider<List<RestTemplateCustomizer>> restTemplateCustomizers) {
		return () -> restTemplateCustomizers.ifAvailable(customizers -> {
			for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) {
				for (RestTemplateCustomizer customizer : customizers) {
                    // 4、使用上面注入的LoadBalancerInterceptor，装饰RestTemplate
					customizer.customize(restTemplate);
				}
			}
		});
	}
    ...
}


```

###### 4、RestTemplate 发起服务调用

```java
@RestController
public class RibbonConsumerController {
    @Autowired
    private RestTemplate restTemplate;

    @GetMapping("/sayHi")
    public String sayHi() {
        // 1、（非源码）使用被LoadBalancerInterceptor装饰过的RestTemplate，发起服务调用
        return restTemplate.getForObject("http://eureka-client/sayHi", String.class);
    }
}


```

###### 5、LoadBalancerInterceptor 拦截调用请求

```java
public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor {
	@Override
	public ClientHttpResponse intercept(final HttpRequest request, final byte[] body,
			final ClientHttpRequestExecution execution) throws IOException {
		...
        // 1、使用注入的LoadBalancerClient执行服务调用
		return this.loadBalancer.execute(serviceName,
				this.requestFactory.createRequest(request, body, execution));
	}
}

public class RibbonLoadBalancerClient implements LoadBalancerClient {
	@Override
	public <T> T execute(String serviceId, LoadBalancerRequest<T> request)
			throws IOException {
        // 2、使用注入的LoadBalancerClient执行服务调用
		return execute(serviceId, request, null);
	}
    
	public <T> T execute(String serviceId, LoadBalancerRequest<T> request, Object hint) throws IOException {
        // 3、同Eureka章节服务调用中的，RibbonLoadBalancerClient#getLoadBalancer => 使用SpringClientFactory负载均衡客户端的上下文工厂，构造一个负载均衡器Bean实例
		ILoadBalancer loadBalancer = getLoadBalancer(serviceId);
        
        // 4、同Eureka章节服务调用中的，RibbonLoadBalancerClient#getServer => 根据服务名选择一个具体的服务实例
		Server server = getServer(loadBalancer, hint);
		if (server == null) {
			throw new IllegalStateException("No instances available for " + serviceId);
		}
        
        // 5、构造RibbonServer
		RibbonServer ribbonServer = new RibbonServer(serviceId, server,
				isSecure(server, serviceId),
				serverIntrospector(serviceId).getMetadata(server));

        // 6、执行远程调用
		return execute(serviceId, ribbonServer, request);
	}
    
	@Override
	public <T> T execute(String serviceId, ServiceInstance serviceInstance,
			LoadBalancerRequest<T> request) throws IOException {
		...
        // 7. 底层依赖于org.springframework.http.client.AsyncClientHttpRequestExecution#executeAsync方法，执行异步远程调用
        T returnVal = request.apply(serviceInstance);
        statsRecorder.recordStats(returnVal);
        return returnVal;
		...
	}
}


```

##### Feign + Ribbon 原理

写到 Feign 时再回来补充。

#### 负载均衡策略原理

##### 负载均衡策略

| 负载均衡策略              | 作用                                                         | 特点                                                         |
| ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| RandomRule                | 随机选择 Server                                              | 随机策略，使用**自旋重试**方式获取，直到服务器列表为空，或者找到有效服务实例为止 |
| RoundRobinRule            | 按顺序选择 Server                                            | 轮训策略，Ribbon 默认负载均衡策略，**CAS 索引计数器 + 自旋重试**，最多重试 10 次 |
| RetryRule                 | 在一个配置的时间段内（默认为 500ms），如果 Server 选择不成功，则会一直重新尝试选择，直到时间结束或者选到为止 | 重试策略，默认使用装饰类 RoundRobinRule 进行负载均衡，接口实现要注意**幂等性** |
| WeightedResponseTimeRule  | 根据 Server 的响应时间分配权重，响应时间越长，权重越低，则被选中的概率就越低；相反，响应时间越短，权重越高，则被选中的高绿就越高 | 最小响应时间策略，适用于**耗时主要在接口**上的重量级接口（RT 敏感模型） |
| BestAvailableRule         | 逐个检查 Server，如果 Server 的断路器已打开（当前发生熔断），则忽略该 Server，即只会从断路器关闭中进行选取，然后再选择并发连接最低的 Server | 最低并发策略，适用于耗时主要在网络上的短响应时间接口（连接数敏感模型） |
| AvailabilityFilteringRule | 过滤掉断路器已打开（当前发生熔断），或者当前并发数超过阈值的 Server | 可用性过滤策略                                               |
| ZoneAvoidanceRule         | 剔除不可用区域中的所有 Server，和区域中的不可用 Server（默认区域为1），在过滤后的服务列表中轮训选择 Server | 区域可用性过滤策略                                           |

##### 策略实现原理

###### RandomRule | 随机

```java
public class RandomRule extends AbstractLoadBalancerRule {
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            return null;
        }
        Server server = null;

        // 1、开始自旋
        while (server == null) {
            if (Thread.interrupted()) {
                return null;
            }
            List<Server> upList = lb.getReachableServers();
            List<Server> allList = lb.getAllServers();

            int serverCount = allList.size();
            if (serverCount == 0) {
                // 2、一台 Server 都没，则返回 null
                return null;
            }

            // 3、ThreadLocalRandom.current().nextInt(serverCount); => 从所有ServerCount中，返回一个索引
            int index = chooseRandomInt(serverCount);
            // 4、从在线的upList中，选择对应索引的Server（可能会越界！）
            server = upList.get(index);

            // 5、当前线程让步，继续自旋，直到服务器列表为空，或者找到为止
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 6、如果Server存活（通过ServerListUpdater.UpdateAction#doUpdate通过Eureka Client 定时更新），则返回该Server
            if (server.isAlive()) {
                return (server);
            }

            // 7、当前线程让步，继续自旋，直到服务器列表为空，或者找到为止
            server = null;
            Thread.yield();
        }

        return server;
    }
}


```

###### RoundRobinRule | 轮训

```java
public class RoundRobinRule extends AbstractLoadBalancerRule {
    
    private AtomicInteger nextServerCyclicCounter;
    
    public RoundRobinRule() {
        // 1、初始化索引计数器 => 如果某一时刻，大片服务器同时重启，则可能会有大量请求负载到第0个服务实例，但由于每台机器最终启动完成的时间与接收的请求数量并不相同，所以也不会给负载的服务实例造成太大压力
        nextServerCyclicCounter = new AtomicInteger(0);
    }
    
    // 4、int next = (current + 1) % modulo 取模，得到目标索引
    private int incrementAndGetModulo(int modulo) {
        for (;;) {
            int current = nextServerCyclicCounter.get();
            int next = (current + 1) % modulo;
            if (nextServerCyclicCounter.compareAndSet(current, next))
                return next;
        }
    }
    
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            log.warn("no load balancer");
            return null;
        }

        Server server = null;
        int count = 0;
        
        // 2、最多重试10次
        while (server == null && count++ < 10) {
            List<Server> reachableServers = lb.getReachableServers();
            List<Server> allServers = lb.getAllServers();
            int upCount = reachableServers.size();
            int serverCount = allServers.size();

            if ((upCount == 0) || (serverCount == 0)) {
                log.warn("No up servers available from load balancer: " + lb);
                return null;
            }

            // 3、int next = (current + 1) % modulo 取模，得到目标索引
            int nextServerIndex = incrementAndGetModulo(serverCount);
            server = allServers.get(nextServerIndex);

            // 4、服务实例为空，则线程让步，继续自旋
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 5、服务实例可用，则返回即可
            if (server.isAlive() && (server.isReadyToServe())) {
                return (server);
            }

            // 6、继续自旋
            server = null;
        }

        // 7、最多重试10次
        if (count >= 10) {
            log.warn("No available alive servers after 10 tries from load balancer: "
                    + lb);
        }
        return server;
    }
    ...
}


```

###### RetryRule | 重试

```java
public class RetryRule extends AbstractLoadBalancerRule {
    
    long maxRetryMillis = 500;
    IRule subRule = new RoundRobinRule();
    
    ....
    
   	public Server choose(ILoadBalancer lb, Object key) {
		long requestTime = System.currentTimeMillis();
		long deadline = requestTime + maxRetryMillis;

		Server answer = null;

        // 1、默认使用装饰类RoundRobinRule，进行负载均衡
		answer = subRule.choose(key);

        // 2、如果装饰类获取不到有效服务实例，且当前时间小于最大重试时间，则继续使用装饰类重试
		if (((answer == null) || (!answer.isAlive()))
				&& (System.currentTimeMillis() < deadline)) {

            // 3、根据最大重试时间开启定时任务，到点则中断当前线程
			InterruptTask task = new InterruptTask(deadline
					- System.currentTimeMillis());

            // 4、开始自旋
			while (!Thread.interrupted()) {
                // 5、继续使用装饰类重试
				answer = subRule.choose(key);

                // 6、如果还是获取不到有效服务实例，且没超出最大重试时间，则线程让步，继续自旋
				if (((answer == null) || (!answer.isAlive()))
						&& (System.currentTimeMillis() < deadline)) {
					Thread.yield();
				} 
                // 7、否则结束自旋
                else {
					break;
				}
			}

            // 8、取消定时任务
			task.cancel();
		}

        // 9、返回目标服务实例，如果无效则返回null
		if ((answer == null) || (!answer.isAlive())) {
			return null;
		} else {
			return answer;
		}
	}
	...
}


```

###### WeightedResponseTimeRule | 最小响应时间

```java
public class WeightedResponseTimeRule extends RoundRobinRule {
    
    public static final int DEFAULT_TIMER_INTERVAL = 30 * 1000;
    private int serverWeightTaskTimerInterval = DEFAULT_TIMER_INTERVAL;
    
    private volatile List<Double> accumulatedWeights = new ArrayList<Double>();
    protected Timer serverWeightTimer = null;
    protected AtomicBoolean serverWeightAssignmentInProgress = new AtomicBoolean(false);

    @Override
    public void setLoadBalancer(ILoadBalancer lb) {
        ...
        // 1、设置抽象父类的LoadBalancer后，初始化权重
        initialize(lb);
    }
    
    void initialize(ILoadBalancer lb) {
        ...
        // 2、不延迟执行，默认定期30s执行一次DynamicServerWeightTask，来初始化权重
        serverWeightTimer.schedule(new DynamicServerWeightTask(), 0,
                serverWeightTaskTimerInterval);
        
        // 3、立即调用一次，来初始化权重
        ServerWeight sw = new ServerWeight();
        sw.maintainWeights();
    }
    
    class DynamicServerWeightTask extends TimerTask {
        public void run() {
            ServerWeight serverWeight = new ServerWeight();
            try {
                // 4、初始化权重
                serverWeight.maintainWeights();
            } catch (Exception e) {
                logger.error("Error running DynamicServerWeightTask for {}", name, e);
            }
        }
    }
    
    
    class ServerWeight {
        // 初始化权重
        public void maintainWeights() {
            ...
            
            // 5、CAS设置服务权重更新中的标记为true，代表更新中
            if (!serverWeightAssignmentInProgress.compareAndSet(false,  true))  {
                return; 
            }
            
            try {
                ...
                
                // 找到最大 95% 的响应时间
                // 6、遍历全部Server，累加平均响应时间（在RibbonLoadBalancerClient#execute方法中，执行完远程调用后，会调用一次statsRecorder.recordStats来记录统计信息）
                double totalResponseTime = 0;
                for (Server server : nlb.getAllServers()) {
                    ServerStats ss = stats.getSingleServerStat(server);
                    totalResponseTime += ss.getResponseTimeAvg();
                }

                // 7、使用总的平均响应时间 - 每个服务实例的平均响应时间，可以得到响应时间的权重 => 响应时间越长，服务实例越靠前，权重越小；响应时间越短，服务实例越靠后，权重越大
                Double weightSoFar = 0.0;
                List<Double> finalWeights = new ArrayList<Double>();
                for (Server server : nlb.getAllServers()) {
                    ServerStats ss = stats.getSingleServerStat(server);
                    double weight = totalResponseTime - ss.getResponseTimeAvg();
                    weightSoFar += weight;
                    finalWeights.add(weightSoFar);   
                }
                // 8、设置服务权重列表
                setWeights(finalWeights);
            } catch (Exception e) {
                logger.error(...);
            } finally 
                // 10、最后CAS设置服务权重更新中的标记为false，代表更新完毕
                serverWeightAssignmentInProgress.set(false);
            }

        }
    }
    
    // 9、设置服务权重列表
    void setWeights(List<Double> weights) {
        this.accumulatedWeights = weights;
    }

    @Override
    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            return null;
        }
        Server server = null;

        while (server == null) {
            // 11、获取当前时刻的服务权重列表（有可能下一刻就会被其他列表更新替换掉）
            List<Double> currentWeights = accumulatedWeights;
            if (Thread.interrupted()) {
                return null;
            }
            
            List<Server> allList = lb.getAllServers();
            int serverCount = allList.size();
            if (serverCount == 0) {
                return null;
            }
			int serverIndex = 0;
            
            // 12、列表中的最后一个，代表最大的服务权重
            double maxTotalWeight = currentWeights.size() == 0 ? 0 : currentWeights.get(currentWeights.size() - 1); 
            
            // 13、如果最大权重小于0.001，或者权重列表个数不等于服务列表个数，说明权重无效，则回退到父类RoundRobinRule规则，来获取服务实例
            if (maxTotalWeight < 0.001d || serverCount != currentWeights.size()) {
                // 14、以父类RoundRobinRule规则获取服务实例
                server =  super.choose(getLoadBalancer(), key);
                if(server == null) {
                    return server;
                }
            } 
            // 15、如果最大权重不小于0.001，且权重列表个数等于服务列表个数，说明权重有效，则进行权重筛选
            else {
                // 16、生成 [0，maxTotalWeight）之间的随机权重
                double randomWeight = random.nextDouble() * maxTotalWeight;
                
                // 17、获取权重列表中，第一个大于等于随机权重的服务实例，代表目标服务实例
                int n = 0;
                for (Double d : currentWeights) {
                    if (d >= randomWeight) {
                        serverIndex = n;
                        break;
                    } else {
                        n++;
                    }
                }

                server = allList.get(serverIndex);
            }

            // 18、如果实例为空，则线程让步，继续自旋
            if (server == null) {
                Thread.yield();
                continue;
            }

            // 19、如果实例存活，则返回即可
            if (server.isAlive()) {
                return (server);
            }

            server = null;
        }
        return server;
    }
}


```

###### BestAvailableRule | 最低并发

```java
public class BestAvailableRule extends ClientConfigEnabledRoundRobinRule {
    @Override
    public Server choose(Object key) {
        // 1、如果没有服务统计信息，则使用父类默认的RoundRobinRule规则，进行服务实例选取
        if (loadBalancerStats == null) {
            return super.choose(key);
        }
        
        // 2、如果有服务统计信息，则获取当前系统时间
        List<Server> serverList = getLoadBalancer().getAllServers();
        int minimalConcurrentConnections = Integer.MAX_VALUE;
        long currentTime = System.currentTimeMillis();
        Server chosen = null;
        
        // 3、遍历所有服务列表
        for (Server server: serverList) {
            ServerStats serverStats = loadBalancerStats.getSingleServerStat(server);
            // 4、根据当前系统时间，判断服务实例的断路器是否已经打开
            if (!serverStats.isCircuitBreakerTripped(currentTime)) {
                // 8、如果该服务实例断路器没有被打开，则获取他当前系统时间的并发请求数量
                int concurrentConnections = serverStats.getActiveRequestsCount(currentTime);
                // 9、比较获取最小并发请求数量的服务实例，作为目标服务实例
                if (concurrentConnections < minimalConcurrentConnections) {
                    minimalConcurrentConnections = concurrentConnections;
                    chosen = server;
                }
            }
        }
        // 10、如果目标服务实例无效，则使用父类默认的RoundRobinRule规则，进行服务实例选取
        if (chosen == null) {
            return super.choose(key);
        } 
        // 11、如果目标服务实例有效，则返回即可
        else {
            return chosen;
        }
    }
}

public class ServerStats {
    // 5、根据当前系统时间，判断服务实例的断路器是否已经打开
    public boolean isCircuitBreakerTripped(long currentTime) {
        // 6、获取当前服务断路器的超时时间
        long circuitBreakerTimeout = getCircuitBreakerTimeout();
        
        // 7、如果该超时时间无效，或者已经小于了当前系统时间，则认为断路器已关闭，服务实例有效
        if (circuitBreakerTimeout <= 0) {
            return false;
        }
        return circuitBreakerTimeout > currentTime;
    }
    
    private long getCircuitBreakerTimeout() {
        // 6.1、 获取断路器持续周期
        long blackOutPeriod = getCircuitBreakerBlackoutPeriod();
        if (blackOutPeriod <= 0) {
            return 0;
        }
        // 6.6、断路器持续周期 + 最后连接失败的时间 = 断路器超时时间
        return lastConnectionFailedTimestamp + blackOutPeriod;
    }
    
    private long getCircuitBreakerBlackoutPeriod() {
        int failureCount = successiveConnectionFailureCount.get();
        int threshold = connectionFailureThreshold.get();
        
        // 6.2、如果调用失败的数量，没有达到阈值niws.loadbalancer.service-name.connectionFailureCountThreshold（默认为3），则返回0，表示不开启断路器
        if (failureCount < threshold) {
            return 0;
        }
        
        // 6.3、否则调用失败数量 - 断路器阈值，得到差值（最大为16）
        int diff = (failureCount - threshold) > 16 ? 16 : (failureCount - threshold);
        
        // 6.4、然后计算断路器持续周期/s = 差值 * niws.loadbalancer.service-name-.circuitTripTimeoutFactorSeconds（默认为10），即默认最大为160s（2min40s）
        int blackOutSeconds = (1 << diff) * circuitTrippedTimeoutFactor.get();
        if (blackOutSeconds > maxCircuitTrippedTimeout.get()) {
            blackOutSeconds = maxCircuitTrippedTimeout.get();
        }
        
        // 6.5、最后s转换为ms，并返回
        return blackOutSeconds * 1000L;
    }
}


```

###### AvailabilityFilteringRule | 可用性过滤

```java
public class AvailabilityFilteringRule extends PredicateBasedRule {
    
    private AbstractServerPredicate predicate;
    
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        // 1、初始化可用性断言
    	predicate = CompositePredicate.withPredicate(new AvailabilityPredicate(this, clientConfig)).addFallbackPredicate(AbstractServerPredicate.alwaysTrue()).build();
    }
    
    @Override
    public Server choose(Object key) {
        int count = 0;
        // 4、调用父类默认的RoundRobinRule规则，进行服务实例的选择
        Server server = roundRobinRule.choose(key);
        // 5、最多选择再选择10次服务实例+判断可用性断言是否成立
        while (count++ <= 10) {
            // 6、判断当前服务实例是否符合可用性断言，如果是则返回即可，否则继续获取服务实例来判断
            if (predicate.apply(new PredicateKey(server))) {
                return server;
            }
            server = roundRobinRule.choose(key);
        }
        // 7、如果10次判断都没有符合断言的服务实例，则再使用RoundRobinRule来获取最后一次
        return super.choose(key);
    }
}

public class AvailabilityPredicate extends  AbstractServerPredicate {
   
    public AvailabilityPredicate(IRule rule, IClientConfig clientConfig) {
        super(rule, clientConfig);
        // 2、初始化可用性断言
        initDynamicProperty(clientConfig);
    }
    
    private void initDynamicProperty(IClientConfig clientConfig) {
        String id = "default";
        if (clientConfig != null) {
            id = clientConfig.getClientName();
            // 3、设置activeConnectionsLimit，默认为niws.loadbalancer.availabilityFilteringRule.activeConnectionsLimit=Integer.MAX_VALUE
            activeConnectionsLimit = new ChainedDynamicProperty.IntProperty(id + "." + clientConfig.getNameSpace() + ".ActiveConnectionsLimit", ACTIVE_CONNECTIONS_LIMIT); 
        }               
    }
    
    @Override
    public boolean apply(@Nullable PredicateKey input) {
        LoadBalancerStats stats = getLBStats();
        if (stats == null) {
            return true;
        }
        // 6.1、判断当前服务实例是否符合可用性断言，如果shouldSkipServer返回true，则代表需要跳过，不能作为目标服务实例；否则说明可以作为目标服务实例
        return !shouldSkipServer(stats.getSingleServerStat(input.getServer()));
    }
    
    private boolean shouldSkipServer(ServerStats stats) {
        // 6.2、先看断路器过滤是否已经打开niws.loadbalancer.availabilityFilteringRule.filterCircuitTripped（默认为true），如果判断到断路器开关已经打开，说明发生了熔断，则直接返回true；否则，如果并发数超过了activeConnectionsLimit（默认最大Integer.MAX_VALUE），也返回true => 认为不可用，需要跳过
        if ((CIRCUIT_BREAKER_FILTERING.get() && stats.isCircuitBreakerTripped()) 
                || stats.getActiveRequestsCount() >= activeConnectionsLimit.get()) {
            return true;
        }
        // 6.3、如果既不熔断，又没超过最大并发数，则返回false，代表可用，不需要跳过
        return false;
    }
}


```

###### ZoneAvoidanceRule | 区域可用性过滤

```java
public class ZoneAvoidanceRule extends PredicateBasedRule {
    
    private CompositePredicate compositePredicate;
    
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {
        // 1、初始化ZoneAvoidancePredicate断言，在区域<=1时恒为true
        ZoneAvoidancePredicate zonePredicate = new ZoneAvoidancePredicate(this, clientConfig);
        // 2、初始化可用性断言，同AvailabilityFilteringRule的可用性过滤
        AvailabilityPredicate availabilityPredicate = new AvailabilityPredicate(this, clientConfig);
        // 3、组合断言compositePredicate，链式判断zonePredicate和availabilityPredicate
        compositePredicate = createCompositePredicate(zonePredicate, availabilityPredicate);
    }
    
    // 7、获取ZoneAvoidanceRule的断言compositePredicate
    @Override
    public AbstractServerPredicate getPredicate() {
        return compositePredicate;
    }
}

public abstract class PredicateBasedRule extends ClientConfigEnabledRoundRobinRule {
 	// 4、ZoneAvoidanceRule使用父类PredicateBasedRule，进行服务实例的选择
    @Override
    public Server choose(Object key) {
        ILoadBalancer lb = getLoadBalancer();
        Optional<Server> server = 
            // 5、多态获取ZoneAvoidanceRule的断言
            getPredicate()
            // 8、从过滤后的服务列表中，获取目标服务实例
            .chooseRoundRobinAfterFiltering(lb.getAllServers(), key);
        if (server.isPresent()) {
            return server.get();
        } else {
            return null;
        }       
    }
    
    // 6、多态获取ZoneAvoidanceRule的断言
    public abstract AbstractServerPredicate getPredicate();
}

public abstract class AbstractServerPredicate implements Predicate<PredicateKey> {
    public Optional<Server> chooseRoundRobinAfterFiltering(List<Server> servers, Object loadBalancerKey) {
        // 9、根据断言，获取过滤后的服务列表
        List<Server> eligible = getEligibleServers(servers, loadBalancerKey);
        if (eligible.size() == 0) {
            return Optional.absent();
        }
        return Optional.of(eligible.get(incrementAndGetModulo(eligible.size())));
    }
    
    public List<Server> getEligibleServers(List<Server> servers, Object loadBalancerKey) {
        if (loadBalancerKey == null) {
            return ImmutableList.copyOf(Iterables.filter(servers, this.getServerOnlyPredicate()));            
        } else {
            List<Server> results = Lists.newArrayList();
            for (Server server: servers) {
                // 10、应用组合断言compositePredicate，链式判断zonePredicate（区域<=1时恒为true）和availabilityPredicate（无熔断，并发数不超阈值时为true）
                if (this.apply(new PredicateKey(loadBalancerKey, server))) {
                    results.add(server);
                }
            }
            return results;            
        }
    }
}


```

##### 自定义负载均衡算法 | 一致性 Hash

```java
// 自定义负载均衡算法，一致性Hash => 实现 IRule 接口，继承 AbstractLoadBalancerRule 抽象类
public class ConsistentHashRule extends AbstractLoadBalancerRule implements IRule {
    @Override
    public void initWithNiwsConfig(IClientConfig clientConfig) {

    }
    
    @Override
    public Server choose(Object key) {
        // 1、获取请求标识，用于计算hash，这里用了服务路径+请求参数
        HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();
        String uri = request.getServletPath() + "?" + request.getQueryString();
  		// 2、先获取全部服务实例，然后根据hash值，获取目标服务实例
        return route(uri.hashCode(), getLoadBalancer().getAllServers());
    }
    
    public Server route(int hashId, List<Server> addressList){
        if(CollectionUtils.isEmpty(addressList)){
            return null;
        }

        // 3、虚化Server结点, 假设这里每个Server拥有8个虚化结点 => 可以参考Dubbo 160个虚拟结点的hash环
        TreeMap<Long, Server> address = new TreeMap<>();
        addressList.stream().forEach(server -> {
            // 4、虚化Server结点到环上
            for(int i = 0; i < 8; i++){
                // 5、加入服务实例ID作为变数
                long hash = hash(server.getId() + i);
                address.put(hash, server);
            }
        });

        // 6、tailMap取比当前hash大的且离他最近的一个结点 => 顺时针方向: tailMap有序, 会拿到所有比他大的结点
        long hash = hash(String.valueOf(hashId));
        SortedMap<Long, Server> lastSevers = address.tailMap(hash);

        // 7、如果拿不到比他大的结点, 说明我们的hash到了末尾, 需要取最小的结点, 从而虚化成一个环
        if(lastSevers.isEmpty()){
            return address.firstEntry().getValue();
        }

        // 8、如果拿得到比他大的结点, 则取大集中的最小值
        return lastSevers.get(lastSevers.firstKey());
    }
    
    // 5.1、哈希函数
    public long hash(String key){
        MessageDigest md5 = null;
        try {
            md5 = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        }

        byte[] keyBytes = null;
        try {
            keyBytes = key.getBytes("UTF-8");
        } catch (UnsupportedEncodingException e) {
            e.printStackTrace();
        }

        // 5.2、根据Key的字节数组生成16字节(128位)的MD5摘要
        md5.update(keyBytes);
        byte[] digest = md5.digest();

        // 5.3、计算long长度的hashCode => 这里做测试, 只取低4个字节整成long型数字作为hashCode, 其中高4个字节都取0, 这里与0xFF避免字节本身为1开头时移位带来的问题
        long hashCode = (digest[3] & 0xFF) << 24    // 高16位
                      | (digest[2] & 0xFF) << 16    // 高8位
                      | (digest[1] & 0xFF) << 8     // 低16位
                      | (digest[0] & 0xFF);         // 低8位

        // 5.4、只取低8字节作为long型返回, 一个long型数字占8个字节
        return hashCode & 0xFFFFFFFFL;
    }
}


```

### 1.9. 详细介绍 Feign？

#### 概念

Feign 是声明式的服务客户端，使得调用远程方法就像调用本地接口一样方便，只需把要调用的服务方法，定义成接口，然后直接调用就行，而无需手动构建 Http 请求再发起服务调用。

| @Feign Client 属性 | 默认值     | 作用                                                         |
| ------------------ | ---------- | ------------------------------------------------------------ |
| value              | ""         | 将要调用的服务名称，是 name 属性的别名                       |
| serviceId          | ""         | 已废弃，将要调用的服务id，作用和 name 属性相同               |
| name               | ""         | 将要调用的服务名称，是 name 属性的别名                       |
| url                | ""         | 全服务路径地址，或者 hostname                                |
| decode404          | false      | 响应状态码为 404 时，是否应该抛出 FeginException             |
| configuration      | {}         | 自定义当前 Feign Client 配置                                 |
| fallback           | void.class | 降级机制（需启用 @EnableHystrix），调用失败时走的一些回退方法，可以用来抛出异常或者给出默认返回的数据 |
| fallbackFactory    | void.class | 为当前 Feign Client接口定义一个降级工厂，用于生成降级类的实例 |
| path               | ""         | 自动给所有方法的 @RequestMapping 加上前缀，类似于 Controller 类上的 @RequestMapping |
| primary            | true       | 是否将当前 Feign Client 标记为第一个注入 Bean                |

#### 架构原理

![1639579104510](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1639579104510.png)

| 组件                     | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| InvocationHandlerFactory | 代理对象生成组件，采用 JDK 的动态代理方式生成代理对象，当调用 Feign 接口时，实际上是去调用远程的 HTTP API |
| Contract                 | 协议组件，解析 @Feign 配置的参数，比如请求类型是 GET 还是 POST，请求的 URI 是什么 |
| MethodHander             | 实际处理组件，当调用 Feign 接口时，实际上是交由该类，来进行远程调用的相关处理 |
| Encoder/Decoder          | 编码/解码组件，通过它们，可以将请求信息，采用指定的方式进行编/解码后再传输/接收 |
| Logger                   | 日志组件，负责记录 Feign 中的日志。其中，可以指定 Logger 的级别以及自定义日志的输出 |
| Client                   | 请求执行组件，负责 HTTP 请求的执行。其中，Feign 默认的 Client 是通过 JDK#HttpURLConnection 发起请求的，在每次发送请求时，都会创建新的 HttpURLConnection 连接，性能很差；因此，可以通过扩展该接口，使用比如 Apache HttpClient 等，基于连接池的高性能 HTTP 客户端来进行优化 |
| Retryer                  | 重试组件，负责重试请求调用，Feign 内置了重试器，当 HTTP 请求出现 IO 异常时，Feign 会限定一个最大重试次数，来进行重试操作 |
| RequestInterceptor       | 请求拦截器组件，可以为 Feign 添加多个拦截器，在请求执行前设置一些扩展的参数信息 |

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>


```

##### 配置 Feign 接口

```java
@FeignClient(value = "feign-client")
public interface IService {
    @GetMapping("/sayHi")
    public String sayHi();
}


```

##### 使用 Feign 接口

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启FeignClient扫描
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

@RestController
public class FeignConsumerController {
    // 2、注入Feign接口代理类
    @Resource
    private IService iService;

    @GetMapping("/sayHi")
    public String sayHi(){
        // 3、发起Http调用
        return iService.sayHi();
    }
}


```

##### 超时重试配置

下面这些配置只是针对 feign-client 服务的配置，对于全局服务的配置参数名一样，不同的是没有服务名作为配置前缀，而是使用 `feign.client.config.default` 作为前缀。

```properties
# 只对服务消费者设置超时与重试策略:
# Ribbon指定服务的超时策略: 请求服务的连接超时时间: Http连接所花费的时间(ms)
feign-client.ribbon.ConnectTimeout=1000
# Ribbon指定服务的超时策略: 服务的业务处理超时时间(ms)
feign-client.ribbon.ReadTimeout=2000

# Ribbon指定服务的重试策略: 允许在所有Http Method都进行重试策略(Get/Post/Put/Delete...)
feign-client.ribbon.OkToRetryOnAllOperations=true
# Ribbon指定服务的重试策略: 每台机器最大的服务超时重试次数 => 因此, 每台机器的请求次数 = 1 + 2 = 3次
feign-client.ribbon.MaxAutoRetries=2
# Ribbon指定服务的重试策略: 服务重试超时时, 还可以再重试几台机器 => 因此, 一共可以请求机器数 = 1 + 2 = 3台, 如果只有1台机器, 那么会继续请求该台机器
feign-client.ribbon.MaxAutoRetriesNextServer=2
# 因此, 一次服务请求的最大超时次数 = (1000 + 2000) * (1 + 2) * (1 + 2) = 27000ms = 27s


```

##### 高性能客户端配置

```yml
feign:
  # 使用okhttp高性能客户端
  okhttp: true
  # 使用Apache httpclient高性能客户端
  # httpclient: true


```

##### 调用日志配置

```yaml
feign:
  client:
    config:
      # Feign全局配置
      default:
        # 记录请求和响应的标头、正文和元数据
        loggerLevel: full


```

##### 请求包压缩配置

```yaml
feign:
  compression:
    request:
      # 开启请求GZIP压缩
      enabled: true
      # 配置压缩数据⼤大⼩小的下限
      min-request-size: 2048
      # 配置支持压缩的MIME TYPE
      mime-types: text/xml,application/xml,application/json
    response:
      #开启响应GZIP压缩
      enabled: true


```

##### 拦截器扩展

```java
@Component
@Slf4j
public class FeignRequestInterceptor implements RequestInterceptor {
    @Override
    public void apply(RequestTemplate requestTemplate) {
        // 在Header设置Feign Client请求标志
        requestTemplate.header(ProjectConstant.FEIGN_CLIENT_REQUEST_FLAG, "true");
    }
}


```

##### 自定义包装类解码器

```java
// 1、自定义Feign解码器: 解决Feign Sever结果统一包装的问题
@Component
class FeignResultDecoder implements Decoder {
    @Autowired
    private ObjectMapper objectMapper;

    @Override
    public Object decode(Response response, Type type) throws IOException, DecodeException, FeignException {
        if (response.body() == null)
            throw new DecodeException(...);

        // 2、解析body, 得到Result包装类实例
        Result result = objectMapper.readValue(Util.toString(response.body().asReader(Util.UTF_8)), Result.class);
        if (ResultCode.ERROR_CODE.equals(result.getRetCode()))
            throw new DecodeException(...);

        // 3、重新解析包装类Result#data实例并返回
        return objectMapper.readValue(objectMapper.writeValueAsString(result.getData()), TypeFactory.defaultInstance().constructType(type));
    }
}


```

##### Hystrix 降级熔断配置

```java
// 1、直接配置降级熔断处理类IFallbackHandler
@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
public interface HystrixFallbackService extends IService {

}

// 2、配置降级工厂类HystrixClientFallbackFactory，用于生成降级熔断处理类
@FeignClient(value = "feign-client", fallback = HystrixClientFallbackFactory.class)
public interface HystrixFallbackService extends IService {

}

@Component
public class HystrixClientFallbackFactory implements FallbackFactory<HystrixFallbackService> {
    @Override
    public HystrixFallbackService create(Throwable cause) {
        // 2.1、手动实现一个HystrixFallbackService降级熔断处理类
        return new HystrixFallbackService(){
            ...
        }
    }
}


```

#### 动态代理原理

##### 1、开启 FeignClient 扫描

```java
@SpringBootApplication
@EnableDiscoveryClient
// 1、开启FeignClient扫描
@EnableFeignClients
public class FeignConsumerApplication {
    public static void main(String[] args) {
        new SpringApplicationBuilder(FeignConsumerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.TYPE)
@Documented
// 2、导入FeignClientsRegistrar
@Import(FeignClientsRegistrar.class)
public @interface EnableFeignClients {
    ...
}




```

##### 2、扫描 @FeignClient 注解

```java
class FeignClientsRegistrar
    implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware {
	@Override
	public void registerBeanDefinitions(AnnotationMetadata metadata,
			BeanDefinitionRegistry registry) {
        // 1、读取并注册@EnableFeignClients#defaultConfiguration配置
		registerDefaultConfiguration(metadata, registry);
        // 2、扫描并注册FeignClient
		registerFeignClients(metadata, registry);
	}
    
    public void registerFeignClients(AnnotationMetadata metadata,
                                     BeanDefinitionRegistry registry) {
        // 3、获取注解扫描器
		ClassPathScanningCandidateComponentProvider scanner = getScanner();
		scanner.setResourceLoader(this.resourceLoader);

		Set<String> basePackages;

        // 4、读取@EnableFeignClients#clients属性
		Map<String, Object> attrs = metadata
				.getAnnotationAttributes(EnableFeignClients.class.getName());
		final Class<?>[] clients = attrs == null ? null
				: (Class<?>[]) attrs.get("clients");
        
        // 5、如果@EnableFeignClients没配置clients属性，则配置@FeignClient注解扫描过滤器
        AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(
            FeignClient.class);
		if (clients == null || clients.length == 0) {
			scanner.addIncludeFilter(annotationTypeFilter);
            // 5.1、从@EnableFeignClients配置的value、basePackages、basePackageClasses，以及springbootApplication启动类包中，选出要扫描的包
			basePackages = getBasePackages(metadata);
		}
        // 6、否则，@EnableFeignClients#clients属性所在的包名加入basePackages
		else {
			...
		}

        // 7、扫描basePackages下的注解
		for (String basePackage : basePackages) {
			Set<BeanDefinition> candidateComponents = scanner
					.findCandidateComponents(basePackage);
			for (BeanDefinition candidateComponent : candidateComponents) {
				if (candidateComponent instanceof AnnotatedBeanDefinition) {
					AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;
					AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();
					Assert.isTrue(...);

                    // 8、扫描basePackages下的@FeignClient组件
					Map<String, Object> attributes = annotationMetadata
							.getAnnotationAttributes(
									FeignClient.class.getCanonicalName());

                    // 9、获取@FeignClient#contextId、value、name、serviceId属性
					String name = getClientName(attributes);
                    
                    // 10、注册@FeignClient#configuration
					registerClientConfiguration(registry, name,
							attributes.get("configuration"));

                    // 11、注册 FeignClientFactoryBean
					registerFeignClient(registry, annotationMetadata, attributes);
				}
			}
		}
    }
}


```

##### 3、注册 FeignClientFactoryBean

```java
class FeignClientsRegistrar
    implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware {
    
	private void registerFeignClient(BeanDefinitionRegistry registry,
			AnnotationMetadata annotationMetadata, Map<String, Object> attributes) {
        ...
        // 1、获取FeignClientFactoryBean#BeanDefinitionBuilder
        BeanDefinitionBuilder definition = BeanDefinitionBuilder
            .genericBeanDefinition(FeignClientFactoryBean.class);
		...
        // 2、构造FeignClientFactoryBean#BeanDefinition
		AbstractBeanDefinition beanDefinition = definition.getBeanDefinition();
        BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] { alias });
        // 3、注册FeignClientFactoryBean
		BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);
	}
}


```

##### 4、注入 FeignClient

```java
class FeignClientFactoryBean
    implements FactoryBean<Object>, InitializingBean, ApplicationContextAware {
    // 1、@Autowire在注入时调用FactoryBean#getObject
	@Override
	public Object getObject() throws Exception {
		return getTarget();
	}

    <T> T getTarget() {
        // 2、获取SPI#FeignAutoConfiguration注入的FeignContext Bean实例
        FeignContext context = this.applicationContext.getBean(FeignContext.class);
        
        // 3、根据上下文构造Feign.Builder
        Feign.Builder builder = feign(context);
        
        // 4、@FeignClient#uri属性为空
		if (!StringUtils.hasText(this.url)) {
            // 5、则追加http+@FeignClient#name
			if (!this.name.startsWith("http")) {
				this.url = "http://" + this.name;
			}
			else {
				this.url = this.name;
			}
			this.url += cleanPath();
            
            // 6、对已注入的FeignClient进行代理
			return (T) loadBalance(builder, context,
					new HardCodedTarget<>(this.type, this.name, this.url));
		}
        // 4、否则使用uri对已注入的FeignClient进行代理
    }

    protected <T> T loadBalance(Feign.Builder builder, FeignContext context,
			HardCodedTarget<T> target) {
        // 7、获取已注入的LoadBalancerFeignClient实例 => DefaultFeignLoadBalancedConfiguration自动装配注入
		Client client = getOptional(context, Client.class);
		if (client != null) {
			builder.client(client);
            // 8、获取代理生产类HystrixTargeter => SPI#FeignAutoConfiguration注入
			Targeter targeter = get(context, Targeter.class);
            // 9、获取FeignClient目标代理
			return targeter.target(this, builder, context, target);
		}

		throw new IllegalStateException(...);
	}
    
    // 根据上下文构造Feign.Builder
	protected Feign.Builder feign(FeignContext context) {
        ...
        // 3.1、获取Feign.Builder实例 => FeignClientsConfiguration自动装配注入
		Feign.Builder builder = get(context, Feign.Builder.class)
            // 3.2、配置当前类作为日志记录者logger 
            .logger(logger)
            // 3.3、配置Encoder实例SpringDecoder => FeignClientsConfiguration自动装配注入，Missing Encoder Bean 时默认注入（可扩展修改）
            .encoder(get(context, Encoder.class))
            // 3.4、配置Decoder实例SpringEncoder => FeignClientsConfiguration自动装配注入，Missing Decoder Bean 时默认注入
            .decoder(get(context, Decoder.class))
       // 3.5. 配置Contract实例SpringMvcContract，用于限定 @FeignClient 的配置规则 => FeignClientsConfiguration自动装配注入，Missing Contract Bean 时默认注入（可扩展修改）
            .contract(get(context, Contract.class));
		// 3.6 配置Feign，比如RequestInterceptor
        configureFeign(context, builder);
        // 3.7. 返回Feign Builder
		return builder;
	}
}


```

##### 5、获取 FeignClient 目标代理

```java
class HystrixTargeter implements Targeter {

	@Override
	public <T> T target(FeignClientFactoryBean factory, Feign.Builder feign,
                        FeignContext context, Target.HardCodedTarget<T> target) {
        // 1、Feign.Builder实例 => FeignClientsConfiguration自动装配注入
		if (!(feign instanceof feign.hystrix.HystrixFeign.Builder)) {
            // 2、进入Feign代理逻辑
			return feign.target(target);
		}
        ...// 1、否则进入Hystrix熔断逻辑
    }
}

public abstract class Feign {
    ...
    public static class Builder {
        public <T> T target(Target<T> target) {
            // 3、构造ReflectiveFeign实例，其中包括设置SynchronousMethodHandler.Factory
      		return build().newInstance(target);
    	}
    }
    ...
}

public class ReflectiveFeign extends Feign { 
  	@Override
    public <T> T newInstance(Target<T> target) {
        // 4、为@FeignClient接口里的方法，使用SynchronousMethodHandler.Factory构建SynchronousMethodHandler实例
        Map<String, MethodHandler> nameToHandler = targetToHandlersByName.apply(target);
        ...
        // 4、为@FeignClient接口设置JDK动态代理处理类FeignInvocationHandler
        InvocationHandler handler = factory.create(target, methodToHandler);
        // 5、创建@FeignClient接口动态代理类
        T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(),
        	new Class<?>[] {target.type()}, handler);
        ...
        return proxy;
    }
}


```

#### 服务调用原理

##### 1、FeignInvocationHandler#invoke

```java
public class ReflectiveFeign extends Feign {
    ...
    static class FeignInvocationHandler implements InvocationHandler {
        ...
        // 1、JDK动态代理
    	@Override
        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
           ...
           // 2、调用SynchronousMethodHandler#invoke
           return dispatch.get(method).invoke(args);
        }
    }
}


```

##### 2、SynchronousMethodHandler#invoke

```java
final class SynchronousMethodHandler implements MethodHandler {
    @Override
    public Object invoke(Object[] argv) throws Throwable {
        // 1、获取请求模板 => GET /sayHi HTTP/1.1 Binary data
        RequestTemplate template = buildTemplateFromArgs.create(argv);
        // 2、默认从不重试 => FeignClientsConfiguration#Retryer.NEVER_RETRY注入
        Retryer retryer = this.retryer.clone();
        // 3、开始自旋重试
        while (true) {
            try {
                // 4、执行请求和解码响应
                return executeAndDecode(template);
            } catch (RetryableException e) {
                try {
                    // 5、由于默认不重试，所以重试时会报错
                    retryer.continueOrPropagate(e);
                } catch (RetryableException th) {
                    ...
                }
                // 6、记录日志
                if (logLevel != Logger.Level.NONE) {
                    logger.logRetry(metadata.configKey(), logLevel);
                }
                continue;
            }
        }
    }
}


```

##### 3、SynchronousMethodHandler#executeAndDecode

```java
final class SynchronousMethodHandler implements MethodHandler {
    
    Object executeAndDecode(RequestTemplate template) throws Throwable {
        // 1、请求前拦截
        Request request = targetRequest(template);
		...
        // 2、调用LoadBalancerFeignClient（修饰了feign.Client#Default）发起请求
        response = client.execute(request, options);
        ...
        if (response.status() >= 200 && response.status() < 300) {
            if (void.class == metadata.returnType()) {
                return null;
            } else {
                // 3、响应200，解码（默认为SpringEncoder编码,SpringDecoder解码）
                Object result = decode(response);
                shouldClose = closeAfterDecode;
                return result;
            }
        } else if (decode404 && response.status() == 404 && void.class != metadata.returnType()) {
            // 4、响应404，解码（默认为SpringEncoder编码,SpringDecoder解码）
            Object result = decode(response);
            shouldClose = closeAfterDecode;
            return result;
        } else {
        // 5、ErrorDecoder异常解码，默认为ErrorDecoder.Default，用于抛出RetryableException
            throw errorDecoder.decode(metadata.configKey(), response);
        }
    }

    Request targetRequest(RequestTemplate template) {
        // 1.1、请求前拦截
        for (RequestInterceptor interceptor : requestInterceptors) {
            interceptor.apply(template);
        }
        // 1.2、构造feign.Request实例
        return target.apply(template);
    }
}


```

##### 4、LoadBalancerFeignClient#execute

```java
package org.springframework.cloud.openfeign.ribbon;

public class LoadBalancerFeignClient implements Client {
	@Override
    public Response execute(Request request, Request.Options options) throws IOException {
        ...// 1、组装uri、host和RibbonRequest实例
        // 2、类似于Ribbon调用SpringClientFactory，底层实质调用Spring AbstractApplicationContext#refresh，触发RibbonClientConfiguration注入，然后就有了Ribbon服务列表缓存和其他注入的实例
        IClientConfig requestConfig = getClientConfig(options, clientName);
        // 3、底层构造FeignLoadBalancer（默认修饰Ribbon#ZoneAwareLoadBalancer）
        return lbClient(clientName)
            // 4、调用AbstractLoadBalancerAwareClient#executeWithLoadBalancer
            .executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse();
    }
}

public abstract class AbstractLoadBalancerAwareClient<S extends ClientRequest, T extends IResponse> extends LoadBalancerContext implements IClient<S, T>, IClientConfigAware {
    public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException {
        ...// RXJava语法略
        return Observable.just(
            // 5、调用FeignLoadBalancer#execute方法
            AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));
    }
}


```

##### 5、FeignLoadBalancer#execute

```java
public class FeignLoadBalancer extends
    AbstractLoadBalancerAwareClient<FeignLoadBalancer.RibbonRequest, FeignLoadBalancer.RibbonResponse> {
	@Override
	public RibbonResponse execute(RibbonRequest request, IClientConfig configOverride) throws IOException {
		...
        // 1、最终调用feign.Client#execute方法
		Response response = request.client().execute(request.toRequest(), options);
		return new RibbonResponse(request.getUri(), response);
	}
}

public interface Client {
    @Override
    public Response execute(Request request, Options options) throws IOException {
      // 2、建立连接，发送请求
      HttpURLConnection connection = convertAndSend(request, options);
      // 3、把连接和请求转换为响应实例
      return convertResponse(connection, request);
    }
    
    HttpURLConnection convertAndSend(Request request, Options options) throws IOException {
        // 2.1、建立连接
        final HttpURLConnection connection =
            (HttpURLConnection) new URL(request.url()).openConnection();
        ...// 2.2、设置连接超时、读超时等属性
        // 2.3、如果存在请求体，则发送请求体
        if (request.body() != null) {
            ...
			out.write(request.body());
            ...
        }
        ...
        // 2.4、最后返回建立好的连接
        return connection;
    }
    
    Response convertResponse(HttpURLConnection connection, Request request) throws IOException {
        // 3.1、获取响应码
        int status = connection.getResponseCode();
        // 3.2、获取响应内容
        String reason = connection.getResponseMessage();
        // 3.3、构造返回响应实例
        return Response.builder()
            .status(status)
            .reason(reason)
            .headers(headers)
            .request(request)
            .body(stream, length)
            .build();
    }
}


```

### 2.0. 详细介绍 Hystrix？

#### 背景

1. 当一个服务调用另一个服务时，由于网络或者自身等原因，在调用期间出现问题，调用者就会一直等待被调用者的响应，当越来越多的服务请求到这些出问题的资源，则会导致更多的请求等待，从而发生**雪崩效应**。
2. **雪崩效应**是指，在微服务项目中，由于微服务之间调用是互通的，高并发的数据库访问量会导致服务线程阻塞，使单个服务宕机时，其服务的不可用会蔓延到其他服务，引起整体服务不可用的灾难性后果。
   - **举例**：电商系统很多模块都依赖营销优惠服务，其负载可谓非常之高，如果这个服务出现了异常，导致响应超时，那么所有依赖它的下游系统的响应时间都会被拉长，从而引发一个滚雪球的雪崩效应，由最上游的系统问题，引发一系列下游系统响应超时，最终导致整个系统被拖垮。
3. 其中，雪崩效应产生的**根本原因**是，由于 Tomcat 在默认情况下，只有一个线程池来维护接收到的请求，此时，如果某接口在某时刻被大量访问，就会占据 Tomcat 线程池中的所有线程（即**请求处理资源耗尽**），使得其他请求处于等待状态，无法连接到服务接口。
   - **解决方案**：扩容、限流、增加硬件监控、排查代码问题，使用 Hystrix 进行资源隔离、熔断降级、快速失败等。

#### 概念

1. Hystrix，中文含义为豪猪，因其背上长满棘刺，从而拥有了自我保护的能力，基于此特征的引申，Netflix 公司在分布式微服务架构的践行下，将其保护服务的稳定性而设计的**断路器熔断解决方案**，称之为 Hystrix。
2. Hystrix，是 SpringCloud 中一个防止服务雪崩的**容错框架**，具有**服务降级、服务熔断、服务隔离、服务监控**等技术，从而实现服务保护的效果。
   - **服务降级**：接口调用失败时，为了防止客户端一直等待，其不会再处理业务代码，而是直接返回一个友好的提示给客户端，即调用接口提前定义好的**降级方法**，比如返回一个 NULL。
   - **服务熔断**：
     1. 服务熔断，是在服务降级的基础上，做的一个更直接的保护方式。
     2. 指在统计时间范围内，请求失败数达到了阈值 `requestVolumeThreshold`  + 请求错误率也达到了阈值 `errorThresholdPercentage` 时， 则打开断路器，使得之后的请求直接走**降级方法**，不再走业务代码，并且，在 `sleepWindowInMilliseconds` 后尝试恢复。
   - **服务隔离**：
     1. 指隔离服务资源间的相互影响，使得在高并发的场景下，不影响到其他服务。
     2. 服务隔离有**线程池和信号量**两种实现方式，一般使用线程池方式，即为隔离的服务开启一个独立的线程池。
   - **服务监控**：比如接口调用时，把每秒请求数、成功请求数、失败请求数、请求拒绝数等运行指标都记录下来。

#### 架构原理

##### 服务降级

假如  HystrixClient 调用目标请求时发生了异常，此时 Hystrix 会自动把该请求转发到**降级逻辑**中，由于服务调用方来编写异常处理逻辑，比如**调用超时**等。

![1644325501264](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644325501264.png)

##### 服务熔断

- 服务熔断是建立在服务降级之上的一个异常处理措施，可以看作是服务降级的升级版，引入了一种**断路器（熔断器）**的机制，当断路器打开时，对服务的调用请求不会发送到目标服务节点，而是直接转向**降级逻辑**中。

  ![1644325922862](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644325922862.png)

- 断路器，可以显著缓解由 QPS （Query Per Second，每秒访问请求，用于衡量系统当前压力）激增导致的雪崩效应，断路器打开后，由于请求直接转向降级逻辑，而不会发起服务调用，因此会大幅降低承压服务的系统压力，熔断打开状态的判断维度有：

  - 在一定时间窗口内，发生异常的请求数量达到临界值 `circuitBreaker.requestVolumeThreshold`，默认为 20。
  - 在一定时间窗口内，发生异常的请求数量占请求总数量的一定比例 `circuitBreaker.errorThresholdPercentage`，默认为 50。

  | 状态      | 作用                                                         |
  | --------- | ------------------------------------------------------------ |
  | OPEN      | 打开状态，服务熔断中，在一段时间内不得像外部发起服务调用，调用者想调用该服务则会一律走到降级逻辑中 |
  | HALF-OPEN | 半开状态，可尝试发起一个真实的服务调用，但一切都会被监视着，调用失败的从新回到打开状态，等待下一次半开状态 |
  | CLOSED    | 关闭状态，上一步调用成功了，则可以停止服务熔断，重新恢复正常 |

##### 线程隔离

- Hystrix 通过线程隔离的方案，将执行服务调用的代码，和容器本身的线程池进行隔离，同时允许配置每个服务所需线程的最大数量，使得即便一个服务的线程池被吃满，也不会影响其他服务。

  ![1644326225115](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644326225115.png)

- Hystrix 提供了两种线程隔离的方式，分别是线程池技术和信号量技术，两者业务流程上是一致的，在默认情况下，Hystrix 使用的是**线程池**的方式。

|            | 概念                                                         | 超时判定                                             | 性能                                                         | 使用场景                                                     |
| ---------- | ------------------------------------------------------------ | ---------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 线程池技术 | 使用 Hystrix 内建的线程池去执行方法调用，而不是使用容器线程  | 非容器线程，因此可以直接对执行阶段超时做**主动判定** | 涉及线程创建、销毁、任务调度，在资源利用率和效率的角度上看，线程池技术会比较慢 | 一般场景下尽量使用，但要注意线程切换导致的 ThreadLocal 变量的问题 |
| 信号量技术 | 直接使用容器线程去执行方法，不会另外创建新的线程，只是当开关和计数器的作用，其中，获取到信号量的线程才可以执行方法，没获取到的就会转到降级流程 | 容器线程，只能等待诸如网络请求超时等做**被动判定**   | 没有额外的系统资源开销，性能方面有优势                       | 超高并发下，线程开销大，对接口无需再调用外部服务的场景       |

```properties
# 切换线程隔离方式为信号量方式
execution.isolation.strategy = ExecutionIsolationStrategy.SEMAPHORE


```

#### 使用方式

##### Feign +  Hystrix

```java 
/**
 * 测试HystrixFallback降级应用
 */
@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients
@EnableCircuitBreaker
public class HystrixFallbackApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(HystrixFallbackApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }
}

/**
 * 测试HystrixFallback降级服务
 */
// 允许Bean同名覆盖: 不配置会报"feign-client.FeignClientSpecification"错误, 因为Feign的代理对象名称是使用里面的服务属性拼凑的, 所以可以配置允许Bean同名覆盖
//@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
@FeignClient(value = "feign-client", fallback = IFallbackHandler.class)
public interface IHystrixFallbackService extends ICommonService {

}

@Component
@Slf4j
public class IFallbackHandler implements IHystrixFallbackService {
    /**
     * 直接异常降级实现
     * @return
     */
    @Override
    public String error() {
        log.info("Fallback: I'm not a black sheep any more.");
        return "Fallback: I'm not a black sheep any more.";
    }
}


```

##### @HystrixCommand

```java
/**
 * 测试HystrixFallback降级服务: 测试Hystrix RequestCache
 */
@Service
@Slf4j
public class IRequestCacheService {
    /**
     * 使用name作为CacheKey, 只有key同样, 才返回Hystrix上下文缓存:
     * => 配置口令: 121: 1个HystrixRequestContext上下文, 2个Cache注解@CacheResult和@CacheKey, 1个Command注解@HystrixCommand
     * @param name
     * @return
     */
    // 指定服务降级的第二种写法
    @HystrixCommand(commandKey = "requestCache", fallbackMethod = "requestCacheFallback")
    // 注意@CacheResult是作用在@HystrixCommand注定的方法, 所以还需要配置@HystrixCommand
    @CacheResult
    public Friend requestCache(@CacheKey String name){
        ...
    }
    
    /**
     * 测试RequestCache降级服务: 可见, Hystrix是通过开启一个新的线程来实现降级的, 两不冲突
     * => 测试成功, Hystrix降级时, 会打断@HystrixCommand指定的线程
     * @param name
     * @return
     */
    private Friend requestCacheFallback(String name){...}
}


```

#### 使用经验

##### HystrixCommand + 配置中心

1. Hystrix 配置项非常多，如果不对接配置中心，所有配置只能在代码里修改，在集群部署情况下，难以应对紧急情况。
2. 因此，可以在项目中只设置一个 `CommandKey`，其他配置都在配置中心进行指定，这样出现紧急情况，比如需隔离部分请求时，只需在配置中心进行修改以后，强制更新即可。

##### 降级逻辑 + 手动埋点

1. 当请求失败或者超时，会执行降级逻辑，但如果出现大量的降级，则说明某些服务出问题了。
2. 此时，可以在降级逻辑中加入手动埋点的操作，上报数据给监控系统，并输出降级日志，统一由日志收集的程序去进行处理。
3. 这样就可以把问题暴露出去，然后通过实时数据分析进行告警操作。

##### Gateway + 信号量隔离

1. Gateway 网关，是所有请求的入口，路由服务数量会有很多，几十个到上百个都有可能。
2. 如果用线程池隔离，那么需要创建上百个独立的线程池，开销太大，不建议。
3. 而用信号量隔离，则开销就小很多，同时还能起到限流的作用。

##### 超时控制

Hystrix的超时时间要⼤于Ribbon的超时时间，因为Hystrix将请求包装了起来，特别需要注意的是，如果Ribbon开启了重试机制，⽐如重试3 次，Ribbon 的超时为 1 秒，那么Hystrix 的超时时间应该⼤于 3 秒，否则就会出现 Ribbon 还在重试中，⽽ Hystrix 已经超时的现象。

##### 常用降级方案

真实项目里的降级逻辑有很多，但目标都是相同的，那就是把异常对系统的影响**降到最低**。

- **静默处理**：所谓的静默处理，就是什么也不干，在降级逻辑中直接返回一个 null。
- **默认值**：瞒天过海，说一个假话，在并不确定真实结果的情况下，返回一个默认值。
- **缓存异常**：对于非热点数据，在缓存故障无法处理时，可在降级逻辑里转而访问数据库。
- **主备切换**：在主从库都发生故障时，可以在降级逻辑里，先于人工干预自动访问备库数据，该场景主要用于主链路接口上，平常不要随意访问备库，以免造成脏读幻读。
- **重试**：虽然 Ribbon 可以进行超时重试，但对于接口非超时等其他异常，可以在降级逻辑中自己实现重新调用的逻辑。
- **多级降级**：进入降级逻辑后，如果还发生异常，那么可以对其进行二次、三次等多次降级。
- **人工干预**：对于一些及其重要的接口，可在降级逻辑中启动人工干预流程，比如日志打点、监控报警、通知人工介入等。

### 2.1. 详细介绍 Sentinel？

#### 概念

Sentinel是⼀个⾯向云原⽣微服务的流量控制、熔断降级组件，可用于替代 Hystrix，针对的问题有：**服务雪崩、服务降级、服务熔断、服务限流**，可不依赖任何框架，通过 UI 界⾯配置即可完成细粒度控制。

#### 优点

![1644385609542](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644385609542.png)

- **丰富的应⽤场景**：Sentinel 承接了阿⾥巴巴近 10 年的双⼗⼀⼤促流量的核⼼场景，例如秒杀、消息削峰填⾕、集群流量控制、实时熔断下游不可⽤应⽤等。
- **完备的实时监控**：可以看到 500 台以下规模的集群的汇总，也可以看到单机的秒级数据。
- **⼴泛的开源⽣态**：与 SpringCloud、Dubbo的整合，只需要引⼊相应的依赖并进⾏简单的配置即可快速地接⼊ Sentinel。

#### 原理

##### 限流

- 假设系统可以处理 1w 的并发，但某时刻并发数为 2w，那么限流机制就会保证 1w 用户是正常使用的，否则请求量过大，会将系统可用性拖垮。
- 限流的主要目的是，通过**限制并发访问数**，或者**限制一个时间窗口**内允许处理的请求数量，来保护系统，一旦达到限制流量，则对当前请求进行处理，采取对应的拒绝策略，比如跳转错误页面、进行排队、服务降级等。

##### 熔断

服务熔断是指，当某个服务提供者无法正常为服务调用者提供服务时，比如请求超时、服务异常等，为了防止整个系统出现雪崩效应，**暂时地将出现故障的接口隔离出来**，断绝与外部接口额度联系，即当触发熔断之后，后续一段时间内，该服务调用者的请求都会直接失败，直到目标服务恢复正常。

#### 使用方式

##### 流控 | HelloWorld

```java
/**
 * Sentinel快速入门
 */
public class HelloWorld {

    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 初始化流控规则
     */
    private static void initFlowRules() {
        ArrayList<FlowRule> flowRules = new ArrayList<>();
        FlowRule flowRule = new FlowRule();

        // 注意, 记得把规则和资源绑定起来, 一般一个规则对应一个资源, 但也可以一个规则对应多个资源
        flowRule.setResource(RESOURCE_NAME);

        // 设置QPS维度的流控规则
        flowRule.setGrade(RuleConstant.FLOW_GRADE_QPS);

        // 设置QPS为20个
        flowRule.setCount(20);

        // 交由流控管理器管理
        flowRules.add(flowRule);
        FlowRuleManager.loadRules(flowRules);
    }

    /**
     * 	对主流的5种流控策略做了 底层的抽象和资源的封装
     *
     * 	对于规则： FlowRule 、DegradeRule、ParamFlowRule、SystemRule、AuthorityRule
     * 	对于管理器：FlowRuleManager、DegradeRuleManager、ParamFlowRuleManager、SystemRuleManager、AuthorityRuleManager
     *  对于异常：FlowException、DegradeException、ParamFlowException、SystemBlockException、AuthorityException
     */
    public static void main(String[] args) throws InterruptedException {
        // 0. 引入Maven依赖
        /**
         *         <dependency>
         *             <groupId>com.alibaba.csp</groupId>
         *             <artifactId>sentinel-core</artifactId>
         *             <version>1.8.2-SNAPSHOT</version>
         *         </dependency>
         */

        // 1. 定义规则
        initFlowRules();

        // 2. 定义资源
        while (true) {
            // 流控的Entry
            Entry entry = null;
            try {
                // 2.1. 定义资源名称
                entry = SphU.entry(RESOURCE_NAME);

                // 2.2. 执行业务代码
                System.out.println("执行业务代码...");
                Thread.sleep(20);
            } catch (BlockException e) {
                // 2.3. 抛出异常, 表示被流控住了, 执行流控逻辑
                System.err.println("要访问的资源被流控了, 执行流控逻辑!");
            } finally {
                if(entry != null){
                    // 2.4. 关闭资源
                    entry.exit();
                }
            }
        }

        // 3. 查看结果

        // 4. 配置控制台
    }
}


```

##### 降级 | HelloWorld

```java
/**
 * 初始化降级规则
 */
private static void initDradeRules() {
    ArrayList<DegradeRule> degradeRules = new ArrayList<>();
    DegradeRule degradeRule = new DegradeRule();
    degradeRule.setResource("com.jsonyao.sentinel.controller.IndexController:degrade:test");
    degradeRule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT);
    degradeRule.setCount(2);
    degradeRules.add(degradeRule);
    DegradeRuleManager.loadRules(degradeRules);
}


```

##### 流控 | 注解

```java
// 切面@Around代理@SentinelResource
@Configuration
public class AopConfiguration {
    @Bean
    public SentinelResourceAspect sentinelResourceAspect() {
        return new SentinelResourceAspect();
    }
}

/**
 * 测试注解设置流控
 */
@Service
public class FlowService {

    /**
     * 测试注解设置流控
     *
     * 	blockHandler: 流控降级异常的时候进入的兜底函数
     *  fallback: 抛出业务异常的时候进入的兜底函数
     *  (1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理)
     *
     * @return
     */
    @SentinelResource(
            value = "com.jsonyao.sentinel.service.FlowService:flow",
            // 资源调用的流量类型, 表示控制出口流量, 注意系统规则只会对入口流量生效
            entryType = EntryType.OUT,
            blockHandler = "flowBlockHandler"
//            , fallback = ""
    )
    public String flow() {
        System.err.println("----> 正常执行flow方法");
        return "flow";
    }

    /**
     * 触发流控
     * @param ex
     * @return
     */
    public String flowBlockHandler(BlockException ex) {
        System.err.println("----> 触发流控策略:" + ex);
        return "执行流控方法";
    }
}


```

##### 降级 | 注解

```java
// 切面@Around代理@SentinelResource
@Configuration
public class AopConfiguration {
    @Bean
    public SentinelResourceAspect sentinelResourceAspect() {
        return new SentinelResourceAspect();
    }
}

/**
 * 测试注解降级流控
 */
@Service
public class DegradeService {

    /**
     * 用于测试注解降级流控
     */
    private AtomicInteger counts = new AtomicInteger(0);

    /**
     * 测试注解降级流控
     *
     * 	blockHandler: 流控降级异常的时候进入的兜底函数
     *  fallback: 抛出业务异常的时候进入的兜底函数
     *  (1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理)
     *
     * @return
     */
    @SentinelResource(
            value = "com.jsonyao.sentinel.service.DegradeService:degrade",
            // 资源调用的流量类型, 表示控制出口流量, 注意系统规则只会对入口流量生效
            entryType = EntryType.OUT,
            blockHandler = "degradeBlockHandler",
            fallback = "degradeFallback"
    )
    public String degrade() {
        System.err.println("----> 正常执行degrade方法");

        if(counts.incrementAndGet() % 2 == 0){
            throw new RuntimeException("抛出业务异常");
        }

        return "degrade";
    }

    /**
     * 触发降级流控
     * @param ex
     * @return
     */
    public String degradeBlockHandler(BlockException ex) {
        System.err.println("----> 触发降级流控策略:" + ex);
        return "执行降级流控方法";
    }

    /**
     * 触发业务异常降级
     * @param t
     * @return
     */
    public String degradeFallback(Throwable t) {
        System.err.println("----> 触发异常时的降级策略:" + t);
        return "执行异常降级方法";
    }
}



```

##### 流控 | 控制台

```java
@RestController
public class IndexController {
    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 控制台流控测试： 控制台配置、读取规则
     * @return
     */
    @RequestMapping("/flow")
    public String flow(){
        // 1. 定义规则 => main方法中加载
//        initFlowRules();

        // 2. 定义资源
        Entry entry = null;// 流控的Entry
        try {
            // 2.1. 定义资源名称
            entry = SphU.entry(RESOURCE_NAME);

            // 2.2. 执行业务代码
            System.out.println("执行业务代码...");
            Thread.sleep(20);
        } catch (BlockException e) {
            // 2.3. 抛出异常, 表示被流控住了, 执行流控逻辑
            System.err.println("要访问的资源被流控了, 执行流控逻辑!");
        } catch (InterruptedException e) {

        } finally {
            if(entry != null){
                // 2.4. 关闭资源
                entry.exit();
            }
        }

        return "flow";
    }
}


```

##### 降级 | 控制台

```java
@RestController
public class IndexController {
    /**
     * 用于流控测试的资源名称
     */
    public static final String RESOURCE_NAME = "helloworld";

    /**
     * 控制台降级测试: 控制台配置、读取规则
     * @return
     */
    public AtomicInteger counts = new AtomicInteger(0);
    @RequestMapping("/degrade")
    public String degrade() {
        Entry entry = null;// 流控的Entry
        try {
            String resourceName = "com.jsonyao.sentinel.controller.IndexController:degrade:test";
            entry = SphU.entry(resourceName);

            System.out.println("执行业务代码...");
            if(counts.getAndIncrement() % 2 == 0){
                Thread.sleep(100);
            }

            Thread.sleep(20);
        } catch (BlockException e) {
            System.err.println("要访问的资源被流控了, 执行流控逻辑!");
        } catch (InterruptedException e) {

        } finally {
            if(entry != null){
                entry.exit();
            }
        }

        return "degrade";
    }
}


```

#### Sentinel vs Hystrix

1. **机制不同**：Sentinel 不会像 Hystrix 那样，只在半开状态才放过⼀个请求尝试⾃我修复，就是明明确确地**按时间窗⼝**来，熔断触发后，时间窗⼝内拒绝请求，时间窗⼝后就恢复。
2. **更方便**：Sentinel Dashboard 中添加的规则数据存储在内存，微服务停掉规则数据就消失，在⽣产环境下不合适，可以将 Sentinel 规则数据持久化到 Nacos **配置中⼼**，让微服务从配置中心获取。
3. **其他区别**：

| 维度           | Sentinel                                       | Hystrix                       |
| -------------- | ---------------------------------------------- | ----------------------------- |
| 隔离策略       | 信号量                                         | 线程池/信号量                 |
| 熔断降级策略   | 基于响应时间、基于失败比率                     | 基于失败比率                  |
| 实时指标实现   | 滑动窗口                                       | 滑动窗口（RxJava）            |
| 扩展性         | 多个扩展点                                     | 插件的形式                    |
| 限流           | 基于 QPS，支持基于调用关系的限流               | 不支持                        |
| 流量整形       | 支持慢启动、匀速器模式                         | 不支持                        |
| 系统负载保护   | 支持                                           | 不支持                        |
| 控制台         | 开箱即用，可配置规则、查看秒级监控、机器发现等 | 不完善                        |
| 常见框架的适配 | Servlet、Spring Cloud、Dubbo、gRPC             | Servlet、Spring Cloud Netflix |

### 2.2. 详细介绍 Config？

#### 概念

![1644387119633](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644387119633.png)

Config，Spring Cloud 官方指定配置中心，在配置管理方面主要提供了三个功能：

- **统一配置**：提供了一个中心化的配置方案，将各个项目中的配置内容，集中在 Config Server 一端。
- **环境隔离**：Config Server 提供了多种环境隔离机制，Client 可以根据自身所处的项目环境（比如测试、生产等）加载对应的配置文件。
- **动态刷新**：支持**运行期间**动态改变配置属性。

#### 架构原理

##### Config Server 原理

![1644387439409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644387439409.png)

###### 1、自动装配

1）启动类

```java
/**
 * 配置中心: 可拉取远端的配置文件
 */
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(ConfigServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }

    //    获取配置文件的不同URL姿势，都是GET请求, 如果不指定{label}的话默认用master
    // 1. http://localhost:60000/{label}/{application}-{profile}.* (yml, properties, json)
    // 2. http://localhost:60000/{application}/{profile}/{label}
}


```

2）@EnableConfigServer

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Import(ConfigServerConfiguration.class)
public @interface EnableConfigServer {

}


```

3）org.springframework.cloud.config.server.config.ConfigServerConfiguration

```java
@Configuration
public class ConfigServerConfiguration {

	@Bean
	public Marker enableConfigServerMarker() {
		return new Marker();
	}

	class Marker {

	}

}


```

4）org.springframework.cloud.config.server.config.ConfigServerConfiguration.Marker

```java
@Configuration
public class ConfigServerConfiguration {

	@Bean
	public Marker enableConfigServerMarker() {
		return new Marker();
	}

	class Marker {

	}

}


```

5）org.springframework.cloud.config.server.config.ConfigServerAutoConfiguration

```java
@Configuration
@ConditionalOnBean(ConfigServerConfiguration.Marker.class)
@EnableConfigurationProperties(ConfigServerProperties.class)
@Import({ 
    	// 环境仓库配置
    	EnvironmentRepositoryConfiguration.class, 
    	CompositeConfiguration.class,
		ResourceRepositoryConfiguration.class, ConfigServerEncryptionConfiguration.class,
    	// Rest接口配置
		ConfigServerMvcConfiguration.class })
public class ConfigServerAutoConfiguration {

}



```

###### 2、环境仓库配置

```java
...
public class EnvironmentRepositoryConfiguration {
    ...
    // 支持JDBC、SVN、GITHUB和本地文件，默认基于GITHUB
	@Configuration
	@ConditionalOnClass(TransportConfigCallback.class)
	static class JGitFactoryConfig {

		@Bean
		public MultipleJGitEnvironmentRepositoryFactory gitEnvironmentRepositoryFactory(
				ConfigurableEnvironment environment, ConfigServerProperties server,
				Optional<ConfigurableHttpConnectionFactory> jgitHttpConnectionFactory,
				Optional<TransportConfigCallback> customTransportConfigCallback) {
			return new MultipleJGitEnvironmentRepositoryFactory(environment, server,
					jgitHttpConnectionFactory, customTransportConfigCallback);
		}

	}

	@Configuration
	@ConditionalOnClass({ HttpClient.class, TransportConfigCallback.class })
	static class JGitHttpClientConfig {

		@Bean
		public ConfigurableHttpConnectionFactory httpClientConnectionFactory() {
			return new HttpClientConfigurableHttpConnectionFactory();
		}

	}
    ...
}


```

###### 3、对外 REST 接口

1）org.springframework.cloud.config.server.config.ConfigServerMvcConfiguration}

```java
@Configuration
@ConditionalOnWebApplication
public class ConfigServerMvcConfiguration extends WebMvcConfigurerAdapter {
    ...
	@Bean
	public EnvironmentController environmentController(
			EnvironmentRepository envRepository, ConfigServerProperties server) {
		EnvironmentController controller = new EnvironmentController(
				encrypted(envRepository, server), this.objectMapper);
		controller.setStripDocumentFromYaml(server.isStripDocumentFromYaml());
		controller.setAcceptEmpty(server.isAcceptEmpty());
		return controller;
	}

	@Bean
	@ConditionalOnBean(ResourceRepository.class)
	public ResourceController resourceController(ResourceRepository repository,
			EnvironmentRepository envRepository, ConfigServerProperties server) {
		ResourceController controller = new ResourceController(repository,
				encrypted(envRepository, server));
		return controller;
	}
    ...
}


```

##### Config Client 原理

- **配置 `${value}`**：某个属性的值，在配置文件中使用 `${value}` 来配置，放到 bootstrap.yml 中配置的话，可以使得其在所有文件加载前加载，从而保证程序顺利完成启动。

- **初始化 `${value}`**：

  ![1644388710373](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644388710373.png)

###### 1、SpringBoot 构建 Context

```java
public class SpringApplication {
    public ConfigurableApplicationContext run(String... args) {
        ...
        prepareContext(context, environment, listeners, applicationArguments,
					printedBanner);
        ...
    }
    
    private void prepareContext(ConfigurableApplicationContext context,
      ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) {
        ...
		applyInitializers(context);
        ...
    }
    
	protected void applyInitializers(ConfigurableApplicationContext context) {
		for (ApplicationContextInitializer initializer : getInitializers()) {
			Class<?> requiredType = GenericTypeResolver.resolveTypeArgument(
					initializer.getClass(), ApplicationContextInitializer.class);
			Assert.isInstanceOf(requiredType, context, "Unable to call initializer.");
			initializer.initialize(context);
		}
	}
}


```

###### 2、加载 initializer

```java
@Configuration
@EnableConfigurationProperties(PropertySourceBootstrapProperties.class)
public class PropertySourceBootstrapConfiguration implements
    ApplicationContextInitializer<ConfigurableApplicationContext>, Ordered {
   	@Override
    public void initialize(ConfigurableApplicationContext applicationContext) {
        ...
        for (PropertySourceLocator locator : this.propertySourceLocators) {
			PropertySource<?> source = null;
			source = locator.locate(environment);
			if (source == null) {
				continue;
			}
			logger.info("Located property source: " + source);
			composite.addPropertySource(source);
			empty = false;
		}
        ...
    }
}


```

###### 3、初始化属性资源

```java
// 越小优先级越高, 0代表最优先执行
@Order(0)
public class ConfigServicePropertySourceLocator implements PropertySourceLocator {
	@Override
	@Retryable(interceptor = "configServerRetryInterceptor")
	public org.springframework.core.env.PropertySource<?> locate(
        org.springframework.core.env.Environment environment) {
        	...
			for (String label : labels) {
                ...
				Environment result = getRemoteEnvironment(restTemplate, properties,
						label.trim(), state);
                ...
            }
        	...
    	}
    }
}	


```

###### 4、拉取远程文件

```java
@Order(0)
public class ConfigServicePropertySourceLocator implements PropertySourceLocator {
	private Environment getRemoteEnvironment(RestTemplate restTemplate,
                                             ConfigClientProperties properties, String label, String state) {
       	String path = "/{name}/{profile}";
		String name = properties.getName();
		String profile = properties.getProfile();
		String token = properties.getToken();
        ...
        ResponseEntity<Environment> response = null;
        ...
        final HttpEntity<Void> entity = new HttpEntity<>((Void) null, headers);
        response = restTemplate.exchange(uri + path, HttpMethod.GET, entity,
                                         Environment.class, args);
        ...
    }
}


```

##### 属性动态刷新原理

![1644390259593](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644390259593.png)

1. **发送刷新请求**：选择一个服务节点，通过 post 请求 `/actuator/refresh`，此后该节点会向 Config Server 发起一个请求。
2. **拉取文件**：Config Server 收到上述节点的请求后，默认会访问 GITHUB，拉取最新的配置内容，并把配制文件下载到本地。
3. **获取更新内容**：服务节点从 ConfigServer 获取并更新配置信息后，然后销毁所有 RefreshScope 作用域的 Bean，由于 @RefreshScope 是懒加载模式，所以下次用到时会重新去 Config Server 中加载。

###### 1、RefreshEndpoint#refresh

```java
@Endpoint(id = "refresh")
public class RefreshEndpoint {

	private ContextRefresher contextRefresher;

	public RefreshEndpoint(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@WriteOperation
	public Collection<String> refresh() {
		Set<String> keys = this.contextRefresher.refresh();
		return keys;
	}

}


```

###### 2、ContextRefresher#refresh

方法逻辑同《BUS - 作业流程 - RefreshRemoteApplicationEvent#refresh》。

```java
public class ContextRefresher {
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
}


```

#### 使用方式

##### Config Server

###### POM 依赖

```xml
<!-- 配置中心化的配置中心: 可拉取远端的配置文件 -->
<dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-config-server</artifactId>
    </dependency>
</dependencies>


```

###### yml 配置

```yaml
server:
  port: 60000

spring:
  application:
    name: config-server
  cloud:
    # 配置配置中心
    config:
      server:
        # 使用git方式拉取配置文件
        git:
          # 强制拉取资源文件, 默认为false
          force-pull: true
          # git仓库地址
          uri: https://github.com/JsonYaoo/config-repo.git
          # git仓库下配置文件所在的子目录名称: eg => abc, def...
#          search-paths:
          # 仓库登录用户名: public项目不需要
#          username:
          # 仓库登录用户密码: public项目不需要
#          password:


```

###### @EnableConfigServer

```java
/**
 * 配置中心: 可拉取远端的配置文件
 */
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {

    public static void main(String[] args) {
        new SpringApplicationBuilder(ConfigServerApplication.class)
                .web(WebApplicationType.SERVLET)
                .run(args);
    }

    //    获取配置文件的不同URL姿势，都是GET请求, 如果不指定{label}的话默认用master
    // 1. http://localhost:60000/{label}/{application}-{profile}.* (yml, properties, json)
    // 2. http://localhost:60000/{application}/{profile}/{label}
}


```

##### Config Client

###### POM 依赖

```xml
<!-- 配置配置中心的客户端: 拉取配置中心的配置文件属性 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-config</artifactId>
</dependency>

<!-- 配置配置中心的客户端: 动态刷新配置文件 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<!-- 配置高可用的配置中心的客户端: 从Eureka那里拉取配置中心列表 -->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>


```

###### yaml 配置

```yaml
server:
  port: 61000

spring:
  application:
    name: config-client
  cloud:
    config:
      # 指定拉取配置中心中配置文件的applicationName, 默认为spring application name
      name: config-consumer
      # 指定基础版的配置中心地址
#      uri: http://localhost:60000
      # 指定高可用的配置中心ID
      discovery:
        enabled: true
        service-id: config-server-eureka
      # 指定拉取的配置文件profile, 但一般是在环境中配置(比如args或者系统环境变量中设置)
      profile: prod
      # 指定拉取的配置文件所在的分支, 默认为master
      label: master

# Eureka注册中心地址
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:20000/eureka/

# Actuator配置: 这里主要是为了能够动态刷新配置文件:
management:
  # 已过期, 可不配
#  security:
#    enabled: false
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    health:
      show-details: always

# 通过拉取到的配置文件中的配置属性, 注入到本地的配置变量中
myWords: ${words}

```

###### 测试属性加载

```java
/**
 * 配置中心客户端: 前端控制器
 */
@RestController
public class ConfigClientController {

    /**
     * 测试直接注入配置中心的配置属性
     */
    @Value("${name}")
    private String name;

    /**
     * 测试配置中心注入到本地配置文件的配置属性
     */
    @Value("${myWords}")
    private String words;

    /**
     * 测试直接注入配置中心的配置属性
     * @return
     */
    @GetMapping("/name")
    public String getName(){
        return name;
    }

    /**
     * 测试配置中心注入到本地配置文件的配置属性
     * @return
     */
    @GetMapping("/words")
    public String getWords(){
        return words;
    }
}


```

###### 测试属性动态刷新

```java
/**
 * 配置中心客户端: 动态刷新配置文件
 */
@RestController
@RequestMapping("/refresh")
// 运行期进行刷新这个Bean, 在下一次方法调用时会对所有上下游依赖重新注入
@RefreshScope
public class ConfigClientRefreshController {

    /**
     * 测试配置中心动态刷新到本地配置文件的配置属性
     */
    @Value("${myWords}")
    private String words;

    /**
     * 测试配置中心使用秘钥进行解密
     */
    @Value("${food}")
    private String food;

    /**
     * 测试配置中心动态刷新到本地配置文件的配置属性
     * @return
     */
    @GetMapping("/words")
    public String getWords(){
        return words;
    }

    /**
     * 测试配置中心使用秘钥进行解密
     * @return
     */
    @GetMapping("/dinner")
    public String dinner(){
        return "May I have on " + food;
    }
}


```

### 2.3. 详细介绍 Bus？

#### 概念

Bus，消息总线，可以将消息变更发送给所有的服务节点，从而实现广播状态更改，比如配置变更或者其他管理指令。

#### 架构原理

##### 作业流程

![1644390995665](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644390995665.png)

- **MQ/Kafka**：BUS 只是一个调用的封装，背后还是需要依赖消息中间件，来完成底层的消息分发，实际项目中最常用的还是 RabbitMQ 和 Kafka。
- **BUS**：作为对接上游应用和下游中间件系统的中间层，当接到刷新请求时，会通知底层中间件向所有服务节点推送消息。
- **Refresh 请求**： BUS 节点接收到 refresh 请求后，会发布 RefreshRemoteApplicationEvent 事件，被服务节点监听到后，服务节点会从 ConfigServer 更新配置信息，然后销毁所有 RefreshScope 作用域的 Bean，由于 @RefreshScope 是懒加载模式，所以下次用到时会重新去 Config Server 中加载。

###### 1、请求 bus-refresh

```java
@Endpoint(id = "bus-refresh") // TODO: document new id
public class RefreshBusEndpoint extends AbstractBusEndpoint {

	public RefreshBusEndpoint(ApplicationEventPublisher context, String id) {
		super(context, id);
	}

	...
        
	@WriteOperation
	public void busRefresh() {
		publish(new RefreshRemoteApplicationEvent(this, getInstanceId(), null));
	}
}


```

###### 2、BUS 节点发布 RefreshRemoteApplicationEvent

```java
@SuppressWarnings("serial")
public class RefreshRemoteApplicationEvent extends RemoteApplicationEvent {

	@SuppressWarnings("unused")
	private RefreshRemoteApplicationEvent() {
		// for serializers
	}

	public RefreshRemoteApplicationEvent(Object source, String originService,
			String destinationService) {
		super(source, originService, destinationService);
	}

}

@SuppressWarnings("serial")
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
@JsonIgnoreProperties("source")
public abstract class RemoteApplicationEvent extends ApplicationEvent {
	protected RemoteApplicationEvent(Object source, String originService,
                                     String destinationService) {
        ...
    }
}


```

###### 3、服务节点监听 RefreshRemoteApplicationEvent

```java
public class RefreshListener
		implements ApplicationListener<RefreshRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(RefreshListener.class);

	private ContextRefresher contextRefresher;

	public RefreshListener(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@Override
	public void onApplicationEvent(RefreshRemoteApplicationEvent event) {
		Set<String> keys = this.contextRefresher.refresh();
		log.info("Received remote refresh request. Keys refreshed " + keys);
	}
    
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
}


```

###### 4、服务节点更新配置信息

```java
public class ContextRefresher {
	public synchronized Set<String> refreshEnvironment() {
        // 加载内存中的配置
		Map<String, Object> before = extract(
				this.context.getEnvironment().getPropertySources());
        // 单独启动一个内部容器, 进行新的远程配置加载
		addConfigFilesToEnvironment();
        // 交叉对比、更新配置信息
		Set<String> keys = changes(before,
			extract(this.context.getEnvironment().getPropertySources())).keySet();
        // 发布缓存变更事件
		this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys));
		return keys;
	}
}


```

###### 5、服务节点销毁 RefreshScope 作用域的 Bean

FactoryBean 对象，下次再获取这些 Refresh Scope 的 Bean 后会重新加载。

```java
@ManagedResource
public class RefreshScope extends GenericScope implements ApplicationContextAware,
ApplicationListener<ContextRefreshedEvent>, Ordered {
	public void refreshAll() {
		super.destroy();
		this.context.publishEvent(new RefreshScopeRefreshedEvent());
	}
}


```

##### 事件对象

```java
@SuppressWarnings("serial")
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
@JsonIgnoreProperties("source")
public abstract class RemoteApplicationEvent extends ApplicationEvent {

	private static final Object TRANSIENT_SOURCE = new Object();

	private final String originService;

	private final String destinationService;

	private final String id;
    
    protected RemoteApplicationEvent(Object source, String originService,
                                     String destinationService) {
        ...
    }
}


```

| 维度                | 解释                                                         |
| ------------------- | ------------------------------------------------------------ |
| Source              | 必填，包含一个事件想要表达的信息，可以hi一个自定义可被序列化的对象 |
| Original Service    | 消息来源方，通常是事件发布方的机器 ID 或者 AppID 等          |
| Destination Serivce | 目标机器，BUS 会根据 Destination Serivce 指定的过滤条件（比如服务名、端口等），只让指定的监听者响应事件 |

##### 消息发布者

BUS 通过 /actuator 对外提供 2 个 endpoint 作为消息发布者，可发布 2 种事件。 

###### bus - env

EnvironmentChangeRemoteApplicationEvent，表示一个远程环境变更事件，事件监听者收到这个事件后，会将事件中的 values 添加到 Spring 环境变量中，由 Spring Cloud 的 EnvironmentManager 负责具体处理，从而达到**修改环境变量**的目的。

```java
@SuppressWarnings("serial")
public class EnvironmentChangeRemoteApplicationEvent extends RemoteApplicationEvent {

	private final Map<String, String> values;

	@SuppressWarnings("unused")
	private EnvironmentChangeRemoteApplicationEvent() {
		// for serializers
		this.values = null;
	}

	public EnvironmentChangeRemoteApplicationEvent(Object source, String originService,
			String destinationService, Map<String, String> values) {
		super(source, originService, destinationService);
		this.values = values;
	}

	public Map<String, String> getValues() {
		return this.values;
	}
    ...
}


```

###### bus - refresh

RefreshRemoteApplicationEvent，表示一个远程配置刷新事件，会触发 **@RefreshScope** 所修饰类中的属性刷新。

```java
public class RefreshRemoteApplicationEvent extends RemoteApplicationEvent {

	@SuppressWarnings("unused")
	private RefreshRemoteApplicationEvent() {
		// for serializers
	}

	public RefreshRemoteApplicationEvent(Object source, String originService,
			String destinationService) {
		super(source, originService, destinationService);
	}

}


```

##### 消息监听者

BUS 默认创建了 2 个消息监听器，分别对应上面的两个消息发布 endpoints。

###### bus - env

EnvironmentChangeListener，用于监听远程环境变更事件，将事件中传递的环境变量挨个加入 Spring 本地上下文中。

```java
public class EnvironmentChangeListener
		implements ApplicationListener<EnvironmentChangeRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(EnvironmentChangeListener.class);

	@Autowired
	private EnvironmentManager env;

	@Override
	public void onApplicationEvent(EnvironmentChangeRemoteApplicationEvent event) {
		Map<String, String> values = event.getValues();
		log.info("Received remote environment change request. Keys/values to update "
				+ values);
		for (Map.Entry<String, String> entry : values.entrySet()) {
			this.env.setProperty(entry.getKey(), entry.getValue());
		}
	}

}


```

###### bus - refresh

RefreshListener，用于监听远程配置刷新事件，底层通过触发 EnvironmentChangeEvent 和 RefreshScopeRefreshedEvent 事件，最终实现**属性刷新**。

```java
public class RefreshListener
		implements ApplicationListener<RefreshRemoteApplicationEvent> {

	private static Log log = LogFactory.getLog(RefreshListener.class);

	private ContextRefresher contextRefresher;

	public RefreshListener(ContextRefresher contextRefresher) {
		this.contextRefresher = contextRefresher;
	}

	@Override
	public void onApplicationEvent(RefreshRemoteApplicationEvent event) {
		Set<String> keys = this.contextRefresher.refresh();
		log.info("Received remote refresh request. Keys refreshed " + keys);
	}
}

public class ContextRefresher {
	public synchronized Set<String> refresh() {
		Set<String> keys = refreshEnvironment();
		this.scope.refreshAll();
		return keys;
	}
    
	public synchronized Set<String> refreshEnvironment() {
		Map<String, Object> before = extract(
				this.context.getEnvironment().getPropertySources());
		addConfigFilesToEnvironment();
		Set<String> keys = changes(before,
				extract(this.context.getEnvironment().getPropertySources())).keySet();
		this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys));
		return keys;
	}

   	public void refreshAll() {
		super.destroy();
		this.context.publishEvent(new RefreshScopeRefreshedEvent());
	}
}


```

##### 发布 - 订阅模型

![1644392911868](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644392911868.png)

BUS 事件推送由三个角色构成：

- 事件对象：BUS 事件类，通常是一个 Pojo 对象，包含消费者需要的信息。
- 事件发布：BUS 消息生产者，将事件对象通过广播的形式发布出去。
- 事件监听：由 BUS 事件消费者监听 BUS 事件的发布动作，当获取到事件对象后，会调用处理方法进行消费。

###### 1、自定义事件对象

```java
public class MyEvent extends RemoteApplicationEvent {

   public MyEvent() {
   }

   public MyEvent(Object body, String originService, String destinationService) {
       super(body, originService, destinationService);
   }
}



```

###### 2、注册事件对象

```java
@Configuration
@RemoteApplicationEventScan(basePackageClasses = MyEvent.class)
public class BusExtConfiguration {

}



```

###### 3、监听事件

```java
@Component
public class MyEventListener implements ApplicationListener<MyEvent> {
    
    @Override
    public void onApplicationEvent(MyEvent event) {
        logger.info("Received MyCustomRemoteEvent - message: ");
    }
}



```

###### 4、发布事件

```java
@PostMapping("/bus/publish/myevent")
public boolean publishMyEvent(@RequestBody EventBody body) {
   MyEvent event = new MyEvent(body, applicationContext.getId(), "");
   try {
       // 可以注入ApplicationEventPublisher来发送event
       eventPublisher.publishEvent(event);
       // 也可以直接使用 
       // applicationContext.publishEvent(event)
       return true;   
   } catch (Exception e) {
            log.error("failed in publishing event", e);  
   }  
   return false;
}



```

#### 应用场景

- **清空缓存**：通知所有服务监听者清空某项业务的本地缓存信息，也可以在消息体中加入具体的业务属性，使其定点清除某个特定业务对象的缓存。
- **数据同步**：子系统依赖实时的数据库记录变动，触发相应的业务逻辑，比如可以把 binlog 抓取出来，通过广播功能同步到所有监听器，从而起到数据同步的作用。

### 2.4. 详细介绍 Stream？

#### 概念

Spring Cloud Stream，是基于 Spring Boot 构建的，专门用于**消息驱动服务**所设计的应用框架，底层使用 Spring Integration（一体化） 来为消息代理层提供网络连接支持。

![1644397898722](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644397898722.png)

| 关键词               | 解释                                                         |
| -------------------- | ------------------------------------------------------------ |
| 应用模型             | Stream 提供了应用模型的抽象，引入了三个角色，分别是输入通道 Input、输出通道 Output 和通道与底层中间件之间的代理 Binder |
| 适配层抽象           | Stream 将组件与底层中间件之间的通信过程抽象成了 Binder 层，使得应用层不需要关心底层中间件是 Kafka 还是 RabbitMQ，只需要关注自身的业务逻辑就好 |
| 插件式适配层         | Binder 层采用一种插件形式来提供服务，开发人员可以很方便地自定义适配逻辑 |
| 持久化的发布订阅模型 | 发布订阅是所有消息组件最核心的功能                           |
| 消费组               | Stream 允许将多个 Consumer 加入到一个消费者组，作用是确保一条消息只被组内的一个实例消费 |
| 分区                 | Stream 支持在多个消费者实例之间创建分区，以便于通过某些特征量做消息分发，保证相同标识的消息**总是**能被同一个消费者处理 |

#### 架构原理

![1644398403640](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644398403640.png)

Stream 体系架构主要包括 Input、Output 和 Binder 三部分组成：

##### Input 通道

Input，输入通道（Spring 输入到消息队列），作用是将消息组件中获取到的 Message 传递给消息者进行消费，使用 Stream 可以在接口中使用 @Iutput 注解，声明并定义一个输出通道。

```java
public interface MyTopic {
    @Input
    SubscribableChannel input();
}


```

##### Output 通道

Output，输出通道（消息队列输出到 Spring），作用是把生产者生产的新消息发送到对应的 Topic 中去，使用 Stream 可以在接口中使用 @Output 注解，声明并定义一个输出通道。

```java
public interface MyTopic {

	// 这里可以给Output自定义目标通道名称，比如@Output("myTarget")
    @Output
    MessageChannel output();
}


```

##### Binder

- Stream 提供了一个 Binder 抽象层，作为连接外部消息中间件的桥梁，针对每一个不同的 Broker（比如 Kafka 或者 RabbitMQ），Stream 都有一个对应的 Binder 具体实现来做适配。
- Broker 作为一个适配层，对上层应用程序和底层消息组件之间做了一层屏障，使得应用程序无需关注底层的中间件，只管用注解开启响应的消息通道，剩下的事交给 Binder 来搞定就行。
- 而在更改底层中间件时，只需要变更 Binder 的依赖项，然后修改配置文件就可以了，对于应用程序来说几乎是无感知的。 

![1644399728162](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644399728162.png)

##### 目的地绑定

如果想要 @Input 和 @Output 使用不同名字，但又想绑定同一个 Topic，那么可以进行目的地绑定配置：

```properties
spring.cloud.stream.bindings.<@Input名/@Output名>.destination=<Topic名>


```

#### 使用方式

##### 公共消息实体

```java
/**
 * Stream测试应用: 消息实体
 */
@Data
public class MessageBean {

    /**
     * 消息体
     */
    private String payload;
}


```

##### 广播消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 广播Topic
 */
public interface BroadcastTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "broadcastTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "broadcastTopic-producer";

    /**
     * BroadcastTopic Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * BroadcastTopic Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 配置Stream自定义广播消息Topic: 绑定消费者、生产者信道到broadcastTopic
spring.cloud.stream.bindings.broadcastTopic-consumer.destination=broadcastTopic
spring.cloud.stream.bindings.broadcastTopic-producer.destination=broadcastTopic


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {    
    /**
     * 快速入门 HelloWord: 测试消费者消费
     * @param payload
     */
    // Stream默认的信道, 用于测试消费者消费
    @StreamListener(Sink.INPUT)
    public void consumer(Object payload) {
        log.info("message consumed successfully, payload={}", payload);
    }

    /**
     * 测试自定义广播消息
     * @param payload
     */
    @StreamListener(BroadcastTopic.INPUT)
    public void consumerBroadcastTopic(Object payload) {
        log.info("Broadcast message consumed successfully, payload={}", payload);
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private BroadcastTopic broadcastTopic;
    
    /**
     * 测试广播: 写@RequestParams后, 如果value没变, 但入参名称变了还是可以保持请求报文入参不变, 便于维持前端代码不变
     * @param body
     */
    @PostMapping("send")
    public void sendMessage(@RequestParam(value = "body") String body){
        Message<String> message = MessageBuilder.withPayload(body).build();
        broadcastTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

##### 单播消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 单播Topic
 */
public interface GroupTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "groupTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "groupTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试单播: 绑定消费者、生产者信道到groupTopic
spring.cloud.stream.bindings.groupTopic-consumer.destination=groupTopic
spring.cloud.stream.bindings.groupTopic-producer.destination=groupTopic

# 测试单播: 配置消费者分组 => 实际上是一个组一个queue, 每个queue有多个Consumer
spring.cloud.stream.bindings.groupTopic-consumer.group=GroupA

# 测试单播: 配置消息分区 => 经测试可知, 消息分区和消费组可以合起来使用, 消费组可用来实现单播(组内轮训消费), 消息分区可用来隔离消费组(只有满足条件即SpEL匹配的消费组才能消费消息)
# 打开消费者的消费分区功能
spring.cloud.stream.bindings.groupTopic-consumer.consumer.partitioned=true
# 指定当前消费者实例的总数
spring.cloud.stream.instance-count=2
# 指定当前消费者实例的索引号, 最大值为count-1, 用于测试消息分区
spring.cloud.stream.instance-index=1
# 指定生产者拥有两个消息分区
spring.cloud.stream.bindings.groupTopic-producer.producer.partition-count=2
# SpEL => Key Resolver解析, 表示只有节点为1的消费者才能消费消息, 即SpEL匹配才能消费
spring.cloud.stream.bindings..groupTopic-producer.producer.partition-key-expression=1


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {    
    /**
     * 测试单播消息
     * @param payload
     */
    @StreamListener(GroupTopic.INPUT)
    public void consumerGroupTopic(Object payload) {
        log.info("Group message consumed successfully, payload={}", payload);
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private GroupTopic groupTopic;
    
    /**
     * 测试单播
     * @param body
     */
    @PostMapping("sendToGroup")
    public void sendMessageToGroup(@RequestParam(value = "body") String body){
        Message<String> message = MessageBuilder.withPayload(body).build();
        groupTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

##### 延迟消息

###### 1、声明通道

```java
/**
 * 测试Stream应用: 延迟Topic，需要中间件支持延迟消息
 */
public interface DelayedTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "delayedTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "delayedTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试延迟消息: 绑定消费者、生产者信道到delayedTopic
spring.cloud.stream.bindings.delayedTopic-consumer.destination=delayedTopic
spring.cloud.stream.bindings.delayedTopic-producer.destination=delayedTopic

# 测试延迟消息: 生产者允许生成延迟交换机与延迟队列(都只有一个)
spring.cloud.stream.rabbit.bindings.delayedTopic-producer.producer.delayed-exchange=true


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试延迟消息
     * @param messageBean
     */
    @StreamListener(DelayedTopic.INPUT)
    public void consumerDelayedTopic(MessageBean messageBean) {
        log.info("Delayed message consumed successfully, payload={}", messageBean.getPayload());
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private DelayedTopic delayedTopic;
    
    /**
     * 测试延迟消息
     * @param body
     */
    @PostMapping("sendDelayedMessage")
    public void sendDelayedMessage(@RequestParam(value = "body") String body,
                                   @RequestParam(value = "seconds") Integer seconds){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);

        log.info("ready to send delayed message");

        // 注意, Rabbitmq延迟消息必须在header里添加x-delay参数: 表示多少ms后延迟队列会对延迟消息进行消费
        Message<MessageBean> message = MessageBuilder
                .withPayload(msg)
                .setHeader("x-delay", 1000 * seconds)
                .build();
        delayedTopic.output().send(message);

        log.info("发送完毕 {}" + message);
    }
}


```

##### 异常重试

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
 */
public interface ExceptionTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "exceptionTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "exceptionTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitm: 绑定消费者、生产者信道到exceptionTopic
spring.cloud.stream.bindings.exceptionTopic-consumer.destination=exceptionTopic
spring.cloud.stream.bindings.exceptionTopic-producer.destination=exceptionTopic

# 测试测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitm: 配置本机重试次数, 次数为1代表不重试
spring.cloud.stream.bindings.exceptionTopic-consumer.consumer.max-attempts=2


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
 
    /**
     * 异常重试计数器
     */
    private AtomicInteger count = new AtomicInteger(1);

    @Autowired
    private ExceptionTopic exceptionTopic;
    
    /**
     * 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
     * @param messageBean
     */
    @StreamListener(ExceptionTopic.INPUT)
    public void consumerExceptionTopic(MessageBean messageBean) {
        log.info("Are you OK?");

        // 由于初始值为1, 所以只会重试2次就成功了
        if(count.incrementAndGet() % 3 == 0){
            log.info("Fine, thank you. And you?");
            // 清0, 下次重试测试时, 由于初始值是0, 当重试次数用完还是有异常, 则会一次性抛出所有异常, 否则如果最终能消费成功, 则不会抛出异常
            count.set(0);
        } else {
            log.info("What's your problem?");
            throw new RuntimeException("I'm not OK!");
        }
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private ExceptionTopic exceptionTopic;
    
    /**
     * 测试异常重试(单机版), 即在Consumer本地重试, 而不会发回给Rabbitmq
     * @param body
     */
    @PostMapping("sendException")
    public void sendException(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        exceptionTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

##### 重回队列

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
 */
public interface RequeueTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "requeueTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "requeueTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部: 绑定消费者、生产者信道到requeueTopic
spring.cloud.stream.bindings.requeueTopic-consumer.destination=requeueTopic
spring.cloud.stream.bindings.requeueTopic-producer.destination=requeueTopic

# 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部: 对指定Consumer配置重新入队
#spring.cloud.stream.rabbit.bindings.requeueTopic-consumer.consumer.requeueRejected=true
# 默认全局开启Direct重新入队(不过会被Consumer重试覆盖)
#spring.rabbitmq.listener.direct.default-requeue-rejected=true
# 所以配置Consumer只能重试1次
spring.cloud.stream.bindings.requeueTopic-consumer.consumer.max-attempts=1
# 测试不同分组的消费者消费Requeue消息 => 实际上Group、Topic的名称最好都用-作为连接, 而不是驼峰标识
spring.cloud.stream.bindings.requeueTopic-consumer.group=requeue-group


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
     * @param messageBean
     */
    @StreamListener(RequeueTopic.INPUT)
    public void consumerRequeueTopic(MessageBean messageBean) {
        log.info("Are you OK?");

        try {
            Thread.sleep(3000);
        } catch (Exception e) {
            // do nothing
        }

        throw new RuntimeException("I'm not OK!");
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private RequeueTopic requeueTopic;
    
    /**
     * 测试Stream应用: 测试异常重试(联机版), 消费者会重新生成把消息投递回队列尾部
     * @param body
     */
    @PostMapping("requeue")
    public void requeue(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        requeueTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

##### 死信队列

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试死信队列Topic
 */
public interface DlqTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "dlqTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "dlqTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试死信队列Topic: 绑定消费者、生产者信道到dlqTopic
spring.cloud.stream.bindings.dlqTopic-consumer.destination=dlqTopic
spring.cloud.stream.bindings.dlqTopic-producer.destination=dlqTopic
spring.cloud.stream.bindings.dlqTopic-consumer.consumer.max-attempts=2
spring.cloud.stream.bindings.dlqTopic-consumer.group=dlq-group
# 开启死信队列(默认名称为${dlqTopic}.dlq, 复杂的需要自己指定DLK), 允许指定Consumer绑定DLQ
# => rabbitmq-plugins enable rabbitmq_shovel rabbitmq_shovel_management, 管理控制台开启重推消息其他队列功能
spring.cloud.stream.rabbit.bindings.dlqTopic-consumer.consumer.auto-bind-dlq=true


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试死信队列Topic
     * @param messageBean
     */
    @StreamListener(DlqTopic.INPUT)
    public void consumerDlqTopic(MessageBean messageBean) {
        log.info("DLQ: Are you OK?");

        // 由于初始值为1, 所以只会重试2次就成功了
        if(count.incrementAndGet() % 3 == 0){
            // 死信队列重推消息到该队列时, 由于count已经大于3, 则会消费成功
            log.info("DLQ: Fine, thank you. And you?");
        } else {
            // 当重试次数用完还是有异常, 则会一次性抛出所有异常, 进入死信队列, 否则如果最终能消费成功, 则不会抛出异常
            log.info("DLQ: What's your problem?");
            throw new RuntimeException("DLQ: I'm not OK!");
        }
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private DlqTopic dlqTopic;
    
    /**
     * 测试Stream应用: 测试死信队列Topic
     * @param body
     */
    @PostMapping("dlq")
    public void dlq(@RequestParam(value = "body") String body){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        Message<MessageBean> message = MessageBuilder.withPayload(msg).build();
        dlqTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

##### 异常降级

###### 1、声明通道

```java
/**
 * 测试Stream应用: 测试异常降级, 自定义异常逻辑 + 接口升版
 */
public interface FallbackTopic {

    /**
     * 消费者消费的Topic名称
     */
    String INPUT = "fallbackTopic-consumer";

    /**
     * 生产者生产的Topic名称
     */
    String OUTPUT = "fallbackTopic-producer";

    /**
     * Topic 消费者
     * @return
     */
    @Input(INPUT)
    SubscribableChannel input();

    /**
     * Topic 生产者
     * @return
     */
    // 注意, 这里如果Input和Output如果value相同, 则启动会抛出bean definition with this name already exists异常,
    // 所以, 需要配置不同的通道名称, 然后在配置文件配置他们的destination
    @Output(OUTPUT)
    MessageChannel output();
}


```

###### 2、目的地绑定

```properties
# 测试异常降级, 自定义异常逻辑 + 接口升版: 绑定消费者、生产者信道到dlqTopic
spring.cloud.stream.bindings.fallbackTopic-consumer.destination=fallback-Topic
spring.cloud.stream.bindings.fallbackTopic-producer.destination=fallback-Topic
spring.cloud.stream.bindings.fallbackTopic-consumer.consumer.max-attempts=2
spring.cloud.stream.bindings.fallbackTopic-consumer.group=fallback-group
# errors 是规定写死的
# inputChannel => fallback-Topic.fallback-group.errors


```

###### 3、消费者开启监听

```java
/**
 * Stream测试应用: 测试消费者
 */
@Slf4j
// 绑定信道, 单存的配置项, 可以在配置类中配置
@EnableBinding(value = {
        Sink.class,
        BroadcastTopic.class,
        GroupTopic.class,
        DelayedTopic.class,
        ExceptionTopic.class,
        RequeueTopic.class,
        DlqTopic.class,
        FallbackTopic.class
})
public class StreamConsumer {
    /**
     * 测试异常降级, 自定义异常逻辑 + 接口升版
     * @param messageBean
     */
    @StreamListener(FallbackTopic.INPUT)
    public void consumerFallbackTopic(MessageBean messageBean, @Header("version") String version) {
        log.info("Fallback: Are you OK?");

        // 接口升版: 可以根据不同的版本走不同的逻辑
        if("1.0".equalsIgnoreCase(version)){
            log.info("Fallback: Fine, thank you. And you?");
        } else if("2.0".equalsIgnoreCase(version)){
            // 当重试次数用完还是有异常, 则会一次性抛出所有异常, 进入具体异常降级逻辑, 否则如果最终能消费成功, 则不会抛出异常
            log.info("Fallback: unsupported version?");
            throw new RuntimeException("Fallback: I'm not OK!");
        } else {
            log.info("Fallback: version={}", version);
        }
    }

    /**
     * 具体异常降级逻辑
     * @param message
     */
    // 当前方法用于处理MQTT消息, inputChannel参数指定了用于接收消息的channel
    @ServiceActivator(inputChannel = "fallback-Topic.fallback-group.errors")
    public void fallback(Message<?> message){
        log.info("fallback entered, message={}", message);
    }
}


```

###### 4、生产者消息投递

```java
@RestController
@Slf4j
public class StreamSampleController {
    
    @Autowired
    private FallbackTopic fallbackTopic;
    
    /**
     * 测试Stream应用: 测试异常降级, 自定义异常逻辑 + 接口升版
     * @param body
     */
    @PostMapping("fallback")
    public void fallback(@RequestParam(value = "body") String body,
                         @RequestParam(value = "version", defaultValue = "1.0") String version){
        MessageBean msg = new MessageBean();
        msg.setPayload(body);
        log.info("ready to send delayed message");

        // 设置接口版本: V1 => queue1, V2 => queue2
        Message<MessageBean> message = MessageBuilder
                .withPayload(msg)
                .setHeader("version", version)
                .build();
        fallbackTopic.output().send(message);
        log.info("发送完毕 {}" + message);
    }
}


```

#### 应用场景

![1644400521818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644400521818.png)

在每次运营修改商品数据时，如果帧听到主属性发生变化，需要清空本地缓存和 Tair 缓存中，所有保存了该商品额度数据，可以用发布订阅模式来解决：每次主商品发生修改时， 会向 MetaQ 发布一条对应 Topic 的消息，此时可以对这个 Topic 配置一个广播和单播的监听器：

- **广播组**：包括所有商品详情页的后台服务节点，商品修改的消息被每个服务节点消费，清空它们本地缓存中对应的商品信息。
- **单播组**：单播消息只会被消费一次，用于删除 Tair 分布式缓存中对应的商品信息，因此，这里只配置了一个消费组，保证消息只会被组内的某一台机器所消费。

### 2.5.  详细介绍 Sleuth？

#### 概念

![1644458483392](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644458483392.png)

Sleuth，中文意思大侦探，是为了对微服务之间调用链进行跟踪的一个组件，在一个用户请求发起到结束的整个过程中，该 Request 经过的所有服务都会  Sleuth 梳理出来，从而很容易就可以追溯链路上下游所有的调用。

#### 优点

- **无业务侵入**：Sleuth 在设计上秉承低侵入的概念，无需对业务代码做任何改动，即可静默接入链路追踪功能。
- **高性能**：一般认为在代码里加入完善的同步 log（10 行代码对应 2 条 log），会让接口降低 5% 左右的性能，而通过链路追踪在 log 里做埋点，多多少少也会影响一定性能的，所以 Sleuth 在埋点过程中力求性能影响降低到最小，同时还提供了**采样率配置**来进一步降低开销。

#### 架构原理

##### 集成 Log 系统

- Sleuth 底层采用集成 Log 系统来实现业务埋点，链路信息会传递给底层 log 组件，同时 log 组件会在每行 log 头部输出这些数据。

- log 业务埋点，就需要把链路追踪信息加入开发人员写的业务 log 中，而不是 Sleuth 生产出一行 log，所以，Sleuth 使用 `MDC` + `Format Pattern` 的方式输出信息。

- 比如，当使用 `log.info` 打印日志时，Log 组件会将写入动作，封装成一个 LogEvent 事件，用于生成 Log 文件，而这个事件的具体表现形式由 `MDC` + `Format Pattern` 共同控制：

  - `Format Pattern`：决定了 log 的输出样式，其中集成 Sleuth 后的 log 输出格式为：

    ```properties
    "%5p [sleuth-traceA,%X{X-B3-TraceId:-},%X{X-B3-SpanId:-},%X{X-Span-Export:-}]"
    
    
    ```

  - `MDC`：决定了 log 输出内容，其通过 InheritableThreadLocal 来实现，可以携带当前线程的上下文信息，Sleuth 借助了 AOP 机制，在方法调用时配置了切面，将链路追踪数据加入到了 `MDC` 中，这样在 log 打印时就能从 `MDC` 获取到这些值，然后填入 `Format Pattern` 中配置的占位符了。

![1644459405453](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644459405453.png)

##### Sleuth 数据结构

- **Trace**：
  - 由一系列 spans 组成的一个树状结构，包含一个请求从头贯穿到尾的调用链 ID，即 TraceID。
  - 在一次请求中，不管调用链中途访问了多少服务节点，在每个节点 log 中打印的都是同一个 TraceID。
- **Span**：
  - Sleuth 的一个基本工作单元，包含一个独一无二的单元 ID，即 SpanID，在服务 A 发起对服务 B 的调用，这个事件就可以看作是一个独立单元，生成一个独立的 SpanID。
  - Span 还包含了时间戳，用于标识一个事件从开始到结束经过的时间，可用于统计接口的执行时间。
  - Span 还包含了一些特殊的标记 Annotation，用于标识这个 Span 在执行过程中发起的一些特殊事件。
- **Annotation**：
  - 标记，用来及时记录一个事件的存在，一个 Span 可以包含多个 Annotation，每个 Annotation 表示一个**特殊事件**，同时含有一个时间戳字段，可以用来分析一个 Span 内每个事件的起始和结束时间。
    - **Client Sent**：cs，客户端发起一个请求，描述了某个 span 的开始。
    - **Server Received**：sr，服务端获得请求并准备开始处理它，sr - cs = 本次请求的网络延迟时间。
    - **Server Sent**：ss，服务端请求处理完成，将要把 Response 返回给客户端，ss - sr = 本次请求服务端处理的时间。
    - **Client Received**：cr，客户端成功接收到服务端的回复，表示一个 span 的结束，cr - cs = 客户端从服务端获取回复所需的时间。

![1644460217838](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644460217838.png)

##### 服务节点间的 ID 传递

Sleuth 通过 Filter 向 Http Header 中添加链路追踪信息，使得下游系统可以识别出当前的 TraceID 以及前置的 SpanID 是什么。

| 请求头名称        | 请求头内容     | 解释            |
| ----------------- | -------------- | --------------- |
| X-B3-TraceId      | Trace ID       | 链路全局唯一 ID |
| X-B3-SpanId       | Span ID        | 当前 Span ID    |
| X-B3-ParentSpanId | Parent Span ID | 前置 Span ID    |
| X-Span-Export     | boolean        | 是否可以被采样  |

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>

<!-- Logstash for ELK，非Sleuth！ -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>5.2</version>
</dependency>


```

##### 采样率配置

```properties
# Sleuth采样率配置 => eg: 1为100%收集, 但如果没有Zipkin收集的话, 显示还是为false
spring.sleuth.sampler.probability=1


```

##### 控制台日志格式配置

```xml
<!-- 日志格式： 关键是 -%5p 
	 对应的输出内容：10:53:47.520  INFO [-,,,] 14264 --- [           main] msg...
-->
<property name="CONSOLE_LOG_PATTERN"
          value="%clr(%d{HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}" />


```

##### LogStash 日志格式配置

```xml
<!-- Logstash -->
<!-- 为logstash输出的JSON格式的Appender -->
<appender name="logstash"
          class="net.logstash.logback.appender.LogstashTcpSocketAppender">
    <destination>192.168.1.150:5044</destination>
    <!-- 日志输出编码 -->
    <encoder
             class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
        <providers>
            <timestamp>
                <timeZone>UTC</timeZone>
            </timestamp>
            <pattern>
                <pattern>
                    {
                    "severity": "%level",
                    "service": "${springAppName:-}",
                    "trace": "%X{X-B3-TraceId:-}",
                    "span": "%X{X-B3-SpanId:-}",
                    "exportable": "%X{X-Span-Export:-}",
                    "pid": "${PID:-}",
                    "thread": "%thread",
                    "class": "%logger{40}",
                    "rest": "%message"
                    }
                </pattern>
            </pattern>
        </providers>
    </encoder>
</appender>


```

#### 应用场景

借助 Sleuth 的链路追踪能力，还可以完成一些其他的任务：

- **线上故障定位**：结合 TracingID + ELK 可以寻找出上下游链路中所有的日志信息，来协助定位故障。
- **依赖分析梳理**：梳理上下游依赖关系，理清整个系统中所有微服务之间的依赖关系。
- **链路优化**：通过对链路调用情况的统计分析，识别出转化率最高的业务场景，从而为以后的产品设计提供指导意见。
- **性能分析**：梳理各个环节的时间消耗，找出性能瓶颈，为性能优化、软硬件资源调配指明方向。

### 2.6. 详细介绍 Gateway？

#### 网关层概念

##### 背景

1. **路由维护成本高**：微服务下，部署包非常多，提供给外部用户访问的 url+端口也各不相同，如果由前端负责配置，则会拖慢项目进度，且页面在一大堆 url 跳来跳去，用户体验可能也不好，如果由运维团队负责配置，则增加、删除服务节点，导致的 IP 变化时又要重新配置，十分麻烦。
2. **安全性问题**：不同服务的访问控制可能会不一样，如果让每个服务都实现同样的访问验证逻辑，未免有些太繁琐，且如果有一天需要更改权限认证方案，所有服务都得跟着改，也是麻烦。

##### 架构

引入网关层后，微服务架构变更为以下样子，网关层作为唯一的对外服务，外部请求不直接访问服务层，而是由网关层承接所有的 Http 请求，且可与 Nginx 一同使用。

![1644463270083](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644463270083.png)

##### 作用

- **路由规则**：解决**微服务路由维护成本高**的问题，包含 2 个方面：
  1. **服务寻址**：依赖微服务的服务发现机制和负载均衡机制，实现服务寻址和负载均衡。
  2. **URL 映射**：客户端访问的 URL 不再是真实的路径，是需要经过网关层的路径规则，把来访的 URL 映射成真正的服务路径，再去请求对应的服务。
- **访问控制**：访问控制的具体实现并不是由网关层提供，但网关层却是作为一个载体，承载 2 个相关方面的任务：
  - **拦截请求**：网关层可以检查访问请求中，是否携带令牌等身份信息，如果没有说明还没有登录，则直接返回 403 即可。
  - **鉴权**：对于携带有令牌的请求，网关层还可以调用其他服务，来验证令牌的真假，对令牌校验失败或者已过期的请求，拒绝执行服务请求。

#### Gateway 概念

- Gateway，是 Spring Cloud 中的第二代网关，⽬标是取代 Zuul，在各项指标上都领先 Zuul。
- Gateway，基于 Spring 5.0 + SpringBoot 2.0 + WebFlux + Netty 等技术开发，提供**统⼀的路由**⽅式，并且**基于 Filter 链**的⽅式提供了⽹关基本的功能，比如：鉴权、流量控制、熔断、路径重写、⽇志监控等。

#### 架构原理

##### 集成 Netty

![1644474442817](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644474442817.png)

Netty，是一个非阻塞、高性能、高可靠的异步输入输出框架，在网络领域是黄金 AK 般的存在，性能非常高，其在 Gateway 中主要应用在以下几个地方：

1. **发起服务调用**：由 NettyRoutingFilter 实现，底层基于 Netty#Http Client 来发起外部服务调用。
2. **Response 调用**：由 NettyResponseFilter 实现，外部服务调用结束后，把 Response 回传给 Gateway 调用者。
3. **Socket 连接**：Gateway 的 Socket 连接具体由 ReactorNettyWebSocketClient 类承接，其底层也是基于 Netty#Http Client 发起连接请求。

=> 客户端发起请求到 Gateway，由 NettyRoutingFilter 底层的 Netty#HttpClient 向服务发起调用，调用结束后的 Response 再由 NettyResponseFilter 回传给客户端，可见，Netty 贯穿了从 Request 发起到 Response 结束的整个过程，承担了所有和网络调用相关的任务，也因为有了 Netty 的加持，Gateway 相对于 Zuul 1.x#Servlet 网络请求效率大幅提升。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
	@Configuration
    // reactor.netty.http.client.HttpClient
	@ConditionalOnClass(HttpClient.class)
    protected static class NettyConfiguration {
        @Bean
		@ConditionalOnMissingBean
        public HttpClient httpClient(HttpClientProperties properties) {
            ...
        }
        
		@Bean
		public HttpClientProperties httpClientProperties() {
			return new HttpClientProperties();
		}

		@Bean
		public NettyRoutingFilter routingFilter(HttpClient httpClient,
				ObjectProvider<List<HttpHeadersFilter>> headersFilters,
				HttpClientProperties properties) {
			return new NettyRoutingFilter(httpClient, headersFilters, properties);
		}

		@Bean
		public NettyWriteResponseFilter nettyWriteResponseFilter(
				GatewayProperties properties) {
			return new NettyWriteResponseFilter(properties.getStreamingMediaTypes());
		}

		@Bean
		public ReactorNettyWebSocketClient reactorNettyWebSocketClient(
				HttpClient httpClient) {
			return new ReactorNettyWebSocketClient(httpClient);
		}
    }
}

```

##### Gateway 自动装配

![1644475101295](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644475101295.png)

- **GatewayAutoConfiguration**：核心自动装配主类，负责初始化所有的 Route 路由规则、Predicate 断言工厂和 Filter 过滤器（包括 Global Filter 和 Route Filter），以及加载 Netty 相关配置，用于完成基本的路由功能。
- **GatewayLoadBalancerClientAutoConfiguration**：在 GatewayAutoConfiguration 自动装配完成后，负责加载 Ribbon 和一系列负载均衡配置。
- **GatewayClassPathWarningAutoConfiguration**：在 GatewayAutoConfiguration 自动装配完成后，负责检查项目中的 Spring WebFlux 是否加载了正确的配置。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
    ...// 初始化路由规则、断言工厂、过滤器等Bean
}

```

- **GatewayRedisAutoConfiguration**：负责限流功能的自动装配。
- **GatewayMetricsAutoConfiguration**：负责做一些统计的工作，比如运行时长和调用次数的统计。
- **GatewayDiscoveryClientAutoConfiguration**：负责服务发现功能的自动装配。

```properties
# Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.cloud.gateway.config.GatewayClassPathWarningAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayLoadBalancerClientAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayNoLoadBalancerClientAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayMetricsAutoConfiguration,\
org.springframework.cloud.gateway.config.GatewayRedisAutoConfiguration,\
org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration
org.springframework.boot.env.EnvironmentPostProcessor=\
org.springframework.cloud.gateway.config.GatewayEnvironmentPostProcessor


```

##### Route 数据结构

![1644475772551](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644475772551.png)

Route，路由，是**最基础的工作单元**，Gateway 中可以定义很多个 Route，一个 Route 就是一套包含完整转发规则的路由，主要由三部分组成：

- **断言集合**：Predicates，是路由处理的第一个环节，是路由的匹配规则，决定了一个网络请求是否可以匹配给当前 Route 来处理，当 Route 断言集合中的每个 Predicate 都匹配成功以后，才算匹配 Route，才能走到 Filter 环节。
- **过滤器集合**：Filters，如果请求通过了前面的 Predicate，那么就表示该请求正式被当前 Route 路由接手了，接下来就需要经过一系列的过滤器集合，在请求前或者后执⾏业务逻辑。
- **UR**I：如果请求顺利通过了过滤器的处理，那么接下来就是转发请求了，URI 是统一资源标识符，可以是一个具体的网址，也可以是 IP+端口，也可以是在 Eureka 中注册的服务名称。

```java
public class Route implements Ordered {

	private final String id;

	private final URI uri;

	private final int order;

	private final AsyncPredicate<ServerWebExchange> predicate;

	private final List<GatewayFilter> gatewayFilters;
   	...
    public static class Builder extends AbstractBuilder<Builder> {

		protected Predicate<ServerWebExchange> predicate;
        ...
    }
}


```

##### Route 工作流程

![1644476775581](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644476775581.png)

- **RoutePredicateHandlerMapping**：获取所有已配置的路由集，然后依次循环每个 Route，把本次请求与 Route 中配置的所有断言进行匹配，选定该**第一个**所有的断言**都通过**的 Route 来接手后面的工作。
- **FilteringWebHandler**：在前一步选中 Route 后，由 FilteringWebHandler 把请求交给过滤器，不仅当前 Route 的过滤器会生效，在项目中添加的全局过滤器 Global Filter 也会生效，在请求前或者后执⾏业务逻辑：
  - **请求前 `pre` 类型过滤器**：参数校验、权限校验（鉴权）、流量监控、⽇志输出、协议转换等。
  - **请求后 `post` 类型过滤器**：响应内容、响应头修改、⽇志输出、流量监控等。
- **寻址**：如果请求顺利通过了过滤器的处理，那么接下来就是转发请求了，URI 可以是一个具体的网址，也可以是 IP+端口，也可以是在 Eureka 中注册的服务名称：
  - **负载均衡**：Gateway 转发过程可以采用 Eurea 注册的服务名称方式来调用，底层借助 Ribbon 来实现负载均衡，配置方式为 `lb://服务名称/`。

```java
@Configuration
@ConditionalOnProperty(name = "spring.cloud.gateway.enabled", matchIfMissing = true)
@EnableConfigurationProperties
@AutoConfigureBefore({ HttpHandlerAutoConfiguration.class,
		WebFluxAutoConfiguration.class })
@AutoConfigureAfter({ GatewayLoadBalancerClientAutoConfiguration.class,
		GatewayClassPathWarningAutoConfiguration.class })
@ConditionalOnClass(DispatcherHandler.class)
public class GatewayAutoConfiguration {
    ...
	@Bean
	public RoutePredicateHandlerMapping routePredicateHandlerMapping(
			FilteringWebHandler webHandler, RouteLocator routeLocator,
			GlobalCorsProperties globalCorsProperties, Environment environment) {
		return new RoutePredicateHandlerMapping(webHandler, routeLocator,
				globalCorsProperties, environment);
	}
    ...
}


```

##### 断言 Predicate

Gateway 提供了十多种内置的断言，常用的有：

| 内置断言种类 | 用法                                                         | 作用                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 路径断言     | .route(r -> r.path("/gateway/**").uri(...))                  | 当请求的URL与断言中的 "/gateway/**"规则匹配，才继续下发（下发到过滤、url 转发中） |
| 方法断言     | .route(r -> r.path("/gateway/**").and().method(HttpMethod.GET).uri(...)) | 当请求的 Http Method 与断言中的匹配时，才继续下发            |
| 请求参数断言 | .route(r -> r.path("/gateway/**").and().and().query("name", "test").and().query("age").uri(...)) | 分为属性名验证（名称相同即算匹配）和属性值验证（名称+值都相同才算匹配），才继续下发 |
| 请求头断言   | .route(r -> r.path("/gateway/**").and().header("Authorization").uri(...)) | 分为属性名验证（名称相同即算匹配）和属性值验证（名称+值都相同才算匹配），才继续下发 |
| Cookie断言   | .route(r -> r.path("/gateway/**").and().cookie("name", "test").uri(...)) | 只有当名称+值都相同才算匹配，才继续下发                      |
| 时间片断言   | .route(r -> r.path("/gateway/**")<br/>.and().before(ZonedDateTime.now().plusMinutes(1)).uri(...)) | 分为 Before、Between 和 After 三种，分别指定了是在是什么时间之前、之间、之后才算匹配，才继续下发 |

##### 过滤器 Filter

Gateway 中的过滤器，会经过优先级排列，所有网关调用请求从最高优先级的过滤器开始，一路走到被最后一个过滤器处理才返回。

###### 按执行阶段分

1）**请求前 `pre` 类型过滤器**：order=0，代表优先级最低，越晚被执行，order=MAX，代表优先级最高，越早被执行。

```java
@Override
public GatewayFilter apply(NameValueConfig config) {
	return (exchange, chain) -> {
        // 在Response中添加Header信息
        exchange.getResponse().getHeaders().add(config.getName(), config.getValue());
        return chain.filter(exchange);
    };
}


```

2）**请求后 `post` 类型过滤器**：与 pre 相反，order=0，代表优先级最高，越早被执行，order=MAX，代表优先级最低，越晚被执行。

```java
return chain.filter(exchange)
    	// then是回调函数，在下级调用链路都完成以后才被执行
    	.then(Mono.fromRunnable(() -> {
		// 业务逻辑...
		}));


```

###### 按功能类型分

1）**请求头过滤器**：

```java
// 为Response增加who请求头
.filters(f -> f.addResponseHeader("who", "gateway-header"))


```

2）**前缀截断过滤器**：

```java
.route(r -> r.path("/gateway-test/**")
       		// 截取去掉/gateway-test前缀
             .filters(f -> f.stripPrefix(1))
             .uri("lb://FEIGN-SERVICE-PROVIDER/")
)


```

3）**前缀加入过滤器**：

```java
.route(r -> r.path("/gateway-test/**")
       		// 在/gateway-test前面加入/go/前缀
             .filters(f -> f.prefixPath("go"))
             .uri("lb://FEIGN-SERVICE-PROVIDER/")
)


```

4）**重定向过滤器**：

```java
.filters(f -> f.redirect(302, "https://www.imooc.com/"))


```

5）**会话过滤器**：

```java
// 基于Spring-Session或者Spring-Security时，在调用服务前强制保存Session
.filters(f -> f.saveSession())


```

#### 使用方式

##### POM 依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>


```

##### 配置文件配置 Route

```yaml
spring:
  application:
    name: gateway-service
  cloud:
    gateway:
      discovery:
        # 开启时, 会自动配置默认路由规则
        locator:
          enabled: true
          # 使用小写的服务ID(默认为大写): 配置后Gateway对大写的服务ID将不生效, 自定义的路由规则可以实现既大写又小写
          lower-case-service-id: true
      # 配置自定义路由规则
      routes:
      # 设置路由ID列表(不允许重复?)
      - id: feignclient
        predicates:
        # 设置路径断言列表: 匹配yml的所有请求都会被转发到下面的uri(可以配置多个路由断言共同作用)
        - Path=/yml/**
        filters:
        # 设置路由过滤器: 截去路径断言中的path, 拼接uri进行转发(可以配置多个过滤器共同作用)
        - StripPrefix=1
        # 设置转发路径/服务
        uri: lb://FEIGN-CLIENT


```

##### Configuration 配置 Route

```java
/**
 * Gateway配置测试类: 测试自定义路由规则
 */
@Configuration
// @ConditionalOnBean没用, 注入的AuthFilter还是为null => 解决方式: GatewayConfiguration必须与自定义的Filter在同级目录注入时才不会为null
//@ConditionalOnBean({TimerFilter.class, AuthFilter.class})
public class GatewayConfiguration {

    // 利用Gateway实现Zuul After Filter
    @Autowired
    private TimerFilter timerFilter;

    /**
     * 测试网关JWT鉴权过滤器
     */
    @Autowired
    private AuthFilter authFilter;

    @Bean
    @Order
    public RouteLocator customizedRoutes(RouteLocatorBuilder routeLocatorBuilder){
        return routeLocatorBuilder.routes()
                // 第一个路由规则
                .route(r ->
                        // 配置路径断言
                        r.path("/java/**")
                        // 配置请求方法断言
                        .and().method(HttpMethod.POST)
                        // 配置header断言
                        .and().header("name")
                        // 配置过滤器
                        .filters(f ->
                                // 配置截去再拼接过滤器
                                f.stripPrefix(1)
                                // 配置响应header过滤器
                                .addResponseHeader("java-param", "gateway-config")
                                // 利用Gateway实现Zuul After Filter
                                .filter(timerFilter)
                                // 测试网关JWT鉴权
                                .filter(authFilter)
                        )
                        // 配置转发uri
                        .uri("lb://FEIGN-CLIENT")
                )
                // 第二个路由规则
                .route(r ->
                        // 配置路径断言
                        r.path("/seckill/**")
                                // 配置After断言: 服务器启动后的2分钟生效
                                .and().after(ZonedDateTime.now().plusMinutes(2))
                                // 配置过滤器
                                .filters(f ->
                                        // 配置截去再拼接过滤器
                                        f.stripPrefix(1)
                                )
                                // 配置转发uri
                                .uri("lb://FEIGN-CLIENT")
                )
                .build();
    }
}


```

##### 自定义 Gateway Filter

```java
/**
 * 测试网关JWT鉴权: 网关鉴权核心逻辑
 */
@Component
@Slf4j
// 全局Global过滤器 GlobalFilter
public class AuthFilter implements GatewayFilter, Ordered {
    /**
     * 执行过滤逻辑
     * @param exchange
     * @param chain
     * @return
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ...
    }
    
    /**
     * 高优先级: 小, 低优先级: 大 => 后置过滤器则反过来(钩子)
     * @return
     */
    @Override
    public int getOrder() {
        return 0;
    }
}


```

##### 自定义 Global Filter

```java
/**
 * 利用Gateway实现Zuul After Filter
 */
@Component
@Slf4j
// 全局Global过滤器 GlobalFilter
public class TimerFilter implements GlobalFilter, Ordered {
    /**
     * 执行过滤逻辑
     * @param exchange
     * @param chain
     * @return
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ...
    }
    
    /**
     * 高优先级: 小, 低优先级: 大 => 后置过滤器则反过来(钩子)
     * @return
     */
    @Override
    public int getOrder() {
        return 0;
    }
}


```

### 2.7. DDD 领域驱动模型？

#### 背景

1. 2004 年，Eric Evans 发表《领域驱动设计——软件核心复杂性应对之道》（**Domain-Driven Design** –Tackling Complexity in the Heart of Software），简称 Evans DDD，领域驱动设计思想进入了软件开发者的视野。
2. 领域驱动设计分为两个阶段：
   - 1）以一种领域专家、设计人员、开发人员都能理解的通用语言，作为相互交流的工具，在交流的过程中，发现领域概念，然后将这些概念设计成一个领域模型。
   - 2）再由领域模型驱动软件设计，用代码来实现该领域模型。

#### 概念

1. 软件开发不是一蹴而就的事，我们不可能在不了解产品（或行业领域）的前提下，就进行软件开发。
2. 在开发前，通常需要进行大量的业务知识梳理，然后到达软件设计的层面，最后才是开发。
3. 而在业务知识梳理的过程中，我们必然会形成某个领域知识，**根据领域知识来一步步驱动软件设计**，就是领域驱动设计的基本概念。
4. 而领域驱动设计的核心，就在于建立正确的领域驱动模型。

#### 设计思想

1. 在传统模型中，对象是数据的载体，只有简单的 `getter/setter` 方法，没有行为，是以数据为中心，以数据库 ER 设计作为驱动，分层架构在这种开发模式下，可以理解为是对数据移动、处理和实现的过程。
2. 这就导致，业务逻辑都写在 Service 中的，业务实体只是个数据载体，没有任何行为，是一种贫血模型。再简单的业务系统中，采用这种贫血模型和过程化设计是没有问题的，但在业务逻辑复杂了，业务逻辑、状态会散落到在大量方法中，会使得原本的代码意图会渐渐不明确，这种情况称为**由贫血症引起的失忆症**。
3. 总结一下，**传统架构的特点**为：
   - 1）以数据为中心，以数据库 ER 设计作为驱动。
   - 2）业务实体为贫血模型。
   - 3）业务逻辑散落在大量的方法中，当系统越来越复杂时，开发时间指数增长，维护成本很高。
4. **DDD 设计思想**是：
   - 1）业务逻辑不再集中在这几个大型的 Service 类上，而是由大量相对小的领域对象组成，这些类具备它自己的状态和行为，每个类是相对完整的独立体，并与现实领域的业务对象进行映射。
   - 2）因此，领域模型是由许多细粒度的类组成的。

#### 分层架构

![1647597162041](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647597162041.png)

| 架构分层   | 作用                                                         |
| ---------- | ------------------------------------------------------------ |
| 表现层     | 用于向用户展现信息，以及解释用户命令                         |
| 应用层     | 很薄的一层，用于协调应用的活动，不包含业务逻辑，也不保留业务对象的状态，但保有应用任务的进度状态 |
| 领域层     | 业务软件的核心所在，包含关于领域的信息，会保留业务对象的状态，然后把对业务对象状态的持久化委托给基础设施层 |
| 基础设施层 | 作为其他层的支撑库存在，提供了层间的通信，实现对业务对象的持久化 |

1. 层结构的划分是很有必要的，只有清晰的结构，那么最终的领域设计才适合使用。
2. 比如，用户要预定航班，向 Application Layer 的 service 发起请求，而后 Domain Layler 从 Infrastructure Layer 获取领域对象，校验通过后会更新用户状态，最后再次通过 Infratructure Layer 持久化到数据库中。

#### 核心概念

![1647597643876](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647597643876.png)

##### 1）实体 Entity

实体，与面向对象中的概念类似，在领域模型中，实体具有唯一的标识符，从设计的一开始就应该被考虑。

##### 2）值对象 Value Object

值对象，是没有唯一标识符的实体，比如有两个收获地址的信息完全一样，那它就是值对象，并不是实体，值对象在领域模型中可以被共享，且不可变即只读的，当有其他地方用到值对象时，可以将它的副本作为参数传递。

##### 3）服务 Services

1. 在分析某一领域时，并非所有的点都能用模型对象去涵盖，当对象有属性、状态和行为时，领域中的一些行为是无法映射到具体的对象中的，所以，此时也不能强行将其放入在某一个模型对象中，这就需要**服务**。
2. **服务是无状态的，对象是有状态的**，所谓状态，就是对象的基本属性，高矮胖瘦，年轻漂亮等，服务本身也是对象，但它却**没有属性，只有行为**，因此说是无状态的。
3. 服务存在的目的就是，为领域提供简单的方法，为了提供大量便捷的方法，则会关联许多的领域模型。

所以，服务**特点**为：

1. 服务中体现的行为，一定是不属于任何实体和值对象的，但它属于领域模型范围内的。
2. 服务的行为，一定涉及其他多个对象。
3. 服务的操作，是无状态的。

##### 4）模块 Moudles

1. 对于一个复杂的应用来说，领域模型将会变的越来越大，使得最后很难去描述和理解，更别提模型之间的关系了。
2. 模块的出现，就是为了组织统一的模型概念，来达到**减少复杂性的目的**。
3. 而另一个原因，则是模块可以**提高代码质量和可维护性**，比如常说的高内聚、低耦合，就是要提倡将相关的类内聚在一起实现模块化。
4. 模块应当有对外的统一接口，供其他模块调用，比如有三个对象在模块 A 中，那么模块 B 不应该直接操作这三个对象，而是**操作暴露的接口**。
5. 另外，**模块的命名**也很有讲究，最好能够深层次反映领域模型。

##### 5）聚合 Aggregates

![1647667802186](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647667802186.png)

1. **聚合**，表示一组领域对象，包括实体和值对象，用来表述一个完整的领域概念。
2. 每个聚合都有一个根实体，这个根实体又叫做**聚合根**。
3. 比如，一个电脑包含硬盘、CPU、内存条等，这一个组合就是一个聚合，而电脑就是这个组合的聚合根。
4. 在聚合中，聚合根是唯一允许外部对象保持对它的引用的元素，内部的对象之间，则可以互相引用。

##### 6）工厂 Factory

1. 一个对象的创建可能是它自身的主要操作，但是复杂的组装操作，则不应该成为被创建对象的职责，如果在对象内部组合这样的创建职责，会产生笨拙的设计，也很难让人理解。
2. 因此，有必要引入一个新的概念，帮助封装复杂的对象创建过程，这就是工厂 Factory。
3. 工厂，用来封装对象创建所必需的知识，它们对创建聚合特别有用，当聚合根建立时，所有聚合包含的对象将随之建立。

##### 7）资源库 Repositories

1. 资源库，是封装所有获取对象引用所需的逻辑，会保存对某些对象的引用。
2. 当一个对象被创建出来时，它可以被保存到资源库中，然后以后使用时，则可从资源库中检索到。
3. 如果客户程序从资源库中请求一个对象，而资源库中并没有它，就会从存储介质中获取它。
4. 换种说法是，资源库，是作为一个全局的可访问对象的存储点而存在的。
5. Repository 的接口，应当采用领域通用语言，使得作为客户端，不用知道数据库实现的细节。

**Repository vs DAO**：

1. DAO 是比 Repository 更低的一层，因为它要包含如何从数据库中提取数据的代码。
2. 而 Repository 则以“领域”为中心，所描述的是“领域语言”，把 ORM 框架与领域模型隔离，对外隐藏封装了数据访问机制。

**Repository  vs Factory**：

1. 工厂和资源库之间存在一定的关系，它们都是模型驱动设计中的模式，都能帮助关联领域对象的生命周期。
2. 然而，工厂关注的是对象的创建，而资源库关心的是已经存在的对象。
3. 资源库是用来发现已经创建过的对象，而工厂则是创建新的对象，所以，资源库不能被视为一个工厂，当一个新对象被添加到资源库时，它应该是先由工厂创建过的，然后被被传递给资源库，以便将来保存它。

##### 8）规约 Specification

1. 规约，是一种布尔型的断言。
2. 规约，是业务规则的部分，理论上规约类中的方法只有个：`isSatisfiedBy(Object obj)`。
3. 规约，用来测试对象是否满足某种条件，用来进行对象查询，或者某个对象创建的判断条件。
4. 多个规约，可以通过组合，从而表现出更复杂的规约。

##### 9）界限上下文 Bounded Context

1. 界限上下文，可以明确定义模型所应用的上下文，在边界内，要严格保持模型的一致性，不能受到边界之外问题的混淆，由每个团队负责自己的模型，并为其他模型提供服务。
2. 可以根据团队的组织、软件系统的功能、以及物理表现（代码数据库），来设置模型的边界。
3. 一个企业应会用有多个模型，每个模型有自己的界限上下文，建议用上下文作为团队组织的基础。
4. 在同一个界限上下文的团队里，人们能更容易地沟通，也能很好地将模型集成和实现，但每个团队又都工作于自己的模型，所以最好让每个人都能了解所有的模型。

##### 10）上下文映射 Context Map

上下文映射，是指抽象出不同界限上下文之间**关系的文档**，可以是一个图表，可以是其他任何形式的文档，以让每个在项目中工作的人，都能够得到并理解它。

#### 实战举例

##### 1）业务

顾客排队，收银员使用收银机收银，收银机能计算出要收的钱，收银员扫一下就 OK 了~

##### 2）系统建模

分析**业务关键字**：

1. **商品对象**：
   - **属性**：商品名称、商品价格。
   - **行为**：在这里商品对象是没有行为的，可以作为“值对象”。
2. **顾客对象**：
   - **属性**：顾客姓名、顾客选购的商品。
   - **行为**：选购想买的商品、听收银员说要收多少钱。
3. **收银员对象**：
   - **属性**：收银员姓名。
   - **行为**：收银。
4. **收银机对象**：
   - **属性**：收银机编号、总金额。
   - **行为**：收银机收银、显示收银总额。

=> 因此，面向对象分析可以很直观地描述各自的业务（Okey 作为对象的标识），此时对象就是对现实的抽象，现实中的事务，自然可以很方便的用对象抽象出来，这样和用表来描述业务就方便了很多，因为表只能描述属性，导致属性与行为的分离，而对象则既包括属性又含有行为。

![1647669110003](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647669110003.png)

##### 3）代码示例

###### 1、商品对象设计

```java
public class Goods {
    public Guid OKey { get; set; }
    
    // 商品名称
    public string GoodsName { get; set; }
    // 商品价格
    public decimal GoodsPrice { get; set; }
}

```

###### 2、顾客对象设计

```java
public class Customer {
    public Guid OKey { get; set; }
    
    // 顾客姓名
    public string CustomerName { get; set; }
	
    // 顾客购买的商品
    private List<Goods> _goodss = new List<Goods>();
    public List<Goods> Goodss {
        get { return _goodss; }
        set { _goodss = value; }
    }

    // 行为：选购想买的商品
    public void LikeBuy(Goods goods) {
        this._goodss.Add(goods);
    }

    // 行为：听收银员应收多少钱
    public void ListenAmount(decimal amount) {
        Console.WriteLine("我是[{0}],我买了{1}件商品。我共花了{2}元RMB。", this.CustomerName, this.Goodss.Count, amount.ToString("f2"));
    }
}

```

###### 3、收银员对象设计

```java
public class Cashier {
    public Guid OKey { get; set; }
    
    // 收银员姓名
    public string CashierName { get; set; }

    // 行为：收银
    public void CashRegister(Customer customer) {
        // 1、打开使用收银机
        CashRegister cashRegister = new CashRegister();

        // 2、对顾客的商品进行收银机扫码，收银
        foreach (var goods in customer.Goodss) {
            // 3、使用收银机扫商品进行收银
            cashRegister.CashRegisters(goods);
        }

        // 4、通知顾客一共收多少钱
        customer.ListenAmount(cashRegister.ShowAmount());
    }
}

```

###### 4、收银机对象设计

```java
public class CashRegister {
    public Guid OKey { get; set; }
    
    // 收银机编号
    public string CashRegisterNo { get; set; }

    // 总价格
    private decimal _totalAmount { get; set; }
	
    // 构造方法：收银总额置0
    public CashRegister() {
        this._totalAmount = 0;
    }

    // 行为： 收银机收银
    public void CashRegisters(Goods goods) {
        this._totalAmount += goods.GoodsPrice;
    }

    // 行为：显示收银总额
    public decimal ShowAmount() {
        return this._totalAmount;
    }
}

```

###### 5、业务流程实现

```java
// 1、创建几样商品
Goods RedWine = new Goods() { 
    GoodsName = "红酒", GoodsPrice = 1800, OKey=Guid.NewGuid()
};
Goods apple = new Goods() { 
    GoodsName = "苹果", GoodsPrice = 3.5, OKey=Guid.NewGuid() 
};

// 2、创建几位顾客
Customer Anan = new Customer() { CustomerName = "安安", OKey = Guid.NewGuid() };
Customer Beianqi = new Customer() { CustomerName = "贝安琪", OKey = Guid.NewGuid() };

// 3、创建收银员
Cashier CashierMM = new Cashier() { CashierName = "收银员MM", OKey = Guid.NewGuid() };

// 4、顾客逛了一圈，选了自己想要的商品
Anan.LikeBuy(RedWine);
Beianqi.LikeBuy(RedWine);
Beianqi.LikeBuy(apple);

// 5、顾客开始排队结帐了
Queue<Customer> customerQueue = new Queue<Customer>();
customerQueue.Enqueue(Anan);
customerQueue.Enqueue(Beianqi);

// 6、队伍过来，按先后顺序挨个收银
foreach (var customer in customerQueue) {
    // 7、收银
    CashierMM.CashRegister(customer);
}

```

###### 6、最后结果显示

```java
我是[安安]，我买了1件商品。我共花了1800.00元RMB。
我是[贝安琪]，我买了2件商品。我共花了1803.50元RMB。

```

#### 优势

1. **方法论完整**：DDD 是一套完整而系统的设计方法，能从战略设计到战术设计，给出标准的设计过程，使得你的设计思路能够更加清晰，设计过程更加规范。
   - **战略设计**，主要从业务视角出发，建立业务领域模型，划分领域边界，建立通用语言的界限上下文，界限上下文可以作为微服务设计的参考边界。
   - **战术设计**，则从技术视角出发，侧重于领域模型的技术实现，完成软件开发和落地，包括：聚合根、实体、值对象、领域服务、应用服务、以及资源库等代码逻辑的设计和实现。
2. **避免对象的属性和行为分离**：传统需求分析，接触到需求后，第一步是将其切割成数据和行为，然后数据用数据库实现，行为用服务实现，造成需求的首肢分离，而 DDD 则第一步是，考虑领域模型，避免了对象的属性和行为分离。
3. **降低维护成本**：DDD 可以降低服务的耦合性，让系统设计更加规范，使得即使是刚加入团队的新人，也可以根据业务快速找到对应的代码模块，降低维护成本。
4. **适合高复杂度业务开发**：DDD 善于处理与领域相关的拥有高复杂度业务的产品开发，通过它可以建立一个核心而稳定的领域模型，有利于领域知识的传递与传承，更强调团队与领域专家的合作，能够帮助团队建立一个沟通良好的氛围，构建一致的架构体系。
5. **适合微服务拆分**：DDD 可以根据领域模型界限上下文边界，来快速拆分微服务，实现系统架构适应业务的快速变化。

#### 局限

1. **不适合简单、业务不会继续迭代的系统**：

   - 1）如图是两层架构、多层SOA架构、以及 DDD，随着业务复杂度的增加，其在开发成本上的比较。
   - 2）可以看到，刚开始 DDD 的成本是最高的，所以，如果是简单的系统，后续业务不会有太大变化，那么确实不适合用DDD，因为只有合适才是最好的。

   ![1647598333362](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647598333362.png)

2. **对设计、开发人员的要求相对较高，实现起来相对复杂**：

   - 1）不同企业的研发管理能力和个人开发水平可能会存在差异，尤其对于传统企业而言，在战术设计落地的过程中，可能会存在一定挑战和困难.
   - 2）所以公司如果有这方面的想法，一定要先谨慎评估团队的能力，选择最合适的方法去落地 DDD。

#### 微服务设计原则

1. 要领域驱动设计，而不是数据驱动设计，也不是界面驱动设计。
2. 要边界清晰的微服务，而不是泥球小单体。
3. 要职能清晰的分层，而不是什么都放的大箩筐。
4. 要做自己能 hold 住的微服务，而不是过度拆分的微服务。

#### 微服务拆分考虑点

1. **基于领域模型拆分**：围绕业务领域按职责单一性、功能完整性进行拆分。
2. **基于业务需求变化频率拆分**：
   - 1）识别领域模型中的业务需求变动频繁的功能，考虑业务变更频率与相关度，将业务需求变动较高和功能相对稳定的业务进行分离。
   - 2）这是因为需求的经常性变动，必然会导致代码的频繁修改和版本发布，这种分离可以有效降低频繁变动的敏态业务对稳态业务的影响。
3. **基于应用性能拆分**：
   - 1）识别领域模型中性能压力较大的功能。
   - 2）因为性能要求高的功能，可能会拖累其它功能，在资源要求上也会有区别，为了避免对整体性能和资源的影响，可以把在性能方面有较高要求的功能给拆分出去。
4. **基于组织架构和团队规模拆分**：
   - 1）除非有意识地优化组织架构，否则微服务的拆分，应尽量避免带来团队和组织架构的调整，避免由于功能的重新划分，而增加大量且不必要的团队之间的沟通成本。
   - 2）拆分后的微服务项目团队规模保持在 10～12 人左右为宜。
5. **基于安全边界拆分**：如果有特殊安全要求的功能，应从领域模型中拆分独立，避免相互影响。
6. **基于技术异构拆分**：
   - 1）领域模型中有些功能虽然在同一个业务域内，但在技术实现时可能会存在较大的差异，也就是说领域模型内部不同的功能存在技术异构的问题。
   - 2）由于业务场景或者技术条件的限制，有的可能用.NET，有的则是 Java，有的甚至大数据架构。对于这些存在技术异构的功能，可以考虑按照技术边界进行拆分。

# 九、Netty篇

### 1.1. 内核空间、用户空间？

1. 现在操作系统都是采用虚拟存储器，那么对 32 位操作系统而言，它的寻址空间（虚拟存储空间）为 4G（2的32次方）。
2. 操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限，所以，为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。
3. 针对 linux 操作系统而言，将最高的 1G 字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF），供内核使用，称为内核空间。
4. 而将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。

### 1.2. 进程切换？

为了控制进程的执行，内核必须有能力挂起正在 CPU 上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：

1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新 PCB 信息。
3. 把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其 PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

=> **总而言之就是很耗资源**。

### 1.3. 进程的阻塞？

1. 正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由进程自动执行阻塞原语（Block），使自己由运行状态变为阻塞状态。
2. 所以，进程的阻塞，是进程自身的一种**主动行为**，也因此只有处于运行态的进程（已获得 CPU 的进程），才可能将其转为阻塞状态。
3. 当进程进入阻塞状态后，会让出 CPU 资源，不占用 CPU。

### 1.4. 同步、异步、阻塞、非阻塞？

- **同步、异步**：同步和异步，是针对应用程序和内核的**交互**而言的：
  1. 同步，是指用户进程触发 I/O 操作，并等待或者轮询地去查看 I/O 操作是否就绪。
  2. 异步，则是指用户进程触发 I/O 操作以后，便开始做自己的事情，当 I/O 操作已经完成时，会得到操作系统派发的 I/O 操作完成的通知。
- **阻塞、非阻塞**：阻塞和非阻塞，是针对于进程在访问数据时，根据 I/O 操作的就绪状态而采取的不同方式，说白了就是读取或者写入时说调用**函数的不同实现方式**：
  1. 阻塞方式下，读取或者写入函数，应用程序需要一直等待，直到函数执行完成。
  2. 非阻塞方式下，读取或者写入函数，会立即返回一个状态值，相当于是一个尝试性的执行动作。

=> 综上所述，同步、异步是相对于应用和内核的交互方式而言的，同步需要主动去询问，而异步的时候内核在 I/O 事件发生时通知应用程序，而阻塞、非阻塞仅仅是系统在调用系统调用时，函数的实现方式不同而已。

### 1.5. 文件描述符 fd？

1. 文件描述符，File descriptor，是计算机科学中的一个术语，是一个用于表述指向**文件引用**的抽象化概念。
2. 文件描述符，在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开**文件的记录表**：当程序打开一个现有文件，或者创建一个新文件时，内核向进程返回一个文件描述符。
3. 在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展，但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

### 1.6. 缓存 I/O？

1. 缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。
2. 在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据，缓存在文件系统的页缓存（page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区中，拷贝到应用程序的地址空间。
3. **缓存 I/O 的缺点**：数据在传输过程中，需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

### 1.7. Linux I/O 模式？

对于一次 I/O 访问（以 read 为例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，所以，当一个 read 操作发生时，它会经历两个阶段：

1. 等待数据准备 (Waiting for the data to be ready)
2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

正式因为这两个阶段，linux 系统产生了下面五种网络模式的方案：

- 阻塞 I/O（blocking I/O）
- 非阻塞 I/O（nonblocking I/O）
- I/O 多路复用（ I/O multiplexing）
- 信号驱动 I/O（ signal driven I/O）
- 异步 I/O（asynchronous I/O）

注：signal driven IO 在实际中并不常用~

#### 1）阻塞 I/O（blocking I/O）

在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：

![1646817239297](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817239297.png)

1. 当用户进程调用了 `recvfrom` 这个系统调用，kernel 就开始了 I/O 的第一个阶段：准备数据（对于网络 I/O 来说，很多时候数据在一开始还没有到达，比如，还没有收到一个完整的 UDP 包，这个时候，kernel 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。
2. 而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 状态，重新运行起来。
3. 所以，blocking I/O 的特点是，在 I/O 执行的两个阶段都会被 block 住。

#### 2）非阻塞 I/O（nonblocking I/O）

linux 下，可以通过设置 socket 使其变为 non-blocking，当对一个 non-blocking socket 执行读操作时，流程是这个样子：

![1646817424161](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817424161.png)

1. 当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。
2. 从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果，但用户进程判断结果是一个 error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。
3. 一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回。
4. 所以，nonblocking I/O 的特点是，用户进程需要不断的主动询问 kernel 数据好了没有。

#### 3）I/O 多路复用（ I/O multiplexing）

I/O multiplexing 就是我们说的 `select`、`poll` 和 `epoll`，有些地方也称这种 I/O 方式为事件驱动型 I/O event driven IO。

1. `select` / `epoll` 的好处就在于，单个 process 就可以同时处理**多个**网络连接的 I/O，其基本原理是，`select`、`poll` 、`epoll` 这些 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。
2. 当用户进程调用了 `select`，那么整个进程会被block，同时，kernel会“监视”所有 `select` 负责的socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。
3. 所以，I/O 多路复用的特点是，通过一种机制，让一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select` 函数就可以返回了。

![1646817566451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646817566451.png)

- 这个图和 blocking IO 的图其实并没有太大的不同，事实上，还更差一些，因为这里需要使用两个 system call  (`select` 和 `recvfrom`)，而blocking IO只调用了一个 system call (`recvfrom`)。
- 但是，用 `select` 的优势在于它可以同时处理多个 connection，所以，如果处理的连接数不是很高的话，使用 `select` / `epoll` 的web server不一定比使用 multi-threading + blocking IO 的 web server 性能更好，可能延迟还更大，即其优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。
- 在 IO multiplexing Model 当前模型中，实际中，对于每一个 socket，一般都设置成为 non-blocking，但是，如上图所示，整个用户的 process 其实是一直被 block 的，只不过 process 过程是被 `select` 这个函数 block，而不是被 socket I/O 给 block 住。

=> 所以，基于多路复用模型实现的代码，处理网络 I/O 过程，可以看作是同步非阻塞的。

#### 4）信号驱动 I/O（ signal driven I/O）

1. 在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞。
2. 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中，调用 I/O 操作函数处理数据。

![1646818238023](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646818238023.png)

- **优点**：线程并没有在等待数据时被阻塞，可以提高资源的利用率。
- **缺点**：信号 I/O 在大量 I/O 操作时，可能会因为信号队列溢出，导致没法通知。
- **适用场景**：
  1. 信号驱动 I/O 尽管对于处理 UDP 套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。
  2. 但是，对于 TCP 而言，信号驱动的 I/O 方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源，与前几种方式相比优势尽失。

#### 5）异步 I/O（asynchronous I/O）

inux 下的 asynchronous I/O 其实用得很少，先看一下它的流程：

![1646818029954](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646818029954.png)

1. 用户进程发起 read 操作之后，立刻就可以开始去做其它的事。
2. 而另一方面，从 kernel 的角度，当它受到一个 asynchronous read 之后，首先它会立刻返回，不会对用户进程产生任何 block。
3. 然后，kernel 会等待数据准备完成后，再将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal，告诉它 read 操作完成了。

### 1.8. select、poll、epoll？

1. `select`、`poll`、`epoll` 都是 I/O 多路复用的机制。
2. I/O多路复用，就是通过一种机制，让一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
3. 但 `select`、`poll`、`epoll` 本质上都是同步 I/O，因为它们都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，操作系统会负责把数据从内核拷贝到用户空间。

#### 1）select

```c++
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

1. `select` 函数监视的文件描述符分 3 类，分别是 `writefds`、`readfds`、和 `exceptfds`。
2. 调用后，`select` 函数会阻塞，直到有描述副就绪（比如有数据 可读、可写、或者有 except），或者超时（`timeout` 指定等待时间，如果立即返回设为 null 即可），则函数返回。
3. 当 `select` 函数返回后，可以通过遍历 `fdset` ，来找到就绪的描述符。

- **优点**：`select` 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。
- **缺点**：`select` 的一个缺点在于，单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义，甚至重新编译内核的方式来提升这一限制，但是这样也会造成效率的降低。

#### 2）poll

```c++
int poll (struct pollfd *fds, unsigned int nfds, int timeout);

struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

- **特点**：
  1. 不同与 `select` 使用三个位图来表示三个 `fdset` 的方式，`poll` 只使用一个 `pollfd` 的指针来实现。
  2. `pollfd` 结构包含了要监视的 event，和 发生的 event，不再使用 `select` “参数-值” 的传递方式。
  3. 同时，`pollfd` 并没有最大数量限制，但数量过大后性能也还是会下降。 
  4. 和 `select` 函数一样，`poll` 返回后，需要轮询 `pollfd` 来获取就绪的描述符。
- **缺点**：
  1. 从上面看，`select` 和 `poll` 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。
  2. 事实上，同时连接的大量客户端，在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

#### 3）epoll

`epoll` 是在 Linux 2.6 内核中提出的，是之前的 `select` 和`poll` 的增强版本。

1. 相对于 `select` 和 `poll` 来说，`epoll` 更加灵活，没有描述符限制。
2. `epoll` 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件，存放到内核的一个事件表中，这样在用户空间和内核空间只需一次的 copy。

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

##### API  - int epoll_create(int size)

1. 创建一个 `epoll` 句柄，size 用来告诉内核这个监听的数目一共有多大，这个参数不同于 `select()` 中的第一个参数，给出最大监听的 fd+1 的值，参数 size 并不是限制了 `epoll` 所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。
2. 当创建好 `epoll` 句柄后，它就会占用一个 fd 值，在 linux 下如果查看 `/proc/进程id/fd/`，是能够看到这个fd 的，所以在使用完 `epoll` 后，必须调用 `close()` 关闭，否则可能导致 fd 被耗尽。

##### API - int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)

此函数是对指定描述符 fd 执行 op 操作：

1. **epfd**：是 `epoll_create()` 的返回值。
2. **op**：表示op操作，用三个宏来表示：
   - 1）`EPOLL_CTL_ADD` ：添加对 fd 的监听事件。
   - 2）`EPOLL_CTL_DEL`：删除对 fd 的监听事件。
   - 3）`EPOLL_CTL_MOD`：修改对 fd 的监听事件。
3. **fd**：是需要监听的文件描述符 fd。
4. **epoll_event**：是告诉内核需要监听什么事，`struct epoll_event` 结构如下：

```c++
// struct epoll_event结构
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
```

##### API - int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout)

等待 `epfd` 上的 I/O 事件，最多返回 `maxevents` 个事件。

1. 参数 `events` 用来从内核得到事件的集合。
2. 参数 `maxevents` 用来告诉内核这个 `events` 有多大，这个 `maxevents` 的值不能大于创建 `epoll_create()` 时的size。
3. 参数 `timeout` 是超时时间，毫秒，0 会立即返回，-1 表示不确定，也有说法说是永久阻塞。
4. **返回值**：该函数返回需要处理的事件数目，如返回0表示已超时。

###### epoll 工作模式

`epoll` 对文件描述符的操作有两种模式：

- **LT 模式**：level trigger，水平触发模式，默认模式。

  1. 当 `epoll_wait` 检测到描述符事件发生，并将此事件通知应用程序，应用程序可以不用立即处理该事件。
  2. 在下次调用 `epoll_wait` 时，操作系统会再次响应应用程序并通知此事件

- **ET模式**：edge trigger，边缘触发模式。

  1. 当 `epoll_wait` 检测到描述符事件发生，并将此事件通知应用程序，应用程序必须立即处理该事件。
  2. 如果一直不对这个 `fd` 做 I/O 操作，内核不会发送更多的通知 (only once)，在下次调用 `epoll_wait` 时，操作系统不会再次响应应用程序通知此事件。

  => **优点**：ET 模式在很大程度上，减少了 `epoll` 事件被重复触发的次数，因此效率要比 LT 模式高。

  => **局限**：`epoll` 工作在 ET 模式时，必须使用 no-block socket 非阻塞套接口，以避免由于一个文件句柄的阻塞读、或者阻塞写操作，把处理多个文件描述符的任务饿死。

##### 4）epoll 总结

- **原理**：
  1. 在 `select` / `poll` 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描。
  2. 而 `epoll` 事先通过 `epoll_ctl()` 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 `callback` 的回调机制，迅速激活这个文件描述符，当进程调用 `epoll_wait()` 时便得到通知。
  3. 这样，`epoll` 去掉了遍历文件描述符，而是通过监听回调的的机制，这也正是 `epoll` 的魅力所在。
- **优点**：
  1. **监视的描述符数量不受限制**：`epoll` 所支持的 fd 上限，是最大可以打开文件的数目，这个数字一般远大于 2048。比如，在 1GB 内存的机器上大约为10 万左右，具体数目可以 `cat /proc/sys/fs/file-max` 察看，一般来说这个数目和系统内存关系很大。
     - `select` 的最大缺点就是，进程打开的 fd 是有数量限制的，这对于连接数量比较大的服务器来说，根本不能满足。虽然也可以选择多进程的解决方案(Apache就是这样实现的)，不过虽然 linux 上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。
  2. **I/O 效率不会随着监视 fd 的数量的增长而下降**：`epoll` 不同于 `select` 和 `poll` 轮询的方式，而是通过每个 fd 定义的回调函数来实现的，只有就绪的 fd 才会执行回调函数。

=> 如果没有大量的 idle -connection 或者 dead-connection，`epoll` 的效率并不会比 `select` / `poll` 高很多，但是当遇到大量的 idle- connection，就会发现 `epoll` 的效率大大高于 `select` / `poll`。

### 1.9. Java 复制？

#### 1）直接赋值

直接赋值， 比如在 Java 中，`A a1 = a2`，实际上复制的是引用，也就是说 `a1` 和 `a2` 指向的是同一个对象，因此，当 `a1` 变化时，`a2` 里面的成员变量也会跟着变化。

#### 2）浅复制

浅复制，指创建一个新对象时，把对象的非静态字段复制到新对象上，如果字段是值类型，则会对该字段执行复制，如果字段是引用类型，则只会复制引用不复制引用的对象，因此，原始对象及其复制后的副本，它们的引用类型属性引用属于同一个对象。

=> 通过复制引用的方式，来完成对象引用类型属性值的复制，叫做浅复制。

- **实现方式**：实现 `Cloneable` 接口，然后调用 `Object#clone()`。

  ```java
  @Test
  public void testBook() {
      Chapter chapter1 = new Chapter("第一章", 2500, 15);
      Chapter chapter2 = new Chapter("第二章", 2600, 16);
      Book book = new Book(1l, "三国演义", "罗贯中", Lists.newArrayList(chapter1, chapter2));
      
      Book cloneBook = (Book) book.clone();
      
      // false
      System.out.println(book == cloneBook);  
      // true
      System.out.println(book.getChapterList() == cloneBook.getChapterList()); 
   
      //给book对象的chapterList加一个元素，可以看到cloneBook的chapter也变化了
      book.getChapterList().add(new Chapter("第三章", 2500, 15));
      System.out.println(cloneBook.getChapterList().size()); //3
  }
  ```

#### 3）深复制

深拷贝，指不仅复制对象本身，还复制其引用类型属性所指向的对象。

- **实现方式**： 实现 `Serializable` 接口，把对象写到一个流里，再从流里读出来，可以重建对象。

  ```java
  @Test
  public void testDeepClone() throws Exception{
      Chapter chapter1 = new Chapter("第一章", 2500, 15);
      Chapter chapter2 = new Chapter("第二章", 2600, 16);
      Book book = new Book(1l, "三国演义", "罗贯中", Lists.newArrayList(chapter1, chapter2));
      
      //将对象转换为字节流写入流中
      ByteArrayOutputStream baos = new ByteArrayOutputStream();
      ObjectOutputStream oos = new ObjectOutputStream(baos);
      oos.writeObject(book);
   
      //从流里读出来
      ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
      ObjectInputStream ois = new ObjectInputStream(bais);
      Book cloneBook = (Book) ois.readObject();
      
      //关闭流
      baos.close();
      oos.close();
      bais.close();
      ois.close();
   
      /**
       * 此处如果没有实现Serializable接口，就会报错java.io.NotSerializableException
       * Library持有任何对象的类型都要实现Serializable接口，否则会报错
       */
      // false
      System.out.println(book == cloneBook);
      // false
      System.out.println(book.getChapterList() == cloneBook.getChapterList());
  }
  ```

### 2.0. Java 序列化？

- **序列化**：

  - 指将 Java 对象转化为字节序列的过程，即将对象的状态转化成字节流，然后可以通过这些值再生成相同状态的对象。
  - 对象序列化，是对象**持久化**的一种实现方法，是将对象的属性和方法转化为一种序列化的形式，用于存储和传输。

- **反序列化**：指将字节序列转化为 Java 对象的过程，即将对象字节序列重建对象的过程。

- **优点**：

  - 实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上，通常是放在文件里，比如 Redis 的RDB。
  - 利用序列化实现远程通信，即在网络上传送对象的字节序列，比如 Google 的 ProtoBuf。

- **反序列失败场景**：

  - 如果 `serialVersionUID` 不一致，会导致反序列化失败。
  - **`serialVersionUID` 作用**：
    1. 如果用户没有自己声明一个 `serialVersionUID`，接口会默认生成一个 `serialVersionUID`。
    2. 但是，强烈建议用户自定义一个 `serialVersionUID`，因为默认的 `serialVersinUID` 对于 class 的细节非常敏感，反序列化时可能会导致 `InvalidClassException` 异常。
    3. 比如说先进行序列化，然后在反序列化之前修改了类，那么就会报错，因为修改了类，对应的`serialversionUID` 也变化了，而序列化和反序列化就是通过对比其 `serialversionUID` 来进行的，一旦 `serialversionUID` 不匹配，反序列化就无法成功。

  ```java
  private static final Long serialVersionUID = 1573531233370L;
  ```

- **transient  关键字**：可以阻止所修饰的变量被序列化到文件中。 

  1. 在变量前加上 `transient`  关键字，可以阻止该变量被序列化到文件中，在被反序列
     化后，`transient` 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 
  2. 服务器端给客户端发送序列化对象数据，对象中有一些数据是敏感的，比如密码字符串
     等，希望对该密码字段在序列化时，进行加密，而客户端如果拥有解密的密钥，只有在
     客户端进行反序列化时，才可以对密码进行读取，这样可以一定程度保证序列化对象的
     数据安全。

### 2.1. 什么是 Java I/O？

- Java#I/O，是以流为基础进行数据输入输出的，所有数据被串行化出写入输出流，所谓串行化，就是数据按顺序进行输入输，简单来说就是 Java 通过 IO 流的方式和外部设备进行交互。
- 在 Java 类库中，IO 部分的内容是很庞大的，因为它涉及的领域很广泛：标准输入输出、文件的操作、网络数据传输流、字符串流、对象流等等。
- 比如程序从服务器上下载图片，就是通过流的方式，从网络上以流的方式加载到程序中，最后保存到硬盘中。

### 2.2. Java I/O 流分类？

![1646819558347](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646819558347.png)

#### 1）按照实际IO操作来分

1. **输入流**：从文件读入到内存，只能进行读操作。
2. **输出流**：从内存读出到文件，只能进行写操作。

=> **注意**：输出流可以帮助我们创建文件，而输入流不会。

#### 2）按照读写的单位大小来分

1. **字节流**：以字节为单位，每次次读入或读出是 8 位数据（一个字节占 8 bit），可以读任何类型数据，比如图片、文件、音乐视频等，在 Java 代码中，接收数据只能为 `byte[]` 。
2. **字符流**：以字符为单位，每次次读入或读出是 16 位数据（char 占两个字节），其只能读取字符类型数据，在 Java 代码中，接收数据为一般为 `char[]`。

#### 3）按照读写时是否直接与硬盘、内存等节点连接来分

1. **节点流**：直接与数据源相连，可读入或读出。
2. **处理流**：也叫**包装流**，是对一个对于已存在的流连接进行包装，通过所封装流的功能调用，以实现数据读写，比如添加个 Buffered 缓冲区的 `BufferedInputStream`。

=> **注意**：为什么要有处理流？主要作用是在读入或写出时，对数据进行缓存，以减少 I/O 次数，以便下次更好更快地读写文件，所以有了处理流。

### 2.3. Java I/O 常用实现类？

![1646820304336](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646820304336.png)

#### 1）FileReader | 字符节点输入流

```java
public class FileReaderTest {

    public static void main(String[] args) {
        FileReaderTest fileReaderTest = new FileReaderTest();
        fileReaderTest.printStr(Constant.FILE_READ_PATH);
    }

    public void printStr(String path) {
        // 读取文件
        FileReader fileReader = null;
        try {
            fileReader = new FileReader(path);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 读取文件内容
        int res = -1;
        List<Character> characterList = new ArrayList<>();
        while (true) {
            try {
                res = fileReader.read();
                if(res == -1) {
                    break;
                }
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }

            characterList.add((char) res);
        }

        // 打印文件内容
        StringBuilder sb = new StringBuilder();
        for (Character character : characterList) {
            if(character != '\r' && character != '\n') {
                sb.append(character);
            }
            if(character == '\n') {
                // HelloWorld!
                // Nice!
                // 哈喽!
                System.err.println(sb.toString());
                sb = new StringBuilder();
            }
        }

        // 关闭流
        try {
            fileReader.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

#### 2）BufferedReader | 字符处理输入流

```java
public class BufferedReaderTest {

    public static void main(String[] args) {
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_READ_PATH);
    }

    public void printStr(String path) {
        // 读取文件
        FileReader fileReader = null;
        try {
            fileReader = new FileReader(path);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedReader bufferedReader = new BufferedReader(fileReader);

        // 读取文件内容
        String str = null;
        List<String> stringList = new ArrayList<>();
        while (true) {
            try {
                str = bufferedReader.readLine();
                if(str == null) {
                    break;
                }
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }

            stringList.add(str);
        }

        // 打印文件内容
        // [HelloWorld!, Nice!, 哈喽!]
        System.err.println(stringList);

        // 关闭流
        try {
            bufferedReader.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                fileReader.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}

```

#### 3）FileWriter | 字符节点输出流

```java
public class FileWriterTest {

    public static void main(String[] args) {
        // 读取文件
        FileWriter fileWriter = null;

        try {
            // 文件不存在时则创建, true代表追加式写入
            fileWriter = new FileWriter(Constant.FILE_WRITE_PATH, true);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        }

        // 写入内容到文件
        try {
            fileWriter.write("哈喽Write!\r\n");
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 关闭流
        try {
            fileWriter.close();
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 读取并打印文件内容: [哈喽Write!, 哈喽Write!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}

```

#### 4）BufferedWriter | 字符处理输出流

```java
public class BufferedWriterTest {

    public static void main(String[] args) {
        // 读取文件
        FileWriter fileWriter = null;

        try {
            // 文件不存在时则创建, true代表追加式写入
            fileWriter = new FileWriter(Constant.FILE_WRITE_PATH, true);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedWriter bufferedWriter = new BufferedWriter(fileWriter);

        // 写入内容到文件
        try {
            bufferedWriter.write("哈喽BufferdWrite!\r\n");
        } catch (IOException e) {
            e.printStackTrace();
        }

        // 关闭流
        try {
            bufferedWriter.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                fileWriter.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

        // 读取并打印文件内容: [哈喽BufferdWrite!, 哈喽BufferdWrite!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}

```

#### 5）FileInputStream、FileOutputStream | 字节节点输入输出流

```java
public class FileInputOutTest {

    public static void main(String[] args) {
        // 读取文件
        FileInputStream fileInputStream = null;
        FileOutputStream fileOutputStream = null;
        try {
            fileInputStream = new FileInputStream(Constant.FILE_READ_PATH);

            // 文件不存在时则创建, true代表追加式写入
            fileOutputStream = new FileOutputStream(Constant.FILE_WRITE_PATH, true);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        try {
            // 读取可用空间
            byte[] bytes = new byte[fileInputStream.available()];

            // 读取流内容到bytes数组中
            fileInputStream.read(bytes);

            // 输出bytes数组到另一个文件中
            fileOutputStream.write(bytes);
        } catch (IOException e) {
            e.printStackTrace();
            return;
        } finally {
            try {
                fileOutputStream.close();
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    fileInputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }

        // 打印并读取输入后的文件结果: [哈喽BufferdWrite!, 哈喽BufferdWrite!, HelloWorld!, Nice!, 哈喽!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}

```

#### 6）BufferedInputStream、BufferedOutputStream | 字节处理输入输出流

```java
public class FileBufferdInputOutTest {

    public static void main(String[] args) {
        // 读取文件
        FileInputStream fileInputStream = null;
        FileOutputStream fileOutputStream = null;
        try {
            fileInputStream = new FileInputStream(Constant.FILE_READ_PATH);

            // 文件不存在时则创建, true代表追加式写入
            fileOutputStream = new FileOutputStream(Constant.FILE_WRITE_PATH, true);
        } catch (FileNotFoundException e) {
            e.printStackTrace();
            return;
        }

        // 节点流对接处理流: 缓冲区的作用的主要目的是, 避免每次和硬盘打交道，提高数据访问的效率
        BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream);
        BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(fileOutputStream);

        while (true) {
            try {
                int read = bufferedInputStream.read();
                if(read == -1) {
                    break;
                }

                bufferedOutputStream.write(read);
            } catch (IOException e) {
                e.printStackTrace();
                break;
            }
        }

        try {
            bufferedOutputStream.close();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            try {
                bufferedInputStream.close();
            } catch (IOException e) {
                e.printStackTrace();
            } finally {
                try {
                    fileOutputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                } finally {
                    try {
                        fileInputStream.close();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                }
            }
        }

        // 打印并读取输入后的文件结果: [哈喽BufferdWrite!, 哈喽BufferdWrite!, HelloWorld!, Nice!, 哈喽!, HelloWorld!, Nice!, 哈喽!, HelloWorld!, Nice!, 哈喽!]
        BufferedReaderTest bufferedReaderTest = new BufferedReaderTest();
        bufferedReaderTest.printStr(Constant.FILE_WRITE_PATH);
    }
}

```

### 2.4. TCP Socket API？

![1646914477436](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646914477436.png)

#### 1）服务端 - API

1. new Socket（..）：构造 Socket 对象，在 Java 中，为 `new ServerSocket() `。
2. bind（..）：绑定端口。
3. listen（）：监听端口，在 Java 中，该方法已经与 `bind（..）` 方法融为一体了。
4. accept（）：TCP 三次握手成功，则唤醒当前阻塞的线程，在 Java 中，返回一个 `Socket` 对象。
5. read（） / write（）：在 Java 中，是通过使用 `Socket` 的输入输出流来实现读取和写出。
6. close（）：关闭套接字文件描述符。

#### 2）客户端 - API

1. new Socket（..）：构造 Socket 对象，在 Java 中，为 `new Socket() ` 。
2. connect（）：连接目标服务端口，在 Java 中，该方法已经与`new Socket() ` 方法融为一体了。
3. read（） / write（）：在 Java 中，是通过使用 `Socket` 的输入输出流来实现读取和写出。
4. close（）：关闭套接字文件描述符。



### 2.5. Java BIO、NIO、AIO？

#### 1）BIO

BIO，**同步阻塞 I/O**：

1. 服务器实现一个连接一个线程，即客户端有连接请求时，服务器端就需要启动一个线程进行处理，没处理完之前，此线程不能做其他操作。
2. 如果是单线程的情况下，传输的文件很大，可以通过线程池机制改善。

=> 因此，BIO 适用于连接数目比较小、且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，是 JDK 1.4 以前的唯一选择，同时程序也直观简单、易于理解。

##### BIO Server

```java
public class BioServerTest {

    private static final AtomicInteger COUNT = new AtomicInteger(0);

    public static void start(int port) throws IOException {
        // socket
        ServerSocket server = new ServerSocket();
        // bind & listen
        server.bind(new InetSocketAddress(port));
        System.err.println("bind & listen!");

        while (true) {
            // accept
            final Socket socket = server.accept();// block!
            int count = COUNT.incrementAndGet();
            System.err.println("accept! ip=" + socket.getRemoteSocketAddress() + ", count=" + count);

            // or user thread pool
            new Thread(() -> {
                try {
                    BufferedReader in = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                    PrintWriter out = new PrintWriter(socket.getOutputStream(), true);
                    String line = in.readLine();

                    while (line != null) {
                        System.err.println("read: " + line);
                        out.println(line);
                        out.flush();
                        line = in.readLine();
                    }
                    socket.close();
                } catch (IOException e) {
                    e.printStackTrace();
                    try {
                        socket.close();
                    } catch (IOException ee) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

    }

    public static void main(String[] args) throws IOException {
        start(8084);
    }
}

```

##### BIO Client

```java
public class BioClientTest implements Cloneable {

    public static final String[] commands = new String[]{
            "hi\n",
            "i am client\n",
            "helloworld\n",
            "java and netty\n"
    };

    public static void main(String[] args) throws IOException {
        BioClientTest bioClientTest = new BioClientTest();
        try {
            Object clone = bioClientTest.clone();
        } catch (CloneNotSupportedException e) {
            e.printStackTrace();
        }

        int concurrent = 100;
        Runnable task = () -> {
            try {
                Socket socket = new Socket("127.0.0.1", 8084);
                DataOutputStream out = new DataOutputStream(socket.getOutputStream());
                for (String str : commands) {
                    out.write(str.getBytes());
                }
                out.flush();

                Thread.sleep(100);
                BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream()));
                while (br.ready()) {
                    Thread.sleep(100);
                    System.out.println(br.readLine());
                }

                socket.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        };

        ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 2, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(1024));
        for (int i = 0; i < concurrent; i++) {
            executor.execute(task);
        }
        executor.shutdown();
    }
}

```

#### 2）NIO

NIO，**同步非阻塞 I/O**：

1. 服务器实现一个连接一个线程，即客户端发送的连接请求都会注册到多路复用器上。
2. 多路复用器轮询到连接有 I/O 请求时，才会启动一个线程进行处理。

=> 因此，NIO 方式适用于连接数目多、且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，在 JDK 1.4 之后开始支持。

##### NIO Server

Selector 可以处理 4 个事件：

1. **OP_READ = 1**：读取事件。
2. **OP_WRITE = 4**：写出事件。
3. **OP_CONNECT = 8**：通道已连接事件。
4. **OP_ACCEPT = 16**：服务端套接字已准备就绪事件。

```java
public class NioServerTest {

    public static void start(int port) throws IOException {
        // non blocking
        ServerSocketChannel serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);

        // bind & listen
        InetSocketAddress address = new InetSocketAddress(port);
        serverChannel.bind(address);
        System.err.println("bind & listen");

        Selector selector = Selector.open();
        serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        System.err.println("注册事件: OP_ACCEPT");

        while (true) {
            // epoll: blocking
            selector.select();

            // OP_ACCEPT | OP_READ
            Set<SelectionKey> readyKeys = selector.selectedKeys();
            Iterator<SelectionKey> it = readyKeys.iterator();
            while (it.hasNext()) {
                SelectionKey key = it.next();

                // OP_ACCEPT: 三次握手成功, 注册读事件
                if (key.isAcceptable()) {
                    ServerSocketChannel server = (ServerSocketChannel) key.channel();
                    SocketChannel socket = server.accept();
                    System.err.println("Accept !");

                    socket.configureBlocking(false);
                    socket.register(selector, SelectionKey.OP_READ);
                    System.err.println("注册事件: OP_READ");
                } else if (key.isReadable()) {
                    SocketChannel socket = (SocketChannel) key.channel();
                    final ByteBuffer buffer = ByteBuffer.allocate(64);
                    final int bytesRead = socket.read(buffer);
                    if (bytesRead > 0) {
                        System.err.println("read: " + new String(buffer.array()).trim());
                        buffer.flip();
                        int ret = socket.write(buffer);
                        // 尝试写, 没写完则要注册写事件
//                         if (ret <=0) {
//                        	 //register op_write
//                         }
                        buffer.clear();
                    } else if (bytesRead < 0) {
                        key.cancel();
                        socket.close();
                        System.err.println("Client close");
                    }
                }

                // 从readyKeys中移除, 免得下次重新执行
                it.remove();
            }
        }
    }


    public static void main(String[] args) throws InterruptedException, IOException {
        start(8084);
    }
}	

```

#### 3）AIO

AIO，**异步非阻塞 I/O**：

1. 服务器实现模式为一个有效请求一个线程。
2. 客户端的 I/O 请求都是由操作系统先完成了，再通过回调，通知客户端应用去启动线程进行处理。

=> AIO 方式适用于连接数目多、且连接比较长（重操作）的架构，比如相册服务器，可以充分调用操作系统参与并发操作，编程比较复杂，在 JDK 1.7 之后开始支持。

- AIO 属于 NIO 包中的类实现，其实 I/O 主要分为 BIO和 NIO，AIO 只是附加品，主要是为了解决 I/O 不能异步实现的问题。
- 在以前很少有 Linux 系统支持 AIO，Windows 的 IOCP 就是此 AIO 模型，但是现在的服务器一般都是支持AIO 操作。

#### 4）总结

1. BIO 是阻塞的，NIO 是非阻塞的。
2. BIO 是面向流的，只能单向读写，NIO 是面向缓冲的, 可以双向读写。
   - 使用 BIO 做 Socket 连接时，由于单向读写，当没有数据时，会挂起当前线程，阻塞等待，为防止影响其它连接,需要为每个连接新建线程处理，然而系统资源是有限的，不能过多的新建线程，线程过多带来线程上下文的切换，从来带来更大的性能损耗，因此需要使用 NIO 进行 BIO 多路复用，使用一个线程来监听所有 Socket连接，使用本线程或者其他线程处理连接。
3. AIO 以非阻塞的异步方式发起 I/O 操作，当 I/O 操作进行后，自己可以去做其他操作，由操作系统内核空间提醒 I/O 操作已完成。

### 2.6. Java IO 设计模式？

在高性能 I/O 设计中，有两个比较著名的模式，Reactor 和 Proactor 模式，其中 Reactor 模式用于同步 I/O，而 Proactor 运用于异步 I/O 操作。

#### Reactor 模式

Reactor 模式，应用于同步 I/O 场景，以 read 操作为例，Reactor 中的具体步骤为：

1. 应用程序注册 `读就绪` 事件和相关联的事件处理器。
2. 事件分离器等待事件的发生。
3. 当发生 `读就绪` 事件时，事件分离器调用第一步注册的事件处理器
4. 事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理。

![1646831826891](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831826891.png)

##### 1）单 Reactor 单线程模式

###### Reactor NIO 原型实现

1. 在 NIO Server 的基础上，抽取了一个 `ChannelHandler`，用于处理连接和读取事件。
2. 以及分离了连接和读取事件所实现的位置，分别丢给 `Accept ChannelHandler` 和 `Read ChannelHandler`  来处理，以实现业务解耦。
3. 这就是 Reactor 的思路原型，其中还有很多地方可以继续抽象优化的~

```java
public class BaseReactorServer {

    interface ChannelHandler {
        void onRead(SocketChannel channel) throws Exception;
        void onAccept();
    }

    public static void start(int port) throws Exception {
        // non blocking
        final ServerSocketChannel serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);

        //bind & listen
        InetSocketAddress address = new InetSocketAddress(port);
        serverChannel.bind(address);

        final Selector selector = Selector.open();
        SelectionKey selectionKey = serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        System.err.println("注册事件: OP_ACCEPT");

        // Acceptor: 绑定OP_ACCEPT
        selectionKey.attach(new ChannelHandler() {
            public void onRead(SocketChannel channel) {

            }

            // ChannelHandler: 绑定OP_READ
            public void onAccept() {
                try {
                    SocketChannel socket = serverChannel.accept();
                    System.out.println("Accept !");
                    socket.configureBlocking(false);
                    SelectionKey sk = socket.register(selector, SelectionKey.OP_READ);

                    // 绑定
                    sk.attach(new ChannelHandler() {
                        public void onRead(SocketChannel socket) throws IOException {
                            final ByteBuffer buffer = ByteBuffer.allocate(256);
                            final int bytesRead = socket.read(buffer);

                            // Worker
                            if (bytesRead > 0) {
                                // 读
                                String readRes = new String(buffer.array()).trim();
                                System.err.println("read: " + readRes);

                                // 模拟业务执行过久
                                doBusiness(500, readRes);

                                // 写
                                buffer.flip();
                                socket.write(buffer);
                                buffer.clear();
                            } else if (bytesRead < 0) {
                                socket.close();
                                System.out.println("Client close");
                            }
                        }

                        public void onAccept() {

                        }

                        // 模拟业务执行过久
                        private void doBusiness(long time, String readRes) {
                            System.err.println("测试业务处理: time=" + time);
                            try {
                                Thread.sleep(time);
                            } catch (InterruptedException e) {
                                e.printStackTrace();
                            }
                        }
                    });
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        });

        while (true) {
            selector.select();
            Set<SelectionKey> readyKeys = selector.selectedKeys();
            Iterator<SelectionKey> it = readyKeys.iterator();
            while (it.hasNext()) {
                SelectionKey key = it.next();
                ChannelHandler handler = (ChannelHandler) key.attachment();
                System.err.println(String.format("handler: %s", handler));

                // OP_ACCEPT
                if (key.isAcceptable()) {
                    handler.onAccept();
                }
                // OP_READ
                else if (key.isReadable()) {
                    handler.onRead((SocketChannel) key.channel());
                }

                // 从readyKeys中移除, 免得下次重新执行
                it.remove();
            }
        }

    }

    public static void main(String[] args) throws Exception {
        start(8084);
    }
}

```

###### Reactor 架构图实现

Reactor 又称之为响应器模式，常用于 NIO 网络通信框架，其单线程服务架构图如下，不同于传统 I/O 的串行调度方式，NIO 把整个服务请求分为五个阶段：

1. **read**：接收到请求，读取数据。
2. **decode**：解码数据。
3. **compute**：业务逻辑处理。
4. **encode**：编码返回数据。
5. **send**：返回数据。

![1646831937063](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831937063.png)

1. `selector.select()` 是前面 NIO#API （多路复用模型），可以实现一个阻塞对象监听多路的连接请求。
2. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后通过 `dispatch()` 进行分发。
3. 如果是建立连接请求事件，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理连接完成后的后续业务处理。
4. 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应。
5. `Handler` 会完成 `read()` -> `doBusiness()` 业务处理 -> `send()` 一个完整的业务流程。

- **优点**：服务器使用一个线程，通过多路复用搞定所有 I/O 操作（包括连接、读、写等），编码简单，清晰明了，但如果客户端连接数量较多，将无法支撑。
- **缺点**：
  1. **性能问题**：只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上业务时，整个进程无法处理其它连接事件，容易导致性能瓶颈。
  2. **可靠性问题**：线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

```java
/**
 * 1、单Reactor单线程
 */
public class AaReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public AaReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.selector, this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("Waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            AaReactorServer aaReactorServer = new AaReactorServer(8084);
            aaReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public Acceptor(Selector selector, ServerSocketChannel serverSocketChannel) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // ChannelHandler: 绑定OP_READ
            SelectionKey selectionKey = socketChannel.register(this.selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 唤醒一个阻塞的selector
            this.selector.wakeup();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    int state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = 0;
    }

    @Override
    public void run() {
        try {
            // 读取
            if(this.state == 0) {
                read();
            }
            // 返回
            else {
                send();
            }
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    private synchronized void read() throws IOException {
        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = this.socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            // 执行业务处理
            doBusiness(str);
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 读取 -> 返回
            this.state = 1;
            this.selectionKey.interestOps(SelectionKey.OP_WRITE);

            // 唤醒一个阻塞的selector
            selectionKey.selector().wakeup();
        }
    }

    private void doBusiness(String str) {
        System.err.println("执行业务处理...");
    }

    private void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private void send() throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        this.state = 0;
        this.selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}

```

##### 2）单 Reactor 多线程模式

![1646889343446](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889343446.png)

1. `Reactor` 对象通过 `selector.select()` 监控客户端请求事件，收到事件后，通过 `dispatch()` 进行分发。
2. 如果是建立连接请求，则由 `Acceptor` 通过 `serverSocketChannel.accept()` 处理连接请求，然后创建一个 `Handler` 对象，来处理完成连接后的各种事件。
3. 如果不是连接请求，则由 `Reactor` 对象分发调用连接对应的 `Handler` 来处理。
4. 此时，`Handler` 只负责读取和响应事件，不做具体的业务处理，通过 `read()` 读取数据后，会分发给后面的 `Worker` 线程池的某个线程进行处理业务。
5. `Worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `Handler`。
6. `Handler` 收到线程池处理完的结果后，通过 `send()` 将结果返回给 Client。

- **优点**：可以充分利用多核 CPU 的处理能力。
- **缺点**：
  1. 多线程在需要数据共享时，可能实现比较复杂。
  2. Reactor 单线程处理完所有的监听、连接、读、写事件，在高并发场景下，容易出现性能瓶颈。

```java
/**
 * 1、单Reactor多线程
 */
public class AbReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public AbReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.selector, this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("Waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            AbReactorServer abReactorServer = new AbReactorServer(8084);
            abReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public Acceptor(Selector selector, ServerSocketChannel serverSocketChannel) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // ChannelHandler: 绑定OP_READ
            SelectionKey selectionKey = socketChannel.register(this.selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 唤醒一个阻塞的selector
            this.selector.wakeup();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private static final int DEFAULT_THREAD_COUNT = 4;
    private static final int MAX_THREAD_COUNT = 8;
    private static final ThreadPoolExecutor POOL = new ThreadPoolExecutor(
            DEFAULT_THREAD_COUNT,
            MAX_THREAD_COUNT,
            10,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1024)
    );

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    private HandlerState state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = new ReadState();
    }

    @Override
    public void run() {
        try {
            state.handle(this, this.selectionKey, this.socketChannel, POOL);
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    public void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void setState(HandlerState state) {
        this.state = state;
    }
}

/**
 * 4、状态
 */
public interface HandlerState {

    /**
     * 状态处理事件
     *
     * @param handler
     * @param selectionKey
     * @param socketChannel
     * @param pool
     */
    void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException;
}

/**
 * 5、读取状态
 */
public class ReadState implements HandlerState {

    private SelectionKey selectionKey;

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        this.selectionKey = selectionKey;

        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            handler.closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 开始处理业务
            handler.setState(new WorkState(str, handler, selectionKey, socketChannel, pool));
        }
    }
}

/**
 * 6、工作状态
 */
public class WorkState implements HandlerState {

    private String readResult;
    private SelectionKey selectionKey;

    public WorkState(String readResult, ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) {
        this.readResult = readResult;
        this.selectionKey = selectionKey;

        try {
            this.handle(handler, selectionKey, socketChannel, pool);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        pool.execute(new WorkerThread(handler, this.readResult));
    }

    private synchronized void change2WriteState(ChannelHandler handler, String str) {
        // 读取 -> 返回
        handler.setState(new WriteState());
        this.selectionKey.interestOps(SelectionKey.OP_WRITE);

        // 唤醒一个阻塞的selector
        this.selectionKey.selector().wakeup();
    }

    class WorkerThread implements Runnable {

        private ChannelHandler handler;
        private String str;

        public WorkerThread(ChannelHandler handler, String str) {
            this.handler = handler;
            this.str = str;
        }

        @Override
        public void run() {
            // 执行业务处理
            doBusiness(str);
            change2WriteState(this.handler, this.str);
        }

        private void doBusiness(String str) {
            System.err.println("执行业务处理...");
        }
    }
}

/**
 * 7、返回状态
 */
public class WriteState implements HandlerState {

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        handler.setState(new ReadState());
        selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}

```

##### 3）主从 Reactor 多线程模式

![1646889441630](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646889441630.png)

1. `Reactor` 主线程 `MainReactor` 对象，通过 `selector.select()` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件。
2. 当 `Acceptor` 处理连接事件后，`MainReactor` 轮训式地将连接分配给 `SubReactor`，其中，`Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainReactor` 可以关联多个 `SubReactor`。
3. `SubReactor` 将连接加入到连接队列进行监听，并创建 `Handler` 进行各种事件处理。
4. 当有新事件发生时，`SubReactor` 就会调用对应的 `Handler` 进行处理。
5. `Handler` 通过 `read()` 读取数据，分发给后面线程池中的 `Worker` 线程进行处理。
6. `Worker` 线程池会分配独立的 worker 线程进行业务处理，并返回结果。
7. `Handler` 收到处理结果后，再通过 `send()` 将结果返回给 Client。

- **优点**：
  1. 父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  2. 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
- **缺点**：编程复杂度较高。

=> 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

```java
/**
 * 1、主从Reactor
 */
public class BbReactorServer implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;

    public BbReactorServer(int port) throws IOException {
        // non blocking
        this.serverSocketChannel = ServerSocketChannel.open();
        this.serverSocketChannel.configureBlocking(false);

        // listen & bind
        this.serverSocketChannel.socket().bind(new InetSocketAddress(port));

        // Acceptor: 绑定OP_ACCEPT, 主selector用于处理连接
        this.selector = Selector.open();
        SelectionKey selectionKey = this.serverSocketChannel.register(this.selector, SelectionKey.OP_ACCEPT);
        selectionKey.attach(new Acceptor(this.serverSocketChannel));
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            System.out.println("MainReactor waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    public static void main(String[] args) {
        try {
            BbReactorServer bbReactorServer = new BbReactorServer(8084);
            bbReactorServer.run();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 2、Acceptor
 */
public class Acceptor implements Runnable {

    private static final int CORES = Runtime.getRuntime().availableProcessors();
    private final ServerSocketChannel serverSocketChannel;
    private final Selector[] selectors = new Selector[CORES];
    private int selIndex = 0;
    private SubReactor[] subReactors = new SubReactor[CORES];
    private Thread[] threads = new Thread[CORES];

    public Acceptor(ServerSocketChannel serverSocketChannel) throws IOException {
        this.serverSocketChannel = serverSocketChannel;

        // 创建多个selector, 以及多个SubReactor线程
        for (int i = 0; i < CORES; i++) {
            this.selectors[i] = Selector.open();
            this.subReactors[i] = new SubReactor(this.selectors[i], serverSocketChannel, i);
            this.threads[i] = new Thread(this.subReactors[i]);
            this.threads[i].start();
        }
    }

    @Override
    public void run() {
        try {
            // OP_ACCEPT
            SocketChannel socketChannel = this.serverSocketChannel.accept();
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + " is connected...");

            // non blocking
            socketChannel.configureBlocking(false);

            // 暂停SubReactor线程, 停止轮训
            SubReactor subReactor = this.subReactors[this.selIndex];
            Selector selector = this.selectors[this.selIndex];
            Thread thread = this.threads[this.selIndex];
            subReactor.setRestart(true);

            // 唤醒一个阻塞的selector
            selector.wakeup();

            // ChannelHandler: 绑定OP_READ, 从selector用于处理读取、返回
            SelectionKey selectionKey = socketChannel.register(selector, SelectionKey.OP_READ);
            selectionKey.attach(new ChannelHandler(selectionKey, socketChannel));

            // 重启SubReactor线程, 只有为false才会继续轮训
            subReactor.setRestart(false);
            LockSupport.unpark(thread);

            // 轮训重置selIndex
            if(++this.selIndex == this.selectors.length) {
                this.selIndex = 0;
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

/**
 * 3、子Reactor
 */
public class SubReactor implements Runnable {

    private final ServerSocketChannel serverSocketChannel;
    private final Selector selector;
    private volatile boolean restart = false;
    private int num;

    public SubReactor(Selector selector, ServerSocketChannel serverSocketChannel, int num) {
        this.serverSocketChannel = serverSocketChannel;
        this.selector = selector;
        this.num = num;
    }

    @Override
    public void run() {
        while(!Thread.interrupted()) {
            if(this.restart) {
                LockSupport.park();
            }

            System.out.println("SubReactor"+ this.num + " waiting for new event on port: " + this.serverSocketChannel.socket().getLocalPort() + "...");
            try {
                // 如果没有事件发生, 则继续自旋
                if(this.selector.select() == 0) {
                    continue;
                }
            } catch (IOException e) {
                e.printStackTrace();
            }

            // 有事件发生, 则取出所有发生的事件
            Set<SelectionKey> selectionKeys = this.selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                // 根据事件进行派发
                dispatch(iterator.next());

                // 派发完毕, 从selectionKeys中移除, 免得下次重新执行
                iterator.remove();
            }
        }
    }

    // 根据事件进行派发
    private void dispatch(SelectionKey key) {
        // 根据key绑定的对象, 开辟新线程
        Runnable runnable = (Runnable) key.attachment();
        if(runnable != null) {
            runnable.run();
        }
    }

    // 重启SubReactor线程, 只有为false才会继续轮训
    public void setRestart(boolean restart) {
        this.restart = restart;
    }
}

/**
 * 4、ChannelHandler
 */
public class ChannelHandler implements Runnable {

    private static final int DEFAULT_THREAD_COUNT = 4;
    private static final int MAX_THREAD_COUNT = 8;
    private static final ThreadPoolExecutor POOL = new ThreadPoolExecutor(
            DEFAULT_THREAD_COUNT,
            MAX_THREAD_COUNT,
            10,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue<>(1024)
    );

    private final SelectionKey selectionKey;
    private final SocketChannel socketChannel;
    private HandlerState state;

    public ChannelHandler(SelectionKey selectionKey, SocketChannel socketChannel) {
        this.selectionKey = selectionKey;
        this.socketChannel = socketChannel;

        // 初始默认为read状态
        state = new ReadState();
    }

    @Override
    public void run() {
        try {
            state.handle(this, this.selectionKey, this.socketChannel, POOL);
        } catch (IOException e) {
            System.out.println("Waring! A Client has been closed...");
            closeChannel();
        }
    }

    public void closeChannel() {
        selectionKey.cancel();
        try {
            socketChannel.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public void setState(HandlerState state) {
        this.state = state;
    }
}

/**
 * 5、状态
 */
public interface HandlerState {

    /**
     * 状态处理事件
     *
     * @param handler
     * @param selectionKey
     * @param socketChannel
     * @param pool
     */
    void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException;
}

/**
 * 6、读取状态
 */
public class ReadState implements HandlerState {

    private SelectionKey selectionKey;

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        this.selectionKey = selectionKey;

        // non-blocking下不可用Readers, 因为Readers不支持non-blocking
        byte[] bytes = new byte[1024];
        ByteBuffer byteBuffer = ByteBuffer.wrap(bytes);

        // 读取字符串
        int numReadBytes = socketChannel.read(byteBuffer);
        if(numReadBytes == -1) {
            System.out.println("Warning! A client has bean closed...");
            handler.closeChannel();
            return;
        }

        // byte[] => String
        String str = new String(bytes);
        if(!"".equals(str)) {
            System.out.println(socketChannel.socket().getRemoteSocketAddress().toString() + ">" + str);

            // 开始处理业务
            handler.setState(new WorkState(str, handler, selectionKey, socketChannel, pool));
        }
    }
}

/**
 * 7、工作状态
 */
public class WorkState implements HandlerState {

    private String readResult;
    private SelectionKey selectionKey;

    public WorkState(String readResult, ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) {
        this.readResult = readResult;
        this.selectionKey = selectionKey;

        try {
            this.handle(handler, selectionKey, socketChannel, pool);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        pool.execute(new WorkerThread(handler, this.readResult));
    }

    private synchronized void change2WriteState(ChannelHandler handler, String str) {
        // 读取 -> 返回
        handler.setState(new WriteState());
        this.selectionKey.interestOps(SelectionKey.OP_WRITE);

        // 唤醒一个阻塞的selector
        this.selectionKey.selector().wakeup();
    }

    // 工作线程用于处理业务逻辑
    class WorkerThread implements Runnable {

        private ChannelHandler handler;
        private String str;

        public WorkerThread(ChannelHandler handler, String str) {
            this.handler = handler;
            this.str = str;
        }

        @Override
        public void run() {
            // 执行业务处理
            doBusiness(str);
            change2WriteState(this.handler, this.str);
        }

        private void doBusiness(String str) {
            System.err.println("执行业务处理...");
        }
    }
}

/**
 * 8、返回状态
 */
public class WriteState implements HandlerState {

    @Override
    public void handle(ChannelHandler handler, SelectionKey selectionKey, SocketChannel socketChannel, ThreadPoolExecutor pool) throws IOException {
        // 返回数据
        String str = "Your message has sent to " + socketChannel.socket().getLocalSocketAddress().toString() + "\r\n";
        ByteBuffer byteBuffer = ByteBuffer.wrap(str.getBytes());
        while (byteBuffer.hasRemaining()) {
            socketChannel.write(byteBuffer);
        }

        // 返回 -> 读取
        handler.setState(new ReadState());
        selectionKey.interestOps(SelectionKey.OP_READ);

        // 唤醒一个阻塞的selector
        selectionKey.selector().wakeup();
    }
}

```

##### Reactor 模式总结

| Reactor 线程模型    | 比喻                                           |
| ------------------- | ---------------------------------------------- |
| 单 Reactor 单线程   | 前台接待员和服务员都是同一个人，全程为顾客服务 |
| 单 Reactor 多线程   | 1 个前台接待员，多个服务员，接待员只负责接待   |
| 主从 Reactor 多线程 | 多个前台接待员，多个服务生                     |

**Reactor 优点**：

1. 响应快，不必被单个同步时间所阻塞，虽然 Reactor 本身依然是同步的。
2. 可以最大程度地避免复杂了多线程及同步问题，并且避免了多线程 / 进程切换的开销。
3. 扩展性好，可以方便的通过增加 Reactor 实例个数，来充分利用 CPU 资源。
4. 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。

#### Proactor 模式

Proactor 模式 read 操作过程为：

1. 应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注 `读取就绪` 事件，而是关注 `读完成` 事件，这是区别于 Reactor 的关键。
2. 事件分离器等待 `读完成` 事件。
3. 在事件分离器等待 `读完成` 时，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中，这也是区别于 Reactor的一点，Proactor 中，应用程序**需传递缓存区**。
4. 事件分离器捕获到 `读完成` 事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。
5. 而 Proactor 中的 write 操作和 read 操作类似，即感兴趣的事件是 `写完成` 事件。

![1646831843451](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646831843451.png)

=> 从上面可以看出，Reactor 和 Proactor 模式的主要区别就是，真正的读取和写入操作是由谁来完成的，Reactor 中需要应用程序自己读取或者写入数据，而 Proactor 模式中，应用程序不需要进行实际的读写过程，只需要从缓存区读取或者写入即可，操作系统会写入缓存区或者从缓存区读取并写入到真正的 I/O 设备中。

### 2.7. 什么是 Netty？

- **概念**：Netty 是一个 基于 JAVA NIO 实现的高性能、异步事件驱动的 NIO 框架。
- **原理**：它提供了对TCP、UDP 和文件传输的支持，作为一个异步实现的 NIO 框架，Netty 的所有 I/O 操作都是异步非阻塞的，通过 `Future-Listener` 机制，用户可以方便地主动获取，或者通过通知机制获得 I/O 操作结果。 
- **高性能原理**：
  1. **I/O 多路复用**：见 I/O 多路复用模型。
  2. **Reactor 线程模型**：见主从 Reactor 模型。
  3. **零拷贝机制**：
     1. Netty 接收和发送的 ByteBuffer，底层采用`DirectBuffers` 使用堆外内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。
     2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行Socket读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
     3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
        方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
        Buffer。 
     4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
        避免了传统通过循环 `write()`方式导致的内存拷贝问题。
  4. **高性能的序列化框架**：Netty 默认提供了对 Google Protobuf 的支持，通过扩展 Netty 的编解码接口，用户可以自定义实现其它的高性能序列化框架，比如 Thrift 的压缩二进制编解码框架等。 

### 2.8. Netty 快速入门？

Netty 实现通信的步骤：（客户端与服务端基本一致）

1. 先创建 2 个 NIO 线程组，一个专门用于网络事件的处理（接受客户端的连接），另一个则进行网络通信读写。
2. 然后，创建一个 `ServerBootStrap` 对象，配置 Netty 的一些列参数，比如接受传出数据的缓存大小等等。
3. 接着，创建一个实际处理数据的 `ChannelInitializer` 类，进行初始化的准备工作，比如设置接受传出数据的字符集、格式、实际处理数据的 `ChannelHandler` 等。
4. 最后，绑定接口，执行同步阻塞方法，等待服务端启动即可。

#### 1、NettyServer

```java
/**
 * 1、NettyServer
 */
public class NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 指定连接超时时间
                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000)
                // 2.4. TCP不允许延迟, 通信不延迟
                .option(ChannelOption.TCP_NODELAY, true)
                // 2.5. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.6. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.6.1. 设置接收缓冲区自动扩容, 已弃用
//                .option(ChannelOption.RCVBUF_ALLOCATOR, AdaptiveRecvByteBufAllocator.DEFAULT)
                // 2.6.2. 设置发送缓冲区使用对象池, 重用缓冲区
//                .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT)
                // 2.7. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.7.1. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}

```

#### 2、NettyServerHandler

```java
/**
 * 2、NettyServerHandler
 */
public class NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 获取TCP包缓冲区数据
        ByteBuf byteBuf = (ByteBuf) msg;

        // 2. 根据缓冲数据大小构造字节数组
        byte[] bytes = new byte[byteBuf.readableBytes()];

        // 3. 读取到缓冲区数据到字节数组中
        byteBuf.readBytes(bytes);

        // 4. 使用UTF-8编码解码字节数组成字符串
        String body = new String(bytes, "utf-8");
        System.err.println("Netty server: " + body);

        // 5. 构造响应体给客户端 => 测试与客户端的交互
        String response = "Netty server ack: " + body;
        ctx.writeAndFlush(Unpooled.copiedBuffer(response.getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}

```

#### 3、NettyClient

```java
/**
 * 3、NettyClient
 */
public class NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 指定连接超时时间
                .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 3000)
                // 2.4. TCP不允许延迟, 通信不延迟
                .option(ChannelOption.TCP_NODELAY, true)
                // 2.5. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.6. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.7. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.7.1. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("Hello netty!".getBytes()));

        // 5. 睡眠10秒钟后再发送一条数据到服务端
        Thread.sleep(10000);
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("Hello netty again!".getBytes()));

        // 6. 同步阻塞5s, 再关闭监听并释放资源
        cf.channel().closeFuture().await(5, TimeUnit.SECONDS);
        
        // 7. 释放资源
        workGroup.shutdownGracefully();
    }
}


```

#### 4、ClientHandler

```java
/**
 * 4、ClientHandler
 */
public class NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 获取TCP包缓冲区数据
            ByteBuf byteBuf = (ByteBuf) msg;

            // 2. 根据缓冲数据大小构造字节数组
            byte[] bytes = new byte[byteBuf.readableBytes()];

            // 3. 读取到缓冲区数据到字节数组中
            byteBuf.readBytes(bytes);

            // 4. 使用UTF-8编码解码字节数组成字符串
            String body = new String(bytes, "utf-8");

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client receive ack: " + body);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}

```

### 2.9. RPC、HTTP、MQ、Netty？

| 技术  | 应用场景                                          |
| ----- | ------------------------------------------------- |
| RPC   | 系统间即时访问、同步服务调用                      |
| HTTP  | 外部接口 API 提供、非高并发场景、非大数据报文传输 |
| MQ    | 微服务之间解耦、流量削峰                          |
| Netty | 底层基础通信、数据传输、数据同步                  |

### 3.0 Netty 核心组件？

#### 1）Channel

Channel，通道，连接是单向的，**通道双向的**，是Java NIO 的一个基本构造，可以看作是传入或传出数据的载体，它可以被打开或关闭，连接或者断开连接。以下是常用的 Channel 有 `EmbeddedChannel` 、`LocalServerChannel` 、`NioDatagramChannel` 、`NioSctpChannel` 、`NioSocketChannel`。

#### 2）Future 

1. Netty 中所有的 I/O 操作都是异步的，一个操作可能不会立即返回，可以在之后的某个时间点确定其结果的方法。
2. 和 `Handler` 回调 是相互补充的机制，提供了另一种在操作完成时通知应用程序的方式，可以看作是一个异步操作结果的占位符，将在未来的某个时刻完成，并提供对其结果的访问。
3. Netty 提供了 `ChannelFuture`，用于在执行异步操作的时候使用，每个 Netty 的 I/O 操作都会返回一个`ChannelFuture`。
4. `ChannelFuture` 能够注册一个或者多个 `ChannelFutureListener` 实例，监听器的回调方法`operationComplete()` 将会在对应的操作完成时被调用。

#### 3）ChannelHandler

1. Netty 的主要组件是 ChannelHandler，它负责所有处理出入站数据的逻辑处理。
2. Netty 使用不同的事件，来通知操作状态的改变，每个事件都可以被分发给 ChannelHandler 类中某个用户自定义实现的方法中。
3. Netty 还提供了大量预定义的、可以开箱即用的 ChannelHandler 实现，包括用于各种协议的ChannelHandler。

#### 4）ChannelPipeline

1. ChannelPipeline 提供了 ChannelHandler 链的容器，并定义了用于在该链上传播入站和出站事件流的 API，在应用程序的初始化、或者引导阶段被安装。
2. 这可以使事件流经 ChannelPipeline 时，让 ChannelHandler 进行相关工作，然后将数据传递给链中的下一个 ChannelHandler。

![1646917753469](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646917753469.png)

#### 5）EventLoop

1. EventLoop 定义了 Netty 的核心抽象，用来处理连接的生命周期中所发生的事件，在内部，将会为每个Channel 分配一个 EventLoop 。
2. EventLoop 本身只由一个线程驱动，其处理了一个 Channel 的所有 I/O 事件，并且在该 EventLoop 的整个生命周期内都不会改变。
3. EventLoop 的管理是通过 EventLoopGroup 来实现的。

![1646918023384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918023384.png)

#### 6）BootStarp、ServerBootstrap 

1. BootStarp 和 ServerBootstrap 被称为引导类，指对应用程序进行配置，并使他运行起来的过程。

2. BootStrap 是客户端的引导类，Bootstrap 在调用 `bind()`（连接UDP）和 `connect()`（连接TCP）方法时，会新创建一个 Channel，仅创建一个单独的、没有父 Channel 的 Channel 来实现所有的网络交换，只需要一个 EventLoopGroup。

   ![1646918238983](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918238983.png)

3. ServerBootstrap 是服务端的引导类，ServerBootstarp 在调用 `bind()` 方法时，会创建一个 ServerChannel 来接受来自客户端的连接，并且该 ServerChannel 管理了多个子 Channel，用于同客户端之间的通信，通常需要两个 EventLoopGroup，一个用来接收客户端连接，一个用来处理 I/O 事件。

   ![1646918257373](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1646918257373.png)

#### 7）ByteBuffer

1. Netty 接收和发送的 ByteBuffer，底层采用`DirectBuffers` 使用堆外内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。
2. 如果使用传统的堆内存 `HEAP BUFFERS` 进行Socket读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中，此时相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
3. Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样
   方便，对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式，将几个小 Buffer 合并成一个大的
   Buffer。 
4. Netty 文件传输采用了 `transferTo()` 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，
   避免了传统通过循环 `write()`方式导致的内存拷贝问题。
5. 

### 3.1. Netty 拆包粘包问题？

#### TCP 拆包粘包机制

1. 由于 TCP 是基于流的协议，本身没有界限，没有任何分界线，它不会理解上层数据包的含义。
2. 所以，一个上层的数据包可能会被拆成多个包，分批发送，这就是**拆包问题**。
3. 同理，多个上层小的数据包也能会被合成一个大包，一起发送，这就是**粘包问题**。

#### 问题产生原因

1. 应用程序写入的字节大小，大于套接字发送缓冲区的大小。
2. 进行 MSS 大小的 TCP 分段、以太网帧的 payload 大于 MTU 进行 IP 分片等。

#### 业务主流解决方案

1. **消息定长**：比如，每个报文大小固定为 200 个字节，如果不够，则用空格补位。
2. **在包尾添加特殊字符进行分割**：比如加回车符等。
3. **消息分为消息头 Header 和消息体 Body**：在消息头中包含表示消息总长度的字段，然后根据长度去读取消息体，再进行业务处理。
   - 用得最多，比如自定义协议栈。

##### 1）Netty 消息定长解决方案 | FixedLengthFrameDecoder

###### 1、NettyServer

```java
/**
 * 测试Netty: 服务端, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.4. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.5. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.5.1. 测试消息定长, 空格补位解决TCP拆包/粘包问题 => 定长5个字符
                        ch.pipeline().addLast(new FixedLengthFrameDecoder(5));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.5.3. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg1NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}

```

###### 2、NettyServerHandler

```java
/**
 * 测试Netty: 服务端业务处理器, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 使用了Netty String解码器后, 可以直接转换成String类型
        String body = (String) msg;
        System.err.println("Netty server: " + body);

        // 2. 构造响应体给客户端 => 测试与客户端的交互
        ctx.writeAndFlush(Unpooled.copiedBuffer(body.getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}

```

###### 3、NettyClient

```java
/**
 * 测试Netty: 客户端, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试消息定长, 空格补位解决TCP拆包/粘包问题 => 定长5个字符
                        ch.pipeline().addLast(new FixedLengthFrameDecoder(5));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.3.2. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg1NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端 => 5个a, 5个b
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("aaaaabbbbb".getBytes()));

        // 5. 睡眠10秒钟后再发送一条数据到服务端、
        System.err.println("睡10s...");
        Thread.sleep(10000);
//        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ccccccc   ".getBytes()));// => 7个c + 3个空格 => 后面2个c和3个空格可以发送
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ccccccc".getBytes()));// => 7个c + 没有空格补位 => 后面2个c不可以发送

        // 5.1. 再睡眠10秒钟后再发送一条数据到服务端
        System.err.println("再睡10s...");
        Thread.sleep(10000);
        channelFuture.channel().writeAndFlush(Unpooled.copiedBuffer("ddd".getBytes()));// => 3个d, 凑够5个字符 => 之前残留的2个c在缓冲区中, 凑了3个d凑够5个字符后, 可以一起发送出去

        // 6. 阻塞的方式等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 7. 释放资源
        workGroup.shutdownGracefully();
    }
}

```

###### 4、ClientHandler

```java
/**
 * 测试Netty: 客户端业务处理器, 测试消息定长方式解决TCP拆包/粘包问题
 */
public class Pkg1NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 使用了Netty String解码器后, 可以直接转换成String类型
            String response = (String) msg;

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client: " + response);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}

```

##### 2）Netty 特殊字符解决方案 | DelimiterBasedFrameDecoder

###### 1、NettyServer

```java
/**
 * 测试Netty: 服务端, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyServer {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建两个线程组: 一个是用于处理服务端接收客户端连接, 一个用于进行网络通信(即网络读写)
        NioEventLoopGroup parentGroup = new NioEventLoopGroup();
        NioEventLoopGroup childGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 用于服务器通道的一系列配置
        ServerBootstrap serverBootstrap = new ServerBootstrap();
        serverBootstrap
                // 2.1. 绑定两个线程组, 父子线程组
                .group(parentGroup, childGroup)
                // 2.2. 指定NIO模式, 因为是Server端, 所以要绑定NioServerSocketChannel
                .channel(NioServerSocketChannel.class)
                // 2.3. 设置TCP缓冲区大小 eg => 32M = sync队列 + accept队列
                .option(ChannelOption.SO_BACKLOG, 32 * 1024)
                // 2.4. 设置接收缓冲区大小
                .option(ChannelOption.SO_RCVBUF, 32 * 1024)
                // 2.5. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .childHandler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试特殊字符方式解决TCP拆包/粘包问题, 以"$_"结尾作为分割符(只要收到$_,就认为到这里就是一个数据包), 最大帧长1024bit
                        ByteBuf delimiterBuf = Unpooled.copiedBuffer("$_".getBytes());
                        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiterBuf));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.5.3. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg2NettyServerHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口 => 同步阻塞
        ChannelFuture channelFuture = serverBootstrap.bind(8765).sync();

        // 4. 同步阻塞等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 5. 释放资源
        parentGroup.shutdownGracefully();
        childGroup.shutdownGracefully();
    }
}

```

###### 2、NettyServerHandler

```java
/**
 * 测试Netty: 服务端业务处理器, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyServerHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 收到客户端连接则进行处理
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 1. 使用了Netty String解码器后, 可以直接转换成String类型
        String body = (String) msg;
        System.err.println("Netty server: " + body);

        // 2. 构造响应体给客户端 => 测试与客户端的交互
        ctx.writeAndFlush(Unpooled.copiedBuffer(("服务器响应: " + body + "$_").getBytes()));
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        super.exceptionCaught(ctx, cause);
    }
}

```

###### 3、NettyClient

```java
/**
 * 测试Netty: 客户端, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyClient {

    public static void main(String[] args) throws InterruptedException {
        // 1. 创建一个线程组: 只需要一个线程组用于实际业务的处理(网络通信的读写)
        NioEventLoopGroup workGroup = new NioEventLoopGroup();

        // 2. 创建辅助配置工具类, 进行配置响应的参数 => 用于构造Client
        Bootstrap bootstrap = new Bootstrap();
        bootstrap
                // 2.1. 绑定线程组
                .group(workGroup)
                // 2.2. 指定NIO模式, 因为是Client端, 所以要绑定NioSocketChannel
                .channel(NioSocketChannel.class)
                // 2.3. 进行初始化ChannelInitializer , 用于构建双向链表 "pipeline" 添加业务handler处理
                .handler(new ChannelInitializer<SocketChannel>() {
                    @Override
                    protected void initChannel(SocketChannel ch) throws Exception {
                        // 2.3.1. 测试特殊字符方式解决TCP拆包/粘包问题, 以"$_"结尾作为分割符(只要收到$_,就认为到这里就是一个数据包), 最大帧长1024bit
                        ByteBuf delimiterBuf = Unpooled.copiedBuffer("$_".getBytes());
                        ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, delimiterBuf));

                        // 2.3.2. Netty String解码器
                        ch.pipeline().addLast(new StringDecoder());

                        // 2.3.2. 配置自定义具体业务接收和处理的方法
                        ch.pipeline().addLast(new Pkg2NettyClientHandler());
                    }
                });

        // 3. 使用辅助配置工具类绑定要监听的端口, 并启动服务 => 同步阻塞
        ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 8765).syncUninterruptibly();

        // 4. 打破连接的同步阻塞, 则发送一条数据到服务器端 => 循环发送100次带特殊字符的消息
        for (int i = 0; i < 100; i++) {
            channelFuture.channel().writeAndFlush(Unpooled.wrappedBuffer(("消息" + i + "$_").getBytes()));
        }

        // 5. 阻塞的方式等待通道关闭 => 如果两边都不关闭, 则客户端和服务端的通道都会一直开着
        channelFuture.channel().closeFuture().sync();

        // 6. 释放资源
        workGroup.shutdownGracefully();
    }
}

```

###### 4、ClientHandler

```java
/**
 * 测试Netty: 客户端业务处理器, 测试特殊字符方式解决TCP拆包/粘包问题
 */
public class Pkg2NettyClientHandler extends ChannelInboundHandlerAdapter {

    /**
     * 通道激活方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel active... ");
    }

    /**
     * 通道关闭方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty client channel inactive... ");
    }

    /**
     * 读写数据核心方法 => 用于处理服务端回写的数据
     * @param ctx
     * @param msg
     * @throws Exception
     */
    @Override
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
        // 固定模式的 try .. finally
        // 在try代码片段处理逻辑, finally进行释放缓存资源, 也就是 Object msg (buffer)
        try {
            // 1. 使用了Netty String解码器后, 可以直接转换成String类型
            String response = (String) msg;

            // 5. 构造响应体给客户端 => 测试与客户端的交互
            System.err.println("Netty client: " + response);
        } finally {
            // 6. 释放资源
            ReferenceCountUtil.release(msg);
        }
    }

    /**
     * 读写数据完毕方法
     * @param ctx
     * @throws Exception
     */
    @Override
    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {
        System.err.println("Netty server channel read complete... ");
    }

    /**
     * 捕获异常方法
     * @param ctx
     * @param cause
     * @throws Exception
     */
    @Override
    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
        // 客户端读写异常, 则关闭连接
        ctx.close();
    }
}

```

##### 3）Netty 报文帧解决方案 | LengthFieldBasedFrameDecoder

###### 1、NettyServer

```java
public class Server {
    
	private static void start(int port) throws InterruptedException {
		EventLoopGroup bossGroup = new NioEventLoopGroup();
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup);
            b.channel(NioServerSocketChannel.class);
            b.childHandler(new ChannelInitializer() {
				@Override
				protected void initChannel(Channel ch) throws Exception {
					 ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024,0,2,0,2));
					 ch.pipeline().addLast(new DefaultEventExecutorGroup(16), new IProtocalHandler());
					 ch.pipeline().addLast(new StringEncoder(CharsetUtil.UTF_8));
				}            	
            });
            
            ChannelFuture f = b.bind(port).sync();
            f.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
	}
	
    public static void main( String[] args ) throws InterruptedException{
    	 start(8084);
    }
}

```

###### 2、NettyServerHandler

```java
public class IProtocalHandler extends ChannelInboundHandlerAdapter {
	@Override
	public void channelRead(ChannelHandlerContext ctx, final Object msg) throws Exception {
		int sleep = 500 * new Random().nextInt(5);
		System.out.println("sleep:" + sleep);
		Thread.sleep(sleep);
		
		final ByteBuf buf = (ByteBuf) msg;
		String outputStr = buf.toString(CharsetUtil.UTF_8);
		System.out.println(outputStr);
		
		ctx.channel().writeAndFlush(outputStr+"\n");
	}
}

```

# 十、Spring篇

### 1.1. 说说你对 Spring 的理解？

1. Spring 是一个开源框架，可以为了简化企业级 Java 开发过程，使得开发变得更加优雅和简洁。
2. Spring 是一个 **IoC** 控制反转和 **AOP** 面向切面编程的**容器框架**，包含并管理了对象的生命周期。

### 1.2. 说说 Spring 的优势有哪些？

1. Spring 通过 DI、AOP 和消除样板式代码，来简化企业级 Java 开发，同时由于低侵入式的设计，对业务代码的污染极低，以及其扩展性、开放性极高，使得并不强制应用完全依赖于 Spring，开发者可以自由选用 Spring 框架的部分或全部。
2. 其中， Spring 的 IoC 容器，降低了对象替换的复杂性，提高了组件之间的解耦。
3. Spring 的 AOP 则支持允许将一些通用任务如安全、事务、日志等进行集中式处理，从而提供了更好的复用。
4. Spring 的 ORM 和 DAO，则提供了与第三方持久层框架的的良好整合，并简化了底层的数据库访问。
5. 除 Spring 框架之外，还存在一个构建在核心框架之上的庞大生态圈，它将 Spring 扩展到不同的领域，比如 Web 服务、REST、移动开发、 NoSQL 以及 CloudFundry 这些。

### 1.3. Spring 是如何简化企业级 Java 开发的？

1. 基于 POJO 的轻量级和最小侵入性编程。
2. 通过依赖注入和面向接口，实现松耦合。
3. 基于切面和惯例，进行声明式编程。
4. 通过切面和模板，减少样板式代码。

### 1.4. 说说你对 IoC 的理解？

1. **IoC**，Inversion of Control，**控制反转**，是⼀种设计思想，指将原本在程序中⼿动创建对象的控制权，交由专门的容器来进行管理，比如 Spring，而 IoC 在其他语⾔中也有应⽤，并⾮ Spring 特有。 
2. **IoC 容器**，是 Spring ⽤来实现 IoC 的载体， 实际上就是个 Map（key，value）键值对，其中存放的是各种对象，将对象之间的相互依赖关系**交给 IoC 容器来管理**，并由 IoC 容器**完成对象的注⼊**。
   - **DI**：Dependancy Injection，依赖注入，站在容器的角度，将对象创建依赖的其他对象，注入到该对象中。
3. 也就是，**IoC 容器**像⼀个⼯⼚，当需要创建⼀个对象时，只需要配置好配置⽂件或者注解即可，不⽤考虑对象是如何被创建出来的，这样可以很⼤程度上简化应⽤的开发，把应⽤从复杂的依赖关系中解放出来。 

### 1.5. Spring IOC 容器的实现原理？

1. 先准备一个基本的容器对象，包含一些 map 结构的集合，用来方便后续过程中存储具体的对象。
2. 进行配置文件的读取工作，或者注解的解析工作，将需要创建的 bean 对象，都封装成 BeanDefinition 对象存储在容器中。
3. 容器将封装好了的 BeanDefinition 对象，通过反射的方式进行实例化，完成对象的实例化工作。
4. 进行对象属性的依赖注入工作，完成整个对象的创建，成为一个 bean 对象，存储在容器的 map 结构中。
5. 通过容器来获取对象，进行对象的获取和逻辑处理工作。
6. 提供销毁操作，当对象不用，或者容器关闭时，将无用的对象进行销毁。

### 1.6. Spring Bean 的生命周期？

#### 从生命周期长短来看

- **单例对象**： singleton，此时，对象的生命周期和容器相同。
- **多例对象**： prototype，此时，对象的生命周期有 3 个阶段：
  1. **出生**：使用对象时，Spring 才进行创建。
  2. **存活**：对象只要是在使用，那么就一直活着。
  3. **死亡**：当对象长时间不用，且没有其它对象引用时，会由 Java 垃圾回收机制回收。

#### 从构造过程的步骤来看

  ![1645326910721](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645326910721.png)

1. **Bean 对象实例化**：通过反射的方式进行对象的创建，此时的创建只是在堆空间中申请内存空间，属性都是默认值。
2. **注入对象属性**：给对象中的属性进行依赖注入的工作。
3. **执行 Aware**：
   1. 如果这个 Bean 实现了 `BeanNameAware` 接口，那么就会调用它实现的 `setBeanName(String)` 方法，由 Spring 容器来传入 `beanName` 的值。
   2. 如果这个 Bean 实现了 `BeanClassLoaderAware` 接口，那么就会调用它实现 的`setBeanClassLoader(ClassLoader)`，由 Spring 容器来传入 `ClassLoader` 对象。
   3. 如果这个 Bean 实现了 `BeanFactoryAware` 接口，那么就会调用它实现 的`setBeanFactory(BeanFactory)`，由 Spring 容器来传入 `BeanFactory` 对象。
4. **BeanPostProcessor 前置处理**：如果这个 Bean 实现了 `BeanPostProcessor` 接口，那么就会调用它实现的 `postProcessBeforeInitialization()` 方法，对生成的 Bean 对象进行前置处理工作，比如经常用作对 Bean 内容的更改，由于这个是在 Bean 初始化结束时调用的方法，所以可以被应用于缓存技术。
5. **InitializatingBean、init-method 检查和执行**：
   1. 如果这个 Bean 实现了 InitializatingBean 接口，那么就会调用它实现的 `afterPropertiesSet()`，在属性设置后的进行一些处理工作。
   2. 如果这个 Bean 自定义并配置了 `init-method` 方法，那么就会调用其初始化方法。
6. **BeanPostProcessor 后置处理**：如果这个 Bean 实现了 `BeanPostProcessor` 接口，那么就会调用 `postProcessAfterInitialization()`，对生成的 Bean 对象进行后置处理工作，比如打印日志等。
7. **注册回调方法**：如果对象实现了 `DestructionXXX` 相关的接口，那么就会调用它实现的回调接口，方便以后对象的销毁操作。
8. **Bean 使用**：通过 Spring 容器，来获取 Bean 对象并进行使用。
9. **执行销毁方法**：当Bean不再需要时，会进入清理阶段：
   1. 如果这个 Bean 实现了 `DisposableBean` 接口，自定义并配置了 `destroy-method` 方法，那么就会调用它实现的 `destroy()` 方法，进行对象的销毁工作。

### 1.7. Spring Bean 的作用域？

| 类型           | 作用域                                                       |
| -------------- | ------------------------------------------------------------ |
| **singleton**  | **单例对象，默认值的作用域**                                 |
| **prototype**  | **每次获取都会创建⼀个新的 Bean 实例**                       |
| request        | 每⼀次 HTTP 请求都会产⽣⼀个新的 Bean 实例，该 Bean 仅在当前 HTTP request 内有效 |
| session        | 仅用于 HTTP Session，同一个 Session 共享一个 Bean 实例，不同 Session 使用不同的实例 |
| global-session | 仅用于HTTP Session， 将对象存入到 web 项目集群的 session 域中，所有 Session 共享一个Bean 实例，但若不存在集群，则 global session 相当于 session |

- 默认作用域是 **singleton**，多个线程访问同一个 bean 时，会存在**线程不安全**问题，其**保障线程安全方法**有：
  1. 在 Bean 对象中，尽量避免不去定义可变的成员变量：有时不太现实。
  2. 在类中定义⼀个 `ThreadLocal` 成员变量，将需要的可变成员变量，保存在该 `ThreadLocal` 中：
     - 这样每个线程中都有一个自己的 ThreadLocalMap 对象，则可以把自己线程的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。
     - 将一个**共用的 ThreadLocal 静态实例作为 key**，将不同对象的引用，保存到不同线程的ThreadLocalMap 中，然后在线程执行的各处，通过这个静态`ThreadLocal#get()` 方法取得自己线程保存的那个对象，避免了将这个对象作为**参数传递**的麻烦。

### 1.8. BeanFactory 和 ApplicationContext 有什么区别？

- **相同点**：
  1. **IoC 容器**：两者都是 Spring 的 IoC 容器，都可以用 XML 来配置属性，都支持属性的自动注入。
  2. **接口**：两者都是接口，其中 ApplicationContext 继承于 ListableBeanFactory，ListableBeanFactory 又继承于 BeanFactory，都提供了一种 `getBean(name)`的方式，来获取 Bean 对象。
- **不同点**：
  1. **Bean 提早实例化**：调用 BeanFactory#getBean()  时会对 Bean 进行实例化，而 Application#getBean() 被调用时，并不会再对 Bean 进行实例化，而是早就在容器启动时实例化完毕。
  2. **自动注入方便**：如果使用BeanFactory 来实现自动注入，则需要注册 AutoWiredBeanPostProcessor，而如果使用 ApplicationContext，则可以直接使用 XML 进行 Bean 配置。
  3. **支持事件发布**：BeanFactory不支持事件发布，而 ApplicationContext 能够把事件发布到注册了监听器的Bean 中。
  4. **支持国际化**：BeanFactory不支持国际化，即 i18n，而 ApplicationContext 提供了对它的支持。
- **总结**：
  1. 简而言之，BeanFactory 提供基本的 IoC 和 DI 的功能，而 ApplicationContext 则还提供了高级的功能。
  2. 所以，BeanFactory 只在测试和非生产环境使用，ApplicationContext 则提供更强大的功能来应对生产环境，应该优于 BeanFactory。

### 1.9. Bean Factory 与 Factory Bean 有什么区别？

- **相同点**：都是用来创建 Bean对象的。
- **不同点**：使用 BeanFactory 创建对象时，必须要遵循**严格的生命周期流程**，这太复杂了，如果想要简单地自定义某个对象的创建，同时创建完成的对象还想交给 Spring 来管理的话，那么就可以实现 FactoryBean 接口，其中包含以下三个方法：
  1. **boolean isSingleton()**：是否为单例对象。
  2. **Class<?> getObjectType()**：返回对象的类型。
  3. **Object getObject()**：自定义对象的创建过程，比如 new、反射、动态代理，例子有 FeignClient 的动态代理实现。

### 2.0. BeanFactoryPostProcessor 与 BeanPostProcessor 有什么区别？

- **相同点**：都是接口，都是 Spring 的扩展点。
- **不同点**：BeanFactoryPostProcessor 指的是 Bean 工厂后置处理器，在 Bean 工厂准备完毕后，用于改写 BeanDefinition 的，而 BeanPostProcessor 指的是 Bean 初始化前/后置处理器，是在 Bean 初始化前和初始化后进行调用处理的，分别对应 `postProcessBeforeInitialization` 和 `postProcessAfterInitialization`。

### 2.1. Spring 启动流程原理？

![1645341206075](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645341206075.png)

```java
public abstract class AbstractApplicationContext extends DefaultResourceLoader
implements ConfigurableApplicationContext {
	@Override
    public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) {
        // 1：刷新前的预处理，包括一些scanner缓存清空、标志位active激活、时间戳记录等 
        prepareRefresh();
        // 2: 获取DefaultListableBeanFactory
        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
        // 3: 做一些BeanFactory的准备工作，包括设置classLoader、注册environment、systemProperties、systemEnvironment单例等
        prepareBeanFactory(beanFactory);
        try {
                // 4: 允许一些上下文子类在BeanFactory完成准备工作后，做一些后置的处理工作
                postProcessBeanFactory(beanFactory);
                // 5: 实例化并顺序执行BeanFactoryProcessor，以在实例化Bean之前，添加更多的BeanDefinition，其中核心的是ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry去扫描解析所有@Configuration下的@PropertySource、@ComponentScan、@Import、@ImportResource、@Bean，并加载成为BeanDefinitions
                invokeBeanFactoryPostProcessors(beanFactory);
                // 6: 实例化并注册所有的BeanPostProcessor，但没有执行，要在Bean初始化前/后再执行
                registerBeanPostProcessors(beanFactory);
                // 7: 实例化并注册MessageSource组件，用于做国际化功能、消息绑定、消息解析等
                initMessageSource();
                // 8: 实例化并注册事件多播器，用于观察者模式
                initApplicationEventMulticaster();
                // 9: 允许一些上下文子类，在容器刷新时自定义逻辑 
                onRefresh();
                // 10: 注册ApplicationListener
                registerListeners();
                // 11： 实例化所有剩下非懒加载的单例Bean，并完成它们的初始化和依赖注入，通过遍历所有beanNames，然后挨个判断走FactoryBean的流程，还是走BeanFactory的流程，其中主要步骤总结起来分为3步，分别是NewInstance实例化、Populate属性赋值、Initialization初始化
                finishBeanFactoryInitialization(beanFactory);
                // 12: 完成上下文的刷新，主要是调用LifecycleProcessor#onRefresh()方法
                finishRefresh();
            }
        ...
	}
}

```

### 2.2. Spring 是如何解决循环依赖的？

- **概念**：循环依赖，其实就是 Bean 的循环引用，也就是两个或者两个以上的 Bean 互相持有对方，最终形成依赖闭环，比如 A 依赖于B，B又依赖于A。

- **Spring中循环依赖场景有**: 

  1. prototype 原型 bean 的循环依赖。
  2. 构造器注入的循环依赖（构造器注入）。
  3. Field 属性注入的循环依赖（set注入）。

  => 其中，**构造器的循环依赖**问题无法解决，在解决属性循环依赖，也可以使用**懒加载**，而 Spring 采用的是**提前暴露对象**的方式来解决的。

- **懒加载 @Lazy 解决循环依赖问题**：

  1. Spring 启动时，会把所有的 bean 信息，包括 XML 和注解解析转化成 Spring 能够识别的 BeanDefinition 存到 HashMap 里，供后面初始化时使用。
  2. 然后对每个 BeanDefinition 进行处理，普通 Bean 初始化是在容器启动初始化阶段执行的，而被 `lazy-init=true` 修饰的 bean，则是在从容器里第一次进行 `context.getBean()` 时才会被触发，而此时其依赖的普通 Bean 早就被初始化完毕了，所以可以解决正常情况下的属性注入的循环依赖问题。 

- **三级缓存解决循环依赖问题**：

  ![1645350673009](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645350673009.png)

  Class A 依赖（这里是 @Autowire） Class B，Class B 又依赖（这里是 @Autowire） Class A，造成循环依赖，Spring 的解决方式是**三级缓存**：

  1. Class A 首先被实例化（一个空壳），实例化后立马放入三级缓存中。
  2. 然后在 populateBean填充 Class A 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class B name 调用 doGetBean 方法，获取 Class B 的实例。
  3. 然后在 Class B 也被实例化（一个空壳），实例化后也立马放入三级缓存中。
  4. 然后在 populateBean 填充 Class B 实例时，回调 @AutoWired 的回调接口`AutowiredAnnotationBeanPostProcessor#postProcessProperties()`，根据 Class A name 调用 doGetBean 方法，获取 Class A 的实例。
  5. 由于此时 A 已经在三级缓存中，所以取出 A 的 ObjectFactory 表达式并执行，获取到 Class A 实例的引用。
     - 其中要注意的是，这个表达式调用的 `getEarlyBeanReference(beanName, mbd, bean)` 方法，可以获取 AOP 代理的空壳引用，即该方法要么返回的是原对象，要么返回的是代理对象，如果返回的是代理对象，那么该代理对象 B'/A' 不会持有另外一个 A/B 的引用，而是**持有 B/A 原对象的引用**，再由原对象去持有 A/B 的引用，而 A/B 则持有代理对象的引用 B'/A'。
  6. 获取到 Class A 实例的引用，设置到二级缓存中，删除 A 三级缓存，并返回给 Class B 注入。
  7. 此时 Class B 已经解决了循环依赖 A 的问题，最后设置单例 Class B 到一级缓存中，删除 B 二三级缓存。
  8. 由于此时 B 已经在一级缓存中，所以取出 B 实例引用，返回给 Class A 注入。
  9. 此时 Class A 也解决了循环依赖 B 的问题，最后设置单例 Class A 到一级缓存中，删除 A 二三级缓存。

  => 最后，Class A、Class B 分别完成注入，也就是解决了循环依赖的问题。

### 2.3. 说说你对 AOP 的理解？

1. **AOP**，Aspect-Oriented Programming，**⾯向切⾯编程**，为解耦而生，能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑，或者责任封装起来（比如事务管理、⽇志管理、权限控制等），以便于减少系统的重复代码，降低模块间的耦合度，有利于未来的可拓展性和可维护性。

2. AOP 有如下 7 个核心的**概念**：

   1. **切面**：Aspect，指对哪些方法进行拦截处理的**横切关注点**，可能会横切多个对象，比如 Spring 的事务管理， 在 Spring AOP 中，切面可以在普通类中以 `@Aspect` 注解来实现。
   2. **连接点**：Join point，指在程序执行过程中某个特定的点，比如某个方法调用的时间点，或者处理异常的时间点，在 Spring AOP 中，一个连接点代表一个**方法的执行**。
   3. **通知**：Advice，在切面的某个特定的连接点上**执行的动作**，通知有多种类型，包括 `around`， `before`， 和 `after` 等等。
   4. **切点**：Pointcut，**匹配连接点的断言**，通知会在满足这个切点的连接点上运行，比如 AOP 去执行某个特定名称的方法。
   5. **目标对象**：Target object，被一个或者多个切面所通知的对象，也被称作**被通知的业务对象**。
   6. **织入**：Weaving，把切面连接到目标对象上，并创建一个代理对象的过程。
   7. **AOP 代理**：AOP proxy，AOP 框架创建的对象，用来实现切面契约，包括通知方法执行等功能，在Spring 中，AOP代理可以是 JDK 动态代理，或者是 CGLIB 动态代理。

3. 比如日志管理的公共代码，可以抽象出一个**切面**，然后注入到**目标对象**中（具体的业务对象），通过**动态代理**，将对目标对象进行代理，在进行调用时，代理对象会根据通知类型，在对应的时间点，执行切面中增强的方法，从而实现日志统一管理，避免了代码的冗余。

4. **原理**：Spring AOP 是基于**动态代理**实现的，是 IoC 的一个扩展功能，是在 IoC 整个流程中新增的一个 BeanPostProcessor `AbstractAutoProxyCreator` 扩展点而已。

   1. `AbstractAutoProxyCreator` 实现了 `postProcessAfterInitialization(bean,beanName)` 方法，底层调用动态代理过程。
   2. 如果要代理的对象实现了某个接⼝，那么 Spring AOP 会使⽤ JDK Proxy，去创建代理对象。
   3. ⽽对于没有实现接⼝的对象，就⽆法使⽤ JDK Proxy 去进⾏代理了，此时 Spring AOP 则会使⽤基于 asm框架字节流的 Cglib 动态代理 ，⽣成⼀个被代理对象的⼦类来作为代理。

5. **实现**：选讲，只是用于记忆而已。

   - **1、POM 依赖**：

     ```xml
     <dependency>
         <groupId>org.springframework.boot</groupId>
         <artifactId>spring-boot-starter-aop</artifactId>
     </dependency>
     
     ```

   - **2、开启 AOP**：

     ```java
     // proxyTargetClass默认为false, 表示默认使用JDK 动态代理, 碰到接口或者设置为true, 则使用CGLIB动态代理
     @EnableAspectJAutoProxy(proxyTargetClass = true)
     @SpringBootApplication
     public class SpringbootDemoApplication {
         public static void main(String[] args) {
             SpringApplication.run(SpringbootDemoApplication.class, args);
         }
     }
     
     ```

   - **3、配置切面、切点、通知**：

     ```java
     @Aspect
     @Component
     public class AspectJConfig {
         @Pointcut("execution(* com.jsonyao.cs.controller.*.*(..))")
         private void pointcut() {
     
         }
     
         @Around("pointcut()")
         public Object around(ProceedingJoinPoint point) throws Throwable {
             long start = System.currentTimeMillis();
             Object res = point.proceed();
             long end = System.currentTimeMillis();
             System.err.println("执行结果: " + res + ", 消耗时间: " + (end - start));
             return res;
         }
     }
     
     ```

   - **4、测试切面**：

     ```java
     package com.jsonyao.cs.controller;
     
     @RestController
     @RequestMapping("/boot")
     public class UserController {
         @Autowired
         private UserSerivce userService;
     	
         // 打印了日志：执行结果: User{id=0, username='AOP', password='AOP'}, 消耗时间: 8
         @RequestMapping("/getUser/{id}")
         public String GetUser(@PathVariable Long id){
             return userService.findById(id).toString();
         }
     }
     
     ```

### 2.4. Spring 事务传播属性？

- **概念**：

| 属性                     | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| REQUIRED（默认属性）     | 如果存在一个事务，则支持**当前事务**，如果没有事务，则开启一个**新的事务** |
| MANDATORY                | 支持**当前事务**，如果当前没有事务，就**抛出异常**           |
| NEVER                    | 以**非事务**方式执行，如果当前存在事务，则**抛出异常**       |
| NOT_SUPPORTED            | 以**非事务**方式执行操作，如果当前存在事务，就把当前事务**挂起** |
| REQUIRES_NEW（相互独立） | **新建事务**，如果当前存在事务，把当前**事务挂起**，内外两个事务相互独立，互不影响，当外层事务失败时，并不会回滚内层事务所做的动作，而内层事务操作失败时，也不会引起外层事务的回滚 |
| SUPPORTS                 | 支持**当前事务**，如果当前没有事务，就以**非事务**方式执行   |
| NESTED（局部回滚）       | 支持**当前事务**，新增 Savepoint 点，与当前事务**同步提交或回滚**。嵌套事务一个非常重要的概念，就是内层事务依赖于外层事务，当外层事务失败时，会回滚内层事务所做的动作，而内层事务操作失败时，并不会引起外层事务的回滚 |

- **实现**：@Transactional

  ```java
  @EnableTransactionManagement 
  @Transactional
  
  ```

- **原理**：

  ![1645359975955](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645359975955.png)

  Spring 的事务是由 AOP 来实现的，首先按照 AOP 的整套流程来执行具体的操作逻辑，使用 `InfrastructureAdvisorAutoProxyCreator` （AbstractAutoProxyCreator 的子类）来生成具体的代理对象，然后通过一个 `TransactionInterceptor` 来实现，在调用 `JdkDynamicAopProxy#invoke(proxy, method, args)` 方法时，则代理到 `TransactionInterceptor`  实现的具体逻辑中。

  1. 先做准备工作，解析各个方法上事务相关的属性，根据具体的属性来判断是否开始新事务。
  2. 当需要开启事务时，则获取数据库连接，关闭自动提交功能，开启事务。
  3. 执行具体的业务逻辑。
  4. 在执行过程中发生异常，那么会通过 `completeTransactionAfterThrowing` 来完成事务的回滚操作，回滚的具体逻辑是通过 `doRollBack` 方法来实现的，实现的时候也是要先获取链接对象，再通过连接对象来回滚。
  5. 如果执行过程中，没有任何意外情况的发生，那么通过 `commitTransactionAfterReturning` 来完成事务的提交操作，提交的具体逻辑是通过 `doCommit` 方法来实现的，实现的时候也要获取链接，通过链接对象来提交。
  6. 当事务执行完毕之后，需要通过 `cleanupTransactionInfo` 来清除相关的事务信息。 

- **注意事项**：

  1. 事务函数中不要处理**耗时任务**，会导致长期占有数据库连接。
  2. 事务函数中不要处理**无关业务**，防止产生异常导致事务回滚。
  3. Spring 事务控制什么时候会**失效**？
     1. Bean 对象没有被 Spring 容器所管理。
     2. 调用方法的访问修饰符不是 public。
     3. 数据源没有配置事务管理器。
     4. 数据库不支持事务。
     5. 异常被捕获，所以没有回滚。

### 2.5. Spring 中的设计模式？

- **单例模式** : Bean 默认都是单例的。
- **⼯⼚模式** : 使用 BeanFactory、ApplicationContext 来创建 Bean 对象。
- **模板方法模式**：BeanFactoryPostProcessor#postProcessBeanFactory，AbstractApplicationContext#onRefresh。
- **代理模式** ：AOP。
- **观察者模式**：事件驱动模型。
- **责任链模式**：MVC Filter。
- **适配器模式**：MVC 适配器适配 Controller 。

### 2.6. 谈谈你对 SpringBoot 的理解？

- **背景**：SpringBoot 所解决了的问题。
  1. 搭建后端框架时需要涉及很多 **XML 配置文件**，增加了搭建难度和时间成本。
  2. 将项目编译成 war 包，部署到 Tomcat 中，项目**部署依赖 Tomcat**，这样非常不方便。
  3. **应用监控**需要做的比较简单，通过一个没有任何逻辑的接口，来判断应用的存活状态。
- **概念**：
  1. 使用 Spring Boot 通过简单的步骤，就可以创建一个 Spring 应用。
  2. Spring Boot 为 Spring 整合第三方框架提供了**开箱即用**的功能。
  3. Spring Boot 的核心思想是**约定大于配置**。
- **优点**：
  1. **自动装配**：Spring Boot 会根据某些规则对所有配置的 Bean 进行初始化，减少了很多重复性的工作。
     - 比如使用 MongoDB 时，只需加入 MongoDB 的 Starter 包，然后配置  的连接信息，就可以直接使用 MongoTemplate 自动装配来操作数据库了。简化了 Maven Jar 包的依赖，降低了烦琐配置的出错几率。
  2. **内嵌容器：**Spring Boot 应用程序可以不用部署到外部容器中，比如 Tomcat，应用程序可以直接通过 Maven 命令编译成可执行的 jar 包，通过 java-jar 命令启动即可，非常方便。
  3. **应用监控：**Spring Boot 中自带监控功能 Actuator，可以实现对程序内部运行情况进行监控，比如 Bean 加载情况、环境变量、日志信息、线程信息等，也可以自定义跟业务相关的监控，通过Actuator 的端点信息进行暴露。

### 2.7. SpringBoot 自动装配原理？

- **Starter 是什么**：
  1. starter 就是一个 jar 包，写一个 @Configuration 的配置类，把这些 Bean 的定义都包含在其中，然后在 Starter 包下的 `META-INF/spring.factories` 中写入该配置类，那么 SpringBoot 程序在启动时，就会按照约定来加载该配置类。
  2. 开发人员只需要将相应的 Starter 包依赖进应用中，然后进行相关的属性配置，就可以进行代码开发，而不需要再单独对 Bean 进行配置。
- **自定义 Starter**：
  1. 创建 Starter 项目，定义 Starter 需要的 Properties 配置类，比如数据库连接信息等。
  2. 然后编写自动配置类，自动配置类就是获取配置，根据配置来自动装配 Bean。
  3. 编写 `META-INF/spring.factories` 文件，以让 SpringBoot 在启动时加载自动配置类。
  4. 然后在项目中，引入自定义 Starter 的 Maven 依赖，增加对应的配置值后，即可直接使用。
- **原理**：
  1. 当启动 SpringBoot 应用时，会先创建 SpringApplication 的对象，在对象的构造方法中，会进行某些参数的初始化工作，最主要的是判断当前应用的类型（比如 Servlet） 以及 SPI 加载整个应用的 `spring.factories` 文件中的初始化器和监听器 Class 类。
  2. SpringApplication 对象创建完成之后，开始执行 `run()` 方法，来完成整个启动，启动过程中最主要的有两个方法，第一个叫做 `prepareContext()`，第二个叫做 `refreshContext()`，在这两个步骤中完整了自动装配的核心功能，而其他方法的处理逻辑包含了上下文对象的创建、Banner 的打印、异常报告期的准备等各个准备工作，方便后续来进行调用。
  3. 在 `prepareContext()` 方法中，主要完成了对上下文对象的初始化工作，包括属性值的设置，比如环境对象，在整个过程中，有一个非常重要的方法 `load()`，`load()` 主要完成一件事，那就是将**启动类**作为BeanDefinition 注册到 Registry 中，方便后续在进行 BeanFactoryPostProcessor 调用执行时，找到对应的主类来完成 `@SpringBootApplication` 和 `@EnableAutoConfiguration` 等注解的解析工作。
  4. 在 `refreshContext()` 方法中，会进行整个容器的刷新过程，会调用 Spring 中的启动流程，即`AbstractApplicationContext#refresh()`，有 13 个关键方法，来完成整个  Spring 应用的启动，其中会调用 `invokeBeanFactoryPostProcessor()` 方法，主要是对`ConfigurationClassPostProcessor` 的处理，会先调用实现 `BeanDefinitionRegistryPostProcessor` 接口的 `postProcessBeanDefinitionRegistry()` 方法，然后再调用自己实现的 `postProcessBeanFactory()` 方法，处理各种包括 @PropertySource、@ComponentScan、@Import、@ImportResource、@Bean 等注解。
  5. 其中，在解析 @Import 注解时，会有一个 `getImports()` 的方法，会从**启动类**开始递归解析注解，把所有包含 @Import 注解都收集到，然后在 `processImport()` 方法中，对 Import 导入的类进行分类，这里主要起识别作用的是 `ImportSelect` 的实现类  `AutoConfigurationImportSelect`，来调用 `selectImports()` 方法使用 SPI 方式，来获取并加载 `spring.factories` 中的 `EnableAutoConfiguration` 自动装配配置类的 Class。
  6. 接着，调用子类上下文 `ServletWebServerApplicationContext#onRefresh` 方法，来拉起嵌入式 Tomcat 服务器。
  7. 最后，还有一步关键步骤是 `finishBeanFactoryInitialization()` 方法，主要是实例化所有剩下非懒加载的单例 Bean，并完成它们的初始化和依赖注入，通过遍历所有 beanNames，然后挨个判断走FactoryBean 的流程，还是走 BeanFactory 的流程，其中主要步骤总结起来分为 3 步，分别是NewInstance 实例化、Populate 属性赋值 和 Initialization 初始化，从而完成自动配置配置 Bean 的自动注入。

### 2.8. Spring MVC 原理？

- **自动装配原理**：

  - ../spring-boot-**autoconfigure**-2.2.2.RELEASE.jar!/META-INF/**spring.factories**：

    ```properties
    # Auto Configure
    org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
    ...,
    org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\
    ...
    
    ```

  - **DispatcherServletAutoConfiguration**：Springboot 中 的Spring MVC，主要是依靠DispatcherServletAutoConfiguration 中的两个内部类进行初始化，两者配合，最终完成初始化工作：

    ```java
    @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)
    @Configuration(proxyBeanMethods = false)
    @ConditionalOnWebApplication(type = Type.SERVLET)
    @ConditionalOnClass(DispatcherServlet.class)
    @AutoConfigureAfter(ServletWebServerFactoryAutoConfiguration.class)
    public class DispatcherServletAutoConfiguration {
        
        // 1、DispatcherServletConfiguration，负责生成dispatcherServlet
    	@Configuration(proxyBeanMethods = false)
    	@Conditional(DefaultDispatcherServletCondition.class)
    	@ConditionalOnClass(ServletRegistration.class)
    	@EnableConfigurationProperties({ HttpProperties.class, WebMvcProperties.class })
        protected static class DispatcherServletConfiguration {
            @Bean(name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)
            public DispatcherServlet dispatcherServlet(HttpProperties httpProperties, WebMvcProperties webMvcProperties) {
                ...
            }
            ...
        }
        
        // 2、DispatcherServletRegistrationConfiguration，负责将dispatcherServlet注册到系统里面的servlet中，使其生效
        @Configuration(proxyBeanMethods = false)
    	@Conditional(DispatcherServletRegistrationCondition.class)
    	@ConditionalOnClass(ServletRegistration.class)
    	@EnableConfigurationProperties(WebMvcProperties.class)
    	@Import(DispatcherServletConfiguration.class)
        protected static class DispatcherServletRegistrationConfiguration {
            ...
        }
    }
    
    ```

- **请求访问原理**：

![1645420150788](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1645420150788.png)

总：当客户端发起请求时，被中心控制器拦截到请求，根据请求参数生成代理请求，找到对应的实际控制器，调用控制器去处理请求，创建数据模型，访问数据库填充好模型后，再把模型视图返回给适配器到中心控制器，然后由中心控制器去调用视图解析器，根据逻辑的视图获取实际的视图，再使用模型去渲染该视图后，最后再把视图返回给客户端，从而完成一次请求的处理。

分：

1. DispatcherServlet，表示中心控制器，在客户端发出请求后，经过 Web 容器（比如 Tomcat）后，会打到 DispatcherServlet 上，并由其来处理请求。
2. HandlerMapping，表示处理器映射，DispatcherServlet 收到请求后，会调用 HandlerMapping，HandlerMapping 会根据请求 url 去查找对应的 Handler，即一个 Handler Method 对象，指的是 url 对应 Controller 中的对应方法。
3. HandlerExecutionChain，表示处理器执行链，Handler 解析完 url  后，会返回一个处理器执行链给DispatcherServlet。
4. HandlerAdapter，表示处理器适配器，DispatcherServlet 会按照规则去匹配对应的 HandlerAdapter。
5. 再由对应的 Handler Method 去处理请求，其中就包括调用去执行我们编写的业务逻辑。
6. Controller 代理对象，则会去创建数据模型，访问数据库填充好模型后，再把 ModelAndView 返回给 HandlerAdapter。
   - 对于我们平常使用的 @ResponseBoday 的方法，返回的 ModelAndView 为空，也就是不会返回视图给客户端，而是经过 `RequestResponseBodyMethodProcessor`，把 JSON 串写入到 Response 的 Body 中。
7. HandlerAdapter 收到后，再将 ModelAndView  传递给 DispatcherServlet。
8. DispatcherServlet 收到后，则调用视图解析器 ViewResolver，来解析 ModelAndView。
9. ViewResolver 会解析逻辑视图名，根据逻辑的 View 找到实例的 View，并返回给 DispatcherServlet。
10. DispatcherServlet 收到后，则根据 ViewResolver 解析出的 View，调用对应的实际视图，结合 Model 进行渲染。
11. 最后，DispatcherServlet 再将渲染后的 View 作为结果，响应给客户端。

- **MVC 9 大组件**：
  1. **HandlerMapping**：处理器映射，RequestMappingHandlerMapping 可以根据 request#url，找到 **Handler Method** 对象，这指的是 url 对应 Controller 中的对应方法。
  2. **HandlerAdapter**：调用 Handler Method 的适配器，主要处理方法参数、相关注解、数据绑定、消息转换、返回值、调用视图解析器等工作。
  3. HandlerExceptionResolver：异常解析器，对异常进行处理。
  4. **ViewResolver**：视图解析器，用来将 String 类型的视图名和 Locale 解析为 View 类型的逻辑视图。
  5. RequestToViewNameTranslator：请求视图名获取器，有的 Handler Method 处理完后没有设置返回类型，比如是 void 返回值的方法，就需要从 request 中获取 viewName。
  6. LocaleResolver：多语言解析器，从 request 中解析出请求中的本地语言 Locale，Locale表示一个区域，比如 zh-cn，针对不同的区域的用户，显示不同的结果，即 i18n（SpringMVC 中有具体的拦截器`LocaleChangeInterceptor`）。
  7. ThemeResolver：主题解析器，主题解析，这种类似于我们手机更换主题，不同的 UI，css 等。
  8. MultipartResolver：多部件文件解析器，处理上传请求，把普通的request封装成MultipartHttpServletRequest。
  9. FlashMapManager：FlashMap 管理器，用于管理 FlashMap，FlashMap 可以用于在 redirect 重定向中传递参数。

### 2.9. Spring、Spring MVC、Spring Boot 的区别是什么？

1. Spring，是一个一站式的轻量级 Java 开发框架，核心是控制反转（IOC）和面向切面（AOP），针对于开发的
   WEB 层(Spring Mvc)、业务层(IoC)、持久层(JdbcTemplate)等都提供了多种配置解决方案。
2. Spring MVC，是 Spring 基础之上的一个 MVC 框架，主要处理 WEB 开发的路径映射和视图渲染，属于 Spring 框架中 WEB 层开发的一部分。
3. SpringBoot，由于 Spring 配置非常复杂，各种 XML、JavaConfig、Servlet 处理起来比较繁琐，为了简化开发者的使用，从而创造性地推出了 SpringBoot 脚手架，相对于 Spring MVC 框架来说，更专注于开发微服务后台接口，不开发前端视图，同时遵循默认优于配置，简化了插件配置流程，不需要配置 XML，大大简化了配置流程。

### 3.0. Spring 常用注解？

| 注解           | 包位置           | 作用                                                         | 用法举例                                                     |
| -------------- | ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| @Autowired     | spring-beans     | 属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入 | @Autowired + 属性、@Autowired + setxxx()、@Autowired + 构造方法、@Autowired + 方法参数，原理见 AutowiredAnnotationBeanPostProcessor |
| @Resource      | javax.annotation | 属性注入，先按属性名字去找，再按属性类型去找，如果指定名字则直接按名字去找 | @Resource、@Resource(name = "beanName")                      |
| @Value         | spring-beans     | 注入普通字符串、占位符替换、SpringEL                         | @Value（"abc"）、@Value（"${str}"）、@Value（"#{beanName}"） |
| @Lazy          | spring-context   | 懒加载式注入代理 Bean、解决构造函数循环依赖问题              | @Lazy + 类、@Lazy + 属性、@Lazy + 方法、@Lazy + 方法参数、@Lazy + 构造方法 |
| @Lookup        | spring-beans     | 找到对应的 Bean 作为返回值返回                               | @Lookup("beanName") + 方法                                   |
| @Bean          | spring-context   | Bean 注入                                                    | @Configuration + @Bean 配置 Bean、@Component + @Bean 普通 Bean |
| @Component     | spring-context   | Bean 注入                                                    | @Component + 类，延伸出 @Configuration、@Service、@Controller、@Repository |
| @Primary       | spring-context   | 标识某个 Bean 为主 Bean，优先注入                            | @Bean + @Primary、@Component + @Primary                      |
| @Configuration | spring-context   | 标识为配置 Bean                                              | @Configuration + @Bean，配置 Bean 不仅会被注入，还会被解析   |
| @ComponentScan | spring-context   | @Component Bean 扫描                                         | @Component("beanPkg") + includeFilters、excludeFilters、META-INF/spring-components 索引 |
| @Conditional   | spring-context   | 条件式注入                                                   | @Conditional + 类、@Conditional + 方法、实现 Condition#matches 接口方法，返回 true 则代表匹配 |
| @Import        | spring-context   | 批量导入 Bean 类从而注入 Bean                                | @Import（BeanClass） + ImportSelector#selectImports、或者 DeferredImportSelector#selectImports、或者 ImportBeanDefinitionRegistrar#registerBeanDefinitions |

### 3.1. Spring 注入一个 Bean 的方式？

1. **@Component（@Configuration、@Service、@Controller、@Repository）**：通过注入某个类成为 Bean。
2. **@Bean**：通过解析某个方法成为 Bean。
3. **@Import**：导入类或者 BeanDefinition 成为 Bean。
4. **@ImportResource**：导入一个 Spring.xml 文件，通过解析文件注册 Bean。
5. **BeanDefinitionRegistryPostProcessor**：通过 BeanDefinition 注册 Bean。
6. **FactoryBean、SmartFactoryBean**：将自己 New 的一个对象注册为 Bean。
7. **ApplicationContext#registerBean**：通过 ApplicationContext 实现 Supplier 接口，来提供一个对象成为 Bean。
8. **ApplicationContext#register**：通过 ApplicationContext 某个类注册成为 Bean。
9. **ApplicationContext#registerBeanDefinition**：通过 BeanDefinition 注册 Bean。

### 3.2. Spring 依赖注入方式？

1. **@Autowired**：属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入。
2. **@Resource**：属性注入，先按属性名字去找，再按属性类型去找，如果指定名字则直接按名字去找。
3. **@Value**：注入普通字符串、占位符替换、SpringEL。
4. **自定义注解**：实现 BeanPostProcessor#postProcessBeforeInitialization 方法，解析 Bean 上的自定义注解，完成属性注入。

### 3.3. ApplicationContext 获取方式？

1. **@Autowired**：属性注入，先按属性类型去找，再按属性名字去找、方法注入、方法参数注入、构造方法注入。
2. **实现自省接口**：实现 ApplicationContextAware#setApplicationContext 方法。

### 3.4. Spring AOP 使用方式？

1. **ProxyFactory**：代理对象工厂，封装了 JDK 和 CGLIB 动态代理方法，比如：

   ![1647155729524](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155729524.png)

2. **ProxyFactoryBean**：利用 FactoryBean 机制，将代理对象作为一个 Bean，比如：

   ![1647155822496](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155822496.png)

3. **BeanNameAutoProxyCreator**：指定某个 beanName，让 Spring 对其匹配的 Bean，进行批量 AOP，比如：

   ![1647155851621](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155851621.png)

4. **DefaultAdvisorAutoProxyCreator**：指定某个 Advisor，让 Spring 对其匹配的 Bean，进行批量 AOP。

   ![1647155943409](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647155943409.png)

5. **@EnableAspectJAutoProxy**：开启支持 AspectJ。

### 3.5. Spring MVC 常用注解？

| 注解            | 包位置     | 作用                                           | 用法举例                                                     |
| --------------- | ---------- | ---------------------------------------------- | ------------------------------------------------------------ |
| @RequestMapping | spring-web | 映射Web请求                                    | @RequestMapping（"path"）+ 类、@RequestMapping（"path"）+ 方法 |
| @RequestBody    | spring-web | 读取请求体中的参数                             | @RequestBody + 方法参数                                      |
| @PathVariable   | spring-web | 读取请求路径中的参数                           | @PathVariable + 方法参数                                     |
| @ResponseBody   | spring-web | 把 json 返回值放在 response 内，而不是一个页面 | @ResponseBody + 类 = @RestController、@ResponseBody + 方法   |

### 3.6. Spring Boot 常用注解？

| 注解                   | 包位置                    | 作用                                                         | 用法举例                    |
| ---------------------- | ------------------------- | ------------------------------------------------------------ | --------------------------- |
| @SpringBootApplication | spring-boot-autoconfigure | @SpringBootConfiguration 表示为配置 Bean + @EnableAutoConfiguration 开启自动装配 `META-INF/spring.factories` + @ComponentScan 扫描注解 | @SpringBootApplication + 类 |

# 十一、MyBatis篇

### 1.1. MyBatis 是什么？

1. Mybatis 是一个半 ORM（对象关系映射）框架，它内部封装了 JDBC，开发时只需要关注 SQL 语句本身，不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程，程序员直接编写原生态 sql，可以严格控制 sql 执行性能，灵活度高。
2. MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO 映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。

### 1.2. MyBatis 优缺点？

- **优点**：
  1. 基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在 XML 里，解除 sql 与程序代码的耦合，便于统一管理，且提供 XML 标签，支持编写动态 SQL 语句，并可重用。
  2. 与 JDBC 相比，减少了 50% 以上的代码量，消除了 JDBC 大量冗余的代码，不需要手动开关连接。
  3. 很好的与各种数据库兼容（因为 MyBatis 使用 JDBC 来连接数据库，所以只要 JDBC 支持的数据库，MyBatis 都支持）。
  4. 提供映射标签，支持对象与数据库的 ORM 字段关系映射，提供对象关系映射标签，支持对象关系组件维护。
  5. 能够与 Spring 很好的集成。
- **缺点**：
  1. SQL 语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写 SQL 语句的功底有一定要求。
  2. SQL 语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

### 1.3. Mybatis 和 Hibernate 的区别？ 

- **1）概念上**：
  1. Hibernate，是一个开放源代码的对象关系映射框架，它对 JDBC 进行了非常轻量级的对象封装，建立对象与数据库表的映射，是一个全自动的、完全面向对象的持久层框架。
  2. Mybatis，是一个开源对象关系映射框架，原名 Ibatis，2010年由谷歌接管以后更名，是一个半自动化的持久层框架。
- **2）开发速度上**：
  1. Hibernate 开发中，sql 语句已经被封装，直接可以使用，加快系统开发。
  2. Mybatis 属于半自动化，sql需要手工完成，稍微繁琐。
  3. 但是，凡事都不是绝对的，如果对于庞大复杂的系统项目来说，复杂语句较多，hibernate 就不是好方案。
- **3）sql 性能上**：
  1. Hibernate 自动生成sql，有些语句较为繁琐，会多消耗一些性能。
  2. Mybatis 手动编写sql，可以避免不需要的查询，提高系统性能。
- **4）对象管理比对**：
  1. Hibernate，是完整的对象-关系映射的框架，开发工程中，无需过多关注底层实现，只要去管理对象即可。
  2. Mybatis 需要自行管理映射关系，所以，称之为半自动 ORM 映射工具。
     - **ORM**：Object Relational Mapping，对象关系映射，是一种为了解决关系型数据库数据与简单 Java对象（POJO）的映射关系的技术，简单来说就是，ORM 通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系型数据库中。

#### 1、jdbc

```java
@Slf4j
public class UserExecutor {

    public static final String URL = "jdbc:mysql://localhost:3306/muse";
    public static final String USER = "root";
    public static final String PASSWORD = "root";

    public static void main(String[] args) throws Exception {
        //1.加载驱动程序
        Class.forName("com.mysql.jdbc.Driver");
        //2. 获得数据库连接
        Connection conn = DriverManager.getConnection(URL, USER, PASSWORD);
        ResultSet rs = null;
        PreparedStatement ps = null;
        try {
            //3.操作数据库，实现增删改查
            ps = conn.prepareStatement("SELECT name, age FROM tb_user where id = ?");
            ps.setInt(1, 2);
            rs = ps.executeQuery();
            //如果有数据，rs.next()返回true
            while (rs.next()) {
                System.out.println("姓名：" + rs.getString("name") + "，年龄：" + rs.getInt("age"));
            }
        } catch (SQLException e) {
            log.error("error", e);
        } finally {
            close(rs, ps, conn);
        }
    }

    private static void close(ResultSet rs, Statement stmt, Connection connection) {
        try {
            if (rs !=null && !rs.isClosed()) {
                rs.close();
            }
        } catch (SQLException e) {
            log.error("rs.close() error!", e);
        }

        try {
            if (stmt != null && stmt.isClosed()) {
                stmt.close();
            }
        } catch (SQLException e) {
            log.error("stmt.close() error!", e);
        }

        try {
            if (connection != null && connection.isClosed()) {
                connection.close();
            }
        } catch (SQLException e) {
            log.error("connection.close() error!", e);
        }

    }
}

```

#### 2、Hibernate

```java
public class UserExecutor {

    //保存用户的案例
    public static void main(String[] args) {
        Configuration configuration = new Configuration().configure("hibernate.cfg.xml");
        SessionFactory sessionFactory = configuration.buildSessionFactory();
        Session session = null;
        try {
            session = sessionFactory.openSession();
            User user = session.get(User.class, 2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        } finally {
            if (session != null) {
                //7. 释放资源
                session.close();
                sessionFactory.close();
            }
        }
    }
}

```

#### 3、Mybatis

```java
public class MessageExecuter {
    public static void main(String[] args) {
        sqlSession = SqlSessionFactoryUtil.openSqlSession();
        MessageMapper messageMapper = sqlSession.getMapper(MessageMapper.class);
        Message message = messageMapper.getMessageById(2L);
        System.out.println("getMessageById--->" + message);
    }
}

```

### 1.4. MyBatis 核心组件？

1. **SqlSessionFactoryBuilder**：构造器，根据配置信息或代码，来生成 SqlSessionFactory。
2. **SqlSessionFactory**：工厂，用来生成SqlSession。
3. **SqlSession**：会话，可以用来发送 SQL，去执行并返回结果，也可以获取 Mapper 的接口。
4. **SQL Mapper**：它由一个 Java 接口和 XML 文件/注解构成，需要给出对应的 SQL 和映射规则，负责发送 SQL 去执行，并返回结果。

### 1.5. MyBatis 使用？

#### 1、使用步骤

1. **第一步**：配置mybatis-config.xml：

   ```xml
   <configuration>
       <!-- 属性 -->
       <properties resource="sqlmap/mybatis/mysql/jdbc.properties"/>
       
       <!-- 配置 -->
       <settings>
           <!-- PARTIAL是默认值，只会自动映射，没有定义嵌套结果集映射的结果集 -->
           <setting name="autoMappingBehavior" value="PARTIAL"/>
   		<!-- 打印查询语句 -->
           <setting name="logImpl" value="STDOUT_LOGGING"/>
           <!-- 配置驼峰转下划线 数据库中的下划线，转换Java Bean中的驼峰-->
           <setting name="mapUnderscoreToCamelCase" value="true"/>
       </settings>
   
       <!-- 类型别名 -->
       <typeAliases>
           <package name="vo"/>
           <!-- <typeAlias type="vo.User" alias="user"/> -->
       </typeAliases>
   
       <!-- 类型处理器
       <typeHandlers/> -->
   
       <!-- 对象工厂
       <objectFactory type="" />   -->
   
       <!-- 对象包装工厂
       <objectWrapperFactory type="" />    -->
   
       <!-- 对象工厂
       <reflectorFactory type="" />    -->
   
       <!-- 插件
       <plugins>
           <plugin interceptor=""></plugin>
       </plugins> -->
   
       <!-- 配置数据库环境 -->
       <environments default="dev">
           <environment id="dev">
               <transactionManager type="JDBC"/> <!-- 事务管理器 -->
               <dataSource type="POOLED">
                   <property name="driver" value="${driver}"/>
                   <property name="url" value="${url}"/>
                   <property name="username" value="${username}"/>
                   <property name="password" value="${password}"/>
               </dataSource>
           </environment>
       </environments>
   
       <!-- 数据库厂商标识 -->
       <databaseIdProvider type="DB_VENDOR"/>
   
       <!-- 映射器 -->
       <mappers>
           <mapper resource="sqlmap/mybatis/mysql/UserMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/UserContactMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/MessageMapper.xml"/>
           <mapper resource="sqlmap/mybatis/mysql/MessageDetailMapper.xml"/>
       </mappers>
   </configuration>
   
   ```

2. **第二步**：配置 MessageMapper.xml：

   ```xml
   java id, msgid, status, content, deleted, createtime, update_time...
   
   ```

3. **第三步**：构建 Message 实体类和 MessageMapper 接口：

   ```java
   public interface MessageMapper { 
       Message getMessageById(Long id); 
       int insert(User user); 
       int delById(Long id);
   }
   
   ```

#### 2、select | 查询

##### 1）基础类型查询

```java
Message message = messageMapper.getMessageById(2L);

public interface MessageMapper {
    Message getMessageById(Long id); 
}

```

```xml
<select id="getMessageById" parameterType="long" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} 
</select>

```

##### 2）Map 类型查询

```java
Map<String, String> paramsMap = new HashMap<>(); 
paramsMap.put("id", "2");
paramsMap.put("msgId", "1001"); 
Message message = messageMapper.getMessageByMap(paramsMap);

public interface MessageMapper {
    Message getMessageByMap(Map<String, String> params); 
}

```

```xml
<select id="getMessageByMap" parameterType="map" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} and msg_id = #{msgId} 
</select>

```

##### 3）注解方式传递参数

```java
message = messageMapper.getMessageByAnnotation(2L, "1001");

public interface MessageMapper { 
    Message getMessageByAnnotation(@Param("id") Long id, @Param("msgId") String msgId); 
}

```

```xml
<select id="getMessageByAnnotation" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} and msg_id = #{msgId} 
</select>

```

##### 4）Java Bean 方式传递参数

```java
Message param = new Message(); 
param.setId(1L); 
param.setMsgId("1000"); 
message = messageMapper.getMessageByMessage(param);

public interface MessageMapper {
    Message getMessageByMessage(Message message);
}

```

```xml
<select id="getMessageByMessage" parameterType="vo.Message" resultMap="messageResult"> 
     select 
     	<include refid="allColumns"/> 
     from tb_message 
     where id = #{id} 
     and msg_id = #{msgId} 
</select>

```

> 总结：
>
> - 使用 Map 传递参数：
>   => 会导致业务可读性的丧失，后续维护困难，实际工作中应该尽量避免使用这种方式
> - 使用 @Param 注解：
>   => 如果参数 <= 5时，是最佳的传参方式，比 JavaBean 更直观，但是如果参数多，那么会造成接口参数膨胀，可读性和维护性差。
> - 使用 Java Bean 方式：
>   => 当参数个数 > 5时，建议采用这种方式。

#### 3、insert | 插入

##### 1）普通插入 | 主键不回填

```xml
<insert id="insert" parameterType="message" keyProperty="id"> 
    insert into tb_message(<include refid="updateAllColumns"/>) 
    values (#{msgId}, #{status}, #{content}, #{deleted}, #{createTime}) 
</insert>

```

##### 2）主键回填 | useGeneratedKeys="true"

```xml
<insert id="insertAndGetIdBack" parameterType="message" keyProperty="id" useGeneratedKeys="true"> 
    insert into tb_message(<include refid="updateAllColumns"/>) 
    values (#{msgId}, #{status}, #{content}, #{deleted}, #{createTime}) 
</insert>

```

#### 4、update | 更新

```java
messageMapper.updateContentById(1L, "bbbb");
sqlSession.commit();

int updateContentById(@Param("id") Long id, @Param("content") String content);

```

```xml
<update id="updateContentById" parameterType="message"> 
    update tb_message 
    set content=#{content} 
    where id=#{id} 
</update>

```

#### 5、delete | 删除

```java
messageMapper.delById(28L); 
sqlSession.commit();

int delById(@Param("id") Long id);

```

```xml
<delete id="delById" parameterType="long"> 
    delete from tb_message where id = #{id} 
</delete>

```

#### 6、${} 与 #{} | 防止sql注入

1. 简单的说就是，`#{}` 是经过预编译的，属于占位符的作用，参数赋值时只会替换掉占位符，由于 SQL 格式在编译时已经确认，所以无论参数怎么传，都是安全的。
2. 而 `${}` 是未经过预编译的，仅仅是取变量的值，属于字符串 append 添加，可能会追加新的 SQL，是非安全的，存在 SQL 注入的风险。
3. 因此，在编写 mybatis 的映射语句时，尽量采用 `#{}`  的格式。

##### 1）#{} 方式

```xml
<select id="getMessageByMsgId" resultMap="messageResult">
    select 
    	<include refid="allColumns"/> 
    from tb_message where msg_id = #{msgId} 
</select>

```

```java
// 结果输出与结论：所以，#{}采用的是，预编译的方式，去构建查询语句
Preparing: select id, msg_id, status, content, deleted, create_time, update_time from tb_message where msg_id = ? 
==> Parameters: 1001(String)

```

##### 2）${} 方式

```xml
<select id="getMessageByMsgId" resultMap="messageResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where msg_id = ${msgId} 
</select>

```

```java
// 结果输出与结论：所以，${}方式采用的是，值传递的方式，去构建查询语句，存在SQL注入的风险
Preparing: 
select id, msg_id, status, content, deleted, create_time, update_time from tb_message where msg_id = 1001

```

#### 7、结果集处理

##### 1）使用 Map 存储结果集

```java
Map map = messageMapper.getMessageMapById(2L);

```

```xml
<select id="getMessageMapById" resultType="map"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message where id = #{id} 
</select>

```

##### 2）使用 POJO 存储结果集

```java
Message message = messageMapper.getMessageById(2L);

```

```xml
<resultMap id="messageResult" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
</resultMap>

<select id="getMessageById" resultMap="messageResult">
    select
    <include refid="allColumns"/>
    from tb_message where id = #{id}
</select>

```

#### 8、级联查询

##### 1）一对一 | association

```java
Message message = messageMapper.getMessageAndMessageDetailById(2L);

Message getMessageAndMessageDetailById(@Param("id") Long id);

```

```xml
<resultMap id="messageAndDetailResult" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
    <association column="msg_id" property="messageDetail" select="mapper.MessageDetailMapper.getMessageByMsgId"/>
</resultMap>

<select id="getMessageByMsgId" resultMap="msgDetailResult"> 
    select 
    	<include refid="allColumns"/> 
    from tb_message_detail where msg_id = #{msgId} 
</select>

```

##### 2）一对一 | 多参数关联

```java
Message message = messageMapper.getMessageAndMessageDetailById1(2L);

Message getMessageAndMessageDetailById1(@Param("id") Long id);
MessageDetail getMessageByMsgIdAndCreateTime(@Param("msgId") String msgId, @Param("content") String content);

```

```xml
<resultMap id="messageAndDetailResult1" type="vo.Message">
    <id column="id" property="id"/>
    <result column="msg_id" property="msgId"/>
    <result column="status" property="status"/>
    <result column="content" property="content"/>
    <result column="deleted" property="deleted"/>
    <result column="create_time" property="createTime"/>
    <result column="update_time" property="updateTime"/>
    <association column="{msgId=msg_id, content=content}" property="messageDetail"
                 select="mapper.MessageDetailMapper.getMessageByMsgIdAndCreateTime"/>
</resultMap>

<select id="getMessageAndMessageDetailById1" parameterType="long" resultMap="messageAndDetailResult1">
    select
    <include refid="allColumns"/>
    from tb_message where id = #{id}
</select>

```

##### 3）一对多 | collection

```java
User getUserAndContactById(@Param("id") Long id);

```

```xml
<resultMap id="userContactResultMap" type="vo.User">
    <id column="id" property="id"/>
    <result column="name" property="name"/>
    <result column="age" property="age"/>
    <collection column="id" property="userContacts" select="mapper.UserContactMapper.getUserContactByUserId"/>
</resultMap>

<select id="getUserAndContactById" parameterType="long" resultMap="userContactResultMap">
    select id, name, age from tb_user where id = #{id}
</select>

```

#### 9、缓存

##### 1）一级缓存

MyBatis 默认开启一级缓存，即：同一个 SqlSession 对象，调用同一个 Mapper 的方法时，如果没有声明需要刷新，并且缓存没超时的情况下，一般只执行一次 SQL，其他的查询 SqlSession 都只会取出当前缓存的数据。如下所示：

```java
public class CacheExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = SqlSessionFactoryUtil.openSqlSession();
        UserMapper userMapper = sqlSession.getMapper(UserMapper.class);

        User user1 = userMapper.getUserById(1L);
        System.out.println("----真实查询-----user1 = " + user1);

        //当使用二级缓存的时候，只有调用了commit方法后才会生效。
        sqlSession.commit();

        User user2 = userMapper.getUserById(1L);
        System.out.println("----缓存查询-----user2 = " + user2);

        /**
         * 开启了新的sqlSession，则无法利用一级缓存。因为一级缓存是sqlSession之间隔离的。
         */
        sqlSession = SqlSessionFactoryUtil.openSqlSession();
        userMapper = sqlSession.getMapper(UserMapper.class);
        User user3 = userMapper.getUserById(1L);
        System.out.println("----真实查询-----user3 = " + user3);
    }
}

```

输出如下：

```java
Created connection 1071097621. Returned connection 1071097621 to pool. Cache Hit Ratio [mapper.UserMapper]: 0.0 Opening JDBC
Connection Checked out connection 1071097621 from pool. Setting autocommit to false on JDBC Connection
[com.mysql.cj.jdbc.ConnectionImpl@3fd7a715] 
==> Preparing: select id, name, age from tbuser where id = ? ==> Parameters: 1(Long) 
<== Columns: id, name, age 
<== Row: 1, muse1, 22 
<== Total: 1 ----真实查询-----user1 = User{id=1, name='muse1', age=22, userContacts=null}
Cache Hit Ratio [mapper.UserMapper]: 0.0 ----缓存查询-----user2 = User{id=1, name='muse1', age=22, userContacts=null} 
Cache Hit Ratio
[mapper.UserMapper]: 0.0 Opening JDBC Connection Created connection 280265505. Setting autocommit to false on JDBC Connection
[com.mysql.cj.jdbc.ConnectionImpl@10b48321] 
==> Preparing: select id, name, age from tbuser where id = ? ==> Parameters: 1(Long) <== Columns: id, name, age 
<== Row: 1, muse1, 22 
<== Total: 1 ----真实查询-----user3 = User{id=1, name='muse1', age=22, userContacts=null}
Process finished with exit code 0

```

##### 2）二级缓存

在 UserMapper.xml 中添加标签，当使用二级缓存的时候，只有调用了 `sqlSession.commit();` 方法后才会生效，且 POJO 必须实现 Serializable 接口。使用方式：

```xml
<mapper namespace="mapper.UserMapper">
	<!-- UserMapper开启二级缓存 -->
	<cache/>
</mapper>

```

##### 3）自定义缓存

可以通过实现 `org.apache.ibatis.cache.Cache` 接口，使用 Redis，Memcache 等缓存机制，来实现自定义缓存。使用方式：

```xml
<mapper namespace="mapper.UserMapper">
	<!-- UserMapper开启二级缓存 -->
	<cache type="com.muse.RedisCache"/>
</mapper>

```

#### 10、动态 SQL

##### 1）if

最常用的判断语句：

```java
public interface UserMapper { 
    User getUserByUser(User user);
}

```

```xml
<select id="getUserByUser" parameterType="vo.User" resultMap="userResultMap"> 
    select id, name, age 
    from tb_user
    where 1=1 
    <if test="id != null"> 
        and id = #{id} 
    </if> 
    <if test="name != null and name != ''">
        and name = #{name}
    </if> 
    <if test="age != null"> 
        and age = #{age} 
    </if> 
</select>

```

##### 2）choose、when、otherwise

相当于 if-if else-else：

```java
User userParam = new User();
userParam.setName("muse1"); 
// userParam.setId(1L); 
userParam.setAge(22);
User user = userMapper.getUserByUser2(userParam);
System.out.println("user = " + user);

public interface UserMapper { 
    User getUserByUser2(User user); 
}

```

```xml
<select id="getUserByUser2" parameterType="vo.User" resultMap="userResultMap">
    select id, name, age
    from tb_user
    where 1=1
    <choose>
        <when test="id != null">
            and id = #{id}
        </when>
        <when test="name != null and name != ''">
            and name = #{name}
        </when>
        <otherwise>
            and age is not null
        </otherwise>
    </choose>
</select>

```

##### 3）where

可以通过标签，来避免去写 where 1=1。如下所示：

```java
User userParam = new User(); 
userParam.setId(1L);
List<User> user = userMapper.getUserByUser3(userParam); System.out.println("user = " + user);

// 指定ID的输出结果：
==> Preparing: select id, name, age from tb_user WHERE id = ? 
==> Parameters: 1(Long) 
<== Columns: id, name, age <== Row: 1, muse1, 22
<== Total: 1 user = [User{id=1, name='muse1', age=22, userContacts=null}]

```

```java
User userParam = new User(); 
// userParam.setId(1L);
List<User> user = userMapper.getUserByUser3(userParam);
System.out.println("user = " + user);

// 不指定ID的输出结果：
==> Preparing: select id, name, age from tb_user
==> Parameters: 
<== Columns: id, name, age 
<== Row: 1, muse1, 22 <== Row: 2, muse2, 24 
<== Total: 2 user = [User{id=1, name='muse1', age=22, userContacts=null}, User{id=2, name='muse2', age=24, userContacts=null}]

```

```xml
<select id="getUserByUser3" parameterType="vo.User" resultMap="userResultMap">
    select
    id, name, age from tb_user
    <where>
        <if test="id != null">
            and id = #{id}
        </if>
    </where>
</select>

```

##### 4）trim

有时候，要去掉一些特殊的 SQL 语法，比如 and、or。则可以使用 trim 标签。

```xml
<select id="getUserByUser4" parameterType="vo.User" resultMap="userResultMap">
    select id, name, age 
    from tb_user 
    <trim prefix="where" prefixOverrides="and">
        and id = #{id} 
    </trim> 
</select>

```

【解释】

- prefix，表示输出前缀语句 where。
- prefixOverrides，表示 where 后面的语句的前缀（第一个）and，要清除掉。

##### 5）set

set 标签会默认把最后一个逗号去掉：

```xml
<update id="updateUserByUser" parameterType="vo.User"> 
    update tb_user
    <set> 
        <if test="name != null and name != ''"> name = #{name}, </if>
        <if test="age != null"> age = #{age}, </if>
    </set> 
    where id = #{id} 
</update>

```

也可以采用 trim 的方式：

```xml
<update id="updateUserByUser" parameterType="vo.User"> 
    update tb_user 
    <trim prefix="set" suffixOverrides=","> 
        <if test="name != null and name != ''"> name = #{name}, </if> 
        <if test="age != null"> age = #{age}, </if> 
    </trim>
    where id = #{id}
</update>

```

##### 6）foreach

foreach 语句，用于循环遍历传入的集合数据：

```java
public interface UserMapper {
    List<User> getUserByIds(@Param("idList") List<Long> idList);
}

```

```xml
<select id="getUserByIds" resultMap="userResultMap">
    select id, name, age 
    from tb_user where id in 
    <foreach collection="idList" index="index" item="id" open="(" separator="," close=")"> 
        #{id} 
    </foreach> 
</select>

```

【解释】

- collection：传递进来的参数名称，可以是数组、List、Set等集合。
- index：当前元素在集合的下标位置。
- item：循环中当前的元素。
- open和close：使用什么符号包装集合元素。
- separator：每个元素的间隔符号。

##### 7）test

test 属性用于条件判断的语句中。

```xml
<select id="getUserByUser3" parameterType="vo.User" resultMap="userResultMap"> 
    select id, name, age 
    from tb_user 
    <where> 
        <if test="id != null"> and id = #{id} </if> 
    </where> 
</select>

```

##### 8）bind

bind 用于优化重复的 SQL 字段模板：

```java
List<User> users = userMapper.getUserByName("muse");

List<User> getUserByName(@Param("name") String name);

// 输出结果：
==> Preparing: select id, name, age from tb_user where name like ? ==> Parameters: %muse%(String) 
<== Columns: id, name, age 
<== Row: 1, muse, 22 
<== Row: 2, muse2, 24 
<== Total: 2

```

```xml
<select id="getUserByName" parameterType="string" resultMap="userResultMap"> 
    <bind name="namePattern" value="'%' + name + '%'"/> 
    select id, name, age from tb_user 
    where name like #{namePattern} 
    <!-- 等于name like concat('%', #{name}, '%') --> 
</select>

```

### 1.6. Java 动态代理？

#### 1、反射

```java
public class Reflaction { 
    public static void main(String[] args) throws Throwable { 
        Class clazz = User.class; 
        User user = (User) clazz.newInstance();
        Method method = clazz.getMethod("setName", String.class); 
        method.invoke(user, "张三");
        System.out.println(user.getName()); // 输出：张三 
    }
}

```

#### 2、JDK 动态代理

JDK 动态代理，需要提供接口，而 MyBatis 的 Mapper 就是一个接口，它采用的就是 JDK 动态代理。如下所示：

```java
public interface MessageService { 
    void sendMessage(); 
}

public class MessageServiceImpl implements MessageService {
    public void sendMessage() {
        System.out.println("MessageServiceImpl.sendMessage"); 
    } 
}

```

```java
public class JdkProxy<T> implements InvocationHandler {

    T target;

    public T getProxy(T target) {
        this.target = target;

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("JDK动态代理拦截开始！");
        Object result =  method.invoke(target, args);
        System.out.println("JDK动态代理拦截结束！");
        return result;
    }
}

```

```java
public class Executer {
    public static void main(String[] args) {
        JdkProxy<MessageService> jdkProxy = new JdkProxy();
        MessageService messageService = jdkProxy.getProxy(new MessageServiceImpl());
        messageService.sendMessage();
    }
}

```

#### 3、CGLIB 动态代理

CGLIB，不需要提供接口，即可实现动态代理，当然，它也可以代理有接口的服务类。如下所示：

```java
public class PlayService {
    public void play() {
        System.out.println("PlayService.play");
    }
}

```

```java
public class CglibProxy<T> implements MethodInterceptor {

    T target;

    public T getProxy(T target) {
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return (T) enhancer.create();
    }

    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {
        System.out.println("CGLIB动态代理拦截开始!");
        Object result = methodProxy.invokeSuper(o, objects);
        System.out.println("CGLIB动态代理拦截结束!");
        return result;
    }
}

```

```java
public class Executer {
    public static void main(String[] args) {
        CglibProxy<PlayService> cglibProxy = new CglibProxy();
        
        // 代理无接口服务类
        PlayService playService = cglibProxy.getProxy(new PlayService());
        playService.play();

//        CglibProxy<MessageService> cglibProxy1 = new CglibProxy();
//        // 代理有接口服务类
//        MessageService messageService = cglibProxy1.getProxy(new MessageServiceImpl());
//        messageService.sendMessage();
    }
}

```

### 1.7. MyBatis 整体架构？

![1647161327867](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647161327867.png)

MyBatis 的整体架构分为三层：

1. **API接口层**：
   - 提供给外部使用的接口 API，开发人员通过这些本地 API 来操纵数据库。
   - 接口层一接收到调用请求，就会调用数据处理层来完成具体的数据处理。
2. **数据处理层**：
   - 负责具体的 SQL 查找、SQL 解析、SQL 执行和执行结果映射处理等。
   - 其主要的目的是，根据调用的请求完成一次数据库操作。
3. **基础支撑层**：
   - 负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理。
   - 这些都是共用的东西，将他们抽取出来作为最基础的组件，为上层的数据处理层提供最基础的支撑。

### 1.8. MyBatis SqlSession 执行流程？

#### 1、获取 Mapper 的动态代理

1. 自定义的 Mapper 接口想要发挥功能，必须有具体的实现类，在 MyBatis 中是通过为 Mapper 每个接口提供一个动态代理。
2. 动态代理类来实现的整个过程主要有四个类：MapperRegistry、MapperProxyFactory、MapperProxy、MapperMethod。
   - **MapperRegistry**：是 Mapper 接口及其对应的代理对象工厂的注册中心。
   - **MapperProxyFactory**：是 MapperProxy 的工厂类，主要方法就是包装了 Java 动态代理 `Proxy.newProxyInstance()` 方法。
   - **MapperProxy**：是一个动态代理类，实现了 `InvocationHandler` 接口，对于代理对象的调用都会被代理到 `InvocationHandler#invoke()` 方法上。
   - **MapperMethod**：包含了具体增删改查方法的实现逻辑。

```java
public class UserExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = null;
        try {
            sqlSession = SqlSessionFactoryUtil.openSqlSession();
            // 1、获取 Mapper 的动态代理
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            User user = userMapper.getUserById(2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        }
    }
}

public class DefaultSqlSession implements SqlSession {
    @Override
    public <T> T getMapper(Class<T> type) {
        // 2、获取 Mapper 的动态代理
        return configuration.<T>getMapper(type, this);
    }
}

public class Configuration {
    public <T> T getMapper(Class<T> type, SqlSession sqlSession) {
        // 3、获取 Mapper 的动态代理
        return mapperRegistry.getMapper(type, sqlSession);
    }
}

public class MapperRegistry {
    /**
      * 4、加载mybatis-config.xml配置的<mapper>配置，根据指定type，查找对应的MapperProxyFactory对象
      **/
    // eg1: 获得UserMapper的mapperProxyFactory
    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);
    
    /**
      * 5、如果没配置<mapper>，则找不到对应的MapperProxyFactory，抛出BindingException异常
      */
    if (mapperProxyFactory == null) {
        throw new BindingException("Type " + type + " is not known to the MapperRegistry.");
    }
    
    try {
        /** 6、使用该工厂类生成MapperProxy的代理对象 */
        return mapperProxyFactory.newInstance(sqlSession);
    } catch (Exception e) {
        throw new BindingException("Error getting mapper instance. Cause: " + e, e);
    }
}

public class MapperProxyFactory<T> {

    public T newInstance(SqlSession sqlSession) {
        /**
         * 7、创建MapperProxy对象，每次调用都会创建新的MapperProxy对象，MapperProxy implements InvocationHandler
         */
        final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);
        return newInstance(mapperProxy);
    }
    
   protected T newInstance(MapperProxy<T> mapperProxy) {
        // 8、通过动态代理，创建mapperInterface的代理类对象
        return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] {mapperInterface}, mapperProxy);
    }
}

```

#### 2、获得 MapperMethod 对象

```java
public class UserExecuter {
    public static void main(String[] args) {
        SqlSession sqlSession = null;
        try {
            sqlSession = SqlSessionFactoryUtil.openSqlSession();
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            // 1、发起方法调用，调用代理对象增强后的方法
            User user = userMapper.getUserById(2L);
            System.out.println("姓名：" + user.getName() + "，年龄：" + user.getAge());
        }
    }
}

public class MapperProxy<T> implements InvocationHandler, Serializable {
    // eg1: UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
    //      User user = userMapper.getUserById(2L); args = {2L}
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        try {
            /** 2、如果被代理的方法是Object类的方法，如toString()、clone()，则不进行代理 */
            // eg1: method.getDeclaringClass()==interface mapper.UserMapper  由于被代理的方法是UserMapper的getUserById方法，而不是Object的方法，所以返回false
            if (Object.class.equals(method.getDeclaringClass())) {
                return method.invoke(this, args);
            }

            /** 3、如果是接口中的default方法，则调用default方法 */
            else if (isDefaultMethod(method)) { // eg1: 不是default方法，返回false
                return invokeDefaultMethod(proxy, method, args);
            }
        } catch (Throwable t) {
            throw ExceptionUtil.unwrapThrowable(t);
        }
        
        // eg1: method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
        /** 4、初始化一个MapperMethod并放入缓存中 或者 从缓存中取出之前的MapperMethod */
        final MapperMethod mapperMethod = cachedMapperMethod(method);

        // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
        /** 99、调用MapperMethod.execute()方法执行SQL语句 */
        return mapperMethod.execute(sqlSession, args);
    }
    
    // eg1: public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
    private MapperMethod cachedMapperMethod(Method method) {
        /**
         * 5、在缓存中查找MapperMethod，若没有，则创建MapperMethod对象，并添加到methodCache集合中缓存
         */
        // eg1: 因为methodCache为空，所以mapperMethod等于null
        MapperMethod mapperMethod = methodCache.get(method);
        if (mapperMethod == null) {
            // eg1: 6、构建mapperMethod对象，并维护到缓存methodCache中
            mapperMethod = new MapperMethod(mapperInterface, method, sqlSession.getConfiguration());
            // eg1: method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
            methodCache.put(method, mapperMethod);
        }
        return mapperMethod;
    }
}

public class MapperMethod {
    // eg1: 7、mapperInterface = interface mapper.UserMapper
    //      method = public abstract vo.User mapper.UserMapper.getUserById(java.lang.Long)
    public MapperMethod(Class<?> mapperInterface, Method method, Configuration config) {
        this.command = new SqlCommand(config, mapperInterface, method);
        this.method = new MethodSignature(config, mapperInterface, method);
    }
}

```

#### 3、根据 SQL 指令跳转执行语句

```java
public class MapperProxy<T> implements InvocationHandler, Serializable {
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
      	...
        // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
        /** 1、调用MapperMethod.execute()方法执行SQL语句 */
        return mapperMethod.execute(sqlSession, args);
    }
}

public class MapperMethod {
    /**
     * 2、MapperMethod采用命令模式运行，根据上下文跳转，它可能跳转到许多方法中。实际上它最后就是通过SqlSession对象去运行对象的SQL。
     */
    // eg1: sqlSession = DefaultSqlSession@1953  args = {2L}
    public Object execute(SqlSession sqlSession, Object[] args) {
        Object result;
        // eg1: command.getType() = SELECT
        switch (command.getType()) {
            case INSERT: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.insert(command.getName(), param));
                break;
            }
            case UPDATE: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.update(command.getName(), param));
                break;
            }
            case DELETE: {
                Object param = method.convertArgsToSqlCommandParam(args);
                result = rowCountResult(sqlSession.delete(command.getName(), param));
                break;
            }
            case SELECT:
                // eg1: method.returnsVoid() = false  method.hasResultHandler() = false
                if (method.returnsVoid() && method.hasResultHandler()) {
                    executeWithResultHandler(sqlSession, args);
                    result = null;
                } else if (method.returnsMany()) { // eg1: method.returnsMany() = false
                    result = executeForMany(sqlSession, args);
                } else if (method.returnsMap()) { // eg1: method.returnsMap() = false
                    result = executeForMap(sqlSession, args);
                } else if (method.returnsCursor()) { // eg1: method.returnsCursor() = false
                    result = executeForCursor(sqlSession, args);
                } else {
                    // eg1: args = {2L}
                    /** 3、将参数转换为sql语句需要的入参 */
                    Object param = method.convertArgsToSqlCommandParam(args);

                    // eg1: sqlSession=DefaultSqlSession  command.getName()="mapper.UserMapper.getUserById" param={"id":2L, "param1":2L}
                    /** 4、执行sql查询操作 */
                    result = sqlSession.selectOne(command.getName(), param);
                }
                break;
            case FLUSH:
                result = sqlSession.flushStatements();
                break;
            default:
                ...
        }
        return result;
    }
}

```

#### 4、查询前的缓存处理

```java
public class MapperMethod {
    public Object execute(SqlSession sqlSession, Object[] args) {
        ...
        // 1、执行sql查询操作
        result = sqlSession.selectOne(command.getName(), param);
        ...
    }
}

public class DefaultSqlSession implements SqlSession {
    // 2、eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <T> T selectOne(String statement, Object parameter) {
        List<T> list = this.selectList(statement, parameter);
        if (list.size() == 1) {
            return list.get(0);
        } else if (list.size() > 1) {
            throw new TooManyResultsException(
                    "Expected one result (or null) to be returned by selectOne(), but found: " + list.size());
        } else {
            return null;
        }
    }
    
    // 3、eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <E> List<E> selectList(String statement, Object parameter) {
        return this.selectList(statement, parameter, RowBounds.DEFAULT);
    }
    
    // eg1: statement="mapper.UserMapper.getUserById" parameter={"id":2L, "param1":2L}
    @Override
    public <E> List<E> selectList(String statement, Object parameter, RowBounds rowBounds) {
        try {
            // 4、eg1: statement="mapper.UserMapper.getUserById"
            MappedStatement ms = configuration.getMappedStatement(statement);
            // 5、eg1: executor=CachingExecutor
            //      wrapCollection(parameter)=parameter={"id": 2L, "param1", 2L}
            //      rowBounds=RowBounds.DEFAULT=new RowBounds()
            //      Executor.NO_RESULT_HANDLER=null
            return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
        } catch (Exception e) {
            throw ExceptionFactory.wrapException("Error querying database.  Cause: " + e, e);
        } finally {
            ErrorContext.instance().reset();
        }
    }
}

public class CachingExecutor implements Executor {
    // 6、eg1: parameterObject={"id":2L, "param1":2L}
    //      rowBounds=new RowBounds()
    //      resultHandler=null
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
        // eg1: parameterObject = {"id":2L, "param1":2L}
        /** 7、获得boundSql对象，承载着sql和对应的参数*/
        BoundSql boundSql = ms.getBoundSql(parameterObject);

        // eg1: parameterObject = {"id":2L, "param1":2L}  rowBounds = new RowBounds()
        /** 8、生成缓存key */
        CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql);

        // eg1: parameterObject = {"id":2L, "param1":2L}  rowBounds = new RowBounds() resultHandler = null
        /** 9、执行查询语句 */
        return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
    
    // 10、eg1: parameterObject = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameterObject, RowBounds rowBounds,
                             ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        Cache cache = ms.getCache();
        // eg1: cache = null
        /** 11、如果在UserMapper.xml配置了<cache/>开启了二级缓存，则cache不为null*/
        if (cache != null) {
            /**
             * 如果flushCacheRequired=true并且缓存中有数据，则先清空缓存
             *
             * <select id="save" parameterType="XXXXXEO" statementType="CALLABLE" flushCache="true" useCache="false">
             *     ……
             * </select>
             * */
            flushCacheIfRequired(ms);

            /** 12、如果useCache=true并且resultHandler=null*/
            if (ms.isUseCache() && resultHandler == null) {
                ensureNoOutParams(ms, parameterObject, boundSql);
                @SuppressWarnings("unchecked")
                List<E> list = (List<E>) tcm.getObject(cache, key);
                if (list == null) {
                    /** 13、执行查询语句 */
                    list = delegate.<E>query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
                    /** 14、以cacheKey为主键，将结果维护到缓存中 */
                    tcm.putObject(cache, key, list); // issue #578 and #116
                }
                return list;
            }
        }
        // 15、如果没有开启二级缓存，则走这里
        // eg1: delegate = SimpleExecutor(BaseExecutor) parameterObject = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
        return delegate.<E>query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);
    }
}

public abstract class BaseExecutor implements Executor {
    // 16、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @SuppressWarnings("unchecked")
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                             CacheKey key, BoundSql boundSql) throws SQLException {
        ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId());
        // 17、eg1: closed = false
        if (closed) {
            throw new ExecutorException("Executor was closed.");
        }

        // eg1: queryStack = 0  ms.isFlushCacheRequired() = false
        /** 18、如果配置了flushCacheRequired=true并且queryStack=0（没有正在执行的查询操作），则会执行清空缓存操作*/
        if (queryStack == 0 && ms.isFlushCacheRequired()) {
            clearLocalCache();
        }

        List<E> list;
        try {
            /** 19、记录正在执行查询操作的任务数*/
            queryStack++; // eg1: queryStack=1

            // eg1: resultHandler=null localCache.getObject(key)=null
            /** 20、localCache维护一级缓存，试图从一级缓存中获取结果数据，如果有数据，则返回结果；如果没有数据，再执行queryFromDatabase */
            list = resultHandler == null ? (List<E>) localCache.getObject(key) : null;
            // eg1: list = null
            if (list != null) {
                /** 21、如果是执行存储过程 */
                handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
            } else {
                // eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
                list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
            }
        } finally {
            queryStack--;
        }
        if (queryStack == 0) {
            /** 22、延迟加载处理 */
            for (DeferredLoad deferredLoad : deferredLoads) {
                deferredLoad.load();
            }
            // issue #601
            deferredLoads.clear();

            // eg1: configuration.getLocalCacheScope()=SESSION
            /** 23、如果设置了<setting name="localCacheScope" value="STATEMENT"/>，则会每次执行完清空缓存。即：使得一级缓存失效 */
            if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) {
                // issue #482
                clearLocalCache();
            }
        }
        return list;
    }
    
    @Override
    public void clearLocalCache() {
        if (!closed) {
            localCache.clear();
            localOutputParameterCache.clear();
        }
    }
}

```

#### 5、执行 DB 查询操作

Mapper执行的过程是通过 Executor、StatementHandler、ParameterHandler 和 ResultHandler 来完成数据库操作和结果返回的：

1. **Executor**：
   - 1）代表执行器，由它来调度 StatementHandler、ParameterHandler、ResultHandler 等来执行对应的SQL。
   - 2）执行器 Executor 是一个真正执行执行 Java 和数据库交互的类，一共有 3 种执行器，可以在MyBatis 的配置文件中，设置 defaultExecutorType 属性来进行选择：
     1. **SIMPLE**：org.apache.ibatis.executor.SimpleExecutor，简易执行器，默认执行器。
     2. **REUSE**：org.apache.ibatis.executor.ReuseExecutor，是一种执行器重用预处理语句。
     3. **BATCH**：org.apache.ibatis.executor.BatchExecutor，执行器重用语句和批量更新，它是针对批量专用批量专用的执行器。
2. **StatementHandler**：
   - 1）作用是使用数据库的 Statement（PreparedStatement）执行操作，起到承上启下的作用，专门处理数据库会话的，创建 StatementHandler 的过程在 Configuration 中。
   - 2）MyBatis 是使用来委派模式，把具体的 StatementHandler 类型隐藏起来，通过 `RoutingStatementHandler` 来统一管理，一共用三种具体的StatementHandler类型：
     SimpleHandler、PreparedStatementHandler 和 CallableStatementHandler。
   - 3）在 Executor 的具体执行逻辑中，主要关注 `StatementHandler#prepared` 和 `StatementHandler#parameterize` 两个方法。
3. **ParameterHandler**：
   - 1）用于SQL对参数的处理。
   - 2）MyBatis 是通过 ParameterHandler 对预编译的语句进行参数设置的。
   - 3）MyBatis 为 ParameterHandler 提供了一个实现类 DefaultParameterHandler，具体执行过程是：
     1. 从 parameterObject 对象中取参数。
     2. 然后使用 typeHandler 进行参数处理。
     3. 而 typeHandler 也是在 MyBatis 初始化时，注册在 Configuration 里面的，需要时可以直接拿来用。
4. **ResultHandler**：
   - 1）进行最后数据集（ResultSet）的封装返回处理。
   - 2）MyBatis 为我们提供了一个 DefaultResultSetHandler 类，在默认情况下，都是通过这个类进行处理的。
   - 3）这个类 JAVASSIST 或者 CGLIB 作为延迟加载，然后通过 typeHandler 和 ObjectFactory 进行组装结果再返回。

=> 以 SimpleExecutor 来看一下 Executor 的**具体执行逻辑**：

1. 根据 Configuration 来构建 StatementHandler。
2. 然后使用 `prepareStatement` 方法，对 SQL 编译并对参数进行初始化。
3. 在 `prepareStatement` 方法中，调用了 `StatementHandler#prepared` 进行了预编译和基础设置。
4. 然后通过 `StatementHandler#parameterize` 来设置参数并执行。
5. 包装好的 Statement 通过 StatementHandler 来执行，并把结果传递给 resultHandler。

```java
public abstract class BaseExecutor implements Executor {
    @SuppressWarnings("unchecked")
    @Override
    public <E> List<E> query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                             CacheKey key, BoundSql boundSql) throws SQLException {
        ...
        // 1、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);
        ...
    }
    
    // 2、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    private <E> List<E> queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds,
                                          ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
        List<E> list;
        // 3、eg1: key = -445449180:-48278933:mapper.UserMapper.getUserById:0:2147483647:select id, name, age from tb_user where id = ?:2:dev
        localCache.putObject(key, EXECUTION_PLACEHOLDER);
        try {
            // 4、eg1: SimpleExecutor.doQuery parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
            list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
        } finally {
            localCache.removeObject(key);
        }
        /** 99、将查询结果放到一级缓存中，如果同一session中有相同查询操作，则可以直接从缓存中获取结果*/
        localCache.putObject(key, list);

        // eg1: ms.getStatementType() = PREPARED
        if (ms.getStatementType() == StatementType.CALLABLE) {
            localOutputParameterCache.putObject(key, parameter);
        }
        return list;
    }
}

public class SimpleExecutor extends BaseExecutor {
    // 5、eg1: parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
    @Override
    public <E> List<E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler,
                               BoundSql boundSql) throws SQLException {
        Statement stmt = null;
        try {
            Configuration configuration = ms.getConfiguration();
            /** 6、根据Configuration来构建StatementHandler */
            StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds,
                    resultHandler, boundSql);

            // eg1: handler=RoutingStatementHandler
            /** 7、然后使用prepareStatement方法，对SQL进行预编译并设置入参 */
            stmt = prepareStatement(handler, ms.getStatementLog());

            // eg1: handler=RoutingStatementHandler parameter = {"id": 2L, "param1", 2L}  rowBounds = new RowBounds() resultHandler = null
            /** 21、开始执行真正的查询操作。将包装好的Statement通过StatementHandler来执行，并把结果传递给resultHandler */
            return handler.<E>query(stmt, resultHandler);
        } finally {
            closeStatement(stmt);
        }
    }
    
    /**
     * 使用prepareStatement方法，对SQL编译并设置入参
     *
     * @param handler
     * @param statementLog
     * @return
     * @throws SQLException
     */
    // 8、eg1: handler=RoutingStatementHandler
    private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {
        Statement stmt;

        /** 9、获得Connection实例 */
        Connection connection = getConnection(statementLog);

        // eg1: handler=RoutingStatementHandler
        /** 10、第一步：调用了StatementHandler的prepared进行了【sql的预编译】 */
        stmt = handler.prepare(connection, transaction.getTimeout());

        /** 14、第二步：通过PreparedStatementHandler的parameterize来给【sql设置入参】 */
        handler.parameterize(stmt);

        // 20、eg1: 返回org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
        return stmt;
    }
}

public class RoutingStatementHandler implements StatementHandler {
    // 11、eg1: delegate=PreparedStatementHandler
    @Override
    public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException {
        return delegate.prepare(connection, transactionTimeout);
    }
    
    // 22、eg1: delegate = PreparedStatementHandler  resultHandler = null
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        return delegate.<E>query(statement, resultHandler);
    }
    
    // 15、第二步：通过PreparedStatementHandler的parameterize来给【sql设置入参】
    @Override
    public void parameterize(Statement statement) throws SQLException {
        delegate.parameterize(statement);
    }
}

public abstract class BaseStatementHandler implements StatementHandler {
    // eg1: delegate=PreparedStatementHandler
    /**
     * 12、执行预编译语句
     */
    @Override
    public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException {
        ErrorContext.instance().sql(boundSql.getSql());
        Statement statement = null;
        try {
            // eg1: 13、调用PreparedStatementHandler的instantiateStatement
            statement = instantiateStatement(connection);
            setStatementTimeout(statement, transactionTimeout);
            setFetchSize(statement);
            return statement;
        } catch (SQLException e) {
            closeStatement(statement);
            throw e;
        } catch (Exception e) {
            closeStatement(statement);
            throw new ExecutorException("Error preparing statement.  Cause: " + e, e);
        }
    }
}

public class PreparedStatementHandler extends BaseStatementHandler {
    // 16、eg1: org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
    @Override
    public void parameterize(Statement statement) throws SQLException {
        parameterHandler.setParameters((PreparedStatement) statement);
    }
    
    // 23、eg1: delegate = PreparedStatementHandler  resultHandler = null
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        /** 24、最终还是使用JDBC去进行数据操作 */
        PreparedStatement ps = (PreparedStatement) statement;

        /** 25、执行查询操作 */
        ps.execute();

        // eg1: 封装结果集 resultSetHandler=DefaultResultSetHandler
        /** 26、将结果集进行封装 */
        return resultSetHandler.handleResultSets(ps);
    }
}

public class DefaultParameterHandler implements ParameterHandler {
    // eg1: org.apache.ibatis.logging.jdbc.PreparedStatementLogger@2e570ded
    /**
     * 17、针对预处理语句，设置入参
     */
    @Override
    public void setParameters(PreparedStatement ps) {
        ErrorContext.instance().activity("setting parameters").object(mappedStatement.getParameterMap().getId());

        // 18、eg1: parameterMappings[0] = ParameterMapping{property='id', mode=IN, javaType=class java.lang.Long, jdbcType=null, numericScale=null, resultMapId='null', jdbcTypeName='null', expression='null'}
        List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();
        if (parameterMappings != null) {
            ...
            // eg1: typeHandler=BaseTypeHandler
            /** 19、针对预处理语句，设置入参 */
            typeHandler.setParameter(ps, i + 1, value, jdbcType);
            ...
        }
    }
}

```

#### 6、针对 ResultSet 结果集转换为 POJO

```java
public class PreparedStatementHandler extends BaseStatementHandler {
    @Override
    public <E> List<E> query(Statement statement, ResultHandler resultHandler) throws SQLException {
        ...
        // eg1: 封装结果集 resultSetHandler=DefaultResultSetHandler
        /** 1、将结果集进行封装 */
        return resultSetHandler.handleResultSets(ps);
    }
}

public class DefaultResultSetHandler implements ResultSetHandler {
    
    // 4、eg1: 执行到这里
    private ResultSetWrapper getFirstResultSet(Statement stmt) throws SQLException {
        // eg1: rs != null
        /** 5、通过JDBC获得结果集ResultSet */
        ResultSet rs = stmt.getResultSet();
        while (rs == null) {
            if (stmt.getMoreResults()) {
                rs = stmt.getResultSet();
            } else {
                /**
                 * 6、getUpdateCount()==-1,既不是结果集,又不是更新计数了.说明没的返回了。
                 * 如果getUpdateCount()>=0,则说明当前指针是更新计数(0的时候有可能是DDL指令)。
                 * 无论是返回结果集或是更新计数,那么则可能还继续有其它返回。
                 * 只有在当前指指针getResultSet()==null && getUpdateCount()==-1才说明没有再多的返回。
                 */
                if (stmt.getUpdateCount() == -1) {
                    // no more results. Must be no resultset
                    break;
                }
            }
        }
        // eg1: rs不为空，则将结果集封装到ResultSetWrapper中
        /** 7、将结果集ResultSet封装到ResultSetWrapper实例中 */
        return rs != null ? new ResultSetWrapper(rs, configuration) : null;
    }
    
    /**
     * 2、处理数据库操作的结果集
     */
    // eg1: 执行到这里
    @Override
    public List<Object> handleResultSets(Statement stmt) throws SQLException {
        ErrorContext.instance().activity("handling results").object(mappedStatement.getId());

        final List<Object> multipleResults = new ArrayList<>();
        int resultSetCount = 0;

        /** 3、首先：获得执行后的结果集，并封装到ResultSetWrapper */
        ResultSetWrapper rsw = getFirstResultSet(stmt);

        /** 8、其次：如果rsw != null && resultMapCount < 1，则抛异常ExecutorException */
        List<ResultMap> resultMaps = mappedStatement.getResultMaps();
        int resultMapCount = resultMaps.size(); // eg1: resultMapCount = 1
        validateResultMapsCount(rsw, resultMapCount);

        // eg1: rsw不为空 resultMapCount=1 resultSetCount=0
        /** 9、第三步：处理结果集 */
        while (rsw != null && resultMapCount > resultSetCount) {
            // eg1: ResultMap resultMap=resultMaps.get(0);
            ResultMap resultMap = resultMaps.get(resultSetCount);

            /** 10、处理结果集, 存储在multipleResults中 */
            handleResultSet(rsw, resultMap, multipleResults, null);

            // 33、eg1: rsw=null
            rsw = getNextResultSet(stmt);

            cleanUpAfterHandlingResultSet();
            resultSetCount++; // eg1: 自增后resultSetCount=1
        }

        String[] resultSets = mappedStatement.getResultSets();
        // eg1: 34、resultSets = null
        if (resultSets != null) {
            while (rsw != null && resultSetCount < resultSets.length) {
                ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
                if (parentMapping != null) {
                    String nestedResultMapId = parentMapping.getNestedResultMapId();
                    ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
                    handleResultSet(rsw, resultMap, null, parentMapping);
                }
                rsw = getNextResultSet(stmt);
                cleanUpAfterHandlingResultSet();
                resultSetCount++;
            }
        }

        // eg1: multipleResults.get(0).get(0) = User{id=2, name='muse2', age=24, userContacts=null}
        /** 99、返回结果 */
        return collapseSingleResultList(multipleResults);
    }
    
    // eg1: parentMapping = null
    /**
     * 11、处理结果集
     */
    private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List<Object> multipleResults,
                                 ResultMapping parentMapping) throws SQLException {
        try {
            // eg1: parentMapping = null
            if (parentMapping != null) {
                handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
            } else {
                // eg1: resultHandler = null
                if (resultHandler == null) {
                    // eg1: objectFactory = DefaultObjectFactory defaultResultHandler里面包含了一个空集合的ArrayList实例
                    /** 12、初始化ResultHandler实例，用于解析查询结果并存储于该实例对象中 */
                    DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
                    /** 13、解析行数据 */
                    handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
                    multipleResults.add(defaultResultHandler.getResultList());
                } else {
                    handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
                }
            }
        } finally {
            // eg1：
            /** 关闭ResultSet */
            closeResultSet(rsw.getResultSet());
        }
    }
    
    // 14、eg1: parentMapping = null
    public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler<?> resultHandler,
                                RowBounds rowBounds, ResultMapping parentMapping) throws SQLException {
        // eg1: resultMap.hasNestedResultMaps()=false
        /** 15、是否是聚合Nested类型的结果集 */
        if (resultMap.hasNestedResultMaps()) {
            ensureNoRowBounds();
            checkResultHandler();
            handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        } else {
            // 16、eg1: parentMapping = null
            handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping);
        }
    }
    
    // 17、eg1: parentMapping = null
    private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap,
                                                   ResultHandler<?> resultHandler, RowBounds rowBounds,
                                                   ResultMapping parentMapping) throws SQLException {
        DefaultResultContext<Object> resultContext = new DefaultResultContext<>();

        // eg1: skipRows里面没做什么事情
        /** 18、将指针移动到rowBounds.getOffset()指定的行号，即：略过（skip）offset之前的行 */
        skipRows(rsw.getResultSet(), rowBounds);

        // eg1: shouldProcessMoreRows(resultContext, rowBounds) = true    rsw.getResultSet().next() = true
        while (shouldProcessMoreRows(resultContext, rowBounds) && rsw.getResultSet().next()) {
            /** 23、解析结果集中的鉴别器<discriminate/> */
            ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null);

            /** 24、将数据库操作结果保存到POJO并返回 */
            Object rowValue = getRowValue(rsw, discriminatedResultMap);

            // eg1: rowValue=User{id=2, name='muse2', age=24, userContacts=null}  parentMapping = null
            /** 32、存储POJO对象到DefaultResultHandler中 */
            storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet());
        }
    }
    
    // eg1:
    /**
     * 19、将指针移动到rowBounds.getOffset()指定的行号，即：略过（skip）offset之前的行
     *
     * @param rs
     * @param rowBounds
     * @throws SQLException
     */
    private void skipRows(ResultSet rs, RowBounds rowBounds) throws SQLException {
        // 20、eg1: rs.getType() = 1003 = ResultSet.TYPE_FORWARD_ONLY
        /**
         * ResultSet.TYPE_FORWARD_ONLY          结果集的游标只能向下滚动
         * ResultSet.TYPE_SCROLL_INSENSITIVE    结果集的游标可以上下移动，当数据库变化时，当前结果集不变。
         * ResultSet.TYPE_SCROLL_SENSITIVE      返回可滚动的结果集，当数据库变化时，当前结果集同步改变
         */
        if (rs.getType() != ResultSet.TYPE_FORWARD_ONLY) {
            /** rowBounds.getOffset()不为0 */
            if (rowBounds.getOffset() != RowBounds.NO_ROW_OFFSET) {
                /** 21、将指针移动到此ResultSet对象的给定行编号rowBounds.getOffset()。 */
                rs.absolute(rowBounds.getOffset());
            }
        } else {
            // eg1: rowBounds.getOffset() = 0
            for (int i = 0; i < rowBounds.getOffset(); i++) {
                /** 22、将指针移动到此ResultSet对象的给定行编号rowBounds.getOffset()。 */
                rs.next();
            }
        }
    }
    
    /**
     * 25、将数据库操作结果保存到POJO并返回
     */
    private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException {
        final ResultLoaderMap lazyLoader = new ResultLoaderMap();
        /** 26、创建空的结果对象 */
        Object rowValue = createResultObject(rsw, resultMap, lazyLoader, null);

        // eg1: rowValue=User{id=null, name='null', age=null, userContacts=null}   hasTypeHandlerForResultObject(rsw, resultMap.getType())=false
        if (rowValue != null && !hasTypeHandlerForResultObject(rsw, resultMap.getType())) {
            /** 27、创建rowValue的metaObject */
            final MetaObject metaObject = configuration.newMetaObject(rowValue);

            // eg1: foundValues = useConstructorMappings = false
            boolean foundValues = this.useConstructorMappings;

            // eg1: shouldApplyAutomaticMappings(resultMap, false) = true
            /** 28、是否应用自动映射 */
            if (shouldApplyAutomaticMappings(resultMap, false)) {
                // eg1: applyAutomaticMappings(rsw, resultMap, metaObject, null)=true
                /**
                 * 29、将查询出来的值赋值给metaObject中的POJO对象
                 */
                foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues; // eg1: foundValues=true
            }

            // eg1: foundValues=true
            foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues;

            // eg1: lazyLoader.size()=0   foundValues=true
            foundValues = lazyLoader.size() > 0 || foundValues;

            // 31、eg1: foundValues=true  configuration.isReturnInstanceForEmptyRow()=false
            /** configuration.isReturnInstanceForEmptyRow() 当返回行的所有列都是空时，MyBatis默认返回null。当开启这个设置时，MyBatis会返回一个空实例。*/
            rowValue = (foundValues || configuration.isReturnInstanceForEmptyRow()) ? rowValue : null;
        }
        return rowValue; // eg1: rowValue=User{id=2, name='muse2', age=24, userContacts=null}
    }
    
    // eg1: columnPrefix=null
    private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject,
                                           String columnPrefix) throws SQLException {
        /** 30、创建自动映射 */
        List<UnMappedColumnAutoMapping> autoMapping = createAutomaticMappings(rsw, resultMap, metaObject, columnPrefix);
        boolean foundValues = false;

        // eg1: autoMapping={UnMappedColumnAutoMapping("id", "id", LongTypeHandler@2397, false),
        //                   UnMappedColumnAutoMapping("name", "name", StringTypeHandler@2418, false),
        //                   UnMappedColumnAutoMapping("age", "age", IntegerTypeHandler@2433, false)}
        if (autoMapping.size() > 0) {
            for (UnMappedColumnAutoMapping mapping : autoMapping) {
                // eg1: mapping.column="id"      mapping.typeHandler=LongTypeHandler       value=2L
                // eg1: mapping.column="name"    mapping.typeHandler=StringTypeHandler     value="muse2"
                // eg1: mapping.column="age"     mapping.typeHandler=IntegerTypeHandler    value=24
                final Object value = mapping.typeHandler.getResult(rsw.getResultSet(), mapping.column);
                if (value != null) {
                    // eg1: foundValues = true
                    // eg1: foundValues = true
                    // eg1: foundValues = true
                    foundValues = true;
                }
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                // eg1: configuration.isCallSettersOnNulls()=false  mapping.primitive=false
                if (value != null || (configuration.isCallSettersOnNulls() && !mapping.primitive)) {
                    // eg1: mapping.property="id"  value=2L
                    // eg1: mapping.property="name"  value="muse2"
                    // eg1: mapping.property="age"  value=24
                    metaObject.setValue(mapping.property, value);
                }
            }
        }
        return foundValues; // eg1: 返回true
    }
}

```

### 1.9. Mybatis 是如何进行分页的？分页插件的原理是什么？

1. Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的**内存分页**，而非物理分页，可以在 sql 内直接书写带有物理分页的参数，来完成物理分页功能，也可以使用分页插件来完成物理分页。
2. 分页插件的基本原理是，使用 Mybatis 提供的插件接口，实现自定义插件，在插件的拦截方法内，拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数。
3. 比如，`select * from student`，拦截 sql 后重写为 `select t.* from (select * from student) t limit 0, 10`，从而完成插件分页的功能。

### 2.0. Mybatis 插件运行原理，以及如何编写一个插件？

1. Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这4种接口的插件。
2. Mybatis 使用 JDK 动态代理，为需要拦截的接口生成代理对象，以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 `InvocationHandler#invoke()` 方法，拦截那些指定需要拦截的方法。
3. 具体做法为，实现 `Mybatis#Interceptor#intercept()` 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法，最后在配置文件中，配置所编写的插件即可。

# **十二、分布式篇**

### 1.1. 分布式系统？

1. 分布式系统，是一个硬件或者软件分布在不同的计算机上，彼此之间仅仅通过消息传递，进行通信和协调的系统。
2. 提到分布式架构，就一定绕不开 `一致性` 问题，而 `一致性` 又包含了 `数据一致性` 和 `事务一致性` 两种情况，其解决方案在后面都有给出。

### 1.2. CAP 定理？

1. **CAP 定理**，又叫布鲁尔定理，指的是，在一个分布式系统中，最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）三项中的两项。
   - CAP 的适用场景是副本性数据，业务间的不一致性（比如订单和库存的不一致）不在 CAP 的讨论范畴。
2. **C：一致性（Consistency）**，数据在多个副本中保持一致，可以理解成两个用户访问两个系统 A 和 B，当 A系统数据有变化时，及时同步给 B 系统，让两个用户看到的数据是一致的。
   - 强调的是，对某个读操作，必须保证能够返回最新的写操作结果，要求的是**数据强一致性**，要和弱一致性、最终一致性、缓存一致性、业务一致性区分开来。
   - **保证方案**：分布式一致性算法。
3. **A：可用性（Availability）**，系统对外提供服务必须一直处于可用状态，在任何故障下，客户端都能在合理时间内，获得服务端非错误的响应。
   - 强调的是，对某次请求，必须保证在合理的时间内，返回合理的响应（不是错误和超时的响应），要求的是**返回及时**。
   - **保证方案**：接口高性能相关，比如缓存、限流、降级、熔断。
4. **P：分区容错性（Partition tolerance）**，在分布式系统中，遇到任何网络分区故障，系统仍然能对外提供服务。其中，网络分区是指，由于某些原因，子节点之间的网络出现故障，导致不同的节点分布在不同的子网络中，有可能子网络中只有一个节点，这就是网络分区。
   - 强调的是，当出现网络分区后，系统能够继续履行职责，要求的是**分布式和数据同步**。
   - **保证方案**：集群、日志复制、主从复制。

证明，为什么只能满足其中两个，而不能 3 个都满足：

![1647171096774](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647171096774.png)

- 假设，系统 A 和系统 B 是可以通过网络，进行同步数据的。
- 此时，用户 1 和用户 2 分别要访问系统 A 和系统 B，理想情况下，用户 1 访问系统 A 对数据进行修改，将 data1 改成了 data2，同时用户 2 访问系统 B，拿到的数据应该是 data2。
- 但是，由于网络总是不可靠的，涉及网络调用，就需要一一进行分析：
  1. 当网络发生故障时，系统 A 和系统 B 没法进行数据同步，也就是不能满足 P，同时两个系统依然可以访
     问，那么此时其实相当于是单机系统，就不是分布式系统了，因此，对于分布式系统，P 是必须满足的。
  2. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让用户 2 通过系统 B 正确地拿到 data2，那么此时就满足了 C，由于 P 的存在，可能会导致一致性同步的时间无限延长，在同步期间，任何人不能访问系统 B，从而导致系统 B 不可用，以保证数据一致性，此时满足的是 CP。
  3. 当 P 满足时，如果用户 1 通过系统 A 对数据进行了修改，将 data1 改成了 data2，如果也想让系统 B 能继续提供服务，那么此时，由于 P 的存在，一致性同步可能需要更多的时间，所以只能牺牲掉一致性，接受系统 A 没有将 data2 同步给系统B，此时满足的就是 AP。
- 因此，分布式系统只能同时满足 CAP 定理中其中 2 个，比如注册中心 Eureka 满足的是 AP，并不能保证 C，Zookeeper 保证了 CP，但不满足 A，而在生产中，A 和 C 的选择，没有正确的答案，应该要取决于自己的业务，比如 12306 系统满足 CP，是因为买票必须满足数据的一致性，不然一个座位多卖了，对铁路运输都是不可以接受的。

### 1.3. Base 理论？

由于 CAP 中一致性 C 和可用性 A 无法兼得，eBay 的架构师，提出了 BASE 理论，它是通过牺牲数据的强一致性，来获得可用性，属于对 CAP 中 AP 方案的一个补充，BASE 理论并没有要求数据的强一致性，而是允许数据在一定的时间段内是不一致的，但在最终某个状态会达到一致。

它具有如下 3 种特征：

1. **基本可用**：Basically Available，分布式系统在出现不可预知故障时，允许损失部分可用性，保证核心功能的可用性。
2. **软状态**：Soft state，软状态也称为弱状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该
   中间状态的存在，不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间，进行数据同步的过程存在延时。
3. **最终一致性**：Eventually consistent，最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是，需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。

在生产环境中，很多公司，会采用 BASE 理论来实现数据的一致，因为产品的可用性相比强一致性来说，更加重要。

1. 比如在电商平台中，当用户对一个订单发起支付时，往往会调用第三方支付平台，比如支付宝支付或者微信支付。
2. 调用第三方成功后，第三方并不能及时通知我方系统，在第三方没有通知我方系统的这段时间内，我们给用户的订单状态显示支付中，等到第三方回调之后，我们再将状态改成已支付。
3. 虽然订单状态在短期内存在不一致，但是用户却获得了更好的产品体验。

### 1.4. 分布式数据一致性？

#### 1、数据不一致性产生原因

复制，是导致数据一致性问题的唯一原因。

如果只用一台数据库实例，来处理所有的写入和读取请求，就一定不存在数据一致性的问题。但在中大型项目中，却经常需要将一份数据，存储在超过一台数据库中（即复制），原因有三：

1. **高可用**：即使一部分数据库出现故障，系统也能正常工作。
2. **降低延迟**：使数据与用户在地理上接近。
3. **可扩展性、提高读取吞吐量**：可以扩展处理读请求的机器数量。

这里假设数据集非常小，每台机器的空间都足够保存整个数据集，否则将会引入一个新的话题 `数据分区`。

#### 2、强一致性与弱一致性 | 强弱角度

其实只有两类数据一致性，**强一致性与弱一致性**。

1. **强一致性**：也叫做线性一致性，除此以外，所有其他的一致性都是弱一致性的特殊情况。
2. **弱一致性**：所谓强一致性，即复制是同步的，弱一致性，即复制是异步的。

用户更新网站头像，在某个时间点，用户向主库发送更新请求，不久之后主库就收到了请求。在某个时刻，主库又会将数据变更转发给自己的从库。最后，主库通知用户更新成功。

1. **强一致性举例**：如果在返回“更新成功”并使新头像对其他用户可见之前，主库需要等待从库的确认，确保从库已经收到写入操作，那么复制是同步的，即**强一致性**。
2. **弱一致性举例**：如果主库写入成功后，不等待从库的响应，直接返回“更新成功”，则复制是异步的，即弱一致性。

**优点**：强一致性，可以保证从库有与主库一致的数据。如果主库突然宕机，仍可以保证数据完整。

**缺点**：但如果从库宕机或网络阻塞，主库就无法完成写入操作。

**结论**：

1. 在实践中，通常使一个从库是同步的，而其他的则是异步的。如果这个同步的从库出现问题，则使另一个异步从库同步。
2. 这可以确保永远有两个节点拥有完整数据：主库和同步从库。 这种配置称为**半同步。**

#### 3、最终一致性 | 强弱角度

除了强一致性以外，所有其他的一致性都是弱一致性的特殊情况，最终一致性就是其中一种特例。

- **最终一致性举例**：当用户从异步从库读取时，如果此异步从库落后，他可能会看到过时的信息。

这种不一致只是一个暂时的状态，如果等待一段时间，从库最终会赶上并与主库保持一致吗，这就是最终一致性。

- **最终**：这两个字用得很微妙，反映了从写入主库到同步至从库之间的延迟，可能仅仅是几分之一秒，也可能是几个小时，时延是不确定的。

#### 4、读写一致性 | 读写角度

读写一致性，也称为读己之写一致性。它可以保证，如果用户刷新页面，总会看到自己刚提交的任何更新，虽然不能保证其他用户的写入，他们的更新可能稍等才会看到，但它保证用户自己提交的数据能马上被自己看到。

- **读写不一致性举例**：手机刷虎扑的时候经常遇到，回复某人的帖子然后想马上查看，但我刚提交的回复可能尚未到达从库，看起来好像是刚提交的数据丢失了，很不爽。

如何实现读写一致性？最简单的方案，对于某些特定的内容，都**从主库读**。

- **举例**：知乎个人主页信息只能由用户本人编辑，而不能由其他人编辑。因此，永远从主库读取用户自己的个人主页，从从库读取其他用户的个人主页。

还有一种更好的方法是：

1. 客户端可以在本地记住**最近一次写入的时间戳**，发起请求时带着此时间戳。
2. 从库提供任何查询服务前，需确保该时间戳前的变更都已经同步到了本从库中。
3. 如果当前从库不够新，则可以从另一个从库读，或者等待从库追赶上来。

#### 5、单调一致性 | 多次读角度

单调读，比强一致性更弱，比最终一致性更强，意味着如果一个用户进行多次读取时，绝对不会遇到时光倒流，即如果先前读取到较新的数据，后续读取不会得到更旧的数据。

- **多次读不一致性举例**：用户在从某从库查询到了一条记录，再次刷新后发现此记录不见了，就像遇到了**时光倒流**。如果用户从不同从库进行多次读取，就可能发生这种情况。

实现单调读取的一种方式是：

1. 确保每个用户总是从**同一个节点**进行读取（不同的用户可以从不同的节点读取）。
2. 比如，可以基于用户 ID 哈希值来选择节点，而不是随机选择节点。

#### 6、因果一致性 | 数据分区角度

数据分区（分片）后，每个节点并不包含全部数据。不同的节点独立运行，不存在全局写入顺序。

1. 如果用户A提交一个问题，用户B提交了回答。
2. 问题写入了节点A，回答写入了节点B。
3. 由于同步延迟，发起查询的用户可能会先看到回答，再看到问题。

为了防止这种异常，需要保证**因果一致性**， 即如果一系列写入按某个逻辑顺序发生，那么任何人读取这些写入时，会看见它们以正确的逻辑顺序出现。

- **解决方案举例**：由应用来保证，将问题和对应的回答写入**相同的分区**。

### 1.5. 分布式一致性算法？

#### 1、背景

1. 分布式系统，对分区容错性的一般解决方案是 `state machine replication` 状态机复制。
2. 分布式一致性算法，本质上就是一种 `state machine replication` 状体机复制的共识算法。
3. 分布式系统，有多个节点就会存在节点间通信的问题，存在着两种节点通讯模型：共享内存（Shared memory）和消息传递（Messages passing）传递模型。
4. 以下谈到的分布式一致性算法，都是基于**消息传递**通讯模型实现的，从而保证在分布式系统中，进程间基于消息传递就某个值达成一致。

#### 2、一致性模型

1. 现阶段工业，有 2 种一致性模型：弱一致性和强一致性。
2. 弱一致性中最主要的是最终一致性，对于**最终一致性**最好的体现是 DNS（Domain Name System） 和 Gossip （Cassandra、Redis 的通信协议）。
3. **强一致性**主要有：同步模型（主从同步）和多数派机制模型（Paxos、Raft、Zab）。

#### 3、同步模型

**基本思想**：

1. Master 接受写请求。
2. Master 复制日志至 Slave。
3. Master 等待，直到所有从库返回后，才响应客户端。

**存在的问题**：任意一个从节点返回失败，都会导致 Master 阻塞，导致整个集群不可用，虽然保证了一致性，但可用性大大降低。

#### 4、多数派模型

**基本思想**：

1. 每次写，都保证写入大于 N / 2 个节点。
2. 每次读，都保证从大于 N / 2 个节点中读。

**相关算法**：

![1647235115496](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235115496.png)

Paxos 算法，是莱斯利 · 兰伯特(Leslie Lamport) 于 1990 年提出的一种基于消息传递的一致性算法，其发展分类有：Basic Paxos、Multi Paxos 和 Fast Paxos，其中工业界用得最多的是 Raft 和 ZAB。

##### 1）Basic Paxos

**算法角色**：

- **Client**： 系统外部角色，请求发起者，像民众。
- **Proposer**： 接受 Client 请求，向集群提出提议（propose），并在冲突发生时，起到冲突调解的作用，像提议员，替民众提出议案。
- **Acceptor**：提议投票和接受者，只有在形成法定人数（Quorum，一般即为 majority 多数派）时，提议才会最终被接受，像国会议员。
- **Learner**：提议接受者，负责 backup 备份工作，对集群一致性没什么影响，像记录员。

![1647235532293](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235532293.png)

**算法阶段**，有 2 个阶段，每个阶段有 2 个分支阶段：

1. **Prepare**：提出一个提案，编号为N，只有 N 大于此 Propser 之前提出的提案编号（全局递增的一种编号）， 请求才会被 Accpetor 的 Quorum 多数派接受。
2. **Promise**：接受发过来的请求，前提是该请求编号 N 大于之前任何提案的编号。
3. **Accept**：如果 Propser  确认达到了多数派，则会发出 Accept 请求，该请求包含提案编号 N 和提案内容。
4. **Accpeted**：如果 Acccetor 集群在此期间，没有收到任何编号还大于 N 的提案，则接受刚刚的提案，否则忽略。

**算法问题**：

1. **活锁问题**：在议案还没有被接受时，如果再出现新议案编号，那么就会不断出现 Prepare + Promise 讨论新提案，而不是 Accept 接受一个提案。
   - **解决方案**：提供一个 random timeout，其他的提案需要等待一段随机时间，才被讨论。
2. **效率较低**：提交提案、接收提案进行了 2 轮的 RPC 操作，效率较低。
3. **实现难度大，且不容易理解**。

![1647235817187](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647235817187.png)

##### 2）Multi Paxos

**目的**：为了减少角色，简化步骤。

**解决方案**：

1. 由于 Basic Paxos 存在活锁问题，其根因是多个 Proposer 导致的，所以，Multi Paxos 提出了一个新的概念 -> Leader，Leader 是唯一的 Proposer，所有请求都需经过此 Leader。
2. 由于 Basic Paxos 存在两轮 RPC 导致的效率低下问题，所以，Multi Paxos 则通过 Leader 角色 + 在消息中增加一个随机的 Term 任期，使得两轮 RPC 的情况，只在竞选 Leader （选举）时才出现，其余情况（复制）只需要进行一轮 RPC。

![1647236688258](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647236688258.png)

##### 3）Raft

Raft，可以认为是比 Multi Paxos 更简单的一致性算法。

其**算法角色**有：

1. **Leader**：主节点，整个集群只有一个 Leader，所有的写请求都通过 Leader 发送给 Follower。
   - **Term**：在每一个 Leader 的任期期间，都有唯一表示该任期的一个 Term。
2. **Follower**：从节点（跟随角色）。
3. **Candidate**：在 Leader 消息发送失败或宕机，整集群没有 Leader 时，Follower 接收 Leader 的心跳包超时，则它们以 Candidate 身份，开始竞选 Leader。Candidate 只是个中间状态，不会长期存在。

Raft 将分布式问题划分成 3 个小问题：

1. **Leader Election**：主节点选举，集群启动、或者 Leader 心跳包消息无法发送给 Follower 时，触发选主操作。

   集群启动：

   ![1647238020422](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238020422.png)

2. **Log Replication**：日志复制。

   1. 客户端请求 Leader 写入数据.
   2. Leader 将数据分发到 Follower 中，然后数据被写入 Follower 的内存.
   3. Follower 向 Leader 发送确认消息，Leader 首先提交自己的数据，响应客户端，然后向 Follower 发送提交数据请求。
   4. Follower 收到提交请求后，提交数据。

   ![1647238328150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238328150.png)

3. **Safety**：安全恢复。

   - **1）Leader 宕机感知**：

     1. 通过 timeout，来保证 Follower 能正确感知 Leader 宕机或消息丢失的事件，并触发 Follower 竞选Leader。

        ![1647238709444](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238709444.png)

     2. Leader 需要给 Follower 发送心跳包（heartbeats），数据也是携带在心跳包中，发送给 Follower 的。

        ![1647238617190](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238617190.png)

   - **2）选主平票情况**：Leader Election 平票时，两个 Candidates 会产生一个随机的 timewait，继续发送下一个竞选消息。

     ![1647238893242](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238893242.png)

   - **3）脑裂（大小集群）情况**：

     1. 小集群由于没有得到多数派的回复，写操作失败。
     2. 大集群会发生重新选主的过程，且新 Leader 拥有自己新的 Term(任期)，写操作成功。
     3. 当小集群回到大集群时，由于小集群的 Term 小于新集群的 Term，则会同步大集群的信息。

     ![1647238545305](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647238545305.png)

##### 4）ZAB

ZAB，全称是 Zookeeper atomic broadcast protocol，是 ZK 内部用到的一致性协议，基本与 Raft 相同：

1. Zab 将任期 Term 换成了epoch。
2. 用于保证日志连续性的心跳检测，方向 ZAB 改由 Follower 发送至 Leader。

**算法角色**：

1. **Leader**：负责投票的发起和决议、更新系统状态。
2. **Follower**：接受客户端请求、响应客户端结果、参与投票。
3. **Observer**：可以接受客户端请求，将其转发给 Leader，但是不参与投票过程，只同步 Leader 状态，目的是为了扩展系统，提高读取速度。

ZAB 有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。

- **1）恢复模式（选主）**：
  1. 当服务启动或者在领导者崩溃后，ZAB 就进入了恢复模式。
  2. 当领导者被选举出来，且大多数 Follower 完成了和Leader 的状态同步以后，恢复模式就结束了。
  3. 状态同步保证了 Leader 和 Follower 具有相同的系统状态。
  4. ZK 的选举算法有两种：一种是基于 basic paxos 实现的，另外一种是基于 fast paxos 算法实现的，系统默认的选举算法为 fast paxos。
- **2）广播模式（同步）**：
  1. 选完 leader 以后，ZK 就进入状态同步过程。
  2. leader 等待 server 连接。
  3. Follower 连接 leader，将最大的 ZXID（全局递增的事务 ID）发送给leader。
  4. Leader 根据 Follower 的 ZXID 确定同步点。
  5. 完成同步后，通知 Follower 已经成为 uptodate 状态。
  6. Follower 收到 uptodate 消息后，又可以重新接受 client 的请求，继续进行服务了。

### 1.6. 分布式事务一致性？

#### 1）XA 方案 - 2PC 协议 | 数据库实现 | 非 100% 一致

**XA 方案**：

1. XA，是由 X/Open 组织提出的分布式事务规范，由一个事务管理器（TM）和多个资源管理器（RM）组成。
2. 当一个事务跨越多个节点时，为了保持事务 ACID 的特性，需要引入协调者（TM），来统一掌控所有参与者节点（RM）的操作结果，并最终指示这些节点是否要把操作结果进行真正的提交或者回滚。

**两阶段提交**，Two phaseCommit，是指在计算机网络以及数据库领域中，为了使基于分布式系统架构下的所有节点，在进行事务提交时，保持一致性而设计的一种算法，整体思路可以概括为：

1. 参与者将操作成败通知协调者。
2. 再由协调者根据所有参与者的反馈情报，决定各参与者是否要提交操作还是回滚操作。

所谓的两个阶段是指：**准备阶段和提交阶段**。

1. **准备阶段**：

   1. 事务协调者（TM）给每个参与者（RM）发送Prepare消息。
   2. 每个参与者（RM），要么直接返回失败，比如权限验证失败等，要么在执行本地事务，各自写本地的 redo log 和 undo log，但不提交事务。

   ![1647248864385](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647248864385.png)

2. **提交阶段**：

   1. 如果协调者（TM），收到了参与者（RM）的失败通知或者超时，则直接给每个参与者（RM）发送回滚（Rollback）通知；否则，发送提交（Commit）通知。
   2. 参与者（RM），根据协调者（TM）的指令，执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源，注意的是，2 PC 协议是必须在最后阶段，才会释放锁资源。

   ![1647250694317](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250694317.png)

**缺点**：

1. **同步阻塞问题**：执行过程中，所有参与节点（RM）都是事务阻塞的，当参与者（RM）占有公共资源时，其他第三方节点访问公共资源，将不得不处于阻塞状态。
2. **存在单点故障风险**：一旦协调者（TM）发生故障，参与者（RM）将会一直阻塞下去，尤其在第二阶段，协调者发生故障，那么所有的参与者（RM）还都处于锁定事务资源的状态中，而无法继续完成事务操作。
   - **解决方案**：如果是协调者（TM）挂了，可以重新选举一个协调者（TM），但是无法解决因为协调者（TM）宕机，导致的参与者（RM）处于阻塞状态的问题。
3. **数据不一致**：
   1. 在两阶段提交的二阶段中，当协调者（TM）向参与者（RM）发送 commit 请求后，如果发生局部的网络异常，或者在发送 commit 请求过程中，协调者（TM）发生故障，则会导致只有一部分参与者（RM）接受到了 commit 请求。
   2. 而在这部分参与者（RM）接到 commit 请求之后，就会执行 commit 操作。
   3. 但是，其他部分未接到 commit 请求的参与者（RM），则无法执行事务提交。
   4. 于是，整个分布式系统便出现了数据不一致性的情况。

#### 2）XA 方案 - 3PC 协议 | 数据库实现 | 非 100% 一致

![1647250732842](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647250732842.png)

**3PC 算法流程**：

1. **`can commit` 阶段**：准备阶段，3PC 的 `can commit` 阶段其实和 2PC 的准备阶段很像。协调者（TM）向参与者（RM）发送 commit 请求，如果参与者（RM）可以提交就返回 Yes 响应，否则返回 No 响应。
2. **`pre commit` 阶段**：预提交阶段，协调者（TM），根据参与者（RM）的反应情况，来决定是否可以进行事务的 `preCommit` 操作：
   1. **参与者（RM）情况判断**：如果协调者（TM）从所有的参与者（RM），获得的反馈都是 Yes 响应，那么就会执行事务的预执行。
   2. **发送预提交请求**：协调者（TM）向参与者（RM），发送 `pre commit` 请求，并进入 prepared 阶段。
   3. **事务预提交**：参与者（RM）接收到 `pre commit` 请求后，会执行事务操作，并将 undo log 和 redo log记录到本地的事务日志中。
   4. **响应反馈**：如果参与者（RM）成功执行了事务操作，则返回 ACK 响应给协调者（TM），同时开始等待其最终的指令。
   5. **事务中断**：但是，如果有任何一个参与者（RM），向协调者（TM）发送了 No 响应，或者协调者（TM）等待超时，没有接到参与者（RM）的响应，那么就执行事务的中断：
      - **1）发送中断请求**：协调者（TM）发送中断 abort 请求给所有参与者（RM）。
      - **2）事务中断**：参与者（RM），收到来自协调者（TM）的 abort 请求后，或超时没收到协调者（TM）的任何请求，则执行事务中断，**什么都不用做**。
3. **`do commit` 阶段**：提交阶段，此阶段进行真正的事务提交，也需要分为以下 2 种情况：
   1. **发送提交请求**：协调者（TM），收到参与者（RM）返回的 ACK 响应，则会从预提交状态进入到提交状态，并向所有参与者（RM）发送 `do commit` 请求。
   2. **事务提交**：参与者（RM），接收到 `do commit` 请求后，执行正式的事务提交，并在完成事务提交后，释放所有事务资源。
   3. **响应反馈**：参与者（RM）事务提交完之后，向协调者（TM）再次返回 ACK 响应。
   4. **完成事务**：协调者（TM），再次接收到所有参与者（RM）的 ACK 响应之后，代表本次分布式事务完成。
   5. **中断事务**：但是，如果协调者（TM），没有接收到任意一个参与者（RM）返回的 ACK 响应，可能是响应的不是 ACK，也可能发生了超时，那么就会执行中断事务：
      - **1）发送中断请求**：协调者（TM），向所有参与者（RM）发送 `abort` 请求。
      - **2）事务回滚**：参与者（RM），接收到 `abort` 请求后，利用其在 `pre commit` 阶段记录的 undo log 来执行本地事务的回滚操作，并在完成回滚之后，释放所有的事务资源；但如果超时没收到协调者（TM）的任何请求，则参与者（RM）会进行**事务提交**（因为都到了这一阶段了，大概率是可以提交的）。
      - **3）反馈结果**：参与者（RM），完成事务回滚之后，向协调者（TM）发送 ACK 响应。
      - **4）中断事务**：协调者（TM），接收到参与者（RM）反馈的 ACK 响应之后，执行最终的事务中断。

**2PC 和 3PC 的区别**：

1. **3PC 能够及时释放资源**：3PC 比 2PC，多了一个 `can commit` 阶段，减少了不必要的资源浪费。
   - 因为 2PC 在第一阶段会占用资源，而 3PC 在 `can commit` 阶段不占用资源，只是校验一下 sql，如果不能执行，则直接返回，减少了资源占用。
2. **3PC 引入了参与者（RM）超时机制**：在协调者（TM）和参与者（RM），都引入超时机制。
   - **2PC**：只有协调者（TM）有超时机制，超时后，发送会发送回滚指令。
   - **3PC**：协调者（TM）和参与者（RM）都有超时机制：
     1. **协调者（TM）超时**：`can commit`、`pre commit` 阶段，如果收不到参与者（RM）的反馈，则协调者（TM）会向参与者（RM）发送中断指令，参与者（RM）进行事务中断，什么都不用做。
     2. **参与者（RM）超时**：`pre commit` 阶段，参与者（RM）进行回滚；`do commit` 阶段，参与者（RM）进行事务提交（因为都到了这一阶段了，大概率是可以提交的）。

**总结**：

1. 3PC 相对于 2PC 做了一定的改进，引入了参与者（RM）超时机制，并且增加了 `pre commit` 预提交阶段，使得故障恢复之后，协调者（TM）的决策复杂度降低，但整体的交互过程更长了，性能会有所下降，并且同样还会存在数据不一致的问题。
2. 所以，2PC 和 3PC 都**不能保证数据 100% 一致**，因此，一般都需要有**定时扫描补偿机制**来兜底。
3. 3PC 只是纯理论上的东西，相比于 2PC 只是做了一些优化，但是效果甚微，所以只做了解即可。

#### 3）AT 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

![1647251563240](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647251563240.png)

AT 模式，基于支持本地 ACID 事务的关系型数据库实现：

1. **一阶段 `prepare` 行为**：在本地事务中，一并提交业务数据更新，和相应回滚日志记录。
2. **二阶段 `commit` 行为**：马上成功结束，自动异步批量清理回滚日志。
3. **二阶段 `rollback` 行为**：通过回滚日志，自动解析生成补偿 SQL，完成数据回滚。

**缺点**：

1. 解析回滚日志，生成 SQL 损耗性能。
2. 默认事务隔离级别是读未提交，无法解决脏读。如果设定读已提交（`SELECT FOR UPDATE` 申请全局锁），则性能会直线下降。

#### 4）TCC 方案 | Seata 实现 | 默认读未提交，读已提交性能低下 

TCC，Try-Confirm-Cancel，是一种 Seata 的分布式事务解决方案，它将一个事务拆分成 3 个步骤：

1. **T**：try，业务检查阶段，主要进行业务校验，以及检查或者资源预留，也可以进行一些业务处理。
2. **C**：confirm，业务确认阶段，主要是对 `try` 阶段校验过的业务，或者预留的资源进行确认。
3. **C**：cancel，业务回滚阶段，主要进行与上面相反的业务操作，释放 `try` 阶段预留的资源或者业务。

![1647254230571](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647254230571.png)

**TCC  方案 VS AT 方案**：

1. TCC 方案，相当于 AT 方案的人工版，属于事务补偿型。
2. AT 方案的回滚，是自动解析回滚日志，解析出反向 SQL。
3. 而 TCC 方案则是完全把 `perpare`、`rollback` 和 `commit` 三个方法全都交给开发者来实现。

**TCC 空回滚是解决什么问题的？**

1. 在没有调用 `try` 方法的情况下，调用了二阶段的 `cancel` 方法。
2. 比如，当 `try` 请求由于网络延迟或故障等原因，没有执行，且结果返回了异常时， `cancel` 不能正常执行，只能进行空回滚，因为 `try` 并没有对数据进行修改，如果 `cancel` 正常执行，对数据进行反向修改，那就会导致数据的不一致。
3. **解决思路**：
   1. 关键是要识别出这个空回滚，也就是需要知道 `try` 阶段到底是否执行，如果  `try`  执行了，那就正常回滚，如果  `try`  没有执行，那就空回滚。
   2. 可以让协调者（TM）在发起全局事务时，生成全局事务记录以及分支事务记录， `try` 阶段插入一条记录，表示 `try` 阶段执行了，`cancel` 阶段再读取该记录，如果该记录存在，则正常回滚，如果该记录不存在，则进行空回滚。

**如何解决 TCC 幂等问题？**

1. 为了保证 TCC 二阶段提交，重试机制不会引发数据的不一致，就要求 TCC 的二阶段 `confirm` 和 `cancel` 方法保证幂等性。
2. 这样才不会重复使用或者释放资源，但如果幂等性控制没有做好，很可能会导致数据不一致等严重问题。
3. **解决思路**：
   1. 在上述所说的分支事务记录中，增加执行状态，每次执行前都查询该状态是否已执行，执行过了就不再执行。
   2. 也可以用分布式锁解决。

**如何解决 TCC 中悬挂问题？**

1. 悬挂，就是对于一个分布式事务，其二阶段 `cancel` 方法比 一阶段的 `try` 方法先执行。
2. **出现原因**是，在调用分支事务 `try` 时，由于网络发生拥堵，造成了超时，协调者（TM）就会通知参与者（RM）回滚该分布式事务，可能回滚完成后，`try` 请求才到达参与者（RM）被真正执行。
3. **造成的后果**是，由于一个 `try` 方法预留的业务资源，只有该分布式事务才能使用，此分布式事务最后才执行的 `try`，导致业务资源预留后，无法被继续处理。
4. **解决思路**是：
   1. 如果二阶段执行完成，那一阶段就不能再继续执行。
   2. 在执行一阶段事务时，判断在该全局事务下，分支事务记录表中，是否已经有二阶段的事务记录，如果有，则不再执行 `try` 。

**缺点**：

1. 默认事务隔离级别读未提交，还是会出现脏读问题。
2. 所要编写的代码量，可能会恶心死人。

#### 5）Saga 方案 | Seata 实现 | 默认读未提交，读已提交性能低下

Saga，长事务解决方案，事务一旦 start，各个参与者（RM）按照顺序，一个一个执行自己的逻辑，当其中有一个参与者（RM）执行失败，那么之前已经执行的参与者（RM）都需要**反向逆序**进行回滚。

![1647255581291](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647255581291.png)

**优点**：

1. 一阶段提交本地事务，无锁，高性能。
2. 事件驱动架构，参与者（RM）可异步执行，高吞吐。
3. 补偿服务易于实现。

**缺点**：默认事务隔离级别读未提交，还是会出现脏读问题，不保证隔离性。

**适用场景**：

1. **业务流程长、业务流程多时**。
2. **调用第三方业务**：参与者（RM）包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口时。

#### 6）本地消息表 | MQ 实现 | 最终一致性

本地消息表，其实就是利用了**各系统本地的事务**来实现分布式事务。

1. 本地消息表，顾名思义就是，会有一张存放本地消息的表，一般都是放在数据库中。
2. 然后，在执行业务时，将业务的执行和将消息放入消息表中的操作，包在同一个事务中，以保证消息放入本地表后，业务肯定能够执行成功。
3. 然后，再去调用下一个操作，如果下一个操作调用成功了，那么消息表的消息状态直接改成已成功。
4. 如果调用失败了，那也没事，会有后台任务定时去读取本地消息表，筛选出还未成功的消息，再调用对应的服务，服务更新成功了再变更对应消息的状态。
5. 其中，有可能消息对应的操作不成功，所以，还需要进行重试（要保证服务接口幂等），在超过最大次数时，还需要记录下来，报警，进行人工处理。

可以看到，本地消息表，其实实现的是最终一致性，容忍了数据暂时不一致的情况。

#### 7）可靠消息最终一致性方案 | MQ 实现 | 最终一致性	

可靠消息最终一致性方案，指的是：当事务发起方（消息发送者）执行完本地事务后，发出一条消息，保证事务参与方（消息的消费者）一定能够接受消息，并可以成功处理他自己的事务。

1. **可靠消息**：发起方一定得把消息传递到消费者。
2. **最终一致性**：最终，发起方的业务处理，和消费方的业务处理都得完成，达到数据的最终一致性。

![1647242994399](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647242994399.png)

**解决方案**：比如，阿里 RocketMQ 的消息事务（**双端都要进行确认，重试要保证幂等性**）

1. A（比如订单）系统，先发送一个 `prepared` 消息到 Broker。
2. 如果 `prepared` 消息发送失败，则取消操作，不再执行。
3. 如果 `prepared`  消息发送成功后，则执行 A 的本地事务，执行成功，则发送确认消息到 Broker，执行失败，则发送回滚消息到 Broker，其中，Broker 会**定时轮询**所有 `prepared` 消息回调的接口，以确认事务的执行状态。
4. 如果 Broker 收到了确认消息，则 B （比如仓储） 系统会接收到该事务消息，然后执行 B 的本地事务。
5. 如果 B 事务执行失败，则会不断重试，直到成功，或者达到一定次数后，发送报警，人工介入，来手工回滚或者补偿。

![1647256631363](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647256631363.png)

#### 8）最大努力通知方案 | MQ 实现 | 最终一致性

**概念**：

1. 其实，本地消息表，也可以算作最大努力通知，事务消息也可以算最大努力通知。
2. 本地消息表来说，会有后台任务定时去查看未完成的消息，然后去调用对应的服务，当一个消息多次调用都失败时，可以记录下来，然后人工介入，也可以直接舍弃掉，算最大努力通知。
3. 事务消息也是一样，当 half message 被 commit 了之后，确实就是普通消息了，如果订阅者一直不消费，或者消费不了，则会一直重试，最后进入死信队列，也算是最大努力通知。
4. 所以，最大努力通知，其实就是一种**柔性事务**的思想，我已经尽力我最大的努力，想达成事务的最终一致了。

**执行流程**：

1. 系统 A 本地事务执行完后，发送消息到 MQ。
2. 然后有个专门消费 MQ 的**最大努力通知服务**，去调用系统 B 的接口。
3. 要是系统 B 执行失败了，就会定时尝试重新调用系统 B 的接口，**反复 N 次** 。
4. 最后还是不行的话，就**放弃**。

**注意要点**：

1. **消息重复通知机制**：由于消费可能没有接收到通知，所以需要有一定的机制，对消息进行重复通知。
2. **消息校对机制**：如果尽最大努力，也没有通知到消费方，或者消费方消费消息后要再次消费，就可由消费方，主动向生产方，查询消息信息来满足需求。

**适用场景**：适用于对时间不敏感的业务，比如短信通知。

#### 9）分布式事务总结

1. 可以看出 2PC 和 3PC 是一种**强一致性事务**，不过还是有数据不一致、事务阻塞等风险，且只能用在数据库层面。
2. 而 TCC 则是一种**补偿性事务**的思想，适用范围更广，由于在业务层面实现，所以对业务的侵入性较大，每个分布式事务，都需要实现对应的三个方法。
3. 本地消息表、事务消息和最大努力通知，都属于**最终一致性事务**，所以，适用于一些对时间不敏感的业务。

**比如**：

1. 如果是一个严格资金绝对不能错的场景，可以用 **TCC 方案**。
2. 如果是一个一般的分布式事务场景，比如积分数据，可以用**事务消息**方案。
3. 如果分布式场景允许不一致，可以使用**本地消息表、最大努力通知**等最终一致性方案。

### 1.7. 分布式消息队列？

见《消息队列篇》。

### 1.8. 分布式缓存？

见《Redis篇》。

#### 1、数据库、缓存双写一致性？

##### 1、总

1. 首先，从理论上来讲，给缓存设置**过期时间**，所有写操作以数据库的为准，对缓存操作只尽最大努力更新的话，如果数据库写成功，缓存更新失败，只要缓存到达了过期时间，那么后面的读请求自然会从数据库中，读取到新值，然后回填到缓存，是可以实现**最终一致性**的。
2. 而如果要给出依赖过期时间的方案的话，可以从更新/删除缓存的角度去思考，它们的大前提是，先读缓存，如果缓存没有，才从数据库读取：
   1. 先更新缓存，再更新数据库。（不可取，数据丢失）
   2. 先更新数据库，再更新缓存。（不可取，后者脏数据覆盖）
   3. 先删除缓存，再更新数据库。（不可取，延迟双删、异步双删依然不能保证一致性）
   4. 先更新数据库，再删除缓存。（可取，Cannal + MQ 实现业务解耦、以及最终一致性）

##### 2、分

###### 1）先更新缓存，再更新数据库 | 数据丢失

1. 这个方案会出现，同一个缓存被频繁写入，但还没来得及更新到数据库，造成数据丢失的问题。
2. 故，放弃。

###### 2）先更新数据库，再更新缓存 | 后者脏数据覆盖

1. 这个方案，也是有问题的，如果有请求 A 和请求 B 并发进行更新操作，那么就会出现：
   - （1）线程 A 更新了数据库。
   - （2）线程 B 更新了数据库。
   - （3）线程 B 更新了缓存。
   - （4）线程 A 更新了缓存。
2. 理论上，请求 A 更新缓存，应该比请求 B 更新缓存早才对，但是由于网络等原因，B 却比 A 更早更新了缓存，导致 A 最后才把脏数据刷到缓存中，造成数据不一致。
3. 故，放弃。

显然，删除缓存才是更好的选择。

###### 3）先删除缓存，再更新数据库 | 延迟双删、异步双删依然不能保证一致性

1. 这个方案，也还是有问题的，如果在请求 A 更新时，请求 B 并发查，会出现：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询，发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值填入缓存。
   - （4）请求 A 将新值写入数据库。
2. 上述情况就会导致不一致的情形出现，如果不给缓存设置过期时间，则该数据永远都是脏数据。
3. 此时，解决方案可以采用**延时双删**策略：
   - （1）先淘汰缓存。
   - （2）再写数据库（这两步和原来一样） 。
   - （3）关键来了，再**休眠** n 秒，然后淘汰缓存，这么做，可以把 n 秒内，所产生的缓存脏数据，再次删除掉。
4. 但是，这个 n 秒怎么确定，可以在写数据后，休眠的时间在读数据业务逻辑的耗时基础上，加几百 ms 即可，这么做的目的，就是确保读请求结束后，写请求可以删除读请求造成的缓存脏数据。
5. 然而，如果 MySQL 读写分离架构下，还是会出现不一致的情况：
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 A 将数据写入数据库了。
   - （3）请求 B 查询缓存，发现缓存没有值，然后去从库查询，但是此时，还没有完成主从同步，因此，查询到的还是旧值。
   - （4）请求 B 将旧值写入缓存。
   - （5）数据库完成主从同步，从库变为新值 。
6. 上述情况也产生了数据不一致的现象，解决方法还是使用**延时双删**策略，只不过，休眠时间 n，需要在主从同步的延时时间基础上，加几百 ms，而不是读耗时加几百 ms。
7. 但是，采用这种同步淘汰策略，由于设计到阻塞休眠 n s，接口吞吐量将会降低很多，此时可以把第二次休眠后删除的步骤，改为**异步**的操作，即起一个线程做异步删除。这样，写请求就不用沉睡一段时间后才返回响应。
8. 如果采用**异步双删**，虽然保证了吞吐量，但第二次可能会**删除失败**，比如：
   - 为了方便，假设是单库。
   - （1）请求 A 进行写操作，删除缓存。
   - （2）请求 B 查询发现缓存不存在，则去数据库查询得到旧值。
   - （3）请求 B 将旧值写入缓存。
   - （4）请求 A 将新值写入数据库。
   - （5）请求 A 试图去删除，但由于某种原因失败了，导致缓存中一直存在 B 放入的旧值。
9. 这种情况下，如果第二次删除缓存失败，还是会出现后面缓存和数据库不一致的现象。
10. 所以，更新数据库前的缓存删除，起不到任何作用，一致性是由第二次缓存删除来保证的。
11. 故，放弃更新前缓存删除方案。

###### 4）先更新数据库，再删除缓存

1. 这种情况，也还是会存在并发问题：
   - （1）缓存刚好失效。
   - （2）请求 A 查询数据库，得一个旧值。
   - （3）请求 B 将新值写入数据库。
   - （4）请求 B 删除缓存。
   - （5）请求 A 将查到的旧值写入缓存。 
2. 上述情况，确实还是有脏数据，解决方案有：
   1. **过期时间**：给缓存设有效时间是一种方案。
   2. **异步删除**：采用上面的异步删除策略，保证读请求完成以后，再进行删除操作也可以，但同样，也存在缓存删除失败导致数据不一致的情况，此时可以提供一个**重试删除**机制即可解决。

##### 3、总

1. 因此，要保证数据库、缓存双写一致性的关键在于，**先更新数据库 + 再删除缓存 + 异步重试删除**，实现方案如下：

2. **方案一**：

   - （1）更新数据库后，再删除缓存。
   - （2）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （3）然后消费消息，获取到要删除的 key。
   - （5）接着根据 key 继续重试删除操作，直到成功。

   **缺点**：对业务线代码，造成了大量的侵入。

   ![1647257594150](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257594150.png)

3. **方案二**： 启动一个订阅程序，去订阅数据库的 **binlog**，获得需要操作的数据，然后另起一个程序，获得这个订阅程序传来的数据，进行删除缓存操作。

   - （1）更新数据库数据。
   - （2）数据库则会把更新操作的信息，写入 binlog 日志当中。
   - （3）binlog 日志被订阅程序订阅到，则提取出所需要的数据以及 key。
     - 这个订阅 binlog 程序，在 MySQL 有现成的中间件（阿里# Canal），至于 Oracle 目前好像还没有现成的中间件。
   - （4）调用另一段非业务代码，获得 key。
   - （5）根据这个 key，尝试执行缓存删除操作。
   - （6）如果缓存删除失败，则将需要删除的 key，丢到消息队列中。
   - （7）然后消费消息，获取到要删除的 key。
   - （8）接着根据 key 继续重试删除操作，直到成功。

   ![1647257612877](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647257612877.png)

=> 以上，就是我对数据库、缓存双写一致性的一些实现方案的理解，请问有什么细节需要补充的吗？

### 1.9. 分布式锁？

#### 1、总

分布式锁指的是，在不同的系统或者同一个系统的不同主机之间，共享访问某个资源时，用来互斥地防止彼此干扰保证一致性的锁实现，其实现方式有：

- **基于数据库实现**：通过乐观锁，或者唯一索引实现。
- **基于分布式缓存实现**： 典型的有，通过 Redis 实现。
- **基于分布式一致性算法实现**：典型的有，通过 ZK 实现。

#### 2、分

##### 1）基于数据库实现 | 负担大

- **基于乐观锁实现**：原理是，根据版本号，来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。
- **基于唯一索引实现**：原理是，在表上建立唯一索引，当想要获得锁时，向表中插入一条记录，释放锁时则删除这条记录。
  - **缺点**：
    1. **锁没有失效时间**，解锁失败会导致死锁，此时该唯一索引所有 insert 都会返回失败，其他线程无法再获取到锁。
    2. **不可重入**，同一线程在没有释放锁之前无法再获取到锁。

##### 2）基于分布式缓存实现 | 锁失效

- **基于 Redis 单机实现**：使用 `SET NX EX` 指令加锁，保证**原子性**地给锁设置**过期时间，防止死锁**，使用 LUA 脚本 `redis.call` 指令，保证 key 值判断与删除键指令原子性执行，且防止由于 STW 时间过长，锁被其他进程误删。

  - **缺点**：会出现由于**时钟漂移** 或者 任务执行时间过长，导致的锁被提前释放的问题。

- **基于 Redisson 实现**：它是一个 Redis 的客户端，其分布式锁的实现原理是，让获得锁的线程开启一个定时守护线程，每隔 expireTime / 3 的时间就去检查一下，该线程持有的锁是否还存在，如果存在，则对锁的过期时间重新设置为 expireTime，完成守护线程对**锁的续约**，防止锁由于过期提前释放。

  - **缺点**：这些只是在 Redis 单机实现的分布式锁，加锁时只作用在一个 Redis 节点上，即使通过了 Sentinel 保证了高可用，但由于 Redis 是**异步复制**的，如果在 Master 节点获取到锁后，在未完成数据同步的情况下，发生了故障转移，那么其他客户端上的线程依然可以获取到锁，丧失了锁的安全性。

- **基于 RedLock 算法实现**：红锁算法的原理是，

  1. 先获取当前时间 `t1`，然后按顺序依次尝试从 n 个 Redis 实例，使用相同的 key 和具有唯一性的 value（例如 UUID）来获取锁，当向 Redis 请求获取锁时，除了设置锁的失效时间 `expire`，还应该设置超时时间 `timeout`，且这个超时时间 **<** 锁的失效时间 `expire` ，这样可以避免 Redis 已经挂掉的情况下，客户端不用一直等待响应结果，而是尽快地去尝试另外一个 Redis 实例来获取锁。
  2. 客户端通过使用当前时间 `t3` 减去开始获取锁时间 `t1`，就得到获取锁花费的总时间 `T`，当且仅当从过半数（N/2+1 个）的 Redis 节点都取到锁，并且获取锁花费的总时间 `T` **<** 锁失效时间 `expire` 时，锁才算获取成功，如果获取到了锁，那么 key 的真正有效时间 `real_expire` 等于锁失效时间 `expire` **减去**锁花费的总时间 `T`。
  3. 如果获取锁失败，客户端则应该在所有的 Redis 实例上使用 **Lua 脚本进行解锁**，原因是可能存在某个节点加锁成功后，**返回客户端时**的响应包丢失了，即客户端到服务器的通信是正常的，但反方向却是有问题的，虽然对客户端而言，由于响应超时导致加锁失败，但是对 Redis节点而言，`SET` 指令执行成功，意味着加锁成功，因此，释放锁时，客户端也应该对当时获取锁失败的那些 Redis 节点同样发起解锁请求。

  - **缺点**：
    1. **性能过重**：使用 RedLock 需要维护那么多的 Redis 实例，提升了系统的维护成本。
    2. **仍然不安全**：RedLock 严重依赖系统时钟，如果 Master 系统时间发生回调，则会导致它持有的锁提前过期释放，还是不能保证锁的安全性，这个是基于时间来实现自动释放的分布式锁，都无法解决的问题。

##### 3）基于分布式一致性算法实现 | 强一致

基于 ZK 实现：可以利用**顺序临时节点**的特性，结点在创建时，会自动在结点名后加一个数字后缀，以保证有序，同时，如果客户端连接失效，则还会立即删除结点，再利用 **watcher 监视器**的特性，注册某个结点的监视器，当节点状态发生改变时，watcher 被触发时，ZK 会向客户端发送一条通知。其分布式锁的实现原理是，

1. 创建一个锁目录 lock，希望获得锁的线程 A 在 lock 目录下，将创建**顺序临时结点**。
2. A 先获取锁目录下所有的子结点，判断是否存在序号比自己小的结点，如果不存在，则说明当前线程的顺序号最小，则线程 A 获得锁。
3. 当另外一个线程 B 获取锁时，判断到 B 自己不是最小的结点，存在有更小的线程 A 结点，则设置  watcher 监听器，只监听比自己**次小**的结点 A。
4. 当线程 A 处理完业务后，会删除结点 A，释放掉分布式锁，然后线程 B 监听到节点状态变更事件后，判断自己已经是最小的结点了，则成功获得锁。

#### 3、总

以上，就是我对分布式锁一些实现方案的理解，总结一下就是，

- **基于数据库实现**：
  - **优点**：直接使用数据库，使用简单。
  - **缺点**：但这样会增加数据库的负担。
- **基于分布式缓存实现**：
  - **优点**：属于 AP 模型，性能高，实现起来较为方便，在允许偶发性的锁失效情况发生，不影响系统正常使用时，可以采用分布式缓存来实现锁。
  - **缺点**：通过过期时间实现的锁超时机制不是十分可靠，当业务必须要数据的**强一致性**，不允许重复获得锁时，比如金融场景的重复下单与重复转账场景下，就不能使用分布式缓存来实现锁了，此时可以使用 CP 模型来实现，比如 Zookeeper。
- **基于分布式一致性算法实现**：
  - **优点**：不依靠过期时间来释放锁，可靠性高，当系统要求高可靠性时，可以采用分布式一致性算法来实现锁。
  - **缺点**：性能比不上分布式缓存实现的锁，因为 ZK 需要频繁的创建和删除结点。

### 2.0. 分布式全局 ID？

#### 1、总

1. 在分库分表环境中，由于表中数据同时存在不同数据库中，平时使用的自增主键 ID 将无用武之地，因为某个分区数据库自生成的 ID 无法保证全局唯一。
2. 因此，需要单独设计全局主键，来避免跨库主键重复的问题，我了解到的方案有：UUID、MyISAM ID 表、高可用 ID 服务器、Snowflake 分布式自增 ID 算法、以及美团的 Leaf 分布式 ID 生成系统。

#### 2、分

##### 1）UUID

UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8­4­4­4­12 的 36 个字符，比如：550e8400­e29b­41d4­a716­446655440000。

- **优点**：方案最简单，且本地生成，性能高，没有网络耗时。
- **缺点**：
  1. 由于 UUID 非常长，会占用大量的存储空间。
  2. UUID 作为主键，建立索引和基于索引进行查询时，都会存在性能问题，在 InnoDB 下，UUID 的无序性会引起数据位置频繁变动，导致页分裂。

##### 2）MyISAM ID 表

```sql
-- 使用MyISAM存储引擎建立ID表
CREATE TABLE `sequence` (  
  ìd` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '', 
  PRIMARY KEY  (ìd`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

-- 先删除再获取自增ID
REPLACE INTO sequence (stub) VALUES ('a');  
SELECT LAST_INSERT_ID();

```

- **概念**：
  1. `stub` 字段（存根）设置为**唯一索引**，同一 `stub` 值在 `sequence` 表中只有一条记录，支持同时给多张表生成全局 ID。
  2. 使用 MyISAM 存储引擎而不是 InnoDB，可以获取更高的性能，因为 MyISAM 使用的是表级锁，对表的读写是串行的，不用担心在并发时两次读取同一个 ID 值的问题。
  3. 使用 `REPLACE INTO + SELECT` 来获取自增 ID，保证两操作在同一事务内，它会先删除旧数据，再生成新数据，从而实现主键自增。
- **优点**：实现简单。
- **缺点**：
  1. 存在单点问题，且强依赖 DB，当 DB 异常时，会导致整个分布式系统都不可用。
  2. 虽然可以配置主从来增加可用性，但当主库挂了，主从切换时，数据一致性难以得到保证。
  3. 因此，整个系统的性能瓶颈，被限制在单台 MySQL 的读写性能上。

##### 3）高可用 ID 服务器

![1631524708834](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631524708834.png)

- **背景**：Flickr（弗里克，雅虎的一个图片分享网站）团队使用的一种主键生成策略，与上面的 `sequence` 表方案类似，但可以更好地解决了单点故障和性能瓶颈的问题。

- **思想**：

  1. 建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 `sequence` 表用于记录当前全局 ID。
  2. 表中 ID 增长的**步长相同，等于库的数量，起始值依次错开**，这样能将 ID 的生成散列到各个数据库上，比如第一台为（1，3，5，7，...）以及第二台为（2，4，6，8，...）等等。

- **优点**：生成 ID 的压力，能够均匀分布在多台机器上，同时提高了系统的容错能力，当第一台出现了错误，可以自动切换到第二台机器，来获取 ID。

- **缺点**：

  1. 系统添加机器水平扩展时，需要停止原本正在运行的 ID 服务器，以**修改步长**。
  2. 每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。

- **优化方案 **：**批量获取 ID**。

  - 使用批量获取的方式，可以降低数据库的写压力，每次获取**一段**区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。
    - 1）比如，还是使用 2 台 DB 保证可用性，数据库中只存储当前的最大 ID。
    - 2）ID 生成服务，每次批量获取 6 个ID，可以先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从**号段缓存**中依次派发 0~5 的 ID。
    - 3）当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的ID。
    - 4）这样，数据库的压力降低为原来的 1/6。
  - **缺点**：ID 生成服务需要维护最大 ID 值，再下次生成 ID 时，需要告诉 DB M1、DB M2 各自的初始值。

  ![1631525249951](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525249951.png)

##### 4）Snowflake 分布式自增 ID 算法

Twitter 的 snowflake 算法，解决了分布式系统生成全局 ID 的需求，可以生成 64 位的 long 类型的数值。

![1631525530303](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631525530303.png)

- **概念**：1 + 41 + 10 + 12  = 64位。
  1. 首先是，第 1 位不使用。
  2. 接下来是， 41 位的毫秒级时间戳，最大可以表示 **69年** 的时间。
  3. 然后是，5 位的 `datacenterId`，5位的 `workerId`，这 10 位长度，最多支持部署**1024 个节点**。
  4. 最后是，12 位是毫秒内的计数值，最大支持每个节点、每毫秒产生**4096 个 ID 序列**。
- **优点**：
  1. 毫秒数在高位，生成的 ID 整体上按时间趋势是**递增**的，还可以根据自身业务灵活分配 bit 位。
  2. 不依赖第三方系统，稳定、效率高，理论上 QPS 约为 409.6 w/s（2^12 * 1000 ms），且整个分布式系统中不会产生 ID 碰撞。
- **缺点**：强依赖于机器时钟，如果时钟回拨，则可能导致生成的 ID 重复。

##### 5）美团点评分布式ID生成系统 - Leaf

Leaf，服务美团点评公司内部产品，包含金融、支付交易、餐饮、外卖、酒店旅游、猫眼电影等众多业务线，其性能在 4 C 8 G 的机器上，QPS 能压测到近 5 w/s，TP 999 1ms，能够满足大部分的业务需求。

![1631532240042](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532240042.png)

###### 1、Leaf - segment ID 服务器方案

- **思想**：
  1. 获取 ID 时，向 proxy server 代理服务器批量获取 ID，每次获取一个 segment 号段（由 `step` 决定大小）的值。
  2. 用完之后，再去获取新的号段，可以大大减轻数据库的压力。
- **实现**：
  1. `biz_tag` 用来区分业务，`max_id` 表示该 `biz_tag` 目前所被分配的 ID 号段的最大值，`step` 表示每次分配的号段长度。
  2. 比如，`test_tag` 在第 1 台 Leaf 机器上是 1~1000 的号段，当这个号段用完时，会去加载另一个长度为step=1000 的号段，而如果另外机器的号段都没有更新的话，此时第 1 台机器会重新加载 3001~4000 的号段，同时，数据库对应的 `biz_tag` 这条数据的 `max_id` 会从 3000 被更新成 4000。
  3. 这样，各业务不同的发号需求用 `biz_tag` 字段来区分，每个 `biz-tag` 的 ID 相互隔离，互不影响，如果以后有性能要求，需要对数据库进行扩容时，则不用复杂的扩容操作，只需要对 `biz_tag` 分库分表即可。
  4. 而且，对比原来获取 ID 每次都需要写数据库，现在只需要把 `step` 设置得足够大，比如 1000，那么只有当 1000 个号被消耗完了之后，才会去重新读写一次数据库，此时读写数据库的频率从1  减小到了 **1 / step** 。
- **优点**：
  1. Leaf 服务可以很方便的进行**线性扩展**，性能完全能够支撑大多数业务场景。
  2. 生成的 ID 是**趋势递增**的 8 byte 的数字，满足上述数据库存储的主键要求。
  3. 容灾性高，Leaf 服务内部有**号段缓存**，即使 DB 宕机，短时间内，Leaf 仍能正常对外提供服务。
  4. 可以自定义 `max_id` 的大小，非常方便业务从原有的 ID 方式上**迁移**过来。
- **缺点**：
  1. **TP 999 数据波动大**：当号段使用完之后，还是会 hang 在更新数据库的 I/O 上，TP 999 数据会出现偶尔的尖刺。
  2. **高可用得不到保障**：DB 宕机会造成整个系统不可用。
  3. **生成的 ID 不够随机**：会泄露发号数量的信息，不太安全。

###### 2、双 buffer 优化方案

目的是，优化第 1 个缺点，当号段使用完、线程取号时阻塞的问题。

![1631532711485](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631532711485.png)

- **背景**：
  1. Leaf 取号段的时机，是在号段消耗完时进行的，意味着号段临界点的 ID 下发时间，取决于下一次从 DB 取回号段的时间，并且在这期间，进来的请求也会因为 DB 号段没有取回来，导致线程阻塞。
  2. 假如 Leaf 服务取 DB 时，网络发生抖动，或者 DB 发生慢查询，就会导致整个系统的响应时间变慢。
- **思想**：
  1. 为了让 DB 取号段的过程能够做到无阻塞，不会在 DB 取号段时阻塞请求线程，可以让发号段消费到某个点时，就**异步**的把下一个号段加载到内存中，而不需要等到号段用尽时，才去更新号段。
- **实现**：
  1. 采用双 buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。
  2. 当前号段已下发 10% 时，如果下一个号段未更新，则**异步**另启一个更新线程去更新下一个号段。
  3. 当前号段全部下发完后，如果下个号段准备好了，则切换到下个号段为当前 segment 接着下发，循环往复。

###### 3、高可用容灾方案

目的是，解决第 2 个缺点，DB 宕机会造成整个系统不可用的问题。

![1631543929139](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631543929139.png)

**DB 高可用方案**：

1. 采用 1 主 2 从的方式，同时分机房部署，Master 和 Slave 之间采用半同步复制的方式，进行数据同步，同时使用公司的 DBProxy（原 Atlas）数据库中间件，做主从切换。
2. 当然，这种方案在一些情况会退化成**异步模式**，甚至在非常极端情况下仍然会造成**数据不一致**的情况，但是出现的概率非常小。
3. 如果系统确实要保证 100% 的数据强一致，可以选择使用**类Paxos算法**，实现强一致 MySQL 的方案，但这样运维成本和精力都会相应的增加，应该需要根据实际情况进行选型。

**应用高可用方案**：

1. Leaf 服务分 IDC 部署，内部的服务化框架是 `MTthrift RPC`。
2. 服务调用时，根据负载均衡算法，优先调用同机房的 Leaf 服务。
3. 如果该 IDC 内，Leaf 服务不可用，则会选择其他机房的 Leaf 服务。
4. 同时，服务治理平台 `OCTO` ，还提供了针对服务的过载保护、一键截流、动态流量分配等服务保护措施。

###### 4、Leaf-snowflake 方案

目的是，优化第 3 个缺点，生成的 ID不够随机，会泄露发号数量信息，不太安全的问题。

![1631544317384](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544317384.png)

Leaf-snowflake 方案，完全沿用了 snowflake 方案的 bit 位设计，即是 `1+41+10+12` 的方式组装 ID 号。

1. 对于 `workerID` 的分配，当服务集群数量较小时，完全可以手动配置。
2. 但当 Leaf 服务规模较大时，动手配置成本太高，此时可以使用 ZK 持久顺序节点的特性，自动对 snowflake 节点配置 `wokerID`。

**对接 ZK 的步骤**：

1. 启动 Leaf-snowflake 服务时，会去连接 ZK，在 `leaf_forever` 父节点下，检查自己是否已经注册过，是否有该节点的持久化顺序子节点。
2. 如果有注册过，则直接取回自己的 `workerID`，启动服务。
3. 如果没有注册过，则在该节点下，创建一个持久化顺序节点，创建成功后，取回顺序号当做自己的 `workerID` 号，启动服务。
4. 除了每次会去 ZK 拿数据以外，也会在本机文件系统上，缓存一个 `workerID` 文件，当 ZK 出现问题且恰好 Leaf-snowflake 服务机器也需要重启时，还能保证服务正常启动，做到了对 ZK 的**弱依赖**，一定程度上提高了 SLA 。

![1631544564754](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1631544564754.png)

**解决 snowflake 时钟回退问题**：

由于 snowflake 强依赖机器时间，如果其发生了回拨，则可能会生成重复的 ID，解决方案为：

1. 首先，服务启动时，先检查自己是否写过 `ZK#leaf_forever` 节点。
   - 1）如果写过，则用自身系统时间与 `leaf_forever/#{self}` 节点记录时间做比较，且小于 `leaf_forever/​#{self}` 的时间，则认为当前机器时间发生了回拨，服务启动失败并报警。
   - 2）如果没写过，则证明是新服务节点，此时需要创建持久顺序节点 `leaf_forever/#{self}` ，并写入自身系统的时间。
2. 接下来，综合对比其余 Leaf 节点的系统时间，来判断自身系统时间是否准确，具体做法是：
   - 1）取 `leaf_temporary` 下的所有临时节点（**所有运行中的** Leaf-snowflake节点）的服务 IP+端口。
3. 然后，通过 RPC 请求，得到它们各自的系统时间，计算 `at = sum(time) / nodeSize`。
4. 如果计算结果 `at < 阈值`，认为当前系统时间准确，可以正常启动服务，同时写临时节点 `leaf_temporary/#{self}` ，每隔一段时间（3s），上报自身系统时间，并写入到 `leaf_forever/#{self}` 中，以维持租约。
5. 否则，则认为本机系统时间发生大步长的偏移，启动失败并报警。

#### 3、总

以上，就是我对分布式全局 ID 的一些实现方案的理解，请问有什么细节需要补充的吗？

### 2.1. 分布式幂等性？

#### 1、总

1. 幂等，idempotence，是一个数学与计算机学的概念，常见于抽象代数中。
2. 在编程中，一个幂等操作的特点是，**该操作被任意多次执行，其所产生的影响，都与一次执行的影响相同**。
3. 所以，幂等性的方法是指，可以使用相同参数，重复执行，并还能获得相同结果的方法，这些方法不会影响系统的状态，也不用担心重复执行后，是否会对系统造成多余的改变。
4. 比如，`getUsername()` 和 `setTrue()` 方法就是一个幂等性方法。
5. 因此，我的理解是，幂等就是一个操作，无论执行多少次，返回的结果或者产生的效果都是一样的。

#### 2、分

1. 那么，保证幂等性有哪些方案呢？
2. **查询操作**：查询一次和查询多次，在数据不变的情况下，结果都是一样的。select 是天然的幂等操作。
3. **删除操作**：删除一次和删除多次，都是把数据删除，产生的效果都是一样的，但是返回的结果可能不一样，因为删除的数据不存在时，会返回 0，存在时，则返回 1。
4. **唯一索引**：可以防止新增脏数据，比如，给资金账户表中的用户 ID 加唯一索引，使得并发时，一个用户新增一个资金账户记录，只会让一个新增成功，后新增的则报错，从而保证了只插入一条记录。
   - **注意**：为了幂等性友好反馈，一定要先查询一下，判断是否处理过该笔业务，如果不查询，直接插入业务的话，由于该业务实际已经处理过了，从而导致大量报错的发生。
5. **token 机制**：防止页面重复提交，比如，由于重复点击、或者网络重发等情况，会页面表单被重复提交，解决办法是 token + 分布式锁保证幂等性。

#### 3、总

以上，就是我对分布式幂等性的一些理解，请问有什么细节需要补充的吗？

### 2.2. 分布式会话？

#### 1、为什么 cookie 无法防止 CSRF 攻击，而 token 却可以？

1. CSRF，Cross Site Request Forgery，跨站请求伪造，简单来说，就是用你的身份，去发送一些对你不友好的请求。
   - 1）比如，小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，于是小壮就好奇地点开了这个链接，结果发现自己的账户少了10000元。
   - 2）这是这么回事呢？原来黑客在链接中，藏了一个请求 `<a src=http://www.mybank.com/Transfer?bankId=11&money=10000>科学理财，年盈利率过万</> `，这个请求直接利用小壮的身份，给银行发送了一个转账请求，也就是通过小壮的 cookie 向银行发出请求。
2. 使用 session 认证时，一般使用 cookie 来存储 sessionid，在登陆后，后端生成这个 sessionid，放在 cookie 中，返回给客户端，而服务端通过 Redis 或者其他存储工具，记录保存着这个 sessionid。
3. 客户端登录以后，每次请求都会带上这个 sessionId，服务端就可以用这个 sessionId，来标识哪些请求来源于你个人。
4. 但是，如果别人通过 cookie，拿到了你的 sessionId 后，就可以代替你的身份访问系统了，在登录后的客户端中，攻击者可以通过让用户误点攻击链接，从而利用每次请求都会带上这个 sessionId 的特性，以达到攻击效果。
5. 而如果使用 token 的话，就不会存在这个问题，因为登录成功获得 token 后，一般存放在 local storage 中，然后是前端通过某些方式，在每个发到后端的请求中，都加上这个 token。
6. 而如果点击了个非法链接，由于是非法链接，不是脚本，没有查询 local storage#token 的能力，此时发送给服务端的请求也，是不会携带 token 的，也就是这个请求是非法的，这样，就不会出现 CSRF 漏洞的问题了。

#### 2、什么是 token? 什么是 JWT ? 如何基于 token 进行身份验证？

![1647336741900](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647336741900.png)

1. 由于 session 需要先保存一份在服务器端，使得服务存在状态，这给后端服务带来一定的麻烦，比如，需要保证有 session 信息的服务器的可用性、在扩容时还要为其做额外的考虑、由于依赖于 cookie，所以不适合移动端等等。
2. JWT ，JSON Web Token，可以让服务器端不用保存 session 信息，只需在登录后返回给客户端，由客户端进行保存，以后每次请求都带上这个 token，服务端解析 token 即可拿到 session 信息，从而使后端服务的扩展性得到提升，所以，**token 就相当于一个通行令牌**。
3. JWT，本质上就一段签名后的 JSON 数据，接收者可以根据签名，验证它的真实性，它由 3 部分构成：
   - **1）Header**：token 头，描述 JWT 的元数据，主要定义了，生成签名的算法，以及 token 的类型。
   - **2）Payload**：token 体，主要用来存放实际传递的数据。
   - **3）Signature**：token 签名，服务器通过 Payload、Header 和一个 secret 密钥，使用 Header 指定的签名算法来生成 token 令牌，默认是 `HMAC SHA256`，登录生成后，则把 token 令牌返回给客户端。
4. 客户端收到 token 后，可以保存在 cookie，或者 local storage 里面，在以后发出的所有请求，都携带这个令牌，以标识请求来源，然后服务端检查 JWT，并从中获取用户相关信息，从而替代掉 sessionId。
   - 1）如果放在 cookie 里，让请求发送时自动带上，则不能跨域问题，因为非子域下的 token 将会失效。
   - 2）所以，最好的做法是，放在 `HTTP Header#Authorization` 字段中。

#### 3、token 使用的最佳实践？

1. **设置合理的过期时间**。
2. **注销的 token，如果后端保存过，则需要及时清除**。
3. **监控 token 的使用频率**：防止数据被别人爬取，通过监控使用频率，从请求痕迹中，分析出是否为爬虫程序访问。 
4. **核心功能、敏感操作可以使用动态验证码**：比如提现功能，就要求在提现时，再次进行验证码校验，以防止非本人操作。
5. **识别网络环境、浏览器等信息**：比如，网络环境跟之前使用的不一样时，则需要 APP 重新登录。
6. **secret 加密密钥支持动态修改**：
   - 1）如果 token 的 secret  加密密钥泄露了，意味着别人可以伪造这些 token，这需要能够立刻修改密钥，以更改 token 生成和校验机制。
   - 2）此时，可以将 secret 密钥存储在配置中心，以支持动态修改刷新。
   - 3）但需要注意的是，建议在流量低峰时，再去做 secret 加密密钥的更换操作，否则会导致 token 全部失效，使得所有在线的请求，都需要重新申请 token，导致并发量突增。

#### 4、session 共享方案？

1. **集中式 session 服务器**：还是使用 sessionid 和 cookie 的机制，统一由一个集中式服务器进行 session 管理，缺点是，sessionid  存储在客户端本地有风险，且要保证集中式 session 服务器的高可用。
2. **session 同步**：对各服务器进行 session 数据同步，虽然可以保证每个服务器上都有全部的 session 信息，但当服务器数量过多时，同步会带来很大延迟，甚至同步失败，故放弃。
3. **负载均衡 IP 绑定**：通过负载均衡，比如 nginx 对客户端 IP 与某个服务实例进行绑定，让同一个 IP 只能在指定的同一个机器访问，缺点是对应服务实例宕机后，session 将会丢失，且失去了对请求进行负载均衡的意义。
4. **Redis 共享存储**：把 session 存放到 Redis 中，缺点是需要多访问一次 Redis，但真正实现了 session 共享，不仅可以跨服务器 session 共享，还可以跨平台 session 共享，比如网页端和 APP 端；同时，还支持水平扩展、无状态化后端服务，即使服务重启了，存在 Redis 中的 session 也至于丢失。

#### 5、认证与授权的区别？

1. 认证，Authentication，身份验证，是验证你的身份凭据，比如用户名、用户ID 和密码是否合法，通过这个凭据，系统可以得以知道你就是你，是**身份维度**。
2. 授权，Authorization，发生在认证之后，主要是掌控用户访问系统的权限，有些特定资源只能具有特定权限的人才能访问，比如 admin，是**权限维度**。
3. 认证和授权，一般在系统中都被结合使用，目的是为了保护系统安全。

#### 6、单点登录 SSO？

SSO，Single Sign On，单点登录，是一种会话共享的技术，指用户只需要在某一个网站登录后，那么他所产生的同一次会话，就共享给了其他网站，也就是说，实现了单点登录后，间接地也登录了其他网站。

- **会话**，session，代表的是客户端与服务器的一次交互过程，这个过程可以是连续的，也可以是断断续续的。

根据浏览器的跨域与 cookie 特性，二级域名可同享一级域名的 cookie， 其他不同域名间不共享 cookie，实现基于会话共享的单点登录，可以分为 2 种不同方案：相同一级域名的单点登录和不同一级域名的单点登录。

##### 1、相同一级域名的单点登录 | cookie + Redis

二级域名共享一级域名的 cookie，即 `www.abc.test.com` 和 `www.def.test.com` ，两者共享 `www.test.com` 域名下的 cookie。

**具体流程为**：

1. 首先，前端方面，登录后，后端可以把标志当前会话的 userId，设置到 `www.test.com` 域名下的 cookie 中。
2. 然后，后端方面，则把 userId 作为 key，把会话信息放到 Redis 中，实现分布式会话。

这样，用户在 `www.abc.test.com` 登录后，userId 放入了 `www.test.com`  的 cookie 中，会话信息放到了 Redis 中，只要会话没结束（浏览器没关闭），则在用户下次访问 `www.def.test.com` 时，后端照样能够拿到 cookie 中的 userId，从而去 Redis 查到有会话信息，则认为本次请求有效，无需重新登录，从而实现单点登录。

##### 2、不同一级域名的单点登录 | cookie + CAS + Redis

（图片仅供参考，与下面流程不符）

![1647352168308](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647352168308.png)

不同一级域名间的 cookie 无法共享，即 `www.abc.com` 和 `www.def.com`，两者间的 cookie 无法共享。

这样，就需要引入一个中心节点，用于专门承接单点登录工作，以实现以上两个域名间的 cookie 共享，这个中心节点就是 CAS。

- **CAS**，Center Authentication Service，中央认证服务，是一个单点登录的解决方案，用于不同一级域名之间的单点登录。

**具体流程为**：

![img](file:///D:/MyData/yaocs2/Desktop/%E5%A4%87%E6%B3%A8/5%20SSO/SSO_%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95_%E6%97%B6%E5%BA%8F%E5%9B%BE_20220315.png)

假设 CAS 服务端域名为 `www.cas.com`，其他一级域名都是它的客户端，这里有两个，分别为 `www.abc.com` 和 `www.def.com` 。

1. 一个用户在某个时间，访问了 `www.mtv.com` 服务 A。
2. 此时，A 需要校验请求，由于 A 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
3. CAS 收到请求后，发现请求并没有会话标记，代表没有登录，则重定向用户到登录页面，需要用户进行登录。
4. 用户在登录成功后（账号密码校验通过），则 CAS 为用户创建会话，生成全局门票和临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 A。
5. A 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
6. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 A 登录成功。
7. 接着，用户跑去访问 `www.music.com` 服务 B。
8. 此时，B 需要校验请求，由于 B 没有认证能力，则把请求重定向到 CAS，让中央认证中心去做登录判断。
9. CAS 收到请求后，发现请求有会话标记，然后去查 Redis 是否存在全局门票，如果存在，则说明会话已共享，认为用户已登录，然后生成临时门票，把会话标记 userId，塞到 CAS 域名 `www.cas.com` 的 cookie 中，然后返回临时门票给 B。
10. B 拿到临时门票后，需要再次请求 CAS，让 CAS 去校验临时门票。
11. CAS 门票校验通过，撕毁临时门票，兑换成会话信息，设置到 CAS 域名 `www.cas.com` 的 cookie 中，然后显示 B 登录成功。
12. 至此，一次不同一级域名间的单点登录流程完毕。

其原理在于，利用了两网站间接共享了 CAS 同一个域名的 cookie，使用其中的 userId 作为当前会话的标记，以让后端能够拿着这个标记，去 Redis 中判断是否已生成分布式会话，从而免去第二次的重复登录，实现单点登录。

**全局门票 VS 临时门票**：

1. **全局门票是分布式会话**，是判断当前会话是否已经登录的核心所在。
2. **临时门票是安全性保证**，用于跟 CAS 换取会话信息。
   - **1）假设不用临时门票**，而是直接把全局门票返回给客户端，这样就会导致，如果该全局门票被他人知道了，那么即使用户的当前会话关闭了，劫持者依然能够通过全局门票进行登录操作，就保证不了单点登录是同一次会话。
   - **2）而如果用的是临时门票**，就可以保证本次登录只在当前会话有效，会话结束后，cookie 中的 userId 过期，再次请求 CAS 的话，就需要重新登录和设置了，并且，就算临时门票被劫持了，只需在临时门票兑换会话信息的操作中，增加额外的校验（比如网站来源，或者校验 cookie 中有没有 userId），返回校验不通过，就可以避免掉上面这种劫持风险了。

### 2.3. 分布式限流？

#### 1、分布式限流维度？

1. **时间**：限流基于某段时间范围，或者某个时间点，也就是常说的时间窗口，比如每分钟、每秒钟的时间窗口做限定。
2. **资源**：基于可用资源的限制，比如设定最大访问次数，或者最高可用连接数。

=> 故，

1. **限流就是在某个时间窗口内，对资源访问做限制**，比如设定每秒最多放行 100 个访问请求。
2. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
3. 比如针对了某个 IP 的限流，限制其每秒最多 10 个访问，那么不管这个 IP 的请求，落在了分布式中的哪台机器上，只要是访问了集群中的服务节点，那么都会受到限流规则的制约。

#### 2、分布式限流规则？

在真正的场景里，往往不止设置一种限流规则，而是会设置多个限流规则共同作用，主要以下 4 种规则：

1. **QPS 和连接数控制**：Nginx、Gateway / Zuul、Redis + Lua、Sentinel、Guava#RateLimiter 等。
2. **传输速率**：Nginx 限制下载速度。
3. **黑白名单**：布隆过滤器。

![1647393890625](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393890625.png)

#### 3、分布式限流实现方案？

1. 分布式限流，区别于单机限流的场景，它是把整个分布式环境中，所有的服务器当做一个整体进行考量。
2. 所以，需要将限流信息，保存在一个中心化的组件上，这样它就可以获取到集群中所有机器的访问状态，从而实现分布式限流。

目前比较主流的**实现方案**有：

1. **网关层限流**：把限流规则应用在所有流量的入口处。
2. **中间件限流**：把限流规则存储在分布式环境中的某个中间件里，比如 Redis 缓存中，每个组件都可以从这里，获取到当前时刻的流量统计信息，从而决定是拒绝服务，还是放行流量。

#### 4、分布式限流算法 - 计数器算法？

![1647393051245](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393051245.png)

**概念**：

计数器算法，是指在指定的时间周期内，累加访问次数，如果达到设定的阈值，则触发限流策略，在下一个时间周期进行访问时，再将访问次数清零。

**实现**：此算法无论在单机，还是分布式环境下实现都非常简单，使用 `redis#incr` 原子自增性，再结合 key
的过期时间，可以轻松实现。

**缺点**：

1. 这个算法有一个临界问题，比如在上图中，在 0:00 到 1:00 内，只在 0:50 有 60 个请求，而在 1:00 到 2:00 之间，只在 1:10 有 60 个请求。
2. 虽然在 2 个一分钟的时间内，都没有超过 100 个请求，但是在 0:50 到 1:10 这 20 秒内，却有 120 个请求。
3. 虽然在每个周期内，都没超过阈值，但是在这 20 秒内，却已经远远超过了我们原来设置的 1 分钟内 100 个请求的阈值。

#### 5、分布式限流算法 - 滑动时间窗口算法？

![1647393095141](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647393095141.png)

**概念**：

1. 为了解决计数器算法的临界值问题，于是就发明了滑动时间窗口算法，而在 TCP 网络通信协议中，就采用滑动时间窗口算法来解决网络拥堵问题的。
2. 滑动时间窗口，是将计数器算法中的实际周期，切分成多个小的时间窗口，分别在每个小的时间窗口中，记录访问次数，然后根据时间将窗口往前滑动，并删除过期的小时间窗口，最终只需要统计滑动窗口范围内的小时间窗口的总的请求数即可，本质上也是一种计数器算法。

**优点**：

1. 在上图中，假设我们设置一分钟的请求阈值是 100，则将一分钟拆分成 4 个小时间窗口，这样，每个小的时间窗口只能处理 25 个请求，用虚线方框表示滑动时间窗口，当前窗口的大小是 2，也就是在窗口内最多能处理50 个请求。
2. 随着时间的推移，滑动窗口也随着时间往前移动，比如上图开始时，窗口是 0:00 到 0:30 的这个范围，过了15 秒后，窗口右移到 0:15 到 0:45 的这个范围，窗口中的请求重新清零，很大地减少了计数器算法临界值问题出现的概率。
3. 在滑动时间窗口算法中，我们的小窗口划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。

**缺点**：滑动时间窗口算法，本质上还是计数器算法，所以极端情况下，还是会出现临界值问题，使用令牌桶算法则可以很好地解决这个问题。

#### 6、分布式限流算法 - 漏桶算法？

![1647394890225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394890225.png)

**概念**：

1. 漏桶算法的原理，就像它的名字一样，维持一个漏斗，拥有恒定的流出速度，不管水流流入的速度有多快，漏斗出水的速度始终保持不变。
2. 类似于消息中间件，不管消息的生产者请求量有多大，消息的处理能力取决于消费者。
3. `漏桶的容量 = 漏桶的流出速度 * 可接受的等待时长`，在这个容量范围内的请求，可以排队等待系统的处理，超过这个容量的请求，才会被抛弃。

**限流规则**：

在漏桶限流算法中，存在下面几种情况：

1. 当请求速度大于漏桶的流出速度时，也就是请求量大于当前服务所能处理的最大极限值时，会触发限流策略。
2. 当请求速度小于或等于漏桶的流出速度时，也就是服务的处理能力大于或等于请求量时，则正常执行。s

**缺点**：当系统在短时间内，有突发的大流量时，漏桶算法处理不了。

**优点**：桶末端流量匀速流出，能够保证系统平稳运行，不用应对突发流量。

#### 7、分布式限流算法 - 令牌桶算法？

![1647394814391](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647394814391.png)

**概念**：

1. 令牌桶算法，是增加一个大小固定的容器，也就是令牌桶，系统以**恒定的速率**向令牌桶中放入令牌，当令牌桶满时，再向令牌桶生成令牌时，令牌会被抛弃。
2. 如果有客户端来请求，先需要从令牌桶中拿一个令牌，拿到令牌，才有资格访问系统，这时令牌桶中少一个令牌。

**匀速要生成令牌原因**

1. **提高令牌利用率**：
   - 1）如果前 1 秒，一把梭哈了 10 个，但桶里都有 9 个了，此时只利用了 1 个令牌，其余 9 个令牌都会被丢弃。
   - 2）而如果匀速生成的话，就可以先 10 个令牌一个一个的发放，这样令牌也不至于被梭哈式的丢弃掉，提高了令牌的利用率。
2. **避免服务雪崩**：
   - 1）计数器算法和滑动时间窗口算法，在极端情况下，都会存在一个**临界值的问题**，即虽然某个统计窗口内没超过系统阈值，但前后区间总和却远远超过了系统阈值，从而有可能造成服务响应超时，甚至发生服务雪崩。
   - 2）采用匀速令牌生成，则可以避免某个区间前后之和大于系统阈值，因为**这个和 = 桶容量大小 + 令牌生成速度 * 区间跨度**，可见，令牌生成速度如果是匀速的话，那么这个和就会被限定在一个很小的值，从而可以很好的解决，上述那种人造区间洪峰流量的攻击，避免服务雪崩。

**限流规则**：

在令牌桶算法中，存在以下几种情况：

1. **请求速度大于令牌的生成速度**：那么令牌桶中的令牌会被取完，后续再进来的请求，由于拿不到令牌，会被限
   流。
2. **请求速度等于令牌的生成速度**：那么此时系统处于平稳状态。
3. **请求速度小于令牌的生成速度**：那么此时系统的访问量远远低于系统的并发能力，请求可以被正常处理。

**优点**：令牌桶算法，由于有一个桶的存在，可以处理短时间大流量的场景，这是令牌桶算法和漏桶算法的区别。

**缺点**： 由于可能会存在突发的大量，对系统设计时，需要保留一定的余力去面对。

### 2.5. 分布式文件存储？

#### 1、什么是分布式文件系统？

![1647397927726](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647397927726.png)

1. 随着文件数据的越来越多，通过 tomcat 或者 nginx 虚拟化的静态资源文件，在单一的一个服务器内已经存不下了，如果用多个节点存存储又不利于管理和维护，所以，需要一个系统来管理多台计算机节点上的文件数据，这个系统就是分布式文件系统。
2. 分布式文件系统，是一个允许文件，通过网络在多台节点上分享的文件系统，多台计算机节点，共同组成一个整体，为用户提供更大的文件存储空间。

#### 2、分布式文件系统的优点？

1. **海量文件数据存储**。
2. **文件数据高可用（冗余备份）**。
3. **读写性能好和支持负载均衡**。

#### 3、什么是 Fast DFS？

1. Fast DFS，是一个开源的轻量级的分布式文件系统，用于对文件进行管理，包括：文件存储、文件同步、文件上传、文件下载等。
2. 解决了大容量存储和负载均衡的问题，特别适合以文件为载体的在线服务，比如相册网站、视频网站等。

#### 4、Fast DFS 核心组件？

1. **tracker**：追踪者服务器，主要用于协调调度，起负载均衡的作用，记录 storage 的相关状态信息。
2. **storage**：存储服务器，用于保存文件，以及文件的元数据信息。
3. **group**：组，同组节点提供冗余备份，不同组用于扩容。
4. **mata data**：文件的元数据信息，比如长宽信息、图片后缀，视频帧数等信息。

#### 5、Fast DFS 文件上传流程？

1. Fast DFS 启动后，storage 会定期向 tracker 发送心跳续约。
2. 此时，一个客户端发起一个文件上传请求给 Fast DFS。
3. Fast DFS#tracker 收到请求后，则首先检查目前是否还有可用的 storage。
4. 检查到有，则返回可用的 storage 地址给客户端。
5. 客户端到后，则携带文件数据，到目标 storage 地址上传文件。
6. storage 服务接收文件，把文件写入磁盘中。
7. storage 文件写入磁盘成功后，则组装返回**文件对象信息**给客户端，包括文件相对路径、组名、文件名、文件 ID 等。
8. 客户端收到文件对象信息后，则做关于文件的一些业务处理，比如保存好文件存储的 ID 和路径等。

![1647398273896](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647398273896.png)

#### 6、Fast DFS 文件下载流程？

1. Fast DFS 启动后，storage 会定期向 tracker 发送心跳续约。
2. 此时，一个客户端发起一个文件下载请求给 Fast DFS。
3. Fast DFS#tracker 收到请求后，则首先根据**文件对象信息**（比如文件存储 ID），查找对应的 storage 地址。
4. 查找到，则返回对应的 storage 地址给客户端。
5. 客户端收到后，则到目标 storage 地址，文件进行下载。
6. storage 服务根据客户端给到的文件存储地址，查找所要下载的文件。
7. storage 找到文件后，则输出文件字节流给客户端。
8. 客户端收到文件流数据后，则可以进行文件下载或者展示。

![1647398629900](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647398629900.png)

#### 7、Fast DFS vs HDFS？

- **HDFS**：Hadoop 的默认存储方式，主要解决并行计算中大数据存储的问题，采用分块存储技术，适用于**大文件存储**。
- **Fast DFS**：主要是为文件上传和下载提供在线服务，支持负载均衡和动态扩容，适用于**中小文件存储**，比如用户头像、小视频等。

### 2.6. 分布式搜索？

#### 1、什么是分布式搜索？

分布式搜索，可以将更大范围分布的异构数据联合起来，形成一个逻辑整体，为用户提供强大的**全文检索**能力。

![1647400157225](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647400157225.png)

#### 2、Lucene、Solr、ElasticSearch？

- **Lucene**：是一个基于 Java 的类库，集成了许多 API 方法，相当于一个 Jar 包，只能给 Java 使用，实现集群十分复杂。
- **Solr**：Apche 的开源项目，也是用的 Java 开发，基于 Lucene 的开源搜索引擎，本质上是对 Lucene 进行的一层封装，可以实现集群，可靠性，容错性高。
- **ElasticSearch**：也叫 ES，基于 Lucene 开发，提供很多 RestFul 风格的接口，可供其他语言使用，可扩展性更高，支持 PB 级别的近实时搜索。

#### 3、倒排索引 vs 正排索引？

- **正排索引**：文档 => 关键词，但在检索关键词时很费力，要一个文档一个文档，挨个遍历查找。
- **倒排索引**：关键词 => 文档，可以根据关键词，立马找到其出现过的所有文档。

#### 4、ES 核心概念？

1. **Near Realtime**：NRT，近实时，两个意思：
   - 1）从写入数据到数据可以被搜索到有一个小延迟（大概1秒）。
   - 2）基于es执行搜索和分析可以达到秒级。
2. **Cluster**：
   - 1）集群，包含多个节点，通过配置集群名称，来划分每个节点所属集群。
   - 2）对于中小型应用来说，刚开始一个集群只有一个节点很正常。
3. **Node**：节点，集群中的一个节点，节点也有一个名称，默认随机分配。
4. **index**：
   - 1）索引，包含一堆有相似结构的文档数据，比如客户索引、商品分类索引、订单索引。
   - 2）索引有一个名称，一个 index 包含很多 document，一个 index 就代表了一类类似的或者相同的document 。
   - 3）在 ES 5.x 版本以前，可以在一个索引中定义多个类型，6.x 之后一个索引只能创建一个类型，在 7~8.x 版本中，已经被彻底移除了。
5. **type**：类型，每个索引里都可以有一个或多个 type，type 是 index 中的一个逻辑数据分类，一个 type 下的document，都有相同的 field。
6. **document**：文档，是 ES 中的最小数据单元，一个 document 可以是一条客户数据、一条商品分类数据、一条订单数据，通常用 json 数据结构来表示，每个 index 下的 type 中，都可以去存储多个 document。
7. **field**：属性，一个 document 里面有多个 field，每个 field 就是一个数据字段。
8. **shard**：
   - 1）分区，单台机器无法存储大量数据，ES 就把一个索引中的数据，切分为多个 shard，分布在多台服务器上存储。
   - 2）有了 shard 就可以横向扩展，以存储更多数据，让搜索和分析等操作，分布到多台服务器上去执行，提升吞吐量和性能。
9. **replica**：
   - 1）副本，任何一个服务器随时都可能故障或宕机，导致 shard 可能就会丢失，因此，ES 为每个 shard 创建多个 replica 副本。
   - 2）replica 可以在 shard 故障时，提供备用服务，保证数据不丢失。

| ES       | 类比于 MySQL 中的     |
| -------- | --------------------- |
| index    | 库                    |
| type     | 表                    |
| document | 行                    |
| field    | 列                    |
| mappings | 表结构                |
|          |                       |
| **ES**   | **类比于 Kafka 中的** |
| Node     | Broker                |
| shard    | Partition             |
| replica  | Partition#Replica     |

#### 5、ES 读写原理？

**写原理**：

1. 把索引拆分成多个 shard 分区，每个 shard 存储部分数据。
2. 其中，一个 shard 可以有多个备份，也就是说，每个 shard 都会有一个 primary shard 主分区，负责写入数据，还有几个 replica shard 副本分区。
3. primary shard 主分区写入数据之后，会将数据同步到其他几个 replica shard 副本上去。
4. 通过这个分区 + 副本机制，可以保证每个 shard 都有多个备份，如果某个机器宕机了，则还会有别的副本在别的机器上，从而实现高可用。
5. 如果某台 primary shard 主分区宕机，那么会由 master 节点，让那个宕机节点上的 primary shard 主分区的身份，转移到其他机器上的 replica shard 副本分区中。
6. 当宕机的那台机器修复完，并重启之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据，让集群恢复正常。
7. 而如果 master 节点宕机了，那么则会重新选举一个节点为 master 节点。

**读原理**：

1. 客户端发送一个搜索请求，协调节点会把请求发送给所有的 shard。
2. 然后这些 shard 会去自己里面查，找到可能会匹配到的 doc，返回给协调节点。
3. 协调节点再去 doc 里面去做匹配，找到最符合查询需要的那些 document。
4. 最后再给客户端返回。

#### 6、ES API 使用？

以下操作都是基于《elasticsearch-6.4.3》进行记录的~

##### 一、集群操作

###### 1）查询集群健康信息

```json
GET     /_cluster/health

```

##### 二、索引操作

###### 1）查看索引

```json
GET     _cat/indices?v

```

###### 2）创建索引

```json
PUT     /index_test

{
    "settings": {
        "index": {
            "number_of_shards": "2",
            "number_of_replicas": "0"
        }
    }
}

```

###### 3）删除索引

```json
DELETE      /index_test

```

###### 4）创建索引同时创建 mappings

```
PUT     /index_str

{
    "mappings": {
        "properties": {
            "realname": {
            	"type": "text",
            	"index": true
            },
            "username": {
            	"type": "keyword",
            	"index": false
            }
        }
    }
}

```

###### 5）为已存在的索引新增 mappings

1. 注意，某个 mappings 的属性一旦被建立，就不能再修改了，但还可以追加额外的属性。
2. **主要数据类型**有：
   - 1）**字符串型**：text、keyword。
   - 2）**整型**：long、Integer、short、byte。
   - 3）**浮点型**： double、short。
   - 4）**布尔型**：boolean。
   - 5）**日期型**：date。
   - 6）**对象型**：object（{ } 格式）。
   - 7）**数组型**：[ ] 格式，但里面的类型要一致。
3. **text vs keyword**：
   - **text**：会对内容进行分词，可以用于商品名称、商品详情、商品介绍。
   - **keyword**：不会对内容进行分词，需要精确匹配，可以用于订单状态、qq 号、微信号、手机号等。

```json
POST        /index_str/_mapping

{
    "properties": {
        "id": {
        	"type": "long"
        },
        "age": {
        	"type": "integer"
        },
        "nickname": {
            "type": "keyword"
        },
        "money1": {
            "type": "float"
        },
        "money2": {
            "type": "double"
        },
        "sex": {
            "type": "byte"
        },
        "score": {
            "type": "short"
        },
        "is_teenager": {
            "type": "boolean"
        },
        "birthday": {
            "type": "date"
        },
        "relationship": {
            "type": "object"
        }
    }
}

```

##### 三、文档操作

这些查询方式，称为 QueryString 查询方式。

###### 1）添加文档数据

注意，如果索引没有手动建立 mappings，那么插入文档时，则会根据文档类型自动设置属性类型，这就是 ES 的动态映射。

```json
POST /{索引名}/_doc/{索引ID}

{
    "id": 1001,
    "name": "imooc-1",
    "desc": "imooc is very good, 慕课网非常牛！",
    "create_date": "2019-12-24"
}

```

###### 2）删除文档

注意，文档删除不是立即删除，删除后文档还是会保存在磁盘上，当索引积累得越来越多时，ES 才会把那些曾经标识为删除的清理掉，此时才会真正的从磁盘上移出去。

```json
DELETE /my_doc/_doc/1


```

###### 3）局部更新文档

每次修改后，隐藏的 `version` 字段都会被更改。

```json
POST /my_doc/_doc/1/_update

{
    "doc": {
        "name": "慕课"
    }
}


```

###### 4）全量更新文档

每次修改后，隐藏的 `version` 字段都会 +1。

```json
PUT /my_doc/_doc/1

{
     "id": 1001,
    "name": "imooc-1",
    "desc": "imooc is very good, 慕课网非常牛！",
    "create_date": "2019-12-24"
}

```

###### 5）查询文档

```json
GET /index_demo/_doc/1
GET /index_demo/_doc/_search

```

**查询得到的结果**：

1. **_index**：文档数据所属索引。
2. **_type**：文档数据属于哪个类型。
3. **_id**：文档数据的唯一标识，类似于数据库中某张表的主键，可以自动生成或者手工指定。
4. **_score**：查询相关度，表示与用户查询条件的契合程度，分数越高，用户搜索体验越好。
5. **_version**：版本号。
6. **_source**：真实的文档数据，json 格式表示。

```json
{
    "_index": "my_doc",
    "_type": "_doc",
    "_id": "2",
    "_score": 1.0,
    "_version": 9,
    "_source": {
        "id": 1002,
        "name": "imooc-2",
        "desc": "imooc is fashion",
        "create_date": "2019-12-25"
    }
}

```

###### 6）定制文档查询结果

```json
GET /index_demo/_doc/1?_source=id,name
GET /index_demo/_doc/_search?_source=id,name


```

###### 7）查询文档是否存在

```json
HEAD /index_demo/_doc/1


```

##### 四、分词检索

###### 1）内置分词检索

**ES 内置分词器**：

1. **standard**：默认分词，单词会被拆分，大小会转换为小写。
2. **simple**：按照非字母分词，大小转为小写。
3. **whitespace**：按照空格分词，忽略大小写。
4. **stop**：去掉无意义的单词，比如 the / a / an / is 等等。
5. **keyword**：不做分词，把整个文本作为一个单独的关键词。

```json
POST /my_doc/_analyze

{
    "analyzer": "standard",
    "field": "name",
    "text": "text文本"
}


```

###### 2）IK 分词检索

```json
POST /_analyze

{
    "analyzer": "ik_max_word",
    "text": "上下班车流量很大"
}


```

##### 五、DSL 操作

DSL，Domain Specific Language，领域特定语言，是 ES 基于 JSON 格式的数据查询语言，相比于 Query String 方式，DSL 查询更加灵活，有利于复杂查询。

###### 1）查询所有文档

```json
POST     /shop/_doc/_search

{
    "query": {
        "match_all": {}
    },
    "_source": ["id", "nickname", "age"]
}


```

###### 2）term vs match

1. match 会对 `慕课网` 先进行分词，然后再查询。
2. 而 term 则不会，直接把 `慕课网` 作为一个 整的词汇去搜索。

```json
POST     /shop/_doc/_search

{
    "query": {
        "term": {
            "desc": "慕课网"
        }
    }
}

对比

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    }
}


```

###### 3）连续分词匹配查询

1. match 分词后，只要有匹配就返回。
2. match_phrase：分词结果必须在字段中包含，顺序还要与 query 中的相同才返回，而且必须是连续的。

```json
POST     /shop/_doc/_search

{
    "query": {
        "match_phrase": {
            "desc": {
            	"query": "大学 毕业 研究生",
            	"slop": 2
            }
        }
    }
}


```

###### 4）逻辑匹配查询

and / or 

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    }
}

+

{
    "query": {
        "match": {
            "desc": {
                "query": "xbox游戏机",
                "operator": "or"
            }
        }
    }
}

=> 相当于 select * from shop where desc='xbox' or|and desc='游戏机'


```

###### 5）匹配度查询

minimum_should_match，最低匹配精度，至少有 n% * query 中分词个数的文档才会被匹配。

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": {
                "query": "女友生日送我好玩的xbox游戏机",
                "minimum_should_match": "60%"
            }
        }
    }
}


```

###### 6）主键查询

```json
POST     /shop/_doc/_search

{
    "query": {
        "ids": {
            "type": "_doc",
            "values": ["1001", "1010", "1008"]
        }
    }
}



```

###### 7）多条件匹配

multi_match，多个字段同时满足条件，才会被匹配。

```json
POST     /shop/_doc/_search

{
    "query": {
        "multi_match": {
                "query": "皮特帕克慕课网",
                "fields": ["desc", "nickname"]

        }
    }
}


```

###### 8）权重查询 

权重，为某个字段设置权重，权重越高，文档相关性得分就越高，比如商品名称的权重，一般都比商品简介的权重要高。

```json
POST     /shop/_doc/_search

{
    "query": {
        "multi_match": {
            "query": "皮特帕克慕课网",
            -- nickname^10，表示搜索权重提升10倍相关性，搜索时以nickname为主，desc为辅
            "fields": ["desc", "nickname^10"]
        }
    }
}


```

###### 9）布尔查询

1. **must**：查询必须匹配搜索条件，类似于 and。
2. **should**：查询需匹配满足 1 个以上条件，类似于 or。
3. **must_not**：一个搜索条件都不能匹配。

```json
{
    "query": {
        "bool": {
            "must": [
                {
                	"match": {
                		"desc": "慕"
                	}	
                },
                {
                	"match": {
                		"nickname": "慕"
                	}	
                }
            ],
            "should": [
                {
                	"match": {
                		"sex": "0"
                	}	
                }
            ],
            "must_not": [
                {
                	"term": {
                		"birthday": "1992-12-24"
                	}	
                }
            ]
        }
    }
}


```

###### 10）过滤器

1. 过滤器，可以对搜索出来的结果进行数据过滤，可以和全文检索一起结合使用。
2. 过滤器类型：
   - **gte**：大于等于。
   - **lte**：小于等于。
   - **gt**：大于。
   - **lt**：小于。

```json
POST     /shop/_doc/_search

{
	"query": {
		"match": {
			"desc": "慕课网游戏"
		}	
    },
    "post_filter": {
		"range": {
			"money": {
				"gt": 60,
				"lt": 1000
			}
		}
	}	
}


```

###### 11）排序

类似于 sql 中的排序，asc 表示顺序，desc 表示逆序。

```json
POST     /shop/_doc/_search
{
	"query": {
		"match": {
			"desc": "慕课网游戏"
		}
    },
    "post_filter": {
    	"range": {
    		"money": {
    			"gt": 55.8,
    			"lte": 155.8
    		}
    	}
    },
    "sort": [
        {
            "age": "desc"
        },
        {
            "money": "desc"
        }
    ]
}


```

###### 12）高亮标签

```json
POST     /shop/_doc/_search

{
    "query": {
        "match": {
            "desc": "慕课网"
        }
    },
    "highlight": {
        "pre_tags": ["<tag>"],
        "post_tags": ["</tag>"],
        "fields": {
            "desc": {}
        }
    }
}


```

###### 13）前缀匹配查询

```json
POST     /shop/_doc/_search

{
    "query": {
        "prefix": {
            "desc": "imo"
        }
    }
}


```

###### 14）错误纠偏查询

```json
POST     /shop/_doc/_search

{
  "query": {
    "fuzzy": {
      "desc": "imoov.coom"
    }
  }
}


```

###### 15）占位符查询

- **?**：占 1 个字符。
- *****：占 1 个或者多个字符。

```json
POST     /shop/_doc/_search

{
  "query": {
    "wildcard": {
      "desc": "*oo?"
    }
  }
}


```

###### 16）分页查询

```json
POST     /shop/_doc/_search

{
	"query": {
		"match_all": {}
	},
	"_source": [
		"id",
		"nickname",
		"age"
	],
	"from": 5,
	"size": 5
}


```

###### 17）滚动分页查询 | 解决深度分页问题

scroll=1m，相当于一个 session 会话时间，设置搜索保持的上下文为 1 分钟。

```json
-- 滚动分页第一次查询，开启滚动分页
POST    /shop/_search?scroll=1m
{
    "query": { 
    	"match_all": {
    	}
    },  
    "sort" : ["_doc"], 
    "size":  5
}

-- 滚动分页第二次查询
POST    /_search/scroll
{
    "scroll_id": "DnF1ZXJ5VGhlbkZldGNoBQAAAAABrDnhFnFiRFN6VFZEVDRLNXNCTFJKeHZkTkEAAAAAAaw55BZxYkRTelRWRFQ0SzVzQkxSSnh2ZE5BAAAAAAGsOeMWcWJEU3pUVkRUNEs1c0JMUkp4dmROQQAAAAABrDniFnFiRFN6VFZEVDRLNXNCTFJKeHZkTkEAAAAAAaw55RZxYkRTelRWRFQ0SzVzQkxSSnh2ZE5B",
    "scroll": "1m"
}


```

##### 六、批量操作

###### 1）批量获取文档

```json
GET http://10.18.12.149:9200/shop/_doc/_mget
{
    "ids": [
        "1001",
        "1003",
        "10015"
    ]
}


```

###### 2）批量插入文档及 mappings

```json
POST http://10.18.12.149:9200/_bulk

{"create": {"_index": "shop2", "_type": "_doc", "_id": "2004"}}
{"id": "2004", "nickname": "name-2004"}
{"create": {"_index": "shop2", "_type": "_doc", "_id": "2005"}}
{"id": "2002", "nickname": "name-2005"}
{"create": {"_index": "shop2", "_type": "_doc", "_id": "2003"}}
{"id": "2003", "nickname": "name-2003"}

```

###### 3）批量插入文档到已有索引中

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"create": {"_id": "2007"}}
{"id": "2004", "nickname": "name-2004"}
{"create": {"_id": "2008"}}
{"id": "2002", "nickname": "name-2005"}
{"create": {"_id": "2009"}}
{"id": "2003", "nickname": "name-2003"}

```

###### 4）批量更新或保存文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"index": {"_id": "2004"}}
{"id": "2004", "nickname": "index-2004"}
{"index": {"_id": "2007"}}
{"id": "2007", "nickname": "name-2007"}
{"index": {"_id": "2008"}}
{"id": "2008", "nickname": "name-2008"}

```

###### 5）批量更新文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"update": {"_id": "2004"}}
{"doc": {"id": "3304"}}
{"update": {"_id": "2007"}}
{"doc": {"nickname": "name-update"}}

```

###### 6）批量删除文档

```json
POST http://10.18.12.149:9200/shop2/_doc/_bulk

{"delete": {"_id": "2001"}}
{"delete": {"_id": "2003"}}
{"create": {"_id": "8008"}}
{"id": "8008", "nickname": "name-8088"}
{"update": {"_id": "2002"}}
{"doc": {"id": "2222"}}

```

# **十三、云原生篇**

### 1.1. 什么是云原生？

**云原生**，从字面上可分为云和原生两部分。

- **云**：和本地是相对的，使用云服务器相对于本地服务器，具有即买即用、租用成本低、有专门人员维护等优势。
- **原生**：土生土长的意思，应用运行在云环境中，可充分利用云资源弹性伸缩和分布式的优点。

可以简单地理解为：**云原生 = 微服务 + DevOps（开发即运维） + 持续交付（CI / CD） + 容器化**。

![1647417707915](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647417707915.png)

### 1.2. 容器化技术出现原因？

1. **码头林立**：各种软硬件平台层出不穷，需要有一种的"**集装箱**"（Container）技术，来做统一的兼容器处理，这种"集装箱"技术，就是**容器化技术**。

   ![1647486093741](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486093741.png)

2. **微服务盛行**：

   - 1）微服务高可用，导致虚机需求数量多。
   - 2）每个微服务各自的环境需求差异大，比如 CPU 业务型、GPU 计算型、高吞吐 I/O 型。
   - 3）服务启动速度要求高。

   ![1647486158358](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486158358.png)

3. **DevOps 开发即运维文化盛行**：让开发处理专业的运维不现实，需要有一种简单的界面和处理方式，让开发就能进行各环境发布。

![1647486327631](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647486327631.png)

### 1.3. 容器化技术演进历程？

![1647487118696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647487118696.png)

1. **猿人阶段**：W PAR，大型机独立任务管理。
2. **智人阶段**：Linux Namespace Group，Linux 资源控制制度，比如内核态用户态隔离。
3. **山顶洞人阶段**：Linux Container，LXC，Linux 容器隔离。
4. **现代人阶段**：Docker、Cloud  Foundry，成熟的容器化技术。
5. **未来阶段**：可能不会太关注某一个容器技术，而是立足于抽象技术，比如：
   - 1）平台化容器编排、Paas 公有云服务。
   - 2）ServerLess 无服务器化 （Lambda、Function）。
   - 3）容器技术生态圈化。

### 1.4. 什么是容器？

1. 容器，是一种轻量级的、可移植的、自包含的软件打包技术，使应用程序可以在几乎任何地方、以相同的方式运行。
2. 开发人员在自己笔记本上，创建并测试好的容器，无需任何修改，就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。

### 1.5. 容器 vs 虚拟机？

**相同点**：两者都是为应用提供封装和隔离。

**不同点**：

1. **容器**，由应用本身和应用依赖两部分组成，在操作系统的用户空间运行，与其他进程相互隔离，所有容器共享同一个操作系统，体积比虚拟机小，启动速度快，开销小，更容易迁移。
2. 而**虚拟机**，由部署应用、依赖以及操作系统组成，启动时，需要启动整个虚拟机操作系统，开销更大，启动速度慢。

### 1.5. 什么是 Docker？

![1647494464489](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647494464489.png)

Docker，go 语言开发，思想如 logo 一样，集装箱 Container 容器，主要任务是负责容器的运行和管理，通过隔离机制，使得每个容器间互不影响，以及通过限制每个容器的 CPU、内存和 I/O 资源，还能最大程度地压榨服务器资源。

### 1.6. Docker  vs VM？

![1647495378749](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495378749.png)

1. VM 是虚拟机技术，而 Docker 是容器化技术。
2. VM 虚拟出完整的操作系统，而 Docker 则直接运行在宿主机的内核之上，没有自己的内核和虚拟硬件，更加小巧轻便，可以更高效地利用宿主机的资源。
3. VM 比 Docker 更重，更消耗资源，启动速度也远比 Docker 要慢，Docker 可以实现更快速的运维部署，更便捷的升级以及扩容和缩容。

### 1.7. Docker 架构原理？

![1647495796223](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647495796223.png)

#### 1）Client

 Docker 客户端模块，用于运行 Docker 命令以及 Restful API。

#### 2）Docker host

Docker 服务器模块，存在一个 Docker Daemon 后台进程，负责整个 Docker 容器的生命周期管理，连接 Registry 下载镜像，以及提供 Client 的 API 端口来处理发送过来的命令。

#### 3）Registry

Docker 镜像仓库。

Docker Hub：官方公有的镜像仓库。

https://hub.docker.com

Docker Datacenter：Docker 企业信任仓库。

Docker 私有仓库：内网自建仓库。

#### 4）Images

Docker 镜像，可本地制作，也可来源于镜像仓库，是容器运行前代码、配置、环境变量、操作系统资源的打包，运行起来了之后叫做容器，类似于 VM 的配置模板，通过 UnionFS 联合文件系统，支持镜像的一层层叠加。

![1647499834535](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647499834535.png)

#### 5）Containers

Docker 容器，每个容器共享主机的操作系统，通过 namespace 对 pid 进程、net 网络、ipc 信号量、mnt 文件系统、uts 用户组等进行**隔离**，通过 cgroup 对每个容器的 cpu、mem、io 等资源进行**限制**。

### 1.8. 如何使用 Docker？

![1647496057218](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647496057218.png)

#### 一、基本命令

##### 1）安装 Docker

```shell
sudo yum install docker-ce docker-ce-cli containerd.io

```

##### 2）启动 Docker

```shell
sudo systemctl start docker

```

##### 3）重新加载 Docker 配置

```shell
sudo systemctl daemon-reload

```

##### 4）重启 Docker

```shell
sudo systemctl restart docker

```

##### 5）查看 Docker 版本

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker version
Client: Docker Engine - Community
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.13.15  # go语⾔实现的
 Git commit:        48d30b5
 Built:             Fri Jan 29 14:33:08 2021
 OS/Arch:           linux/amd64

```

##### 6）查看 Docker 基本信息

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker info
Client:
 Context:    default
 Debug Mode: false
 Plugins:
  app: Docker App (Docker Inc., v0.9.1-beta3)
  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)
 
Server:
 Containers: 2   # 有容器两个
  Running: 1    # 1个运⾏中
  Paused: 0
  Stopped: 1    # 1个停⽌
 Images: 26
 Server Version: 20.10.3
 Storage Driver: overlay2

```

##### 7）查看 Docker 帮助命令

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps --help
 
Usage:  docker ps [OPTIONS]
List containers
Options:
  -a, --all             Show all containers (default shows just running)
  -f, --filter filter   Filter output based on conditions provided
      --format string   Pretty-print containers using a Go template
  -n, --last int        Show n last created containers (includes all 
states) (default -1)
  -l, --latest          Show the latest created container (includes all 
states)
      --no-trunc        Don't truncate output
  -q, --quiet           Only display container IDs
  -s, --size            Display total file sizes

```

##### 8）查看运行中的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps
CONTAINER ID   IMAGE          COMMAND       CREATED       STATUS       
PORTS     NAMES
bcd0201753a9   300e315adb2f   "/bin/bash"   6 hours ago   Up 6 hours       
      flamboyant_dirac

```

##### 9）查询所有的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker ps -a
CONTAINER ID   IMAGE          COMMAND       CREATED         STATUS         
            PORTS     NAMES
360354ed578c   hello-world    "/hello"      3 minutes ago   Exited (0) 3 
minutes ago             exciting_galois
bcd0201753a9   300e315adb2f   "/bin/bash"   6 hours ago     Up 6 hours     
                      flamboyant_dirac

```

##### 10）查看容器的进程状态

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker top bcd0201753a9
UID                 PID                 PPID                C               
    STIME               TTY                 TIME                CMD
root                13445               13426               0               
    14:38               pts/0               00:00:00            /bin/bash
root                13738               13426               0               
    14:50               pts/1               00:00:00            /bin/bash
root                13877               13426               0               
    14:52               ?                   00:00:00            /bin/bash

```

##### 11）查看所有容器的状态

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker stats
 
$ docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 
"discovery.type=single-node" elasticsearch:7.10.1
 
$ docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 
"discovery.type=single-node" -e ES_JAVA_OPTS="-Xms64m -Xmx512m" 
elasticsearch:7.10.1

```

##### 12）查看某个容器的元数据信息

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker inspect bcd0201753a9
[
    {
        "Id": 
"bcd0201753a943336ec4c5612e4a4e36388207d03e5d039472101880ef98c514",
        "Created": "2021-03-07T06:37:08.166894239Z",
        "Path": "/bin/bash",
        "Args": [],
        "State": {
            "Status": "running",
            "Running": true,
            "Paused": false,

```

##### 13）开启新的终端，进入容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker exec -it 7719397b904b 
/bin/bash
[root@7719397b904b /]# pwd
/


```

##### 14）复用已有终端，进入容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker attach 7719397b904b
[root@7719397b904b usr]# pwd
/usr


```

##### 15）拷贝主机文件到容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker cp /home/muse/test/a.txt 
7719397b904b:/


```

##### 16）拷贝容器文件到主机

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker cp 7719397b904b:/a.txt 
/home/muse/test


```

#### 二、镜像命令

##### 1）配置镜像源

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# cat /etc/docker/daemon.json
{
  "registry-mirrors": ["https://aa25jngun.mirror.aliyuncs.com"]
}


```

##### 2）列出本机的所有镜像

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker images
REPOSITORY         TAG        IMAGE ID       CREATED         SIZE
muse/centos        1.0        eb78333356a6   2 days ago      209MB
redis01            latest     84a8d576c57d   2 weeks ago     104MB
mysql              5.7        a70d36bc331a   6 weeks ago     449MB
rabbitmq           latest     7471fb821b97   7 weeks ago     167MB


```

##### 3）搜索镜像

https://hub.docker.com

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker search mysql
NAME                              DESCRIPTION                               
      STARS     OFFICIAL   AUTOMATED
mysql                             MySQL is a widely used, open-source 
relation…   10583     [OK]
mariadb                           MariaDB Server is a high performing open 
sou…   3960      [OK]
mysql/mysql-server                Optimized MySQL Server Docker images. 
Create…   776                  [OK]
percona                           Percona Server is a fork of the MySQL 
relati…   527       [OK]
centos/mysql-57-centos7           MySQL 5.7 SQL database server             
      87


```

##### 4）拉取最新镜像

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker pull rabbitmq
Using default tag: latest
latest: Pulling from library/rabbitmq
f22ccc0b8772: Pull complete
3cf8fb62ba5f: Pull complete
e80c964ece6a: Pull complete
c1d2d6c5864b: Pull complete
0adcf6f8f5f2: Pull complete
6d7425e3abe0: Pull complete
b03e46685eee: Pull complete
f83c4b83a829: Pull complete
fab4bdeccdff: Pull complete
02221abafa2c: Pull complete
Digest: 
sha256:5a6e86289ee2d03a6889341bfb3a76943de1d0c4d01b777c4159a944d8d3e9cd
Status: Downloaded newer image for rabbitmq:latest
docker.io/library/rabbitmq:latest


```

##### 5）拉取指定版本的镜像

```shell
docker pull mysql:5.7


```

##### 6）删除镜像

```shell
docker rmi -f [IMAGE ID]
docker rmi -f [IMAGE ID] [IMAGE ID] [IMAGE ID] [IMAGE ID]
docker rmi -f $(docker images -aq)


```

##### 7）Docker File 镜像制作

```shell
# 1、在/home/muse下，构造dockerfiles文件夹和dockerfile01文件

# 2、编写DockerFile（命令大写）
FROM centos
VOLUME ["muse01","muse02"]
CMD echo "------finish------"
CMD /bin/bash

# 3、构造镜像
# -f: 指定生成的Dockerfile路径
# -t：指定生成镜像的标签
docker build -f /home/muse/dockerfiles/dockerfile01 -t muse/centos:1.0 .

# 4、启动自己构建的镜像
# => 通过docker images查询出IMAGE ID为eb78333356a6
docker run -it eb78333356a6 /bin/bash


```

#### 三、容器命令

对容器进行生命周期管理。

##### 1）运行镜像、生成容器、进入容器

可用 `ctrl+p+q` 跳出容器。

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ _data]# docker run -it centos


```

##### 2）交互方式运行容器

```shell
docker run -it centos


```

##### 3）后台方式运行容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker run -d --name nginx1 -p 1111:80 
nginx


```

##### 4）强制删除运行中的容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker rm -f c72b6628c15e


```

##### 5）关闭容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker stop e589400741f2
e589400741f2

# 或者杀死容器进程
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker kill e589400741f2
e589400741f2


```

##### 6）暂停容器

```shell
docker pause 398edf535ba8  
docker unpause 398edf535ba8  


```

##### 7）启动容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker start e589400741f2
e589400741f2


```

##### 8）重启容器

```shell
[root@iZ2ze5ffbqqbeaygcx7o4xZ test]# docker restart e589400741f2
e589400741f2


```

#### 四、数据卷命令

1. 由于 Docker 把应用和环境进行了打包，如果删掉容器的话，数据也会被同时删掉。
2. 如果需要**持久化**容器数据，或者容器之间进行**数据共享**的话，那么就可以使用**容器数据卷**。

![1647500082189](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500082189.png)

##### 1）查看挂载列表

```shell
docker volume ls


```

![1647500564024](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500564024.png)

##### 2）查看挂载元数据

```shell
docker volume inspect [VOLUME]


```

![1647500831275](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647500831275.png)

##### 3）匿名挂载并执行容器

- **-d**：表示后台执行容器。
- **-P**：表示随机映射容器端口。
- **--name**：表示容器名称。
- **-v** ：指定 `：容器内部路径`。

```shell
docker run -d -P --name nginx1 -v :/etc/nginx nginx


```

![1647501166696](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647501166696.png)

##### 4）具名挂载并执行容器 | 常用

- **-v** ：指定 `主机路径：容器内部路径`。

```shell
docker run -d -P --name nginx2 -v nginx2:/etc/nginx nginx


```

##### 5）数据卷容器

1. 数据卷容器，顾名思义，就是挂载另一个容器中已经创建好的数据卷。
2. 如果有一些持续更新的数据，需要在容器之间共享，最好创建数据卷容器。
3. 所以，其实数据卷容器就是一个正常的容器，专门用来提供数据卷，让其它容器挂载。

```shell
# 创建一个数据卷，—volumes-from参数，并不需要所挂载数据卷的容器保持运行状态
$ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres
734273f9ec0b0cf743a79a9da7b27b269ff9c34a02ec17d3df158cf0e3cedcd2
$ sudo docker ps -a
CONTAINER ID        IMAGE              COMMAND                CREATED             STATUS                     PORTS         NAMES
734273f9ec0b        training/postgres  "/docker-entrypoint.   17 seconds ago      Exited (0) 15 seconds ago                dbdata

# 创建容器，挂载该数据卷
# 如果删除了挂载的容器（包括 dbdata、db1 和 db2），数据卷并不会被自动删除。
# 如果要删除一个数据卷，必须删除最后一个还挂载着它的容器，可以使用docker rm -v命令来指定同时删除关联的容器
$ sudo docker run -d --volumes-from dbdata --name db1 training/postgres
$ sudo docker run -d --volumes-from dbdata --name db2 training/postgres
$ sudo docker ps
CONTAINER ID       IMAGE                COMMAND                CREATED             STATUS              PORTS               NAMES
7348cb189292       training/postgres    "/docker-entrypoint.   11 seconds ago      Up 10 seconds       5432/tcp            db2
a262c79688e8       training/postgres    "/docker-entrypoint.   33 seconds ago      Up 32 seconds       5432/tcp            db1


```

### 1.9. Iaas、Paas、Saas 云计算模式？

![1647511175588](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511175588.png)

**举例**：如何找披萨吃~

1. **传统数据中心**：Traditional data-center，本地服务，机房、网络、磁盘、服务器、虚机、操作系统、中间件、软件什么的，都需要自己亲力亲为去搭建，耗时耗力，成本高。
   - 好比从头做一个披萨，需要准备各种材料、亲自烧烤、还要买汽水摆盘各种操作，才可开餐。
2. **Iaas**：Infrastructure as a Service，基础设施即服务，通过购买云产品的基础设施，本地不用再考虑机房、网络、磁盘、服务器、虚机的问题，只需要保证操作系统、中间件的高可用，以及编写业务软件即可。
   - 好比买好冷冻的披萨，此时不需要再准备各种材料，而是从烧烤开始，最后买汽水摆盘即可开餐。
3. **Pass**：Platform as a Service，平台即服务，通过购买云产品的基础设施、平台设置，本地不用再考虑机房、网络、磁盘、服务器、虚机、操作系统、中间件的高可用问题，只需要编写业务软件即可。
   - 好比点披萨外卖，材料准备、烧烤的都不用了，直接买好汽水、摆好餐桌等外卖送到开吃就好。
4. **Saas**：Sofeware as a Service，软件即服务，通过购买一整套云产品，配置好对应的业务模板，即可搞定业务软件。
   - 好比出去餐厅吃披萨，材料、烧烤、买汽水、摆盘都由服务员解决，上菜直接开吃就好。

![1647511082155](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511082155.png)

### 2.0. Docker vs Cloud Foundry？

![1647511905639](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647511905639.png)

Infrastructure、VM 可以认为是做披萨时的准备材料，App Server、Runtime、Container 可以认为是烧烤过程，Application 可以认为是摆盘和买汽水过程。

1. Docker 完成的是摆盘和烧烤过程，即把应用和容器绑定在一起，关注的是应用和环境的打包过程。
2. Cloud Foundry 完成的是烧烤过程，即把应用上传好，由应用找到自适应的虚机进行发布，关注的是选择合适的应用支持。

=> 所以，个人认为使用 Docker 要关注结合过程，供应商只需要提供产品即可，而 Cloud Foundry 要关注选择过程，由供应商来提供产品的结果过程。 

### 2.1. 什么是 Cloud  Foundry？

![1647509134003](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647509134003.png)

容器化技术除了 Docker 外，著名的还有 Pivotal Cloud Foundry，**Spring** 自家产品，是业界第一个开源 **PaaS** 云平台，支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内，进行应用程序的部署和扩展，无需担心任何基础架构的问题。

其**特点**有：

1. **快速发布**：整个 Cloud Foundry 最核心的 一条命令就是 `CF Push`，可谓一招吃遍天。
2. **多语言支持**：几乎支持所有常见语言，包含 Java、Node.js、Go、Python、PHP、Ruby、.NET 等。
3. **网络和路由绑定**：Cloud Foundry 可以通过路由层（Routing）和应用执行层（Application Execution）的配合，可以很方便地实现内部、外部路由的解析和数据通信，解决 Docker 环境跨容器、跨服务器通信复杂的问题。
4. **用户和认证**：容器编码平台 K8S 并没有对这块给予很好的管理和集成，但这正式 Cloud Foundry 的优势所在。
5. **日志和监控**：Cloud Foundry 可以通过在平台里添加砖块（Tile）的方式，很自然地对接主流的监控平台。
6. **第三方支持**：有近 200+  主流产品提供第三方支持，用户可以从本地市场中，选择需要的服务，集成到各自的应用中。

### 2.2. Cloud Foundry 架构原理？

![1647513836355](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647513836355.png)

1. **底层**：可以基于 VMware、OpenStack 等私有环境的虚拟化技术，Amazon、Google、Windown Aware 等公有环境的虚拟化技术。
2. **BOSH**：解耦上层和底层，可对上层虚机自动恢复、备份。
3. **Cell**：虚拟机，Cloud Foundry 核心。
4. **Container**：容器。
5. **Service Brokers**：各容器通过 Service Broker 统一的 url 进行提供。
6. **Router**：url 服务的负载均衡通过 Router 来保证。
7. **Cloud Controller**：提供 CF API 的命令接口。

### 2.3. 如何选型容器化技术？

SWOT 分析法： Strengths 优势、Weaknesses 劣势、Opportunities 机会、Threats 威胁。

![1647514670543](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647514670543.png)

|          | Docker                                     | Cloud Foundry                                    |
| -------- | ------------------------------------------ | ------------------------------------------------ |
| **优势** | 生态圈第一者、环境准备非常方便、镜像胚胎多 | Spring 生态、多语言支持、网络通信方便            |
| **劣势** | 网络方案多且复杂                           | 前期准备麻烦、第三方服务定制复杂、不支持中文文档 |

### 2.4. 什么是容器编排？

容器编排，可以自动化部署、管理、扩展容器以及网络通信处理，为微服务应用提供了理想的应用程序部署单元，和独立的执行环境，使得微服务部署更加简单，同时还支持集成到 CI/CD 工作流，以提效 DevOps 团队工作，适合那些需要部署和管理成百上千个容器和主机的企业，是**云原生**应用程序的基础。

### 2.3. 什么是 K8S？

1. **Kubernetes**，又称作 K8S（中间的 8 个字母省略），是 Google 在 2014 年发布的一个开源项目。
2. 最初 Google 开发了一个叫 Borg 的系统（现在命名为 Omega），来调度近 20 多亿个容器，在积累了数十年的经验后，Google 决定重写这个容器管理系统，并贡献给开源社区，这个系统就是 Kubernetes，它也是 Omega 的开源版本。
3. 从 2014 年第一个版本发布以来，迅速得到了开源社区的追捧，目前，K8S 已经成为了发展最快、市场占有率最高的**容器编排**引擎产品。

其**特点**是：

1. **虚拟数据中心管理**：可以对数据中心资源和容器进行统一管理，同时支持开发、测试、生产各种环境。
2. **软件发布和回退**：部署软件可以像 `yum install` 一样方便，并且可以很方便地指定版本进行回退。
3. **网略和存储透明管理**：适合 DevOps 文化，无需开发人员专门学习存储和网络知识，其服务发现抽象了网络访问，PV / PC 两级管理技术抽象了存储配置，开发人员只需提交明确的配置，K8S 就可以自动完成资源的分配。
4. **弹性扩容**：可以根据策略，自动地增加资源或者释放资源，方便容器弹性扩缩容。
5. **高可用**：K8S 集群本身就是高可用的，且在其上发布的容器，可以通过负载均衡和 Service 功能，实现容器的高可用。

### 2.4. K8S 架构原理？

![1647516641430](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647516641430.png)

**集群节点**：

1. **Kubernetes Cluster**：K8S 集群，是计算、存储和网络资源的集合，是掌握所有计算、存储、网络资源，进行统计管理、调度的节点群。

2. **Kubernets Maseter**：K8S 大脑节点，决定将应用放在哪里运行，它相比图中，该节点还隐藏了许多容器，比如：

   - **1）API Server**：API 服务端，通过控制台、网络，接收传过来的命令，判断是否符合语法标准，并根据实际环境进行处理。

   - **2）Scheduler**：调度执行器，对所有资源按照应用资源，执行统一调度，以及任务发布，负责决定将 Pod 放到哪⼀个 Node 上运⾏。

   - **3）Controller Manager**：核心节点，控制器管理器，负责 Cluster 各种资源的统筹管理。

     1. **replication controller**：负责跨节点部署、通信，实现标签管理、资源选择。
     2. **namespace controller**：管理虚拟化集群的资源隔离，跨节点应用高可用复制与管理。

     ![1647520902702](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647520902702.png)

   - **4）ETCD**：类似于 ZK，对 K8S 集群配置统一管理，保存 K8S 的相关配置和状态信息，如果 POD 有发⽣变化，那么它会迅速通知相关的组件进⾏处理。

   - **5）NetWork**：集群网络解决方案，包括 Flannel 法兰绒、Calico 印花布、Weave、Canal 组合方式等。

   - **6）Node's Components**：支持大脑节点当手脚节点用。

3. **Kubernets Node**：K8S 手脚节点，负责运行容器应用。

   - **1）Kubelet**：核心工作单元，是 K8S 里唯一一个没有以容器形式运行的组件，负责根据 Scheduler 发过来的信息（`--image` 、`volume` 等），去创建和运⾏容器，并向 Master 报告运⾏状态，是直接跟 **Docker** 进行沟通的容器生命管理模块。 

   - **2）Kube-proxy**：网络通讯、服务发现负载模块，是网络代理的概念，当 service 接收到请求后，转发到某个 node 时，会由该 node 的 kube-proxy 模块负责接收，然后转发到后端的容器中，如果有多个副本，还会提供负载均衡的能⼒。

   - **3）Docker daemon**：Docker 后台容器。

   - **4）Pod**：

     1. **K8S 的最小工作单元**（所以，K8S 最小工作单元不是容器！），是运行在 Node 手脚节点上的一堆容器集合，即**比容器更大的"集装箱"**，可以对网络共享、存储共享的**一堆容器**作为一个小单元进行管理，从而扩大管理粒度，降低管理复杂度。
     2. 比如，消息发送容器、消息接收容器、消息队列容器，可以封装成一个 Pod，实现统一部署，共享网络和存储。
     3. Pod 一旦发布，就只能在这个 Node上，与兄弟 Node 节点的 Pod 不同，即使承载的内容可能一样。

     ![1647567752066](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647567752066.png)

   - **5）Controller**：负责对 Pod 进行统一管理。

     1. **Deployment**：一个应用资源，基于 ReplicaSet，会产生一个部署请求，形成一堆 Pod。
     2. **ReplicaSet**：一个会在多个点节点部署多个的 Pod，以完成更多的功能。
     3. **DaemonSet**：一个在同一节点只会运行一份的 Pod。
     4. **StatefulSet**：一个有状态的服务，对外提供的 Pod 名称永远不变。
     5. **Job**：一个短时、定时作业的 Pod。

   - **6）Service**：

     1. **为 Pod 提供了负载均衡**：在当 Pod 之间需要相互访问时，会去 DNS Server 找到对应的 IP 地址，通过 Kube-proxy 服务发现功能，进行网络数据包转发，实现网络服务功能，以用于描述 Pod 和 Pod 之间的应用访问。
     2. **为客户端提供固定的 IP + 端口**：当 Pod 的 IP 发生变化时，Service 可以保证，客户端面对的 Pod 还是固定 IP 和端口。

     ![1647520164299](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647520164299.png)

**其他概念**：

1. **Label**：对某些特殊的 Pod 打个标签，以区分不同的 Pod 或机器资源，方便进行查询、网络发现和服务发现。
2. **Namespace**：虚拟 K8S 集群，解决在同一个 Cluster 集群中，如何区分开 Controller 和 Pod 的问题，默认两个虚拟集群，`kube-system` 用于自身管理的集群，`kube-default` 用于应用部署的默认集群（不指定集群名称时）。

=> 综上，从下到上，组件结构为：**Docker 容器** ->(往上)-> **Pod** ->(往上)-> **Namespace** ->(往上)-> **Kubernetes Cluster**。

当需要执行部署应用，并指定两个副本时，**执行流程**如下所示：

1. kuberctl 发送部署请求到 API Server。
2. API Server 通知 Controller Manager 创建一个 deployment 资源。
3. Scheduler 执行调度任务，将两个副本 Pod 分发到 node1 和 node2 上。
4. node1 和 node2 上的 kubectl 在各自的节点上，创建并运行 Pod。

### 2.5. 如何使用 K8S？

#### 一、集群命令

##### 1）查看 k8s 集群版本

```shell
kubectl version


```

##### 2）查看 k8s API 版本

```shell
kubectl api-versions


```

##### 3）查看 k8s 集群健康状态

```shell
kubectl get cs


```

##### 4）查看 k8s 集群核心组件运行情况

```shell
kubectl cluster-info

```

##### 5）查看 k8s 集群所有 namespace

```shell
kubectl get namespaces

```

##### 4）查看 k8s 集群所有 Node 节点

```shell
kubectl get nodes

```

##### 6）删除 k8s Node 节点

```shell
kubectl delete node k8s2

```

#### 二、Pod

**生命周期**：

![1647567485849](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647567485849.png)

##### 1）查看所有 namespace#pods 运行情况

```shell
kubectl get pods --all-namespaces

```

##### 2）查看具体一个 namespace#pods

```shell
kubectl get pods kubernetes-dashboard-76479d66bb-nj8wr --namespace=kube-system


```

##### 3）查看 namespace#pods 的结构信息

```shell
# 重点，通过这个看日志分析错误（对控制器和服务，node等同样有效）
kubectl describe pods xxxxpodsname --namespace=xxxnamespace


```

##### 4）查看 pod 日志

```shell
kubectl logs $POD_NAME


```

=> 其他 Controller 控制器也类似，就是 kubectl get 控制器 控制器具体名称。

#### 三、Deployment

对于 Deployment，Controller 会通过动态创建和销毁 Pod，来保证其整体的健壮性。

因此，**Pod 是脆弱的，但 Deployment 是健壮的**。

##### 1）查看所有 deployment

```java
kubectl get deployment --all-namespaces


```

##### 2）查看具体一个 deployment

```shell
kubectl get deployment nginx-app


```

##### 3）查看未初始化的 namespace#pod

```shell
kubectl get pods --include-uninitialized


```

##### 4）直接创建

在 v1.18.0 以后，`–replicas` 已弃用 ,推荐用 `kubectl apply` 来创建 pods。

```shell
kubectl run nginx-deployment--image=nginx:1.7.9--replicas=2


```

##### 5）配置文件创建

通过配置文件和 `kubectl apply` 创建。

**步骤**：

1. 编写配置文件 nginx.yml。
2. 执行命令 `kubectl apply -f /home/muse/nginx.yml`。

**构建原理**：

![1647566268366](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647566268366.png)

通过 kubectl——>创建 Deployment ——>创建 ReplicaSet ——>创建 Pod，名称为堆叠的方式。

```shell
# API 版本号
apiVersion: apps/v1
# 类型，如：Pod/ReplicationController/Deployment/Service/Ingress
kind: Deployment
# metadata定义Pod的元数据
metadata:
  # Kind 的名称
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      # 容器标签的名字，发布 Service 时，selector 需要和这⾥对应
      app: nginx
  # 部署的实例数量，默认为1
  replicas: 2
  template:
    metadata:
      labels:
        app: nginx
    # 描述Pod的规格，定义Pod中每一个容器的属性，name和image是必需的
    spec:
      # 配置容器，数组类型，说明可以配置多个容器
      containers:
      # 容器名称
      - name: nginx
        # 容器镜像
        image: nginx:1.17
        # 只有镜像不存在时，才会进⾏镜像拉取
        imagePullPolicy: IfNotPresent
        ports:
        # Pod 端⼝
        - containerPort: 80


```

##### 6）自动失败转移

1. 一开始设置了 pod 数为 3 个，Master 在 Node1 分配了 2 个 Pod，在 Node2 分配了 1 个 Pod。
2. 当 Node1 异常时，Master 会在 Node2 上面，生成新的 2 个 Pod，保证有 3 个 Pod 正常运行。
3. 当 Node1 恢复正常后，新创建的 Pod 将依然会在 Node2 上，并不会做迁移动作。

![1647566333333](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647566333333.png)

##### 7）指定 Node 部署

1. 默认配置下，Scheduler 会将 Pod 调度到所有可用的 Node 上。
2. 不过有些情况，可以通过 `lable` ，将 Pod 部署到指定的 Node 上，比如将有大量磁盘 I/O 的 Pod，部署到配置了 SSD 的 Node 上，或者 Pod 需要 GPU 时，则指定部署在配置了 GPU 的节点上。

```shell
# 先给k8s-node1节点，添加标签——disktype=ssd
kubectl label node k8s-node1disktype=ssd

# 修改nginx.yml配置文件，指定nodeSelector为上一步新建的label
nodeSelector:
  disktype: ssd
  
# 重新部署Deployment
kubectl apply -f nginx.yml

# 查看节点的标签信息
kubectl get node --show-labels


```

##### 8）删除 Deployment

```shell
# 删除pod，如果只是删除其中一个Pod，则依然会被deployment自动失败转移，再补充为n个pod
kubectl delete pod nginx-deployment-7f4fc68488-5v4m7

# 删除deployment，如果整个deployment删除时，则其配置的Pod也会随之自动被删除
kubectl delete deployment nginx-deployment


```

##### 9）动态伸缩 pod

```shell
# 将foo副本集变成3个
kubectl scale --replicas=3 rs/foo
# 将deployment/mysql从2个变成3个
kubectl scale --current-replicas=2 --replicas=3 deployment/mysql
# 变更多个控制器的数量
kubectl scale --replicas=5 rc/foo rc/bar rc/baz
# 查看变更进度
kubectl rollout status deploy deployment/mysql


```

##### 10）自动滚动发布

![1647571435643](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647571435643.png)

1. k8s 滚动更新，是指一次只更新一小部分副本，成功后再更新更多的副本，最终完成所有副本的更新。
2. 滚动更新的最大好处是**零停机**，整个更新过程始终有副本在运行，从而保证了业务的连续性。

#### 四、DaemonSet

**区别**：

1. Deployment 部署的 Pod 会分布在各个 Node 上，每个 Node 都可能会运行好几个副本。
2. 而 DaemonSet 不同的地方在于，它会保证每个 Node 上，**最多只能运行 1 个副本**。

**典型应用场景**：用于存储、日志收集、监控的后台进程，比如 Prometheus Node Exporter。

##### 1）查看 k8s 自身的 DaemonSet 系统运行组件

```shell
kubectl get daemonset --namespace=kube-system


```

![1647568750538](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647568750538.png)

#### 五、Job

![1647568862407](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647568862407.png)

1. 容器按照持续时间划分，可以分为服务类容器和工作类容器。
2. 服务类容器，通常持续提供服务，需要一直运行，比如 Http Server、Daemon 等，ReplicaSet 和 DaemonSet 都是用于管理服务类容器。
3. 工作类容器，是一次性任务，比如批处理程序，完成之后容器就会退出，Job 用于管理工作类容器。

##### 1）普通任务配置

```shell
[root@training3 ~]# cat hello.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    metadata:
      name: hello
    spec:
      containers:
      - name: hello
        image: busybox
        command: ["echo", "hello from feiyang"]
      restartPolicy: Never


```

##### 2）定时任务配置

```shell
[root@training3 ~]# cat myjob.yaml
apiVersion: batch/v2alpha1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: ["echo", "hello feiyang"]
          restartPolicy: Never


```

### 2.6. 什么是 Mesos？

![1647581552572](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647581552572.png)

Apache Mesos，是一个集群管理器，可跨分布式应用程序，提供有效的资源隔离和共享，相当于一个分布式操作系统内核，让用户像使用一台电脑一样**使用整个数据中心**，通过 API 为各种应用，提供跨数据中心和云资源调度的能力。

其**特点**有：

1. **轻量级的 Master**：仅保留各 Framework 和 Slave 的一些状态，易于重构，同时采用 ZK 解决 HA 问题。
2. **配合 Container 技术的 Slave**：利用 LXC 和 Docker 技术，可以实现任务间的 CPU 和内存资源隔离。
3. **资源分配调度简单**：默认的 DRF 优势资源公平算法（Dominant Resource Fairness，决定资源分配情况，最大化数据中心利益），可以轻松实现资源最大化利用，无需人工干预和配置。 

### 2.7. 什么是 Marathon？

![1647572643772](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572643772.png)

1. Marathon，马拉松，是 Mesos 应用调度框架中，最知名的一款软件，能够支持运行**长服务**，比如 WEB 应用等，将应用程序部署为长时间运行的 Mesos 服务，并调用 Mesos 管理的资源实现应用的业务需求。
2. 如果把 Mesos 类比为操作系统内核，负责资源调度，那么 Marathon 可以类比为服务管理模块，比如 `init`、`systemd` 或者 `upstart` 等，用来管理应用的 状态信息。

其**特点**有：

1. **高可用性**：Marathon 作为主动 / 被动集群运行，领导者选举可以实现 100% 高可用。
2. **资源分布可控**：可以允许每个节点仅放置一个应用程序实例，从而缓解单点故障的影响。
3. **服务发现和负载均衡**：可以通过 HA 和 DNS 等方式，实现自动负载均衡。
4. **健康检查**：可以使用 HTTP 或者 TCP，来检查、评估应用程序的运行状况。
5. **活动订阅**：提供 HTTP 端点，以接收通知，比如与外部的负载均衡集成。
6. **UI**：美丽而强调的 UI。
7. **API**：完美的 Rest API，易于集成和编写脚本。
8. **安全**：提供基础认证和 SSL 功能。
9. **监控**：以 json 格式，在 `/metrics` 查询它们，或者将它们推送到  `graphite`、`statsd`、`Datadog` 之类的系统。

### 2.8. Mesos 架构原理？

![1647572679607](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572679607.png)

Mesos 实现整个数据中心统一管理，其核心概念为**资源两级供给**和**作业两级调度**。

**从下而上的资源两级供给**：

1. **Mesos Slave -> Mesos Master**：在 Mesos 集群中，资源的供应方，都来自于 Mesos Slave 所在的物理节点，资源包括 CPU、内存、存储空间、I/O 吞吐能力等。这些资源通过供给的方式，从 Mesos Slave 提供给了 Mesos Master 的 Leader，为第一级的资源供给。
2. **Mesos Master -> Framework Scheduler**：Mesos Master 进一步将资源整合后，作为可选项，提供给各种  framework 框架，比如主流的 Marathon 长服务框架、Jenkins CI / CD 框架、Spark 大数据框架、Kafka 中间件框架、Chronos 任务管理框架、Aurora 应用管理框架等，各种框架可以有选择地对 Mesos Master 整合后的数据中心资源提出要求。

**从上而下的作业两级调度**：

1. **用户 -> Scheduler**：
   - 1）各个框架都有自己的调度  Scheduler，它会根据用户需求，启动特定的工作任务。
   - 2）调度器在上层第一级确定工作任务需要的资源情况，是否需要接收 Mesos 提供的 CPU、内存和存储资源，来运行特定的工作负载。
2. **Mesos Slave -> Executeor**：
   - 1）Mesos 对于上层框架的需求也不是予取予求，而是会采用默认的 DRF 优势资源公平算法，来决定各种框架任务的资源分配情况，从而使整个数据中心利益最大化。
   - 2）比如上层框架中的 Marathon 调度器需要启动 Nginx 任务，而同时 Spark 框架需要启动 Streaming 任务，那么 Mesos 的 DRF 算法，会根据框架提出的要求，将尽量多的内存和 CPU 分配给 Nginx 用于进行反向代理服务，同时将尽可能多的 I/O 吞吐性能提供给 Spark 进行流处理。

### 2.9. Mesos Marathon 整体架构？

![1647572413475](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647572413475.png)

1. **CLI UI**：用户操作界面。
2. **Zookeeper**：多数派选举 Mesos Master Leader。
3. **Marathon Scheduler**：Marathon 调度器，对接 Mesos Master，提供容器编排和应用调度、与 Mesos Slave 端的 Docker Executor 紧密呼应。
4. **Mesos Master**：Leade + Flower 主备模式、沟通 Mesos Slave 整理资源、沟通 Framework 框架提供资源。
5. **Mesos Slave**：沟通 Mesos  Master 获取资源、为各种框架提供执行器环境、执行任务和容器管理。
6. **Docker  Executor**：Marathon 提供的 Docker 执行器。
7. **Docker Container**：运行中的 Docker 容器。

=> 如果想运行长任务，想结合管理数据中心多种形式的任务，同时应用之间也不需要太大的集群耦合性的话，Mesos + Marathon 这一堆数据中心操作系统解决方案，比较适合。

### 3.0. 如何选型容器编排技术？

SWOT 分析法： Strengths 优势、Weaknesses 劣势、Opportunities 机会、Threats 威胁。

![1647582756320](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647582756320.png)

|          | Kubernetes                                                   | Mesos + Marathon                                             |
| :------- | :----------------------------------------------------------- | ------------------------------------------------------------ |
| **优势** | 天然支持公有云（比如阿里云）、提供抽象的存储、支持容器弹性扩缩容、文档多，技术普及率高 | Mesos 资源统一管理，适合于数据中心、支持多个框架并存         |
| **劣势** | 离不开容器，只能进行容器管理，不能进行资源的统筹控制管理、Master 高可用节点安装相对复杂、不适合大数据虚拟机部署场景 | 不能做很复杂的存储抽象、功能需要多个框架拼装，导致可能没有对应的实现、公有云没有对应的实现 |

### 3.1. 什么是 Serverless？

- **问题背景**：

  1. **存在服务器资源成本浪费**：中长尾（大部分时间没有流量）应用，会固定的消耗服务器资源，但实际上，这些应用的调用率并不高，又不能直接做下线处理，因为有些应用是被强依赖的。
  2. **存在人力资源成本浪费**：后端要开发的非业务代码过多、前后端联调周期长。

- **解决方案**：推进 Serverless 方案，在 K8S 基础上，对开发、运维体系进一步抽象，给开发、运维提供一个极简模型。

- **概念**：

  一般来说，Serverless 的概念就如同它的字面含义：

  - **server**：需要关注服务器资源、部署情况，操作系统，软件依赖等细节。
  - **less**：更换少的。

  => 故，Serverless = `server` + `less` = 更少地关注服务端的运维工作 = 运维自动化。 

无论 Serverless 技术栈如何演进，但它始终都在沿着一个不变的目标前行着（NoOps ，No Operations，无运维，或者说简化服务端运维模型 ) 。

### 3.2. Serverless 架构原理？

![1647584496435](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647584496435.png)

#### 1）Serverless 整体架构

具体到开发人员，**狭义的 Serverless 定义**为:

应用程序 Serverless = Trigger 事件驱动 + FaaS 函数即服务 + BaaS 后端即服务。

其中，

- **Trigger**：事件驱动，可以指一次 HTTP/RPC 请求，或者一条订阅的 MQ 消息等。
- **FaaS**：Function As A Service，函数即服务：
  1. FaaS 函数可以理解为是一个容器镜像，镜像的内容可以是一个具备输入输出功能的单个函数代码，由外部的触发器 Trigger 触发后，会先被实例化成一个容器实例，然后执行其中的函数，最终返回结果给外部。
  2. 当 FaaS 函数在 FaaS 函数调用完成后，容器实例会被销毁，并回收资源。
  3. 因此，FaaS 实例实质上是一个**独立的容器实例**。
  4. FaaS 的主要作用是，随时随地的创建、使用、销毁一个函数，在并发量高时，可以进行横向扩容，而在没有流量时，又可以缩容到 0，提高服务器资源利用率。
- **BaaS**：Backend As A Service，后端即服务：
  1. 由于 Faas 函数无状态、实例会不停地扩缩容，所以，对于那些需要**持久化数据**的需求，采用 FaaS 来实现不合适时，可以使用 BaaS 后端即服务组件来解决。
  2. BaaS，一般是指具备**高可用性、弹性伸缩、免运维**的后端服务，专门用于支撑 FaaS，内部可以通过连接池、Local Cache 等方式去优化。
  3. BaaS 的主要作用是，保存状态即存储数据，需要保障稳定性，不能轻易被改动，当面对流量峰值、峰谷的流量差比较大时，能够按峰值去扩容节点，以抗住高流量，但在没有流量时，也要维持固定的开销。

#### 2）Faas 架构原理

![1647585253702](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647585253702.png)

在 FaaS 运行时中，存在 3 个**服务组件**：

- **函数触发器服务**：所有请求的统一入口，当外部事件发生时，会触发事件，通知函数服务，并且等待函数服务 执行返回后，将结果返回给等待的请求。
- **函数服务**：当触发器通知的事件到来时，会先查看一下，当前有没有闲置的函数实例，如果有，则调用函数实例进行处理；如果没有，则会创建函数实例，等函数实例创建完毕后，再调用函数实例处理事件。
- **函数实例**：运行时的函数代码（编写的业务函数），为一个 Docker 实例，在第一次实例化函数时，会从代码仓库中拉取代码，并构建函数实例。

一次 **FaaS 函数调用过程**为：

1. 当客户端第一次通过 HTTP 请求访问函数触发器时， 函数触发器就会 Hold 住客户端的 HTTP 请求，对 HTTP Request 对象进行封装，产生一个事件来通知函数服务。
2. 紧接着，函数服务就会检查有没有闲置的函数实例，如果没有闲着的函数实例，就去函数代码仓库中拉取相应的代码，来初始化并启动一个函数实例，传入事件对象作为函数的输入参数，并执行函数。
3. 函数执行完成后，函数的返回结果会返回给函数触发器，函数触发器再将结果包装成 HTTP Response，返回给等待的客户端。

#### 3）Baas 架构原理

![1647585651029](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1647585651029.png)

BaaS 服务的一种实现方案是，使用 K8ssandra 作为底层的组件。

K8ssandra，是 Apache Cassandra 在 Kubernetes 上的一个发行版，致力于简化 Cassandra 集群在 Kubernetes 上的部署工作，由多个开源组件构建而成，支持监控、备份、同步和数据接口等。

BaaS **底层各组件**分别为：

1. **Stargate**：一款开源的开发接口平台，用于暴露 Cassandra 对数据 CRUD 接口的封装。
2. **Prometheus + Grafana**：Cassandra 监控和看板平台，提供 Cassandra 检测、报表查看功能。
3. **App Backend + App Frontend**：应用通过客户端，直接操作 Cassandra，存储数据。
4. **Reaper**：数据修复工具，保证数据的一致性。
5. **Cass-operator**：保证 Cassandra 集群正常运行。
6. **Medusa**：数据备份工具，支持 S3、GCP Cloud Storage 等。

# 十四、算法篇

### 1.1. Coding 问题？

#### 链表

##### 1）合并有序链表

###### 迭代法 | O（m + n）

- **思路**：
  1. 新建一个节点作为新返回链表的头结点，它在 L1、L2 比较完之后，把较小者加入 next 指针，然后往下移动，继续比较 L1、L2，直到 L1 或者 L2 任意一个遍历完。
  2. 如果 L1 先遍历完，则把 L2 剩余的节点加入这个 next 指针。
  3. 否则，如果 L2 先遍历完，则把 L1 剩余的节点加入这个 next 指针。
- **结论**：合并链表首先要想到的思路，实现简单，面试可用（0ms，100%）。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode mergeTwoLists(ListNode list1, ListNode list2) {
        if(list1 == null) {
            return list2;
        }
        if(list2 == null) {
            return list1;
        }

        ListNode head = new ListNode();
        ListNode pre = head;
        
        while(list1 != null && list2 != null) {
            if(list1.val <= list2.val) {
                pre.next = list1;
                list1 = list1.next;
                pre = pre.next;
            } else {
                pre.next = list2;
                list2 = list2.next;
                pre = pre.next;
            }
        }
        pre.next = list1 == null? list2 : list1;

        return head.next;
    }
}
```

###### 递归法 | O（m + n）

- **思路**：思路很清晰，实现简单，不关心细节，站在宏观角度来看待合并这件事。
  1. 如果当前节点 L1 比 L2 小，可以看作保留 L1 当前节点，递归调用子过程保证 L1.next 和 L2 剩余节点合并，合并完毕后返回 L1 即为最终答案。
  2. 如果当前节点 L2 比 L1 小，可以看作保留 L2 当前节点，递归调用子过程保证 L2.next 和 L1 剩余节点合并，合并完毕后返回 L2 即为最终答案。
- **缺点**：时间复杂度虽然和迭代法的一样（0ms，100%），但额外空间复杂度上，迭代法只需要额外几个变量O（1），而递归法却是每递归一次就需要一次额外空间，最终为 O（m + n）的额外空间复杂度。
- **结论**：合并链表还是比较适合用**迭代法**来实现。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode mergeTwoLists(ListNode list1, ListNode list2) {
        if(list1 == null) {
            return list2;
        }
        if(list2 == null) {
            return list1;
        }
        if(list1.val <= list2.val) {
            list1.next = mergeTwoLists(list1.next, list2);
            return list1;
        } else {
            list2.next = mergeTwoLists(list1, list2.next);
            return list2;
        }
    }
}
```

##### 2）合并 K 个升序链表

###### 小根堆法 | O（n * logn）

- 思路：
  1. 参考两个有序链表合并的迭代法，即使用一个前置节点，不断地在链表比较之后，把小者加入 next 指针，周而复始。
  2. 不过不同的是，由于这里是 K 个有序链表，比较采用的是小根堆的做法，通过一个优先级队列来实现，从队列取出结果就相当于完成一次 K 个有序链表头节点的比较，直到队列元素被取完，合并结束。
- **结论**：时间上还行（4ms，69.27%），实现也简单，面试可用！

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode mergeKLists(ListNode[] lists) {
        if(lists == null || lists.length == 0) {
            return null;
        }
        if(lists.length == 1) {
            return lists[0];
        }
        
        PriorityQueue<ListNode> queue = new PriorityQueue<>((o1, o2) -> o1.val - o2.val);
        for(ListNode listNode : lists) {
            if(listNode != null) {
                queue.add(listNode);
            }
        }

        ListNode head = new ListNode();

        ListNode pre = head;
        while(!queue.isEmpty()) {
            ListNode listNode = queue.poll();
            pre.next = listNode;
            listNode = listNode.next;
            if(listNode != null) {
                queue.add(listNode);
            }
            pre = pre.next;
        }

        return head.next;
    }
}
```

##### 3）环形链表

###### 快慢指针法 | O（n）

- **思路**：
  1. 判断链表中有没有环，核心思路就是会不会从末尾走回前面，这可以用前后指针来实现，即快指针每次走 2 步，慢指针每次走 1 步，如果链表中有环，那么快指针必然会走到慢指针后面，而由于快指针的步长大，时间久了也必然会从后面追上慢指针，也就是相遇时则返回 true，否则返回 false 即可。 
  2. 不过有个细节要注意的是，由于是判断指针地址是否相等，作为返回 true 的条件，所以为了避免一开始指针地址相等，需要先在 while 外面，先手动对快、慢指针提前走一下，来工整下代码。
- **结论**：时间，0ms，100%，空间，39.5mb，57.42%，效率非常高，就这样吧~

```java
/**
 * Definition for singly-linked list.
 * class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) {
 *         val = x;
 *         next = null;
 *     }
 * }
 */
public class Solution {
    public boolean hasCycle(ListNode head) {
        if(head == null) {
            return false;
        }
        if(head.next == null) {
            return false;
        }

        ListNode h1 = head.next, h2 = head.next.next;
        while(h1 != null && h2 != null) {
            if(h1 == h2) {
                return true;
            }
            if(h2.next == null) {
                return false;
            }

            h1 = h1.next;
            h2 = h2.next.next;
        }

        return false;
    }
}
```

##### 4）环形链表2

###### 快慢指针法 | O（n+a）

- **思路**：

  1. 设快慢指针在环中相遇的点为 b，此时快指针已在环中走过了 n 圈，如果 b 在环中继续往后走 c 才能回到入环点，此时入环点与原点距离为 a。
  2. 由于快指针的步长是慢指针的 2 倍，也就是在相同时间里，快指针所走的距离为慢指针的 2 倍，即 a + n * （b + c） + b = 2 * （a + b），可推导出 a = （n - 1）*（b + c）+ c，如果某个点在环上 b 的位置出发, 那么它走过的 n-1 圈的环再回到入环点的距离, 刚好等于后来一起从原点出发到入环点的距离。

  ![1643002320112](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1643002320112.png)

- **结论**：

  1. 时间，1ms，24.37%，空间，38.5mb，46.66%，由于在换上相遇了以后，还需要重新走 a 步，所以时间复杂度为 O（n+a），空间上只使用了有限几个变量，所以额外空间复杂度为 O（1）。
  2. 其中要注意的是，由于这里是快指针提前走了 2 个步长，慢指针也提前走了 1 个步长，所以推导出的公式中的 n 最小值不是 1 而是 0，此时公式应该为 a = c，即从原点走到入环点的距离等于从环中相遇点走到入环点的距离，也就是入环点到原点的距离等于入环点到相遇点的距离，也就是入环点就在原点上，所以 h2 在第一次相遇后移动回原点时，还需要**马上判断一次**是否已经第二次在原点相遇了，如果相遇则直接返回原点即可，否则就还要走 a 的距离才能到入环点。

```java
/**
 * Definition for singly-linked list.
 * class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) {
 *         val = x;
 *         next = null;
 *     }
 * }
 */
public class Solution {
    //  a + n(b+c) + b = 2(a+b)
    //  a + (n+1)b + nc = 2a + 2b
    // -a + (n-1)b + nc = 0
    //  a = (n-1)b + nc = (n-1)(b+c) + c
    // 即如果某个点在环上b的位置出发, 那么它走过的n-1圈的环再回到入环点的距离, 刚好等于后来一起从原点出发到入环点的距离
    public ListNode detectCycle(ListNode head) {
        if(head == null) {
            return null;
        }
        if(head.next == null) {
            return null;
        }

        boolean hasMeet = false;
        ListNode h1 = head.next, h2 = head.next.next;
        while(h1 != null && h2 != null) {
            // 未相遇时, h2 一次走两步
            if(!hasMeet && h2.next == null) {
                return null;
            }
            // 第一次相遇后, h2回到原点, 并更改步长与h1一起走
            if(!hasMeet && h1 == h2) {
                h2 = head;
                hasMeet = true;
            }
            // 再次相遇, 则相遇在入环掉
            if(hasMeet && h1 == h2) {
                return h1;
            }

            h1 = h1.next;
            h2 = !hasMeet? h2.next.next : h2.next;
        }

        return null;
    }
}
```

##### 5）LRU 缓存

见《设计题 - LRU 缓存》。

##### 6）排序链表

###### 暴力解法 | O（n * logn）

- **思路**：先把元素取出，然后进行排序，然后再重组链表即可。
- **结论**：时间，1295ms，5.77%，空间，48.8mb，5.02%，虽然都是 O（n * logn），但可能由于常数项太高，导致效率并不理想？而且空间复杂度也不是 O（1），还需要继续优化。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {

    public ListNode sortList(ListNode head) {
        if(head == null) {
            return null;
        }

        List<ListNode> list = new LinkedList<>();
        while(head != null) {
            list.add(head);
            head = head.next;
        }
        
        // 排序
        list.sort((o1, o2) -> o1.val - o2.val);

        // 重组
        ListNode cur = head = list.get(0), next;
        head.next = null;
        for(int i = 1; i < list.size(); i++) {
            next = list.get(i);
            next.next = null;
            
            cur.next = next;
            cur = cur.next;
        }

        return head;
    }
}
```

###### 归并排序（自顶向下递归） | O（n * logn）

- 思路：
  1. 利用归并排序的思路，对左半边的链表排好序，对右半边的链表排好序，然后调用《合并有序链表》中的思路，合并左右两边有序的链表，即可得到整个有序的链表，而对左、右半边的链表又可以以同样的方式递归进行排序。
  2. 其中，寻找链表中点的方法，可以利用快慢指针来实现，本题实现的慢指针等于 mid.next。
  3. 另外，还有要注意的是，由于是链表没有左右界限做分割，容易导致合并的时候造成把后面的链表也合并上来了，因此，**最关键的一步**是在对左半边链表进行排序时，需要对左半边的右界进行置空，以达到分割左右半边链表的目的。
- **结论**：时间，5ms，98.99%，空间，49.2 mb，5.02%，时间上根据 Master 公式可得到时间复杂度为 O（n * logn），而空间上，递归深度最大为 O（logn），所以额外空间复杂度为 O（logn），因此还需要优化掉递归。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {

    public ListNode sortList(ListNode head) {
        return sortList(head, null);
    }

    private ListNode sortList(ListNode head, ListNode tail) {
        if(head == null) {
            return head;
        }
        // mid.next = slow
        if(head.next == tail) {
            head.next = null;// 最关键的一步, 用于分割前后两个链表
            return head;
        }
        
        ListNode mid = findMidNode(head, tail);
        ListNode list1 = sortList(head, mid);
        ListNode list2 = sortList(mid, tail);
        return merge(list1, list2);
    }

    // 快慢指针法寻找链表中点: mid.next = slow
    private ListNode findMidNode(ListNode head, ListNode tail) {
        ListNode slow = head, fast = head;
        while(fast != tail) {
            slow = slow.next;
            fast = fast.next;
            if(fast != tail) {
                fast = fast.next;
            }
        }
        return slow;
    }

    // 合并两个有序链表
    private ListNode merge(ListNode list1, ListNode list2) {
        ListNode head = new ListNode(), pre = head;
        while(list1 != null && list2 != null) {
            if(list1.val < list2.val) {
                pre.next = list1;
                list1 = list1.next;
                pre = pre.next;
            } else {
                pre.next = list2;
                list2 = list2.next;
                pre = pre.next;
            }
        }
        pre.next = list1 != null? list1 : list2;
        return head.next;
    }
}
```

###### 归并排序（自底向上迭代）| O（n * logn）

- **思路**：
  1. 还是沿用归并排序的思路，不过这次是迭代从下往上，模拟归并排序的实现，即首先归并长度为 1 的有序子链表，再归并长度为 2 的有序子链表...，直到归并到长度为 2^n 超过链表长度的有序子链表，最终得到合并后的有序链表。
  2. 其中要注意的是，子链表的分割、子链表的合并，以及合并子链表的临时保存，如何用 O（1）的方式实现。
- **结论**：时间，9ms，37.98%，空间，48.9mb，5.02%，明明是在原链表上用迭代法实现，但空间和时间最终的效果并不理想，不管了，思路对就行了，其他就是编码问题了~

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {

    public ListNode sortList(ListNode head) {
        if(head == null) {
            return head;
        }

        int listSize = getLen(head);
        ListNode list1 = new ListNode(), list2 = new ListNode();
        ListNode preHead = new ListNode(0, head), end;
        for(int len = 1; len < listSize; len <<= 1) {
            // 获取最新的head, 以及备份头节点
            end = preHead.next = head;

            // 开始归并头节点链表
            head = preHead;
            while(end != null) {
                // 获取长度为len的一个有序左边
                end = subListNode(end, len, list1);

                // 获取长度为len的一个有序右边
                end = subListNode(end, len, list2);

                // 合并, 一个有序左 + 一个有序右 = 一个有序链表
                head.next = merge(list1.next, list2.next);

                // 继续合并剩下的子链表
                while(head.next != null) {
                    head = head.next;
                }
            }

            // 还原头节点
            head = preHead.next;
        }

        return head;
    }

    // 获取链表的长度
    private int getLen(ListNode head) {
        int cur = 0;
        while(head != null) {
            head = head.next;
            cur++;
        }
        return cur;
    }

    // 寻找len长度的子链表
    private ListNode subListNode(ListNode head, int len, ListNode preList) {
        int cur = 0;
        ListNode tail = head, pre = tail;
        while(tail != null && cur < len) {
            pre = tail;
            tail = tail.next;
            cur++;
        }
        
        // 如果子链表的尾节点已经到末尾了, 则无需分割子链表了
        if(tail == null) {
            preList.next = head;
            return tail;
        } 
        // 否则, 根据pre分割子链表
        else {
            pre.next = null;
            preList.next = head;
            return tail;
        }
    }

    // 合并两个有序链表
    private ListNode merge(ListNode list1, ListNode list2) {
        ListNode head = new ListNode(), pre = head;
        while(list1 != null && list2 != null) {
            if(list1.val < list2.val) {
                pre.next = list1;
                list1 = list1.next;
                pre = pre.next;
            } else {
                pre.next = list2;
                list2 = list2.next;
                pre = pre.next;
            }
        }
        pre.next = list1 != null? list1 : list2;
        return head.next;
    }
}
```

##### 7）相交链表

###### 暴力解法 | O（m+n）

- **思路**：由于求的是两个链表相交的节点，也就是相同地址的节点，因此可以先遍历其中一个链表，把路过的节点都加入哈希表中，接着再遍历第二个链表，如果第一次发现哈希表中存在这个节点，返回那个节点就是答案了。
- **结论**：时间，7ms，25.11%，空间，42.7mb，5.02%，时间上，由于使用了哈希表，所以即使都是 O（m+n），但其他方法可能常数项较低，所以就显得当前方法效率慢点，而空间上，由于使用了一个哈希表，所以额外空间复杂度为 O（m）或者 O（n）。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) {
 *         val = x;
 *         next = null;
 *     }
 * }
 */
public class Solution {
    public ListNode getIntersectionNode(ListNode headA, ListNode headB) {
        if(headA == null || headB == null) {
            return null;
        }

        Map<ListNode, ListNode> map = new HashMap<>();
        while(headA != null) {
            map.put(headA, headA);
            headA = headA.next;
        }

        while(headB != null) {
            if(map.containsKey(headB)) {
                return headB;
            } else {
                headB = headB.next;
            }
        }

        return null;
    }
}

```

###### 双指针法 | O（m+n+a）

- **思路**：先分别统计两个链表的长度，然后得知哪个是长链表，哪个是短链表后，再让长链表指针从头开始走长度差那么多步数，长者走完差值步后再与短链表指针一起走，走到第一个相同的节点则为第一个相交的节点（因此相交后面的节点地址必定相同）。
- **结论**：时间，1ms，99.96%，空间，41.5mb，22.12%，时间上，由于需要先遍历完两个链表，再走差值步以及到第一个相交的节点，所以时间复杂度为 O（m+n+a），a 代表相交前要走的步数。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) {
 *         val = x;
 *         next = null;
 *     }
 * }
 */
public class Solution {
    public ListNode getIntersectionNode(ListNode headA, ListNode headB) {
        if(headA == null || headB == null) {
            return null;
        }

        int n = 0;
        ListNode node1 = headA, node2 = headB;
        while(node1.next != null) {
            n++;
            node1 = node1.next;
        }
        while(node2.next != null) {
            n--;
            node2 = node2.next;
        }
        
        // n = headA - headB
        node1 = n > 0? headA : headB;
        node2 = node1 == headA? headB : headA;

        // 长者node1走差值步
        n = Math.abs(n);
        while(n > 0) {
            n--;
            node1 = node1.next;
        }

        // 长者走完差值步再同时起步
        while(node1 != node2) {
            node1 = node1.next;
            node2 = node2.next;
        }

        return node1;
    }
}

```

##### 8）反转链表

###### 递归法 | O（n）

- **思路**：由于递归过程中做不了链表节点的移动，所以只能在当前节点上进行链表节点的引用反转，同时还需要注意清空旧的引用，防止链环的发生。
- **结论**：时间，0ms，100%，空间，38.6mb，5.14%，时间上，由于链表只遍历了一次，所以时间复杂度为 O（n），空间上，递归的最大栈深度为链表长度，所以额外空间复杂度为 O（n），空间上还需要继续优化，尽量在链表本身完成翻转~

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode reverseList(ListNode head) {
        if(head == null) {
            return null;
        }
        
        return f(head);
    }

    private ListNode f(ListNode head) {
        // 如果到了末尾节点, 则返回当前节点, 作为上一个节点的头
        if(head.next == null) {
            return head;
        }

        // 如果还没到末尾节点, 则先获取翻转后的头节点
        ListNode newHead = f(head.next);

        // 翻转引用
        head.next.next = head;

        // 清空引用, 清除链环的发生
        head.next = null;

        // 返回翻转后的头节点
        return newHead;
    }
}

```

###### 迭代法 | O（n）

- **思路**：
  1. 迭代法利用了可以提前记录好 next 指针，再对当前的节点#next 指针进行翻转。
  2. 其中，关键在于初始化 pre 时，由于已经记录好了 next 指针，所以给 pre 赋第一个 head 值时，只需要用到 head 的值，而不需要以前的 next 指针。
- **结论**：时间，0ms，100%，空间，38.4mb，12.95，时间上，由于只遍历了一次链表，所以时间复杂度为 O（n），而空间上，由于只用了几个有限变量，所以额外空间复杂度为 O（1），应该是测试用例不够多，看起来优化的效果并不明显~

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode reverseList(ListNode head) {
        if(head == null) {
            return null;
        }
        if(head.next == null) {
            return head;
        }

        ListNode next = head.next, pre = new ListNode(head.val);
        while(next != null) {
            head = next;
            next = next.next;
            head.next = pre;// 翻转
            pre = head;// 继续移动翻转后的链表
        }

        return head;
    }
}

```

##### 9）回文链表

###### 暴力解法 | O（n）

- **思路**：先遍历链表，把节点收集到 ArrayList 中，然后再从头遍历判断链表是否为回文。
- **结论**：时间，5ms，66.85%，空间，53.3mb，18.89%，时间上，需要遍历 2 次，不过第二次只需要判断一半即可，而空间上，由于使用了一个数组，所以空间复杂度为 O（n），可以用双指针优化成 O（1）。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public boolean isPalindrome(ListNode head) {
        if(head == null) {
            return true;
        }

        int len = 0;
        ListNode node = head;
        List<ListNode> list = new ArrayList<>();
        while(node != null) {
            len++;
            list.add(node);
            node = node.next;
        }

        int index = 0;
        node = head;
        ListNode node2;
        while(node != null && index <= (len-1 >>> 1)) {
            node2 = list.get(len-1-index);
            if(node2.val != node.val) {
                return false;
            }

            index++;
            node = node.next;
        }

        return true;
    }
}

```

###### 前后指针法 | O（n）

- **思路**：先遍历一次算出链表长度，然后前指针先走到链表中点的 **next 节点**，这样可以翻转前指针往后的链表，最后后指针从头开始遍历，前指针从翻转链表的头节点开始遍历，如果遍历过程中有节点不等，则返回 false，否则返回 true。
- **结论**：时间，5ms，66.85%，空间，57.8mb，5.01%，时间上，由于要遍历 4 次，1 次整个链表，3 次半个链表，所以时间复杂度为 O（2.5n），空间上，由于只使用了几个变量，所以额外空间复杂度为 O（1）。

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public boolean isPalindrome(ListNode head) {
        if(head == null) {
            return true;
        }

        int len = 0;
        ListNode node1 = head;
        while(node1 != null) {
            len++;
            node1 = node1.next;
        }

        int index = 0;
        ListNode node2 = head;
        while(node2 != null && index <= (len-1 >>> 1)) {
            node2 = node2.next;
            index++;
        }

        // 翻转后半段链表
        node2 = reverseList(node2);
        
        // 如果为偶数个节点
        node1 = head;
        while(node1 != null && node2 != null) {
            if(node1.val != node2.val) {
                return false;
            }

            node1 = node1.next;
            node2 = node2.next;
        }
        
        return true;
    }

    private ListNode reverseList(ListNode head) {
        if(head == null) {
            return null;
        }
        if(head.next == null) {
            return head;
        }

        ListNode next = head.next, pre = new ListNode(head.val);
        while(next != null) {
            head = next;
            next = next.next;
            head.next = pre;// 翻转
            pre = head;// 继续移动翻转后的链表
        }

        return head;
    }
}

```

#### 二叉树

##### 1）二叉树的中序遍历 | 深度优先遍历

###### 递归法 | O（n）

- **思路**：递归遍历，左 -> 中 -> 右，因此在回到中的时候把节点的值加入集合中即可。
- **结论**：时间，0ms，100%，36.3mb，95.76%，非常简单。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> inorderTraversal(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        return res;
    }

    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        f(root.left, res);
        res.add(root.val);
        f(root.right, res);
    }
}

```

###### 迭代法 | O（n）

- **思路**：
  1. 中序遍历的迭代法实现也是很简单，模拟系统递归压栈的方式即可。
  2. 如果是递归实现中序遍历的话，res.add 是放在了左和右的中间，此时系统会一直找左找到空为止，那么迭代法也可以模拟这个操作，即一直找左，把路上的根节点都先入栈。
  3. 然后回到递归的中序遍历上，如果系统找左找到了空，那么就会返回，此时返回就回到了中间那步 res.add 操作，此时迭代法也可以模拟这操作，即栈弹出一个然后调用 res.add。
  4. 再回到递归的中序遍历上，接着系统收集完值后，就会把找右节点，然后又会一直找它的左节点一路为空，此时用迭代法来模拟就是，把右节点作为根节点，然后重复 2 的操作即可。
- **结论**：时间，0ms，100%，36.3%，96.77%，先序和中序是直接模拟系统栈来实现的，而后续如果用系统栈方式来模拟感觉比较麻烦，就用了先序颠倒再逆序的方式来实现简单一点。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> inorderTraversal(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        while(root != null) {
            stack.push(root);
            root = root.left;
        }

        List<Integer> res = new LinkedList<>();
        while(!stack.isEmpty()) {
            root = stack.pop();
            if(root != null) {
                res.add(root.val);
                if(root.right != null) {
                    root = root.right;
                    while(root != null) {
                        stack.push(root);
                        root = root.left;
                    }
                }
            }
        }

        return res;
    }
}

```

##### 2）二叉树的先序遍历

###### 递归法 | O（n）

- **思路**：递归遍历，中 -> 左 -> 右，因此在一开始来到中时，就把节点的值加入集合中即可。
- **结论**：时间，0ms，100%，36.4mb，92.56%，非常简单。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        return res;
    }
    
    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        res.add(root.val);
        f(root.left, res);
        f(root.right, res);
    }
}

```

###### 迭代法 | O（n）

- **思路**：迭代法中先序遍历实现最简单，因为当前使用的 while 循环可以认为是“中”，然后模拟系统栈把右、左一次压栈即可（可以认为是方法倒过来压栈）。
- **结论**：时间，0ms，100%，36.4mb，93.30%，注意添加和使用前都做个判空，防止空指针和节省空间的使用。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> preorderTraversal(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        if(root != null) {
            stack.push(root);
        }
        
        List<Integer> res = new LinkedList<>();
        while(!stack.isEmpty()) {
            root = stack.pop();
            if(root != null) {
                res.add(root.val);
                if(root.right != null) {
                    stack.push(root.right);
                }
                if(root.left != null) {
                    stack.push(root.left);
                }
            }
        }

        return res;
    }
}

```

##### 3）二叉树的后续遍历

###### 递归法 | O（n）

- **思路**：递归遍历，左 -> 右 -> 中，因此在最后一次来到中时，再把节点的值加入集合中即可。
- **结论**：时间，0ms，100%，36.4mb，95.34%，非常简单。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> postorderTraversal(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        return res;
    }
    
    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        f(root.left, res);
        f(root.right, res);
        res.add(root.val);
    }
}

```

###### 迭代法 | O（n）

- **思路**：
  1. 观察后序遍历的左 -> 右 -> 中，对比先序遍历的中 -> 左 -> 右可知，如果可以先把先序遍历的迭代法结果改成中 -> 右 -> 左的话，那么后序遍历就刚好等于中 -> 右 -> 左的逆序。
  2. 因此，要把先序遍历的迭代法结果改成中 -> 右 -> 左，就需要先压入左、再压入右（从后往前），然后初始栈弹出时不能直接打印，而是装入另一个收集栈中，这样在最后依次弹出收集栈中的节点并打印，即可得到上面操作的逆序，即后序遍历。
- **结论**：时间，0ms，100%，36.5mb，78.24%，思路很简单，就是先序颠倒然后再逆序输出即可。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<Integer> postorderTraversal(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        LinkedList<TreeNode> rstack = new LinkedList<>();
        if(root != null) {
            stack.push(root);
        }

        while(!stack.isEmpty()) {
            root = stack.pop();
            if(root != null) {
                rstack.push(root);
                if(root.left != null) {
                    stack.push(root.left);
                }
                if(root.right != null) {
                    stack.push(root.right);
                }
            }
        }

        List<Integer> res = new LinkedList<>();
        while(!rstack.isEmpty()) {
            root = rstack.pop();
            if(root != null) {
                res.add(root.val);
            }
        }
        
        return res;
    }
}

```

##### 4）二叉树的层序遍历 | 宽度优先遍历

###### 迭代法 | O（n）

- **思路**：
  1. 宽度优先遍历首先想到的就是用队列，先把头节点入队，然后出队时添加它的左孩子和右孩子，周而复始。
  2. 但这样仅仅只能得到遍历的序列而已，还无法确定那几个值属于同一层的，所以还需要增加一个层号表，以及维护一个当前层号。
  3. 在节点进队前，先把层号与节点映射起来（其中如果入队的是左孩子或者右孩子，其层号要+1），下次节点出队时就可以比较当前层号，如果发现节点层号与当前层号不同，说明当前出队的节点已经是下一层的了，这时候就结算上一层的节点，然后当前层号+1。
- **结论**：时间，2ms，89.72%，空间，38.5mb，71.49%，也是挺简单的。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public List<List<Integer>> levelOrder(TreeNode root) {
        Map<TreeNode, Integer> nodeLevelMap = new HashMap<>();
        Queue<TreeNode> queue = new LinkedList<>();
        if(root != null) {
            nodeLevelMap.put(root, 0);
            queue.offer(root);
        }

        int curLevel = 0, level;
        List<List<Integer>> res = new LinkedList<>();
        List<Integer> levelList = new LinkedList<>();
        while(!queue.isEmpty()) {
            root = queue.poll();
            if(root != null) {
                level = nodeLevelMap.get(root);
                if(level != curLevel) {
                    res.add(new ArrayList<>(levelList));
                    levelList.clear();
                    curLevel++;
                }

                levelList.add(root.val);

                if(root.left != null) {
                    nodeLevelMap.put(root.left, level + 1);
                    queue.offer(root.left);
                }

                if(root.right != null) {
                    nodeLevelMap.put(root.right, level + 1);
                    queue.offer(root.right);
                }
            }
        }

        if(!levelList.isEmpty()) {
            res.add(levelList);
        }

        return res;
    }
}

```

##### 5）重建二叉树 | 先序+中序

###### 递归法 | O（n）

- **思路**：
  1. 通过先序遍历的首位，确定并建立好根节点。
  2. 然后通过该根结点的值去哈希表中，拿到中序遍历的索引，根据该索引判断有没有右孩子和左孩子。
  3. 如果该索引往左至少还有 1 个节点，那么就认为还有左孩子，则把参数调整至左边，然后递归调用建立左孩子节点。
  4. 如果该索引往右至少还有 1 个节点，那么就认为还有右孩子，则把参数调整至右边，然后递归调用建立右孩子节点。
  5. 如果只有当前索引自己，那么则认为当前节点是一个叶子节点，则直接返回即可，周而复始。
- **结论**：时间，1ms，99.09%，空间，38.7mb，13.18%，效率还行，就这样吧~

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public TreeNode buildTree(int[] preorder, int[] inorder) {
        if(preorder == null || preorder.length == 0 || inorder == null || inorder.length == 0) {
            return null;
        }

        Map<Integer, Integer> map = new HashMap<>();
        for(int i = 0; i < inorder.length; i++) {
            map.put(inorder[i], i);
        }

        return f(map, preorder, 0, preorder.length-1, inorder, 0, inorder.length-1);
    }

    // f代表从[ip...jp]与[ii...ji]范围内构建二叉树
    private TreeNode f(Map<Integer, Integer> map, int[] pre, int ip, int jp, int[] in, int ii, int ji) {
        TreeNode root = new TreeNode(pre[ip]);
        int r = map.get(pre[ip]);

        // 如果有左孩子
        if(r - ii > 0) {
            root.left = f(map, pre, ip+1, ip+r-ii, in, ii, r-1);
        }

        // 如果有右孩子
        if(ji - r > 0) {
            root.right = f(map, pre, ip+r-ii+1, jp, in, r+1, ji);
        }

        return root;
    }
}

```

##### 6）重建二叉树 | 中序+后序

###### 递归法 | O（n）

- **思路**：
  1. 通过后序遍历的最后一位，确定并建立好根节点。
  2. 然后通过该根结点的值去哈希表中，拿到中序遍历的索引，根据该索引判断有没有右孩子和左孩子。
  3. 如果该索引往左至少还有 1 个节点，那么就认为还有左孩子，则把参数调整至左边，然后递归调用建立左孩子节点。
  4. 如果该索引往右至少还有 1 个节点，那么就认为还有右孩子，则把参数调整至右边，然后递归调用建立右孩子节点。
  5. 如果只有当前索引自己，那么则认为当前节点是一个叶子节点，则直接返回即可，周而复始。
- **结论**：时间，1ms，99.56%，空间，38.5mb，46.67%，效率还行，就这样吧~

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public TreeNode buildTree(int[] inorder, int[] postorder) {
        if(inorder == null || inorder.length == 0 || postorder == null || postorder.length == 0) {
            return null;
        }

        Map<Integer, Integer> map = new HashMap<>();
        for(int i = 0; i < inorder.length; i++) {
            map.put(inorder[i], i);
        }

        return f(map, inorder, 0, inorder.length-1, postorder, 0, postorder.length-1);
    }

    // f代表从[ii...ji]与[ip...jp]范围内构建二叉树
    private TreeNode f(Map<Integer, Integer> map, int[] in, int ii, int ji, int[] post, int ip, int jp) {
        TreeNode root = new TreeNode(post[jp]);
        int r = map.get(post[jp]);

        // 如果有左孩子
        if(r - ii > 0) {
            root.left = f(map, in, ii, r-1, post, ip, ip+r-ii-1);
        }

        // 如果有右孩子
        if(ji - r > 0) {
            root.right = f(map, in, r+1, ji, post, ip+r-ii, jp-1);
        }

        return root;
    }
}

```

##### 7）二叉树展开为链表

###### 暴力解法1 | O（2n）

- **思路**：先做一次先序遍历，把需要的值都收集起来，然后再顺序遍历，使用 root 节点构造满足题意的链表即可。
- **结论**：时间，2ms，35.68%，空间，37.7mb，76.02%，由于需要先收集再遍历，所以时间复杂度为 O（2n），而空间上由于遍历时构建了 n-1 个新的节点，以及使用了 1 个 list，以及递归时最大深度为 n，所以额外空间复杂度为 O（3n），这种取巧的方式面试会挂，需要在原树上进行修改指针！

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public void flatten(TreeNode root) {
        List<Integer> res = new LinkedList<>();
        f(root, res);
        
        for(int i = 1; i < res.size(); i++) {
            root.right = new TreeNode(res.get(i));
            root.left = null;
            root = root.right;
        }
    }

    private void f(TreeNode root, List<Integer> res) {
        if(root == null) {
            return;
        }

        res.add(root.val);
        f(root.left, res);
        f(root.right, res);
    }
}

```

###### 暴力解法2 | O（n）

- **思路**：还是沿用先序遍历的方式，不过采用了迭代法遍历进行优化，使得能够在遍历的过程中实现链表的拼接，在时间复杂度的常数项上进行了缩减，使得只遍历 1 次即可。
- **结论**：时间，1ms，36.68%，空间，37.8mb，61.20%，由于空间上使用了一个栈，因此额外空间复杂度为 O（n），还需要继续优化。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public void flatten(TreeNode root) {
        LinkedList<TreeNode> stack = new LinkedList<>();
        if(root != null) {
            stack.push(root);
        }

        TreeNode t;
        while(!stack.isEmpty()) {
            t = stack.pop();
            if(t.right != null) {
                stack.push(t.right);
            }
            if(t.left != null) {
                stack.push(t.left);
            }
            if(t != root) {
                root.left = null;
                root.right = t;
                root = root.right;
            }
        }
    }
}

```

###### 原地修改法 | O（n）

- **思路**：经过研究二叉树的规律，可得知，转换成链表只需要把左孩子的前驱连接到右孩子，然后剩下的再周而复始接合，所以列入了毁天灭地式的问题，因为没看过题解是真的没想到有这种方法。
- **结论**：时间，0ms，100%，37.8mb，69.48%，由于需要遍历 n 个节点，所以时间复杂度为 O（n），而空间上，由于只在原地修改节点的指针，所以额外空间复杂度为 O（1），这（前驱节点）应该才是面试要考的！

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public void flatten(TreeNode root) {
        TreeNode precursor;
        while(root != null) {
            precursor = findPrecursor(root);
            
            // 存在前驱, 则把前驱的右指针指向根结点右孩子
            if(precursor != null) {
                precursor.right = root.right;
                root.right = root.left;
                root.left = null;
                root = root.right;
            }
            // 前驱不存在, 说明肯定没有左孩子
            else {
                root = root.right;
            }
        }
    }
    
    // 查找前驱节点
    private TreeNode findPrecursor(TreeNode root) {
        TreeNode precursor = root.left;
        if(precursor != null) {
            while(precursor.right != null) {
                precursor = precursor.right;
            }
        }
        return precursor;
    }
}

```

##### 8）翻转二叉树

###### 深度优先搜索 | O（n）

- **思路**：一路递归到最左或者最右节点，交换后返回根节点，作为上一层翻转后的结果设置到左或者右节点即可。
- **结论**：时间，0ms，100%，空间，38.8mb，5.12%，效率非常高了，就这样吧~

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public TreeNode invertTree(TreeNode root) {
        if(root == null) {
            return null;
        }
        
        TreeNode left = root.left;
        TreeNode right = root.right;

        root.right = invertTree(left);
        root.left = invertTree(right);

        return root;
    }
}

```

###### 宽度优先搜索 | O（n）

- **思路**：看到宽度优先搜索首先想到队列，出队则处理左右孩子翻转，然后再把左、右节点入队，周而复始即可。
- **结论**：时间，0ms，100%，空间，39ms，5.12%，效率非常高了，就这样吧~

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public TreeNode invertTree(TreeNode root) {
        if(root == null) {
            return null;
        }
        
        Queue<TreeNode> queue = new LinkedList<>();
        queue.offer(root);

        TreeNode node, left, right;
        while(!queue.isEmpty()) {
            node = queue.poll();
            if(node == null) {
                continue;
            }

            left = node.left;
            right = node.right;

            node.left = right;
            node.right = left;

            queue.offer(left);
            queue.offer(right);
        }

        return root;
    }
}

```

#### 字符串

##### 1）字符串解码

###### 递归法 | O（n）

- **思路**：
  1. 设计一个 f（index）函数，代表处理并返回 [index,  ']' 或者结尾]位置解析后的字符串。
  2. f 函数的实现需要从 index 处开始遍历 s 字符串，一共有 5 种情况：
     1. 如果碰到数字字符，则转换为倍数，0 倍表示字符串原样输出，其中需要注意 10+ 倍连续数字的出现。
     2. 如果碰到左括号字符，则把剩余遍历工作交由子过程去处理，处理完后把其返回结果乘上第 1 步得到的倍数，再与当前返回结果做拼接，然后当前递归继续处理子过程处理后剩余的位置。
     3. 如果碰到小写字母，则把小写字母加入当前返回结果中。
     4. 如果碰到右括号，则把当前处理到的位置记录在 Info 变量上，以告诉父过程什么是已经处理过的，然后把当前处理结果返回，以让父过程做字符串拼接。
     5. 如果当前递归遍历完毕，也没有碰到右括号，说明当前为第一次递归函数，则当前处理结果返回即可。
- **结论**：时间，0ms，100%，空间，39.2mb，6.03%，时间上，虽然递归深度可能会很深，但字符串 s 也就只会被遍历 1 遍，所以时间复杂度为 O（n），空间上，额外空间取决于递归深度，其最坏情况为层层嵌套，记最多嵌套 m 层，所以额外空间复杂度为 O（m）。

```java
class Solution {

    class Info {
        int index;
        Info(int index) {
            this.index = index;
        }
    }

    public String decodeString(String s) {
        if(s == null || s.length() == 0) {
            return "";
        }
        return f(s, new Info(0));
    }

    // f代表处理并返回[index, ']'或者结尾]位置解析后的字符串
    private String f(String s, Info info) {
        if(info.index == s.length()) {
            return "";
        }

        int mul = 0;
        char c;
        StringBuilder sb = new StringBuilder();
        for(int i = info.index; i < s.length(); i++) {
            c = s.charAt(i);
            
            // 数字 => 转换为倍数
            if(c >= '0' && c <= '9') {
                mul = mul * 10 + (c - '0');
            }
            // 左括号 => 后面的交给子过程去处理
            else if(c == '[') {
                info.index = i + 1;
                sb.append(
                    process(f(s, info), mul)
                );
                i = info.index;
                mul = 0;
            }
            // 小写字母 => 加入当前递归字符集
            else if(c >= 97 && c <= 122) {
                sb.append(c);
            }
            // 右括号 => 直接返回当前递归收集到的字符串
            else if(c == ']') {
                info.index = i;
                return sb.toString();
            }
        }

        // 遍历完也没遇到右括号, 说明被消化完了, 则直接返回
        return sb.toString();
    }

    private String process(String s, int k) {
        if(s == null || s.length() == 0) {
            return "";
        }
        if(k == 0) {
            return s;
        }

        StringBuilder sb = new StringBuilder();
        while(k > 0) {
            sb.append(s);
            k--;
        }

        return sb.toString();
    }
}

```

###### 迭代法 | O（n）

- **思路**：跟递归法的思路一样，迭代法的思路也是从头到尾遍历字符串 s，也共分为 5 种情况：
  1. 如果碰到数字字符，则转换为倍数，0 倍表示字符串原样输出，其中需要注意 10+ 倍连续数字的出现。
  2. 如果碰到左括号字符，则初始化好一个字符集并加入字母栈中，以及把收集到的倍数加入倍数栈中，然后清空当前倍数，以继续收集其他处理集的倍数。
  3. 如果碰到小写字母，则如果字母栈不为空，说明为栈顶处理集的字母，则把该小写字母加入字母栈中；如果字母栈为空，说明为顶层处理集的字母，则把该小写字母加入当前处理集中。
  4. 如果碰到右括号，则说明为栈顶处理集的右括号（字母栈肯定不为空），也就是栈顶处理集到尽头了，则字母栈栈顶和倍数栈栈顶弹出，调用 process 处理函数加工乘上倍数后的字符串；如果弹出后字母栈不为空，说明为栈顶处理集的字母，则把该小写字母加入字母栈中；如果字母栈为空，说明为顶层处理集的字母，则把该小写字母加入当前处理集中。
  5. 如果当前递归遍历完毕，说明顶层处理集处理完毕，则返回处理结果即可。
- **结论**：时间，0ms，100%，39.4mb，5.01%，时间上，由于只需要遍历 1 次字符串 s，所以时间复杂度为 O（n），空间上，由于使用了两个栈，最坏情况下层层嵌套的话，记栈的最大深度为 m，此时的额外空间复杂度为 O（m）。

```java
class Solution {

    public String decodeString(String s) {
        if(s == null || s.length() == 0) {
            return "";
        }

        LinkedList<Integer> mulStack = new LinkedList<>();
        LinkedList<StringBuilder> sbStack = new LinkedList<>();

        int mul = 0;
        char c;
        String tmp;
        StringBuilder sb = new StringBuilder();
        for(int i = 0; i < s.length(); i++) {
            c = s.charAt(i);
            
            // 数字 => 转换为倍数
            if(c >= '0' && c <= '9') {
                mul = mul * 10 + (c - '0');
            }
            // 左括号 => 入栈字母栈和倍数栈
            else if(c == '[') {
                sbStack.push(new StringBuilder());
                mulStack.push(mul);
                mul = 0;
            }
            // 小写字母
            else if(c >= 97 && c <= 122) {
                // 加入栈顶的字符集
                if(!sbStack.isEmpty()) {
                    sbStack.peek().append(c);
                } 
                // 加入当前收集的字符集
                else {
                    sb.append(c);
                }
            }
            // 右括号
            else if(c == ']') {
                if(sbStack.isEmpty() || mulStack.isEmpty()) {
                    continue;
                }

                // 加入栈顶的字符集
                tmp = process(sbStack.poll().toString(), mulStack.poll());
                if(!sbStack.isEmpty() && !mulStack.isEmpty()) {
                    sbStack.peek().append(tmp);
                } 
                // 加入当前收集的字符集
                else {
                    sb.append(tmp);
                }
            }
        }

        // 字符串遍历完毕
        return sb.toString();
    }

    private String process(String s, int k) {
        if(s == null || s.length() == 0) {
            return "";
        }
        if(k == 0) {
            return s;
        }

        StringBuilder sb = new StringBuilder();
        while(k > 0) {
            sb.append(s);
            k--;
        }

        return sb.toString();
    }
}

```

### 1.2. 业务角度划分问题？

#### n 数之和

##### 1）两数之和

###### 缓存法 | O（n）

- **思路**：遍历数组，每次都判断哈希表中是否存在和的另一半，存在则返回，不存在则添加到表中，然后继续。
- **优点**：缓存法，一次遍历搞定（1ms，99.36%）。
- **结论**：空间复杂度 O（n），如果仅仅是两数之和，那么这就是最优解，否则如果嵌套两数之和求解，整体复杂度 > O（n）的话，那么用**双向指针**会省很多空间。

```java
import java.util.HashMap;
class Solution {
    public int[] twoSum(int[] nums, int target) {
        if(nums == null || nums.length < 2) {
            return null;
        }
        
        Integer tmp = null;
        HashMap<Integer, Integer> map = new HashMap<>();
        for(int i = 0; i < nums.length; i++) {
            tmp = map.get(target - nums[i]);
            if(tmp != null) {
                return new int[] {i, tmp};    
            }
            map.put(nums[i], i);
        }

        return new int[] {-1, -1};
    }
}

```

##### 2）三数之和

###### 暴力求解 | O（n^3）

- **思路**：3 重循环累加判断是否等于 0， 是的就加入集合，最后去重再返回。
- **缺点**：时间复杂度高，执行**超时**！
- **结论**：面试会挂！不能作为最终答案！

```java
import java.util.LinkedList;
class Solution {
    public List<List<Integer>> threeSum(int[] nums) {
        List<List<Integer>> res = new LinkedList<>();
        if(nums == null || nums.length < 3) {
            return res;
        }

        for(int i = 0; i < nums.length - 2; i++) {
            for(int j = i + 1; j < nums.length - 1; j++) {
                for(int k = j + 1; k < nums.length; k++) {
                    if(nums[i] + nums[j] + nums[k] == 0) {
                        List<Integer> list = new LinkedList<>();
                        list.add(nums[i]);
                        list.add(nums[j]);
                        list.add(nums[k]);
                        res.add(list);
                    }                       
                }
            }
        }

        // 去重
        distinct(res);
        return res;
    }

    // 去重
    private void distinct(List<List<Integer>> list) {
        HashMap<String, String> hasesMap = new HashMap<>();
        Iterator<List<Integer>> it = list.iterator();
        while(it.hasNext()) {
            List<Integer> elist = it.next();
            sort(elist);
            String key = "" + elist.get(0) + elist.get(1) + elist.get(2);
            if(hasesMap.containsKey(key)) {
                it.remove();
            } else {
                hasesMap.put(key, key);
            }
        }
    }

    private void sort(List<Integer> elist) {
        if(elist.get(0) < elist.get(1)) {
            swap(elist, 0, 1);
        }
        if(elist.get(0) < elist.get(2)) {
            swap(elist, 0, 2);
        }
        if(elist.get(1) < elist.get(2)) {
            swap(elist, 1, 2);
        }
    }

   private void swap(List<Integer> elist, int from, int to) {
       int tmp = elist.get(from);
       elist.set(from, elist.get(to));
       elist.set(to, tmp);
    }
}

```

###### 贪心去重 | O（n^2）

- **思路**：
  1. 通过先从小到大排序数组，相同的只取第一个做两数之和生成，避免外层重复。
  2. 由于整体是有序的，所以在做两数之和时，通过顺序 key 做重复判断，重复的将不再添加，避免内层重复。
- **缺点**：耗时严重（259ms，9.81%），因为前后重复运算了相同位置的元素，空间也浪费严重，使用了两个 map。
- **结论**：面试会挂！不能作为最终答案！

```java
class Solution {
    public List<List<Integer>> threeSum(int[] nums) {
        List<List<Integer>> res = new ArrayList<>();
        if(nums == null || nums.length < 3) {
            return res;
        }

        // 从小到大排序
        Arrays.sort(nums);

        HashMap<String, String> distinctMap = new HashMap<>();
        for(int i = 0; i < nums.length; i++) {
            // 相同的跳过重复解, 取第一个即可
            if(i > 0 && nums[i-1] == nums[i]) {
                continue;
            }

            twoSum(nums, i + 1, res, nums[i], distinctMap);
        }

        return res;
    }

    private void twoSum(int[] nums, int start, List<List<Integer>> res, int value, HashMap<String, String> distinctMap) {
        if(nums == null || nums.length - start < 2) {
            return;
        }
        
        Integer tmp = null, target =  0 - value;
        HashMap<Integer, Integer> map = new HashMap<>();
        for(int i = start; i < nums.length; i++) {
            tmp = map.get(target - nums[i]);
            if(tmp != null) {
                String key = "" + value + nums[i] + nums[tmp];
                if(!distinctMap.containsKey(key)) {
                    List<Integer> list = new ArrayList<>(3);
                    list.add(value);
                    list.add(nums[i]);
                    list.add(nums[tmp]);
                    res.add(list);
                    distinctMap.put(key, key);
                }
            }
            map.put(nums[i], i);
        }
    }
}

```

###### 双向指针 + 贪心去重 | O（n^2）

- **思路**：
  1. 通过先从小到大排序数组，相同的只取第一个做两数之和生成，避免外层重复。
  2. 由于整体是有序的，所以在做两数之和时，判断完后再判断是否重复，重复则跳过，避免内层重复。
- **优点**：通过双向指针 + 贪心去重，重复的元素只会计算一次，也不需要哈希表判重，大大节省了时间（22ms，51.86%）和空间。
- **结论**：51.86% 过半了，面试可以尝试下。

```java
class Solution {
    public List<List<Integer>> threeSum(int[] nums) {
        List<List<Integer>> res = new ArrayList<>();
        if(nums == null || nums.length < 3) {
            return res;
        }

        // 从小到大排序
        Arrays.sort(nums);

        for(int i = 0; i < nums.length; i++) {
            // 外层算过了就不用重新算了, 因为代表了包含这个数的解
            if(i > 0 && nums[i-1] == nums[i]) {
                continue;
            }

            twoSum(nums, i + 1, res, nums[i]);
        }

        return res;
    }

    private void twoSum(int[] nums, int start, List<List<Integer>> res, int value) {
        if(nums == null || nums.length - start < 2) {
            return;
        }
        
        int target =  0 - value, l = start, r = nums.length - 1, sum;
        while (l < r) {
            sum = nums[l] + nums[r];
            if(sum == target) {
                List<Integer> list = new ArrayList<>(3);
                list.add(value);
                list.add(nums[l]);
                list.add(nums[r]);
                res.add(list);

                // l这个解算过了就不用再算了, 代表外层+l这个解
                while(l < r && nums[l] == nums[l+1]) {
                    l++;
                }
                l++;

                // r这个解算过了就不用再算了, 代表外层+l+r这个解
                while(l < r && nums[r-1] == nums[r]) {
                    r--;
                }
                r--;
            } 
            // 双指针法, 由于有序递增, 所以如果累加和还小, 则当前位置不用算了, 答案肯定在右边
            else if(sum < target) {
                l++;
            } 
            // 双指针法, 由于有序递增, 所以如果累加和大了, 则当前位置不用算了, 答案肯定在左边
            else {
                r--;
            }
        }
    }
}

```

##### 3）和为 k 的子数组

###### 暴力解法 | O（n^2）

- **思路**：枚举所有子数组，然后统计每个子数组的和，看是否等于 k，从而累加好 count 并返回。
- **结论**：时间，1474ms，14.99%，空间，44.4mb，5.04%，时间复杂度 O（n^2），额外空间复杂度 O（1）。

```java
class Solution {
    public int subarraySum(int[] nums, int k) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int count = 0, sum;
        for(int i = 0; i < nums.length; i++) {
            sum = 0;
            for(int j = i; j < nums.length; j++) {
                sum += nums[j];
                if(sum == k) {
                    count++;
                }
            }
        }

        return count;
    }
}

```

###### 前缀和法 | O（n）

- **思路**：
  1. 建立前缀和数组，pre[i] = pre[i-1] + nums[i]，经过研究发现，pre[i] - pre[j] 刚好就等于 nums[j] +... + nums[i] 连续子数组的元素总和，如果要求 nums[j] +... + nums[i] = k，那么就有 pre[i] - pre[j] = k，即 pre[i] - k = pre[j]，所以问题就转换为了，遍历前缀和数组到 pre[i]，如果能发现 pre[j] = pre[i] - k，那么就说明原数组中元素总和为 k 的存在连续子数组。
  2. 经过尝试发现，并不需要建立 pre 前缀和数组，只需要记录一个 pre 变量，代表上一个前缀和，然后每次累加该变量即可。
  3. 同时，建立前缀和词频表，使得每次计算 pre[j] = pre[i] - k，可以只需要 O（1）的时间内发现 pre[j]，不过要提前录好 pre[j] = 0，以保证任何以 nums[0] 开头的子数组不被算漏~
- **结论**：时间，21ms，92.31%，空间，43.8mb，7.76%，时间上，由于只需要遍历一次 nums 数组，所以时间复杂度为 O（n），空间上，由于使用了一张哈希表，最多存储 n 个元素，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public int subarraySum(int[] nums, int k) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int pre = 0, count = 0;

        Map<Integer, Integer> map = new HashMap<>();
        map.put(0, 1);

        for(int i = 0; i < nums.length; i++) {
            // 直接使用preSum[1]=1, 而不是preSum[0]=0
            pre += nums[i];

            // 累加: 在初始化之前, 确保get(pre-k)不会到自己
            if(map.containsKey(pre-k)) {
                count += map.get(pre-k);
            }

            // 初始化
            map.put(pre, map.getOrDefault(pre, 0) + 1);
        }

        return count;
    }
}

```

#### 数组找数

##### 1）多数元素

见《毁天灭地式问题 - 多数元素》。

##### 2）只出现一次的数字

见《位运算 - 只出现一次的数字》。

##### 3）除自身以外数组的乘积

见《毁天灭地式问题 - 除自身以外数组的乘积》。

##### 4）寻找重复数

见《毁天灭地式问题 - 寻找重复数》。

##### 5）找出所有数组中消失的数字

###### 暴力解法 | O（3 * n）

- **思路**：先使用 arr 数组存放 [1,n] 作为哈希表，然后从左到右遍历 nums，如果发现 nums[i] 在 arr 中存在，那么清空它，清空完毕后，再遍历一次 arr，收集没被清空的那些就是答案了。 
- **结论**：时间，3ms，99.99%，48.9mb，8.48，时间上，由于需要遍历 3 次 n 长的数组，所以时间复杂度为 O（3 * n），空间上，由于使用了一张 arr 数组，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public List<Integer> findDisappearedNumbers(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        int[] arr = new int[nums.length];
        for(int i = 0; i < arr.length; i++) {
            arr[i] = i + 1;
        }

        // 4存在3位置, 但值为4
        for(int i = 0; i < nums.length; i++) {
            arr[nums[i] - 1] = -1;
        }

        List<Integer> res = new ArrayList<>();
        for(int i = 0; i < arr.length; i++) {
            if(arr[i] != -1) {
                res.add(arr[i]);
            }
        }
        return res;
    }
}

```

###### 比较交换法 | O（2 * n）

- **思路**：经过研究数据状态，发现只要每次遍历都把元素放到对的位置，如果碰到目标位置已经是对了，但当前不对，那么说明这个位置就是错误的位置，所以可以在下次遍历时统计收集起来返回即可。
- **结论**：时间，5ms，49.16%，空间，49.1mb，7.54%，时间上，遍历放元素时，由于每个元素放对位置后就不再处理了，所以只会被处理一次，花费 O（n），收集返回结果时遍历数组花费 O（n），因此时间复杂度为 O（2 * n），空间上，由于只使用了有限几个变量，所以空间复杂度为 O（1）。

```java
class Solution {
    public List<Integer> findDisappearedNumbers(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        int ival, target, i = 0;
        while(i < nums.length) {
            ival = nums[i];
            if(ival == i + 1) {
                i++;
                continue;
            }

            target = nums[ival-1];
            if(target == ival) {
                i++;
            } else {
                nums[i] = target;
                nums[ival-1] = ival;
            }
        }

        List<Integer> res = new ArrayList<>();
        for(i = 0; i < nums.length; i++) {
            if(nums[i] != i + 1) {
                res.add(i+1);
            }
        }

        return res;
    }
}

```

#### 第/前 k 个问题

##### 1）数组中的第 k 个最大元素

###### 暴力解法 | O（n * logn）

- **思路**：从小到大排序，从后面取第 k 个元素即可。
- **结论**：时间，2ms，82.75%，41.4mb，5.04%，效率非常高，但没答到点上，本题主要考的是堆排序和快速排序算法~

```java
class Solution {
    public int findKthLargest(int[] nums, int k) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        Arrays.sort(nums);
        return nums[nums.length-k];
    }
}

```

###### 堆排序 | O（n * logn）

- **思路**：建立容量为 k 的小根堆，遍历数组加入堆，如果堆大小大于 k，则弹出堆顶，数组遍历完毕后，堆顶即为第 k 个最大的元素。
- **结论**：
  1. 时间，5ms，46.25%，空间，42mb，5.04%，时间上，遍历一次数组+调整堆，所以时间复杂度为 O（n * logn），空间上，容量为 k 的堆额外需要长度为 k 的数组，所以额外空间复杂度为 O（k）。
  2. 该算法最适合用于，初始时数据长度不定的流式数据。

```java
class Solution {
    public int findKthLargest(int[] nums, int k) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        // 从小到大排序
        PriorityQueue<Integer> queue = new PriorityQueue<>((o1, o2) -> o1 - o2);
        for(int i = 0; i < nums.length; i++) {
            queue.offer(nums[i]);
            if(queue.size() > k) {
                queue.poll();
            }
        }

        return queue.poll();
    }
}

```

###### 快速选择 | <= O（n * logn）

- **思路**：
  1. 对暴力解法进行了改进，由于暴力解法底层以及快速排序，时间复杂度为 O（n * logn），而经过研究，可在快排进行改进，得到比暴力解法更优的解法。
  2. 首先是随机 partition，这是快排 3.0 的基础，旨在使得 partition 目标值的选取变为概率事件，平均期望为 O（n * logn） ，然后每次随机 partition 返回一个数组，代表 partition 后中间位置的左边界和右边界：
     1. 如果第 k 个元素落在中间位置，则返回中间位置的值。
     2. 如果第 k 个元素落在左边区域，则继续从左边区域选择值。
     3. 如果第 k 个元素落在右边区域，则继续从右边区域选择值。
- **结论**：时间，2ms，82.75%，空间，42mb，5.04%，时间上，对比暴力解法的快排后取下标的方式，每次都少了一半的 partition，因此，时间复杂度更低 <= O（n * logn），空间上，额外空间复杂度取决于递归栈的最大深度，为 O（n * logn）。

```java
class Solution {
    public int findKthLargest(int[] nums, int k) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        // 从全部区域中选择值, 第k个元素落在全部区域上
        return quickSelect(nums, 0, nums.length-1, nums.length-k);
    }

    private int quickSelect(int nums[], int L, int R, int targetIndex) {
        // 获取partition后中间位置的左边界和右边界
        int[] p = randomPartition(nums, L, R);

        // 如果第k个元素落在中间位置, 则返回中间位置的值
        if(p[0] <= targetIndex && targetIndex <= p[1]) {
            return nums[p[0]];
        } 
        // 如果第k个元素落在左边区域, 则继续从左边区域选择值
        else if(targetIndex < p[0]) {
            return quickSelect(nums, L, p[0]-1, targetIndex);
        } 
        // 如果第k个元素落在右边区域, 则继续从右边区域选择值
        else {
            return quickSelect(nums, p[1]+1, R, targetIndex);
        }
    }

    private int[] randomPartition(int nums[], int L, int R) {
        // 快排3.0: 随机选择一个值交换到末尾做partition
        swap(nums, L + (int) (Math.random() * (R - L + 1)), R);

        // <区域的左边界, >区域的右边界
        int less = L - 1, more = R;

        // L表示当前数的位置, R表示要比较值的位置, more表示右边界的位置
        while(L < more) {
            // 当前数 < 比较值, 则<区域的左边界+1, 并且继续比较下一个值
            if(nums[L] < nums[R]) {
                swap(nums, ++less, L++);
            }
            // 当前数 == 比较值, 则继续比较下一个值
            else if(nums[L] == nums[R]) {
                L++;
            }
            // 当前数 > 比较值, 则右边界-1, 并且还需要比较当前值
            else {
                swap(nums, --more, L);
            }
        }

        swap(nums, more, R);
        return new int[] {less+1, more};
    }

    private void swap(int nums[], int from, int to) {
        int tmp = nums[from];
        nums[from] = nums[to];
        nums[to] = tmp;
    }
}

```

##### 2）前 k 个高频元素

###### 哈希计数法 | O（k * s）

- **思路**：先对词频进行统计，然后分别找出第 1,2,...,k 大的元素放在结果数组 res 的第 k-1,k-2,...0 位并返回。
- **结论**：时间，3ms，99.72%，空间，43.8mb，5.32%，时间上，由于需要遍历 k 次 counts 数组，每次遍历 counts 数组需要花费 O（max-min+1），记录 max-min+1为 s，所以时间复杂度为 O（k * s），空间上，由于使用了一张 max-min+1 大的 counts 数组，所以额外空间复杂度为 O（s）。

```java
class Solution {
    public int[] topKFrequent(int[] nums, int k) {
        if(nums == null || nums.length == 0 || k > nums.length) {
            return new int[0];
        }
        
        int min = Integer.MAX_VALUE, max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            min = Math.min(min, nums[i]);
            max = Math.max(max, nums[i]);
        }

        int[] counts = new int[max-min+1];
        for(int i = 0; i < nums.length; i++) {
            counts[nums[i]-min] += 1;
        }

        int maxi;
        int[] res = new int[k];
        while(k > 0) {
            maxi = 0;
            max = Integer.MIN_VALUE;
            for(int i = 0; i < counts.length; i++) {
                if(counts[i] > max) {
                    maxi = i;
                    max = counts[i];
                }
            }
            res[k-1] = maxi + min;
            counts[maxi] = Integer.MIN_VALUE;
            k--;
        }
        
        return res;
    }
}

```

#### 排序

##### 1）字母异位词分组

###### 哈希表 + 排序 | O（n * nlogn）

- **思路**：遍历每个字符串，并获取他们的字符数组，然后顺序排序字符数组，再组合成顺序 Key，接着加入哈希表中，这样，含有相同字符的字符串都会进入哈希表同一个桶中，完成分组。
- **结论**：5ms，99.01%，41.3mb，56.10%，垃圾题~

```java
class Solution {
    public List<List<String>> groupAnagrams(String[] strs) {
        if(strs == null) {
            return new ArrayList<>();
        }

        Map<String, List<String>> map = new HashMap<>();
        for(String s : strs) {
            char[] chars = s.toCharArray();
            Arrays.sort(chars);
            String key = String.valueOf(chars);
            if(map.containsKey(key)) {
                map.get(key).add(s);
            } else {
                List<String> list = new ArrayList<>();
                list.add(s);
                map.put(key, list);
            }
        }

        List<List<String>> res = new ArrayList<>(map.size());
        for(List<String> list : map.values()) {
            res.add(list);
        }

        return res;
    }
}

```

##### 2）颜色分类

###### 荷兰国旗 partition 法 | O（n） 

- **思路**：这是经典的荷兰国旗问题，可以设计一个通用的 partition （midValue，start，end）函数，通过不断与 midValue 比较，把 [start,end] 范围内的数组, 划分成 [左边<,中间=,右边>] 的三个区域。
  1. 初始化一个左边界 -1，和一个右边界 num.length+1，开始从左到右遍历。
  2. 如果 nums[i] 小于 midValue，那么需要把它加入左边界里，即**左边界 L++**，然后交换 i 位置的值，接着 i++，继续比较下一个。
  3. 如果 nums[i] 等于 midValue，则认为当前位置是正确的，因为在左边界的右边。
  4. 如果 nums[i] 大于 midValue，那么需要把它加入右边界里，即**右边界 R--**，然后交换 i 位置的值，但由于新交换上来的值还没有比较，不知道是留在 i 位置还是左边界里，所以还需要继续比较，此时 i **保持不变**，开始下一轮比较。
- **结论**：时间，0ms，100%，空间，36.9mb，53.27%，效率非常高，就这样吧~

```java
class Solution {
    public void sortColors(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return;
        }
        partition(nums, 1, 0, nums.length-1);
    }

    // partition荷兰国旗问题, 可以把[start,end]范围内的数组, 划分成[左边<,中间=,右边>]的三个区域
    private void partition(int[] nums, int midValue, int start, int end) {
        if(start > end) {
            return;
        }

        // < midValue 的左边界, > midValue 的右边界
        int L = start - 1, R = end + 1;
        
        // 开始partition
        while(start < R) {
            // 划分到左边: 左边界+1, 与start交换, start+1
            if(nums[start] < midValue) {
                swap(nums, ++L, start++);
            } 
            // 划分到中间, 原地不动, 继续遍历
            else if(nums[start] == midValue){
                start++;
            }
            // 划分到右边: 右边界-1, 与start交换, 继续比对当前位置(刚交换上来的值)
            else {
                swap(nums, --R, start);
            }
        }
    }

    private void swap(int[] nums, int from, int to) {
        int tmp = nums[from];
        nums[from] = nums[to];
        nums[to] = tmp;
    }
}

```

##### 3）排序链表

见《链表 - 排序链表》。

##### 4）数组中的第 k 个最大元素

见《第/前 k 个问题 - 数组中的第 k 个最大元素》。

##### 5）移动零

###### 类冒泡排序 | O（n）

- **思路**：参考冒泡排序的思路，不断从头把 0 移动到数组尾部即可，不过这里做了优化，即先记录好一路上 0 的个数，下次碰到非 0 需要与 0 做交换时，直接跳到最前面的 0 即可，避免了 O（n^2）的发生。
- **结论**：时间，2ms，59.21%，空间，42.6mb，5.04%，时间上，由于数组只遍历一次，所以时间复杂度为 O（n），空间上，由于只是用有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public void moveZeroes(int[] nums) {
        if(nums == null || nums.length == 0) {
            return;
        }

        int k = nums[0] == 0? 1 : 0;
        for(int i = 1; i < nums.length; i++) {
            if(nums[i] == 0) {
                k++;
            } 
            // 从右向左往前寻找最前的不为0的位置, 找到后则交换当前非0数即可
            else if(nums[i-k] == 0) {
                swap(nums, i, i-k);
            }
        }
    }

    private void swap(int[] nums, int from, int to) {
        int tmp = nums[from];
        nums[from] = nums[to];
        nums[to] = tmp;
    }
}

```

##### 6）根据身高重建队列

###### 暴力解法 | O（n * [logn + n + k]）

- **思路**：先按 ki 从小到大排序，然后根据使用交换排序变种，遍历每个位置时，再往前统计大于或者等于当前 hi 的元素个数，如果发现统计结果超过了当前 ki，则交换移动差值步，周而复始。
- **结论**：时间，39ms，5.11%，空间，42mb，5.51%，时间上，根据 ki 从小到大排序需要 O（n * logn），遍历时统计最坏时需要 O（n * n），遍历时移动差值步需要 O（n * k），所以时间复杂度为 O（n * [logn + n + k]），空间上，由于使用了一张长度为 n 的一维表以及排序也需要递归深度 logn，所以额外空间复杂度为 O（logn + n）。

```java
class Solution {

    class Info {
        int hi;
        int ki;

        Info(int hi, int ki) {
            this.hi = hi;
            this.ki = ki;
        }
    }

    public int[][] reconstructQueue(int[][] people) {
        if(people == null || people.length == 0 || people[0].length == 0) {
            return new int[0][0];
        }
        
        // 先按ki进行从小到大排序
        List<Info> list = new ArrayList<>(people.length);
        for(int[] member : people) {
            list.add(new Info(member[0], member[1]));
        }
        list.sort((o1, o2) -> o1.ki - o2.ki);

        // 排序后, 从左到右遍历
        int k, m;
        Info io, jo;
        for(int i = 1; i < list.size(); i++) {
            io = list.get(i);
            k = 0;
            for(int j = i - 1; j > -1; j--) {
                jo = list.get(j);
                if(io.hi <= jo.hi) {
                    k++;
                }
            }
            // 往前交换
            m = i;
            if(io.ki < k) {
                while(k - io.ki > 0) {
                    swap(list, m, m-1);
                    m = m - 1;
                    k--;
                }
            }
        }

        // 输出结果
        int[][] res = new int[list.size()][2];
        for(int i = 0; i < list.size(); i++) {
            io = list.get(i);
            res[i][0] = io.hi;
            res[i][1] = io.ki;
        }
        return res;
    }

    private void swap(List<Info> list, int from, int to) {
        Info tmp = list.get(from);
        list.set(from, list.get(to));
        list.set(to, tmp);
    }
}

// 优化后的版本, 时间复杂度不变 O（n * [logn + n + k]），空间复杂度变为 O(logn)
class Solution {
    public int[][] reconstructQueue(int[][] people) {
        if(people == null || people.length == 0 || people[0].length == 0) {
            return new int[0][0];
        }

        Arrays.sort(people, (o1, o2) -> {
            if(o1[1] != o2[1]) {
                return o1[1] - o2[1];
            } else {
                return o1[0] - o2[0];
            }
        });

        int k, m, iki;
        for(int i = 1; i < people.length; i++) {
            k = 0;
            m = i;
            iki = people[i][1];
            for(int j = i - 1; j > -1; j--) {
                // i.hi <= j.hi
                if(people[i][0] <= people[j][0]) {
                    k++;
                }
            }
            // i.ki < k, 即理论ki要为k的, 但实际只有ki, 所以要向前交换
            while(k - iki > 0) {
                swap(people, m, m-1);
                m--;
                k--;
            }
        }

        return people;   
    }

    private void swap(int[][] people, int from, int to) {
        int[] tmp = people[from];
        people[from] = people[to];
        people[to] = tmp;
    }
}

```

###### 线性探测法 | O（n * [logn + n]）

- **思路**：
  1. 对原数组先按 hi 顺序排序，同时对相同 hi 的元素按 ki 逆序排序，不过这样得到的只是从低到高的队列，由于 ki 题意表示的是前面数组中，比当前大于或者等于的元素个数，所以当前元素可能站的位置不对。
  2. 因此，由于原数组对相同 hi 的 ki 进行逆序排序，也就是 hi 相同时大的 ki 在前，所以可以利用线性探测的方式，从左到右遍历到原数组，把 i 看作是第一个元素（如果已经有元素了则跳过，只比较为 null 的位置），排在第 ki 位置 ，所以向后探测 ki 次，然后放入 ki + 1 的位置上，
- **结论**：时间，11ms，26.52%，空间，41.9%，6.23%，时间上，根据排序需要 O（n * logn），线性探测需要 O（n^2），所以时间复杂度为 O（n * [logn + n]），空间上，需要递归深度 logn，所以额外空间复杂度为 O（logn）。

```java
class Solution {
    public int[][] reconstructQueue(int[][] people) {
        if(people == null || people.length == 0 || people[0].length == 0) {
            return new int[0][0];
        }

        Arrays.sort(people, (o1, o2) -> {
            if(o1[0] != o2[0]) {
                return o1[0] - o2[0];
            } else {
                // 由于后面是判断res[j]是否为null时, skip才-1, 所以这里排序要逆序排, 保证相同的hi时能够先处理ki大的元素
                return o2[1] - o1[1];
            }
        });

        int skip;
        int[][] res = new int[people.length][];
        for(int i = 0; i < people.length; i++) {
            skip = people[i][1];
            for(int j = 0; j < people.length; j++) {
                // 如果j处的数组还没初始化
                if(res[j] == null) {
                    skip--;
                    if(skip == -1) {
                        res[j] = people[i];
                        break;
                    }
                }
            }
        }

        return res; 
    }
}

```

###### 元素挤兑法 | O（n * [logn + n]）

- **思路**：
  1. 先对原数组的 hi 从大到小排序, 相同 hi 的按 ki 从小到大排序, 使得小的 ki 和 hi 先去 list 占位, 保证 list 挤兑后面时不会报 size 校验异常。
  2. 然后利用 list#add 方法的特性，如果有一个元素提前占据了 i 位置，下次再添加元素到 i 位置时，会把之前的元素往后挤兑，所以由于原数组 hi 从大到小排序，相同 hi 的 ki 从小到大排序，因此：
     1. 没有冲突时，可认为数组中 i 元素就排第 i 位，此时相同 hi 大 ki 元素肯定会放置在小 ki 元素的后面。
     2. 发生位置冲突，后面添加的小 hi 元素会把以前大 hi 的元素挤兑，从而保证即使元素后挪了，但 ki 仍无需变化，因为前面插入的是 hi 比它小的元素。
- **结论**：时间，5ms，99.70%，空间，42.1mb，5.35%，时间上，根据排序需要 O（n * logn），list#add需要遍历后面 n次为 O（n^2），所以时间复杂度为 O（n * [logn + n]），空间上，由于使用了排序需要递归深度 logn，并且增加了一个 list，所以额外空间复杂度为 O（logn + n）。

```java 
class Solution {
    public int[][] reconstructQueue(int[][] people) {
        if(people == null || people.length == 0 || people[0].length == 0) {
            return new int[0][0];
        }

        // hi从大到小排序, 相同hi的按ki从小到大排序, 使得小的ki和hi先去list占位, 保证list挤兑后面时不会报size校验异常
        Arrays.sort(people, (o1, o2) -> {
            if(o1[0] != o2[0]) {
                return o2[0] - o1[0];
            } else {
                return o1[1] - o2[1];
            }
        });

        // 亲测: ArrayList每次拷贝后面i-1个元素, 效率比LinkedList遍历到i位置然后添加节点的要高20%+
        List<int[]> list = new ArrayList<>(people.length);
        for(int i = 0; i < people.length; i++) {
            list.add(people[i][1], people[i]);
        }

        return list.toArray(new int[list.size()][]); 
    }
}

```

#### 括号

##### 1）括号生成

见《回溯 - 括号生成》。

##### 2）最长有效括号

见《动态规划 - 最长有效括号》。

##### 3）删除无效的括号

见《回溯 - 删除无效的括号》。

#### 回文

##### 1）最长回文子串

###### 暴力求解 | O（n^3）

- **思路**：尝试每一个子串， 并找出最大的回文子串。
- **缺点**：
  1. O（n^3），耗时的地方在于，第一轮判断过的地方，第二轮又重新判断了，而且用缓存法还超时了！
  2. 用了个对象来状态变量，可优化成直接使用变量。
- **结论**：放弃该方法，面试会挂（1211ms，0%）！

```java
class Solution {

    class MaxInfo {
        int start;
        int len;

        MaxInfo(int start, int len) {
            this.start = start;
            this.len = len;
        }
    }

    public String longestPalindrome(String s) {
        if(s == null) {
            return null;
        }
        
        MaxInfo maxInfo = new MaxInfo(0, 1);
        char[] chars = s.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            for(int j = 1; j <= chars.length - i; j++) {
                if(isPalindrome(chars, i, i + j - 1) && j > maxInfo.len) {
                    maxInfo.start = i;
                    maxInfo.len = j;
                }
            }
        }

        return s.substring(maxInfo.start, maxInfo.start + maxInfo.len);
    }

    private boolean isPalindrome(char[] chars, int start, int end) {
        if(start == end) {
            return true;
        }
        while(start < end) {
            if(chars[start++] != chars[end--]) {
                return false;
            }
        }
        return true;
    }
}

```

###### 马拉车算法 Manacher | O（n）

- **概念**：

  1. **回文半径 r**：指 i 从自身开始算作 1，向外每成功回文一次，则 r + 1。
  2. **回文直径 d**：指 i 向外回文范围内，囊括的字符数。
  3. **回文半径数组 arr**：指从左到右遍历过程中，搜集到的回文半径数组。
  4. **最大回文右边界 R**：指从左到右遍历过程中，回文边界出现得最远的索引位置。
  5. **最大回文右边界中心点 c**：指 R 更新过程中，对应的中心点出现的索引位置。

- **结论**：

  1. **右 r（i） > R**：R 和  c 暴力往右扩。

  2. **右 r（i）<= R**：此时，在 d（c）范围内，出现了 i 的对称点 i' 以及 c 的左边界 L。

     1. **L < 左 r（i'） < c < 右 r（i‘） < R**：说明 i 与 i' 字符数组成逆序关系，r（i） == r（i'），此时不用遍历，可以直接计算得到。

        - **证明**：X != Y，Y == Z，X == L => Z != L。

          ![1641481121818](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641481121818.png)

     2. **左 r（i’）< L <  c**：r（i）= R - i，此时不用遍历，可以直接计算得到。

        - **证明**：X == Y，Y == Z，X != P => Z != P。

          ![1641481747755](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641481747755.png)

     3. **左 r（i'）== L < c**：r（i）部分在 R 内，这段不用遍历，可以直接计算得到，但实际有多远不知道，因此，需要 r（i） 初始值等于 R - i，从 R 位置开始暴力扩。

        - **证明**：就像是 （2）情况 i' 的镜像。

```java
class Solution {
    public String longestPalindrome(String s) {
        if(s == null) {
            return null;
        }
        if("".equals(s) ||  s.length() == 1) {
            return s;
        }

        char[] chars = getManacherChars(s);
        int[] rArr = new int[chars.length];// 回文半径数组
        int R = -1, c = -1;// 最大回文右边界、最大回文右边界中心点
        int maxIndex = -1, max = Integer.MIN_VALUE;// 最大回文半径, 最大回文半径索引
        
        for(int i = 0; i < chars.length; i++) {
            // i' = 2 * c - i, R - i 为 i 到最大回文右边界的距离
            // i < R, 代表 i 在 c 的回文半径内, 为了囊口 r(i) > L、r(i) < L 两种情况, 使用了Math.min结合在了一起, 否则则初始化 rArr[i]
            rArr[i] = i < R? Math.min(rArr[2 * c - i], R - i) : 1;

            // r(i) > R 则暴力扩、r(i) = L 则初始值等于 R - i，从 R 位置开始暴力扩
            while(i + rArr[i] < chars.length && i - rArr[i] > -1) {
                if(chars[i + rArr[i]] == chars[i - rArr[i]]) {
                    rArr[i]++;
                } else {
                    break;
                }
            }

            // 暴力扩出 R 范围，则同时更新 R 和 c 的值
            if(i + rArr[i] > R) {
                R = i + rArr[i];
                c = i;
            }

            // 获取最大回文右边界、最大回文右边界对应的索引
            if(rArr[i] > max) {
                maxIndex = i;
                max = rArr[i];
            }
        }

        return getSubString(chars, maxIndex, max);
    }

    private String getSubString(char[] chars, int maxIndex, int max) {
        StringBuilder sb = new StringBuilder();

        // 偶数位为'#'
        for(int i = maxIndex - (max - 1); i < maxIndex + (max - 1); i++) {
            if((i & 1) == 1) {
                sb.append(chars[i]);
            }
        }

        return sb.toString();
    }

    // 获取马拉车字符数组
    private char[] getManacherChars(String s) {
        char[] chars = s.toCharArray();
        char[] res = new char[chars.length * 2 + 1];
        
        // 偶数位添加'#'
        int index = 0;
        for(int i = 0; i < res.length; i++) {
            res[i] = (i & 1) == 0? '#' : chars[index++];
        }

        return res;
    }
}

```

###### 中心点向外扩散 | O（n^2）

- **思路**：启发于马拉车算法，但好处在于实现简单，利用中心向外扩散 + 奇数位置为正常字符的原理进行实现。
- **缺点**：由于中心向外扩时，没研究 i 与 i' 的回文半径关系，导致每个字符都需要重新从中心向外扩散一次，时间复杂度（21ms，87%）比马拉车（7ms，96%）高了不少。
- **结论**：面试写的步骤可以循序渐进，从暴力求解 -> 中心点向外扩散 -> 马拉车优化。

```java
class Solution {
    
    public String longestPalindrome(String s) {
        if(s == null) {
            return null;
        }
        if("".equals(s) ||  s.length() == 1) {
            return s;
        }

        int maxIndex = -1, max = Integer.MIN_VALUE;
        char[] chars = getManacherChars(s);
        for(int i = 0; i < chars.length; i++) {
            for(int len = 1; i - len > -1 && i + len < chars.length; len++) {
                if(chars[i-len] != chars[i+len]) {
                    break;
                } else if(len + 1 > max) {
                    max = len + 1;
                    maxIndex = i;
                }
            }
        }

        return getSubString(chars, maxIndex, max);
    }
}

```

##### 2）回文子串

###### 暴力解法 | O（n^3）

- **思路**：枚举每个子串，然后判断是否为回文串，是的话则 count++，统计好后在最后返回即可。
- **结论**：时间，95ms，9.10%，空间，39.2mb，12.73%，时间上，枚举子串需要 O（n^2），判断回文需要 O（n），所以总的时间复杂度为 O（n^3），空间上，由于只使用有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        int count = 0;
        char[] chars = s.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            for(int j = i; j < chars.length; j++) {
                if(isPalindrome(chars, i, j)) {
                    count++;
                }
            }
        }

        return count;
    }

    private boolean isPalindrome(char[] chars, int start, int end) {
        if(start == end) {
            return true;
        }
        while(start < end) {
            if(chars[start++] != chars[end--]) {
                return false;
            }
        }
        return true;
    }
}

```

###### 暴力递归 | O（n^3）

- **思路**：与暴力解法思路一样，都是枚举所有子串，然后判断子串是否为回文子串，但不同的是，这里判断回文子串使用的递归的方式判断，也就是还存在优化的可能性。
- **结论**：时间，340ms，6.19%，空间，39.4mb，11.62%，时间上，枚举所有子串需要花费 O（n^2），判断子串是否为回文需要 O（n），所以时间复杂度为 O（n^3），空间上，由于判断子串是否为回文最大递归深度为 logn，所以额外空间复杂度为 O（logn）。

```java
class Solution {
    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        int count = 0;
        char[] chars = s.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            for(int j = i; j < chars.length; j++) {
                if(f(chars, i, j)) {
                    count++;
                }
            }
        }

        return count;
    }

    private boolean f(char[] chars, int i, int j) {
        if(i >= j) {
            return true;
        }
        return chars[i] == chars[j] && f(chars, i+1, j-1);
    }
}

```

###### 记忆化搜索 | O（n^2）

- **思路**：在暴力递归的基础上，增加了 dp 一维表缓存，如果缓存中存在，则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，18ms，10.75%，空间，46.9mb，5.01%，时间上，由于增加了缓存，使得每次二维表内的元素只会被处理一次，所以时间复杂度为 O（n^2），空间上，由于判断子串是否为回文最大递归深度为 logn，且使用了一张 dp 二维表，所以额外空间复杂度为 O（logn + n^2）。

```java
class Solution {

    private Boolean[][] dp;

    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        char[] chars = s.toCharArray();
        dp = new Boolean[chars.length][chars.length];

        int count = 0;
        for(int i = 0; i < chars.length; i++) {
            for(int j = i; j < chars.length; j++) {
                if(f(chars, i, j)) {
                    count++;
                }
            }
        }

        return count;
    }

    private boolean f(char[] chars, int i, int j) {
        if(i >= j) {
            dp[i][j] = true;
            return dp[i][j];
        }
        if(dp[i][j] != null) {
            return dp[i][j];
        }

        dp[i][j] = chars[i] == chars[j] && f(chars, i+1, j-1);
        return dp[i][j];
    }
}

```

###### 严格表结构优化 | O（n^2 + n^2）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现一个值依赖它的左下一个值，所以这是一个从下往上、从左往右的 dp 模型，因此，需要先初始化好左下半部分，然后再设置右上半部分。
- **结论**：时间，6ms，51.77%，空间，41mb，8.96%，时间上，由于初始化 dp 花费了 O（n^2），枚举并判断每个子串是否为回文串花费了 O（n^2），所以时间复杂度为 O（n^2 + n^2），空间上，由于使用了一张 dp 二维表，所以额外空间复杂度为 O（n^2）。

```java
class Solution {
    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        char[] chars = s.toCharArray();
        boolean[][] dp = new boolean[chars.length][chars.length];

        // 初始化左下半部分
        for(int i = 0; i < dp.length; i++) {
            for(int j = 0; j <= i; j++) {
                dp[i][j] = true;
            }
        }

        // 从下往上、从左往右初始化右上半部分
        for(int i = dp.length-2; i > -1; i--) {
            for(int j = i + 1; j < dp[0].length; j++) {
                dp[i][j] = chars[i] == chars[j] && dp[i+1][j-1];
            }
        }

        int count = 0;
        for(int i = 0; i < chars.length; i++) {
            for(int j = i; j < chars.length; j++) {
                if(dp[i][j]) {
                    count++;
                }
            }
        }

        return count;
    }
}

```

###### 中心点向外扩散 | O（n^2）

- **思路**：同暴力解法的思路，都是通过枚举所有子串，然后判断是否为回文串，不过这里的思路是根据中心点的位置来枚举，分为奇数时的中心点位置（索引本身位置）和偶数时的中心点位置（索引本身位置 + 索引前一个位置），然后判断回文串也是使用中心点扩散法来判断~
- **结论**：时间，1ms，99.88%，空间，39.3mb，12.87%，时间上，由于需要枚举两次所有中心点位置的子串 O（2 * n），每次判断子串是否回文需要 O（n），所以时间复杂度为 O（2 * n^2），空间上，由于只使用有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        int n = s.length();
        char[] chars = s.toCharArray();

        // 枚举所有奇数中心点
        int count = 0, wl, wr;
        for(int i = 0; i < n; i++) {
            wl = wr = i;
            while(wl > -1 && wr < n && chars[wl] == chars[wr]) {
                count++;
                wl--;
                wr++;
            }
        }

        // 枚举所有偶数中心点
        for(int i = 1; i < n; i++) {
            wl = i - 1;
            wr = i;
            while(wl > -1 && wr < n && chars[wl] == chars[wr]) {
                count++;
                wl--;
                wr++;
            }
        }

        return count;
    }
}

```

###### 马拉车算法 Manacher | O（n）

- **思路**：马拉车算法可以在 O（n）时间内求得马拉车字符数组中，每个位置 i 的回文半径 r，而 r 的一半就正是原本字符数组中《中心向外扩散》的最远距离，也就是枚举每个 i 为中心向外扩散时的 count，因此，累加每个 r/2 则得到 最终答案，其中马拉车算法的证明见《最长回文子串 - 马拉车算法 Manacher》。
- **结论**：时间，1ms，99.88%，空间，39.6mb，10.72%，时间上，由于回文半径只会增加不会减少，也就是生成回文半径时，每个字符只会被访问一次，要么用于计算出来，要么用于暴力扩，而马拉车字符数组中增加的 '#' 个数为 n+1 个，所以遍历马拉车字符数组的时间复杂度为 O（2n +1），空间上，由于构建了马拉车字符数组 O（2n + 1），以及回文半径数组 O（2n +1），所以额外空间复杂度为 O（4n +2）。

```java
class Solution {
    public int countSubstrings(String s) {
        if(s == null || s.length() == 0) {
            return 0;
        }

        char[] chars = getManacherChars(s);
        int[] rArr = new int[chars.length];// 回文半径数组
        int R = -1, c = -1;// 最大回文右边界、最大回文右边界中心点
        int count = 0;
        
        for(int i = 0; i < chars.length; i++) {
            // i' = 2 * c - i, R - i 为 i 到最大回文右边界的距离
            // i < R, 代表 i 在 c 的回文半径内, 为了囊口 r(i) > L、r(i) < L 两种情况, 使用了Math.min结合在了一起, 否则则初始化 rArr[i]
            rArr[i] = i < R? Math.min(rArr[2 * c - i], R - i) : 1;

            // r(i) > R 则暴力扩、r(i) = L 则初始值等于 R - i，从 R 位置开始暴力扩
            while(i + rArr[i] < chars.length && i - rArr[i] > -1) {
                if(chars[i + rArr[i]] == chars[i - rArr[i]]) {
                    rArr[i]++;
                } else {
                    break;
                }
            }

            // 暴力扩出 R 范围，则同时更新 R 和 c 的值
            if(i + rArr[i] > R) {
                R = i + rArr[i];
                c = i;
            }

            // 除2是为了得到真实的回文个数: 因为有一半的'#'不是原来的子串
            count += rArr[i] / 2;
        }

        return count;
    }

    // 获取马拉车字符数组
    private char[] getManacherChars(String s) {
        char[] chars = s.toCharArray();
        char[] res = new char[chars.length * 2 + 1];
        
        // 偶数位添加'#'
        int index = 0;
        for(int i = 0; i < res.length; i++) {
            res[i] = (i & 1) == 0? '#' : chars[index++];
        }

        return res;
    }
}

```

#### 编辑距离

##### 1）最小覆盖字串

见《滑动窗口 - 最小覆盖字串》。

##### 2）找到字符串中所有字母异位词

见《滑动窗口 - 找到字符串中所有字母异位词》。

#### 子串/子序列/子数组

##### 1）最长回文子串

见《回文 - 最长回文子串》。

##### 2）最长有效括号

见《括号 - 最长有效括号》。

##### 3）最大子数组和

见《动态规划 - 最大子数组和》。

##### 4）最小覆盖子串

见《滑动窗口 - 最小覆盖子串》。

##### 5）子集

见《回溯 - 子集》。

##### 6）乘积最大子数组

见《动态规划 - 乘积最大子数组》。

##### 7）分割等和子集

见《动态规划 - 分割等和子集》。

##### 8）和为 k 的子数组

见《n 数之和 - 和为 k 的子数组》。

##### 9）最短无序连续子数组

###### 暴力解法 | O（n * logn + 2n）

- **思路**：先复制出来一个数组，然后排好序，接着左右指针遍历原数组，如果对比排序数组发现当前值已经位于最终位置时，则 l++ 或者 r--，直到 l 和 r 重逢或者发现位置不合适，然后返回之间的长度，但要注意的是，如果 l 和 r 最终重逢了，说明原数组本身就有序，此时应该返回 0，而不是计算长度的结果 1。
- **结论**：时间，7ms，20.76%，空间，42.7mb，5.01%，时间上，由于复制数组需要 O（n），排序需要 O（n * logn），左右指针移动需要 O（n），所以时间复杂度为 O（n * logn + 2n），空间上，由于额外建立了一个数组 n，排序需要的递归深度 logn，所以额外空间复杂度为 O（n + logn）。

```java
class Solution {
    public int findUnsortedSubarray(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return 0;
        }

        int[] sorteds = new int[nums.length];
        for(int i = 0; i < nums.length; i++) {
            sorteds[i] = nums[i];
        }
        Arrays.sort(sorteds);

        int l = 0, r = nums.length-1;
        while(l < r) {
            if(nums[l] == sorteds[l]) {
                l++;
                if(nums[r] == sorteds[r]) {
                    r--;
                }
                continue;
            }
            if(nums[r] == sorteds[r]) {
                r--;
                if(nums[l] == sorteds[l]) {
                    l++;
                }
                continue;
            }
            break;
        }

        return r == l? 0 : r - l + 1;
    }
}

```

###### 不等式法 | O（2n）

- **思路**：研究数据状态发现，最短无序子数组的右边界，必定满足右边界 nums[i] <  nums[i-1]，同理其左边界也必定满足，左边界 nums[j] > nums[j+1]，因此，可以先遍历找出其右边界，再找出其左边界，然后获取其长度即可。
- **结论**：时间，0ms，100%，空间，41.5mb，8.90%，时间上，由于需要遍历两次数组，所以时间复杂度为 O（2n），空间上，由于只有使用有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int findUnsortedSubarray(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return 0;
        }

        // 右边第一个不符合 r >= l 不等式的下标为右边界
        int lmax = Integer.MIN_VALUE, rres = 0;
        for(int i = 0; i < nums.length; i++) {
            if(nums[i] >= lmax) {
                lmax = nums[i];
            } else {
                rres = i;
            }
        }

        // 左边第一个不符合 l <= r 不等式的下标为左边界
        int rmin = Integer.MAX_VALUE, lres = 0;
        for(int i = nums.length - 1; i > -1; i--) {
            if(nums[i] <= rmin) {
                rmin = nums[i];
            } else {
                lres = i;
            }
        }
        
        return lres >= rres? 0 : rres - lres + 1;
    }
}

```

#### 背包问题

##### 1）零钱兑换 | 完全背包问题

见《动态规划 - 零钱兑换》。

##### 2）分割等和子集 | 01背包问题

见《动态规划 - 分割等和子集》。

##### 3）目标和

见《动态规划 - 目标和》。

#### 买卖股票

##### 1）买卖股票的最佳时机

见《毁天灭地式问题 - 买卖股票的最佳时机》。

#### 斐波那契数列

##### 1）爬楼梯

###### 暴力递归 | Master 公式

- **思路**：如果每步只可以爬 1 阶 或者 2 阶，要爬上第 n 阶楼梯，则可以认为从 n-1 阶爬 1 阶爬上来的，或者从 n-2 阶爬 2 阶爬上来的，所以总和为 f（n-1）+ f（n-2）。
- **结论**：执行超时，是由于 f（n-1）和 f（n-2）有很多重复的递归操作，这可以用记忆化搜索来优化。

```java
class Solution {
    public int climbStairs(int n) {
        if(n == 0 || n == 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }
        return climbStairs(n-1) + climbStairs(n-2);
    }
}

```

###### 记忆化搜索 | O（n）

- **思路**：
  1. 基于暴力递归的基础上，增加了 dp 一维表缓存，如果缓存中存在则从缓存获取，否则返回前先设置结果到缓存再返回。
  2. 并且，发现 n=0,1,2 是不需要缓存的，可以直接返回，此时 dp 缓存也就可以减少前 3 个格子，以节省空间的使用。
- **结论**：时间，0ms，100%，34.9mb，92.24%，效率非常高，应该是最优解了。

```java
class Solution {
    public int climbStairs(int n) {
        if(n == 0 || n == 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }
        
        int[] dp = new int[n-2];
        Arrays.fill(dp, -1);
        return f(dp, n);
    }

    private int f(int[] dp, int n) {
        if(n < 0) {
            return 0;
        }
        if(n == 0 || n == 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }
        if(dp[n-3] != -1) {
            return dp[n-3];
        }

        dp[n-3] = f(dp, n-1) + f(dp, n-2);
        return dp[n-3];
    }
}

```

#### 其他二叉树问题

##### 1）不同的二叉搜索树

见《动态规划 - 不同的二叉搜索树》。

##### 2）验证二叉搜索树

见《树形 dp - 验证二叉搜索树》。

##### 3）二叉树的最大深度

###### 深度优先搜索 | O（n）

- **思路**：
  1. 定义一个 f（root，curlevel）函数，用于获取 root 的最大深度。
  2. 这样每来到一个 root 节点时，都可以先拿左右孩子的最大深度，然后比较当前的深度，最后返回个最大的深度即可。
- **结论**：时间，0ms，100%，38mb，91.85%，也可以尝试宽度有限遍历实现。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public int maxDepth(TreeNode root) {
        return f(root, 1);
    }

    // f代表获取root的最大深度
    private int f(TreeNode root, int curlevel) {
        if(root == null) {
            return 0;
        }

        int leftMax = f(root.left, curlevel+1);
        int rightMax = f(root.right, curlevel+1);

        return Math.max(curlevel, Math.max(leftMax, rightMax));
    }
}

```

###### 宽度优先搜索 | O（n）

- **思路**：
  1. 宽度优先搜索首先想到的就是用队列，首先把根节点加入队列，然后出队时不断把左、右孩子加入队列，循环往复。
  2. 不过如果要返回最大深度，则还要通过使用哈希表，提前记录好节点的层数，再节点出队时与当前层数变量相比较，如果比较发现层数不一样，那么说明来到下一层了，然后更新当前层数的值，最后返回拿到的当前层数的值即可。
- **结论**：时间，3ms，21.57%，空间，38.2mb，73.07%，可见面对求最大深度的问题，深度优先搜索比宽度优先搜索，无论是在时间上，还是在空间上都更有优势！

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public int maxDepth(TreeNode root) {
        if(root == null) {
            return 0;
        }

        Map<TreeNode, Integer> map = new HashMap<>();
        LinkedList<TreeNode> queue = new LinkedList<>();
        if(root != null) {
            map.put(root, 1);
            queue.offer(root);
        }

        int curlevel = 1, level;
        while(!queue.isEmpty()) {
            root = queue.poll();
            if(root != null) {
                level = map.get(root);
                if(level != curlevel) {
                    curlevel++;
                }
                if(root.left != null) {
                    map.put(root.left, level+1);
                    queue.offer(root.left);
                }
                if(root.right != null) {
                    map.put(root.right, level+1);
                    queue.offer(root.right);
                }
            }
        }

        return curlevel;
    }
}

```

##### 4）对称二叉树

###### 深度优先搜索1 | O（2n）

- **思路**：
  1. 观察对称二叉树可以发现，它的中序遍历也是对称的，因此可以沿用中序遍历的套路收集到一个 list 中，最后再作判断。
  2. 其中要注意的是，由于要求是对称的，也就是左对右、右对左，因此，list 收集到的元素是要有方向标识的，这里采用了 val * 1 代表左，val * （-1）代表右，而刚开始的 root.val 不变。
  3. 这样在最后对 list 做判断时，就需要双指针从两个不同的方向判断，如果除中间外，处处左右值相加和为 0，且中间的位置等于 root.val，那么就说明确实是棵对称二叉树，否则就不是。 
- **结论**：时间，1ms，24.74%，空间，37.9mb，6.50%，可能是因为做了两次遍历，时间复杂度为 O（2n），所以效率不是那么高？

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public boolean isSymmetric(TreeNode root) {
        if(root == null) {
            return true;
        }

        List<Integer> res = new ArrayList<>();
        f(root, res, true);

        int i = 0, j = res.size() - 1, sum = 0;
        while(i < j) {
            sum += res.get(i++) + res.get(j--);
            if(sum != 0) {
                return false;
            }
        }

        return res.get(i) == root.val;
    }

    private void f(TreeNode root, List<Integer> res, boolean isLeft) {
        if(root == null) {
            return;
        }

        f(root.left, res, true);// * 1
        res.add(isLeft? root.val : -root.val);
        f(root.right, res, false);// * (-1)
    }
}

```

###### 深度优先搜索2 | O（n）

- **思路**：
  1. 同样是深度优先搜索，但该思路不同于第一种深度优先搜索的思路，将不再拘泥于取到数值后再判断是否对称，而是在遍历过程中就判断到是否为对称，这样做的好处一来简单好实现，二来如果发现不对称，则可以提前返回结果，而不用等到全部遍历完再做处理，提升了效率。
  2. 由于要求的是判断是否为对称二叉树，也就是左.val == 右.val、左.left.val == 右.right.val、左.right.val == 右.left.val，则为对称二叉树，否则就不是。
- **结论**：
  1. 时间，0ms，100%，36.3mb，84.68%，可见对比第一种深度优先搜索，这种边递归边判断的方式大大提高了效率。
  2. 在最坏的情况下，树是链表的形状，使得整个递归深度等于节点的个数，因此额外空间复杂度也为 O（n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public boolean isSymmetric(TreeNode root) {
        if(root == null) {
            return true;
        }
        if(root.left == null && root.right == null) {
            return true;
        }
        if(root.left != null && root.right != null) {
            return f(root.left, root.right);
        }
        return false;
    }

    // f函数用于判断t1和t2是否互为镜像, 也就是t1==t2, t1.l == t2.r, t1.r == t2.l
    private boolean f(TreeNode t1, TreeNode t2) {
        if(t1 == null && t2 == null) {
            return true;
        } else if(t1 != null && t2 != null) {
            if(t1.val != t2.val) {
                return false;
            } else {
                return f(t1.left, t2.right) && f(t1.right, t2.left);
            }
        } else {
            return false;
        }
    }
}

```

###### 宽度优先搜索 | O（n）

- **思路**：宽度优先搜索首先想到的就是队列，但与层序遍历不同的是，由于这里要判断的是否为对称二叉树，所以要交叉比较，而不是顺序加入节点，即先加入 t1.left 和 t2.right，再加入 t1.right 和 t1.left。
- **结论**：时间，1ms，24.68%，37.6mb，20.57%，虽然时间复杂度也是 O（n），但由于使用了额外的数据结构，使得时间上不如深度优先搜索2（系统压栈）来的快？以及额外空间使用了队列，所以也是 O（n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public boolean isSymmetric(TreeNode root) {
        if(root == null) {
            return true;
        }
        if(root.left == null && root.right == null) {
            return true;
        }
        if(root.left != null && root.right != null) {
            Queue<TreeNode> queue = new LinkedList<>();
            queue.offer(root.left);
            queue.offer(root.right);

            TreeNode t1, t2;
            while(!queue.isEmpty()) {
                t1 = queue.poll();
                t2 = queue.poll();

                if(t1 == null && t2 == null) {
                    continue;    
                }
                else if(t1 != null && t2 != null) {
                    if(t1.val != t2.val) {
                        return false;
                    }
                    queue.offer(t1.left);
                    queue.offer(t2.right);
                    queue.offer(t1.right);
                    queue.offer(t2.left);
                }
                else {
                    return false;     
                }
            }

            return true;
        }
        
        return false;
    }
}

```

##### 5）二叉树中的最大路径和

见《树形 dp - 二叉树中的最大路径和》。

##### 6）二叉树的最近公共祖先

###### 迭代法 | O（n + p + q）

- **思路**：
  1. 先使用任意遍历，建立好 fatherMap，代表所有节点的父结点集合。
  2. 然后把求二叉树最低公共祖先的问题，转换为求两单链表的相交节点问题，即利用 fatherMap 先装好 p 到根节点一路上所经过的所有节点在 HashSet 中，然后在利用 father 网上遍历 q 的过程中，判断是否有节点出现在提前装好的 HashSet 中，其中第一个出现的节点就是它们的最近公共祖先。
- **结论**：时间，10ms，16.77%，空间，42.1mb，5.00%，时间上，遍历二叉树花费了 O（n），往上遍历 p 花费了 O（p），往上遍历 q 花费了 O（q），所以总共的时间复杂度为 O（n + p + q），空间上，遍历二叉树的递归深度为 O（logn），而且还是用了一个 fatherMap O（n）和一个 HashSet O（p），所以总共的额外空间复杂度为 O（logn + n + p）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode(int x) { val = x; }
 * }
 */
class Solution {
    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {
        if(root == null || p == null || q == null) {
            return null;
        }

        Map<TreeNode, TreeNode> fatherMap = new HashMap<>();
        fatherMap.put(root, root);
        preOrderTravel(root, fatherMap);

        TreeNode node;
        Set<TreeNode> set = new HashSet<>();
        while(p != (node = fatherMap.get(p))) {
            set.add(p);
            p = node;
        }
        set.add(p);

        while(q != (node = fatherMap.get(q))) {
            if(set.contains(q)) {
                return q;
            }
            q = node;
        }
        if(set.contains(q)) {
            return q;
        }

        return null;
    }

    private void preOrderTravel(TreeNode root, Map<TreeNode, TreeNode> fatherMap) {
        if(root == null) {
            return;
        }

        fatherMap.put(root.left, root);
        fatherMap.put(root.right, root);

        preOrderTravel(root.left, fatherMap);
        preOrderTravel(root.right, fatherMap);
    }
}

```

###### 递归法 | O（n）

- **思路**：
  1. 分析二叉树任意节点的最低公共祖先，一共有 3 种情况：
     1. p 是 q 的最低公共祖先，此时 p 的父结点调用递归函数，一边返回结果 p，而另一边返回结果则是 null，代表没有 p 和 q 节点出现。
     2. q 是 p 的最低公共祖先，此时 q 的父结点调用递归函数，一边返回结果 q，而另一边返回结果则是 null，代表没有 p 和 q 节点出现。
     3. p 不是 p 的最低公共祖先，q 也不是 p 的最低公共祖先，此时公共父节点调用递归函数，一边返回结果 p，而另一边返回结果则是 q。
  2. 可见，递归函数实现为，如果两边的返回结果同时不为 null，则说明本节点为 p 和 q 的最低公共祖先；否则如果左边结果不为 null，右边结果为 null，则返回左边结果；如果右边结果不为 null，左边结果为 null，则返回右边结果。
- **结论**：时间，6ms，100%，空间，43mb，5.00%，时间上，由于只需要遍历一次二叉树，所以时间复杂度为 O（n），空间上，递归最大深度为 O（logn），所以额外空间复杂度为 O（logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode(int x) { val = x; }
 * }
 */
class Solution {
    public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {
        if(root == null) {
            return null;
        }
        if(p == root || q == root) {
            return root;
        }
        
        TreeNode leftLca = lowestCommonAncestor(root.left, p, q);
        TreeNode rightLca = lowestCommonAncestor(root.right, p, q);

        if(leftLca != null && rightLca != null) {
            return root;
        }

        return leftLca != null? leftLca : rightLca;
    }
}

```

##### 7）二叉树的序列化与反序列化

###### 深度优先搜索 | O（n）& O（n）

- **思路**：
  1. 序列化过程：深度优先搜索首先想到的是先序遍历，在遍历过程中搜集 val+","，如果碰到 null 则序列化为 "null" 即可。
  2. 反序列化过程：由于序列化过程是用栈实现的，所以反序列过程也用栈，也就是递归实现，但要注意的点是不能使用普通类型的 i 表示当前字符串数组读取的进度，因为读取左节点字符串回来后，并不知道读到哪里了，所以需要用一个对象比如题目给出的 TreeNode，用 TreeNode.val 来跟踪字符串读取的进度即可。
- **结论**：时间，6ms，98.21%，空间，43mb，5.02%，时间上，序列化和反序列化都只需要遍历一次二叉树的所有节点即可，所以时间复杂度为 O（n），空间上，额外空间复杂度取决于递归深度+字符串数组，为 O（logn + n），不过再尝试一下广度优先搜索方式的实现看看。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode(int x) { val = x; }
 * }
 */
public class Codec {

    // Encodes a tree to a single string.
    public String serialize(TreeNode root) {
        StringBuilder sb = new StringBuilder();
        sf(root, sb);
        return sb.toString().substring(0, sb.length()-1);
    }

    private void sf(TreeNode root, StringBuilder sb) {
        if(root == null) {
            sappend(sb, "null");
            return;
        }
        
        sappend(sb, String.valueOf(root.val));
        sf(root.left, sb);
        sf(root.right, sb);
    }

    private void sappend(StringBuilder sb, String value) {
        sb.append(value).append(",");
    }

    // Decodes your encoded data to tree.
    public TreeNode deserialize(String data) {
        if(data == null || data.length() == 0) {
            return null;
        }
        return df(data.split(","), new TreeNode(0));
    }

    private TreeNode df(String[] strs, TreeNode c) {
        if(c.val >= strs.length) {
            return null;
        }
        if("null".equals(strs[c.val])) {
            return null;
        }

        // 反序列化根节点
        TreeNode root = new TreeNode(Integer.valueOf(strs[c.val]));

        // 反序列化左孩子
        c.val++;
        root.left = df(strs, c);

        // 反序列化右孩子
        c.val++;
        root.right = df(strs, c);

        // 返回根节点
        return root;
    }
}

// Your Codec object will be instantiated and called as such:
// Codec ser = new Codec();
// Codec deser = new Codec();
// TreeNode ans = deser.deserialize(ser.serialize(root));

```

###### 宽度优先搜索 | O（n）& O（n）

- **思路**：
  1. 序列化过程：宽度优先搜索首先想到的是队列与层次遍历，在遍历过程中搜集 val+","，如果碰到 null 则序列化为 "null" 即可。
  2. 反序列化过程：由于序列化过程是用队列实现的，所以反序列过程也用队列，也就是 while 循环，不过队列存放的是根节点，在循环遍历序列化字符串过程中，先从队列取出当前要处理的根节点（必不为 null，因为是只有不为 null 的节点才加入队列的），然后字符串数组指针右移动处理左孩子和右孩子，同样如果碰到 null 则不做任何处理，否则处理完后把它们又当做根节点加入队列，周而复始。
- **结论**：时间，14ms，66.76%，空间，42.6mb，5.02%，时间上，序列化和反序列化都只需要遍历一次二叉树的所有节点即可，所以时间复杂度为 O（n），空间上，由于序列化和反序列化都使用了一个队列和一个字符串数组，额外空间复杂度为 O（2n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode(int x) { val = x; }
 * }
 */
public class Codec {

    // Encodes a tree to a single string.
    public String serialize(TreeNode root) {
        Queue<TreeNode> queue = new LinkedList<>();
        queue.offer(root);
        
        StringBuilder sb = new StringBuilder();
        while(!queue.isEmpty()) {
            root = queue.poll();
            sappend(sb, root);
            if(root != null) {
                queue.offer(root.left);
                queue.offer(root.right);
            }
        }

        return sb.toString().substring(0, sb.length()-1);
    }

    private void sappend(StringBuilder sb, TreeNode root) {
        if(root == null) {
            sb.append("null").append(",");
        } else {
            sb.append(root.val).append(",");
        }
    }

    // Decodes your encoded data to tree.
    public TreeNode deserialize(String data) {
        if(data == null || data.length() == 0) {
            return null;
        }

        String[] strs = data.split(",");
        if("null".equals(strs[0])) {
            return null;
        }

        TreeNode root = new TreeNode(Integer.valueOf(strs[0]));
        Queue<TreeNode> fatherQueue = new LinkedList<>();
        fatherQueue.offer(root);
        
        int i = 0;
        TreeNode node;
        while(i < strs.length) {
            node = fatherQueue.poll();

            // 左孩子
            i++;
            if(i < strs.length && !"null".equals(strs[i])) {
                node.left = new TreeNode(Integer.valueOf(strs[i]));
                fatherQueue.offer(node.left);
            }

            // 右孩子
            i++;
            if(i < strs.length && !"null".equals(strs[i])) {
                node.right = new TreeNode(Integer.valueOf(strs[i]));
                fatherQueue.offer(node.right);
            }
        }

        return root;
    }
}

// Your Codec object will be instantiated and called as such:
// Codec ser = new Codec();
// Codec deser = new Codec();
// TreeNode ans = deser.deserialize(ser.serialize(root));

```

##### 8）打家劫舍3

见《树形 dp - 打家劫舍3》。

##### 9）路径总和3

见《树形 dp - 路径总和3》。

##### 10）把二叉搜索树转换为累加树

###### 深度优先搜索 - 局部变量法 | O（n）

- **思路**：
  1. 设计一个 f（root，rsum）函数，代表右孩子累加 rsum，当前节点累加右孩子 + rsum，左孩子累加右孩子 + rsum + 当前节点。
  2. f 函数分为 3 个累加部分，首先累加右孩子，然后把结果累加到当前节点上，最后再把当前节点累加后的结果累加到左孩子上再返回。
- **结论**：时间，0ms，100%，空间，41.3mb，7.99%，时间上，由于需要遍历整棵树所有节点，所以时间复杂度为 O（n），空间上，由于递归深度最大为 logn，所以额外空间复杂度为 O（logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    public TreeNode convertBST(TreeNode root) {
        f(root, 0);
        return root;
    }

    // f代表右孩子累加 rsum，当前节点累加右孩子 + rsum，左孩子累加右孩子 + rsum + 当前节点
    private int f(TreeNode root, int rsum) {
        // 当前为叶子节点, 没当前、没左、没右, 累加和为rsum自己
        if(root == null) {
            return rsum;
        }

        // 当前 + 获取右边累加后的rsum: 包括所有右孩子的左孩子们的累加!
        root.val += f(root.right, rsum);

        // rusm累加完左孩子后, 返回给父节点, 因为当前左孩子也会大于等于父节点的!
        return f(root.left, root.val);
    }
}

```

###### 深度优先搜索 - 全局变量法 | O（n）

- **思路**：
  1. 与局部变量法的思路一样，也是反中序遍历，即右中左，因此，可以把 sum 累加变量放到全局变量上，然后递归函数调用就不用使用 int 参数和返回 int 值了，递归调法也类似，即先累加右、再右累加中、再右+中累加左再返回。
  2. 不过，虽然左边统统累加了右边，但如果左边负得过于小，而右边正得也不大，那么最后形成的也不一定是倒叙的二叉搜索树，所以两者没什么关联~
- **结论**：时间，0ms，100%，空间，41.5mb，6.15%，时间上，由于需要遍历整棵树所有节点，所以时间复杂度为 O（n），空间上，由于递归深度最大为 logn，所以额外空间复杂度为 O（logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    private int sum = 0;

    public TreeNode convertBST(TreeNode root) {
        if(root == null) {
            return null;
        }

        // 先累加右孩子
        convertBST(root.right);

        // 再累加当前节点
        sum += root.val;
        root.val = sum;

        // 最后累加左孩子
        convertBST(root.left);

        return root;
    }
}

```

##### 11）合并二叉树

###### 深度优先搜索 | O（n）

- **思路**：二叉树遍历变种，这里改的是后序遍历，在左右孩子遍历处理完后，处理当前节点，把左右孩子返回的节点 + 当前累加的值，作为新的节点返回。
- **结论**：时间，0ms，100%，空间，41.5mb，5.24%，时间上，由于是后序遍历，其遍历的最大值取决于两棵树中，节点多的那棵树，记 n = max{n1, n2}，所以时间复杂度为 O（n），空间上，额外空间复杂度取决于递归深度，为 O（logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public TreeNode mergeTrees(TreeNode root1, TreeNode root2) {
        if(root1 == null) {
            return root2;
        }
        if(root2 == null) {
            return root1;
        }

        TreeNode lnode = mergeTrees(root1.left, root2.left);
        TreeNode rnode = mergeTrees(root1.right, root2.right);
        return new TreeNode(root1.val + root2.val, lnode, rnode);
    }
}

```

#### 设计题

##### 1）LRU 缓存

###### 暴力解法 | O（1）

- **思路**：利用 LinkedHashMap 已经实现了的 LRU 结构（访问后移回链表末尾，新增后判断是否超出了最大容量，如果超出则删除最久没被访问的元素），其中要注意的细节有：
  1. 初始化时，要保证初始容量不会发生扩容。
  2. 初始化时，要把 accessOrder 改为 true，代表访问时需要把最近访问的 Entry 放回链表末尾。
  3. 初始化时，要重写 `removeEldestEntry(Map.Entry<K,V>)` 方法， 使新增元素之后能够回调删除方法。
  4. 获取元素时，要判断是否已经被删除了，如果已经被删除了，则返回 -1，避免空指针异常。
- **结论**：时间，41ms，98.99%，空间，108.4mb，47.86%，由于使用的是 JDK 实现的 LinkedHashMap，性能自然是十分高的，但面试要求的应该不只是这点，还需要自己把底层也实现出来~

```java
class LRUCache {

    private int maxSize;
    private Map<Integer, Integer> map;

    public LRUCache(int capacity) {
        this.maxSize = capacity;
        this.map = new LinkedHashMap<Integer, Integer>(
           // 相除是为了保证顶格初始容量, 使其对于maxSize不会再扩容了 => 取大于等于临界值的最小值
            (int) Math.ceil(capacity / 0.75f), 0.75f, true) {
            protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
                return map.size() > maxSize;
            }
        };
    }
    
    public int get(int key) {
        Integer res = map.get(key);
        return res != null? res : -1;
    }
    
    public void put(int key, int value) {
        map.put(key, value);
    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */

```

###### 双向链表法 | O（1）

- **思路**：通过双向链表+哈希表模拟实现 LinkedHashMap，即分为 4 种情况：
  1. 新增元素：新增后，节点需要移动至链表末尾，代表最近被访问过，共有 2 种情况，分为新增的是第一个节点，以及新增的不是第一个节点。
  2. 替换元素值：替换节点值后，节点需要移动至链表末尾，代表最近被访问过，共有 3 种情况，分为替换的是头节点、替换的是未节点，以及替换的是中间节点。
  3. 获取元素值：获取节点值后，节点需要移动至链表末尾，代表最近被访问过，共有 2 种情况，分为节点不存在，以及节点存在。
  4. 删除元素：新增节点后，如果当前哈希表的大小 > 最大大小，那么就要触发 LRU 淘汰机制，淘汰最久没被访问过的元素，即把链表表头的元素脱离链表。
- **结论**：时间，49ms，41.69%，空间，111.6mb，29.18%，效率自然就没 JDK 实现的 LinkedHashMap 的高，面试应该到这里就可以了吧~

```java
class LRUCache {

    class Element {
        private Integer value;
        private Element pre;
        private Element next;

        Element(Integer value) {
            this.value = value;
        }
    }

    private int maxSize;
    private Map<Integer, Integer> dataMap;
    private Map<Integer, Element> elementMap;
    private Element head;
    private Element tail;

    public LRUCache(int capacity) {
        this.maxSize = capacity;
        this.dataMap = new HashMap<>((int) Math.ceil(capacity / 0.75f), 0.75f);
        this.elementMap = new HashMap<>((int) Math.ceil(capacity / 0.75f), 0.75f);
    }

    public int get(int key) {
        Integer res = dataMap.get(key);
        if(res == null) {
            return -1;
        }

        // 链接元素到链表末尾
        Element element = elementMap.get(key);
        link2Last(element);

        return res;
    }

    public void put(int key, int value) {
        Element element = elementMap.get(key);

        // 已存在的, 则链接元素到链表末尾
        if(element != null) {
            dataMap.put(key, value);
            link2Last(element);
        }
        // 新增的, 则新增元素到链表末尾
        else {
            element = new Element(key);
            elementMap.put(key, element);
            dataMap.put(key, value);
            nextLast(element);
            
            // 删除头节点
            if(removeEldestEntry()) {
                Element eldest = unlinkFirst();
                elementMap.remove(eldest.value);
                dataMap.remove(eldest.value);
            }
        }
    }

    private boolean removeEldestEntry() {
        return dataMap.size() > maxSize;
    }

    private Element unlinkFirst() {
        Element eldest = head;
        Element next = head.next;
        head.next = null;
        head = next;
        head.pre = null;
        return eldest;
    }

    private void nextLast(Element element) {
        // 如果为第一个节点
        if(head == null) {
            head = tail = element;
            return;
        }

        // 如果不为第一个节点
        tail.next = element;
        element.pre = tail;
        tail = element;
    }

    private void link2Last(Element element) {
        // 如果为头节点
        if(element == head) {
            if(element == tail) {
                return;
            } else {
                head.next.pre = null;
                head = head.next;
                element.pre = tail;
                tail.next = element;
                element.next = null;
                tail = element;
                return;
            }
        }

        // 如果为末尾节点
        if(element == tail) {
            return;
        }

        // 如果为中间节点
        Element pre = element.pre;
        tail.next = element;
        element.pre = tail;
        pre.next = element.next;
        element.next.pre = pre;
        tail = element;
    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */

```

##### 2）最小栈

###### 单调栈法 | O（1）

- **思路**：维护两个栈，一个数据栈，用于记录数据的存放顺序，所有添加的值都要入栈；一个最小单调栈，用于记录最小值，只有在添加的值小于等于单调栈顶时才能入单调栈，否则忽略那个值。
- **结论**：时间，4ms，99.03%，空间，40.5mb，5.01%，效率非常高，就这样吧~

```java
class MinStack {

    private LinkedList<Integer> dataStack;
    private LinkedList<Integer> minStack;

    public MinStack() {
        dataStack = new LinkedList<>();
        minStack = new LinkedList<>();
    }
    
    public void push(int val) {
        dataStack.push(val);
        if(minStack.isEmpty()) {
            minStack.push(val);
        } else {
            if(val <= minStack.peek()) {
                minStack.push(val);
            }
        }
    }
    
    public void pop() {
        int val = dataStack.pop();
        if(val == minStack.peek()) {
            minStack.pop();
        }
    }
    
    public int top() {
        return dataStack.peek();
    }
    
    public int getMin() {
        return minStack.peek();
    }
}

/**
 * Your MinStack object will be instantiated and called as such:
 * MinStack obj = new MinStack();
 * obj.push(val);
 * obj.pop();
 * int param_3 = obj.top();
 * int param_4 = obj.getMin();
 */

```

##### 3）实现 Trie（前缀树）

见《前缀树 - 实现 Trie（前缀树）》。

### 1.3. 技巧角度划分问题？

#### 位运算

##### 1）只出现一次的数字

###### 异或运算法 | O（n）

- **思路**：利用  a ^ b，相同则等于 0，以及 0 ^ a = a 的特点，只需要遍历一遍即可找出答案。
- **结论**：时间，1ms，100%，空间，38.3mb，89.63%，效率非常好，就这样吧~

```java
class Solution {
    public int singleNumber(int[] nums) {
        if(nums == null || nums.length == 0) {
            throw new IllegalArgumentException("参数不合法!");
        }
        
        int index = 1, res = nums[0];
        while(index < nums.length) {
            res ^= nums[index++];
        }

        return res;
    }
}

```

##### 2）比特位计数

###### 内置函数法 | O（n）

- **思路**：从头遍历数组，然后分别调用 Integer.bitCount 方法获取为 1 的比特位即可。
- **结论**：时间，1ms，99.92%，空间，45.3mb，5.29%，时间上，由于只需要遍历一次数组，所以时间复杂度为 O（n），空间上，由于只使用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];
        for(int i = 0; i <= n; i++) {
            res[i] = Integer.bitCount(i);
        }
        return res;
    }
}

```

###### 右位移法 | O（n * logn）

- **思路**：从头遍历每个 i，然后再遍历它的每一位比特位，判断是否为 1，分别统计它们的比特位为 1 的计数，记录到返回结果中再返回即可。
- **结论**：时间，5ms，15.94%，空间，45.2mb，5.78%，时间上，由于遍历一次数组需要花费 O（n），对于最大值为 n 的比特位需要遍历 log（n）位（因为 2^k = n，k = log(n)），所以时间复杂度为 O（n * logn），空间上，由于只使用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];
        
        int count, tmp;
        for(int i = 0; i <= n; i++) {
            count = 0;
            tmp = i;
            do {
                if((tmp & 1) == 1) {
                    count++;
                }
            } while((tmp >>>= 1) > 0);
            res[i] = count;
        }

        return res;
    }
}

```

###### Brian Kernighan 算法 | O（n * logn）

- **思路**：Brian Kernighan （布莱恩·克尼汉）算法给出，对于任意整数 x，令 x = x &（x-1），可将 x 的二进制表示的最后一个 1 变为 0，因此，如果不断循环执行这个过程则可以获得 x 为 1的比特位个数。
- **结论**：时间，1ms，99.92%，空间，45.1mb，6.45%，时间上，由于遍历一次数组需要花费 O（n），对于最大值为 n 的比特位最多遍历 log（n）位（因为 2^k = n，k = log(n)），所以时间复杂度为 O（n * logn），空间上，由于只使用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];

        int count, tmp;
        for(int i = 0; i <= n; i++) {
            count = 0;
            tmp = i;
            while(tmp > 0) {
                tmp &= tmp -1;
                count++;
            }
            res[i] = count;
        }

        return res;
    }
}

```

###### 动态规划 - 最高位 1  | O（n）

- **思路**：利用最高位+杂项来组合成当前的 i，最高位有一个为 1的比特位，而杂项又可以通过数组中以前算过的结果来获取，所以只需要遍历一次即可。
- **结论**：时间，1ms，99.92%，空间，45.3mb，5.64%，时间上，由于只需要遍历 1 次数组，所以时间复杂度为 O（n），空间上，由于只使用了几个有限变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];
        
        int prehval = 0;
        for(int i = 1; i <= n; i++) {
            // i为2的整数次幂, 则设置上一个高位值为i
            if((i & (i-1)) == 0) {
                prehval = i;
                res[i] = 1;
            } 
            // i不是2的整数次幂, 说明除了高位之后, 低位还有一些杂项, 可在以前算过的结果里取
            else {
                res[i] = res[i - prehval] + 1;
            }
        }

        return res;
    }
}

```

###### 动态规划 - 最低位 1 | O（n）

- **思路**：同理，这种解法是利用了最低位 1 的特性，通过判断 i 是否为奇偶数，最低位是否 1，如果为偶数则结果与右移结果一致，如果为奇数则认为比上一个偶数多了一个低位的 1 而已。
- **结论**：时间，1ms，99.92%，空间，45.6mb，5.02%，时间上，由于只需要遍历 1 次数组，所以时间复杂度为 O（n），空间上，由于只使用了几个有限变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];
        for(int i = 1; i <= n; i++) {
            // i为偶数, 说明0位上的bit为0, 此时结果与右移1位的结果一致
            if(i % 2 == 0) {
                res[i] = res[i >>> 1];
            } 
            // i为奇数, 说明0位上的bit为1, 比上一个值多了1个bit
            else {
                res[i] = res[i-1] + 1;
            }
        }

        return res;
    }
}

```

###### 动态规划 - 最右位 1 | O（n）

- **思路**：解本题的关键就在于如果利用好前面 1 的结果来生成本次 1 的结果，同理，本题利用上次最右 1 的结果来生成本次 1 的结果，由 i & (i-1) 可把最右的 1 变为 0，也就是少了一个 1，所以结果取上次的结果加回来就好。
- **结论**：时间，1ms，99.92%，空间，45.4mb吗，5.02%，时间上，由于只需要遍历 1 次数组，所以时间复杂度为 O（n），空间上，由于只使用了几个有限变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int[] countBits(int n) {
        int[] res = new int[n+1];
        
        for(int i = 1; i <= n; i++) {
            res[i] = res[i & (i-1)] + 1;
        }

        return res;
    }
}

```

##### 3）汉明距离

###### 内置函数法 | O（1）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 内置函数》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.1mb，7.67%，时间上，由于内置函数也是位移操作，所以时间复杂度为 O（1），空间上，由于只使用有限几个变量，所以空间复杂度也是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        return Integer.bitCount(x ^ y);
    }
}

```

###### 右位移法 | O（logn）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - 右位移法》的思路解决即可。
- **结论**：时间，0ms，100%，空间，38.6mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        do {
            if((res & 1) == 1) {
                count++;
            }
        } while((res >>>= 1) > 0);
        return count;
    }
}

```

###### Brian Kernighan  算法 | O（logn）

- **思路**：通过异或操作，得到不同 1 的位置后，再利用 《比特位计数 - Brian Kernighan  算法 》的思路解决即可。
- **结论**：时间，0ms，100%，38.5mb，5.04%，时间上，由于最多遍历 logn 位，所以时间复杂度为 O（logn），空间上，由于只使用有限几个变量，所以空间复杂度是 O（1）。

```java
class Solution {
    public int hammingDistance(int x, int y) {
        int res = (x ^ y), count = 0;
        while(res > 0) {
            res &= res - 1;
            count++;
        }
        return count;
    }
}

```

#### 二分查找

##### 1）搜索旋转排序数组

###### 暴力解法 | O（n）

- **思路**：直接遍历找到即返回。
- **结论**：虽然 0ms，100%，但面试中这样写会挂！

```java
class Solution {
    public int search(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        for(int i = 0; i < nums.length; i++) {
            if(target == nums[i]) {
                return i;
            }
        }

        return -1;
    }
}

```

###### 前后遍历法 | <= O（n）

- **思路**：利用旋转数组的特点，如果 target 比末尾的大，说明目标在前面，则可以从头遍历到尾；否则， 如果 target 比 头的大，说明目标在后面，则可以从后往前遍历。
- **结论**：这个方法平均较少了一半的遍历时间，比暴力解法要好，但没用上数组**有序**这个特点，面试会挂！

```java
class Solution {
    public int search(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return -1;
        }
        if(target == nums[0]) {
            return 0;
        }
        if(target == nums[nums.length - 1]) {
            return nums.length - 1;
        }
        
        // 从左到右
        if(target > nums[nums.length - 1]) {
            for(int i = 0; i < nums.length; i++) {
                if(target == nums[i]) {
                    return i;
                }
            }
        }
        
        // 从右到左
        if(target < nums[nums.length - 1]) {
            for(int i = nums.length - 1; i > -1; i--) {
                if(target == nums[i]) {
                    return i;
                }
            }
        }

        return -1;
    }
}

```

###### 递归式二分 | O（logn）

- **思路**：
  1. 观察可得知，该数组从中点切开，必然是一边有序，另一边无序，可以利用这一特性进行二分。
  2. 每次二分先判断到底那边才是有序，如果 l 比 mid 小，说明 mid 分在了左半部分上，即左边有序、右边无序；如果 l 比 mid 大，说明 mid 分在了右半部分上，即右边有序、左边无序。
  3. 然后通过与两个边界（l~mid 或者 mid~r）的大小判断，看 target 是否落在有序的那部分上，如果是那么就对那部分进行二分查找，否则对另一边进行旋转排序数组的查找。
- **结论**：
  1. 二分查找的核心是，每次丢掉一半的数据，本题正是利用了取中点后，一半有序的特点，从而快速知道 target 到底在哪一边，从而可以丢弃掉另一边，完成 O（logn）。
  2. 这里之所以迭代的条件不用 l <= r，而是用  l < r 的原因是，target = l = r 的情况，在当前循环中 target 与 l 和 r 的比较时就判断过了，因此不用 = 的情况就不用再判断了！

```java
class Solution {
    public int search(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        return search(nums, target, 0, nums.length - 1);
    }

    private int search(int[] nums, int target, int l, int r) {
        if(l > r) {
            return -1;
        }
        if(target == nums[l]) {
            return l;
        }
        if(target == nums[r]) {
            return r;
        }

        int mid = (l + r) / 2;
        if(target == nums[mid]) {
            return mid;
        }
        // l比mid小, 说明左边有序
        else if(nums[l] < nums[mid]) {
            // 如果target落在左边有序这部分, 那么则按二分的方式搜索左边
            if(target > nums[l] && target < nums[mid]) {
                return search(nums, target, l, mid-1);
            } 
            // 否则说明target落在右边无序那部分, 则按旋转排序数组进行搜索右边
            else {
                return search(nums, target, mid+1, r);
            }
        }
        // 否则说明右边有序
        else {
            // 如果target落在右边有序这部分, 那么则按二分的方式搜索右边
            if(target > nums[mid] && target < nums[r]) {
                return search(nums, target, mid+1, r);
            } 
            // 否则说明target落在左边无序那部分, 则按旋转排序数组进行搜索左边
            else {
                return search(nums, target, l, mid-1);
            }
        }
    }
}

```

###### 迭代式二分 | O（logn）

- **思路**：
  1. 同递归式的二分查找，只不过是使用了 while 循环来替换递归行为而已，关键点在于先执行一遍再判断 l > r，不然会在一开始就漏掉 l=r 的情况。
  2. 而剩余迭代中，如果还碰到 l > r，则说明 target 是真的不存在了，那时确实是要返回 -1 的。
- **结论**：两种方式都好实现，但还是递归好想，面试时用先递归吧！

```java
class Solution {
    public int search(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        int l = 0, r = nums.length - 1;
        do {
            if(target == nums[l]) {
                return l;
            }
            if(target == nums[r]) {
                return r;
            }

            int mid = (l + r) / 2;
            if(target == nums[mid]) {
                return mid;
            }
            // l比mid小, 说明左边有序
            else if(nums[l] < nums[mid]) {
                // 如果target落在左边有序这部分, 那么则按二分的方式搜索左边
                if(target > nums[l] && target < nums[mid]) {
                    r = mid - 1;
                } 
                // 否则说明target落在右边无序那部分, 则按旋转排序数组进行搜索右边
                else {
                    l = mid + 1;
                }
            }
            // 否则说明右边有序
            else {
                // 如果target落在右边有序这部分, 那么则按二分的方式搜索右边
                if(target > nums[mid] && target < nums[r]) {
                    l = mid + 1;
                } 
                // 否则说明target落在左边无序那部分, 则按旋转排序数组进行搜索左边
                else {
                    r = mid - 1;
                }
            }
        } while(l < r);

        return -1;
    }
}

```

##### 2）在排序数组中查找元素的第一个和最后一个位置

###### 连续二分 | O（logn）

- 思路：
  1. 首先利用二分的思路，找到第一个等于 target 的索引，但由于可能还有多个，则还要找到两头的索引。
  2. 这里是第一次找到后，先从当前位置遍历到最左等于 target 的索引，然后再从找到的地方（mid）+1~r，找最右的指针。
  3. 同时，使用了一个 isFirst 的变量，代表是否第一次找到，如果是第一次找到则需要遍历最左索引，其他次都是只用寻找最后的索引即可。
- **结论**：最坏的情况是 O（n / 2），即找到了 mid 就等于 target，然后一直遍历到最左，其他次递归都是二分为 O（logn），不是很好，面试可能会挂！

```java
class Solution {
    public int[] searchRange(int[] nums, int target) {
        int[] res = new int[] {-1, -1};
        if(nums == null || nums.length == 0) {
            return res;
        }
        
        f(nums, res, target, 0, nums.length-1, true);
        return res;
    }

    private void f(int[] nums, int[] res, int target, int l, int r, boolean isFirst) {
        if(l > r) {
            return;
        }

        int mid = (l + r) / 2;
        if(target == nums[mid]) {
            // 如果是从第一次二分过来了的, 则设置左边的位置
            if(isFirst) {
               res[0] = getFirstIndex(nums, target, mid); 
            }

            // 否则设置右边的位置, 然后再在右边的区域二分, 直到没有为止
            res[1] = mid;
            f(nums, res, target, mid+1, r, false);
        } else if(target < nums[mid]) {
            f(nums, res, target, l, mid-1, isFirst);
        } else {
            f(nums, res, target, mid+1, r, isFirst);
        }
    }

    private int getFirstIndex(int[] nums, int target, int firstIndex) {
        if(firstIndex - 1 < 0) {
            return firstIndex;
        }

        for(int i = firstIndex - 1; i > -1; i--) {
            if(nums[i] != target) {
                break;
            } else {
                firstIndex = i;
            }
        }

        return firstIndex;
    }
}

```

###### 递归式两次二分 | O（logn）

- **思路**：
  1. 摒弃了连续二分的遍历找最左的思路，采用了两次二分来解决。
  2. 使用一个标记为来标记是第一次二分，还是第二次二分，如果是第一次二分，则负责找最左索引，即找到 mid 后还不断地往**左**找，直到没找到为止，最后返回最近一次找到的索引。
  3. 而如果是第二次二分，则负责找最右索引，即找到 mid 后还不断地往**右**找，直到没找到为止，最后返回最近一次找到的索引。
  4. 完成两次不同功能的二分后，返回结果即是答案。
- **结论**：是完完全全的是 O（logn）水平，但每次递归都要使用一个 int 变量来记录结果（用于判断是否为 -1，如果是 -1 则返回上一次找到的值，如果不是 -1，则返回结果），这样使得空间浪费了不少，可以使用迭代式来实现优化。

```java
class Solution {
    public int[] searchRange(int[] nums, int target) {
        int[] res = new int[] {-1, -1};
        if(nums == null || nums.length == 0) {
            return res;
        }

        // 两次二分
        res[0] = f(nums, target, 0, nums.length-1, true);
        res[1] = f(nums, target, 0, nums.length-1, false);
        return res;
    }

    private int f(int[] nums, int target, int l, int r, boolean nonFirst) {
        if(l > r) {
            return -1;
        }

        int mid = (l + r) / 2;
        if(target == nums[mid]) {
            // 如果已经还没有左索引, 则继续往左边找
            int res;
            if(nonFirst) {
                res = f(nums, target, l, mid-1, nonFirst);
            } 
            // 如果已经有了左索引, 则继续往右边找
            else {
                res = f(nums, target, mid+1, r, nonFirst);
            }
            return res != -1? res : mid;
        } else if(target < nums[mid]) {
            return f(nums, target, l, mid-1, nonFirst);
        } else {
            return f(nums, target, mid+1, r, nonFirst);
        }
    }
}

```

###### 迭代式两次二分 | O（logn）

- **思路**：与递归式两次二分的思路相同，但不同的是，每一次找到 mid 后，递归再找左或者右前，用了一个全局的变量记录前一次的值，这样就比递归的方式少声明了 n 个变量的空间。
- **结论**：递归的 base case 条件是 l > r，而迭代的条件整好相反，为 l <= r，如果少了 = 会报错的！

```java
class Solution {
    public int[] searchRange(int[] nums, int target) {
        int[] res = new int[] {-1, -1};
        if(nums == null || nums.length == 0) {
            return res;
        }

        // 两次二分
        res[0] = f(nums, target, true);
        res[1] = f(nums, target, false);
        return res;
    }

    private int f(int[] nums, int target, boolean nonFirst) {
        int l = 0, r = nums.length - 1, res = -1, mid;
        do {
            mid = l + (r - l) / 2;
            if(target == nums[mid]) {
                res = mid;
                // 如果已经还没有左索引, 则继续往左边找
                if(nonFirst) {
                    r = mid - 1;
                } 
                // 如果已经有了左索引, 则继续往右边找
                else {
                    l = mid + 1;
                }
            } else if(target < nums[mid]) {
                r = mid - 1;
            } else {
                l = mid + 1;
            }
        } while (l <= r);

        return res;
    }
}

```

##### 3）搜索二维矩阵2

###### 递归式二分 | O（logn）

- **思路**：把二维矩阵是以 matrix[0, n-1] 为根节点的一棵二叉搜索树，然后以二分查找的方式查找搜索树即可。
- **结论**：时间，5ms，96.74%，空间，47.4mb，5.00%，效率非常高了，就这样吧~

```java
class Solution {
    public boolean searchMatrix(int[][] matrix, int target) {
        if(matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return false;
        }
        return searchMatrix(matrix, target, matrix.length, matrix[0].length, 0, matrix[0].length-1);
    }

    private boolean searchMatrix(int[][] matrix, int target, int m, int n, int i, int j) {
        if(i < 0 || i >= m || j < 0 || j >= n) {
            return false;
        }

        // 等于
        if(target == matrix[i][j]) {
            return true;
        } 
        // 小于
        else if(target < matrix[i][j]) {
            return searchMatrix(matrix, target, m, n, i, j-1);
        } 
        // 大于
        else {
            return searchMatrix(matrix, target, m, n, i+1, j);
        }
    }
}

```

#### 双向指针

##### 1）盛最多水的容器

###### 暴力求解 | O（n^2）

- **思路**：从左到右，一次固定左边，遍历右边，遍历完移动左边到下一个位置，周而复始。
- **缺点**：没有根据数据状态进行优化，有些值明明不可能作为最大容器的还重新计算了一次，导致**超时**。

```java
class Solution {
    public int maxArea(int[] height) {
        if(height == null || height.length == 0 || height.length == 1) {
            return 0;
        }
        
        int max = Integer.MIN_VALUE;
        for(int i = 0; i < height.length - 1; i++) {
            for(int j = i + 1; j < height.length; j++) {
                max = Math.max(max, (j - i) * Math.min(height[i], height[j]));
            }
        }
        return max;   
    }
}

```

###### 双指向针法 + 贪心 | O（n）

- **思路**：分析业务可知道，容器容量 = 宽度 * 高度，可从宽度或者高度方面着手。
  1. 假设两指针在左右两边，向中间靠近，这样宽度便减小了。
  2. 而如果左比右高，则说明瓶颈在右边，需要移动右指针；否则，如果右比左高，则说明瓶颈在左边，需要移动左指针。
  3. 如果宽度减小，但高度却没变大，则认为肯定不是答案，只去比较那些宽度变小，但高度变大的数据。
- **优点**：从遍历两次减小到了一次（3ms，92.78%），且中间使用了贪心算法，常数项比单纯的双指针法更低。

```java
class Solution {
    public int maxArea(int[] height) {
        if(height == null || height.length == 0 || height.length == 1) {
            return 0;
        }

        int l = 0, r = height.length - 1;
        int max = Integer.MIN_VALUE, limit = Integer.MIN_VALUE, tmp = Integer.MIN_VALUE;
        while(l < r) {
            // 贪心所在：如果高度发生过变化, 则重新计算, 否则不用重新计算(宽度小了但高度却没大)
            if((tmp = Math.min(height[l], height[r])) > limit) {
                max = Math.max(max, (r - l) * tmp);
                limit = Math.max(limit, tmp);
            }
            if(height[l] < height[r]) {
                l++;
            } else {
                r--;
            }
        }

        return max;
    }
}

```

##### 2）三数求和

见《n 数和 -  三数求和》。

##### 3）接雨水

###### 双向指针法 | O（n）

- **思路**：
  1. 利用当前位置与左右边界最小值比较，如果小于最小边界，则认为当前格子有 min - i 的水。
  2. 首先选择左右指针 l 和 r 作为边界，然后从**较小边界**的旁边 i 出发，直到左右边界重合，或者碰到左右边界为止（由于 l 或者 r 每次都往里面缩，而 i 又是比边界更往里面，所以除了特殊数据，并不会出现一开始 i 等于边界的情况）。
  3. 如果 i 比左右两边界都小，则认为边界有效，则用**较小边界的值**结算当前格子的水 min - i，否则每次 i 碰到更大的边界，则替换较小的边界，然后重新选举较小边界的索引，从而得出下一步 i 的位置，周而复始，直到循环结束，得到水的总和即是答案。
- **结论**：时间 0ms，100%，空间 37.7 mb，97.12%，性能十分好，就这样吧~

```java
class Solution {
    public int trap(int[] height) {
        if(height == null || height.length < 3) {
            return 0;
        }

        int l = 0, r = height.length - 1;
        boolean isLeftMin = height[l] < height[r];
        int i = isLeftMin? l+1 : r-1, sum = 0;

        while(l < r && i > l && i < r) {
            // 左边小, 则比较左边
            if(isLeftMin) {
                // i比l小, 则i++
                if(height[i] <= height[l]) {
                    sum += height[l] - height[i];
                    i++;
                } 
                // i比l大, 则替换l, 重新选举i
                else {
                    l = i;
                    isLeftMin = height[l] < height[r];
                    i = isLeftMin? l+1 : r-1;
                }
            } 
            // 右边小, 则比较右边
            else {
                // i比r小, 则i--
                if(height[i] <= height[r]) {
                    sum += height[r] - height[i];
                    i--;
                } 
                // i比r大, 则替换r, 重新选举i
                else {
                    r = i;
                    isLeftMin = height[l] < height[r];
                    i = isLeftMin? l+1 : r-1;
                }
            }
        }

        return sum;
    }
}

```

#### 滑动窗口

##### 1）最小覆盖子串

###### 暴力解法 | O（n^3）

- 思路：
  1. 从左到右遍历匹配串 s，然后再从 0,1,2,...,n 一直尝试不同长度的子串，去匹配原串 t。
  2. 判断是否匹配时，由于匹配不要求顺序，所以对应的字母词频相同即可，所以再遍历每个子串的词频，看是否大于等于 t 的词频，如果相等，则返回 true，否则返回 false。
  3. 最后，判断获取长度最小的匹配子串，然后返回即可。
- **结论**：
  1. 执行超时，由于每次都统计 t 和各子串 的词频，做多了很多重复的工作，所以这方面还可以优化下。
  2. 同时，由于题目约定的用例全都是字母，所以统计词频也不用开辟 128 长度的数组，只需要 59 个格子就好，因为中间多了（58 '：'，59 '；'，60 '<'，61 '='，62 '>'，63 '?'，64 '@'）这 7 个字符！

```java
class Solution {
    public String minWindow(String s, String t) {
        if(s == null || t == null) {
            return "";
        }
        if(t.length() == 0 || s.length() == 0) {
            return "";
        }

        char[] charsS = s.toCharArray();
        char[] charsT = t.toCharArray();

        int[] tCount = new int[59];
        for(int j = 0; j < charsT.length; j++) {
            tCount[charsT[j] - 'A'] += 1;
        }

        int minlen = Integer.MAX_VALUE, minStart = 0;
        for(int i = 0; i < charsS.length; i++) {
            for(int len = 0; len < charsS.length - i; len++) {
                if(f(charsS, tCount, i, len)) {
                    if(len < minlen) {
                        minlen = len;
                        minStart = i;
                    }
                }
            }
        }

        return s.substring(minStart, minStart + minlen + 1);
    }

    private boolean f(char[] charsS, int[] tCount, int i, int len) {
        int[] sCount = new int[59];
        for(int j = i; j <= i + len; j++) {
            sCount[charsS[j] - 'A'] += 1;
        }

        for(int j = 0; j < tCount.length; j++) {
            if(tCount[j] > sCount[j]) {
                return false;
            }
        }

        return true;
    }
}

```

###### 滑动窗口法 | O（n）

- 思路：
  1. 观察暴力解法的过程可得知，暴力解法中，常常由于增加了一个字符，或者换了一个字符开头，就要重新对词频进行一次统计，导致工作了很多重复的内容。
  2. 而这点可以用**滑动窗口**来优化，减少不必要的重复计算：
     1. 设定一个 l 和 r 代表滑动窗口的左右边界，为了方便计算（让 r - l 即等于滑动窗口长度），约定这个区间是一个左闭右开的区间 [l，r)，至此可以让滑动窗口从左到右进行 s 的字符数组扫描。
     2. 同时，由于控制了每次扫描都会增加，或者减少滑动窗口内的一个字符，所以可以通过使用**编辑距离**的方式来优化掉 t 匹配判断函数 f，使其降低为 O（1）。
        1. 即首先初始化好 t 的词频数组，然后使用一个 distance 来表示滑动窗口内接近等于 t 词频的距离。
        2. 如果增加了一个 t 需要的字符，则距离-1，如果减少了一个 t 需要的字符，则距离+1。
        3. 而对于那些 t  不关心的字符，距离不用变，只需要在词频数组中做好记录就行。
     3. 然后滑动窗口的移动逻辑为，首先移动 r，在 r 不越界的情况下，登记 r 字符的词频，以及比较距离是否为 0，如果距离不为 0，说明此时滑动窗口内还完全拥有 t 需要的字符，所以 r 继续向右移动，扩大滑动窗口长度，寻找可行解。
     4. 如果距离为 0 了，说明此时滑动内已经完全拥有了 t 需要的字符，但由于可能有多余的字符，所以还需要 l 从左边进行移动，缩减滑动窗口的大小，逐步可行解转换为最优解，但如果减少了字符后，发现距离不为 0，说明把 t 需要的字符也删了，那么 l 就停止移动，重新移动 r，转向寻找下一堆可行解，然后周而复始。
     5. 就这样，当 r 越界时，说明所有可行解已经寻找完毕，且滑动窗口内也没有多余的字符了，即也是最优解了，因为 r 移动前，是上次 l 移动后发生的，此时 l~r 内必定是缺一个 t 需要的字符的，如果 r 越界前，刚刚找到最后一个 t 需要的字符，那么说明 l~r 内是刚好满足 t 需要的字符的，所以如果此时匹配 t 的话，就已经是此时的最优解了。
     6. 最后，把最小的每个最优解进行对比，然后截取 s 字符串并返回。
- **结论**：时间，2ms，99.64%，38.5mb，79.91%，效率非常高，以后对于这种**缩减暴力解的优化**，可以考虑下滑动窗口。

```java
class Solution {
    public String minWindow(String s, String t) {
        if(s == null || t == null) {
            return "";
        }
        if(t.length() == 0 || s.length() == 0) {
            return "";
        }

        // 使用字符数组比用charAt要好, 因为省去了charAt底层的越界校验
        char[] charsS = s.toCharArray();
        char[] charsT = t.toCharArray();

        // 初始化t数组词频
        int[] tCount = new int[59];
        for(int j = 0; j < charsT.length; j++) {
            tCount[charsT[j] - 'A'] += 1;
        }

        // [l,r): l代表滑动窗口的左边界(左闭), r代表滑动窗口的右边界(右开)
        int l = 0, r = 0;
        // distance代表当前滑动窗口中, 距离匹配t还差多少个字符, 为0时代表与t匹配
        int distance = charsT.length;
        // minlen代表匹配到的最小子串长度
        // minstart代表匹配到的最小子串起始索引, 用于最后截取s和返回结果
        int minlen = Integer.MAX_VALUE, minStart = 0;
        
        // 如果右边界还没越界, 则滑动窗口向右移动, 寻找所有可行解
        int countIndex;
        while(r < charsS.length) {
            // 如果r字符是t需要的, 则距离-1
            countIndex = charsS[r] - 'A';
            if(tCount[countIndex] > 0) {
                distance--;
            }
            
            // 还要减小对应的词频
            tCount[countIndex]--;
            r++;// 先右开
    
            // 如果滑动窗口里的字符正好是t想要的, 则向右移动左边界, 把可行解优化成最优解
            while(distance == 0) {
                // 删除滑动窗口内字符前, 先判断获取最优解
                if(r - l < minlen) {
                    minlen = r - l;
                    minStart = l;
                }

                // 如果l字符刚好是t需要的, 则代表减少错了字符, 此时需要把距离+1, 结束左边界循环
                countIndex = charsS[l] - 'A';
                if(tCount[countIndex] == 0) {
                    distance++;
                }
                
                // 还要增加对应的词频, 代表减少滑动窗口内的字符
                tCount[countIndex]++;
                l++;
            }
        }

        if(minlen > charsS.length) {
            return "";
        } else {
            return s.substring(minStart, minStart + minlen);
        }
    }
}

```

##### 2）滑动窗口最大值

###### 双端队列法 | O（n）

- **思路**：
  1. 设计一个单调递减的双端队列，存放数组的索引（这样可以存放更多的信息），队头到队尾索引对应的元素值从大到小排列。
  2. 根据单调双端队列的特性，在滑动窗口向右滑动时，需要从队尾判断加入的元素是否符合单调性，如果不符合（即大于队列中的元素），则把队列中不符合（小于等于）的元素从队尾一次弹出，再加入当前元素，此时右边界移动完毕。
  3. 由于本题的滑动窗口规定为 k，所以移动右边界完毕还需要移动左边界，右边界为 i 时的理论左边界应该为 i-k+1，如果队头的索引小于该理论值，则认为左边界需要向右移动，此时则从队头弹出元素。
  4. 最后，左右边界移动完毕，此时的滑动窗口已经维护完毕，所以把队头索引对应的值，代表滑动窗口内部的最大值，加入结果集中，然后周而复始即可。 
- **结论**：时间，28ms，90.13%，空间，54.4mb，34.08%，效率非常高了，就这样吧~

```java
class Solution {
    public int[] maxSlidingWindow(int[] nums, int k) {
        if(nums == null || k < 1 || nums.length < k) {
            return null;
        }

        // 双端队列, 存的是数组的下标
        Deque<Integer> dequeue = new LinkedList<>();
        int[] res = new int[nums.length - k + 1];

        // 从左到右移动右边界R
        int index = 0;
        for(int i = 0; i < nums.length; i++) {
            // 从双端队列队尾弹出小于等于当前值的元素
            while(!dequeue.isEmpty() && nums[dequeue.peekLast()] <= nums[i]) {
                dequeue.pollLast();
            }

            // 从双端队列队尾加入当前元素
            dequeue.offerLast(i);

            // 如果双端队列中元素索引跨度大于k, 则从队头弹出, 代表移动左边界L
            if(dequeue.peekFirst() < i-k+1) {
                dequeue.pollFirst();
            }

            // 维护好双端队列后, 把滑动窗口内的最大值(队头元素), 加入结果集中
            if(i-k+1 >= 0) {
                res[index++] = nums[dequeue.peekFirst()];   
            }
        }

        return res;
    }
}

```

##### 3）找到字符串中所有字母异位词

###### 暴力解法 | O （p + [s - p] * p）

- **思路**：
  1. 使用双端队列做滑动窗口，从右进从左出，先输入固定大小为 p 的数据到滑动窗口，然后从 p 开始遍历 s 数组，最左元素出队前，先判断窗口内的字符串是否符合异位词格式，然后再左出队一个吗，右进队一个，周而复始。 
  2. 其中，判断窗口内的字符串是否符合异位词格式，采用遍历的方式去判断，每次遍历 p 次，如果任意有一次不合法，则返回 false，否则返回 true。
- **结论**：
  1. 时间，2418 ms，5.02%，空间，43.2mb，5.00%。
  2. 时间上，初始化窗口需要遍历 p 次，然后从 p 开始遍历到 s 结束，需要遍历 s-p 次，每次遍历需要判断窗口内字符串是否合法，需要遍历 p 次，因此时间复杂度为 O（p + [s-p] * p）。
  3. 空间上，由于使用了两张哈希表，最多存放 p 个元素，一共为 O（2 * p），以及一个滑动窗口，最多存放 s 个元素，所以总的额外空间复杂度为 O（2 * p + s）。

```java
class Solution {
    public List<Integer> findAnagrams(String s, String p) {
        if(s == null || p == null || s.length() == 0 || p.length() == 0 
            || s.length() < p.length()) {
            return new ArrayList<>();
        }

        int sn = s.length(), pn = p.length();
        Map<Character, Integer> pcountMap = new HashMap<>();
        for(char pc : p.toCharArray()) {
            if(!pcountMap.containsKey(pc)) {
                pcountMap.put(pc, 1);
            } else {
                pcountMap.put(pc, pcountMap.get(pc) + 1);
            }
        }

        // 固定滑动窗口大小
        Deque<Integer> slidingWindow = new LinkedList<>();
        Map<Character, Integer> scountMap = new HashMap<>();
        for(int i = 0; i < pn; i++) {
            slidingWindow.offerLast(i);
            maintainScountMap(scountMap, s.charAt(i), 1);
        }

        // 滑动窗口从pn处向右移动
        int li, ri;
        List<Integer> res = new LinkedList<>();
        for(int i = pn; i < sn; i++) {
            li = slidingWindow.peekFirst();
            ri = slidingWindow.peekLast();

            // 判断是否为p的异位词
            if(isValid(scountMap, pcountMap, s, li, ri)) {
                res.add(li);
            }
            
            // 弹出
            slidingWindow.pollFirst();
            maintainScountMap(scountMap, s.charAt(li), -1);

            // 进入
            slidingWindow.offerLast(i);
            maintainScountMap(scountMap, s.charAt(i), 1);
        }

        // 结算滑动窗口内最后的字符串
        li = slidingWindow.peekFirst();
        ri = slidingWindow.peekLast();
        if(isValid(scountMap, pcountMap, s, li, ri)) {
            res.add(li);
        } 

        return res;
    }

    private boolean isValid(Map<Character, Integer> scountMap, Map<Character, Integer> pcountMap, String s, int li, int ri) {
        char c;
        for(int i = li; i <= ri; i++) {
            c = s.charAt(i);
            if(!pcountMap.containsKey(c)) {
                return false;
            }
            if(!scountMap.get(c).equals(pcountMap.get(c))) {
                return false;
            }   
        }

        return true;
    }

    private void maintainScountMap(Map<Character, Integer> scountMap, char sc, int status) {
        // 加
        if(status == 1) {
            if(!scountMap.containsKey(sc)) {
                scountMap.put(sc, 1);
            } else {
                scountMap.put(sc, scountMap.get(sc) + 1);
            }
        } 
        // 减
        else {
            if(!scountMap.containsKey(sc)) {
                return;
            } else {
                scountMap.put(sc, scountMap.get(sc) - 1);
            }
        }   
    }
}

```

###### 词频统计法 | O（p + [s - p] * 26）

- **思路**：在暴力解法的基础上，由于使用了哈希表长度不固定，因此可以用 26 长的词频数组来替代，以及判断异位词合法也不再遍历 p 次了，而是使用了遍历 26 长度词频数组来替代，把时间复杂度从 p 次优化成 26 常数次。
- **结论**：
  1. 时间，13ms，32.67%，空间，43.5mb，4.99%。
  2. 时间上，初始化窗口需要遍历 p 次，然后从 p 开始遍历到 s 结束，需要遍历 s-p 次，每次遍历需要判断窗口内字符串是否合法，需要遍历 26 次，因此时间复杂度为 O（p + [s-p] * 26）。
  3. 空间上，由于使用了两张词频数组，最多存放 26 个元素，一共为 O（52），以及一个滑动窗口，最多存放 s 个元素，所以总的额外空间复杂度为 O（52 + s）。

```java
class Solution {
    public List<Integer> findAnagrams(String s, String p) {
        if(s == null || p == null || s.length() == 0 || p.length() == 0 
            || s.length() < p.length()) {
            return new ArrayList<>();
        }
        
        char[] schars = s.toCharArray(), pchars = p.toCharArray();
        int sn = schars.length, pn = pchars.length;

        // 固定滑动窗口大小
        int[] pcount = new int[26];
        int[] swcount = new int[26];
        Deque<Integer> slidingWindow = new LinkedList<>();
        for(int i = 0; i < pn; i++) {
            pcount[pchars[i] - 'a']++;
            swcount[schars[i] - 'a']++;
            slidingWindow.offerLast(i);
        }

        // 滑动窗口从pn处向右移动
        int li;
        List<Integer> res = new LinkedList<>();
        for(int i = pn; i < sn; i++) {
            li = slidingWindow.peekFirst();

            // 判断是否为p的异位词
            if(Arrays.equals(swcount, pcount)) {
                res.add(li);
            }
            
            // 弹出
            slidingWindow.pollFirst();
            swcount[schars[li] - 'a']--;

            // 进入
            slidingWindow.offerLast(i);
            swcount[schars[i] - 'a']++;
        }

        // 结算滑动窗口内最后的字符串
        if(Arrays.equals(swcount, pcount)) {
            res.add(slidingWindow.peekFirst());
        } 

        return res;
    }
}

```

###### 编辑距离法 | O（26 + s）

- **思路**：
  1. 在词频统计法的基础上，由于每次都需要比较两个词频数组是否相等，使得很多元素重复比较了，因为变化的就只有出队和入队的两个元素。
  2. 所以，采用编辑距离的方式，通过 upDiff 来记录 sc 多了的距离，downDiff 来记录 sc 少了的距离，然后滑动窗口向右移动时，不断判断 upDiff 和 downDiff 是否都为 0 来决定窗口内字符串是否合法。
  3. 以及通过 count[ci] 的状态，来维护 upDiff 和 downDiff 的值，周而复始。
- **结论**：
  1. 时间，11ms，37.91%，空间，42.7mb，4.99%。
  2. 时间上，初始化窗口需要遍历 p 次，然后初始化 upDiff 和 downDiff 需要遍历 26 次  count 数组，然后从 p 开始遍历到 s 结束，需要遍历 s-p 次，因此时间复杂度为 O（p + 26 + [s-p]）= O（26 + s）。
  3. 空间上，由于只使用了 1 张词频数组，最多存放 26 个元素，一共为 O（26），以及一个滑动窗口，最多存放 s 个元素，所以总的额外空间复杂度为 O（26 + s）。

```java
class Solution {
    public List<Integer> findAnagrams(String s, String p) {
        if(s == null || p == null || s.length() == 0 || p.length() == 0 
            || s.length() < p.length()) {
            return new ArrayList<>();
        }
        
        char[] schars = s.toCharArray(), pchars = p.toCharArray();
        int sn = schars.length, pn = pchars.length;

        // 固定滑动窗口大小: pc - sc, 大于0表示sc字母少了, 小于0表示sc字母多了
        int[] count = new int[26];
        Deque<Integer> slidingWindow = new LinkedList<>();
        for(int i = 0; i < pn; i++) {
            count[pchars[i] - 'a']--;
            count[schars[i] - 'a']++;
            slidingWindow.offerLast(i);
        }

        // 获取编辑距离差距
        int upDiff = 0, downDiff = 0;
        for(int i = 0; i < count.length; i++) {
            if(count[i] > 0) {
                upDiff += count[i];// sc多了
            } else if(count[i] < 0) {
                downDiff += count[i];// sc少了
            }
        }

        // 滑动窗口从pn处向右移动
        int li, ci;
        List<Integer> res = new LinkedList<>();
        for(int i = pn; i < sn; i++) {
            li = slidingWindow.pollFirst();

            // 判断是否为p的异位词
            if(upDiff == 0 && downDiff == 0) {
                res.add(li);
            }

            // 弹出, 相当于sc在减少
            if(count[ci = schars[li] - 'a'] == 0) {
                downDiff--;
            } else if(count[ci] > 0) {
                upDiff--;
            } else {
                downDiff--;
            }
            count[ci]--;
            
            // 进入, 相当于sc在增加
            slidingWindow.offerLast(i);
            if(count[ci = schars[i] - 'a'] == 0) {
                upDiff++;
            } else if(count[ci] > 0) {
                upDiff++;
            } else {
                downDiff++;
            }
            count[ci]++;
        }

        // 结算滑动窗口内最后的字符串
        if(upDiff == 0 && downDiff == 0) {
            res.add(slidingWindow.peekFirst());
        }

        return res;
    }
}

```

#### 宏观调度

##### 1）旋转图像

###### 宏观调度法 | O（n/2 * (n-1)）

- **思路**：
  1. 不再拘泥于每个坐标如何变换，从宏观的角度上看待问题，把问题看作成一次宏观的旋转。
  2. 每次选取当前层的左上角和右下角作为调度基准，比如选取左上角的位置作为交换中心，其他的值都和该值做交换，当前层的值都交换完毕后，则逐步把左上角和右下角往里缩进一层，继续调度，直到左右重合即得到最终结果。
  3. 其中值交换的过程为：每层划分为 4 组，分别为第一行、最后一列、最后一行、第一列，每组数量相等，其旋转方式如下：
     1. 第一行的组: 列下标赋值为当前层的最后一列, 行下标依次+1。
     2. 最后一列的组: 行下标赋值为当前层的最后一行, 列下标依次-1。
     3. 最后一行的组: 列下标赋值为当前层的第一列，行下标依次-1。
     4. 第一列的组: 行下标赋值为当前层的第一行, 列下标依次+1。
- **结论**：时间，0ms，100%，空间，38.5mb，72%，性能非常好，就这样吧~

```java
class Solution {
    public void rotate(int[][] matrix) {
        for(int i = 0; i < matrix.length / 2; i++) {
            f(matrix, i, i, matrix.length - 1 - i, matrix.length - 1 - i);
        }
    }

    private void f(int[][] matrix, int left, int up, int right, int down) {
        if(left > right || up > down) {
            return;
        }

        for(int rounds = 1; rounds <= right - left; rounds++) {
            // 第一行的组: 列下标赋值为当前层的最后一列, 行下标依次+1
            swap(matrix, left, left + rounds, up + rounds, right);

            // 最后一列的组: 行下标赋值为当前层的最后一行, 列下标依次-1
            swap(matrix, left, left + rounds, right, right - rounds);

            // 最后一行的组: 列下标赋值为当前层的第一列，行下标依次-1
            swap(matrix, left, left + rounds, down - rounds, left);

            // 第一列的组: 行下标赋值为当前层的第一行, 列下标依次+1
            swap(matrix, left, left + rounds, left, left + rounds);
        }
    }

    // src交换to
    private void swap(int[][] matrix, int from_row, int from_col, int to_row, int to_col) {
        int tmp = matrix[to_row][to_col];
        matrix[to_row][to_col] = matrix[from_row][from_col];
        matrix[from_row][from_col] = tmp;
    }
}

```

##### 2）搜索二维矩阵2

见《二分查找 - 搜索二维矩阵2》。

#### 单调栈

##### 1）合并区间

###### 单调栈法 | O（nlogn）

- **思路**：
  1. 数组顺序问题，可以试着用单调栈去解决。
  2. 先对原数组进行排序，对外层从小到大排序，以保证合并区间时后面的外层不会比前面的外层小，减少处理难度。
  3. 然后遍历外层数组，如果碰到 0 位 比前元素的 1 位还要小或者等于，即不满足单调栈特性时，说明发生区间重叠，此时合并两个区间，即前元素出栈取 0 位作为新元素的 0 位，1 位和当前 1 位的最大者作为新元素的 1 位，然后构建新的元素并加入单调栈中。
- **结论**：时间，9ms，16.32%，42.5mb，15.11%，可能还需要研究一下别的更高效的方法，以满足面试的不同要求。

```java
class Solution {

    public int[][] merge(int[][] intervals) {
        if(intervals == null || intervals.length == 0) {
            return new int[0][0];
        }

        // 按外、里从小到达排序
        Arrays.sort(intervals, (o1, o2) -> o1[0] - o2[0]);

        // 单调栈: 底->顶: 从小到大
        LinkedList<int[]> stack = new LinkedList<>();
        for(int i = 0; i < intervals.length; i++) {
            if(stack.isEmpty()) {
                stack.push(intervals[i]);
            } else {
                int[] member = stack.peek();
                if(member[1] >= intervals[i][0]) {
                    stack.pop();
                    stack.push(new int[] {
                        member[0], Math.max(member[1], intervals[i][1])
                    });
                } else {
                    stack.push(intervals[i]);
                }
            }
        }

        // 从上到下遍历单调栈
        int[][] res = new int[stack.size()][2];
        int index = res.length - 1;
        while(!stack.isEmpty()) {
            int[] member = stack.pop();
            res[index][0] = member[0];
            res[index][1] = member[1];
            index--;
        }

        return res;
    }
}

```

###### 原位修改法 | O（nlogn）

- **思路**：与单调栈法类似，但不同的地方在于，使用了列表的形式去实现，通过对列表末尾元素的判断，然后在其元素本身上修改值，节省了新建的 int[] 数组对象（前提是本题允许了修改原数组）。
- **结论**：时间，9ms，17%，空间，43mb，6%，与单调栈法一样， 谈不上是更优的方式。

```java
class Solution {

    public int[][] merge(int[][] intervals) {
        if(intervals == null || intervals.length == 0) {
            return new int[0][0];
        }

        // 按外、里从小到达排序
        Arrays.sort(intervals, (o1, o2) -> o1[0] - o2[0]);

        // 单调栈: 底->顶: 从小到大
        List<int[]> list = new ArrayList<>();
        for(int i = 0; i < intervals.length; i++) {
            if(list.size() != 0) {
                int[] last = list.get(list.size()-1);
                if(last[1] >= intervals[i][0]) {
                    last[1] = Math.max(last[1], intervals[i][1]);
                    continue;
                } 
            }
            list.add(intervals[i]);
        }

        return list.toArray(new int[list.size()][]);
    }
}

```

##### 2）柱状图中最大的矩形

###### 暴力解法1 | O（n^2）

- **思路**：
  1. 宽度不固定，高度也不固定。
  2. 从左遍历到右先固定 1 位数字作为左边界，然后选择一个右边界再从左遍历到右，矩形的面积 = 宽 * 高，其中高指的是遍历过程中最小的高度 limit，然后周而复始，选出最大的一个矩形即可。
- **结论**：执行超时，因为重复计算了很多次无用的，比如右边界遍历过程中，明知道某个位置的值已经是最小高度了，下次还要用它作为左边界再算一遍，浪费了很多时间。

```java
class Solution {
    public int largestRectangleArea(int[] heights) {
        if(heights == null || heights.length == 0) {
            return 0;
        }

        int max = Integer.MIN_VALUE, limit;
        for(int i = 0; i < heights.length; i++) {
            limit = Integer.MAX_VALUE;
            for(int j = i; j < heights.length; j++) {
                limit = Math.min(limit, Math.min(heights[i], heights[j]));
                max = Math.max(max, (j - i + 1) * limit);
            }
        }

        return max;
    }
}

```

###### 暴力解法2 | O（n^2）

- **思路**：
  1. 高度固定，宽度不固定。
  2. 从左到右选择每一个高度进行尝试，其最大宽度等于高度变小前的索引中间的那部分，面积 = 高度 * 宽度。
- **结论**：执行也超时，但通过用例比暴力解法 1 的多了 3 个，明显该算法的效率高一点。

```java
class Solution {
    public int largestRectangleArea(int[] heights) {
        if(heights == null || heights.length == 0) {
            return 0;
        }

        int max = Integer.MIN_VALUE, limit, l, r;
        for(int i = 0; i < heights.length; i++) {
            limit = heights[i];
            l = r = i;
            while(l - 1 > -1 && heights[l - 1] >= heights[i]) {
                l--;
            }
            while(r + 1 < heights.length && heights[r + 1] >= heights[i]) {
                r++;
            }
            max = Math.max(max, (r - l + 1) * limit);
        }

        return max;
    }
}

```

###### 单调栈法 | O（n）

- **思路**：
  1. 经过研究暴力解法的思路可知，固定一个高度 i 后，如果没确定最大宽度有多少，可以先把它放入栈中，继续遍历。
  2. 等遍历到它的边界，即高度开始减小时，则把它出栈并计算以该值为高度，以当前索引 i 左右它的最右边界（右边开始下降，最右默认为 len），以剩余栈顶 j 作为它的最左边界（左边开始下降，最左默认为 -1），中间作为该高度的最大宽度，再高度 * 宽度，得出该高度的最大矩形面积。
  3. 周而复始，计算出每个值作为高度的最大矩形面积，返回最大值即可。
- **结论**：时间，20ms，67.94%，空间，46.7mb，99.21%，效率可以了。

```java
class Solution {
    public int largestRectangleArea(int[] heights) {
        if(heights == null || heights.length == 0) {
            return 0;
        }

        // 单调栈: 底->顶, 高度从小到大
        LinkedList<Integer> stack = new LinkedList<>();
        stack.push(-1);

        // 遍历高度数组
        int max = Integer.MIN_VALUE, i = 0, top;
        while(i < heights.length) {
            top = stack.peek();

            // 如果符合单调栈高度从小到大排序的特点, 则加入栈中 
            if(getStackValue(heights, top) <= heights[i]) {
                stack.push(i++);
            } 
            // 如果以高度为i的矩形遇到了瓶颈, 那么则弹出高度i
            else {
                stack.pop();

                // 高度i的矩形最大宽度为上一个最小和当前最小的差(肯定有一个-1再里面)
                max = Math.max(max, heights[top] * (i - stack.peek() - 1));
            }
        }

        // 遍历剩余高度i
        while(!stack.isEmpty() && stack.peek() != -1) {
            top = stack.pop();
            max = Math.max(max, heights[top] * (heights.length - stack.peek() - 1));
        }

        return max;
    }

    private int getStackValue(int[] heights, int top) {
        if(top == -1) {
            return 0;
        } else {
            return heights[top];
        }
    }
}

```

##### 3）最大矩形

###### 暴力解法 | O（m^2 * n）

- **思路**：
  1. 通过遍历矩阵中的每个元素，求以它 [i，j] 结尾的最大矩形面积。
  2. 其中，一个以 [i，j] 结尾的最大矩形面积可以通过比较每行的宽 * 高得出，而每行的高初始为 1，宽初始为当前位置的 '1' 的累加和，同理，上一层的高为 2，宽则为上一层位置的 '1' 的累加和...，可见，把最大宽度的求解转换为 '1' 的累加和，可以很轻松就求出当前位置结尾的最大矩形面积。
- **结论**：
  1. 时间，16ms，23.43%，空间，41.7mb，48.05%，遍历整个矩阵的元素需要 O（m * n），而求每个元素作为结尾的最大矩形面积，最大需要遍历 m 行，因此，整个时间复杂度最大为 O（m^2 * n）。
  2. 而由于每个元素都求了最大矩形面积，使得很多方块被重新用来计算了，有时候明知道不可能是最大面积了，还要拿来计算，所以，效率还可以继续优化。

```java
class Solution {
    public int maximalRectangle(char[][] matrix) {
        if(matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return 0;
        }

        // 累加连续1的个数, 遇到0则归零
        int[][] counts = getCounts(matrix);

        // 求以[i,j]结尾的最大矩形面积
        int max = 0;
        for(int i = 0; i < matrix.length; i++) {
            for(int j = 0; j < matrix[0].length; j++) {
                if('1' == matrix[i][j]) {
                    max = Math.max(max, getMax(matrix, counts, i, j));
                }
            }
        }

        return max;
    }

    /** 求以[i,j]结尾的矩形的最大面积 */
    private int getMax(char[][] matrix, int[][] counts, int row, int col) {
        int gao = 1;
        int kuan = counts[row][col];
        int max = kuan * gao;

        while(row - 1 > -1 && counts[row - 1][col] > 0) {
            gao++;
            row--;

            // 如果宽大于上一层的宽, 则取上一层的宽
            if(counts[row][col] < kuan) {
                kuan = counts[row][col];
            }

            max = Integer.max(max, kuan * gao);
        }

        return max;
    }

    /** 累加连续1的个数, 遇到0则归零 */
    private int[][] getCounts(char[][] matrix) {
        int[][] counts = new int[matrix.length][matrix[0].length];

        int sum;
        for(int i = 0; i < matrix.length; i++) {
            sum = 0;
            for(int j = 0; j < matrix[0].length; j++) {
                if('0' == matrix[i][j]) {
                    sum = 0;
                } else {
                    sum += 1;
                }
                counts[i][j] = sum;
            }
        }

        return counts;
    }
}

```

###### 单调栈法 | O（m * n）

- **思路**：

  1. 观察暴力解法可以看出，实际上等同于在**横向**做了多层柱状图的判断，然后每层的判断又回到了《柱状图中最大的矩形》中的暴力解法，花费了 O（ n^2）的时间，因此，可以参考当时的单调栈解法，优化每层的判断最大矩形为花费 O（n）。

  2. 为了直观理解，这里把二维矩阵看作成**竖向**的多层柱状图，然后调用《柱状图中最大的矩形》中的单调栈解法即可解决问题，比如第三层的竖向状态图为，其他层也同理：

     ![1642483436060](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1642483436060.png)

- **结论**：时间，5ms，89.77%，空间，43.4mb，5.05%，由于需要遍历 m 层，每层判断柱状图的最大矩形需要花费 O（n），因此总的时间复杂度为 O（m * n），额外空间花费了若干个变量和二维数组，共 O（m * n）。

```java
class Solution {
    public int maximalRectangle(char[][] matrix) {
        if(matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return 0;
        }

        // 竖向: 累加连续1的个数, 遇到0则归零
        int[][] counts = getCounts(matrix);

        // 计算每层的heights, 然后调用上一题的函数
        int max = 0;
        for(int i = 0; i < matrix.length; i++) {
            max = Math.max(max, largestRectangleArea(counts[i]));
        }

        return max;
    }

    /** 竖向: 累加连续1的个数, 遇到0则归零 */
    private int[][] getCounts(char[][] matrix) {
        int[][] counts = new int[matrix.length][matrix[0].length];

        int sum;
        for(int j = 0; j < matrix[0].length; j++) {
            sum = 0;
            for(int i = 0; i < matrix.length; i++) {
                if('0' == matrix[i][j]) {
                    sum = 0;
                } else {
                    sum += 1;
                }
                counts[i][j] = sum;
            }
        }

        return counts;
    }

    private int largestRectangleArea(int[] heights) {
        if(heights == null || heights.length == 0) {
            return 0;
        }

        // 单调栈: 底->顶, 高度从小到大
        LinkedList<Integer> stack = new LinkedList<>();
        stack.push(-1);

        // 遍历高度数组
        int max = Integer.MIN_VALUE, i = 0, top;
        while(i < heights.length) {
            top = stack.peek();

            // 如果符合单调栈高度从小到大排序的特点, 则加入栈中 
            if(getStackValue(heights, top) <= heights[i]) {
                stack.push(i++);
            } 
            // 如果以高度为i的矩形遇到了瓶颈, 那么则弹出高度i
            else {
                stack.pop();

                // 高度i的矩形最大宽度为上一个最小和当前最小的差(肯定有一个-1再里面)
                max = Math.max(max, heights[top] * (i - stack.peek() - 1));
            }
        }

        // 遍历剩余高度i
        while(!stack.isEmpty() && stack.peek() != -1) {
            top = stack.pop();
            max = Math.max(max, heights[top] * (heights.length - stack.peek() - 1));
        }

        return max;
    }

    private int getStackValue(int[] heights, int top) {
        if(top == -1) {
            return 0;
        } else {
            return heights[top];
        }
    }
}

```

##### 4）最小栈

见《设计题 - 最小栈》。

##### 5）最大正方形

###### 暴力解法 | O（m^2 * n）

- **思路**：在《单调栈 - 最大矩形》的暴力解法基础上，改写了 getMax 方法，从获取矩形面积=高 * 宽，改为获取正方形面积=min{高，宽} ^ 2。 
- **结论**：
  1. 时间，56ms，5.02%，空间，53.9mb，5.03%，时间上，遍历整个矩阵的元素需要 O（m * n），而求每个元素作为结尾的最大正方形面积，最大需要遍历 m 行，因此，整个时间复杂度最大为 O（m^2 * n）。
  2. 而由于每个元素都求了最大正方形面积，使得很多方块被重新用来计算了，有时候明知道不可能是最大面积了，还要拿来计算，所以，效率还可以继续优化。

```java
class Solution {
    public int maximalSquare(char[][] matrix) {
        if(matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return 0;
        }

        // 累加连续1的个数, 遇到0则归零
        int[][] counts = getCounts(matrix);

        // 求以[i,j]结尾的最大矩形面积
        int max = 0;
        for(int i = 0; i < matrix.length; i++) {
            for(int j = 0; j < matrix[0].length; j++) {
                if('1' == matrix[i][j]) {
                    max = Math.max(max, getMax(matrix, counts, i, j));
                }
            }
        }

        return max;
    }

    /** 求以[i,j]结尾的正方形的最大面积 */
    private int getMax(char[][] matrix, int[][] counts, int row, int col) {
        int gao = 1, kuan = counts[row][col];
        int bian = Math.min(gao, kuan), max = bian * bian;
        while(row - 1 > -1 && counts[row - 1][col] > 0) {
            gao++;
            row--;

            // 如果宽大于上一层的宽, 则取上一层的宽
            if(counts[row][col] < kuan) {
                kuan = counts[row][col];
            }

            bian = Math.min(gao, kuan);
            max = Integer.max(max, bian * bian);
        }

        return max;
    }

    /** 累加连续1的个数, 遇到0则归零 */
    private int[][] getCounts(char[][] matrix) {
        int[][] counts = new int[matrix.length][matrix[0].length];

        int sum;
        for(int i = 0; i < matrix.length; i++) {
            sum = 0;
            for(int j = 0; j < matrix[0].length; j++) {
                if('0' == matrix[i][j]) {
                    sum = 0;
                } else {
                    sum += 1;
                }
                counts[i][j] = sum;
            }
        }

        return counts;
    }
}

```

###### 单调栈法 | O（m * n）

- **思路**：

  1. 观察暴力解法可以看出，实际上等同于在**横向**做了多层柱状图的判断，然后每层的判断又回到了《柱状图中最大的矩形》中的暴力解法，花费了 O（n^2）的时间，因此，可以参考当时的单调栈解法，优化每层的判断最大矩形为花费 O（n）。

  2. 为了直观理解，这里把二维矩阵看作成**竖向**的多层柱状图，然后调用《柱状图中最大的矩形》中的单调栈解法即可解决问题，比如第三层的竖向状态图为，其他层也同理：

     ![1642483436060](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1642483436060.png)

  3. 这里求最大正方形只要求出 min{kuan，gao} 作为正方形的边求面积即可。

- **结论**：时间，8ms，14.74%，空间，54.4mb，5.03%，由于需要遍历 m 层，每层判断柱状图的最大正方形需要花费 O（n），因此总的时间复杂度为 O（m * n），额外空间花费了若干个变量和二维数组，共 O（m * n）。

```java
class Solution {
    public int maximalSquare(char[][] matrix) {
        if(matrix == null || matrix.length == 0 || matrix[0].length == 0) {
            return 0;
        }

        // 竖向: 累加连续1的个数, 遇到0则归零
        int[][] counts = getCounts(matrix);

        // 计算每层的heights, 然后调用上一题的函数
        int max = 0;
        for(int i = 0; i < matrix.length; i++) {
            max = Math.max(max, largestRectangleArea(counts[i]));
        }

        return max;
    }

    /** 竖向: 累加连续1的个数, 遇到0则归零 */
    private int[][] getCounts(char[][] matrix) {
        int[][] counts = new int[matrix.length][matrix[0].length];

        int sum;
        for(int j = 0; j < matrix[0].length; j++) {
            sum = 0;
            for(int i = 0; i < matrix.length; i++) {
                if('0' == matrix[i][j]) {
                    sum = 0;
                } else {
                    sum += 1;
                }
                counts[i][j] = sum;
            }
        }

        return counts;
    }

    private int largestRectangleArea(int[] heights) {
        if(heights == null || heights.length == 0) {
            return 0;
        }

        // 单调栈: 底->顶, 高度从小到大
        LinkedList<Integer> stack = new LinkedList<>();
        stack.push(-1);

        // 遍历高度数组
        int max = Integer.MIN_VALUE, i = 0, top, bian;
        while(i < heights.length) {
            top = stack.peek();

            // 如果符合单调栈高度从小到大排序的特点, 则加入栈中 
            if(getStackValue(heights, top) <= heights[i]) {
                stack.push(i++);
            } 
            // 如果以高度为i的矩形遇到了瓶颈, 那么则弹出高度i
            else {
                stack.pop();

                // 高度i的矩形最大宽度为上一个最小和当前最小的差(肯定有一个-1再里面)
                bian = Math.min(heights[top], i - stack.peek() - 1);
                max = Math.max(max, bian * bian);
            }
        }

        // 遍历剩余高度i
        while(!stack.isEmpty() && stack.peek() != -1) {
            top = stack.pop();
            bian = Math.min(heights[top], heights.length - stack.peek() - 1);
            max = Math.max(max, bian * bian);
        }

        return max;
    }

    private int getStackValue(int[] heights, int top) {
        if(top == -1) {
            return 0;
        } else {
            return heights[top];
        }
    }
}

```

##### 6）每日温度

###### 单调栈法 | O（n）

- **思路**：构建单调栈，使得其自底到顶的元素 i 对应的值 v 从大到小排列，这样，每次遍历到的 i2 对应的新值 v2，则与栈顶 itop 对应的值 vtop（栈中最小值）相比，如果 v2 < vtop，那么把 v2 加入栈顶，否则说明 v2 就是 vtop 后面的第一个最高温度，此时弹出 vtop 并设置结果 = i2- itop，直到数组遍历完毕，那么残留再栈中的元素就是后面没有更高温度的元素，所以它们在 res 数组中的值默认为 0。
- **结论**：时间，21ms，93.69%，空间，57.3mb，5.04%，时间上，遍历一次数组需要 O（n），空间上，由于使用了一个单调栈，最多存储 n 个元素，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public int[] dailyTemperatures(int[] temperatures) {
        if(temperatures == null || temperatures.length == 0) {
            return new int[0];
        }

        // 单调栈: 底到顶=从大到小
        int topi;
        LinkedList<Integer> istack = new LinkedList<>();

        int[] res = new int[temperatures.length];
        for(int i = 0; i < temperatures.length; i++) {
            while(!istack.isEmpty() && temperatures[istack.peek()] < temperatures[i]) {
                topi = istack.pop();
                res[topi] = i - topi;
            }
            istack.push(i);
        }

        return res;
    }
}

```

#### 前缀树

##### 1）电话号码的字母组合

###### 前缀树法 | O（4^n - 2）

- **思路**：首先生成电话字母哈希表，然后遍历原数组，取得电话字母列表，按规则放入前缀树，然后深度优先遍历就好。

  ![1641642900473](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641642900473.png)

- **结论**：1ms，59.32%，面试应该可以。

```java
class Solution {
    
    // 前缀树节点
    class Node {
        String value;
        Node[] nodes;
    }

    public List<String> letterCombinations(String digits) {
        if(digits == null || digits == "") {
            return null;
        }

        HashMap<Integer, String[]> map = initMap();
        List<String> res = new ArrayList<>();
        
        Node head = new Node();
        head.nodes = new Node[4];
        List<Node> firstNodeList = new ArrayList<>();
        firstNodeList.add(head);

        HashMap<Integer, List<Node>> nodesMap = new HashMap<>(); 
        nodesMap.put(0, firstNodeList);

        String[] contents;
        char[] chars = digits.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            // 根据数组获取电话字母组合
            contents = map.get(chars[i] - '0');
            
            // 寻找同层的待添加节点
            List<Node> nodeList = nodesMap.get(i);

            // 设置同层节点缓存
            if(!nodesMap.containsKey(i+1)) {
                nodesMap.put(i+1, new ArrayList<>());
            }

            // 每个待添加节点都设置相同的前缀树数组
            for(Node node : nodeList) {
                // 遍历电话字母组合
                for(int j = 0; j < contents.length; j++) {
                    if("".equals(contents[j])) {
                        continue;
                    }

                    Node next = new Node();
                    node.nodes[j] = next;
                    nodesMap.get(i+1).add(next);

                    next.value = contents[j];    
                    if(i != chars.length - 1) {
                        next.nodes = new Node[4];
                    }
                }
            }
        }

        // 深度优先遍历前缀树
        f(res, head, "");
        return res;
    }

    private void f(List<String> res, Node head, String cur) {
        if(head.nodes == null) {
            res.add(cur);
            return;
        }

        for(int i = 0; i < head.nodes.length; i++) {
            if(head.nodes[i] != null) {
                f(res, head.nodes[i], cur + head.nodes[i].value);
            }
        }
    }

    private HashMap<Integer, String[]> initMap() {
        HashMap<Integer, String[]> map = new HashMap<>();

        map.put(2, new String[] {
            "a", "b", "c", ""
        });
        map.put(3, new String[] {
            "d", "e", "f", ""
        });
        map.put(4, new String[] {
            "g", "h", "i", ""
        });
        map.put(5, new String[] {
            "j", "k", "l", ""
        });
        map.put(6, new String[] {
            "m", "n", "o", ""
        });
        map.put(7, new String[] {
            "p", "q", "r", "s"
        });
        map.put(8, new String[] {
            "t", "u", "v", ""
        });
        map.put(9, new String[] {
            "w", "x", "y", "z"
        });

        return map;
    }
}

```

##### 2）括号生成

见《括号 -  括号生成》。

##### 3）实现 Trie（前缀树）

###### 前缀树法 | O（n）

- **思路**：使用通过前缀树套路，通过 Node#value 表示点值，Node#nodes 表示下一个点值，把字符串拆开一个个字符，分别放入一层层的 Node 节点中即可，其中，nodes 使用了数组的形式，可以减少空间的使用和加快访问的效率。
- **结论**：时间，32ms，82.15%，空间，52.1mb，6.47%，时间上，由于每次都只需要遍历字符串的长度，所以时间复杂度为 O（n），空间上，由于可能输入 n 次字符串，记每次字符串长度为 m，因此，额外空间复杂度为 O（n * m * 26）。

```java
class Trie {

    class Node {
        char value;
        Node[] nodes;
        int endCount = 0;

        Node() {
            
        }

        Node(char value) {
            this.value = value;
        }
    }

    private Node head;

    public Trie() {
        head = new Node();
        head.nodes = new Node[26];
    }
    
    public void insert(String word) {
        if(word == null || word.length() == 0) {
            return;
        }

        Node node, pnode = head;
        char[] chars = word.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            node = pnode.nodes[chars[i] - 'a'];
            if(node == null) {
                node = new Node(chars[i]);
                node.nodes = new Node[26];
                pnode.nodes[chars[i] - 'a'] = node;
            }
            if(i == chars.length-1) {
                node.endCount += 1;
            }

            pnode = node;
        }
    }
    
    public boolean search(String word) {
        if(word == null || word.length() == 0) {
            return true;
        }

        Node nextnode = head;
        char[] chars = word.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            nextnode = nextnode.nodes[chars[i] - 'a'];
            if(nextnode == null) {
                return false;
            }
        }

        return nextnode.endCount > 0;
    }
    
    public boolean startsWith(String prefix) {
        if(prefix == null || prefix.length() == 0) {
            return true;
        }

        Node nextnode = head;
        char[] chars = prefix.toCharArray();
        for(int i = 0; i < chars.length; i++) {
            nextnode = nextnode.nodes[chars[i] - 'a'];
            if(nextnode == null) {
                return false;
            }
        }

        return true;
    }
}

/**
 * Your Trie object will be instantiated and called as such:
 * Trie obj = new Trie();
 * obj.insert(word);
 * boolean param_2 = obj.search(word);
 * boolean param_3 = obj.startsWith(prefix);
 */

```

#### 前缀和

##### 1）除自身外数组的乘积

见《毁天灭地式问题 - 除自身外数组的乘积》。

##### 2）和为 k 的子数组

见《n 数之和 - 和为 k 的子数组》。

#### 并查集

##### 1）最长连续序列

###### 暴力解法 | O（n * logn）

- **思路**：先去重，再顺序排序，最后顺序遍历，依次判断是否连续，以及更新连续的最大长度。
- **结论**：时间，20ms，45.04%，空间，53.2mb，62.74%，时间上，由于使用了排序，所以整体时间复杂度为 O（n * logn），空间上，由于额外使用了一个 HashSet 和一个 ArrayList，所以额外空间复杂度为 O（2n），面试会挂，继续优化吧~

```java
class Solution {
    public int longestConsecutive(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        // 去重
        Set<Integer> set = new HashSet<>();
        for(int i = 0; i < nums.length; i++) {
            set.add(nums[i]);
        }

        // 从小到大排序
        List<Integer> list = new ArrayList<>(set);
        list.sort((o1, o2) -> o1 - o2);
        
        int maxlen = 1, curlen = 1;
        for(int i = 1; i < list.size(); i++) {
            if(list.get(i) - 1 == list.get(i-1)) {
                curlen++;
                maxlen = Math.max(maxlen, curlen);
            } else {
                curlen = 1;
            }
        }

        return maxlen;
    }
}

```

###### 并查集法 | O（n * α(n)）

- **思路**：根据题意，需要连续的数字序列，因此可以构建通用 Integer 类型的并查集，通过不断合并自身值 +1 的连续集，最后获取最大连续集的大小即可。
- **结论**：
  1. 时间，92ms，31.26%，空间，73.2mb，4.99%。
  2. 空间上，由于使用的是高级数据结构，所以空间复杂度非常高。
  3. 而时间上，由于只遍历一次，且使用了路径压缩的优化，其中 α（n）反阿克曼函数的值不会超过 5，所以时间复杂度为 O（n），但在这里，由于额外的操作较多，时间开销相对来说就比较大了，因此，还需要找到另外一种高效的解法！

```java
class Solution {
    
    class Element<V> {
        private V value;

        Element(V value) {
            this.value = value;
        }
    }

    class UnionFindSet<V> {
        private Map<V, Element<V>> elementMap = new HashMap<>();
        private Map<Element<V>, Element<V>> fatherMap = new HashMap<>();
        private Map<Element<V>, Integer> sizeMap = new HashMap<>();
        private int maxSize = 1;

        UnionFindSet(Set<V> set) {
            for(V value : set) {
                Element<V> e = new Element<>(value);
                elementMap.put(value, e);
                fatherMap.put(e, e);
                sizeMap.put(e, 1);
            }
        }

        private Element<V> findHeader(V value) {
            LinkedList<Element<V>> stack = new LinkedList<>();

            Element<V> e = elementMap.get(value), ef;
            while(e != (ef = fatherMap.get(e))) {
                stack.push(e);
                e = ef;
            }
            while (!stack.isEmpty()) {
                fatherMap.put(stack.pop(), e);
            }
            
            return e;
        }

        boolean isSameSet(V a, V b) {
            if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
                return false;
            }
            return findHeader(a) == findHeader(b);
        }

        void union(V a, V b) {
            if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
                return;
            }

            Element<V> af = findHeader(a);
            Element<V> bf = findHeader(b);

            if(af != bf) {
                Element<V> big = sizeMap.get(af) > sizeMap.get(bf)? af : bf;
                Element<V> small = big == af? bf : af;
                fatherMap.put(small, big);

                int newSize = sizeMap.get(small) + sizeMap.get(big);
                sizeMap.put(big, newSize);
                sizeMap.remove(small);
                maxSize = Math.max(maxSize, newSize);
            }
        }

        boolean isElement(V v) {
            return elementMap.containsKey(v);
        }

        int getMaxSize() {
            return this.maxSize;
        }
    }

    public int longestConsecutive(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        // 去重
        Set<Integer> set = new HashSet<>();
        for(int i = 0; i < nums.length; i++) {
            set.add(nums[i]);
        }

        // 并差集初始化
        UnionFindSet<Integer> unionFindSet = new UnionFindSet<>(set);

        // 连续集合并
        for(Integer value : set) {
            // 大1存在, 且还不是同一个连续集, 则合并
            if(unionFindSet.isElement(value+1) && !unionFindSet.isSameSet(value, value+1)) {
                unionFindSet.union(value, value+1);
            }
        }

        return unionFindSet.getMaxSize();
    }
}

```

###### 哈希表法 | O（n）

- **思路**：
  1. 如果采用从左到右遍历的暴力解法的话，那么还需要从 i 出发再从左往右遍历 nums[i] + 1 是否存在，即使采用哈希表判存也还需要 O（n^2）的时间开销，而这肯定会执行超时的~
  2. 而经过研究发现，遍历+判存的两次循环是不可避免的，不过出现 O（n^2）的原因是，每个元素被多访问了 n 遍，如果能够做到每个元素只被访问一遍，那么即使有两个循环，但整体上时间复杂度还是 O（n）的。
  3. 所以，如果在来到每个元素判存之前，加上判断这个元素是否已经被判断过，即如果 nums[i]-1 的元素存在，说明当前元素肯定会从 nums[i]-1 判存上来的，所以跳过就好，这样就做到了每个元素只被访问一次，时间复杂度为 O（n）。
- **结论**：时间，13ms，85.99%，空间，53.3mb，58.31%，效率非常高了，就这样吧~

```java
class Solution {
    public int longestConsecutive(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        Set<Integer> set = new HashSet<>();
        for(int i = 0; i < nums.length; i++) {
            set.add(nums[i]);
        }

        int max = 0, len, target;
        for(Integer value : set) {
            if(set.contains(value-1)) {
                continue;
            }

            len = 1;
            target = value;

            while(set.contains(target+1)) {
                len++;
                target++;
            }

            max = Math.max(max, len);
        }

        return max;
    }
}

```

##### 2）岛屿数量

###### 深度优先搜索 | O（2 * m * n）

- **思路**：从左到右、从上到下进行遍历，碰到 '1' 后，则进行 count++，然后感染上、下、左、右附近的 '1'，直到遍历完，返回累加好的 count 即可。
- **结论**：时间，2ms，99.80%，空间，46.8mb，14.58%，时间上，遍历+感染过程由于设置了不为 '1' 则返回，且为 '1' 的也会被感染一次后变为 '2'，所以每个位置最多也就被访问 2 遍，时间复杂度为 O（2 * m * n），空间上，由于递归深度最大能达到整个二维数组，所以额外空间复杂度为 O（m * n）。

```java
class Solution {
    public int numIslands(char[][] grid) {
        if(grid == null || grid.length == 0 || grid[0].length == 0) {
            return 0;
        }
        
        int m = grid.length, n = grid[0].length, count = 0;
        for(int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++) {
                if(grid[i][j] == '1') {
                    count++;
                    infect(grid, m, n, i, j);
                }
            }
        }

        return count;
    }

    // m代表高度, n代表宽度
    private void infect(char[][] grid, int m, int n, int i, int j) {
        if(i < 0 || i >= m || j < 0 || j >= n) {
            return;         
        }
        if(grid[i][j] != '1') {
            return;
        }
        
        // 标记访问过的位置为2
        grid[i][j] = '2';
        
        // 继续感染其他相邻的为1的位置
        infect(grid, m, n, i-1, j);// 上
        infect(grid, m, n, i+1, j);// 下
        infect(grid, m, n, i, j-1);// 左
        infect(grid, m, n, i, j+1);// 右
    }
}

```

###### 宽度优先搜索 | O（2 * m * n）

- **思路**：
  1. 看到宽度优先搜索首先想到的就是用队列，碰到为 '1' 的位置则进行 count++，以及感染附近的 '1' 位置。
  2. 不过感染的过程要是宽度优先的，也就是上 -> 下 -> 左 -> 右, 先找完同层的，再找下一层的。
  3. 关键在于找到下层的 '1' 位置后不向递归那样马上进入下层去查找，而是先找完该层才从队列 poll 出来继续找下层的。
- **结论**：
  1. 时间，6ms，22.87%，空间，47.1mb，5.76%，可见对于这些测试用例，效率不如深度优先搜索的。
  2. 时间上，由于每个位置最多被访问两次，所以时间复杂度也是 O（2 * m * n）。
  3. 空间上，由于最多需要构建 m * n 个 Info 对象，所以额外空间复杂度为 O（m * n），不过这里优化成用 row * m + col 的方式可以优化成 max{O（m），O（n）}，即最坏情况下，队列中要么存放了 m 个 Info 对象，表示遍历完了当前 col 的所有行，要么存放了 n 个 Info 对象，表示遍历完了当前 row 的所有列。

```java
class Solution {

    class Info {
        int row;
        int col;

        Info(int row, int col) {
            this.row = row;
            this.col = col;
        }
    }

    public int numIslands(char[][] grid) {
        if(grid == null || grid.length == 0 || grid[0].length == 0) {
            return 0;
        }
        
        Queue<Info> queue = new LinkedList<>();
        Info info;
        
        int m = grid.length, n = grid[0].length, count = 0;
        for(int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++) {
                if(grid[i][j] != '1') {
                    continue;
                }

                count++;
                grid[i][j] = '2';
                queue.offer(new Info(i, j));
                
                // 感染过程 => 宽度优先搜索, 上 -> 下 -> 左 -> 右, 先找完同层的, 再找下一层的
                while(!queue.isEmpty()) {
                    info = queue.poll();

                    // 上
                    if(info.row-1 > -1 && grid[info.row-1][info.col] == '1') {
                        grid[info.row-1][info.col] = '2';
                        queue.offer(new Info(info.row-1, info.col));
                    }
                    // 下
                    if(info.row+1 < m && grid[info.row+1][info.col] == '1') {
                        grid[info.row+1][info.col] = '2';
                        queue.offer(new Info(info.row+1, info.col));
                    }
                    // 左
                    if(info.col-1 > -1 && grid[info.row][info.col-1] == '1') {
                        grid[info.row][info.col-1] = '2';
                        queue.offer(new Info(info.row, info.col-1));
                    }
                    // 右
                    if(info.col+1 < n && grid[info.row][info.col+1] == '1') {
                        grid[info.row][info.col+1] = '2';
                        queue.offer(new Info(info.row, info.col+1));
                    }
                }
            }
        }

        return count;
    }
}

```

###### 并查集法 | O（m * n * α（m*n））

- **思路**：根据题意，需要求附近一片 '1' 的个数，因此可以构建通用 Integer 类型的并查集，通过不断合并 '1' 的集合，最后获取不同 '1' 集合个数即可。
- **结论**：
  1. 时间，55ms，6.38%，50.9mb，5.02%，单线程下的效率并不好，但多线程下可以使得矩阵分块进行并查集统计，大大提升效率。
  2. 时间上，由于只遍历一次，且使用了路径压缩的优化，其中 α（n）反阿克曼函数的值不会超过 5，所以时间复杂度为 O（m * n）。
  3. 空间上，由于使用的是高级数据结构，所以空间复杂度非常高~

```java
class Solution {

    class Element<V> {
        private V value;

        Element(V value) {
            this.value = value;
        }
    }

    class UnionFindSet<V> {
        private Map<V, Element<V>> elementMap = new HashMap<>();
        private Map<Element<V>, Element<V>> fatherMap = new HashMap<>();
        private Map<Element<V>, Integer> sizeMap = new HashMap<>();

        UnionFindSet(Set<V> set) {
            for(V v : set) {
                Element<V> e = new Element<>(v);
                elementMap.put(v, e);
                fatherMap.put(e, e);
                sizeMap.put(e, 1);
            }
        }

        private Element<V> findHeader(V value) {
            LinkedList<Element<V>> stack = new LinkedList<>();

            Element e = elementMap.get(value), ef;
            while(e != (ef = fatherMap.get(e))) {
                stack.push(e);
                e = ef;
            }

            // 路径压缩
            while(!stack.isEmpty()) {
                fatherMap.put(stack.pop(), e);
            }

            return e;
        }

        private boolean isSameSet(V a, V b) {
            if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
                return false;
            }
            return findHeader(a) == findHeader(b);
        }

        void union(V a, V b) {
            if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
                return;
            }
            if(isSameSet(a, b)) {
                return;
            }

            Element<V> af = findHeader(a); 
            Element<V> bf = findHeader(b); 

            if(af != bf) {
                Element<V> big = sizeMap.get(af) > sizeMap.get(bf)? af : bf;
                Element<V> small = big == af? bf : af;
                fatherMap.put(small, big);

                int newSize = sizeMap.get(small) + sizeMap.get(big);
                sizeMap.put(big, newSize);
                sizeMap.remove(small);
            }
        }

        int getSetCount() {
            return sizeMap.size();
        }
    }

    public int numIslands(char[][] grid) {
        if(grid == null || grid.length == 0 || grid[0].length == 0) {
            return 0;
        }
        
        int m = grid.length, n = grid[0].length;
        Set<Integer> set = new HashSet<>();
        for(int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++) {
                // 只初始化'1'的位置, 作为并查集的元素
                if(grid[i][j] == '1') {
                    set.add(i * m + j);
                }
            }
        }

        UnionFindSet<Integer> unionFindSet = new UnionFindSet<>(set);
        for(int i = 0; i < m; i++) {
            for(int j = 0; j < n; j++) {
                if(grid[i][j] != '1') {
                    continue;
                }

                // 合并并查集
                grid[i][j] = '2';
                int p = i * m + j;
                if(i-1 > -1 && grid[i-1][j] == '1') {
                    unionFindSet.union(p, (i-1) * m + j);
                }
                if(i+1 < m && grid[i+1][j] == '1') {
                    unionFindSet.union(p, (i+1) * m + j);
                }
                if(j-1 > -1 && grid[i][j-1] == '1') {
                    unionFindSet.union(p, i * m + (j-1));
                }
                if(j+1 < n && grid[i][j+1] == '1') {
                    unionFindSet.union(p, i * m + (j+1));
                }
            }
        }

        return unionFindSet.getSetCount();
    }
}

```

#### 小根堆/大根堆

##### 1）合并 K 个升序链表

见《链表 - 合并 K 个升序链表》。

##### 2）数组中的第 k 个最大元素

见《第/前 k 个问题 - 数组中的第 k 个最大元素》。

##### 3）会议室2

###### 小根堆模拟法 | O（2 * n * logn）

- **思路**：
  1. 先按**开始时间**对会议进行顺序排序。
  2. 然后提前构造好一个小根堆, 按**结束时间**对会议进行顺序排序。
  3. 接着模拟平常选择会议室的流程（先从最早的会议开始）：
     1. 如果会议室都没人开会，那么直接进入会议室，此时会议室使用数量 + 1。
     2. 如果最早开会的会议室早就空闲了或者刚刚空闲，那么久先请他们出来，然后进入会议室，此时会议室复用，使用数量不变。
     3. 如果确实没有空闲的会议室，然后自己的会议又要开始了，那么就只能开多一间会议室了，此时会议室使用数量 + 1。
- **结论**：时间，6ms，81.11%，空间，41.2mb，11.78%，时间上，对数组排序需要 O（n * logn），遍历每个会议需要 O（n），并且在里面做堆调整需要 O（logn），所以时间复杂度为 O（2 * n * logn），空间上，由于对数组快速排序需要 O（logn）的递归深度，以及还使用了一个小根堆 O（n），所以额外空间复杂度为 O（logn + n）。

```java
class Solution {
    public int minMeetingRooms(int[][] intervals) {
        if(intervals == null || intervals.length == 0) {
            return 0;
        }
        if(intervals.length == 1) {
            return 1;
        }
        
        // 先按开始时间对会议进行顺序排序
        Arrays.sort(intervals, (o1, o2) -> o1[0] - o2[0]);

        // 构建小根堆, 按结束时间对会议进行顺序排序
        PriorityQueue<int[]> queue = new PriorityQueue<>((o1, o2) -> o1[1] - o2[1]);

        // 先从最早的会议开始
        int count = 0;
        for(int i = 0; i < intervals.length; i++) {
            // 没人开会, 则直接进入会议室, 会议室+1
            if(queue.isEmpty()) {
                queue.offer(intervals[i]);
                count++;
            } 
            // 最早结束的会议室空闲了, 则先请他出来, 再进入会议室
            else if(queue.peek()[1] <= intervals[i][0]) {
                queue.poll();
                queue.offer(intervals[i]);
            }
            // 否则开多一间会议室
            else {
                queue.offer(intervals[i]);
                count++;
            }
        }

        return count;
    }
}

```

#### 图

##### 0）模板代码

###### 构建有向图

```java
// 点
class Node {
    int value;
    int in = 0;
    int out = 0;
    List<Node> nextList = new ArrayList<>();
    List<Edge> edgeList = new ArrayList<>();

    Node(int value) {
        this.value = value;
    }
}

// 边
class Edge {
    int weight;
    Node fromNode;
    Node toNode;

    Edge(int weight, Node fromNode, Node toNode) {
        this.weight = weight;
        this.fromNode = fromNode;
        this.toNode = toNode;
    }
}

// 图
class Graph {
    Map<Integer, Node> nodeMap = new HashMap<>();// 点集
    Set<Edge> edgeSet = new HashSet<>();// 边集
}

// 构建有向图
public Graph createGraph(int[][] matrix) {
    Graph graph = new Graph();
    for(int i = 0; i < matrix.length; i++) {
        Integer fromValue = matrix[i][0];
        Integer toValue = matrix[i][1];
        Integer edgeWeight = matrix[i][2];

        if(!graph.nodeMap.containsKey(fromValue)) {
            graph.nodeMap.put(fromValue, new Node(fromValue));
        }
        if(!graph.nodeMap.containsKey(toValue)) {
            graph.nodeMap.put(toValue, new Node(toValue));
        }

        Node fromNode = graph.nodeMap.get(fromValue);
        Node toNode = graph.nodeMap.get(toValue);
        Edge newEdge = new Edge(edgeWeight, fromNode, toNode);
        fromNode.nextList.add(toNode);
        fromNode.out++;
        toNode.in++;
        fromNode.edgeList.add(newEdge);
        graph.edgeSet.add(newEdge);
    }
    return graph;
}

```

###### 宽度优先遍历

```java
// 宽度优先遍历
private void bfs(Node node) {
    if(node == null) {
        return;
    }

    Queue<Node> queue = new LinkedList<>();
    Set<Node> set = new HashSet<>();
    queue.add(node);
    set.add(node);

    while(!queue.isEmpty()) {
        node = queue.poll();
        // 执行node的宽度优先遍历的业务处理
        for(Node next : node.nextList) {
            if(!set.contains(node)) {
                queue.add(next);
                set.add(next);
            }
        }
    }
}

```

###### 深度优先遍历

```java
// 深度优先遍历
private void dfs(Node node) {
    if(node == null) {
        return;
    }

    LinkedList<Node> stack = new LinkedList<>();
    Set<Node> set = new HashSet<>();
    stack.push(node);
    set.add(node);
    // 执行node的深度优先遍历的业务处理

    while(!stack.isEmpty()) {
        node = stack.pop();
        for(Node next : node.nextList) {
            if(!set.contains(next)) {
                stack.push(node);
                stack.push(next);
                set.add(next);
                // 执行next的深度优先遍历的业务处理
                break;
            }
        }
    }
}

```

###### 拓扑排序

```java
// 拓扑排序
private List<Node> sortedTopology(Graph graph) {
    Map<Node, Integer> inMap = new HashMap<>();
    Queue<Node> zeroInQueue = new LinkedList<>();
    for(Node node : graph.nodeMap.values()) {
        inMap.put(node, node.in);
        if(node.in == 0) {
            zeroInQueue.add(node);
        }
    }

    Node cur;
    List<Node> res = new LinkedList<>();
    while(!zeroInQueue.isEmpty()) {
        cur = zeroInQueue.poll();
        res.add(cur);
        for(Node next : cur.nextList) {
            inMap.put(next, inMap.get(next)-1);
            if(inMap.get(next) == 0) {
                zeroInQueue.add(next);
            }
        }
    }

    return res;
}


```

###### 最小生成树 | Kruskal 算法

```java
// k算法(克鲁斯卡尔算法) -> 从边的角度, 去求无向图的最小生成树
private Set<Edge> kruskalMST(Graph graph) {
    UnionFindSet<Node> unionFindSet = new UnionFindSet<>(new HashSet<>(graph.nodeMap.values()));

    // 所有边按权重从小到大排序
    PriorityQueue<Edge> queue = new PriorityQueue<>((o1, o2) -> o1.weight - o2.weight);
    for(Edge edge : graph.edgeSet) {
        queue.offer(edge);
    }

    Edge edge;
    Set<Edge> res = new HashSet<>();
    while(!queue.isEmpty()) {
        edge = queue.poll();
        if(!unionFindSet.isSameSet(edge.fromNode, edge.toNode)) {
            res.add(edge);
            unionFindSet.union(edge.fromNode, edge.toNode);
        }
    }

    return res;
}

// 并查集元素 -> 无向图求最小生成树
class Element<V> {
    private V value;

    Element(V value) {
        this.value = value;
    }
}

// 并查集 -> 无向图求最小生成树
class UnionFindSet<V> {
    private Map<V, Element<V>> elementMap = new HashMap<>();
    private Map<Element<V>, Element<V>> fatherMap = new HashMap<>();
    private Map<Element<V>, Integer> sizeMap = new HashMap<>();

    UnionFindSet(Set<V> set) {
        for(V v : set) {
            Element<V> e = new Element<>(v);
            elementMap.put(v, e);
            fatherMap.put(e, e);
            sizeMap.put(e, 1);
        }
    }

    private Element<V> findHeader(V value) {
        LinkedList<Element<V>> stack = new LinkedList<>();

        Element e = elementMap.get(value), ef;
        while(e != (ef = fatherMap.get(e))) {
            stack.push(e);
            e = ef;
        }

        // 路径压缩
        while(!stack.isEmpty()) {
            fatherMap.put(stack.pop(), e);
        }

        return e;
    }

    private boolean isSameSet(V a, V b) {
        if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
            return false;
        }
        return findHeader(a) == findHeader(b);
    }

    void union(V a, V b) {
        if(!elementMap.containsKey(a) || !elementMap.containsKey(b)) {
            return;
        }
        if(isSameSet(a, b)) {
            return;
        }

        Element<V> af = findHeader(a);
        Element<V> bf = findHeader(b);

        if(af != bf) {
            Element<V> big = sizeMap.get(af) > sizeMap.get(bf)? af : bf;
            Element<V> small = big == af? bf : af;
            fatherMap.put(small, big);

            int newSize = sizeMap.get(small) + sizeMap.get(big);
            sizeMap.put(big, newSize);
            sizeMap.remove(small);
        }
    }
}

```

###### 最小生成树 | Prim 算法

```java
// p算法(普里姆算法) -> 从点的角度, 去求无向图的最小生成树
private Set<Edge> primMST(Graph graph) {
    Set<Edge> res = new HashSet<>();
    HashSet<Node> nodeSet = new HashSet<>();
    PriorityQueue<Edge> queue = new PriorityQueue<>((o1, o2) -> o1.weight - o2.weight);

    // 遍历每个点, 处理森林的问题, 队列没边时会从这里拿点, 去开启另外一个点团的判断 -> 这正是不需要像k算法那样用并查集去合并的原因
    for (Node node : graph.nodeMap.values()) {
        if(nodeSet.contains(node)) {
            continue;
        }

        // 解锁新点中的边, 所有边按权重从小到大排序
        nodeSet.add(node);
        for (Edge edge : node.edgeList) {
            queue.offer(edge);
        }

        // 遍历解锁出来的边, 判断是否能否有新的边又被解锁出来
        while(!queue.isEmpty()){
            Edge edge = queue.poll();

            // 解锁新点中的边, 所有边按权重从小到大排序
            if(!nodeSet.contains(edge.toNode)) {
                nodeSet.add(edge.toNode);
                res.add(edge);
                for (Edge nextEdge : edge.toNode.edgeList) {
                    queue.offer(nextEdge);
                }
            }
        }
    }

    return res;
}

```

###### 点之间最短路径 | Dijkstra 算法

```java
// Dijkstra算法(迪克斯特拉算法) -> 求 head 到每个点之间的最短路径, 其中图内可以有权重为负数的边, 但要求无累加和为负数的环, 但这里实现的算法规定不能有权重为负数的边!
private Map<Node, Integer> dijkstraShortestPath(Node head) {
    // head 到每个点之间的最短路径, 0表示最短, 不存在的则代表正无穷
    Map<Node, Integer> distanceMap = new HashMap<>();
    distanceMap.put(head, 0);

    // 已经得出了最短路径的点, 锁好无需再重复判断
    Set<Node> selectedNodeSet = new HashSet<>();
    Node minNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodeSet);
    while (minNode != null) {
        int distance = distanceMap.get(minNode);
        for (Edge edge : minNode.edgeList) {
            Node toNode = edge.toNode;

            // 不存在则认为路径无限大, 则更新它的最短路径为当前权重
            if(!distanceMap.containsKey(toNode)) {
                distanceMap.put(toNode, distance + edge.weight);
            }
            // 否则更新它的最短路径: 从to以前的路径与当前点到to的路径做比较, 去最小值作为最小路径
            else {
                distanceMap.put(toNode, Math.min(distanceMap.get(toNode), distance + edge.weight));
            }
        }

        // 判断完最小路径后, 则加入锁定集合中, 无需再重复判断
        selectedNodeSet.add(minNode);
        minNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodeSet);
    }

    return distanceMap;
}

// 根据最短路径Map+锁定的点集合, 筛选出下一个用于继续判断最短路径的点 => 经典实现版本O(n), 可自改小根堆优化成O(logn)
private Node getMinDistanceAndUnselectedNode(Map<Node, Integer> distanceMap, Set<Node> selectedNodeSet) {
    Node minNode = null;
    int minDistance = Integer.MAX_VALUE;

    for (Map.Entry<Node, Integer> entry : distanceMap.entrySet()) {
        Node node = entry.getKey();
        int distance = entry.getValue();
        if (!selectedNodeSet.contains(node) && distance < minDistance) {
            minNode = node;
            minDistance = distance;
        }
    }

    return minNode;
}

```

##### 1）课程表

###### 拓扑排序 | O（3m+2n）

- **思路**：
  1. 分析题目可知，对于 [a, b] 表示要学习 a 必须先学习 b，那么可以建立有向图 a <- b，此时 a 的入度为 1（[5，5] 表示要想学习 5 必须先学习 5，这是不可能完成的事件），因此，要想判断最终的结果是否能够全部学完 n 门课程，则可以通过拓扑排序检验入度的方式，把能够学完的课程加入集合，然后判断集合大小与 n 做比较即可。
  2. 其中要注意的是，给出的 [a, b] 数组可能不全，也就是并没有 n 个这个多，即可能会有孤立节点没给出，此时需要在构建图是补充回去~
- **结论**：
  1. 时间，13ms，14.44%，空间，42.2mb，5.00%，时间上，在构建图时，遍历课程先修数组花费了 O（m），遍历给出的 n 门课程花费了 O（n），在拓扑排序时需要花费 O（n + 2m），因此总的时间复杂度为 O（3m+2n），空间上，由于使用的是高级数据结构，所以是非常高的~
  2. 虽然效率不是很理想，但胜在有统一的模板代码，可以把不同的图题目转换统一的代码格式，大大提高了通过率~

```java
class Solution {

    // 点
    class Node {
        int value;
        int in = 0;
        int out = 0;
        List<Node> nextList = new ArrayList<>();
        List<Edge> edgeList = new ArrayList<>();

        Node(int value) {
            this.value = value;
        }
    }

    // 边
    class Edge {
        int weight;
        Node fromNode;
        Node toNode;

        Edge(int weight, Node fromNode, Node toNode) {
            this.weight = weight;
            this.fromNode = fromNode;
            this.toNode = toNode;
        }
    }

    // 图
    class Graph {
        Map<Integer, Node> nodeMap = new HashMap<>();// 点集
        Set<Edge> edgeSet = new HashSet<>();// 边集
    }

    // 构建有向图
    public Graph createGraph(int numCourses, int[][] prerequisites) {
        Graph graph = new Graph();

        for(int i = 0; i < prerequisites.length; i++) {
            Integer toValue = prerequisites[i][0];
            Integer fromValue = prerequisites[i][1];

            if(!graph.nodeMap.containsKey(fromValue)) {
                graph.nodeMap.put(fromValue, new Node(fromValue));
            }
            if(!graph.nodeMap.containsKey(toValue)) {
                graph.nodeMap.put(toValue, new Node(toValue));
            }

            Node fromNode = graph.nodeMap.get(fromValue);
            Node toNode = graph.nodeMap.get(toValue);
            Edge newEdge = new Edge(0, fromNode, toNode);
            fromNode.nextList.add(toNode);
            fromNode.out++;
            toNode.in++;
            fromNode.edgeList.add(newEdge);
            graph.edgeSet.add(newEdge);
        }

        // 补充孤立节点
        for(int i = 0; i < numCourses; i++) {
            if(!graph.nodeMap.containsKey(i)) {
                graph.nodeMap.put(i, new Node(i));
            }
        }

        return graph;
    }

    public boolean canFinish(int numCourses, int[][] prerequisites) {
        if(prerequisites == null || prerequisites.length == 0 || prerequisites[0].length == 0) {
            return true;
        }

        Graph graph = createGraph(numCourses, prerequisites);
        return sortedTopology(graph).size() == numCourses;
    }

     // 拓扑排序
    private List<Node> sortedTopology(Graph graph) {
        Map<Node, Integer> inMap = new HashMap<>();
        Queue<Node> zeroInQueue = new LinkedList<>();
        for(Node node : graph.nodeMap.values()) {
            inMap.put(node, node.in);
            if(node.in == 0) {
                zeroInQueue.add(node);
            }
        }

        Node cur;
        List<Node> res = new LinkedList<>();
        while(!zeroInQueue.isEmpty()) {
            cur = zeroInQueue.poll();
            res.add(cur);
            for(Node next : cur.nextList) {
                inMap.put(next, inMap.get(next)-1);
                if(inMap.get(next) == 0) {
                    zeroInQueue.add(next);
                }
            }
        }

        return res;
    }
}

```

##### 2）除法求值

###### 深度优先搜索 | O（m + [n * 2m]）

- **思路**：根据题意，给定条件 a / b、b / c，要求 b / a 和 a / b、c / a 和 a / c，所以需要构建有向图，且是双向图，然后执行深度优先遍历，如果目标节点存在，则返回遍历路径累计乘积，否则返回 -1。
- **结论**：时间，1ms，55.20%，空间，39.7mb，7.51%，时间上，记条件列表长度 = 值列表长度 = m，问题列表长度 = n，构建图花费了 O（m），遍历问题列表需要花费 O（n），深度优先遍历需要遍历所有节点 O（2 * m），所以时间复杂度为 O（m + [n * 2m]），空间上，由于使用的是高级数据结构，所以额外空间复杂度为非常高~

```java
class Solution {
    
    // 点
    class Node {
        String value;
        int in;
        int out;
        List<Node> nextList = new ArrayList<>();
        List<Edge> toEdgeList = new ArrayList<>();

        Node(String value) {
            this.value = value;
        }
    }

    // 边
    class Edge {
        double weight;
        Node fromNode;
        Node toNode;

        Edge(double weight, Node fromNode, Node toNode) {
            this.weight = weight;
            this.fromNode = fromNode;
            this.toNode = toNode;
        }
    }

    // 图
    class Graph {
        Map<String, Node> nodeMap = new HashMap<>();// 点集
        Set<Edge> edgeSet = new HashSet<>();// 边集
    }

    // 构造双向图: 无向图的变种, a / b 初始化为 a -> b, a <- b
    private Graph createGraph(List<List<String>> equations, double[] values) {
        Graph graph = new Graph();

        // a -> b, b -> a
        Map<String, String> equation1Map = new HashMap<>();
        Map<String, String> equation2Map = new HashMap<>();

        for(int i = 0; i < equations.size(); i++) {
            List<String> equation = equations.get(i);
        
            String value1 = equation.get(0);
            String value2 = equation.get(1);
            double edgeWeight1 = values[i];
            double edgeWeight2 = 1 / values[i];

            // a -> b 相同, 则只取第一个
            if(value2.equals(equation1Map.get(value1))) {
                continue;
            }
            // b -> a 相同, 则只取第一个
            if(value1.equals(equation2Map.get(value2))) {
                continue;
            }           
            equation1Map.put(value1, value2);
            equation2Map.put(value2, value1);

            if(!graph.nodeMap.containsKey(value1)) {
                graph.nodeMap.put(value1, new Node(value1));
            }
            if(!graph.nodeMap.containsKey(value2)) {
                graph.nodeMap.put(value2, new Node(value2));
            }

            Node node1 = graph.nodeMap.get(value1);
            Node node2 = graph.nodeMap.get(value2);

            // a / b 初始化为 a -> b
            Edge edge1 = new Edge(edgeWeight1, node1, node2);
            node1.out++;
            node2.in++;
            node1.nextList.add(node2);
            node1.toEdgeList.add(edge1);
            graph.edgeSet.add(edge1);

            // a / b 初始化为 b -> a
            Edge edge2 = new Edge(edgeWeight2, node2, node1);
            node2.out++;
            node1.in++;
            node2.nextList.add(node1);
            node2.toEdgeList.add(edge2);
            graph.edgeSet.add(edge2);
        }

        return graph;
    }

    public double[] calcEquation(List<List<String>> equations, double[] values, List<List<String>> queries) {
        // 构造双向图: 无向图的变种, a / b 初始化为 a -> b, a <- b
        Graph graph = createGraph(equations, values);

        // 创建返回结果
        double[] res = new double[queries.size()];

        // 遍历问题列表
        for(int i = 0; i < queries.size(); i++) {
            List<String> query = queries.get(i);
            String fromQuery = query.get(0);
            String toQuery = query.get(1);

            // 没有这个条件, 则返回-1
            if(!graph.nodeMap.containsKey(fromQuery) || !graph.nodeMap.containsKey(toQuery)) {
                res[i] = -1;
                continue;
            }

            Node fromNode = graph.nodeMap.get(fromQuery);
            Node toNode = graph.nodeMap.get(toQuery);

            // 条件都存在, 如果比较的是相同节点, 那么直接返回1
            if(fromNode == toNode){
                res[i] = 1;
                continue;
            }

            // 如果比较的是不同节点, 那么遍历图获取对应的结果
            res[i] = dfs(fromNode, toNode);
        }

        return res;
    }

    // 深度优先搜索
    private double dfs(Node fromNode, Node toNode) {
        LinkedList<Node> stack = new LinkedList<>();
        Set<Node> set = new HashSet<>();

        stack.push(fromNode);
        set.add(fromNode);

        boolean hasToNode = false;
        LinkedList<Edge> edgeStack = new LinkedList<>();
        while(!stack.isEmpty()) {
            fromNode = stack.pop();
            for(Edge toEdge : fromNode.toEdgeList) {
                if(!set.contains(toEdge.toNode)) {
                    stack.push(fromNode);
                    stack.push(toEdge.toNode);
                    set.add(toEdge.toNode);
                    edgeStack.push(toEdge);// 边进栈
                    if(toEdge.toNode == toNode) {
                        hasToNode = true;
                    }
                    break;
                }
            }
            // 弹出没用的边
            if(!edgeStack.isEmpty() && edgeStack.peek().toNode == fromNode) {
                edgeStack.pop();
            }
            if(hasToNode) {
                break;
            }
        }

        // 累计路径乘积
        double res = 1;
        while(!edgeStack.isEmpty()) {
            res *= edgeStack.pop().weight;
        }

        return hasToNode? res : -1;
    }
}

```

#### 回溯

##### 1）组合总和

###### 暴力解法 | >= O（m * n）

- **思路**：定义一个 f（end，rest）函数，它返回以 end 结尾的数组中数字和等于 rest 的所有组合。
  1. 尝试使用 0,1,2,..,n 个 end 值去匹配 rest，如果尝试发现大于了 rest 值，则不用再尝试了，因为再大已经不可能了，强调一下这里求得是**以end结尾**，这里不用再考虑前面的了。
  2. 如果 n 个 end 去匹配，发现没有大于 rest，而是等于 rest，此时说明 n * end 就是其中的一个解，此时把它加入集合中，继续尝试 n+1。
  3. 如果 n 个 end 去匹配，发现小于 rest，说明不够，还需要前面的来凑，此时可以调用 f（end-1，rest-n*num[end]）去获取前面匹配剩余值的所有组合列表。
     1. 如果返回的组合列表为空，说明当前 n * end + 前面，都无法匹配 rest，即 n 不是答案，继续尝试 n+1.
     2. 如果返回的组合列表不为空，说明当前 n * end + 前面，是有解的，因此把他们加入集合中，继续尝试下一个。
  4. 最后尝试完所有尝试后（即 n * end > rest），就不用再试了，返回结果即可。
- **结论**：
  1. 由于需要尝试 m 次，每次尝试最差需要遍历整个数组 n，且还需要包括组装返回结果的时间，因此，整体时间复杂度为 O（m * n）以上，但这是不可避免的，也算是 O（m * n）还好吧（3ms，58.65%）。
  2. 空间浪费严重，38.8mb，24.91%，每次都需要构建 ArrayList 才返回，没能做到复用，面试会挂！

```java
class Solution {
    public List<List<Integer>> combinationSum(int[] candidates, int target) {
        if(candidates == null || candidates.length == 0) {
            return new ArrayList<>();
        }
        return f(candidates, candidates.length - 1, target);
    }

    // 以end结尾时的所有数字组合之和等于rest的所有情况, 都存在res集合中
    private List<List<Integer>> f(int[] nums, int end, int rest) {
        if(rest <= 0 || end < 0) {
            return new ArrayList<>();
        }

        // 开始尝试 => 大于rest则返回, 因为已经是相对最小的了
        int sum;
        List<List<Integer>> res = new ArrayList<>();
        for(int i = 0; (sum = i * nums[end]) <= rest; i++) {
            // n个end等于rest时, 则加入集合
            if(sum == rest) {
                List<Integer> members = new ArrayList<>();
                addMembers(members, nums[end], i);
                res.add(members);
            } else {
                // n个end小于rest时, 则看前面的是否组合成功
                if(sum < rest) {
                    // 如果组合成功, 说明end加前面之和等于rest, 则加入最终结果
                    List<List<Integer>> leftRes = f(nums, end - 1, rest - sum);
                    if(!leftRes.isEmpty()) {
                        for(List<Integer> leftMembers : leftRes) {
                            addMembers(leftMembers, nums[end], i);
                            res.add(leftMembers);
                        }
                    }
                    // 如果组合失败, 则再尝试下一个n+1个end
                }
            }
        }

        // 尝试完毕, 返回结果
        return res;
    }

    private void addMembers(List<Integer> members, int value, int i) {
        for(int j = i; j > 0; j--) {
            members.add(value);
        }
    }
}

```

###### 回溯法 | >= O（m * n）

- **思路**：同暴力解法的思路，但好在使用了 ArrayList 根据索引 O（1）remove 的特性，回溯时从后面挨个把当前 i * end 的尝试删掉，以实现一个 ArrayList 重复利用的目的，大大节省了空间。
- **结论**：时间 3m，58.602%，空间 38 mb，99%，可以了，就这样吧。

```java
class Solution {
    public List<List<Integer>> combinationSum(int[] candidates, int target) {
        if(candidates == null || candidates.length == 0) {
            return new ArrayList<>();
        }

        // 回溯剪枝
        List<List<Integer>> res = new ArrayList<>();
        List<Integer> cur = new ArrayList<>();
        f(candidates, res, cur, candidates.length - 1, target);
        return res;
    }

    // f代表尝试以end结尾的数字, 去组合出刚好等于rest的结果
    private void f(int[] nums, List<List<Integer>> res, List<Integer> cur, int end, int rest) {
        if(rest == 0) {
            res.add(new ArrayList<>(cur));
            return;
        }
        if(rest < 0 || end < 0) {
            return;
        }

        // 开始尝试
        for(int i = 0; i * nums[end] <= rest; i++) {
            // 加入尝试
            addMembers(cur, nums[end], i);

            // 子过程去解决剩余的rest
            f(nums, res, cur, end-1, rest - i * nums[end]);
           
            // 回溯时把上面加入的尝试删除
            removeMembers(cur, i);
        }
    }

    private void addMembers(List<Integer> cur, int value, int n) {
        for(int i = n; i > 0; i--) {
            cur.add(value);
        }
    }

    private void removeMembers(List<Integer> cur, int n) {
        for(int i = n; i > 0; i--) {
            cur.remove(cur.size() - 1);
        }
    }
}

```

##### 2）全排列

###### 回溯法 | O（n * n-1）

- **思路**：
  1. 设计一个 f（end）的函数，代表使用 [0~end]结尾之间所有的数字进行全排列，将得到的组合结果设置到 res 里面。
  2. f（end）函数里，通过索引枚举的方式，从 0 枚举到 num.length - 1，每次枚举都尝试把当前 end 数字放到 i 位置上，设置完成后再把剩余位置交给 end-1 数字来完成填充，而关键的一步是，每次在 end-1 填充完毕后，都需要把当前位置的元素清空掉，以腾出空间继续下一次尝试。
  3. 值得注意的是，如果使用的是 List 实现类的 get（i）/set（i）/remove（i），操作 i 位置元素都会先校验 i 是否越界（即 index >= size），这就需要提前把 size 扩充起来，比如填充一堆 null 进去，即可实现 size 赋初值的目的。
  4. 同理，如果在清空 i 位置元素使用的是 remove（i），则又会在删除元素的同时，把 size--，使得下次 set（i）的时候又报越界异常，因此清空元素使用的是 set（i，null），以达到清空了元素又不会减小 size 的目的。
- **结论**：时间 1ms，80.35%，空间 38.4 mb，88.93%，非常高效，就这样吧~

```java
class Solution {
    public List<List<Integer>> permute(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        List<Integer> cur = new ArrayList<>(nums.length);
        for(int i = 0; i < nums.length; i++) {
            cur.add(null);
        }

        List<List<Integer>> res = new LinkedList<>();        
        f(nums, res, cur, nums.length - 1);
        return res;
    }

    // f代表使用[0~end]结尾所有数字参与的全排列组合
    private void f(int[] nums, List<List<Integer>> res, List<Integer> cur, int end) {
        if(end < 0) {
            res.add(new ArrayList<>(cur));
            return;
        }

        for(int i = 0; i < nums.length; i++) {
            // 如果i位置已经被占据了, 那么就尝试下一个位置
            if(cur.get(i) != null) {
                continue;
            }

            // 加入尝试
            cur.set(i, nums[end]);

            // 子过程填完剩下的格子
            f(nums, res, cur, end-1);

            // 回溯时把之前的尝试清空掉, 以腾出空间, 方便继续下一个尝试
            cur.set(i, null);
        }
    }
}

```

##### 3）子集

###### 暴力迭代 | O（n * 2^n）

- **思路**：经过观察可以发现，第 0 的子集，会出现在后面 1,2,3 的子集中，第 1 次的子集，也会出现在 2,3 的子集中，也就是前面出现的子集会作为后面子集的基础，因此，后面添加使用前面添加过的子集，添加完毕后，再作为更后面的基础，直到数组遍历完成。
- **结论**：
  1. 时间，0ms，100%，空间，38.5mb，75.05%，由于需要遍历 n 次数组，每次遍历都有 2^n 个子集基础，所以实现复杂度为 O（n * 2^n），另外，同样的思路也可以用递归来实现。
  2. 由于每次构建的 ArrayList 都被添加到了 res 中，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public List<List<Integer>> subsets(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        List<List<Integer>> res = new ArrayList<>(1 << nums.length);
        res.add(new ArrayList<>());

        for(int i = 0; i < nums.length; i++) {
            List<List<Integer>> new_res = new ArrayList<>(res.size() << 1);
            for(List<Integer> cur : res) {
                List<Integer> new_cur = new ArrayList<>(cur);
                new_cur.add(nums[i]);
                new_res.add(new_cur);
            }
            res.addAll(new_res);
        }

        return res;
    }
}

```

###### 暴力递归 | O（n * 2^n）

- **思路**：参考暴力迭代的思路，使用递归的方式从顶向下地实现。
- **结论**：
  1. 时间，0ms，100%，空间，38.6mb，60.20%，由于需要遍历 n 次数组，每次遍历都有 2^n 个子集基础，所以实现复杂度为 O（n * 2^n），另外，同样的思路也可以用回溯来实现。
  2. 同样，由于每次构建的 ArrayList 都被添加到了 res 中，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public List<List<Integer>> subsets(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }
        return f(nums, nums.length-1);
    }

    // f代表获取[0...end]数字的子集
    private List<List<Integer>> f(int[] nums, int end) {
        if(end < 0) {
            List<List<Integer>> res = new ArrayList<>();
            res.add(new ArrayList<>());
            return res;
        }

        // 获取前子过程的所有子集
        List<List<Integer>> last = f(nums, end-1);

        // 构造2倍的返回结果, 先把前子过程的结果加入当前的结果中
        List<List<Integer>> res = new ArrayList<>(last.size() << 1);
        res.addAll(last);

        // 把当前数字加入子集中
        for(List<Integer> cur : last) {
            List<Integer> new_cur = new ArrayList<>(cur);
            new_cur.add(nums[end]);
            res.add(new_cur);
        }

        return res;
    }
}

```

###### 回溯 | O（n * 2^n）

- **思路**：
  1. 设计一个 f（start，len）函数，代表获取 [start...end] 数字组成的长度为len的子集。
  2. 观察结果可知，[1,2,3] 的数组则需要获取长度为 0,1,2,3 的子集，因此需要分别循环调用 f（0，0）、f（0，1）、f（0，2）、f（0，3）。
  3. 而每次 f（start，len）的实现，都需要从 start 开始遍历 nums 数组，把 i 位置添加到子集中，添加完毕后需要的 len-1，而由于不需要重复的数字，所以 start 也需要从 i+1 开始，然后把剩余的位置交由子过程去实现。
  4. 当每个子过程实现完毕后，都需要把当前的尝试结果删除掉，以便开展新一轮的尝试。
- **结论**：时间，0ms，100%，空间，38.5mb，86.53%，可见由于中间复用了同一个 res 和 cur，所以额外空间读为 O（n），只在开头额外使用了一个 ArrayList。

```java
class Solution {
    public List<List<Integer>> subsets(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        List<List<Integer>> res = new ArrayList<>(1 << nums.length);
        for(int len = 0; len <= nums.length; len++) {
            f(nums, res, new ArrayList<>(len), 0, len);
        }
        return res;
    }

    // f代表获取由[start...end]数字组成的长度为len的子集
    private void f(int[] nums, List<List<Integer>> res, List<Integer> cur, int start, int len) {
        if(len <= 0) {
            res.add(new ArrayList<>(cur));
            return;
        }

        // 从start开始到end, 遍历每个数字
        for(int i = start; i < nums.length; i++) {
            cur.add(nums[i]);
            f(nums, res, cur, i+1, len-1);
            cur.remove(cur.size()-1);
        }
    }
}

```

###### 迭代二进制枚举 | O（n * 2^n）

- **思路**：
  1. 观察结果可以发现，子集数量刚好等于 2^n 个，此时如果用 0表示数字没出现, 1表示数字出现，则可以完美表示子集的状态。
  2. 因此，通过枚举 2^n 个状态，然后根据状态上 1 的位置来反着获取对应的数字，比如 010 就表示索引为 1 的数字应该加入子集中。
- **结论**：
  1. 时间，0ms，100%，38.5mb，85.78%，枚举类 2^n 个，每次枚举状态的判断都需要遍历 n 遍 bitnums 数组，所以时间复杂度为 O（n * 2^n）。
  2. 而由于使用了一个辅助数组 bitnums，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public List<List<Integer>> subsets(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new ArrayList<>();
        }

        List<List<Integer>> res = new ArrayList<>(1 << nums.length);

        // 二进制辅助数组: 001, 010, 100
        int[] bitnums = new int[nums.length];
        for(int i = 0; i < nums.length; i++) {
            bitnums[i] = 1 << i;
        }

        // 枚举二进制结果: 0表示数字没出现, 1表示数字出现
        for(int i = 0; i < (1 << nums.length); i++) {
            List<Integer> cur = new ArrayList<>();
            res.add(cur);

            // 把出现1的数字加入子集中: 010 & 010 => 1位置为1, 则把2加入子集中
            for(int j = 0; j < bitnums.length; j++) {
                if((i & bitnums[j]) != 0) {
                    cur.add(nums[j]);
                }
            }
        }

        return res;
    }
}

```

##### 4）单词搜索

###### 回溯 | O（n * m * s）

- **思路**：
  1. 设计一个 f（end，row，col）函数，代表 [0...end] 的字符是否连续存在矩阵中。
  2. f（end，row，col）通过判断上、下、左、右的字符是否存在矩阵中来实现，只有字符相同且还没使用的才算存在。
  3. 要注意的是，由于递归是自上而下的，且要求矩阵中的字符不能重复使用，所以在顶层判断好后需要先设置为已使用，然后调用子过程才不会被重复使用，而这个尝试在子过程判断到不存在时，还需要在回溯时把它清除掉，以方便进行下一个尝试。
- **结论**：时间，60ms，96.47%，空间，36.1mb，95.07%，效率非常高，由于极端情况下，需要在矩阵的每个位置都尝试一次 O（n * m），而每次尝试又需要找出字符 s 中的每个字符  O（s），因此，时间复杂度最多需要 O（n * m * s）。

```java
class Solution {
    public boolean exist(char[][] board, String word) {
        if(word == null || word.length() == 0) {
            return true;
        }
        if(board == null || board.length == 0 || board[0].length == 0) {
            return false;
        }

        boolean[][] used = new boolean[board.length][board[0].length];
        char[] chars = word.toCharArray();

        for(int i = 0; i < board.length; i++) {
            for(int j = 0; j < board[0].length; j++) {
                if(f(board, used, chars, chars.length-1, i, j)) {
                    return true;
                }
            }
        }

        return false;
    }

    // f代表[0...end]的字符是否连续存在矩阵中
    private boolean f(char[][] board, boolean[][] used, char[] chars, int end, int row, int col) {
        if(row < 0 || row >= board.length || col < 0 || col >= board[0].length) {
            return false;
        }
        if(end == 0) {
            if(!used[row][col] && board[row][col] == chars[end]) {
                return true;
            } else {
                return false;
            }
        }

        // 当前位置是否存在
        if(!used[row][col] && board[row][col] == chars[end]) {

            // 先认为已经使用了
            used[row][col] = true;

            // 且子串也存在时
            if(
                // 上
                f(board, used, chars, end-1, row-1, col)
                // 下
                || f(board, used, chars, end-1, row+1, col)
                // 左
                || f(board, used, chars, end-1, row, col-1)
                // 右
                || f(board, used, chars, end-1, row, col+1)) {
                // 则才认为存在
                return true;
            }

            // 如果不存在, 则在回溯时恢复正常
            used[row][col] = false;
        }

        return false;
    }
}

```

##### 5）括号生成

###### 前缀树法 | O（2^n * 3 * 2）

- **思路**：

  1. 把 ”（” 和 “）” 一次放入前缀树，然后深度优先遍历，最后过滤掉非法括号串就好。
  2. 过滤非法括号串：初始化一个 count=0，从头遍历到尾，碰到  ”（” 则 count+1，碰到  ”）” 则 count-1，期间如果出现负数，或者最后 count 不为 0，则认为该括号串非法。

  ![1641661558130](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641661558130.png)

- **结论**：259ms，5.63%，面试应该不好，实在想不出来时才用这个吧。

```java
class Solution {

    // 前缀树节点
    class Node {
        String value;
        Node[] nodes;
    }

    public List<String> generateParenthesis(int n) {
        List<String> res = new ArrayList<>();

        Node head = new Node();
        head.nodes = new Node[2];

        List<Node> firstNodeList = new ArrayList<>();
        firstNodeList.add(head);

        Map<Integer, List<Node>> levelMap = new HashMap<>();
        levelMap.put(0, firstNodeList);

        // 2n层前缀树
        int level = 2 * n;
        for(int i = 0; i < level; i++) {
            if(!levelMap.containsKey(i)) {
                levelMap.put(i+1, new ArrayList<>());
            }

            List<Node> nodeList = new ArrayList<>();
            for(Node node : levelMap.get(i)) {
                Node[] nodes = node.nodes;

                Node left = new Node();
                Node right = new Node();
                
                left.value = "(";
                right.value = ")";

                nodes[0] = left;
                nodes[1] = right;

                nodeList.add(left);
                nodeList.add(right);

                if(i < level - 1) {
                    left.nodes = new Node[2];
                    right.nodes = new Node[2];
                }
            }
            levelMap.put(i+1, nodeList);
        }

        generateString(res, head, "");
        filterInvalidString(res, n);
        return res;
    }

    private void filterInvalidString(List<String> res, int n) {
        Iterator<String> it = res.iterator();
        while(it.hasNext()) {
            int count = 0;
            String str = it.next();
            boolean isRemove = false;
            for(char c : str.toCharArray()) {
                if(count < 0) {
                    it.remove();
                    isRemove = true;
                    break;
                }
                if(c == '(') {
                    count++;
                } else {
                    count--;
                }
            }
            if(count != 0 && !isRemove) {
                it.remove();
            }
        }
    }

    private void generateString(List<String> res, Node head, String cur) {
        if(head.nodes == null) {
            res.add(cur);
            return;
        }
        
        for(int i = 0; i < head.nodes.length; i++) {
            generateString(res, head.nodes[i], cur + head.nodes[i].value);
        }
    }
}

```

###### 回溯法 | O（2^[f(n-1)+f(n+2)]）

- **思路**：

  1. 如果左括号数量等于右括号数量，则不可以生成右括号了，接下来就交给子过程去完成剩余部分。
  2. 如果左括号数量不等于右括号数量，则还可以继续生成左括号和右括号：
     1. 如果左括号数量还有，则既可以生成左括号，再生成右括号（顺序不规定）。
     2. 但如果左括号数量没有了，则只能生成右括号来填补了。

- **时间复杂度**：

  1. n=1时，需要递归 2^2 次。
  2. n=2时，需要递归 2^3 次。
  3. n=3时，需要递归 2^5 次。
  4. 因此，n=n 时，需要递归 2^[f(n-1)+f(n+2)] 次。

  ![1641665536662](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641665536662.png)

- **结论**：1ms，73.83%，面试主要考这个思路！

```java
class Solution {
    public List<String> generateParenthesis(int n) {
        List<String> res = new ArrayList<>();
        if(n == 0) {
            return res;
        }

        f(res, "", n, n);
        return res;
    }

    private void f(List<String> res, String cur, int l, int r) {
        if(l == 0 && r == 0) {
            res.add(cur);
            return;
        }
    
        // 如果左括号数量等于右括号数量, 则不可以生成右括号
        if(l == r) {
            f(res, cur + "(", l-1, r);
        }
        // 否则, 只能即生成左括号又可以生成右括号
        else {
            // 如果左括号还有, 且左边左右平衡了, 则可以继续加左括号
            if(l > 0) {
                f(res, cur + "(", l-1, r);
            }

            // 或者右括号, 但如果左括号没有了, 则只能填写右括号了
            f(res, cur + ")", l, r-1);
        }
    }
}

```

##### 6）删除无效的括号

###### 回溯 + 剪枝 | O（n * 2^n）

- **思路**：
  1. 按题意，字符串 s 中可能存在小写字母、'('、')' 三种字符，如果需要获取合法的字符串，那么小写字母可以不用管，跳过就好；其他的则还要判断左括号是否匹配，如果不匹配的，则删除多余的括号。
  2. 这里删除最少的多余的括号，可以走统一的算法，即：
     1. 从左遍历到右，碰到左括号，则左待删除+1。
     2. 碰到右括号，如果左待删除为 0，说明前面没有左括号，则右待删除+1，否则说明匹配，要消耗掉一个左括号和右括号，则左待删除-1，右待删除不变。
     3. 最后，返回左待删除和右待删除，表示最少要删除的左括号数和右括号数。
  3. 然后是判断字符串是否为合法的括号串，这可以参考《动态规划 - 最长有效括号》中的判断方法，即从左到右，遍历到左括号则 count++，遍历到右括号则 count--，并且判断此时 count 是否 0，最后还要判断 count 是否为 0。
  4. 再然后就是递归回溯函数的实现了，由于这里要做的是枚举各个字符串的子序列，然后做括号合法性判断，所以需要根据左待删除和右待删除的数量来进行递归，如果待删除的数量都为 0，说明可以做括号合法性判断了，否则还需要尝试删除 0,1,2,...,n-1 位置上的左括号或者右括号...
  5. 其中，回溯过程中的剪枝过程比较重要，可以跳过很多无用的判断，比如如果前面的括号形状和当前的一样，说明当前括号也是必定要留下的，因为如果当前括号要删除，那么在之前早就被删了，所以跳过尝试即可。
- **结论**：时间，3ms，92.98%，空间，41.7mb，5.00%，时间上，由于 n 个字符的子序列有 2^n 种，对其中一种做合法性校验需要花费 O（n），所以时间复杂度为 O（n * 2^n），空间上，由于需要尝试删除 0,1,2,...n-1 位置上的括号，所以额外空间复杂度取决于递归深度，为 O（n）。

```java
class Solution {
    public List<String> removeInvalidParentheses(String s) {
        if(s == null || s.length() == 0) {
            return new ArrayList<>();
        }

        List<String> res = new LinkedList<>();
        int[] lrRemovingCounts = getLrRemovingCount(s);
        f(s, res, 0, lrRemovingCounts[0], lrRemovingCounts[1]);
        return res;
    }

    private void f(String s, List<String> res, int start, int lremove, int rremove) {
        if(lremove == 0 && rremove == 0) {
            if(isValid(s)) {
                res.add(s);
            }
            return;
        }
        
        for(int i = start; i < s.length(); i++) {
            // 由于删除括号后i保持不变, 所以这里剪枝的意思是, 如果前后两个括号相同, 那么删除前和删除后是一样的, 所以这里只处理第一个出现的括号, 后面重复出现的就不再处理了
            if (i != start && s.charAt(i) == s.charAt(i-1)) {
                continue;
            }
            // 如果剩余字符无法满足需要去掉的左括号和右括号数, 则直接返回即可, 无需继续尝试
            if(lremove + rremove > s.length() - i) {
                return;
            }

            // 尝试去掉一个左括号: 由于是字符串截取, 所以截取后还是从i开始, 而不是i+1
            if(lremove > 0 && s.charAt(i) == '(') {
                f(s.substring(0, i) + s.substring(i+1), res, i, lremove-1, rremove);
            }

            // 尝试去掉一个右括号: 由于是字符串截取, 所以截取后还是从i开始, 而不是i+1
            if(rremove > 0 && s.charAt(i) == ')') {
                f(s.substring(0, i) + s.substring(i+1), res, i, lremove, rremove-1);
            }
        }
    }

    private boolean isValid(String s) {
        int count = 0;

        for(int i = 0; i < s.length(); i++) {
            if(s.charAt(i) == '(') {
                count++;
            } else if(s.charAt(i) == ')') {
                count--;
                if(count < 0) {
                    return false;
                }
            }
        }

        return count == 0;
    }

    private int[] getLrRemovingCount(String s) {
        int lremove = 0, rremove = 0;
        
        for(int i = 0; i < s.length(); i++) {
            if(s.charAt(i) == '(') {
                lremove++;
            } else if(s.charAt(i) == ')') {
                if(lremove == 0) {
                    rremove++;
                } else {
                    lremove--;
                }
            }
        }

        return new int[] {lremove, rremove};
    }   
}

```



#### 动态规划

##### 1）正则表达式匹配

###### 暴力递归 | O（s * p * s）

- **思路**：从左到右尝试模型，比的是 s 目标串和 p匹配串从某位置开始，从左到右是否能够**一直**保持匹配。
- **可能性讨论**：
  1. **p[i + 1] 不为 ***：p[i + 1] 越界、p[i + 1] != '*' 都算。
     1. 先看 p[i] 是否匹配，即是否等于 s[i] 或者 '.'。
     2. 如果匹配，则 s 和 p **一起**从左到右尝试，看剩下 f(s+1,p+1) 是否继续匹配。
     3. 如果不匹配，则返回 false，表示不匹配。
  2. **p[i + 1] 为 ***：p[i + 1] == '*'。
     1. 先看 p[i] 是否匹配，即是否等于 s[i] 或者 '.'。
     2. 如果匹配，则 s **自己**从左到到右尝试，依次匹配0,1,2,... 次 p[i]，这种尝试形态上为 f(s+n, p+2)，n 循环变化的。
     3. 如果不匹配，则看 f(s, p+2) ，代表 p 丢弃了 p[i] 与 * 后，剩余的字符是否还能和 s 继续匹配。
- **缺点**：属于尝试的原型，时间复杂度高（9ms，18%），出现算过的位置又重新递归算的地方。

```java
class Solution {
    public boolean isMatch(String s, String p) {
        if((s == null && p == null) || (s == "" && p == "")) {
            return true;
        }
        if((s == null && p != null) || (s != null && p == null) || p == "") {
            return false;
        }
        
        char[] schars = s.toCharArray();
        char[] pchars = p.toCharArray();

        return isValid(pchars) && f(schars, pchars, 0, 0);
    }

    // 用于保证不会出现 **
    private boolean isValid(char[] pchars) {
        for(int i = 0; i < pchars.length; i++) {
            if(pchars[i] == '*') {
                if(i == 0) {
                    return false;
                }
                if(i + 1 < pchars.length && pchars[i + 1] == '*') {
                    return false;
                }
            }
        }

        return true;
    }

    // si、ei：代表s[si...]一直匹配p[pi...]
    // 一定要保证ei不是*, 即保证无后效性, 即前面的讨论情况留到后面来讨论, 这是不对的
    private boolean f(char[] schars, char[] pchars, int si, int pi) {
        // pi越界, 代表表达式串没了, 这时结果取决于s串是否还有
        if(pi == pchars.length) {
            return si == schars.length;
        }

        // 如果pi没有后续字符, 相当于pi+1不是*, 此时结果取决于si与pi一一匹配
        if(pi + 1 == pchars.length || pchars[pi + 1] != '*') {
            // 如果si提前越界了, 说明字符串不匹配
            if(si == schars.length) {
                return false;
            } 
            // 如果si还没越界, 说明还有得判断, 此时结果看pi是否匹配 + 后面是否匹配得上
            else if(pchars[pi] == '.' || pchars[pi] == schars[si]) {
                return f(schars, pchars, si + 1, pi + 1);// 同时保证了pi不为*
            } else {
                return false;
            }
        } 

        // 如果pi有后续字符, 且为 *, 此时需要做*号的匹配判断
        while (si != schars.length && (pchars[pi] == '.' || pchars[pi] == schars[si])) {
            // 如果一路匹配, 则看后面的是否能够继续匹配
            if(f(schars, pchars, si, pi + 2)) {// 同时保证了pi不为*
                // 如果一路匹配同时后面也匹配, 则说明确实匹配
                return true;
            }
            
            si++;
        }

        // 如果s一路匹配到尾了, 则看p是否还有剩余字符
        // 或者pi可能在0,1,2...任何位置不匹配, 则看丢弃掉n*然后后面是否能够从原si位置匹配s成功
        return f(schars, pchars, si, pi + 2);// 同时保证了pi不为*
    }
}

```

###### 记忆化搜索优化 | <= O（s * p * s）

- **思路**：保持着和暴力递归一样的尝试，但通过缓存的方式，减少了一些多余的递归尝试，可以在常数项上降低一点。
- **缺点**：力扣测试用例不多，效果不明显（13ms，16%）。

```java
class Solution {

    private Boolean[][] dp;

    public boolean isMatch(String s, String p) {
        if((s == null && p == null) || (s == "" && p == "")) {
            return true;
        }
        if((s == null && p != null) || (s != null && p == null) || p == "") {
            return false;
        }
        
        char[] schars = s.toCharArray();
        char[] pchars = p.toCharArray();

        // 记忆化搜索优化: si => row, pi => col
        dp = new Boolean[schars.length + 1][pchars.length + 1];
        return isValid(pchars) && f(schars, pchars, 0, 0);
    }

    // 用于保证不会出现 **
    private boolean isValid(char[] pchars) {
        for(int i = 0; i < pchars.length; i++) {
            if(pchars[i] == '*') {
                if(i == 0) {
                    return false;
                }
                if(i + 1 < pchars.length && pchars[i + 1] == '*') {
                    return false;
                }
            }
        }

        return true;
    }

    // si、ei：代表s[si...]一直匹配p[pi...]
    // 一定要保证ei不是*, 即保证无后效性, 即前面的讨论情况留到后面来讨论, 这是不对的
    private boolean f(char[] schars, char[] pchars, int si, int pi) {
        if(dp[si][pi] != null) {
            return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
        }

        // pi越界, 代表表达式串没了, 这时结果取决于s串是否还有
        if(pi == pchars.length) {
            dp[si][pi] = si == schars.length;
            return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
        }

        // 如果pi没有后续字符, 相当于pi+1不是*, 此时结果取决于si与pi一一匹配
        if(pi + 1 == pchars.length || pchars[pi + 1] != '*') {
            // 如果si提前越界了, 说明字符串不匹配
            if(si == schars.length) {
                dp[si][pi] = false;
                return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
            } 
            // 如果si还没越界, 说明还有得判断, 此时结果看pi是否匹配 + 后面是否匹配得上
            else if(pchars[pi] == '.' || pchars[pi] == schars[si]) {
                dp[si][pi] = f(schars, pchars, si + 1, pi + 1);// 同时保证了pi不为*
                return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
            } else {
                dp[si][pi] = false;
                return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
            }
        } 

        // 如果pi有后续字符, 且为 *, 此时需要做*号的匹配判断
        while (si != schars.length && (pchars[pi] == '.' || pchars[pi] == schars[si])) {
            // 如果一路匹配, 则看后面的是否能够继续匹配
            if(f(schars, pchars, si, pi + 2)) {// 同时保证了pi不为*
                // 如果一路匹配同时后面也匹配, 则说明确实匹配
                dp[si][pi] = true;
                return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
            }
            
            si++;
        }

        // 如果s一路匹配到尾了, 则看p是否还有剩余字符
        // 或者pi可能在0,1,2...任何位置不匹配, 则看丢弃掉n*然后后面是否能够从原si位置匹配s成功
        dp[si][pi] = f(schars, pchars, si, pi + 2);// 同时保证了pi不为*
        return dp[si][pi];// 记忆化搜索优化: si => row, pi => col
    }
}

```

###### 严格表结构优化 | O ( s * p）

- **思路**：

  1. 纸上绘制 S、P 两个维度（因为递归中只有两个**变量**），整理 base case 值、分析 dp 位置值依赖关系。
  2. 这道题的 base case 值不明显，需要根据值依赖关系提前倒推出来。
  3. 值依赖关系为 x = 右下角的值、右边第二列值的枚举。
  4. 因此，目标要求的值为第一行第一列格子的值，可以通过从右往左、从下往上求出来并返回。

  ![1641576066088](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641576066088.png)

- **优点**：dp 是对记忆化搜索的一种优化手段，通过绘图得出每个 dp 位置的值依赖计算，从而省去了递归的开销。

- **缺点**：在碰到 * 时会做了一层枚举计算依赖值，应该属于最痛的地方（3ms，38%），后期看看能否通过进行**斜率优化**。

```java
class Solution {

    public boolean isMatch(String s, String p) {
        if((s == null && p == null) || (s == "" && p == "")) {
            return true;
        }
        if((s == null && p != null) || (s != null && p == null) || p == "") {
            return false;
        }
        
        char[] schars = s.toCharArray();
        char[] pchars = p.toCharArray();
        if(!isValid(pchars)) {// 注释掉这步，虽然能过（2ms，83.33%），但逻辑上是不对的
            return false;
        }

        int S = schars.length + 1, P = pchars.length + 1;
        boolean[][] dp = new boolean[S][P];

        // base case 值整理
        dp[S - 2][P - 2] = schars[S - 2] == pchars[P - 2] || pchars[P - 2] == '.';
        dp[S - 1][P - 1] = true;

        // 最后一行 base case 必须为 a*a*a*...的格式, 否则为 true
        for(int pi = P - 3; pi > -1; pi -= 2) {
            if(pchars[pi + 1] == '*') {
                dp[S - 1][pi] = true;
            } else {
                break;
            }
        }

        // 动态规划 dp => 从右往左, 从下往上
        for(int si = S - 2; si > -1; si--) {
            for(int pi = P - 3; pi > - 1; pi--) {
                if(pchars[pi + 1] != '*') {
                    if(pchars[pi] == '.' || pchars[pi] == schars[si]) {
                        dp[si][pi] = dp[si + 1][pi + 1];
                    }
                } else {
                    int i = si;
                    while (i != S - 1 && (pchars[pi] == '.' || pchars[pi] == schars[i])) {
                        if(dp[i][pi + 2]) {
                            dp[si][pi] = true;
                            break;
                        }
                        i++;
                    }

                    dp[si][pi] = dp[i][pi + 2];
                }
            }
        }

        return dp[0][0];
    }

    // 用于保证不会出现 **
    private boolean isValid(char[] pchars) {
        for(int i = 0; i < pchars.length; i++) {
            if(pchars[i] == '*') {
                if(i == 0) {
                    return false;
                }
                if(i + 1 < pchars.length && pchars[i + 1] == '*') {
                    return false;
                }
            }
        }

        return true;
    }
}

```

##### 2）最长有效括号 | 子序列问题不是子串！

###### 二维暴力递归 | O（n^3）

- **思路**：f（start，end）代表从 [start，end] 内最大的有效括号子串长度。
  1. 每次先判断 [start，end] 是否为有效括号串，如果是则直接返回。
  2. 如果整个 [start，end] 不是有效括号串，则尝试看看 [start，end - 1] 和 [start + 1，end] 哪个才是最长的有效括号串，最后把最大值返回即可。
- **缺点**：时间复杂度高，由于 [start，end - 1] 和 [start + 1，end] 的尝试都要花费 O（n^2），因为要看 n-1,n-2,n-3...1 次，且每次看都要花费 O（n），所以一共花费 O（n^3）。
- **结论**：执行超时，面试会挂，考的应该是动态规划！

```java
class Solution {
    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        char[] chars = s.toCharArray();
        return f(chars, 0, chars.length - 1);
    }

    // 以start开头、以end结尾最大的括号子串
    private int f(char[] chars, int start, int end) {
        if(end - start < 1) {
            return 0;// base case
        }
        if(isValid(chars, start, end)) {
            return end - start + 1;// base case
        }
        return Math.max(f(chars, start, end - 1), f(chars, start + 1, end));
    }

    // 判断从start开头到end结尾是否为合格的括号串
    private boolean isValid(char[] chars, int start, int end) {
        int count = 0;
        for(int i = start; i <= end; i++) {
            if(chars[i] == '(') {
                count++;
            } else {
                count--;
            }
            if(count < 0) {
                return false;
            }
        }
        return count == 0;
    }
}

```

###### 二维记忆化搜索优化 | <= O（n^3）

- **思路**：在暴力递归的基础上，增加 dp 二维数组缓存，每次获取前从缓存中获取，每次返回前先塞到缓存中。
- **结论**：**超过内存限制**，面试会挂，应该考的是动态规划，还要继续优化！

```java
class Solution {

    private int[][] dp;

    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        char[] chars = s.toCharArray();
        dp = new int[chars.length][chars.length];
        for(int i = 0; i < chars.length; i++) {
            for(int j = 0; j < chars.length; j++) {
                dp[i][j] = -1;
            }
        }

        return f(chars, 0, chars.length - 1);
    }

    // 以start开头、以end结尾最大的括号子串
    private int f(char[] chars, int start, int end) {
        if(dp[start][end] != -1) {
            return dp[start][end];
        }
        if(end - start < 1) {
            dp[start][end] = 0;
            return dp[start][end];// base case
        }     
        if(isValid(chars, start, end)) {
            dp[start][end] = end - start + 1;
            return dp[start][end];// base case
        }
        
        dp[start][end] = Math.max(f(chars, start, end - 1), f(chars, start + 1, end));
        return dp[start][end];
    }

    // 判断从start开头到end结尾是否为合格的括号串
    private boolean isValid(char[] chars, int start, int end) {
        int count = 0;
        for(int i = start; i <= end; i++) {
            if(chars[i] == '(') {
                count++;
            } else {
                count--;
            }
            if(count < 0) {
                return false;
            }
        }
        return count == 0;
    }
}

```

###### 二维严格表结构优化 | <= O（n^3）

- **思路**：
  1. 根据对记忆化搜索缓存表的观察可得知，f(x，y) 依赖于 f(x，y-1) 和 f（x+1，y），其中 x 代表二维表的高度，y 代表二维表的宽度，也就是依赖于左边和下边的值。
  2. 因此，二维表的初始化顺序为：从下往上（x 减小方向），从左往右（y 增大方向）。
- **结论**：**超过内存限制**，面试会挂，应该考的是**动态规划的空间压缩技巧**，还要继续优化！

```java
class Solution {

    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        int[][] dp = new int[s.length()][s.length()];

        // 从下往上, 从左往右
        for(int i = s.length() - 1; i > -1; i--) {
            for(int j = 0; j < s.length(); j++) {
                if(j - i < 1) {
                    continue;
                }
                if(isValid(s, i, j)) {
                    dp[i][j] = j - i + 1;
                    continue;
                }
                
                dp[i][j] = Math.max(dp[i][j-1], dp[i+1][j]);
            }
        }

        return dp[0][s.length()-1];
    }

    // 判断从start开头到end结尾是否为合格的括号串
    private boolean isValid(String s, int start, int end) {
        int count = 0;
        for(int i = start; i <= end; i++) {
            if(s.charAt(i) == '(') {
                count++;
            } else {
                count--;
            }
            if(count < 0) {
                return false;
            }
        }
        return count == 0;
    }
}

```

###### 二维表空间压缩优化 | <= O（n^3）

- **思路**：
  1. 观察二维表的依赖行为可发现，一个正常的格子只会依赖它的左边和下边，由于是从下往上、从左往右的初始化顺序，所以可以压缩从下往上方向的维度空间。
  2. 压缩方法为，在下次取下格子值的时候，获取当前数组同位置的老值即可，计算出新值后在塞会该位置，然后网上走一层，这样下次再去下格子值时，此时的位置已经算式老值了。
  3. 同时优化 isValid（）函数，在为非偶数，或者左不为 ‘（’，或者右不为 ')' 时，直接返回false，不用在遍历判断了。
- **结论**：
  1. 内存得到保障后，结果又**超出了时间的限制**，面试会挂，还要继续优化！
  2. 摆脱不了 isValid（）函数的话，就永远降不到 O（n）！

```java
class Solution {

    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        // 压缩start的空间
        int[] dp = new int[s.length()];

        // 从下往上, 从左往右
        for(int i = s.length() - 1; i > -1; i--) {
            for(int j = 0; j < s.length(); j++) {
                if(j - i < 1) {
                    continue;
                }
    
                if(isValid(s, i, j)) {
                    dp[j] = j - i + 1;
                    continue;
                }
                
                dp[j] = Math.max(dp[j-1], dp[j]);
            }
        }

        return dp[s.length()-1];
    }

    // 判断从start开头到end结尾是否为合格的括号串
    private boolean isValid(String s, int start, int end) {
        if(end - start + 1 % 2 == 1) {
            return false;
        }
        if(s.charAt(start) != '(') {
            return false;
        }
        if(s.charAt(end) != ')') {
            return false;
        }

        int count = 0;
        for(int i = start; i <= end; i++) {
            if(count < 0) {
                return false;
            }
            if(s.charAt(i) == '(') {
                count++;
            } else {
                count--;
            }
        }
        return count == 0;
    }
}

```

###### 一维暴力递归 | O（n^2）

- **思路**：f（）函数定义为：以 end 字符结尾的子序列，它的最大括号匹配长度为多少，这样就可以将上述二维的递归降到一维，且摆脱了 isValid（）函数的依赖，时间降到了 O（n）级别。
  1. 如果 end 位置越界，或者剩余的字符根本不够 2 个，说明当前子序列肯定是非法的，返回 0 代表非法子序列。
  2. 如果 end 位置为 '('，说明当前子序列肯定也是非法的，返回 0 代表非法子序列。
  3. 如果 end 位置为 ')'，说明当前子序列有可能是合法的，此时还要看前面的字符是否匹配。
     1. 如果 end-1 字符为 '('，说明 end-1 与 end 匹配，此时最大的匹配长度就等于 f（end-1）+ 2。
     2. 如果 end-1 字符为 ')'，说明 end-1 并不与 end 匹配，此时就还要往前看是否有匹配的字符。
        1. 通过计算 f（end-1）得到 end-1 的最大匹配长度，然后用当前下标 end-1-f（end-1），即可得到远处能够匹配当前 end 的字符索引 l。
        2. 如果 l 合法，且为 '('，说明 l 匹配了 end，也就是 end 同时囊括了 l 和 end-1 子序列的最大匹配长度，此时最大的匹配长度为 2 + f（end-1）+ f（l-1）。
        3. 如果 l 不合法，或者为 ')'，说明 end 肯定不是个合法的子序列，因为即使中间的 l+1~end-1 都匹配了，如果没有 l 或者为 ‘)’，那么 end 处的 ')' 就没有 '(' 匹配了，所以返回 0。
- **结论**：暴力递归重复判断了很多次（18ms，5.01%），可以上记忆化搜索来优化。

```java
class Solution {
    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < s.length(); i++) {
            max = Math.max(max, f(s, i));
        }

        return max;
    }

    // 返回以end字符结尾的子串的最大匹配长度
    private int f(String s, int end) {
        // 1) 如果end位置不够或者越界, 说明本子串为非法的括号串, 返回0
        if(end < 1 || end >= s.length()) {
            return 0;// base case
        }
        // 2) 如果end位置为'(', 说明本子串为非法的括号串, 返回0
        if(s.charAt(end) == '(') {
            return 0;// base case
        }

        // 3) end位置为')'
        // 3.1) end-1位置(必存在)为'(', 则匹配end位置的')', 此时最大匹配长度还要看end-2位置的
        if(s.charAt(end - 1) == '(') {
            if(end - 2 > -1) {
                return 2 + f(s, end - 2);
            } else {
                return 2;
            }
        } 
        
        // 3.2) end-1位置为')', 说明不匹配end位置的')', 此时还要继续往前找左括号
        // 最前的左括号位置可能等于 = 当前位置 - 1 - (end-1)的最大匹配长度
        int prelen = f(s, end - 1);
        int l = end - 1 - prelen;

        // 远处存在'(', 则当前的最大匹配长度为: 2 + prelen + f(s, l-1);
        if(l > -1 && s.charAt(l) == '(') {
            return 2 + prelen + f(s, l - 1);
        } else {
            return 0;
        }
    }
}

```

###### 一维记忆化搜索优化 | <= O（n^2）

- **思路**：在一维暴力递归的基础上，增加 dp 一维数组作为缓存，大大减少了不必要的递归。
- **结论**：还是用到了递归（2ms，54.78%），可以分析表依赖，继续优化为动态规划~

```java
class Solution {

    private int[] dp;

    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        // 记忆化搜索优化
        dp = new int[s.length()];
        Arrays.fill(dp, -1);

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < s.length(); i++) {
            max = Math.max(max, f(s, i));
        }

        return max;
    }

    // 返回以end字符结尾的子串的最大匹配长度
    private int f(String s, int end) {
        // 1) 如果end位置不够或者越界, 说明本子串为非法的括号串, 返回0
        if(end < 1 || end >= s.length()) {   
            return 0;// 越界校验
        }
        if(dp[end] != -1) {
            return dp[end];
        }
        
        // 2) 如果end位置为'(', 说明本子串为非法的括号串, 返回0
        if(s.charAt(end) == '(') {
            dp[end] = 0;
            return dp[end];// base case
        }

        // 3) end位置为')'
        // 3.1) end-1位置(必存在)为'(', 则匹配end位置的')', 此时最大匹配长度还要看end-2位置的
        if(s.charAt(end - 1) == '(') {
            if(end - 2 > -1) {
                dp[end] = 2 + f(s, end - 2);
                return dp[end];
            } else {
                dp[end] = 2;
                return dp[end];
            }
        } 
        
        // 3.2) end-1位置为')', 说明不匹配end位置的')', 此时还要继续往前找左括号
        // 最前的左括号位置可能等于 = 当前位置 - 1 - (end-1)的最大匹配长度
        int prelen = f(s, end - 1);
        int l = end - 1 - prelen;

        // 远处存在'(', 则当前的最大匹配长度为: 2 + prelen + f(s, l-1);
        if(l > -1 && s.charAt(l) == '(') {
            dp[end] = 2 + prelen + f(s, l - 1);
            return dp[end];
        } else {
            dp[end] = 0;
            return dp[end];
        }
    }
}

```

###### 一维严格表结构优化 | O（n）

- **思路**：
  1. 在基于一维记忆化搜索进行了优化，通过分析表中的值依赖关系，替换掉递归。
  2. 由于一个正常的格子，依赖于左边第一个，或者左边两个，所以 dp 表需要从左到右进行初始化。
- **结论**：效率非常高（1ms，100%），根据依赖关系，直接在表上就可以完成值设置，面试必过！

```java
class Solution {

    public int longestValidParentheses(String s) {
        if(s == null || s.length() < 2) {
            return 0;
        }

        int[] dp = new int[s.length()];

        // 1) 如果end位置不够或者越界, 说明本子串为非法的括号串, 返回0
        for(int end = 1; end < s.length(); end++) {
            // 2) 如果end位置为'(', 说明本子串为非法的括号串, 返回0
            if(s.charAt(end) == '(') {
                dp[end] = 0;
                continue;
            }

            // 3) end位置为')'
            // 3.1) end-1位置(必存在)为'(', 则匹配end位置的')', 此时最大匹配长度还要看end-2位置的
            if(s.charAt(end - 1) == '(') {
                if(end - 2 > -1) {
                    dp[end] = 2 + dp[end - 2];
                    continue;
                } else {
                    dp[end] = 2;
                    continue;
                }
            } 
            
            // 3.2) end-1位置为')', 说明不匹配end位置的')', 此时还要继续往前找左括号
            // 最前的左括号位置可能等于 = 当前位置 - 1 - (end-1)的最大匹配长度
            int prelen = dp[end - 1];
            int l = end - 1 - prelen;

            // 远处存在'(', 则当前的最大匹配长度为: 2 + prelen + f(s, l-1);
            if(l > -1 && s.charAt(l) == '(') {
                if(l - 1 > -1) {
                    dp[end] = 2 + prelen + dp[l-1];
                } else {
                    dp[end] = 2 + prelen;   
                }
            } else {
                dp[end] = 0;
            }
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < s.length(); i++) {
            max = Math.max(max, dp[i]);
        }

        return max;
    }
}

```

##### 3）最大子数组和

###### 暴力递归1 | O（n^2）

- **思路**：
  1. 设计一个 f（end）函数，代表以 end 结尾的最大子数组的和是多少。
  2. 如果要计算的是以 end 为结尾的子数组之和，那么分为以 end 为结尾，长度分别为 0,1,2...i 的子数组，然后分别求他们的累加和，即得到的以 end 结尾子数组的最大累加和。
  3. 然后再与 end-1 结尾子数组的最大累加和比较，把较大者返回，即得到以 end 结尾的最大子数组和了。
- **结论**：
  1. 执行超时，每次以 end 结尾的 f（end）调用，都会重新算 0~end-1 的和，这是多余的计算，需要被优化掉。
  2. 经过加 dp 缓存优化，发现依然超时，经验告诉我，这应该是一个**通过不了**的尝试，请换一种方向思考。

```java
class Solution {
    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        return f(nums, nums.length - 1);
    }

    // f代表以end结尾的最大子数组的值
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(end == 0) {
            return nums[end];
        }

        int max = Integer.MIN_VALUE, sum = 0;
        for(int i = 0; i < end + 1; i++) {
            sum += nums[end - i];
            max = Math.max(max, sum);
        }

        return Math.max(max, f(nums, end - 1));
    }
}

```

###### 暴力递归2 | O（n^2）

- **思路**：
  1. 还是沿用暴力递归1 的 f（end）函数，代表以 end 结尾的最大子数组的和是多少。
  2. 但不同的在于，暴力递归1 中 f 函数求最大和是通过遍历的方式实现的，而当前方法只是比对前一个过程的最大和，最后才遍历每个 f 函数。
- **结论**：还是执行超时，还是 O（n^2）的解，因为最后遍历每个 f 函数，其实有很多 f 是重新算了，这个可以通过 dp 缓存数组来优化。

```java
class Solution {

    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }
        
        return max;
    }

    // f代表以end结尾的最大子数组的值
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(end == 0) {
            return nums[end];
        }
        return Math.max(nums[end], f(nums, end - 1) + nums[end]);
    }
}

```

###### 记忆化搜索优化 | <= O（n^2）

- **思路**：在暴力递归2 的基础上，增加了 dp 缓存数组，每次取数先取缓存数组中取，每次返回前先设置缓存数组。
- **结论**：时间，5ms，5.58%，空间，47.2mb，80.43%，时间还是很慢，可能是由于很多无效递归导致，还不如直接遍历数组来的高效~

```java
class Solution {

    private int[] dp;

    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        dp = new int[nums.length];
        Arrays.fill(dp, -1);

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }
        
        return max;
    }

    // f代表以end结尾的最大子数组的值
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(dp[end] != -1) {
            return dp[end];
        }
        if(end == 0) {
            dp[end] = nums[end];
            return dp[end];
        }
        dp[end] = Math.max(nums[end], f(nums, end - 1) + nums[end]);
        return dp[end];
    }
}

```

###### 严格表结构优化 | O（2n）

- **思路**：在记忆化搜索的基础上，把原本递归获取值，改成了从一维数组中获取值，大大提高了效率。
- **结论**：时间，2ms，46.16%，空间，47.3mb，77.50%，虽然提升了不少效率，但是还是需要遍历两次，可以再合并优化一下。

```java
class Solution {

    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int[] dp = new int[nums.length];
        dp[0] = nums[0];
        for(int end = 1; end < nums.length; end++) {
            dp[end] = Math.max(nums[end], dp[end-1] + nums[end]);
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, dp[i]);
        }
        
        return max;
    }
}

```

###### 合并后优化 | O（n）

- **思路**：在严格表结构的基础上，合并了两次的遍历。
- **结论**：时间，2ms，46.16%，空间，47.2mb，80.22%，可见**同一指数的时间复杂度差距是不大的**，但由于减少了一次遍历，能**稍微减少空间的使用**。

```java
class Solution {

    public int maxSubArray(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int[] dp = new int[nums.length];
        dp[0] = nums[0];

        int max = nums[0];
        for(int end = 1; end < nums.length; end++) {
            dp[end] = Math.max(nums[end], dp[end-1] + nums[end]);
            max = Math.max(max, dp[end]);
        }

        return max;
    }
}

```

###### 贪心 | O（n）

- **思路**：利用暴力递归2 的思路，即 nums[end], f(nums, end - 1) + nums[end] 取最大值，代表要么取当前数字，要么取之前的数组+当前数字，但与其不同的地方在于，一次 f 就能调完的了，就根本不用在外层又进行一套 max 比较了。
- **结论**：时间，1ms，100%，48.8mb，6.73%，由于只遍历一次，所以对比暴力递归2 省了一层遍历。

```java
class Solution {
    public int maxSubArray(int[] nums) {
       if(nums == null || nums.length == 0) {
            return 0;
        }

        int max = nums[0], cur = nums[0];
        for(int i = 1; i < nums.length; i++) {
            cur = Math.max(cur + nums[i], nums[i]);
            max = Math.max(max, cur);
        }

        return max;
    }
}

```

##### 4）跳跃游戏

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（end）函数，代表从 0 跳到 end 能否完成。
  2. f（end）的实现通过 end 再往前 0,1,2... 个长度进行判断，比如，如果 end-1 位置的值大于 1，且 f（end-1）为 true，那么说明 0~end-1位置可以到达，且 end-1~end 也可以到达，即 f（end）可以到达。
- **结论**：执行超时，因为重复递归了很多次，可以继续优化。

```java
class Solution {
    public boolean canJump(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return true;
        }
        if(nums[0] == 0) {
            return false;
        }

        return f(nums, nums.length - 1);
    }

    // f代表从0跳到end能否完成
    private boolean f(int[] nums, int end) {
        if(end <= 1) {
            return true;
        }

        for(int len = 1; len <= end; len++) {
            if(nums[end - len] >= len) {
                if(f(nums, end - len)) {
                    return true;
                }
            }
        }

        return false;
    }
}

```

###### 记忆化搜索优化 | <= O（n^2）

- **思路**：延续暴力递归的思路，增加了 dp 缓存表，获取前先从缓存中获取，返回前先设置到缓存中。
- **结论**：时间，4ms，21%，空间，40.4mb，16%，效率提升了不少，看还能不能用动态规划优化。

```java
class Solution {

    private Boolean[] dp;

    public boolean canJump(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return true;
        }
        if(nums[0] == 0) {
            return false;
        }

        dp = new Boolean[nums.length];
        return f(nums, nums.length - 1);
    }

    // f代表从0跳到end能否完成
    private boolean f(int[] nums, int end) {
        if(dp[end] != null) {
            return dp[end];
        }
        if(end <= 1) {
            return true;
        }

        for(int len = 1; len <= end; len++) {
            if(nums[end - len] >= len) {
                if(f(nums, end - len)) {
                    dp[end] = true;
                    return dp[end];
                }
            }
        }

        dp[end] = false;
        return dp[end];
    }
}

```

###### 严格表结构优化 | O（n^2）

- **思路**：经过研究值依赖，可以发现，右边的值依赖左边，也就是需要从左到右的初始化。
- **结论**：时间，37ms，16.27%，39.9mb，20%，这是一道记忆化搜索效率由于严格表结构的题，可是为什么？

```java
class Solution {
    public boolean canJump(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return true;
        }
        if(nums[0] == 0) {
            return false;
        }

        boolean[] dp = new boolean[nums.length];
        dp[0] = dp[1] = true;
        
        for(int end = 2; end < nums.length; end++) {
            for(int len = 1; len <= end; len++) {
                if(nums[end - len] >= len && dp[end - len]) {
                    dp[end] = true;
                    break;
                }
            }
        }

        return dp[nums.length-1];
    }
}

```

###### 贪心1 | O（n）

- **思路**：每个位置都记录自身索引 + 自身值的和，代表能够跳到最远的索引位置，如果遍历过程中，发现某个索引 i 已经超过了当前最大能够到达的索引，则返回 false，否则返回 true。
- **结论**：时间，2ms，95.03%，空间，39.9mb，22.14%，效率非常高，贪心不难写，难在想出来，如果用动态规划写出来发现效率不高，那么可以试着想想用贪心实现了。

```java
class Solution {
    public boolean canJump(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return true;
        }
        if(nums[0] == 0) {
            return false;
        }

        int max = nums[0];
        for(int i = 1; i < nums.length; i++) {
            if(i > max) {
                return false;
            }
            max = Math.max(i + nums[i], max);
        }

        return true;
    }
}

```

###### 贪心2 | O（n）

- **思路**：类似于贪心1，比较的也是索引的位置，但贪心2研究的是从最后节点出发，看前一个节点能不能到达上一个节点，如果可以则继续更新，否则就不更新，最后通过判断上一个节点是否为 0 索引位置，即得知是否完成从 0~end 的跳跃了。
- **结论**：时间，1ms，100%，40mb，12.21%，效率和贪心1差不多，都是 O（n）。

```java
class Solution {
    public boolean canJump(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return true;
        }
        if(nums[0] == 0) {
            return false;
        }

        int last = nums.length - 1;
        for(int i = nums.length - 2; i > -1; i--) {
            if(i + nums[i] >= last) {
                last = i;
            }
        }
        
        return last == 0;
    }
}

```

##### 5）不同路径

###### 暴力递归 | O（m * n）

- **思路**：
  1. 设计一个 f（x，y）的函数，代表从 [0,0] 到 [x,y] 一共有多少种路径可走。
  2. f（x，y）的实现通过从 [x，y] 位置，不断地往前枚举，如果有向左的路径，则 +1，如果有向上的路径，则也 +1，否则为 0，而如果 [x，y] 来到了 [0，0] 的位置，则认为原点到原点，只有 1 条路可走。
- **结论**：执行超时，还需要继续优化。

```java
class Solution {
    public int uniquePaths(int m, int n) {
        return f(n-1, m-1);
    }

    // f代表从[0,0]到[x,y]一共有多少种路径
    private int f(int x, int y) {
        if(x < 0 || y < 0) {
            return 0;
        }
        if(x == 0 && y == 0) {
            return 1;
        }
        
        // 左边
        int leftCount = 0;
        if(x - 1 >= -1) {
            leftCount = f(x - 1, y);
        }

        // 上边
        int upCount = 0;
        if(y - 1 >= -1) {
            upCount = f(x, y - 1);
        }

        return leftCount + upCount;
    }
}

```

###### 记忆化搜索 | O（m * n）

- **思路**：沿用了暴力递归的思路，增加了 dp 二维表的缓存，如果缓存中存在则从缓存中拿，否则返回前先设置在缓存中再返回。
- **结论**：时间，0ms，100%，空间，35.2mb，49.19%，效率已经非常高了，减少了很多重复的 f 递归，不过还可以继续优化。

```java
class Solution {
    public int uniquePaths(int m, int n) {
        int[][] dp = new int[m][n];

        // 初始化
        for(int i = 0; i < dp.length; i++) {
            for(int j = 0; j < dp[i].length; j++) {
                dp[i][j] = -1;
            }
        }

        return f(dp, n-1, m-1);
    }

    // f代表从0到[x,y]有多少种路径
    private int f(int[][] dp, int x, int y) {
        if(x < 0 || y < 0) {
            return 0;
        }
        if(dp[y][x] != -1) {
            return dp[y][x];
        }
        if(x == 0 && y == 0) {
            dp[y][x] = 1;
            return dp[y][x];
        }
        
        // 左边
        int leftCount = 0;
        if(x - 1 > -1) {
            leftCount = f(dp, x - 1, y);
        }

        // 上边
        int upCount = 0;
        if(y - 1 > -1) {
            upCount = f(dp, x, y - 1);
        }

        dp[y][x] = leftCount + upCount;
        return dp[y][x];
    }
}

```

###### 严格表结构优化 | O（m * n）

- **思路**：基于记忆化搜索的思路，放弃了 f 的递归，而是通过了二维表来实现，减少了不少栈空间的使用。
- **结论**：时间，0ms，100%，35mb，84.49%，效率非常高，不过还可以用空间压缩的技巧继续优化。

```java
class Solution {
    public int uniquePaths(int m, int n) {
        int[][] dp = new int[m][n];
        
        // 从左到右, 从上到下
        int count;
        for(int y = 0; y < dp.length; y++) {
            for(int x = 0; x < dp[y].length; x++) {
                if(x == 0 && y == 0) {
                    dp[y][x] = 1;
                    continue;
                }

                // 左边
                count = 0;
                if(x - 1 > -1) {
                    count += dp[y][x-1];
                }

                // 上边
                if(y - 1 > -1) {
                    count += dp[y-1][x];
                }

                dp[y][x] = count;
            }
        }

        return dp[m-1][n-1];
    }
}

```

###### 空间压缩优化 | O（m * n）

- **思路**：基于严格表结构的思路，经过二维表值依赖的研究得知，每个值只依赖它的左边和上边，左边可以通过数组中上一个索引获取，而上边可以通过没赋值前的值获取，也就是完全可以把一个二维数组替换成一个一维数组，以减少空间的使用。
- **结论**：时间，0ms，100%，35mb，86%，可能是用例不够多，导致优化出的效果不明显，但这已经是动态规划的最优解了。

```java
class Solution {
    public int uniquePaths(int m, int n) {
        int[] dp = new int[n];
        
        // 从左到右, 从上到下
        int count;
        for(int y = 0; y < m; y++) {
            for(int x = 0; x < n; x++) {
                if(x == 0 && y == 0) {
                    dp[x] = 1;
                    continue;
                }

                // 左边
                count = 0;
                if(x - 1 > -1) {
                    count += dp[x-1];
                }

                // 上边
                if(y - 1 > -1) {
                    count += dp[x];
                }

                dp[x] = count;
            }
        }

        return dp[n-1];
    }
}

```

##### 6）最小路径和

###### 暴力递归 | O（m * n）

- **思路**：
  1. 设计一个 f（x，y）函数，代表从 [0,0] 走到 [x,y] 需要的最小数字总和。
  2. f 实现通过尝试获取左和获取右两边，来对比出最小的路径和，再加上自身的值，就等于来到当前格子的最小数字总和了。
- **结论**：执行超时，还需要继续优化。

```java
class Solution {
    public int minPathSum(int[][] grid) {
        if(grid == null) {
            return 0;
        }
        return f(grid, grid[0].length-1, grid.length-1);
    }

    // f代表从[0,0]走到[x,y]需要的最小数字总和
    private int f(int[][] grid, int x, int y) {
        if(x < 0 || y < 0) {
            return Integer.MAX_VALUE;
        }
        // 防止0位还继续往左或者往上走
        if(x == 0 && y == 0) {
            return grid[y][x];
        }

        return grid[y][x] + Math.min(f(grid, x-1, y), f(grid, x, y-1));
    }
}

```

###### 记忆化搜索 | O（m * n）

- **思路**：基于暴力递归的思路，建立一个 dp 二维数组缓存，如果缓存中存在则从缓存中获取，否则返回前先设置结果到缓存再返回。
- **结论**：时间，2ms，96.47%，41.3mb，20.92%，效率非常高，不过还可以优化，因为其中有很多 f 递归是被重复调用了的。

```java
class Solution {
    public int minPathSum(int[][] grid) {
        if(grid == null) {
            return 0;
        }
        
        int[][] dp = new int[grid.length][grid[0].length];
        for(int i = 0; i < dp.length; i++) {
            for(int j = 0; j < dp[i].length; j++) {
                dp[i][j] = -1;
            }
        }

        return f(grid, dp, grid[0].length-1, grid.length-1);
    }

    // f代表从[0,0]走到[x,y]需要的最小数字总和
    private int f(int[][] grid, int[][] dp, int x, int y) {
        if(x < 0 || y < 0) {
            return Integer.MAX_VALUE;
        }
        // 防止0位还继续往左或者往上走
        if(x == 0 && y == 0) {
            return grid[y][x];
        }
        if(dp[y][x] != -1) {
            return dp[y][x];
        }

        dp[y][x] = grid[y][x] + Math.min(f(grid, dp, x-1, y), f(grid, dp, x, y-1));
        return dp[y][x];
    }
}

```

###### 严格表结构优化 | O（m * n）

- **思路**：基于记忆化搜索的思路，研究了二维表的值依赖，发现每个值只依赖它的左边和上边，因此需要从左到右的初始化。
- **结论**：时间，2ms，96.47%，空间，40.8mb，93.74%，空间上还可以用一维表继续优化。

```java
class Solution {
    public int minPathSum(int[][] grid) {
        if(grid == null) {
            return 0;
        }
        
        int[][] dp = new int[grid.length][grid[0].length];
        dp[0][0] = grid[0][0];

        for(int y = 0; y < dp.length; y++) {
            for(int x = 0; x < dp[y].length; x++) {
                if(x - 1 > -1 && y - 1 > -1) {
                    dp[y][x] = grid[y][x] + Math.min(dp[y][x-1], dp[y-1][x]);
                } else if(x - 1 > -1){
                    dp[y][x] = grid[y][x] + dp[y][x-1];
                } else if(y - 1 > -1){
                    dp[y][x] = grid[y][x] + dp[y-1][x];
                }
            }
        }

        return dp[grid.length-1][grid[0].length-1];
    }
}

```

###### 空间压缩优化 | O（m * n）

- **思路**：基于严格表结构的思路，经过二维表值依赖的研究得知，每个值只依赖它的左边和上边，左边可以通过数组中上一个索引获取，而上边可以通过没赋值前的值获取，也就是完全可以把一个二维数组替换成一个一维数组，以减少空间的使用。
- **结论**：时间，2ms，96.47%，空间，41.2mb，37.59%，可能是用例不够多，导致优化出的效果不明显，但这已经是动态规划的最优解了。

```java
class Solution {
    public int minPathSum(int[][] grid) {
        if(grid == null) {
            return 0;
        }
        
        int[] dp = new int[grid[0].length];
        dp[0] = grid[0][0];

        for(int y = 0; y < grid.length; y++) {
            for(int x = 0; x < grid[0].length; x++) {
                if(x - 1 > -1 && y - 1 > -1) {
                    dp[x] = grid[y][x] + Math.min(dp[x-1], dp[x]);
                } else if(x - 1 > -1){
                    dp[x] = grid[y][x] + dp[x-1];
                } else if(y - 1 > -1){
                    dp[x] = grid[y][x] + dp[x];
                }
            }
        }

        return dp[grid[0].length-1];
    }
}

```

##### 7）编辑距离

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（end1，end2）函数，代表从 [0...end1] 匹配 [0...end2] 需要的最少操作数。
  2. f（end1，end2）函数的实现，通过比较 word1 和 word2 的末尾字符来判断，如果字符相同，则认为匹配，此时最少操作数取决于 f（end1-1，end2-1）子过程的最少操作数。
  3. 如果字符不相同，则认为本次需要操作，即操作数 + 1，不过总的最少操作数还是要取决于子过程的最少操作数：
     1. 如果尝试了新增操作，那么 word1 就新增了一个匹配的字符，用于匹配 word2 的末尾字符，此时 word2 也少了一个字符，所以子过程的最少操作数为 f（end1，end2-1）。
     2. 如果尝试了删除操作，那么 word1 就删除了一个末尾字符，即 word1 少了一个字符，此时子过程的最少操作数为 f（end1-1，end2）。
     3. 如果尝试了替换操作，那么 word1 就需要替换一个末尾字符，即 word1 和 word2 的字符数都不变，此时子过程的最少操作为 f（end1-1，end2-1）。
     4. 最后只要返回最少操作数的那个尝试，再 +1 即等于当前 end1 和 end2 匹配的最少操作数。
- **结论**：执行超时，由于可能多次调用同一个参数的 f 递归，所以还有优化的空间。

```java
class Solution {
    public int minDistance(String word1, String word2) {
        if(word1 == null && word2 == null) {
            return 0;
        } else if(word1 == null) {
            return word2.length();
        } else if(word2 == null) {
            return word1.length();
        }

        return f(word1, word2, word1.length()-1, word2.length()-1);
    }

    // f代表从[0...end1]匹配[0...end2]需要的最少操作数
    private int f(String word1, String word2, int end1, int end2) {
        // 同时没有那么就不需要操作
        if(end1 < 0 && end2 < 0) {
            return 0;
        }
        // 如果匹配串没有, 但原串还有, 那么就需要插入多少
        else if(end1 < 0) {
            return end2 + 1;
        }
        // 如果原串没有, 但匹配串还有, 那么就需要删除多少
        else if(end2 < 0) {
            return end1 + 1;
        }
        // 否则其他情况, 则按递归去匹配
        // 如果end1等于end2, 那么则无需操作
        if(word1.charAt(end1) == word2.charAt(end2)) {
            return f(word1, word2, end1-1, end2-1);
        }
        // 否则枚举增删改的操作
        return 1 + Math.min(
            // 增
            f(word1, word2, end1, end2 - 1), 
            Math.min(
                // 删
                f(word1, word2, end1-1, end2), 
                // 改
                f(word1, word2, end1-1, end2-1)
            )
        );
    }
}

```

###### 记忆化搜索 | O（n）

- **思路**：基于暴力递归的思路，增加了 dp 二维表缓存，如果缓存中存在则从缓存中获取，否则返回前先把结果设置到缓存中再返回。
- **结论**：时间，3ms，99.64%，空间，38.7mb，5.03%，多次调用了无用的递归，还可以继续优化。

```java
class Solution {
    public int minDistance(String word1, String word2) {
        if(word1 == null && word2 == null) {
            return 0;
        } else if(word1 == null) {
            return word2.length();
        } else if(word2 == null) {
            return word1.length();
        }

        int[][] dp = new int[word1.length()][word2.length()];
        for(int i = 0; i < dp.length; i++) {
            for(int j = 0; j < dp[i].length; j++) {
                dp[i][j] = -1;
            }
        }

        return f(dp, word1, word2, word1.length()-1, word2.length()-1);
    }

    // f代表从[0...end1]匹配[0...end2]需要的最少操作数
    private int f(int[][] dp, String word1, String word2, int end1, int end2) {
        // 同时没有那么就不需要操作
        if(end1 < 0 && end2 < 0) {
            return 0;
        }
        // 如果匹配串没有, 但原串还有, 那么就需要插入多少
        else if(end1 < 0) {
            return end2 + 1;
        }
        // 如果原串没有, 但匹配串还有, 那么就需要删除多少
        else if(end2 < 0) {
            return end1 + 1;
        }
        if(dp[end1][end2] != -1) {
            return dp[end1][end2];
        }

        // 否则其他情况, 则按递归去匹配
        // 如果end1等于end2, 那么则无需操作
        if(word1.charAt(end1) == word2.charAt(end2)) {
            dp[end1][end2] = f(dp, word1, word2, end1-1, end2-1);
            return dp[end1][end2];
        }

        // 否则枚举增删改的操作
        dp[end1][end2] = 1 + Math.min(
            // 增
            f(dp, word1, word2, end1, end2 - 1), 
            Math.min(
                // 删
                f(dp, word1, word2, end1-1, end2), 
                // 改
                f(dp, word1, word2, end1-1, end2-1)
            )
        );
        return dp[end1][end2];
    }
}

```

###### 严格表结构优化 | O（n * m）

- **思路**：基于记忆化搜索的思路，把递归改成了二维表的动态规划，减少了空间的使用。
- **结论**：时间，6ms，20.34%，38.4mb，74.76%，改成了动态规划后发现，空间使用减少了，但时间复杂度变成了 O（n * m），所以二维表的动态规划并不是最优解。

```java
class Solution {
    public int minDistance(String word1, String word2) {
        if(word1 == null && word2 == null) {
            return 0;
        } else if(word1 == null) {
            return word2.length();
        } else if(word2 == null) {
            return word1.length();
        } else if(word1.length() == 0) {
            return word2.length();
        } else if(word2.length() == 0) {
            return word1.length();
        }

        int[][] dp = new int[word1.length()][word2.length()];
        for(int end1 = 0; end1 < dp.length; end1++) {
            for(int end2 = 0; end2 < dp[end1].length; end2++) {
                // 否则其他情况, 则按递归去匹配
                // 如果end1等于end2, 那么则无需操作
                if(word1.charAt(end1) == word2.charAt(end2)) {
                    dp[end1][end2] = getValue(dp, end1-1, end2-1);
                    continue;
                }

                // 否则枚举增删改的操作
                dp[end1][end2] = 1 + Math.min(
                    // 增
                    getValue(dp, end1, end2-1),
                    Math.min(
                        // 删
                        getValue(dp, end1-1, end2),
                        // 改
                        getValue(dp, end1-1, end2-1)
                    )
                );
            }
        }

        return dp[word1.length()-1][word2.length()-1];
    }

    private int getValue(int[][] dp, int end1, int end2) {
        int predictRes = predict(end1, end2);
        return predictRes != -1? predictRes : dp[end1][end2];
    }

    // 根据下标预测出操作数
    private int predict(int end1, int end2) {
        // 同时没有那么就不需要操作
        if(end1 < 0 && end2 < 0) {
            return 0;
        }
        // 如果匹配串没有, 但原串还有, 那么就需要插入多少
        else if(end1 < 0) {
            return end2 + 1;
        }
        // 如果原串没有, 但匹配串还有, 那么就需要删除多少
        else if(end2 < 0) {
            return end1 + 1;
        }
        else {
            return -1;
        }
    }
}

```

##### 8）不同的二叉搜索树

###### 暴力递归 | O（n^2）

- **思路**：
  1. 观察每个 n 的结果可以发现，如果固定好 n=0,1,2,3 这些返回值，然后把 n=4 看做成一个 [0,1,2,3,4] 的节点值数组，就可以很容易直到答案了。
  2. n=4 时，[0,1,2,3]，从左到右分为：f(0) * f(3) + f(1) * f(2) + f(2) * f(1) + f(3) * f(0) = 5 + 2 + 2 + 5 = 14。
     1. 当使用 nums[0] 作为根节点，左边有 0 个节点为 f（0），而右边有 3 个节点为 f（3），因此总的二叉搜索树种数有 f（0） * f（3）种。
     2. 当使用 nums[1] 作为根节点，左边有 1 个节点为 f（1），而右边有 2 个节点为 f（2），因此总的二叉搜索树种数有 f（1） * f（2）种。
     3. 当使用 nums[1] 作为根节点，左边有 2 个节点为 f（2），而右边有 1 个节点为 f（1），因此总的二叉搜索树种数有 f（2） * f（1）种。
     4. 当使用 nums[3] 作为根节点，左边有 3 个节点为 f（3），而右边有 0 个节点为 f（0），因此总的二叉搜索树种数有 f（3） * f（0）种。
     5. 因此，n=4 时，总的二叉树种数为：f(0) * f(3) + f(1) * f(2) + f(2) * f(1) + f(3) * f(0) = 5 + 2 + 2 + 5 = 14。
- **结论**：时间，475ms，6.63%，空间，34.9mb，84.22%，由于每次递归都需要往外扩散 n，从左到右需要触发 n 次，所以时间复杂度为 O（n^2）。

```java
class Solution {
    public int numTrees(int n) {
        if(n == 0) {
            return 1;
        }
        if(n == 1 || n == 2) {
            return n;
        }
        if(n == 3) {
            return 5;
        }

        // n=4时, [0,1,2,3], 从左到右分为: f(3)+f(1)*f(2)+f(2)*f(1)+f(3)=5+2+2+5=14
        int sum = 0;
        for(int i = 0; i < n; i++) {
            sum += numTrees(i) * numTrees(n-1-i);
        }

        return sum;
    }
}

```

###### 记忆化搜索 | O（n）

- **思路**：基于暴力递归的思路，增加了一个一维表的 dp 缓存数组，递归时，如果发现缓存中存在则从缓存获取，否则返回前先设置结果到缓存中再返回。
- **结论**：时间，0ms，100%，34.8mb，92.99%，效率非常高，这应该是该思路最优的了，再优化成动态规划就有点画蛇添足了。

```java
class Solution {
    public int numTrees(int n) {
        int[] dp = new int[n+1];
        Arrays.fill(dp, -1);
        return f(dp, n);
    }

    // n=4时, [0,1,2,3], 从左到右分为: f(3)+f(1)*f(2)+f(2)*f(1)+f(3)=5+2+2+5=14
    private int f(int[] dp, int n) {
        if(dp[n] != -1) {
            return dp[n];
        }
        if(n == 0) {
            dp[n] = 1;
            return dp[n];
        }
        if(n == 1 || n == 2) {
            dp[n] = n;
            return dp[n];
        }
        if(n == 3) {
            dp[n] = 5;
            return dp[n];
        }

        int sum = 0;
        for(int i = 0; i < n; i++) {
            sum += f(dp, i) * f(dp, n-1-i);
        }

        dp[n] = sum;
        return dp[n];
    }
}

```

##### 9）单词拆分

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（end）函数，代表 [0...end] 字符串能否从map中拼接出来。
  2. f（end）的实现通过遍历每个 end,end-1,end-2... 字符是否在字典中 + 再往前的剩余字符串能否被拼接出来，来得到当前结果。
- **结论**：执行超时，由于没作任何处理，导致出现了很多重复的递归，浪费了计算时间。

```java
class Solution {
    public boolean wordBreak(String s, List<String> wordDict) {
        if(s == null || s.length() == 0) {
            return true;
        }
        if(wordDict == null || wordDict.isEmpty()) {
            return false;
        }
        
        Map<String, Integer> map = new HashMap<>();
        for(int i = 0; i < wordDict.size(); i++) {
            map.put(wordDict.get(i), i);
        }

        return f(s, map, s.length()-1);
    }

    // f代表[0...end]字符串能否从map中拼接出来
    private boolean f(String s, Map<String, Integer> map, int end) {
        if(end < 0) {
            return false;
        }

        // 先判断以自身为字符串是否存在map中
        if(map.containsKey(s.substring(0, end+1))) {
            return true;
        }

        // 再判断当前字符+剩余字符串
        for(int i = end; i > -1; i--) {
            if(map.containsKey(s.substring(i, end+1)) && f(s, map, i-1)) {
                return true;
            }
        }

        return false;
    }
}

```

###### 记忆化搜索 | O（n）

- **思路**：沿用暴力递归的思路，增加了 dp 一维数组缓存，如果在缓存中存在则从获取中获取，否则先设置结果到缓存中再返回。
- **结论**：时间，6ms，73.83%，空间，38.5mb，62.13%，效率提升了不少，看还能不能用动态规划来优化下。

```java
class Solution {
    public boolean wordBreak(String s, List<String> wordDict) {
        if(s == null || s.length() == 0) {
            return true;
        }
        if(wordDict == null || wordDict.isEmpty()) {
            return false;
        }
        
        Map<String, Integer> map = new HashMap<>();
        for(int i = 0; i < wordDict.size(); i++) {
            map.put(wordDict.get(i), i);
        }

        Boolean[] dp = new Boolean[s.length()];
        return f(s, map, dp, s.length()-1);
    }

    // f代表[0...end]字符串能否从map中拼接出来
    private boolean f(String s, Map<String, Integer> map, Boolean[] dp, int end) {
        if(end < 0) {
            return false;
        }
        if(dp[end] != null) {
            return dp[end];
        }

        // 先判断以自身为字符串是否存在map中
        if(map.containsKey(s.substring(0, end+1))) {
            dp[end] = true;
            return dp[end];
        }

        // 再判断当前字符+剩余字符串
        for(int i = end; i > -1; i--) {
            if(map.containsKey(s.substring(i, end+1)) && f(s, map, dp, i-1)) {
                dp[end] = true;
                return dp[end];
            }
        }

        dp[end] = false;
        return dp[end];
    }
}

```

###### 严格表结构优化 | O（n）

- **思路**：通过把记忆化搜索的递归行为，优化成从 dp 数组取数的动态规划，免去了递归的调用。
- **结论**：
  1. 时间，4ms，81.34%，空间，38.3%，73.40%，效率提升很多了，就这样吧~
  2. 同时还发现，如果要想严格表结构改的比记忆化搜索的效率还好，那么就要尽量把逻辑卸载暴力递归中的递归函数中，这样才能把递归函数调用优化成从 dp 表中取数的动态规划，不然效率好像提升不大，甚至还降低！

```java
class Solution {
    public boolean wordBreak(String s, List<String> wordDict) {
        if(s == null || s.length() == 0) {
            return true;
        }
        if(wordDict == null || wordDict.isEmpty()) {
            return false;
        }
        
        Map<String, Integer> map = new HashMap<>();
        for(int i = 0; i < wordDict.size(); i++) {
            map.put(wordDict.get(i), i);
        }

        boolean[] dp = new boolean[s.length()];
        dp[0] = map.containsKey(s.substring(0, 1));

        int end = 1;
        while(end < s.length()) {
            // 先判断以自身为字符串是否存在map中
            if(map.containsKey(s.substring(0, end+1))) {
                dp[end] = true;
            }
            else {
                // 再判断当前字符+剩余字符串
                for(int i = end; i > -1; i--) {
                    if(i == 0) {
                        dp[end] = map.containsKey(s.substring(i, end+1));
                         break;
                    }
                    else {
                        if(map.containsKey(s.substring(i, end+1)) && dp[i-1]) {
                            dp[end] = true;
                            break;
                        }
                    }
                }
            }

            end++;
        }

        return dp[s.length()-1];
    }
}

```

##### 10）乘积最大子数组

###### 暴力递归 | O（n^2）

- **思路**：
  1. 看到子数组就想到以 end 结尾子数组，不过这题求的是最大乘积，与最大和不同的是，乘积有正负之分，还需要研究当前位的正负状态。
  2. 如果当前位是正数，那么最大乘积应该等于 max{当前值，当前值 * 前面的最大值}，其中这个最大值可能是最小的负数和最大的正数。
  3. 如果当前位是负数，那么最大乘积应该等于 max{当前值，当前值 * 前面的最小值}，其中这个最小值可能是最大的负数和最小的正数。
  4. 最后循环遍历每个下标，对比每个以 end 结尾的子数组的最大乘积，取最大的一个并返回。
- **结论**：执行超时，由于循环遍历调用递归时，执行了很多重复的递归操作，所以还需要继续优化~

```java
class Solution {

    // 子数组的最大乘积与最小乘积
    class Finfo {
        int max;
        int min;

        Finfo(int max, int min) {
            this.max = max;
            this.min = min;
        }
    }

    public int maxProduct(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i).max);
        }

        return max;
    }

    // f代表以end结尾的子数组的最大乘积与最小乘积
    private Finfo f(int[] nums, int end) {
        if(end == 0) {
            return new Finfo(nums[end], nums[end]);
        }

        Finfo finfo = f(nums, end-1);
        if(nums[end] < 0) {
            return new Finfo(
                Math.max(nums[end], nums[end] * finfo.min), 
                Math.min(nums[end], nums[end] * finfo.max)
            );
        } else {
            return new Finfo(
                Math.max(nums[end], nums[end] * finfo.max), 
                Math.min(nums[end], nums[end] * finfo.min)
            );
        }
    }
}

```

###### 记忆化搜索 | O（n）

- **思路**：沿用暴力递归的思路，增加了 dp 一维表缓存，如果缓存中存在，则直接从缓存中获取，否则则把结果先存入缓存再返回。
- **结论**：时间，1ms，97%，空间，39.7mb，5.15%，效率非常高了，看优化成动态规划的形式有没有性能上的提升~

```java
class Solution {

    // 子数组的最大乘积与最小乘积
    class Finfo {
        int max;
        int min;

        Finfo(int max, int min) {
            this.max = max;
            this.min = min;
        }
    }

    private Finfo[] dp;

    public int maxProduct(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        dp = new Finfo[nums.length];

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i).max);
        }

        return max;
    }

    // f代表以end结尾的子数组的最大乘积与最小乘积
    private Finfo f(int[] nums, int end) {
        if(end == 0) {
            dp[end] = new Finfo(nums[end], nums[end]);
            return dp[end];
        }
        if(dp[end] != null) {
            return dp[end];
        }

        Finfo finfo = f(nums, end-1);
        if(nums[end] < 0) {
            dp[end] = new Finfo(
                Math.max(nums[end], nums[end] * finfo.min), 
                Math.min(nums[end], nums[end] * finfo.max)
            );
            return dp[end];
        } else {
            dp[end] = new Finfo(
                Math.max(nums[end], nums[end] * finfo.max), 
                Math.min(nums[end], nums[end] * finfo.min)
            );
            return dp[end];
        }
    }
}

```

###### 严格表结构优化 | O（n）

- **思路**：在记忆化搜索的基础上，研究了值关系依赖，发现是后面的值依赖前面的值，所以这是一个从左到右的模型，则先初始化 dp[0]，然后从左到右填充 dp 数组，以替代过多的递归行为。
- **结论**：
  1. 时间，1ms，97%，空间，39.7mb，5.15%，可见优化的效果并不明显，就这样吧~
  2. 不过有了新的心得，凡是记忆化搜索改动态规划，无论主函数怎么调的递归，都一定要**先填充好 dp 数组**，再用主函数的调用方法去调，这样是为了分离两个遍历，控制时间复杂度与记忆化搜索一致，不然很可能搞出比记忆化搜索大的时间复杂度，那样就得不偿失了~

```java
class Solution {

    // 子数组的最大乘积与最小乘积
    class Finfo {
        int max;
        int min;

        Finfo(int max, int min) {
            this.max = max;
            this.min = min;
        }
    }

    public int maxProduct(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        Finfo[] dp = new Finfo[nums.length];
        dp[0] = new Finfo(nums[0], nums[0]);
        for(int end = 1; end < nums.length; end++) {
            if(nums[end] < 0) {
                dp[end] = new Finfo(
                    Math.max(nums[end], nums[end] * dp[end-1].min), 
                    Math.min(nums[end], nums[end] * dp[end-1].max)
                );
            } else {
                dp[end] = new Finfo(
                    Math.max(nums[end], nums[end] * dp[end-1].max), 
                    Math.min(nums[end], nums[end] * dp[end-1].min)
                );
            }
        }

        int max = Integer.MIN_VALUE;
        for(int end = 0; end < nums.length; end++) {
            max = Math.max(max, dp[end].max);
        }

        return max;
    }
}

```

##### 11）打家劫舍

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（end）函数，代表必须以 end 结尾的方案，最多能偷多少钱。
  2. 其中，f 函数的实现分为 3 种情况：
     1. 不偷当前这家的钱，看偷前 1 家的最大结果。
     2. 只投当前这家的钱。
     3. 既偷当前这家的钱，又继续看偷前前 1 家的最大结果。
  3. 三种情况取最大值返回即可作为当前 f（end）函数的返回值。
  4. 而最终的最大结果，还要从 0,1,2...length-1 不断尝试，比较出最大结果并返回。
- **结论**：执行超时，由于存在超多重复的递归，所以还需要继续优化~

```java
class Solution {
    public int rob(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }

        return max;
    }
    
    // f代表偷取以end为结尾最多能偷多少钱
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(end == 0) {
            return nums[0];
        }
        if(end == 1) {
            return Math.max(nums[0], nums[1]);
        }

        return Math.max(
            // 不偷这家, 看偷前1家的最大值
            f(nums, end-1),
            Math.max(
                // 只偷这家
                nums[end],
                // 偷这家+看偷前前1家的最大值 
                nums[end] + f(nums, end-2)
            )
        );
    }
}

```

###### 记忆化搜索 | O（2n）

- **思路**：沿用暴力递归的思路，增加了 dp 一维表缓存，如果缓存中存在则直接从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，0ms，100%，空间，36mb，5.50%，由于存在很多多余的递归，占据了很多压栈的空间，所以还需要优化成动态规划，以减少额外空间复杂度。

```java
class Solution {

    private int[] dp;

    public int rob(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        dp = new int[nums.length];
        Arrays.fill(dp, -1);

        int max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }

        return max;
    }
    
    // f代表偷取以end为结尾最多能偷多少钱
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(dp[end] != -1) {
            return dp[end];
        }
        if(end == 0) {
            dp[0] = nums[0];
            return dp[0];
        }
        if(end == 1) {
            dp[1] = Math.max(nums[0], nums[1]);
            return dp[1];
        }

        dp[end] = Math.max(
            // 不偷这家, 看偷前1家的最大值
            f(nums, end-1),
            Math.max(
                // 只偷这家
                nums[end],
                // 偷这家+看偷前前1家的最大值 
                nums[end] + f(nums, end-2)
            )
        );
        
        return dp[end];
    }
}

```

###### 严格表结构优化 | O（2n）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，可知，一个值依赖于它的前一个和前前一个，所以这是一个从左到右的尝试模型，需要先初始化好 dp[0] 和 dp[1]，然后从左到右去给 dp 数组赋值即可。
- **结论**：时间，0ms，100%，空间，36.1mb，5.50%，经过动态规划把递归优化成了 dp 数组取值，优化掉了递归的压栈空间，但应该是测试用例不多，所以优化效果并不明显~

```java
class Solution {

    public int rob(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        if(nums.length == 1) {
            return nums[0];
        }
        
        int[] dp = new int[nums.length];
        dp[0] = nums[0];
        dp[1] = Math.max(nums[0], nums[1]);
        for(int end = 2; end < nums.length; end++) {
            dp[end] = Math.max(
                // 不偷这家, 看偷前1家的最大值
                dp[end-1],
                Math.max(
                    // 只偷这家
                    nums[end],
                    // 偷这家+看偷前前1家的最大值 
                    nums[end] + dp[end-2]
                )
            );
        }

        int max = 0;
        for(int end = 0; end < nums.length; end++) {
            max = Math.max(max, dp[end]);
        }

        return max;
    }
}

```

##### 12）完全平方数

###### 暴力递归 | O（[√n] ^ m）

- **思路**：
  1. 设计一个 f（n）函数，代表获取数字 n 完全平方数的最少个数。
  2. 其中，f（n）函数通过枚举 0,1,2...√n，然后再递归调用 f（n - i）得到子过程完全平方数的最少个数，再 +1 得到当前尝试 i 完全平方数的最少个数。
  3. 当前所有尝试 i 都尝试完毕后，取最小的尝试结果即是当前 n 完全平方数的最少个数。 
- **结论**：执行超时，由于 f（n）时需要遍历 √n 次，每次遍历又需要分别调用子过程 f（n-i^2），子过程又要遍历 √n-i^2 次...，记 n-i^2 = a,b,c...,z，那么每次遍历时间花费平均为 √a * √b... * √z，因此时间复杂度为 O（√n * √a * √b * ... * √z） = O（[√n] ^ m），空间上，每次的递归深度记为 m，所以额外空间复杂度为 O（m * √n）。

```java
class Solution {
    public int numSquares(int n) {
        return f(n);
    }
    
    private int f(int n) {
        if(n <= 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }

        int min = Integer.MAX_VALUE;
        for(int i = 1; (i * i) <= n; i++) {
            if(n-(i*i) > 0) {
                min = Math.min(min, 1 + f(n-(i*i)));
            } else {
                min = 1;
            }
        }

        return min;
    }
}

```

###### 记忆化搜索 | O（m * √n）

- **思路**：基于暴力递归的思路，增加了 dp 一维表缓存，如果缓存中存在则从缓存中获取，否则先设置结果到缓存中再返回。
- **结论**：时间，66ms，15.82%，41.1mb，5.25%，时间上，记需要遍历 √n 次，平均每次遍历需要尝试 m 个完全平方数，因此时间复杂度为 O（m * √n），空间上，每次的递归深度记为 m，所以额外空间复杂度为 O（m * √n）。

```java
class Solution {

    private int[] dp;

    public int numSquares(int n) {
        if(n <= 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }

        dp = new int[n + 1];
        Arrays.fill(dp, -1);
        dp[0] = dp[1] = 1;
        dp[2] = 2;

        return f(n);
    }

    private int f(int n) {
        if(dp[n] != -1) {
            return dp[n];
        }

        int min = Integer.MAX_VALUE;
        for(int i = 1; (i * i) <= n; i++) {
            if(n-(i*i) > 0) {
                min = Math.min(min, 1 + f(n-(i*i)));
            } else {
                min = 1;
            }
        }

        dp[n] = min;
        return dp[n];
    }
}

```

###### 严格表结构优化 | O（n * √n）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现是后面一个值依赖前面每个枚举值，所以可以枚举初始化好 0,1,...n-1，然后获取 n 的值返回即可。
- **结论**：
  1. 时间，23ms，80.99%，空间，40.5mb，7.83%，时间上，由于需要枚举前面 n-1 个值，每次枚举又需要遍历 √n 次，所以时间复杂度为 O（n * √n），空间上，由于使用了一个 n+1 长度的 dp 数组，所以额外空间复杂度为 O（n+1）。
  2. 本题得到一新的心得，如果记忆化搜索改动态规划时，发现递归函数中有枚举行为，则可以先模拟出递归深度有多少、f（n）一共依赖多少个前面的值，然后遍历这些值，再把递归函数中的逻辑拷到遍历里面即可。

```java
class Solution {

    public int numSquares(int n) {
        if(n <= 1) {
            return 1;
        }
        if(n == 2) {
            return 2;
        }

        int[] dp = new int[n + 1];
        dp[0] = dp[1] = 1;
        dp[2] = 2;

        for(int j = 3; j <= n; j++) {
            int min = Integer.MAX_VALUE;
            for(int i = 1; (i * i) <= j; i++) {
                if(j-(i*i) > 0) {
                    min = Math.min(min, 1 + dp[j-(i*i)]);
                } else {
                    min = 1;
                }
            }
            dp[j] = min;
        }

        return dp[n];
    }
}

```

###### 四平方和定理推论 | O（√n）

- **思路**：
  1. 四平方和定理：任意一个正整数，都可以被表示为至多 4 个整数的平方和。
  2. 四平方和定理推论：当前仅当 n = 4^k * （8m + 7）时，n 只能被表示为 4 个正整数的平方和，否则至多表示为 3 个。
     1. 当答案为 1 时，则 n 需要是完美的平方数，即 n = a^2。
     2. 当答案为 2 时，则 n 需要为平方和，即 n = a^2 + b^2。
     3. 当答案为 3 时，n 为其他情况，可排除其他情况后返回。
- **结论**：时间，0ms，100%，空间，38.8mb，11.54%，时间上，在最坏的情况下，当答案为 3 时，需要遍历完答案 2 的所有情况，所以时间复杂度为 O（√n），空间上，由于只使用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int numSquares(int n) {
        if(isPerfectSquares(n)) {
            return 1;
        }
        if(is4k8m7(n)) {
            return 4;
        }

        // 既不是完美平方数, 又不是4^k * (8m + 7), 则枚举判断是否为n=a^2+b^2
        int j;
        for(int i = 1; (i * i) <= n; i++) {
            j = n - i * i;
            if(isPerfectSquares(j)) {
                return 2;
            }
        }

        // 如果还不是n=a^2+b^2, 则只能是剩下的情况了
        return 3;
    }

    // 判断n是否为完美平方数: n=a^2
    private boolean isPerfectSquares(int n) {
        int a = (int) Math.sqrt(n);
        return n == a * a;
    }

    // 判断n是否等于4^k * (8m + 7) <= 四平方和定理推论
    private boolean is4k8m7(int n) {
        while(n % 4 == 0) {
            n /= 4;
        }
        return n % 8 == 7; 
    }
}

```

##### 13）最长递增子序列

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（end）函数，代表获取以 end 结尾的最大递增子序列的长度。
  2. f（end）函数的实现通过当前结尾与枚举前面的最大子序列（即子过程 f（end-i））结合，得出当前的最大递增子序列的长度。
  3. 然后，由于 nums 数组中的最大递增子序列，可能没落在以最后一个字符结尾的子序列中，所以主函数还要枚举各个字符结尾的子序列，最后得出最大的答案并返回即可。
- **结论**：执行超时，时间上，由于每个位置可能被访问 n 次，一共有 n 个位置，所以时间复杂度为 O（n^2），空间上，额外空间复杂度取决于递归的最大深度 n,n-1,...,1 层，所以额外空间复杂度为 O（n^2）。

```java
class Solution {
    public int lengthOfLIS(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        // 尝试选择以每个位置作为结尾的递增子序列
        int max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }

        return max;
    }

    // f代表获取以end结尾的最长递增子序列长度
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(end == 0) {
            return 1;
        }

        // 只选当前位置时为1
        int max = 1;
        
        // 尝试选择前面的递增子序列
        for(int i = 0; i < end; i++) {
            if(nums[end] > nums[i]) {
                max = Math.max(max, 1 + f(nums, i));
            }
        }

        return max;
    }
}

```

###### 记忆化搜索 | O（n^2）

- **思路**：在暴力递归的基础上，增加了 dp 一维表缓存，如果缓存中存在则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，94ms，5.55%，空间，40.8mb，5.00%，时间上，每个元素只需要遍历 n 次，一共 n 个元素，所以空间复杂度为 O（n^2），空间上，额外空间复杂度取决于递归的最大深度 n,n-1,...,1 层，所以额外空间复杂度为 O（n^2）。

```java
class Solution {

    private int dp;

    public int lengthOfLIS(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        dp = new int[nums.length];
        Arrays.fill(dp, -1);

        // 尝试选择以每个位置作为结尾的递增子序列
        int max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, f(nums, i));
        }

        return max;
    }

    // f代表获取以end结尾的最长递增子序列长度
    private int f(int[] nums, int end) {
        if(end < 0) {
            return 0;
        }
        if(dp[end] != -1) {
            return dp[end];
        }
        if(end == 0) {
            dp[end] = 1;
            return dp[end];
        }

        // 只选当前位置时为1
        int max = 1;
        
        // 尝试选择前面的递增子序列
        for(int i = 0; i < end; i++) {
            if(nums[end] > nums[i]) {
                max = Math.max(max, 1 + f(nums, i));
            }
        }

        dp[end] = max;
        return dp[end];
    }
}

```

###### 严格表结构优化 | O（n^2）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系可知，每个值都依赖于前面的 n-1,n-2,...1,0 的值，有枚举的行为，因此需要先在主函数中枚举并初始化好每个 dp 数组的值，然后再比较出最大的递增子序列长度。
- **结论**：时间，55ms，71.50%，空间，40.8mb，5.00%，时间上，需要先循环遍历 2 次初始化好 dp 数组，然后在遍历一次 dp 数组，取得最大递增子序列长度，所以时间复杂度为 O（n^2 + n），空间上，由于使用了一个长度为 n 的 dp 一维数组，所以额外空间复杂度为 O（n）。

```java
class Solution {

    public int lengthOfLIS(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int[] dp = new int[nums.length];
        dp[0] = 1;

        // f代表获取以end结尾的最长递增子序列长度
        int max;
        for(int end = 1; end < nums.length; end++) {
            // 只选当前位置时为1
            max = 1;

            // 尝试选择前面的递增子序列
            for(int i = 0; i < end; i++) {
                if(nums[end] > nums[i]) {
                    max = Math.max(max, 1 + dp[i]);
                }
            }

            dp[end] = max;
        }

        // 尝试选择以每个位置作为结尾的递增子序列
        max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, dp[i]);
        }

        return max;
    }
}

```

###### 二分查找与枚举优化 | O（n * logn）

- **思路**：在严格表结构的基础上，看能不能优化掉动态规划的枚举行为，其中，优化枚举行为的方式有两种，一是观察值依赖的枚举关系，把枚举行为优化成取值行为，从而把 O（i）的复杂度优化成 O（1）；二是由题目的特定条件决定，本题正是经过组合出单调性，通过二分查找来优化掉枚举行为，从而把 O（i）的复杂度优化成 O（logn）。
- **结论**：时间，2ms，99.70%，空间，41mb，5.00%，时间上，初始化 dp 数组需要花费 O（n * logn），遍历并判断 dp 数组最大值花费 O（n），所以时间复杂为 O（n * logn + n），空间上，由于使用了一个长度为 n 的 dp 一维数组，所以额外空间复杂度为 O（n）。

```java
class Solution {

    public int lengthOfLIS(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int[] dp = new int[nums.length];
        dp[0] = 1;

        // 长度为i+1递增子序列的最小结尾: 从小到大排序
        int el = 0, er = 0;
        int[] ends = new int[nums.length];
        ends[0] = nums[0];

        // f代表获取以end结尾的最长递增子序列长度
        for(int end = 1; end < nums.length; end++) {
            dp[end] = processDp(ends, el, er, nums[end]);

            // 有效区+1
            if(dp[end] == er + 2) {
                er++;
            }
        }

        // 尝试选择以每个位置作为结尾的递增子序列
        int max = 0;
        for(int i = 0; i < nums.length; i++) {
            max = Math.max(max, dp[i]);
        }

        return max;
    }

    // 长度为i+1递增子序列的最小结尾: 从小到大排序
    private int processDp(int[] ends, int el, int er, int value) {
        // er+1必合法
        if(value > ends[er]) {
            ends[er+1] = value;
            return er + 2;
        } 
        // 二分查找最右的最小结尾
        else {
            int mid, resi = 0;
            while(el <= er) {
                mid = (el + er) >>> 1;
                
                // 右
                if(value > ends[mid]) {
                    el = mid + 1;
                } 
                // 左边, 也可能就为答案
                else if(value < ends[mid]) {
                    er = mid - 1;
                    resi = mid;
                } 
                // 就是当前位置
                else {
                    resi = mid;
                    break;
                }
            }

            ends[resi] = value;
            return resi + 1;
        }
    }
}

```

##### 14）最佳买卖股票时机含冷冻期

###### 暴力递归1 | >= O（n^3）

- **思路**：
  1. 设计一个 f（start，cur）函数，代表从 start 开始买入可获得的最大利润。
  2. 主函数通过模拟买卖股票的操作，先尝试从 0,1,2,...,n-1 调用递归函数开始买入，求获得利润的最大值返回即是答案。
  3. 然后 f 函数也是通过模拟买卖股票的操作来实现的，先尝试在 start+1,start+2,...n-1 开始卖出、结算或者再枚举到冻结期之后的第 1,2,...,n-1 天又买入...，来计算当前 f（start，cur）的最大利润。
- **结论**：执行超时，时间上，由于枚举了买入、卖出、冻结期之后买入三次，所以时间复杂度至少为 O（n^3），并且由于使用了 cur 作为递归参数，不好做记忆化搜索，所以下一个优化的方向就是把 cur 参数给去掉；空间上，额外空间复杂度取决于递归深度，为 O（n^3）。 

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }

        // 开始尝试买入
        int max = 0;
        for(int i = 0; i < prices.length; i++) {
            max = Math.max(max, f(prices, i, 0));
        }

        return max;
    }

    // f代表从start开始买入可获得的最大利润 
    private int f(int[] prices, int start, int cur) {
        if(start >= prices.length) {
            return cur;
        }

        // 开始尝试卖出
        int mai = prices[start], max = cur;
        for(int i = start + 1; i < prices.length; i++) {
            // 小于等于买入价, 则不用卖, 利润保持不变
            if(prices[i] <= mai) {
                continue;
            }

            // 如果冻结期过后还有得买, 则再尝试从冻结期后的第1,2,...m天买入
            if(i + 2 < prices.length) {
                for(int j = i + 2; j < prices.length; j++) {
                    max = Math.max(max, f(prices, j, cur + prices[i] - mai));
                }
            } 
            // 如果冻结期过后没有得买了, 则做最后的结算
            else {
                max = Math.max(max, f(prices, prices.length, cur + prices[i] - mai));
            }
        }

        return max;
    }
}

```

###### 暴力递归2 | >= O（n^3）

- **思路**：
  1. 在暴力递归1的基础上，更改了 f（start）函数，代表从 start 开始买入可获得的最大收入，这时求利润 =  -成本 + 收入。
  2. 主函数通过模拟买卖股票的操作，先尝试从 0,1,2,...,n-1 调用递归函数开始买入，求获得利润的最大值返回即是答案。
  3. 然后 f 函数也是通过模拟买卖股票的操作来实现的，先尝试在 start+1,start+2,...n-1 开始卖出、结算或者再枚举到冻结期之后的第 1,2,...,n-1 天又买入...，来计算当前 f（star）的最大利润。
- **结论**：执行超时，时间上，由于枚举了买入、卖出、冻结期之后买入三次，所以时间复杂度至少为 O（n^3），空间上，额外空间复杂度取决于递归深度，为 O（n^3）。 

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }

        // 开始尝试买入
        int max = 0;
        for(int i = 0; i < prices.length; i++) {
            max = Math.max(max, -prices[i] + f(prices, i));
        }

        return max;
    }

    // f代表从start开始买入可获得的最大收入, 其中利润 = -成本 + 收入
    private int f(int[] prices, int start) {
        if(start >= prices.length) {
            return 0;
        }

        // 开始尝试卖出
        int max = 0;
        for(int i = start + 1; i < prices.length; i++) {
            // 先尝试冻结期过后不买
            max = Math.max(max, prices[i]);

            // 如果冻结期过后还有得买, 则再尝试从冻结期后的第1,2,...m天买入
            for(int j = i + 2; j < prices.length; j++) {
                max = Math.max(max, prices[i] - prices[j] + f(prices, j));
            }
        }

        return max;
    }
}

```

###### 记忆化搜索2 | O（n^3）

- **思路**：在暴力递归2的基础上，增加了 dp 一维表缓存，如果缓存中存在则从缓存中获取，否则先设置结果到缓存中再返回，其中由于是前面的值依赖后面的值，所以主函数调用递归函数也优化成了从后往前调用。
- **结论**：
  1. 执行还是超时，不过测试用例又通过了 1 个，时间上，由于枚举了买入、卖出、冻结期之后买入三次，所以时间复杂度等于 O（n^3），空间上，额外空间复杂度取决于递归深度，为 O（n^3）。
  2. 根据经验，记忆化搜索都超时了，那么严格表结构的优化也就没有必要进行了，因为那只是优化空间的使用而已，时间复杂度并没有改变，说明这个算法思路不符合题目要求，还是继续尝试其他思路吧~

```java
class Solution {

    private int[] dp;

    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }

        dp = new int[prices.length];
        Arrays.fill(dp, -1);

        // 开始尝试买入
        int max = 0;
        for(int i = prices.length - 1; i > -1; i--) {
            max = Math.max(max, -prices[i] + f(prices, i));
        }
  
        return max;
    }

    // f代表从start开始买入可获得的最大收入, 其中利润 = -成本 + 收入
    private int f(int[] prices, int start) {
        if(dp[start] != -1) {
            return dp[start];
        }

        // 开始尝试卖出
        int max = 0;
        for(int i = start + 1; i < prices.length; i++) {
            // 先尝试冻结期过后不买
            max = Math.max(max, prices[i]);

            // 如果冻结期过后还有得买, 则再尝试从冻结期后的第1,2,...m天买入
            for(int j = i + 2; j < prices.length; j++) {
                max = Math.max(max, prices[i] - prices[j] + f(prices, j));
            }
        }

        dp[start] = max;
        return dp[start];
    }
}

```

###### 暴力递归3 | O（4n）

- **思路**：
  1. 由于暴力递归2 是一维参数，且即使优化成记忆化搜索还是超时，如果要减少时间复杂度，那么就需要升维优化算法思路，所以就有了暴力递归3~
  2. 设计一个 f（day，status）函数，代表在 day 天时，如果状态为 status 能够得到的最大利润，其中，status=0 代表买入状态，status=1 代表卖出状态。
  3. 而 f（day，status）函数的实现，可分为 3 种情况：
     1. 如果 day 天数超过了给定数组的有效值时，则返回 0，代表无法计算更大的利润。
     2. 否则 day 合法，同时如果 status=0，说明来到 day 当天已经为买入状态了，此时要么卖出（跳过冷冷冻期告诉下两个 day 当前已卖出，并结算此时的 price），要么保持不动（把当前状态已经买入告诉下一个 day 当前还是买入状态，不结算此时的 price）。
     3. 但如果 status=1，说明来到 day 当天已经为卖出状态了，此时要么买入（当前为卖出状态，说明肯当前肯定不再冷冻期内，即可买入，所以扣减当前成本 - price，然后告诉下一个 day 当前已买入），要么保持不动（把当前状态已经买入告诉下一个 day 当前还是卖出状态，不扣减此时的成本）。
  4. 最后，主函数通过调用递归函数，告诉第 0 天当前为已卖出状态，要么买入，要么不动，即可取得整个数组的最大利润。
- **结论**：执行超时，时间上，由于递归函数调用 4 次，每次都需要遍历一遍数组，所以时间复杂度为 O（4n），空间上，额外空间复杂度取决于递归深度，为 O（4n）。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }  
        return f(prices, 0, 1);
    }

    // f代表在day天时状态为status能得到的最大利润, status: {0: 买入, 1: 卖出}
    private int f(int[] prices, int day, int status) {
        if(day >= prices.length) {
            return 0;
        }

        // 当前为买入状态, 可卖出或者保持不动
        int max = 0;
        if(status == 0) {
            max = Math.max(prices[day] + f(prices, day+2, 1), f(prices, day+1, 0));
        } 
        // 当前为卖出状态, 可买入或者保持不动
        else if(status == 1) {
            max = Math.max(-prices[day] + f(prices, day+1, -1), f(prices, day+1, 1));
        }

        return max;
    }
}

```

###### 记忆化搜索3 | O（n）

- **思路**：在暴力递归 3 的基础上，增加了 dp 二维表缓存，如果缓存中存在则从缓存中获取，否则先设置结果到缓存中再返回。
- **结论**：时间，1ms，87%，空间，39.6mb，5.00%，时间上，把递归行为优化成了去缓存中取数，也就是暴力递归 3 中要遍历 4 次数组的行为，优化成了只需要遍历 1 次即可，所以时间复杂度为 O（n），空间上，由于使用了一张 dp 二维表，所以额外空间复杂度为 O（2n）。

```java
class Solution {

    private int[][] dp;

    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }

        dp = new int[2][prices.length];
        for(int i = 0; i < dp.length; i++) {
            Arrays.fill(dp[i], -1);
        }

        return f(prices, 0, 1);
    }

    // f代表在day天时状态为status能得到的最大利润, status: {0: 买入, 1: 卖出}
    private int f(int[] prices, int day, int status) {
        if(day >= prices.length) {
            return 0;
        }
        if(dp[status][day] != -1) {
            return dp[status][day];
        }

        // 当前为买入状态, 可卖出或者保持不动
        int max = 0;
        if(status == 0) {
            max = Math.max(prices[day] + f(prices, day+2, 1), f(prices, day+1, 0));
        }
        // 当前为卖出状态, 可买入或者保持不动
        else if(status == 1) {
            max = Math.max(-prices[day] + f(prices, day+1, 0), f(prices, day+1, 1));
        }

        dp[status][day] = max;
        return dp[status][day];
    }
}

```

###### 严格表结构优化 | O（n）

- **思路**：
  1. 在记忆化搜索 3 的基础上，经过研究值依赖关系后得出，当前值依赖于后一个和后两个值，所以本题是一个从右往左初始化的模型。
  2. 不过，需要先初始化好最后两个值，这可以通过脑补递归函数传入 n-1 和 n-2 参数时的行为，即可得出最后两个值。
  3. 其中，如果保持像记忆化搜索 3 那样，使用列数为 n 的二维表的话，那么就错失了超过数组传长度时，结果为 0 的边界值，从而造成了执行错误，所以需要增加一列，使用 n+1 列 2 行的二维表作为 dp 数组，保证初始化好 n 列（全 0）和 n-1 列即可（脑补递归函数传入 n-1 参数时的行为，来模仿求出）。
- **结论**：时间，0ms，100%，空间，39.6mb，5.00%，时间上，初始化好 dp 二维表，由于行状态只有两个值，可以在一次循环里分别填写，所以只需要遍历列数即可，因此时间复杂度为 O（n），空间上，由于使用了一张 n+1 列 2 行的二维表作为 dp 数组，所以额外空间复杂度为 O（2 * [n + 1]）。

```java
class Solution {
    
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length <= 1) {
            return 0;
        }

        int n = prices.length;
        int[][] dp = new int[2][n+1];
        dp[0][n] = 0;
        dp[1][n] = 0;
        dp[0][n-1] = Math.max(prices[n-1], dp[0][n]);
        dp[1][n-1] = Math.max(-prices[n-1] + dp[0][n], dp[1][n]);
        
        for(int day = n - 2; day > -1; day--) {
            // 当前为买入状态, 可卖出或者保持不动
            dp[0][day] = Math.max(prices[day] + dp[1][day+2], dp[0][day+1]);

            // 当前为卖出状态, 可买入或者保持不动
            dp[1][day] = Math.max(-prices[day] + dp[0][day+1], dp[1][day+1]);
        }

        return dp[1][0];
    }
}

```

##### 15）戳气球

###### 暴力递归 | >= O（n^3）

- **思路**：
  1. 设计一个 f（l，r）函数，代表打爆 [l, r] 范围内的气球，所能带来的最大收益。
  2. 其中，f 函数通过尝试最后打爆第 0,1,...,n-1 个气球，分别计算各自的收益，来比较得到 [l, r] 范围内的最大收益。
- **结论**：执行超时，时间上，由于是二维参数， f 函数实现需要依赖 l+1 和 r-1， 所以需要花费 O（n^2）来铺满所有的二维参数，且每次递归还需要花费 O（n）来从头遍历 nums 数组，因此时间复杂度至少为 O（n^3），空间上，最大递归深度  O（n^2），同时还是使用了一个 help 辅助数组 O（n+2），所以额外空间复杂度为 O（n^2 + n+2）。

```java
class Solution {
    public int maxCoins(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int n = nums.length;
        int[] help = new int[n+2];
        help[0] = help[n+1] = 1;
        for(int i = 1; i < n+1; i++) {
            help[i] = nums[i-1];
        }

        return f(help, 1, n);
    }

    // f代表[l,r]范围内的气球被打爆能带来的最大收益
    // 潜台词: 打爆[l,r]时, l-1和r+1肯定没有被打爆
    private int f(int[] help, int l, int r) {
        if(l > r) {
            return 0;
        }
        if(l == r) {
            return help[l-1] * help[l] * help[r+1];
        }

        int max = Math.max(
            // 尝试最后才打爆l上的气球: 之前打爆后面的分数 + 当前分数
            f(help, l+1, r) + help[l-1] * help[l] * help[r+1],
            // 尝试最后才打爆r上的气球: 之前打爆前面的分数 + 当前分数
            f(help, l, r-1) + help[l-1] * help[r] * help[r+1]
        );

        // 尝试最后才打爆中间位置上的气球: 之前打爆前面的分数 + 之前打爆后面的分数 + 当前分数 
        for(int i = l + 1; i < r; i++) {
            max = Math.max(
                max,
                f(help, l, i-1) + f(help, i+1, r) + help[l-1] * help[i] * help[r+1]
            );
        }

        return max;
    }
}

```

###### 记忆化搜索 | O（n^3）

- **思路**：在暴力递归的基础上，增加了一张 dp 二维表缓存数组，如果缓存中存在则先从缓存中获取，否则先设置结果到缓存中再返回。
- **结论**：时间，104ms，20%，空间，40.6mb，7%，时间上，由于是二维参数， f 函数实现需要依赖 l+1 和 r-1， 所以需要花费 O（n^2）来铺满所有的二维参数，且每次递归还需要花费 O（n）来从头遍历 nums 数组，同时因为有缓存数组的存在，因此时间复杂度为 O（n^3），空间上，二维表 dp 数组  O（n^2），同时还是使用了一个 help 辅助数组 O（n+2），所以额外空间复杂度为 O（n^2 + n+2）。

```java
class Solution {

    private int[][] dp;

    public int maxCoins(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int n = nums.length;
        int[] help = new int[n+2];
        help[0] = help[n+1] = 1;
        for(int i = 1; i < n+1; i++) {
            help[i] = nums[i-1];
        }

        dp = new int[n+1][n+1];
        for(int i = 0; i < dp.length; i++) {
            Arrays.fill(dp[i], -1);
        }

        return f(help, 1, n);
    }

    // f代表[l,r]范围内的气球被打爆能带来的最大收益
    // 潜台词: 打爆[l,r]时, l-1和r+1肯定没有被打爆
    private int f(int[] help, int l, int r) {
        if(l > r) {
            return 0;
        }
        if(dp[l][r] != -1) {
            return dp[l][r];
        }
        if(l == r) {
            dp[l][r] = help[l-1] * help[l] * help[r+1];
            return dp[l][r];
        }

        int max = Math.max(
            // 尝试最后才打爆l上的气球: 之前打爆后面的分数 + 当前分数
            f(help, l+1, r) + help[l-1] * help[l] * help[r+1],
            // 尝试最后才打爆r上的气球: 之前打爆前面的分数 + 当前分数
            f(help, l, r-1) + help[l-1] * help[r] * help[r+1]
        );

        // 尝试最后才打爆中间位置上的气球: 之前打爆前面的分数 + 之前打爆后面的分数 + 当前分数 
        for(int i = l + 1; i < r; i++) {
            max = Math.max(
                max,
                f(help, l, i-1) + f(help, i+1, r) + help[l-1] * help[i] * help[r+1]
            );
        }

        dp[l][r] = max;
        return max;
    }
}

```

###### 严格表结构优化 | O（n^3）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现一个值依赖它左边和下边的值，且左半部分是没用的部分，默认设置为 0，所以这是一个从下往上、从左往右初始化 dp 数组的模型。
- **结论**：时间，27ms，100%，空间，40.6mb，6.81%，时间上，时间复杂度等于初始化 dp 所花费的时间 O（n^3），空间上，使用了一张二维表 dp 数组以及一张 help 辅助数组，所以额外空间复杂度为 O（n^2 + n+2）。

```java
class Solution {

    public int maxCoins(int[] nums) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int n = nums.length;
        int[] help = new int[n+2];
        help[0] = help[n+1] = 1;
        for(int i = 1; i < n+1; i++) {
            help[i] = nums[i-1];
        }
        
        // 初始化对角线
        int[][] dp = new int[n+1][n+1];
        for(int i = 1; i < dp.length; i++) {
            dp[i][i] = help[i-1] * help[i] * help[i+1];
        }
        // 从下往上、从左往右进行初始化: 其中k范围取[1...n], j范围取左半部分
        int max;
        for(int k = dp.length - 2; k > 0; k--) {
            for(int j = k + 1; j < dp[k].length; j++) {
                max = Math.max(
                    // 尝试最后才打爆l上的气球: 之前打爆后面的分数 + 当前分数
                    dp[k+1][j] + help[k-1] * help[k] * help[j+1],
                    // 尝试最后才打爆r上的气球: 之前打爆前面的分数 + 当前分数
                    dp[k][j-1] + help[k-1] * help[j] * help[j+1]
                );

            // 尝试最后才打爆中间位置上的气球: 之前打爆前面的分数 + 之前打爆后面的分数 + 当前分数 
                for(int i = k + 1; i < j; i++) {
                    max = Math.max(
                        max,
                        dp[k][i-1] + dp[i+1][j] + help[k-1] * help[i] * help[j+1]
                    );
                }

                dp[k][j] = max;
            }
        }

        return dp[1][n];
    }
}

```

##### 16）零钱兑换

###### 暴力递归1 | >= O（s^2 * n）

- **思路**：
  1. 设计一个 f（index，rest）函数，代表使用 [0, index] 处的硬币，来凑成 rest 金额的最少硬币数。
  2. f 函数的实现通过枚举 index 处的硬币使用 0,1,2,...n 个 + 剩余的金额使用子过程去枚举 index-1,index-2,..., 0 处的硬币，从而得到每种情况的最少硬币数，然后再比较得出最少的硬币数作为当前参数的最少硬币数。
- **结论**：执行超时，时间上，记金额为 s，数组长度为 n，最坏情况下，递归函数首先需要遍历 s 次，然后递归深度需要覆盖两个参数，需要遍历 s * n 二维矩阵，所以时间复杂度至少为 O（s^2 * n），空间上，额外空间复杂度取决于递归深度，为 O（s * n）。

```java
class Solution {

    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }
        return f(coins, coins.length-1, amount);
    }

    // f代表使用[0, index]处的硬币, 凑成rest金额的最少硬币数
    private int f(int[] coins, int index, int rest) {
        int min = Integer.MAX_VALUE, count, cur;
        for(int i = 0; i * coins[index] <= rest; i++) {
            // 使用i个当前硬币
            cur = rest - i * coins[index];

            // 只使用当前硬币凑成rest
            if(cur == 0) {
                min = Math.min(min, i);
            }
            // 没凑完, 如果还有的凑, 则剩余的则交给前面的硬币去凑
            else if(index - 1 > -1) {
                count = f(coins, index - 1, cur);

                // 如果前面的凑不成, 则跳过; 如果凑成的, 则比较最小硬币数
                if(count != -1) {
                    min = Math.min(min, i + count);
                }
            }
        }

        // 如果没凑成, 则返回-1, 否则返回能凑成的最少硬币数
        return min == Integer.MAX_VALUE? -1 : min;
    }
}

```

###### 记忆化搜索1 | O（s^2 * n）

- **思路**：在暴力递归 1 的基础上，增加了一张 dp 二维表缓存，如果缓存中存在则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：执行超时，时间上，由于增加了缓存，缓存设置一次后将不再处理，所以时间复杂度等于暴力递归 1 的下限 O（s^2 * n），空间上，由于在暴力递归1 的基础上增加了一张 dp 二维表缓存，所以额外空间复杂度为 O（2s * n）。

```java
class Solution {

    private int[][] dp;

    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }

        dp = new int[coins.length][amount+1];
        for(int i = 0; i < dp.length; i++) {
            Arrays.fill(dp[i], -1);
        }

        return f(coins, coins.length-1, amount);
    }

    // f代表使用[0, index]处的硬币, 凑成rest金额的最少硬币数
    private int f(int[] coins, int index, int rest) {
        if(dp[index][rest] != -1) {
            return dp[index][rest];
        }

        int min = Integer.MAX_VALUE, count, cur;
        for(int i = 0; i * coins[index] <= rest; i++) {
            // 使用i个当前硬币
            cur = rest - i * coins[index];

            // 只使用当前硬币凑成rest
            if(cur == 0) {
                min = Math.min(min, i);
            }
            // 没凑完, 如果还有的凑, 则剩余的则交给前面的硬币去凑
            else if(index - 1 > -1) {
                count = f(coins, index - 1, cur);

                // 如果前面的凑不成, 则跳过; 如果凑成的, 则比较最小硬币数
                if(count != -1) {
                    min = Math.min(min, i + count);
                }
            }
        }

        // 如果没凑成, 则返回-1, 否则返回能凑成的最少硬币数
        dp[index][rest] = min == Integer.MAX_VALUE? -1 : min;
        return dp[index][rest];
    }
}

```

###### 严格表结构优化1 | O（s^2 * n）

- **思路**：在记忆化搜索 1 的基础上，经过研究值依赖关系，发现一个值只依赖与它前面 -1 的值，所以这是从上往下初始化 dp 的模型，其中 index=0 处的初始化值，等于是否能够使用 0 处硬币凑成各种 rest 金额的数量，凑不成则为 -1。
- **结论**：时间，535ms，5.01%，空间，5.02%，时间上，时间复杂度取决于初始化 dp，需要花费 O（n * s * s），空间上，由于使用了一张 n*（s+1）的二维表，所以额外空间复杂度为 O（s * n）。

```java
class Solution {

    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }
        if(amount == 0) {
            return 0;
        }

        int[][] dp = new int[coins.length][amount+1];
        for(int i = 0; i < dp[0].length; i++) {
            dp[0][i] = i % coins[0] == 0? i / coins[0] : -1;
        }

        int min, count, cur;
        for(int index = 1; index < dp.length; index++) {
            for(int rest = 0; rest < dp[0].length; rest++) {
                min = Integer.MAX_VALUE;
                for(int i = 0; i * coins[index] <= rest; i++) {
                    // 使用i个当前硬币
                    cur = rest - i * coins[index];

                    // 只使用当前硬币凑成rest
                    if(cur == 0) {
                        min = Math.min(min, i);
                    }
                    // 没凑完, 如果还有的凑, 则剩余的则交给前面的硬币去凑
                    else if(index - 1 > -1) {
                        count = dp[index-1][cur];

                        // 如果前面的凑不成, 则跳过; 如果凑成的, 则比较最小硬币数
                        if(count != -1) {
                            min = Math.min(min, i + count);
                        }
                    }
                }

                // 如果没凑成, 则返回-1, 否则返回能凑成的最少硬币数
                dp[index][rest] = min == Integer.MAX_VALUE? -1 : min;
            }
        }

        return dp[coins.length-1][amount];
    }
}

```

###### 暴力递归2 | >= O（s * n）

- **思路**：
  1. 由于暴力递归 1 思路的时间复杂度太高，所以需要考虑过其他思路。
  2. 设计一个 f（rest）函数，代表使用 coins 数组中所有的硬币，来凑成 rest 金额的最小硬币数。
  3. f 函数通过遍历每个硬币，一次递归中只使用 1 个 coin 硬币，而不是尝试 n 个，然后再把剩余的 rest 交由子过程去尝试所有硬币，同时也是每个子过程只尝试 1 个 coin硬币...周而复始，从而把两个参数降低为 1个参数的递归。
- **结论**：执行超时，时间上，由于每次递归要遍历 n 长的 coins 数组，然后最多要递归 s 次，所以时间复杂度为 O（s * n），空间上，额外空间复杂度取决于递归深度，为 O（s）。

```java
class Solution {

    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }
        return f(coins, amount);
    }

    // f代表使用coins数组中所有的硬币, 凑成amount金额的最小硬币数
    private int f(int[] coins, int rest) {
        if(rest == 0) {
            return 0;
        }

        int min = Integer.MAX_VALUE, count, cur;
        for(int coin : coins) {        
            // 只使用1个coin就凑成了rest
            cur = rest - coin;
            if(cur == 0) {
                min = 1;
            }
            // 组合使用coin
            else if(cur > 0) {
                count = f(coins, cur);

                // 凑成rest, 则对比最小硬币数
                if(count != -1) {
                    min = Math.min(min, count+1);
                }
            }
        }

        return min == Integer.MAX_VALUE? -1 : min;
    }
}

```

###### 记忆化搜索2 | O（s * n）

- **思路**：在暴力递归2 的基础上，增加了 dp 一维表缓存，如果缓存中存在则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：执行超时，时间上，由于增加了缓存，同参数的递归只会处理 1 次，所以时间复杂度等于暴力递归 2 的时间复杂度，为 O（s * n），空间上，由于在暴力递归2 的基础上增加了一张 dp 一维表缓存数组，所以额外空间复杂度为 O（2s）。

```java
class Solution {

    private int[] dp;

    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }

        dp = new int[amount+1];
        Arrays.fill(dp, -1);

        return f(coins, amount);
    }

    // f代表使用coins数组中所有的硬币, 凑成amount金额的最小硬币数
    private int f(int[] coins, int rest) {
        if(dp[rest] != -1) {
            return dp[rest];
        }
        if(rest == 0) {
            dp[rest] = 0;
            return dp[rest];
        }

        int min = Integer.MAX_VALUE, count, cur;
        for(int coin : coins) {        
            // 只使用1个coin就凑成了rest
            cur = rest - coin;
            if(cur == 0) {
                min = 1;
            }
            // 组合使用coin
            else if(cur > 0) {
                count = f(coins, cur);

                // 凑成rest, 则对比最小硬币数
                if(count != -1) {
                    min = Math.min(min, count+1);
                }
            }
        }

        dp[rest] = min == Integer.MAX_VALUE? -1 : min;
        return dp[rest];
    }
}

```

###### 严格表结构优化2 | O（S * n）

- **思路**：在记忆化搜索2 的基础上，经过研究值依赖关系，发现一个依赖它 rest-coin 的值，且没有负数的时候，也就是 rest 最小也只是 0 而已，所以只需初始化 dp[0]，然后从左到右初始化 dp 数组即可。
- **结论**：时间，13ms，56.77%，空间，41.1mb，5.02%，时间上，时间复杂度取决于初始化 dp 数组的花费 O（s * n），空间上，由于使用了一张 dp 一维表数组，所以额外空间复杂度为 O（s）。

```java
class Solution {
    
    public int coinChange(int[] coins, int amount) {
        if(coins == null || coins.length == 0) {
            return -1;
        }

        int[] dp = new int[amount+1];
        dp[0] = 0;
        
        int min, count, cur;
        for(int rest = 1; rest <= amount; rest++) {
            min = Integer.MAX_VALUE;
            for(int coin : coins) {        
                // 只使用1个coin就凑成了rest
                cur = rest - coin;
                if(cur == 0) {
                    min = 1;
                }
                // 组合使用coin
                else if(cur > 0) {
                    count = dp[cur];

                    // 凑成rest, 则对比最小硬币数
                    if(count != -1) {
                        min = Math.min(min, count+1);
                    }
                }
            }

            dp[rest] = min == Integer.MAX_VALUE? -1 : min;
        }

        return dp[amount];
    }
}

```

##### 17）比特位计数

见《位运算 - 比特位计数》。

##### 18）分割等和子集

###### 暴力递归 | O（n^2）

- **思路**：
  1. 递归函数调用前，先获取原数组总和，如果总和为奇数，那么肯定不能分割等和子集，直接返回 false 即可。
  2. 然后设计一个 f（start，cur）函数，代表 [start...结尾] 能否扣减 cur 为 0。
  3. f 函数实现分为 2 种情况：一是，扣减当前 start 上的值，此时需要把扣减后的和传给子过程继续判断；二是，不扣减当前 start 上的值，此时只需要把 cur 原封不动的传给子过程继续判断即可。
- **结论**：执行超时，时间上，由于扣和不扣当前值，调用了两次递归函数到数组末尾，深度最大为 n，组合起来一共有 n^2 种递归行为，所以时间复杂度为 O（n^2），空间上，额外空间复杂度取决于递归深度，为 O（n^2）。

```java
class Solution {
    public boolean canPartition(int[] nums) {
        if(nums == null || nums.length == 0) {
            return true;
        }

        // 校验总和是否为奇数
        int sum = 0;
        for(int i = 0; i < nums.length; i++) {
            sum += nums[i];
        }
        if(sum % 2 != 0) {
            return false;
        }

        return f(nums, 0, sum / 2);
    }

    // f代表判断[start...结尾]能否扣减cur为0
    private boolean f(int[] nums, int start, int cur) {
        if(cur < 0) {
            return false;
        }
        if(start == nums.length) {
            return cur == 0;
        }
        // 扣减当前值
        return f(nums, start+1, cur-nums[start]) || 
                // 不扣减当前值
               f(nums, start+1, cur);
    }
}

```

###### 记忆化搜索 | <= O（n^2）

- **思路**：在暴力递归的基础上，增加了 dp 二维表缓存，如果缓存中存在则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，5ms，99.17%，54.6mb，5.02%，时间上，由于有缓存的存在，同样参数的递归行为只会处理一次，所以时间复杂度会比暴力递归的少，即 <= O（n^2），空间上，递归深度最大为 O（n），且还使用了一张 dp 二维表 O（n * t/2），所以额外空间复杂度为 O（n + n* t/2）。

```java
class Solution {

    private Boolean[][] dp;

    public boolean canPartition(int[] nums) {
        if(nums == null || nums.length == 0) {
            return true;
        }

        // 校验总和是否为奇数
        int sum = 0;
        for(int i = 0; i < nums.length; i++) {
            sum += nums[i];
        }
        if(sum % 2 != 0) {
            return false;
        }

        dp = new Boolean[nums.length + 1][sum/2 + 1];
        return f(nums, 0, sum / 2);
    }

    // f代表判断[start...结尾]能否扣减cur为0
    private boolean f(int[] nums, int start, int cur) {
        if(cur < 0) {
            return false;
        }
        if(start == nums.length) {
            return cur == 0;
        }
        if(dp[start][cur] != null) {
            return dp[start][cur];
        }

        // 扣减当前值
        dp[start][cur] = f(nums, start+1, cur-nums[start]) || 
                         // 不扣减当前值
                         f(nums, start+1, cur);

        return dp[start][cur];
    }
}

```

###### 严格表结构优化 | O（n * t/2）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现一个值依赖它下方和左方的值，所以需要初始化好最左边的一列和最下边的一行，然后从下往上、从左往右构建 dp 数组。
- **结论**：时间，31ms，43.18%，42.2mb，11.25%，时间上，记忆化搜索中 cur - nums[start] 执行的都是关键的递归行为，而动态规划中，由于是从下往上、从左往右依次执行，执行了很多多余的参数，相对地就比记忆化搜索的更慢了，所以时间复杂度为 O（n * t/2），空间上，由于使用了一张 dp 二维表数组，所以额外空间复杂度为 O（n * t/2）。

```java
class Solution {

    public boolean canPartition(int[] nums) {
        if(nums == null || nums.length == 0) {
            return true;
        }

        // 校验总和是否为奇数
        int sum = 0;
        for(int i = 0; i < nums.length; i++) {
            sum += nums[i];
        }
        if(sum % 2 != 0) {
            return false;
        }

        // 初始化第一列为true
        boolean[][] dp = new boolean[nums.length + 1][sum/2 + 1];
        for(int i = 0; i < dp.length; i++) {
            dp[i][0] = true;
        }
        // 从下往上, 从左往右初始化
        int rest;
        for(int start = dp.length-2; start > -1; start--) {
            for(int cur = 1; cur < dp[0].length; cur++) {
                // 扣减当前值 || 不扣减当前值
                rest = cur - nums[start];
                dp[start][cur] = (rest < 0? false : dp[start+1][rest]) || dp[start+1][cur];
            }
        }

        return dp[0][dp[0].length-1];
    }
}

```

##### 19）目标和

###### 暴力递归 | O（n^2）

- **思路**：
  1. 设计一个 f（idx，rest）函数，代表获取 [idx, 结尾] 数字能够组合等于 rest 的不同表达式数量。
  2. f 函数的实现分为 2 种情况：
     1. 如果 idx 已越界，则看 rest 是否为 0 了，是则返回 1，代表这一路的组合是一种满足条件的表达式，如果还没为 0，代表已经没有元素可以凑 0 了，即这一路的组合不满足条件。
     2. 如果 idx 没越界，则当前 idx 的符号尝试使用 + 号，以及尝试使用 - 号，返回结果取两者的和。
- **结论**：时间，526ms，11.74%，空间，39.2mb，10.58%，时间上，由于需要尝试两种符号 + 号 和 - 号，递归深度最大为 n，所以一共需要 n*n 次递归，时间复杂度为 O（n^2），空间上，由于需要执行 n^2 次递归行为，所以额外空间复杂度为 O（n^2）。

```java
class Solution {

    public int findTargetSumWays(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return 0;
        }
        return f(nums, 0, target);
    }

    // f代表获取[idx, 结尾]数字能够组合等于rest的不同表达式数量
    private int f(int[] nums, int idx, int rest) {
        if(idx == nums.length) {
            return rest == 0? 1 : 0;
        }
        return f(nums, idx+1, rest-nums[idx]) + f(nums, idx+1, rest+nums[idx]);
    }
}

```

###### 记忆化搜索 | <= O（n^2）

- **思路**：在暴力递归的基础上，增加了一张 dp 二维表缓存，如果缓存中存在则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，7ms，52.70%，空间，41.4mb，5.05%，时间上，由于增加了 dp 缓存，相同参数的递归行为只会被处理一次，也就是时间复杂度会比暴力递归的少，即 <= O（n^2），空间上，由于使用了一张长为 n+1, 宽为 m+1 的表，m 为 target + 所有nums[i] 的总和，所以空间复杂度为 O（n * m）。

```java
class Solution {

    private Integer[][] dp;
    private int offset;

    public int findTargetSumWays(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int min = target, max = target;
        for(int i = 0; i < nums.length; i++) {
            min -= nums[i];
            max += nums[i];
        }

        offset = 0 - min;
        max += offset;
        dp = new Integer[nums.length+1][max+1];

        return f(nums, 0, target + offset);
    }

    // f代表获取[idx, 结尾]数字能够组合等于rest的不同表达式数量
    private int f(int[] nums, int idx, int rest) {
        if(dp[idx][rest] != null) {
            return dp[idx][rest];
        }
        if(idx == nums.length) {
            dp[idx][rest] = rest == offset? 1 : 0;
            return dp[idx][rest];
        }

        dp[idx][rest] = f(nums, idx+1, rest-nums[idx]) + f(nums, idx+1, rest+nums[idx]);
        return dp[idx][rest];
    }
}

```

###### 严格表结构优化 | O（n * m）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现一个值依赖它下方的值，所以这是从下到上，从左到右的初始化模型，因此，首先初始化好最后一行，再从下往上、从左往右初始化 dp 数组。
- **结论**：时间，7ms，52.70%，空间，41.6mb，5.01%，时间上，记 m 为 target + 所有nums[i] 的总和 ，初始化 dp 数组需要遍历 n-1 行，最坏情况下 num[i]=0 时，需要遍历 m 列，因此，最坏的时间复杂度为 O（n * m），空间上，由于使用了一张  n * m 的二维表，所以额外空间复杂度为 O（n * m）。

```java
class Solution {

    public int findTargetSumWays(int[] nums, int target) {
        if(nums == null || nums.length == 0) {
            return 0;
        }

        int min = target, max = target;
        for(int i = 0; i < nums.length; i++) {
            min -= nums[i];
            max += nums[i];
        }

        int offset = 0 - min;
        max += offset;
        int[][] dp = new int[nums.length+1][max+1];

        // 初始化最后一行
        for(int j = 0; j < dp[0].length; j++) {
            dp[dp.length-1][j] = j == offset? 1 : 0;
        }
        // 从下往上、从左往右初始化dp数组
        for(int idx = dp.length-2; idx > -1; idx--) {
            for(int rest = nums[idx]; rest < dp[0].length - nums[idx]; rest++) {
                dp[idx][rest] = dp[idx+1][rest-nums[idx]] + dp[idx+1][rest+nums[idx]];
            }
        }

        return dp[0][target+offset];
    }
}

```

##### 20）回文子串

见《回文 - 回文子串》。

#### 贪心

##### 1）最大子数组和

见《动态规划 - 最大子数组和》。

##### 2）跳跃游戏

见《动态规划 - 跳跃游戏》。

#### 树形 dp

##### 1）验证二叉搜索树

###### 树形 dp 递归 | O（n）

- **思路**：
  1. 通过根节点不断向下收集左孩子和右孩子的信息，来实现树形 dp。
  2. 由于需要左右孩子的信息来判断是否为二叉搜索树，所以结合概念得知，需要直到左、右孩子是否为二叉搜索树，以及最大值和最小值，因此需要建立一个特定数据结构 BstRes。
  3. 如果收集到左右孩子的信息后，则还要进行判断，生成当前根节点的信息，包括是否为二叉搜索树、最大值和最小值。
     1. 如果没有左右孩子，说明当前为叶子节点，那么返回是二叉搜索树，最大值为 val，最小值为 val。
     2. 如果同时有左右孩子，且左、右孩子都为二叉搜索树、 val 大于左孩子的最大值、val 小于右孩子的最小值，那么返回是二叉搜索树，最小值为左孩子最小，最大值为右孩子最大，否则返回 false。
     3. 如果只有左孩子，且左孩子为二叉搜索树、 val 大于左孩子的最大值，那么返回是二叉搜索树，最小值为左孩子最小，最大值为 val，否则返回 false。
     4. 如果只有右孩子，且右孩子为二叉搜索树、 val 小于右孩子的最小值，那么返回是二叉搜索树，最小值为 val，最大值为右孩子最大，否则返回 false。
- **结论**：时间，0ms，100%，38.1mb，51.71%，效率非常好，就这吧~

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class BstRes {
        TreeNode node;
        boolean isBST;
        int min;
        int max;
        
        BstRes(TreeNode node, boolean isBST, int min, int max) {
            this.node = node;
            this.isBST = isBST;
            this.min = min;
            this.max = max;
        }
    }

    public boolean isValidBST(TreeNode root) {
        BstRes bstRes = f(root);
        return bstRes.isBST;
    }

    private BstRes f(TreeNode root) {
        if(root == null) {
            return new BstRes(root, true, root.val, root.val);
        }
        if(root.left == null && root.right == null) {
            return new BstRes(root, true, root.val, root.val);
        } 
        // 左孩子不为空, 右孩子不为空
        else if(root.left != null && root.right != null) {
            BstRes leftRes = f(root.left);
            BstRes rightRes = f(root.right);

            if(leftRes.isBST && rightRes.isBST
                & leftRes.max < root.val && root.val < rightRes.min) {
                return new BstRes(root, true, leftRes.min, rightRes.max);
            }
        } 
        // 左孩子不为空, 右孩子为空
        else if(root.left != null){
            BstRes leftRes = f(root.left);
            if(leftRes.max < root.val && leftRes.isBST) {
                return new BstRes(root, true, leftRes.min, root.val);
            }
        } 
        // 右孩子不为空, 左孩子为空
        else {
            BstRes rightRes = f(root.right);
            if(root.val < rightRes.min && rightRes.isBST) {
                return new BstRes(root, true, root.val, rightRes.max);
            }
        }

        return new BstRes(root, false, Integer.MAX_VALUE, Integer.MIN_VALUE);
    }
}

```

##### 2）二叉树中的最大路径和

###### 树形 dp 递归 | O（n）

- **思路**：
  1. 通过根节点不断向下收集左孩子和右孩子的信息，来实现树形 dp。
  2. 根据题意是求最大路径和，而最大路径和有三个方向：左边+中间、右边+中间、左边+中间+右边，因此设计的递归返回的数据结构有：左边+中间最大和 lmax、右边+中间最大和 rmax、当前的最大路径和 max，来用于给上层组装它自己的最大路径和，其中任意一层 root 可以分为 4 种情况：
     1. root 既没有左孩子也没有右孩子：则直接用当前值作为 dp 信息 返回给上一层。
     2. root 既有左孩子又有右孩子：则先获取左右孩子的 dp 信息，来辅助构建自己的 dp 信息：
        - 当前 lmax = Max{当前值，当前值+左孩子的lmax，当前值+左孩子的rmax}。
        - 当前 rmax = Max{当前值，当前值+右孩子的lmax，当前值+右孩子的rmax}。
        - 当前 max = Max{当前值，当期 lmax，当前 rmax， 当前 lmax +当前 rmax - 当前值，左孩子的 max，右孩子的 max}。
     3. root 只有左孩子没有右孩子：则只获取左孩子的 dp 信息，来辅助构建自己的 dp 信息：
        - 当前 lmax = Max{当前值，当前值+左孩子的lmax，当前值+左孩子的rmax}。
        - 当前 rmax = Max{当前值}。
        - 当前 max = Max{当前值，当期 lmax，当前 rmax， 当前 lmax +当前 rmax - 当前值，左孩子的 max}。
     4. root 没有左孩子只有右孩子：则只获取右孩子的 dp 信息，来辅助构建自己的 dp 信息：
        - 当前 lmax = Max{当前值，当前值+右孩子的lmax，当前值+右孩子的rmax}。
        - 当前 rmax = Max{当前值}。
        - 当前 max = Max{当前值，当期 lmax，当前 rmax， 当前 lmax +当前 rmax - 当前值，右孩子的 max}。
- **结论**：时间，1ms，46.45%，空间，40.7mb，5.08%，虽然效率不是很高，但胜在稳，直接使用树形 dp 的套路来思考又快又准！

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class NodeInfo {
        int lmax;// 左边含根结点最大路径和
        int rmax;// 右边含根结点最大路径和
        int max;// 根结点开始的树的最大路径和

        NodeInfo(int val) {
            this.lmax = val;
            this.rmax = val;
            this.max = val;
        }
    }

    public int maxPathSum(TreeNode root) {
        if(root == null) {
            return 0;
        }
        return f(root).max;
    }

    // f代表获取以root作为根结点的NodeInfo信息, 要保证root不为空!
    private NodeInfo f(TreeNode root) {
        NodeInfo curInfo = new NodeInfo(root.val);

        if(root.left != null && root.right != null) {
            NodeInfo lInfo = f(root.left);
            NodeInfo rInfo = f(root.right);

            // 左边含根结点最大路径和
            curInfo.lmax = Math.max(
                root.val,
                Math.max(root.val + lInfo.lmax, root.val + lInfo.rmax)
            );

            // 右边含根结点最大路径和
            curInfo.rmax = Math.max(
                root.val, 
                Math.max(root.val + rInfo.lmax, root.val + rInfo.rmax)
            );

            // 根结点开始的树的最大路径和
            curInfo.max = Math.max(
                // 中间, 左边最大, 右边最大
                Math.max(root.val, Math.max(lInfo.max, rInfo.max)),
                Math.max(
                    // 左边中间, 右边中间
                    Math.max(curInfo.lmax, curInfo.rmax),
                    // 左边中间 + 右边中间 - 中间
                    curInfo.lmax + curInfo.rmax - root.val
                )
            );
        } else if(root.left != null) {
            NodeInfo lInfo = f(root.left);

            // 左边含根结点最大路径和
            curInfo.lmax = Math.max(
                root.val,
                Math.max(root.val + lInfo.lmax, root.val + lInfo.rmax)
            );

            // 右边含根结点最大路径和
            curInfo.rmax = root.val;

            // 根结点开始的树的最大路径和
            curInfo.max = Math.max(
                // 中间, 左边最大
                Math.max(root.val, lInfo.max),
                Math.max(
                    // 左边中间, 右边中间
                    Math.max(curInfo.lmax, curInfo.rmax),
                    // 左边中间 + 右边中间 - 中间
                    curInfo.lmax + curInfo.rmax - root.val
                )
            );
        } else if(root.right != null) {
            NodeInfo rInfo = f(root.right);

            // 左边含根结点最大路径和
            curInfo.lmax = root.val;

            // 右边含根结点最大路径和
            curInfo.rmax = Math.max(
                root.val, 
                Math.max(root.val + rInfo.lmax, root.val + rInfo.rmax)
            );

            // 根结点开始的树的最大路径和
            curInfo.max = Math.max(
                // 中间, 左边最大, 右边最大
                Math.max(root.val, rInfo.max),
                Math.max(
                    // 左边中间, 右边中间
                    Math.max(curInfo.lmax, curInfo.rmax),
                    // 左边中间 + 右边中间 - 中间
                    curInfo.lmax + curInfo.rmax - root.val
                )
            );
        }

        return curInfo;
    }
}

```

##### 3）打家劫舍3

###### 暴力递归 | > O（2 * n）

- **思路**：
  1. 设计一个 Info 结构，用于跟左右孩子要信息：一个是 isRob，代表孩子节点是否偷了钱，一个是 total，代表孩子节点总共偷了多少钱（偷了钱时包括自身）。
  2. 设计一个 f（root，canRob）函数，代表在前一个节点偷或者没有（当前节点不可以偷或者可以偷）的前提下，所能获得的左右孩子信息。
  3. f 函数实现一共 3 种情况：
     1. 如果 root 当前节点为 null，说明为叶子节点，则返回 0 代表的 Info 信息。
     2. 否则，如果当前节点不可以偷，则获取左右孩子可以偷的信息，然后组装返回即可，因为当前节点是不可以偷的，无需比较其他的了。
     3. 如果当前节点可以偷，此时又可以分为两种情况，即当前偷和当前不偷，取当前偷+左右孩子不偷，和当前不偷+左右孩子偷的最大信息返回即可。
- **结论**：执行超时，时间上，由于最坏情况下，当前节点可以偷需要分为偷和不偷分别递归执行，此时至少需要花费 O（2 * n），空间上，额外空间复杂度取决于递归深度，为 O（2 * n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class Info {
        boolean isRob;// 当前是否偷了钱
        int total;// 当前总共偷了多少钱, 包括自己
        Info(boolean isRob, int total) {
            this.isRob = isRob;
            this.total = total;
        }
    }

    public int rob(TreeNode root) {
        // return getMaxInfo(f(root, true), f(root, false)).total;
        return 0;
    }

    private Info getMaxInfo(Info rob1, Info rob2) {
        return rob1.total > rob2.total? rob1 : rob2;
    }

    // f代表在前一个节点偷或者没偷所能获得的左右孩子信息
    private Info f(TreeNode root, boolean canRob) {
        if(root == null) {
            return new Info(false, 0);
        }

        // 前一个偷了, 当前不能偷, 左右孩子全都要
        if(!canRob) {
            return new Info(false, f(root.left, true).total + f(root.right, true).total);
        } else {
            return getMaxInfo(
                // 前一个没偷, 则当前可以偷
                getCurRobInfo(root, f(root.left, false), f(root.right, false)),
                // 前一个没偷, 当前也可以不偷
                new Info(false, f(root.left, true).total + f(root.right, true).total)
            );
        }
    }

    private Info getCurRobInfo(TreeNode root, Info linfo, Info rinfo) {
        // 前一个没偷, 则还需要取舍左右孩子
        // 左右孩子都偷了
        int tmp;
        if(linfo.isRob && rinfo.isRob) {
            // 不偷左, 不偷右, 偷当前
            if(root.val > (tmp = linfo.total + rinfo.total)) {
                return new Info(true, root.val);
            } 
            // 偷左, 偷右, 不偷当前
            else {
                return new Info(false, tmp);
            }
        } 
        // 左孩子偷了, 右孩子没偷
        else if(linfo.isRob) {
            // 不偷左, 偷右, 偷当前
            if((tmp = root.val + rinfo.total) > linfo.total) {
                return new Info(true, tmp);
            } 
            // 偷左, 不偷右, 不偷当前
            else {
                return new Info(false, linfo.total);
            }
        }
        // 右孩子偷了, 左孩子没偷
        else if(rinfo.isRob) {
            // 偷左, 不偷右, 偷当前
            if((tmp = root.val + linfo.total) > rinfo.total) {
                return new Info(true, tmp);
            } 
            // 不偷左, 偷右, 不偷当前
            else {
                return new Info(false, rinfo.total);
            }
        } 
        // 左右孩子都没有偷
        else {
            // 偷左, 偷右, 偷当前
            return new Info(true, root.val + linfo.total + rinfo.total);
        }
    }
}

```

###### 记忆化搜索 | O（2 * n）

- **思路**：在暴力递归的基础上，增加了 trueDp 和 falseDp 哈希表缓存，如果缓存中存在，则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：执行超时，时间上，由于增加了缓存，访问过一遍的参数将不再重复处理，所以时间复杂度取暴力递归的下限 O（2 * n），空间上，额外空间复杂度取决于递归深度+两张 dp 缓存哈希表，所以为 O（4 * n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class Info {
        boolean isRob;// 当前是否偷了钱
        int total;// 当前总共偷了多少钱, 包括自己
        Info(boolean isRob, int total) {
            this.isRob = isRob;
            this.total = total;
        }
    }

    private Map<TreeNode, Info> trueDp;
    private Map<TreeNode, Info> falseDp;

    public int rob(TreeNode root) {
        trueDp = new HashMap<>();
        falseDp = new HashMap<>();

        Info nullInfo = new Info(false, 0);
        trueDp.put(null, nullInfo);
        falseDp.put(null, nullInfo);

        return getMaxInfo(f(root, true), f(root, false)).total;
    }

    private Info getMaxInfo(Info rob1, Info rob2) {
        return rob1.total > rob2.total? rob1 : rob2;
    }

    // f代表在前一个节点偷或者没偷所能获得的左右孩子信息
    private Info f(TreeNode root, boolean canRob) {
        if(canRob && trueDp.containsKey(root)) {
            return trueDp.get(root);
        }
        if(!canRob && falseDp.containsKey(root)) {
            return falseDp.get(root);
        }

        // 前一个偷了, 当前不能偷, 左右孩子全都要
        Info res;
        if(!canRob) {
            res = new Info(false, f(root.left, true).total + f(root.right, true).total);
            falseDp.put(root, res);
        } else {
            res = getMaxInfo(
                // 前一个没偷, 则当前可以偷
                getCurRobInfo(root, f(root.left, false), f(root.right, false)),
                // 前一个没偷, 当前也可以不偷
                new Info(false, f(root.left, true).total + f(root.right, true).total)
            );
            trueDp.put(root, res);
        }

        return res;
    }

    private Info getCurRobInfo(TreeNode root, Info linfo, Info rinfo) {
        // 前一个没偷, 则还需要取舍左右孩子
        // 左右孩子都偷了
        int tmp;
        if(linfo.isRob && rinfo.isRob) {
            // 不偷左, 不偷右, 偷当前
            if(root.val > (tmp = linfo.total + rinfo.total)) {
                return new Info(true, root.val);
            } 
            // 偷左, 偷右, 不偷当前
            else {
                return new Info(false, tmp);
            }
        } 
        // 左孩子偷了, 右孩子没偷
        else if(linfo.isRob) {
            // 不偷左, 偷右, 偷当前
            if((tmp = root.val + rinfo.total) > linfo.total) {
                return new Info(true, tmp);
            } 
            // 偷左, 不偷右, 不偷当前
            else {
                return new Info(false, linfo.total);
            }
        }
        // 右孩子偷了, 左孩子没偷
        else if(rinfo.isRob) {
            // 偷左, 不偷右, 偷当前
            if((tmp = root.val + linfo.total) > rinfo.total) {
                return new Info(true, tmp);
            } 
            // 不偷左, 偷右, 不偷当前
            else {
                return new Info(false, rinfo.total);
            }
        } 
        // 左右孩子都没有偷
        else {
            // 偷左, 偷右, 偷当前
            return new Info(true, root.val + linfo.total + rinfo.total);
        }
    }
}

```

###### 严格表结构优化 | O（n）

- **思路**：在记忆化搜索的基础上，经过研究值依赖关系，发现发现 falseDp 依赖 trueDp.get（left）和 trueDp.get（right），以及 trueDp 依赖 Max { falseDp.get（left）和 falseDp.get（right），trueDp.get（left）和 trueDp.get（right） }，因此，可以只进行一次后序遍历，在其中分别设置 falseDp 和 trueDp 即可。
- **结论**：时间，3ms，22.15%，空间，42.3mb，5.01%，时间上，由于只需要做一次后序遍历，所以时间复杂度为 O（n），空间上，由于使用了两张 dp 哈希表，以及递归深度，所以额外空间复杂度 O（3 * n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class Info {
        boolean isRob;// 当前是否偷了钱
        int total;// 当前总共偷了多少钱, 包括自己
        Info(boolean isRob, int total) {
            this.isRob = isRob;
            this.total = total;
        }
    }

    private Map<TreeNode, Info> trueDp;
    private Map<TreeNode, Info> falseDp;

    public int rob(TreeNode root) {
        trueDp = new HashMap<>();
        falseDp = new HashMap<>();

        Info nullInfo = new Info(false, 0);
        trueDp.put(null, nullInfo);
        falseDp.put(null, nullInfo);

        dfs(root);
        return getMaxInfo(trueDp.get(root), falseDp.get(root)).total;
    }

    private Info getMaxInfo(Info rob1, Info rob2) {
        return rob1.total > rob2.total? rob1 : rob2;
    }

    private void dfs(TreeNode root) {
        if(root == null) {
            return;
        }

        dfs(root.left);
        dfs(root.right);

        // 前一个偷了, 当前不能偷, 左右孩子全都要
        falseDp.put(
            root, 
            new Info(false, trueDp.get(root.left).total + trueDp.get(root.right).total)
        );
        trueDp.put(root, getMaxInfo(
            // 前一个没偷, 则当前可以偷
            getCurRobInfo(root, falseDp.get(root.left), falseDp.get(root.right)),
            // 前一个没偷, 当前也可以不偷
            new Info(false, trueDp.get(root.left).total + trueDp.get(root.right).total)
        ));
    }

    private Info getCurRobInfo(TreeNode root, Info linfo, Info rinfo) {
        // 前一个没偷, 则还需要取舍左右孩子
        // 左右孩子都偷了
        int tmp;
        if(linfo.isRob && rinfo.isRob) {
            // 不偷左, 不偷右, 偷当前
            if(root.val > (tmp = linfo.total + rinfo.total)) {
                return new Info(true, root.val);
            } 
            // 偷左, 偷右, 不偷当前
            else {
                return new Info(false, tmp);
            }
        } 
        // 左孩子偷了, 右孩子没偷
        else if(linfo.isRob) {
            // 不偷左, 偷右, 偷当前
            if((tmp = root.val + rinfo.total) > linfo.total) {
                return new Info(true, tmp);
            } 
            // 偷左, 不偷右, 不偷当前
            else {
                return new Info(false, linfo.total);
            }
        }
        // 右孩子偷了, 左孩子没偷
        else if(rinfo.isRob) {
            // 偷左, 不偷右, 偷当前
            if((tmp = root.val + linfo.total) > rinfo.total) {
                return new Info(true, tmp);
            } 
            // 不偷左, 偷右, 不偷当前
            else {
                return new Info(false, rinfo.total);
            }
        } 
        // 左右孩子都没有偷
        else {
            // 偷左, 偷右, 偷当前
            return new Info(true, root.val + linfo.total + rinfo.total);
        }
    }
}

```

###### 空间压缩优化 | O（n）

- **思路**：在严格表结构优化的基础上，由于 dp 哈希表存放了所有节点的信息，又分为 trueDp 和 falseDp，所以可以尝试把这两张 dp 哈希表优化成一个 Info[2] 的数组，0 位置存放节点为 false 时的信息，1 位置存放节点为 true 时的信息，构建完成后通过 dfs 返回值返回。
- **结论**：时间，1ms，47.20%，空间，40.7mb，6.85%，时间上，由于只需要执行一次后序遍历，所以时间复杂度为 O（n），空间上，由于递归深度 O（n）是不可以避免的，以及需要一张不断动态申请和释放的 Info[2] 数组，所以额外空间复杂度为 O（n + 2）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class Info {
        boolean isRob;// 当前是否偷了钱
        int total;// 当前总共偷了多少钱, 包括自己
        Info(boolean isRob, int total) {
            this.isRob = isRob;
            this.total = total;
        }
    }

    private Info NULL_INFO = new Info(false, 0);
    private Info[] NUll_ARR = new Info[] {NULL_INFO, NULL_INFO};

    public int rob(TreeNode root) {
        Info[] infos = dfs(root);
        return getMaxInfo(infos[0], infos[1]).total;
    }

    private Info getMaxInfo(Info rob1, Info rob2) {
        return rob1.total > rob2.total? rob1 : rob2;
    }

    // 0: false, 1: true
    private Info[] dfs(TreeNode root) {
        if(root == null) {
            return NUll_ARR;
        }

        Info[] linfos = dfs(root.left);
        Info[] rinfos = dfs(root.right);

        // 前一个偷了, 当前不能偷, 左右孩子全都要
        return new Info[] {
            new Info(false, linfos[1].total + rinfos[1].total),
            getMaxInfo(
                // 前一个没偷, 则当前可以偷
                getCurRobInfo(root, linfos[0], rinfos[0]),
                // 前一个没偷, 当前也可以不偷
                new Info(false, linfos[1].total + rinfos[1].total)
            )
        };
    }

    private Info getCurRobInfo(TreeNode root, Info linfo, Info rinfo) {
        // 前一个没偷, 则还需要取舍左右孩子
        // 左右孩子都偷了
        int tmp;
        if(linfo.isRob && rinfo.isRob) {
            // 不偷左, 不偷右, 偷当前
            if(root.val > (tmp = linfo.total + rinfo.total)) {
                return new Info(true, root.val);
            } 
            // 偷左, 偷右, 不偷当前
            else {
                return new Info(false, tmp);
            }
        } 
        // 左孩子偷了, 右孩子没偷
        else if(linfo.isRob) {
            // 不偷左, 偷右, 偷当前
            if((tmp = root.val + rinfo.total) > linfo.total) {
                return new Info(true, tmp);
            } 
            // 偷左, 不偷右, 不偷当前
            else {
                return new Info(false, linfo.total);
            }
        }
        // 右孩子偷了, 左孩子没偷
        else if(rinfo.isRob) {
            // 偷左, 不偷右, 偷当前
            if((tmp = root.val + linfo.total) > rinfo.total) {
                return new Info(true, tmp);
            } 
            // 不偷左, 偷右, 不偷当前
            else {
                return new Info(false, rinfo.total);
            }
        } 
        // 左右孩子都没有偷
        else {
            // 偷左, 偷右, 偷当前
            return new Info(true, root.val + linfo.total + rinfo.total);
        }
    }
}

```

##### 4）路径总和3

###### 暴力递归 | O（n）

- **思路**：
  1. 设计一个 Info 数据结构： count，代表统计当前节点#独立 val 路径、左 + val 路径、右 + val 路径中，满足等于 target 的数量；sumList，代表存放当前独立 val 路径、左 + val 路径、右 + val 路径三种所有的路径。
  2. 然后设计一个 f（root）函数，可以要取 root 节点的 Info 信息，包括 count 和 sumList。
  3. f 函数的实现，需要先要取 root.left 左孩子的 Info 信息，然后获取 root.right右孩子的 Info 信息，再使用   lInfo.count + rInfo.count 生成当前的 curInfo，接着还需要统计 3 个部分的信息再返回 curInfo：
     1. 把当前独立 val 加入 sumList，然后统计是否等于 target。
     2. 遍历 lInfo.sumList，把当前 val 累加后再加入 sumList，然后统计其中等于 target 的数量。
     3. 遍历 rInfo.sumList，把当前 val 累加后再加入 sumList，然后统计其中等于 target 的数量。
- **结论**：时间，26ms，39.16%，空间，41.7mb，5.04%，时间上，由于需要遍历整棵树的所有节点，所以时间复杂度为 O（n），空间上，最坏情况下，完全二叉树时，i 层节点的 sumList 会存放 2^i 个值，也就是 logn 层的 root节点的 sumList 长度为 O（2^logn），递归深度最大为 O（logn），因此额外空间复杂度为 O（2^logn + logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    class Info {
        int count;
        List<Integer> sumList = new ArrayList<>();

        Info(int count) {
            this.count = count;
        } 
    }

    // 不能跨左根右, 但可不限于一个方向, 如根+左+右...
    public int pathSum(TreeNode root, int targetSum) {
        return f(root, targetSum).count;
    }

    private Info f(TreeNode root, int targetSum) {
        if(root == null) {
            return new Info(0);
        }

        Info lInfo = f(root.left, targetSum);
        Info rInfo = f(root.right, targetSum);
        Info curInfo = new Info(lInfo.count + rInfo.count);

        // 统计独立val路径, 是否等于target
        curInfo.sumList.add(root.val);
        curInfo.count += root.val == targetSum? 1 : 0;

        // 统计左+val路径中, 满足等于target的数量
        if(!lInfo.sumList.isEmpty()) {
            for(Integer sum : lInfo.sumList) {
                sum += root.val;
                curInfo.sumList.add(sum);
                if(sum == targetSum) {
                    curInfo.count++;
                }
            }
        }

        // 统计右+val路径中, 满足等于target的数量
        if(!rInfo.sumList.isEmpty()) {
            for(Integer sum : rInfo.sumList) {
                sum += root.val;
                curInfo.sumList.add(sum);
                if(sum == targetSum) {
                    curInfo.count++;
                }
            }
        }

        return curInfo;
    }
}

```

##### 5）二叉树的直径

###### 暴力递归1 | O（n^2）

- **思路**：先求出每个节点的左高度和右高度，根据题意【左高度 + 右高度】并不是它的直径，而答案可能藏在孩子节点里，所以还要递归找它的孩子节点，取最大的【左高度 + 右高度】然后返回即可。
- **结论**：时间，15ms，9.45%，空间，41.2mb，5.07%，时间上，由于当前节点找左高度和找右高度需要花费 O（n）的时间，而比较每个节点的【左高度+右高度】的最大值，又需要遍历整棵树的所有节点，所以时间复杂度为 O（n^2），空间上，寻找高度递归深度为 O（logn），遍历整棵树的最大深度为 O（logn），所以额外空间复杂度为 O（logn * logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public int diameterOfBinaryTree(TreeNode root) {
        if(root == null) {
            return 0;
        }

        return Math.max(
            getHight(root.left) + getHight(root.right), 
            Math.max(diameterOfBinaryTree(root.left), diameterOfBinaryTree(root.right))
        );
    }

    private int getHight(TreeNode root) {
        if(root == null) {
            return 0;
        }

        int lh = getHight(root.left);
        int rh = getHight(root.right);

        return lh > rh? lh + 1 : rh + 1;
    }
}

```

###### 记忆化搜索1 | O（2 * n）

- **思路**：在暴力递归的基础上，对高度查找的函数增加了一张 dp 哈希表缓存，如果缓存中存在，则从缓存中获取，否则先把结果设置到缓存中再返回。
- **结论**：时间，2ms，10.13%，空间，41.2mb，5.07%，时间上，由于高度查找增加了一层缓存，使得每个节点找它们的【左高度和右高度】只需要处理一次，也就是找高度花费 O（n），遍历树花费 O（n），所以总共的时间复杂度为 O（2 * n），空间上，由于递归深度没改变过，等于暴力递归的递归深度总和 O（logn * logn），同时还增加了一张 dp 缓存表 O（n），所以额外空间复杂度为 O（logn * logn + n）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {
    public int diameterOfBinaryTree(TreeNode root) {
        if(root == null) {
            return 0;
        }

        return Math.max(
            getHight(root.left) + getHight(root.right), 
            Math.max(diameterOfBinaryTree(root.left), diameterOfBinaryTree(root.right))
        );
    }

    private Map<TreeNode, Integer> dp = new HashMap<>();

    private int getHight(TreeNode root) {
        if(dp.containsKey(root)) {
            return dp.get(root);
        }
        if(root == null) {
            dp.put(root, 0);
            return 0;
        }

        int lh = getHight(root.left);
        int rh = getHight(root.right);

        dp.put(root, lh > rh? lh + 1 : rh + 1);
        return dp.get(root);
    }
}

```

###### 暴力递归2 | O（n）

- **思路**：
  1. 在记忆化搜索1 的基础上，研究发现，由于每次都是先找左、右高度，然后再判断最大的左右深度和，即使增加了记忆化缓存，也仍然有大量的重复递归行为，所以，可以在每次返回左、右高度前，增加对最大左右深度和的判断，这样可以减少外层 O（n） 的整棵树遍历。
  2. 而由于调用一次高度查找时，对于每个节点只会被遍历 1 次，没有重复的递归行为，所以并不需要记忆化缓存，去掉就好。
- **结论**：时间，0ms，100%，空间，41mb，7.16%，时间上，由于每个节点只会被遍历 1 次，所以时间复杂度为 O（n），空间上，最大递归深度为 O（logn），所以额外空间复杂度为 O（logn）。

```java
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 *     int val;
 *     TreeNode left;
 *     TreeNode right;
 *     TreeNode() {}
 *     TreeNode(int val) { this.val = val; }
 *     TreeNode(int val, TreeNode left, TreeNode right) {
 *         this.val = val;
 *         this.left = left;
 *         this.right = right;
 *     }
 * }
 */
class Solution {

    private int max;

    public int diameterOfBinaryTree(TreeNode root) {
        if(root == null) {
            return 0;
        }
        getHight(root);
        return max;
    }

    private int getHight(TreeNode root) {
        if(root == null) {
            return 0;
        }

        int lh = getHight(root.left);
        int rh = getHight(root.right);
        max = Math.max(max, lh + rh);
        return lh > rh? lh + 1 : rh + 1;
    }
}

```

### 1.4. 毁天灭地式问题？

毁天灭地式指的是，没看过题解模型是做不出来的，记吧记吧~

#### 1）下一个排列

要求空间复杂度 O（1），即原地计算。

##### 极值解法 | O（n * nlogn）

- **思路**：从后往左遍历，交换次小值和次大值，然后对次小值后面的位置进行顺序排序。

  1. 从后往左遍历，保证找到的次小值是最右的次小值，也就是最右的下坡（相同时的最右一个）。
  2. 找到次小值后，再次从后往左遍历，找到最左的次大致，也就是最左的上坡（相同时不论左右）。
  3. 如果找到次小值，那么必定有次大值（因为存在下坡），接着交换次小值和次大值，可以使得序列整体在 i 位置提高一些，但为了保证下一个序列是相邻的，所以只能提高一点，因此，还需要对 i 位置以后的序列，进行顺序排列，以保证最小。
  4. 如果没找到次小值，那么说明这个序列本身是降序排列的，所以，下一个序列应该为升序序列，因此对整个序列进行顺序排列即可。

  ![1641719239061](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1641719239061.png)

- **结论**：这种题没看过模型是做不出来的（1ms，43.52%），硬记吧，到时面试记不起来也没办法了~

```java
class Solution {
    public void nextPermutation(int[] nums) {
        if(nums == null || nums.length < 2) {
            return;
        }

        // 由于前面降序, 比如例子32116440, 如果想要找到再大点的排列
        // 那么就要从后往前找到一个最右的次小值, 比如最右1的位置(相同的区分左右)
        int i = nums.length - 2;
        while(i > -1 && nums[i] >= nums[i+1]) {
            i--;
        }
        
        // 如果i为-1了, 比如321, 则翻转成123
        if(i == -1) {
            Arrays.sort(nums);
        } 
        // 如果i有效, 说明找到了次小值i, 比如例子321164410中的1
        // 此时由于要大点的排列, 那么还需要再找个最左的次大值, 比如4的位置(相同的不区分左右)
        else {
            int j = nums.length - 1;
            while(j > -1 && nums[i] >= nums[j]) {
                j--;
            }

            // 如果找到有效的次小值j, 说明必定存在比次小值大一点的次大值, 比如例子321164410中的右4
            // 此时, 交换次小值和次大值, 再对i位置后的数组排序, 比如例子321464110中的左4后面的数组
            swap(nums, i, j);
            Arrays.sort(nums, i+1, nums.length);
        }
    }

    private void swap(int[] nums, int from, int to) {
        int tmp = nums[from];
        nums[from] = nums[to];
        nums[to] = tmp;
    }
}

```

#### 2）买卖股票的最佳时机

##### 暴力解法 | O（n^2）

- **思路**：
  1. 根据题意，只能买卖一次，所以只要保证买在最低点，卖在最高点，且最低点在最高点之前即可。
  2. 这样可以设计一个 f（start）的函数，来表示 [start...end]天内买卖股票能够得到的最大利润，其中买入点就是 start，而卖出点由最大利润来决定。
  3. 然后循环判断出最大的买入点，即可得到最大的利润。
- **结论**：执行超时，由于每次比较都没研究子过程的数据状态，所以浪费了很多次的计算，因此还可以继续优化。

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = 0; i < prices.length; i++) {
            max = Math.max(max, f(prices, i));
        }

        return max;
    }

    // f表示[start...end]天内买卖股票能够得到的最大利润
    private int f(int[] prices, int start) {
        if(start < 0 || start >= prices.length) {
            return 0;
        }

        int max = Integer.MIN_VALUE;
        for(int i = start; i < prices.length; i++) {
            max = Math.max(max, prices[i] - prices[start]);
        }

        return max;
    }
}

```

##### 极值法 | O（n）

- **思路**：
  1. 从左到右遍历，每次找到极小值则记录起来，用于与后面的股票价格相比，得出的最大利润则是答案。
  2. 其中，如果遇到极小值是比之前的更小，此时算利润的话是为负数，肯定不是最大值，所以只更新掉替换之前极小值即可，无需计算利润。
- **结论**：时间，2ms，88.95%，空间，51mb，90.14%， 是数学的求极值问题，所以用暴力递归 -> 记忆化搜索 -> 动态规划是想不出来的！

```java
class Solution {
    public int maxProfit(int[] prices) {
        if(prices == null || prices.length == 0) {
            return 0;
        }

        int max_profit = 0, min_price = Integer.MAX_VALUE, profit;
        for(int i = 0; i < prices.length; i++) {
            if(prices[i] < min_price) {
                min_price = prices[i];
            } else {
                max_profit = Math.max(max_profit, prices[i] - min_price);
            }
        }

        return max_profit;
    }
}

```

#### 3）多数元素

##### 暴力解法 | O（2n）

- **思路**：遍历统计每个元素出现的次数，在一个哈希表中登记好，然后遍历这个哈希表，取出现次数大于 n / 2 的元素返回即可。
- **结论**：时间，14ms，14.91%，空间，43.9mb，72.03%，时间上，由于遍历两遍，时间复杂度最坏 O（2n），空间上由于需要一张哈希表，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public int majorityElement(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        Map<Integer, Integer> map = new HashMap<>();
        for(int i = 0; i < nums.length; i++) {
            if(map.containsKey(nums[i])) {
                map.put(nums[i], map.get(nums[i]) + 1);
            } else {
                map.put(nums[i], 1);
            }
        }

        for(Map.Entry<Integer, Integer> entry : map.entrySet()) {
            if(entry.getValue() > (nums.length >>> 1)) {
                return entry.getKey();
            }
        }

        return Integer.MIN_VALUE;
    }
}

```

##### 排序法 | O（n * logn）

- **思路**：由于求的是出现次数大于 n / 2 的元素，所以对原数组进行顺序排序，目标元素必经过中点，因此取中点元素返回即可。
- **结论**：时间，2ms，61.20%，空间，44.7mb，5.04%，时间上，快排需要 O（n * logn），应该是测试用例没有足够多，所以才看起来比暴力解法的 O（n）还快，而空间上，递归栈的深度为 O（logn）。

```java
class Solution {
    public int majorityElement(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        Arrays.sort(nums);
        return nums[nums.length >>> 1];
    }
}

```

##### 摩尔投票法 | O（n）

- **思路**：
  1. Boyer- Moore，摩尔投票算法，初始时，记投票数为 0，然后开始遍历。
  2. 如果投票数为 0 时，则选举当前遍历到的元素作为返回值，然后继续遍历。
  3. 如果投票数不为 0，则要看当前遍历到的元素是否等于标记的返回值，如果等于则投票 + 1，否则投票 -1，继续遍历。
  4. 遍历完整个数组，最后标记的返回值就是答案。
- **结论**：时间，1ms，99.91%，空间，44.6mb，5.04%，时间复杂度为 O（n），空间复杂度为 O（1），效率非常好，但没心思去证明它了~

```java
class Solution {
    public int majorityElement(int[] nums) {
        if(nums == null || nums.length == 0) {
            return Integer.MIN_VALUE;
        }

        int count = 0, res = Integer.MIN_VALUE;
        for(int i = 0; i < nums.length; i++) {
            if(count == 0) {
                res = nums[i];
                count++;
            } else {
                count += nums[i] == res? 1 : -1;
            }
        }

        return res;
    }
}

```

#### 4）除自身以外数组的乘积

##### 前缀积后缀积 | O（n）

- **思路**：
  1. 根据题意，不能使用除法，且要在 O（n）时间内完成计算，经过研究可得知，每个元素除自身以外的乘积=它的前缀元素之积 * 它的后缀元素之积，因此，只要先提前算好前缀积、后缀积，即可得到答案。
  2. 其中要注意的是，为了能够让额外空间复杂度降低到 O（1），需要前缀积数组复用返回结果的数组，并且通过一个变量 r 来替代后缀积的数组。
- **结论**：时间，2ms，45.67%，空间，49.6mb，31.37%，效率就这样吧~

```java
class Solution {
    public int[] productExceptSelf(int[] nums) {
        if(nums == null || nums.length == 0) {
            return new int[0];
        }

        // 计算前缀积
        int[] res = new int[nums.length];
        for(int i = 0; i < nums.length; i++) {
            if(i == 0) {
                res[i] = 1;
            } else {
                res[i] = res[i-1] * nums[i-1];
            }
        }

        // 计算结果=前缀积 * 后缀积
        int r = 1;
        for(int i = nums.length - 1; i > -1; i--) {
            if(i == nums.length - 1) {
                res[i] = res[i] * r;
            } else {
                r = r * nums[i+1];
                res[i] = res[i] * r;
            }
        }

        return res;
    }
}

```

#### 5）完全平方数

见《动态规划 - 完全平方数 - 四平方和定理推论》。

#### 6）寻找重复数

##### 暴力解法 | O（n^2）

- **思路**：双重循环遍历，碰到第一个值相同的元素则返回。
- **结论**：执行超时，时间上，由于是双重循环遍历，所以时间复杂度为 O（n^2），空间上，由于只用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int findDuplicate(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return -1;
        }

        for(int i = 0; i < nums.length; i++) {
            for(int j = i + 1; j < nums.length; j++) {
                if(nums[i] == nums[j]) {
                    return nums[i];
                }
            }
        }

        return -1;
    }
}

```

##### 哈希表法 | O（n）

- **思路**：从头到尾遍历数组，然后判断当前元素是否已经存在哈希表中，如果存在则代表重复了，返回即可，否则把元素加入哈希表中。
- **结论**：时间，19ms，44.22%，空间，57.9mb，5.01%，时间上，由于只遍历一次数组，所以时间复杂度为 O（n），空间上，由于使用了一个哈希表，所以额外空间复杂度为 O（n）。

```java
class Solution {
    public int findDuplicate(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return -1;
        }

        Set<Integer> set = new HashSet<>();
        for(int i = 0; i < nums.length; i++) {
            if(set.contains(nums[i])) {
                return nums[i];
            } else {
                set.add(nums[i]);
            }
        }

        return -1;
    }
}

```

##### 二分查找法 | O（n * logn）

- **思路**：
  1. 看到二分查找的标签，首先要去想研究数组的单调性。
  2. 根据本题题意，分析可得，在值为 1,2,...n 的数组中，如果统计小于等于 i 值的个数，由于有重复值的存在，则会导致重复值及其以后的统计小于等于的个数都会比当前 i 值还大，即存在着单调性。
  3. 另外，至于在值为 1,3...,n（重复值 3 之前的 2 缺失数组） 或者 1,2,3,..,n （重复值 3 之后的 4 缺失数组）中，上述结论同样成立，前者相当于 3 占据了 2 的位置而已，对于 1 依然成立；后者相当于 3 占据了 4 的位置而已，相对于 5,...n 依然成立。
  4. 因此，基于这种单调性，可对 count[i] 数组进行二分查找，如果发现 i 处的 count 值 > i 值，那么说明重复值就在当下或者在左前面；否则，如果发现 i 处的 count 值 <= i 值，那么说明重复值在右后面。
- **结论**：时间，25ms，38.09%，空间，58.4mb，5.01%，时间上，由于需要二分 1,2,3,...,数组花费 O（logn），每步二分又要遍历 nums 数组花费 O（n），所以时间复杂度为 O（n * logn），空间上，由于只花费了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int findDuplicate(int[] nums) {
        if(nums == null || nums.length <= 1) {
            return -1;
        }

        // l、r代表的不是原数组的下标, 而是1,2,3...n数值统计数组count[i]的下标
        int res = -1, l = 1, r = nums.length-1, mid, icount;
        while(l <= r) {
            mid = (l + r) >>> 1;
            icount = getCount(nums, mid);
            
            // 如果小于等于mid值的个数, 大于当前mid下标, 说明重复值在左边, 或者本身可能就是重复值
            if(icount > mid) {
                r = mid - 1;
                res = mid;
            } 
            // 如果小于等于mid值的个数, 小于等于当前mid下标, 说明重复值
            else {
                l = mid + 1;
            }
        }

        return res;
    }

    // 统计原生数组中小于等于target的个数
    private int getCount(int[] nums, int target) {
        int count = 0;
        for(int i = 0; i < nums.length; i++) {
            if(nums[i] <= target) {
                count++;
            }
        }
        return count;
    }
}

```

##### 数组转链表法 | O（n + a）

- **思路**：

  1. 这个方法很奇妙，由于数组的下标为 0,1,2,...,n-1，值是 1,2,...n，如果把 nums[0] 看作是链头节点，再把 nums[nums[0]] 看作是链头的下一个节点...，则构成一条链的数据结构，如果 0 位置的节点一旦出去就回不来了，但如果是重复元素也不会影响最终结果，因为如果 nums[0] 与 nums[1] 重复，判断 nums[1] 也是一样的。 
  2. 由于数组中存在重复元素，所以这种链的数据结构就存在者链环，因此，完全可以走《链表 - 环形链表2》的快慢指针套路了~

  ![1643716096926](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1643716096926.png)

- **结论**：时间，4ms，95.17%，空间，58.4mb，5.01%，时间上，遍历一次链表 + 再遍历一次链头到入环点的距离 a，时间复杂度为 O（n + a），空间上，由于只使用了有限几个变量，所以额外空间复杂度为 O（1）。

```java
class Solution {
    public int findDuplicate(int[] nums) {
        if(nums == null || nums.length == 0) {
            return -1;
        }

        // 慢指针一次走1步, 快指针一次走2步
        int t1 = nums[0], t2 = nums[0];
        do {
            t1 = nums[t1];
            t2 = nums[nums[t2]];
        } while(t1 != t2);

        // 快慢指针第一次相遇后, 快指针回到链表开头, 然后与慢指针每次走1步, 最终会在入环点相遇
        t2 = nums[0];
        while(t1 != t2) {
            t1 = nums[t1];
            t2 = nums[t2];
        }

        return t1;
    }
}

```

#### 7）任务调度器

##### 暴力解法 | O（n + m + n * 2m）

- **思路**：
  1. 经过数组状态的研究，发现只要选择优先选择不在冷却中的，且执行次数最多的任务，优先执行，那么就可以得到最优解，因为这样可以平均剩余任务的执行次数，让 cpu 处于等待状态的概率尽量小，从而获取最短的任务执行时间。
  2. 在实现方面，是通过维护 time 时间轴来得到结果的，其中要注意的地方有：
     1. 在任务都冷却时，设置 time + n + 1可以跳过冷却时间。
     2. 而获取到最小冷却后可执行时间的任务时，需要和当前时间轴相比，如果当前时间大则不能更新，因为时间不能倒流，而如果最小冷却后可执行时间大于当前时间，那么时间轴则跳到该可执行时间，以减少时间复杂度。
     3. 每次都优先选择不在冷却中，且执行次数最多的任务来执行，执行后减少可执行次数，以及更新可执行时间为下次冷却后可执行的时间。
- **结论**：时间，72ms，5.30%，空间，42.3mb，6.17%，时间上，初始化 countMap 需要 O（n），初始化 nextValids 和 rests 需要 O（m），遍历一次所有任务为 O（n），每次任务遍历中需要有 2 次的所有的任务种类遍历为 O（m），所以时间复杂度为 O（n + m + n * 2m），空间上，由于使用了一张 m 大的 countMap，一个 m 长的 nextValids 和 rests，所以额外空间复杂度为 O（3m）。

```java
class Solution {
    public int leastInterval(char[] tasks, int n) {
        if(tasks == null || tasks.length == 0) {
            return 0;
        }
        if(n == 0) {
            return tasks.length;
        }

        // 统计每个任务的个数
        Map<Character, Integer> countMap = new HashMap<>();
        for(int i = 0; i < tasks.length; i++) {
            countMap.put(tasks[i], countMap.getOrDefault(tasks[i], 0) + 1);
        }

        // 初始化最早可执行的时间数组nextValids, 以及任务剩余执行次数数组rests
        int taskSize = countMap.size();
        List<Integer> nextValids = new ArrayList<>(taskSize);
        List<Integer> rests = new ArrayList<>(taskSize);
        for(Map.Entry<Character, Integer> entry : countMap.entrySet()) {
            nextValids.add(1);
            rests.add(entry.getValue());
        }

        // 更新时间轴time, 默认从0开始
        int time = 0, nextValid, besti;
        for(int i = 0; i < tasks.length; i++) {
            // 时间轴每次都运行, 且后面负责让time跳过等待时间, 以减少时间复杂度
            time++;

            // 选择其中最小的被冷却限制后的时间
            nextValid = getNextValid(nextValids, rests);
            
            // 时间轴移动到nextValid或者保持不动
            time = Math.max(time, nextValid);

            // 核心逻辑: 选择不在冷却中任务, 且剩余执行次数最多的任务索引
            besti = chooseBestTaskIndex(nextValids, rests, time);
            if(besti != -1) {
                // 执行一次besti处的任务
                rests.set(besti, rests.get(besti) - 1);
                // 更新besti处的任务经过冷却后下次可执行的时间, time跳过等待时间
                nextValids.set(besti, time + n + 1);
            }
        }

        // 全部任务遍历执行并等待完毕, 则返回时间轴当前来到的时间
        return time;
    }

    private int chooseBestTaskIndex(List<Integer> nextValids, List<Integer> rests, int time) {
        int besti = -1;
        for(int i = 0; i < nextValids.size(); i++) {
            // 从不在冷却中的任务进行选择
            if(rests.get(i) != 0 && nextValids.get(i) <= time) {
                // 初始时选择第一个不在冷却中的任务
                if(besti == -1) {
                    besti = i;
                }
                // 优先选择剩余执行次数最多的任务
                else if(rests.get(i) > rests.get(besti)){
                    besti = i;
                }
            }
        }
        return besti;
    }

    private int getNextValid(List<Integer> nextValids, List<Integer> rests) {
        int min = Integer.MAX_VALUE;
        for(int i = 0; i < nextValids.size(); i++) {
            // 从还有执行次数的任务中选取
            if(rests.get(i) != 0) {
                min = Math.min(min, nextValids.get(i));
            }
        }
        return min;
    }
}

```

##### 多边形分析法 | O（n + m）

- **思路**：把最多执行次数的任务放满第一列，其余任务从 n-1 开始，由下往上堆叠任务组成 m 长 n+1 宽的多边形，此时，这些任务的最短执行时间=(最多的执行次数-1) * (n+1) + 额外执行的任务数量，证明略，不过由于要执行完所有任务，所以还要将其与任务总数求最大值才返回。

  ![1644310807277](D:\MyData\yaocs2\AppData\Roaming\Typora\typora-user-images\1644310807277.png)

- **结论**：时间，15ms，38.41%，空间，41.8mb，10.25%，时间上，统计任务个数要 O（n），统计任务最大执行次数要 O（m），所以时间复杂度为 O（n + m），空间上，由于使用了一张 m 长的 countMap，所以额外空间复杂度为 O（m）。

```java
class Solution {
    public int leastInterval(char[] tasks, int n) {
        if(tasks == null || tasks.length == 0) {
            return 0;
        }
        if(n == 0) {
            return tasks.length;
        }

        // 统计每个任务的个数
        int count, maxCount = 0;
        Map<Character, Integer> countMap = new HashMap<>();
        for(int i = 0; i < tasks.length; i++) {
            count = countMap.getOrDefault(tasks[i], 0) + 1;
            countMap.put(tasks[i], count);
            maxCount = Math.max(maxCount, count);
        }

        // 具有最多执行次数的任务数量
        int extraCount = 0; 
        for(Map.Entry<Character, Integer> entry : countMap.entrySet()) {
            if(entry.getValue() == maxCount) {
                extraCount++;
            }
        }

        // 最短时间=(最多的执行次数-1) * (n+1) + 额外执行的任务数量
        return Math.max((maxCount-1) * (n+1) + extraCount, tasks.length);
    }
}

```

